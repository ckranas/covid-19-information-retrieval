22aa3efee096e0b6bc775fe524931b18676bac81
Cost-Effectiveness of Surveillance for Bloodstream Infections for Sepsis Manage-ment in Low-Resource Settings
E C Penno S J Baird J A Crump 


Introduction Yearly 300 000 people develop visceral leishmaniasis (VL), a parasitic disease, which is fatal if left untreated. While the development of rk39 rapid diagnostic tests have revolutionised the serodiagnosis of VL on the Indian subcontinent, sensitivity is sub-optimal in Eastern Africa. The only serological test with proven high accuracy in all VL endemic regions is the Direct Agglutination Test (DAT). This test is however not suitable as a point-of-care test. The epitopes responsible for the agglutination reaction in DAT are unknown. Aim We want to develop an alternative rapid serodiagnostic test for Eastern Africa based on peptides that mimic the major epitopes of the DAT antigen, so called mimotopes. African VL patient sera. With these antibodies we screened a phage library displaying random dodecamer peptides. Selected phages were confirmed in their idiotype-specificity by means of ELISA. The peptide-coding DNA of the phages of interest was sequenced and the corresponding peptides were synthesised. The reactivity of these peptides was assessed in ELISA against a panel of DAT positive (n = 71) and negative (n = 22) sera originating from Sudan and Ethiopia. To increase their reactivity, peptide repeats were generated using 1-ethyl-3 (3dimethylaminopropyl)carbodiimide (EDC). In addition, one peptide was synthesised as a 3-tandem-repeat stretch. Competition between DAT and peptides was evaluated in an inhibition ELISA. Results Among the 30 synthetic peptides, four showed diagnostic potential with an Area Under the Curve of 0.74, 0.76, 0.89 and 0.78. However ELISA signals were weak. Generating peptide repeats by EDC polymerisation led to a 15.6 fold increase of average O.D.. This could be confirmed by a trirepeat-peptide, which increased reactivity in a comparable manner (7.1 fold increase of average O.D.). Reactivity of the peptide repeats was inhibited up to 72.0 percent when sera were pre-incubated with DAT antigen. We identified four mimotopes of the DAT epitopes. Moreover we showed that peptide reactivity can be increased through polymerisation as tandem repeats. Background Plasmodium falciparum parasites avoid the blood circulation and splenic clearance by attaching infected erythrocytes to blood vessels. The sequestration of parasites in host organs provoke malaria pathogenesis. Severe malaria symptoms are associated with parasites expressing an antigenically distinct subset of the P. falciparum erythrocyte membrane protein 1 (PfEMP1) adhesins, which mediate binding to endothelial receptors. Previous studies have converged to indicate that PfEMP1 with so-called CIDRa1 domains capable of binding endothelial protein C receptor (EPCR) constitute the PfEMP1 subset expressed in severe malaria patients. Method Here, we quantified var transcripts in children hospitalized with severe (N = 123) or uncomplicated (N = 42) malaria and in 22 children found P. falciparum positive during a village cross sectional survey, using an extensive set of quantitative PCR primers targeting most subtypes of PFEMP1 var genes. Introduction Bacterial blood stream infections are a common cause of mortality and morbidity around the world. As the causative agents and the resulting treatment decisions vary by country and region, near-patient testing and surveillance tools are necessary to monitor the bacterial causes. A recent study 1 suggested that about 534 lives per 100 000 patients could be saved with an incremental cost-effectiveness ratio of USD 4739. The gold standard to identify bacterial blood stream infections is blood culture, a methodology not widely available in resourcepoor settings. Aim The aim of the study was to develop draft target product profiles of a simplified blood culture system to inform product development efforts. Methods To identify the minimal/optimal specifications, FIND interviewed experts in Africa and Asia to understand challenges and needs in the relevant settings. The group was composed of infectious disease physicians, public health/clinical microbiologists, clinical researchers and technology experts, and characteristics were reviewed and discussed in a structured phone/video interview. In total, eight experts were interviewed and all independently suggested that blood culture should ideally be available at district hospital level (level 2). During the interviews many of the same operational challenges, such as the limited availability of blood culture bottles, electricity and connectivity, extreme dust and the lack of ambient temperature control were identified across the different regions. In addition, in some places blood culture bottles were only entered into a dedicated system (manual/automated) after many hours delay (4-48 hr) due to logistical challenges or long distances. Further to these operational challenges, the "culture of culture"i.e., the social aspects of using culture as a diagnostic methodwas identified as a hurdle in many places. Conclusion Blood cultures, although the accepted gold standard, are not widely available outside of reference or research centres in Africa and Asia. To extend the reach of this important diagnostic tool, it is crucial to engage product developers and academic research partners to develop simple alternatives. In addition, our work highlighted the need for integrated training for laboratory and clinical staff to overcome the many hurdles related to local perceptions of blood culture. Trypanosoma brucei gambiense human African trypanosomiasis (gHAT) is by screening using serological tests. Until recently, the Card Agglutination Test for Trypanosomiasis (CATT) was the only screening tool used routinely. This test has several limitations, which have been partially addressed by the recent availability of rapid diagnostic tests (RDTs). However, current RDTs, such as the SD BIOLIONE HAT (RDT1), require the production of native antigens, which is challenging. Aim The objective of this study was to prospectively evaluate the diagnostic accuracy of a new RDT, the SD BIOLINE HAT 2.0 (RDT2), developed using recombinant antigens, and demonstrate its non-inferiority in comparison to RDT1. Methods The RDT2 was evaluated in 10 health facilities and 5 mobile teams in the Democratic Republic of the Congo. A population of 57 632 individuals, including 260 confirmed HAT cases, was screened using CATT, RDT1 and RDT2 in parallel. Results When results of passive and active screening were combined, the sensitivity of CATT, RDT1 and RDT2 was 62.5%, 59.0% and 71.2%, and the specificity was 99.2%, 98.9% and 98.1%, respectively. Sensitivity results were lower than previously reported, as some HAT cases were detected by only one test. Sensitivity in passive screening (74.6%, 70.0% and 90.1%) was higher than in active screening (51.8%, 49.2% and 54.8%). The difference may be attributed to differential expression of antigens by parasites as infections progress, resulting in immune responses to multiple antigens with advancing disease. Combining RDT1 with RDT2 in passive screening resulted in a higher sensitivity (98.4%). The improvement in sensitivity was more pronounced in active screening, where it was low in each of the 3 tests, and combining the two RDTs resulted in a significant improvement (83.0%). Conclusion This study demonstrated the non-inferiority of RDT2 vs RDT1. The observed low sensitivity of all three screening tests could be due to each test detecting a subpopulation of cases with different serological profiles. While the cost-effectiveness of algorithms including several screening tests should be investigated, this study has shown that using two or more tests to screen for HAT greatly improves sensitivity. Introduction Among the research priorities in the diagnosis of visceral leishmaniasis (VL), are determining treatment outcome and predicting progression from asymptomatic infection to symptomatic disease. Although previous work has shown the potential of an IgG1 test for those purposes, it currently relies on the use of a whole Leishmania lysate. Finding the key antigen(s) or epitope(s) to which the IgG1 binds could enable a more standardized, easily produced, lower cost, specific and sensitive test. Standard wet laboratory techniques to identify antigens, such as immunoblots with whole Leishmania lysate, can be optimised by in silico searches. Aim Combine wet-lab and in silico techniques to optimize the search for biomarkers able to predict progression to disease and determine cure versus relapse after treatment of VL. Methods Mass spectrometry (MS) identified 678 putative promastigote proteins that reacted with IgG1 from Indian VL patients. In order to identify the proteins most likely to be antigenic, the following properties were assessed, in silico: Non-low gene expression (haploid depth -RNAseq) for promastigotes and amastigotes; Confident MS identification. All proteins satisfying those criteria were then analysed further for (i) secretion and (ii) presence of tandem repeats (TR). All these short-listed proteins had their epitopes mapped using four in silico algorithms. The highest scoring 40 epitopes identified by each algorithm and 150 epitopes predicted by ≥3 algorithms are being synthesised on a microarray and tested for IgG1 recognition using sera from VL patients. Additionally, the epitope of a protein currently used in VL diagnosis will be mapped using peptide arrays. Results From 678 proteins identified by MS, 62 were secreted proteins expressed in both life cycle stages while 3 satisfied the second criterion i.e. presence of TR, expressed in both life cycle stages. MS identified all proteins with confidence. The antigenic (IgG1) evaluation of the selected peptides is ongoing and we will present the results. Conclusion In silico tools can be applied to screen for desired protein properties, dramatically reducing large output sometimes generated by simple wet-lab experiments. Our preliminary in silico epitope mapping indicates good performance of this approach, which we will evaluate by serology using sera from VL patients. Introduction Identifying the causative agent implicated in an outbreak is crucial for selecting suitable treatment and/or control measures. Usually an outbreak starts with patients showing unspecific symptoms, such as headache, fever, back pain, etc. Polymerase Chain Reaction (PCR) is considered as standard tests for molecular detection of pathogens in an early diagnostic window. PCR assays rely on the use of known sequence data sets of specific target genes. A false negative PCR result might be obtained in case of a novel variant of a known pathogen or sequences might be unknown for the agents of emerging diseases. Next generation Sequencing (NGS), can be applied to identify the pathogen responsible for the outbreak through sequencing all the DNA or RNA information present in a sample extract. Sequencing data obtained can potentially identify new agents or new variants of known agents. Aim In this study, we explored a sequencing protocol relying on multiple displacement amplification and nanopore sequencing in order to allow the identification of the causative agent in a sample. To develop the procedure for use in a suitcase laboratory, a mock sample consisting of supernatant from a Zika virus tissue culture was used. Methods The whole procedure took around 8 hours as follow: RNA extraction, 30 min; DNA digestion and reverse transcription of RNA, 35 min; second strand cDNA synthesis, 90 min; random isothermal amplification, 120 min; library preparation, 70 min; sequencing, 20 min; data analysis using BLAST search, 120 min. In total, 34 326 sequence files covering around 10 000 bases were extracted. BLAST search revealed the presence of Zika virus, which was close to an isolate from Senegal. In conclusion, the protocol has potential for point of need sequencing to identify RNA viruses. The whole procedure was operated in a suitcase laboratory powered by solar power batteries. However, the procedure is cooling chain dependent and the cost per sequencing run is still very high. In addition, sequencing and data analysis pipelines for optimized and rapid subtraction of background information and assembly of relevant virus information are required so that they can be operated on a laptop. The approach needs further development before it can be tested in the field with real patient samples. Loop-mediated isothermal amplification for asymptomatic malaria diagnosis in the Peruvian Amazon: technical performance and pilot implementation in challenging field settings Introduction Loop-mediated isothermal amplification (LAMP) methodology offers an opportunity for point-of-care (POC) molecular detection of asymptomatic malaria infections. However, there is still little evidence on the feasibility of implementing this technique for population screenings in isolated field settings. Methods Overall, 1167 individuals from terrestrial ('Road') and hydric ('Riverine') communities of the Peruvian Amazon were recruited for a cross-sectional survey to detect asymptomatic malaria infection. The operational feasibility of introducing LAMP in the routine logistics of the mobile screening teams was assessed based on field-suitability parameters, and complemented with pilot POC-LAMP implementation in an isolated community without laboratory infrastructure. The performance of LAMP diagnosis to detect low-density infections in the study area was evaluated in a subgroup of 503 samples, using real-time Polymerase Chain Reaction (qPCR) as reference standard. Results LAMP had a sensitivity of 91.8% (87.7-94.9) and specificity of 91.9% (87.8-95.0) when compared to qPCR, and the overall accuracy was significantly better among samples collected during Road screenings than in Riverine communities (P ≤ 0.004). LAMP-based diagnostic strategy was successfully implemented within the mobile field-team logistics, i.e. simple equipment requirements, unambiguous result interpretation and sufficient throughput capacity. The LAMP-POC pilot in the community allowed for a notable reduction in the turnaround time for case management, from 12-24 hr to <5 hr. Hemolysis of samples was regularly observed in Riverine screenings and could help explaining the hindered performance/interpretation of the LAMP reaction in these communities. Conclusions LAMP-based molecular malaria diagnostics can be deployed outside of reference laboratories, providing similar performance as highly-sensitive qPCR assays. However, scale-up in remote field settings needs to consider a number of logistical challenges (e.g. environmental conditions, labor-intensiveness in large population screenings) that can influence its optimal implementation. Introduction Early diagnosis and treatment of Buruli ulcer (BU), a necrotizing skin infection caused by Mycobacterium ulcerans, are crucial for case management and disease control. Laboratory confirmation of BU by the currently recommended IS2404 PCR requires well-equipped molecular biology laboratories and is thus restricted to tertiary (reference) level facilities in endemic countries. However, as the burden of BU is in rural areas, molecular detection formats applicable as pointof-care tests are urgently needed. Loop-mediated isothermal amplification (LAMP) is considered an appropriate technology for microscopy level laboratories. Aim The aim of this study was to optimize and evaluate a dry reagent-based (DRB) LAMP test for detection of M. ulcerans DNA (IS2404) using a portable fluorimeter. Methods Two sets of previously validated IS2404 LAMP primers were analysed using freeze-dried LAMP chemistries from OptiGene and Lucigen. A Genie III fluorimeter (OptiGene) was used for isothermal amplification, detection of LAMP products and confirmation of amplicon specificity by annealing curve analysis. Different freeze-dried primer/chemistry combinations were prepared and their performance assessed by analysis of specificity, sensitivity (as lower limit of detection [LOD] ) and time to positivity (Tp) using serial dilutions of IS2404 plasmid standards, M. ulcerans culture extracts and DNA extracts derived from swab and fine-needle aspirate samples from BU patients, as well as must-not-detect samples from laboratory confirmed leprosy patients. Results Both primer combinations using OptiGene chemistry detected M. ulcerans DNA in all M. ulcerans culture extracts and clinical BU samples, and showed 100% specificity. The LOD was 5 and 0.5 M. ulcerans genome equivalents, respectively. The Tp was 3-19 min depending on the amount of template DNA. Freeze-dried primer combinations using Lucigen chemistry did not yield any positive result under our laboratory conditions. The optimized DRB LAMP test was highly specific, sensitive and robust and will now be subjected to largescale, blinded clinical validation. In addition, non-automated DNA extraction procedures will be assessed for an utterly fieldfriendly application. DRB-LAMP will contribute in filling the diagnostic gap between the confirmatory testing conducted in tertiary laboratories and the endemic foci in rural areas where the major burden of BU exists. Shotgun metagenomics as a tool for the rapid diagnosis and genotyping of Dengue Introduction Dengue virus (DENV) diagnosis can be performed by serological tests, isolation of the virus or by molecular methods. Especially, qRT-PCR and nested RT-PCR are widely used to detect DENV during the acute phase of illness. For genotyping, Sanger sequencing is often used; however, it is time-consuming and unsuitable for initial diagnosis. Therefore, new methodologies are required to improve rapid detection and genotyping of DENV and other viruses directly from clinical material. Aim We applied shotgun metagenomics combined with sequence classification methods to identify and type DENV directly from plasma samples. Methods From five DENV-2 RT-PCR positive patients' samples from Venezuela (2015), viral RNA was isolated using the QIAmp â Viral RNA kit (Qiagen). cDNA libraries were prepared with TruSeq RNA v2 library prep kit (Illumina) and sequenced on a MiSeq instrument (Illumina) using MiSeq Reagent Kit v2 (300-cycles, paired-end). First, the data was analysed with Taxonomer (IDbyDNA), an ultrafast web-tool for comprehensive metagenomics data investigation. Subsequently, the raw reads were mapped against a human genome (hg18) and de novo assembled using CLC Genomics Workbench v9.5.4. Next, a BLAST analysis of the longest contig was performed. The phylogenetic analysis was performed in MEGA v7.0 using the maximum likelihood method, based on the general time reversible model, with 1000 bootstrap replications. The mean total number of reads for the samples was 3 145 628. Taxonomer could correctly identify DENV-2 in all samples. About 85.23% of the reads were mapped against the human genome, while the proportion of reads that matched DENV were 4.02%. After de novo assembly, sequences with an average length of 10 700 bp and an average coverage of 1651.15 reads were obtained. Using BLAST, the closest strains identified were DENV 2 strains (99% identity) isolated in Venezuela between 2005 and 2007. Conclusion Dengue identification and genotyping was possible directly from the patients' plasma. The whole workflow was performed in three days, which is approximately twice as fast as what is needed for classical genotyping through standard isolation and identification. This approach also enables the detection and discrimination of other viruses causing similar clinical presentations, namely chikungunya and Zika. Introduction Malaria elimination is an increasingly accepted worldwide goal. In Solomon Islands, intensified control has drastically reduced malaria transmission and Plasmodium vivax is now the predominant Plasmodium species, with most infections afebrile and of low density. Asymptomatic and submicroscopic infections are a challenge for the malaria control program and a better understanding of their role in the local P. vivax epidemiology is thus essential. Methods An observational cohort was established among children (0.5-12 years old) from 20 villages in Ngella (Central Province) from May 2013 to April 2014. Parasites were detected by qPCR and genotyped. Malaria episodes were treated according to national guidelines and primaquine was not given to G6PD-deficient children. Comprehensive analyses of P. vivax infection prevalence, new infection and infection density as well as malaria incidences were performed. Results 860 children who attended ≥6 active surveillance were included in the analyses. Prevalence of P. vivax infections was 11.9% and most infections were sub-microscopic (71.2%) and/or asymptomatic (93.6%). 34.2% of children had ≥1 P. vivax infection, with 2/3 of them having subsequent infections, indicating that relapses from hypnozoites contributed a majority of P. vivax infections. The average incidence of new P. vivax blood-stage infection( mol FOB) was 1.1/year [0.9,1.2]. Strong spatial heterogeneity was observed within Ngella [prevalence: 1.2% to 47.4% (P < 0.01); mol FOB: 0.05/year to 4.6 infections/ year (P < 0.01)]. Age and exposure (i.e. past antimalarial treatment and mol FOB) were the key risk factors for P. vivax infections and disease, albeit in different ways. While prevalence and incidence of new infection risks ( adj OR = 1.18 and adj IRR = 1.21, both P < 0.01) both increased with age, clinical disease risk decreased ( adj HR = 0.90, P < 0.01), indicating immunity acquisition. High exposure was consistently associated with an excess risk of both infection and disease. G6PD-deficient children(10.8%) had significant higher risk of infection ( adj OR = 1.77, P < 0.01) and new infection ( adj IRR = 1.51, P = 0.03), indicating an excess risk associated with blood-stage treatment only. Conclusion P. vivax remains endemic in Ngella, with heterogeneous transmission and strong individual variation in risk. The local control program needs to develop better approaches including a more efficient targeted surveillance system as well as primaquine treatment strategy to combat the high proportion of asymptomatic and submicroscopic P. vivax infections. 1S3.2 Increase of mutations associated with SP resistance in Plasmodium falciparum isolates collected during pregnancy in Nanoro, Burkina Faso Introduction Pregnant women are a high risk group for Plasmodium falciparum infections, which may result in maternal anemia and low birth weight newborns, among other adverse birth outcomes. Intermittent preventive treatment with sulfadoxine-pyrimethamine during pregnancy (IPTp-SP) is widely implemented to prevent these negative effects of malaria. However, resistance against SP by P. falciparum may decrease efficacy of IPTp-SP. Combinations of point mutations in the dhps (codons A437, K540) and dhfr genes (codons N51, C59, S108) of P. falciparum are associated with SP resistance. Aim To study the prevalence of SP resistance mutations was determined among P. falciparum found in pregnant women and the general population (GP) from Nanoro, Burkina Faso and the association of IPTp-SP dosing and other variables with mutations. Methods Blood spots on filter papers were collected from pregnant women at their first antenatal care visit (ANC booking) and at delivery from an ongoing trial and from the GP in a cross-sectional survey. The dhps and dhfr genes were amplified by nested PCR and products were sequenced to identify mutations conferring resistance (ANC booking, n = 400; delivery, n = 223; GP, n = 400). Prevalence was estimated with generalized estimating equations and for multivariate analyses mixed effects logistic regression was used. The prevalence of the triple dhfr mutation was high, and significantly higher in the GP and at delivery than at ANC booking, but it did not affect birth weight. Furthermore, quintuple mutations (triple dhfr and double dhps mutations) were found for the first time in Burkina Faso. IPTp-SP did not significantly affect the occurrence of any of the mutations, but high transmission season was associated with increased mutation prevalence in delivery samples. It is unclear why the prevalence of mutations was higher in the GP than in pregnant women at ANC booking. Conclusion The high number of mutants and the presence of quintuple mutants in Burkina Faso confirm concerns about the efficacy of IPTp-SP in the near future. Other drug combinations to tackle malaria in pregnancy should therefore be explored. An increase in mutation prevalence due to IPTp-SP dosing could not be confirmed.  Detecting Schistosoma mansoni transmission using environmental DNA in water samples Introduction The trematode, Schistosoma mansoni, causes serious health problems and significant economic burdens in the poorest regions of the world, especially in Africa. For decades, control of schistosomiasis has focused on drug treatment in humans. However, the future WHO strategy aims for elimination of schistosomiasis, which entails complete interruption of transmission. In order to achieve this, accurate monitoring of S. mansoni transmission in the environment is crucial. Aim To develop a species-specific qPCR assay for detecting S. mansoni transmission using environmental DNA (eDNA) in water samples which is more sensitive than traditional methods (snail shedding and cercariometry). Methods The diagnostic sensitivity of the eDNA qPCR assay was confirmed firstly in a lab-based microcosm setup with aquaria containing varying densities of Biomphalaria vector snails infected with S. mansoni (0, 1, 3, 6 snails/5 L water). Secondly, the field applicability of the eDNA analysis was tested using a total of 30 environmental water samples collected from 10 sites in Kangundo and Mwea, Kenya during September 2015. between the density of infected snails in the water and S. mansoni DNA molecules in the water sample. In the field samples, S. mansoni was detected in 4 sites using eDNA qPCR assay as compared to 2 sites using traditional shedding of vector snails. This shows that the newly developed eDNA qPCR assay can detect the presence of S. mansoni in a field setting and that the assay has a higher sensitivity than the traditional methods. Introduction Buruli ulcer (BU) is a debilitating and neglected tropical skin disease caused by Mycobacterium ulcerans, mostly affecting rural regions of West and Central Africa. The clonal nature of M. ulcerans has complicated molecular epidemiology analyses, as typing methods with sufficient resolution have been lacking. Increased availability of Next Generation Sequencing techniques now allows us to address previously unanswerable questions, such as how M. ulcerans is transmitted to humans. The combination of molecular and classical epidemiology at the village level provides a novel approach to unraveling the enigmatic nature of M. ulcerans transmission. Methods In the Ou em e river valley in southern Benin, BU patients are well documented. In a retrospective spatiotemporal clustering analysis of M. ulcerans genotypes of 600 isolates collected between 1994 and 2015, we sequenced DNA of the M. ulcerans isolates using an Illumina HiSeq 2000 DNA sequencer. A multiple SNP sequence alignment was generated by concatenating all genomic variant loci. Phylogenetic analyses were done on this alignment in addition to multivariate analyses including genetic, spatial, temporal, clinical, demographic, and epidemiological data. Results Preliminary results on 498 bacterial genomes from this focused geographic region reveal 1757 SNPs distinguishing the genomes from the Oueme river basin. Within a river valley, genetic variability does not seem to correlate with geographical nor temporal variability. However, clusters of identical genomes are slightly more geographically confined, and cannot be explained by bacteria or their vectors following the current of the Ou em e river downstream. This pattern is distinct from the geographically specific genotypes seen at river-valley and continental scales. Conclusion Since the introduction of the A conjugate vaccine MenAfriVac â , meningococcal strains expressing non-A capsules, such as W, C and X are the dominating cause of meningoccal meningitis in the African meningitis belt. Our WGS data indicate that new hypervirulent lineages emerge by horizontal gene transfer events affecting primarily genes associated with the antigenic composition of the meningococcal cell surface. Introduction Until now, studies on Leishmania genome diversity were performed using DNA of cultured isolates. However, these results may not fully reflect the situation in vivo, as i) there might be selection bias introduced by isolation/ cultivation, and ii) we observed drastic changes in genome pattern of a given strain in different experimental environments (in vitro promastigotes vs in vivo amastigotes). Efficient immunization and full protection from lethal challenge by PLLAV-YF17D, a novel thermostable and readily scalable plasmid-launched life-attenuated yellow fever vaccine candidate produced in E. coli Methods A convenient plasmid-based system was engineered that allows launching of the genuine LAV directly from stably cloned YFV-17D cDNA (Plasmid-Launched LAV, PLLAV-YF17D). Replication of PLLAV-YF17D progeny was compared head-to-head with Stamaril â both in vitro and in AG129 mice. Vaccine efficacy was tested in a hamster model. Seroconversion was assessed by PRNT and cellular immune responses by flow cytometry and RT-qPCR profiling. Protection from wild-type YFV was assessed by scoring for challenge virus viremia, hepatitis, weight loss and death. Results YFV-17D launched from PLLAV-YF17D could not be distinguished from Stamaril â regarding growth kinetics, plaque phenotype, nor replication fitness in mice. In hamsters, a single dose of PLLAV-YF17D induced nAb at comparable kinetics and to similar titers as the licensed LAV. PLLAV-YF17D and Stamaril â showed equally strong and balanced activation of antigen presenting cells. Alike the commercial vaccine, PLLAV-YF17D was able to fully protect from all virological and clinical signs of lethal YFV challenge. Conclusion PLLAV-YF17D is an experimental yellow fever vaccine candidate that appears non-inferior to WHO prequalified vaccines. First immunogenicity testing has been initiated in non-human primates, using low lg amounts of pDNA and needle-free jet injection. Importantly, PLLAV-YF17D is thermostable (>14d at 50°C vs. near immediate inactivation of Stamaril â ) and is amenable to large scale high-yield plasmid production in E. coli at minimal costs of goods. We will also present how, following the same blueprint, PLLAV against other pathogens such as the Japanese encephalitis and Zika virus can be tailored. Dendritic cells, macophages, and fibroblasts are the initial targets for replication of the live-attenuated yellow fever vaccine in the dermis Introduction The live-attenuated yellow fever virus vaccine (YFV-17D) has efficiently protected people in tropical regions of Africa and the Americas from yellow fever for more than 80 years. In non-vaccinated individuals, the mosquito-borne yellow fever virus may cause high fever, hemorrhage, and devastating destruction of the liver with a case fatality rate of 34% in the recent 2015/16 outbreak in Angola. Nevertheless, many underlying mechanisms how YFV-17D induces longlasting protection remain unknown. Identifying the cellular tropism of the YFV-17D vaccine is important to understand which cells produce viral antigens and induce protective immunity. Previous studies showed that YFV-17D infects human monocyte-derived dendritic cells (DCs) in vitro as well as DCs and B cells in the peripheral blood of humanized mice following intravenous inoculation. Aim We here set out to address the long-standing question about the very first cellular targets for replication of YFV-17D in the skin following intradermal vaccination, as a relevant route. Methods We constructed novel YFV-17D reporter viruses to allow tracking of the cellular tropism and dissemination in (IFNreceptor deficient) AG129 mice that are susceptible to YFV-17D infection. Results Intradermal inoculation of AG129 mice with a mCherry-expressing YFV-17D reporter virus and analysis via flow cytometry revealed that fibroblasts and skin-resident macrophages and classical DCs (the most efficient inducers of T cell responses) are the initial targets of YFV-17D replication. Further, we constructed a nano luciferase-expressing YFV-17D reporter to determine virus replication and dissemination via in vivo luminescence imaging. Intradermal inoculation of AG129 mice led to localized replication in the inoculated ear skin and draining lymph nodes after 5-10 days. Using these new tools, we are currently dissecting the dynamics of infection, virus dissemination, and targets for replication within various tissues. Conclusion Our data provide crucial information regarding the targeting of specific cell types and tissues for optimized vaccination against various pathogens. Overall, we expect that insight into YFV-17D tropism will allow to optimize the delivery of an entirely novel and flexible YFV-17D-derived vaccine platform that we are currently developing. This novel vaccine technology allows, among others, to store and transport the vaccine independently of a cold-chain. Safety and immunogenicity of the Malaria Vaccine Candidate R21 adjuvanted with Matrix-M1 in West African adult volunteers, Burkina Faso Introduction A highly effective malaria vaccine would help reduce disease burden in malaria endemic countries. We have assessed the safety and immunogenicity of the malaria vaccine candidate R21, a virus-like particle comprising a fusion protein of part of the P. falciparum circumsporozoite protein with the hepatitis B surface antigen. Aim To assess the safety, reactogenicity and immunogenicity of three (3) doses of 10 lg of the malaria vaccine candidate R21 adjuvanted with Matrix-M1 in healthy West African adult volunteers living in a malaria-endemic area. Methods A phase Ib randomised, controlled, single-blind study was conducted. Volunteers were randomly assigned in a 2:1 ratio to receive 3 doses of the malaria vaccine or the control (normal saline) intramuscularly 1 month apart. Participants were actively followed up at home daily during the 7 days following each vaccination to collect local and systemic solicited adverse events. Serious adverse events were recorded throughout the study duration. Venous blood samples were obtained for clinical safety and immunological evaluations. The study duration was 140 days for each participant. Results A total of 8 and 5 participants have received respectively 10 lg of the malaria vaccine or a saline control immunisation. The most reported local solicited symptoms post vaccination were mild to moderate pain (25%, 2/8) and swelling (12.5%; 1/8) at injection site following each vaccination; all reported in the R21 vaccine group. Solicited systemic symptoms include moderate joint pain and headache. Neither severe adverse event nor serious adverse event was recorded. There was significant increase of anti-NANP IgG following vaccination in the R21 group compared to the controls. Conclusion This was the first administration of R21 malaria vaccine candidate in Africa. The vaccine was immunogenic in semi immune adults with a good safety profile. These data are supportive for further development of the R21 malaria vaccine candidate. Introduction Vaccine development against leishmaniases is supported by evidence of natural immunity against infection, mediated by a dominant cellular Th1 response and production of IFN-c, IL-2 and TNF-a by polyfunctional TCD4 + and TCD8 + cells, ultimately leading to macrophage activation and parasite killing. The main challenge is how to induce a strong and long lasting protection or, how to ascertain which immunodominant epitopes are responsible for natural protection. Aim To develop a 2nd generation vaccine from the Leishmania secretome, with the potential for large scale dissemination in a cost-effective, reproducible approach. Methods The secretome of six main pathogenic species was analysed by Mass-Spectrometry and conserved candidate antigens were searched in the complete dataset. In silico HLA-I and -II epitope binding prediction analysis was performed on all selected proteins, with world coverage regarding HLA restriction. To select the best epitopes, an automated R script was developed in-house, according to strict rational criteria. Selected epitopes were synthesized and tested ex vivo for cell toxicity. To attest the peptides' immunogenicity and prophylactic potential, we are testing our candidate peptides in immunoscreenings with human lymphocytes. The peptides will be further tested in PBMCs from healed individuals from endemic areas to measure their ability to recall protective responses. We selected a total of 52 protein candidates. Interestingly, we found 28 previously described vaccine candidates, and an additional 24 new candidates through a reverse vaccinology approach. From thousands of potential epitopes, the automated script in combination with optimal IC50, homology to host and solubility properties allowed us to select 50 class I and 24 class II epitopes, synthesized as individual peptides. These peptides are non-toxic to cells. Conclusion Through the combination of proteomic analysis and in silico tools we were able to swiftly identify promising antigen candidates. We further established the secretome as an optimal starting point for vaccine development and the proposed in silico pipeline provides a rapid selection of the best epitopes, with great immunogenic and antigenic potential. Together, experimental validation exclusively in human samples will provide us a very strong base for a vaccine formulation and allow to fast-track translation to the field. An ongoing field trial to evaluate the influence of canine leishmaniasis vaccination (Canileish â ) in the study of the disease seroprevalence in Spain Introduction In recent years, an increase in canine leishmaniasis (CanL) cases has been observed in the Mediterranean region. Dog immunization is advocated as a method for disease control and there are currently three licenced vaccines for CanL, one in Brazil (LeishTec â ) and two in Europe (CaniLeish â and Letifend â ). Only a few studies were performed on the impact of dog vaccination in CanL seroprevalence surveys, and these only address the Brazilian situation. Aim To assess the possible influence of a commercial vaccine against canine leishmaniasis (CaniLeish â ) in CanL seroepidemiological studies. Methods A total of 170 dogs of different breeds, sex and age have been enrolled in the study. These dogs live in 21 dog kennels in Girona province (NE Spain), an endemic area for CanL. Inclusion criteria were the ones mentioned on CaniLeish â leaflet: healthy animals, aged 6 months or more and serologically negative for Leishmania infantum. Selected dogs were randomly allocated to two groups: vaccinated (N = 85) and control (N = 85). Each animal in the vaccinated group received a three vaccine course, following manufacturer's instructions. Samples were collected at pre-determined timepoints and plasma from each animal was preserved at À40°C for subsequent processing. An "in-house" enzyme-linked immunosorbent assay (ELISA) was used as serological test, using sonicated promastigotes as antigen. The first results obtained show that vaccination with CaniLeish â induces a raise in total Leishmania-induced antibody titre, which in some cases is maintained up to 6 months after vaccination. Conclusions Preliminary results indicate that dog vaccination can impact seroepidemiological surveys of CanL, hindering the ability of these studies to correctly estimate CanL seroprevalence. This research is funded by the European Union's H2020 Programme under the MSCA GA n°642609. The Drug Discovery Unit at the University of Dundee and the GlaxoSmithKline Kinetoplastid Discovery Performance Unit, with support from the Wellcome Trust, have formed a long-term partnership to conduct drug discovery within kinetoplastid diseases. This collaboration has made significant progress, highlighted by the identification of two new oral pre-clinical candidates for visceral leishmaniasis (VL). Here we describe the initial identification of both series through transitioning active series from Trypanosoma brucei and Trypanosoma cruzi programmes into VL active series. Both series were profiled extensively in a panel of in vitro Leishmania assays including promastigote, axenic amastigote and intracellular assays as well as rate-of-kill and clinical isolate assays, an effort which helped us develop our Leishmania screening cascade. In addition we have demonstrated that both series work through different modes of action. A short overview of both lead-optimisation campaigns will demonstrate how for both series a focus on balancing potency and solubility delivered compounds with candidate-level properties. Current standard of care for VL suffers from multiple issues (lack of efficacy, safety, drug resistance, stability, cost, parenteral administration only) and community-wide there is a limited pipeline for VL. The two new chemical series presented here are a significant step forward towards the development of new oral drugs for visceral leishmaniasis and open avenues towards combination treatment. This work illustrates the substantial benefits that working in an academic-industry partnership brings for the development of new drugs for neglected diseases. Modelling the antimalarial activity of SJ733, a novel promising investivational antimalarial using early phase human pharmacokinetic and efficacy data Introduction Efficient progression of investigational antimalarials to Proof-of-Concept (PoC) studies in patients with clinical malaria should be based on understanding their potential for clinical efficacy. This is best predicted by evaluating an agent's exposure-response relationship early in clinical development. Aim We sought to use PK and PD data from an experimentally induced blood-stage P. falciparum malaria challenge model in human volunteers to determine the SJ733 PK/PD relationship to inform program progression. The dose and the dosing regimen needed to achieve cure of infection was assessed using simulations from this PK/PD model. Volunteers received a single dose of 150 mg or 600 mg in two cohorts of 7 and 8 subjects after reaching target parasitemia. Plasma SJ733 concentration and parasitemia data were modelled and simulations of different doses and dose regimens to achieve cure were evaluated. Results SJ733 showed activity against P. falciparum at both doses. However, the effect was transient at 150 mg. The observed parasite clearance half-life was 6.5 hrs (95%CI: 5.9 -7.2 hrs) for the 150 mg dose and 3.6 hrs (95%CI: 3.3 -3.9 hrs) for the 600 mg dose. A two-compartment PK model with a sigmoidal E max PD model described the data adequately. For the dose of 600 mg, the maximum kill rate was sustained for approximately 30 hours with concentration above 300 ng/mL. Modelling of the PK/PD data emphasizes SJ733's potential as an efficacious investigational antimalarial. To move it into a PoC study in clinical malaria and to investigate it as a component in combination antimalarial drug products, formulation and delivery optimization studies are needed. Possible approaches to improving its activity include improving its exposure profile by reformulation or the use of a CYP inhibitor. The effect of oral administration of antibiotics on Schistosoma mansoni egg-induced pathology in mouse models that depletion of gut microbiota by oral administration of antibiotics resulted in reduced inflammation and granuloma formation in response to S. mansoni eggs in intestinal tissue but no effects were observed in liver tissue. Both humans and mice show metabonomic changes related to gut microbiota in response to S. mansoni infection. These findings implicate a role for gut microbiota in S. mansoni pathology. It is therefore relevant to investigate whether intake of antibiotics can change pathology related to S. mansoni eggs. Aim To investigate consequences of oral antibiotics intake on S. mansoni egg-induced pathology. Methods Gut microbial composition determined by 16S rRNA gene amplicon sequencing was altered by oral administration of ampicillin/vancomycin and combined with S. mansoni infection in a C57BL/6NTAC mouse model. Egginduced granulomatous responses were quantified in liver and intestinal tissue by immunohistochemistry and stereological principles. Liver enzymes and albumin were measured in serum and intestinal permeability assayed by FITC-dextran analysis. A tissue immune response profile was obtained by a Fluigdigm based gene expression assay. Results Long term administration of ampicillin/vancomycin resulted in altered gut microbiome, intestinal permeability, immune response profile and degree of inflammation in S. mansoni infected animals. Furthermore, changes in liver parameters including the ratio of AST/ALT associated with infection and antibiotics treatment were observed. Conclusion Alteration of the commensal gut microbiota by administration of broad-spectrum antibiotics can affect eggassociated pathology in S. mansoni infection in a mouse model shown by methods which can be applied in a human context. Antiviral treatment efficiently inhibits Chikungunya virus replication in the joints of mice during the acute but not during the chronic phase of infection Introduction The last decade, the chikungunya virus (CHIKV) has become a significant global health threat because of its high disease burden, (re-)emergence, and the lack of vaccines or therapeutics. We reported earlier that favipiravir (T-705), a broad-spectrum antiviral, inhibits the replication of CHIKV in vitro and protects against disease progression in CHIKV-infected immune-deficient mice. Aim We here explored whether favipiravir is effective in a CHIKV-induced arthritis mouse model 1 during the acute and/or the chronic phase of the infection. Methods C57BL/6J mice were infected with the CHIKV 899 strain (1000 PFU) in the left footpad and were treated with favipiravir (300 mg/kg/day, orally) either during the acute phase (from day zero to day 3 post-infection (p.i.)) or during the chronic phase of infection (from day 49 to 55 p.i.). The viral load was determined in serum and organs by qRT-PCR (RNA) or by end-point titration (infectious virus). Results Favipiravir treatment during the acute phase resulted in complete inhibition of systemic viral spread. In contrast, when favipiravir treatment was initiated late, no significant differences in viral RNA levels were noted between the treated and untreated mice. Moreover, viral RNA was still present in the ankles of infected mice up to 14 weeks p.i.; however, no infectious virus could be detected. Interestingly, when attempting to amplify the viral genome from these 'late' samples by PCR, some parts of the genome, such as the viral polymerase gene, could not be amplified and the amplicons for the non-structural protein 1 (nsP1) and the envelope glycoprotein (E2) were shorter than expected. Conclusion Collectively, these results suggest that the viral RNA detected during the chronic phase is likely defective, which also explains the lack of effect of a viral replication inhibitor. It will have to be explored whether a same situation would hold for CHIKV infections in man. Introduction Mosquito-borne viruses are a major public health problem throughout the tropical and subtropical regions of the world. In Venezuela (South America), transmission of dengue virus (DENV) has become perennial with frequent epidemics since 2001. The long-term pattern of this disease has involved not only a general upward trend in cases but also a dramatic increase in the frequency and size of epidemic outbreaks. Previous studies indicate that DENV multiyear cycles are the result of both extrinsic (e.g. climate variability) and intrinsic (e.g. herd immunity and host susceptibility) factors. Aim In this study, we focused on the influence of local and regional climate on dengue occurrence. We explored the periodicity of dengue incidence and local climate variables in data time-series (16 years) from two northern regions of Venezuela, using wavelet analyses (WA), a statistical approach specifically developed for non-stationary patterns. We then determined whether dengue incidence was related to local climate variability and regional climate anomalies such as the El Niño Southern Oscillation (ENSO) using wavelet coherence analysis to identify time-and frequencyspecific associations. Results WA detected seasonal (1-year) and multiyear (2-4 years) cycles of dengue incidence in both regions and in Venezuela as a whole. Both seasonal (1-year) and multiyear (2-3-year) cycles of dengue incidence were significantly associated with ENSO and with local temperatures (maximum and minimum). This correlation suggests that ENSO and warmer temperatures have influenced the occurrence of dengue periodic outbreaks in Venezuela. viruses in Venezuela. Understanding the periodicity of dengue in Venezuela can give useful insights with regards to arboviral outbreaks. Therefore, our findings may be used to forecast dengue and other vector-borne viral epidemics and to improve disease surveillance and control strategies. West Nile surveillance and response in Italy: a one health approach Introduction West Nile virus (WNV) was first detected in Italy in horses in 1998. The virus circulates between mosquitoes (Culex pipiens) and wild birds, with humans and horses as deadend hosts. Since 2008, yearly autochthonous WN human cases were reported. Endemic areas were defined according to previous WNV circulation. Aim In 2016, we issued an integrated plan involving Public Health, Veterinary, Entomological and Environment Services, aimed to early detect virus circulation, to permit a rapid risk assessment, and to prevent the risk of human transmission. The plan defined the information flow to improve the management of epidemic emergencies. The plan included detection and notification of human cases and surveillance on wild birds, horses, and mosquitoes. A particular effort was done in Pianura Padana Regions sampling mosquitoes fortnightly from June to September in fixed sites, uniformly distributed on the territory. A common platform was shared for real time data consultation. Georeference systems were used for mapping and monitoring the competent vector and for supporting decisions. An epidemiological bulletin was published. In 2016, 71 laboratory-confirmed human cases were recorded, and positive results in 51 horses, 88 birds and 137 mosquito pools. In case of virus circulation, measures were implemented to reduce the risk of transmission to humans, such as disinfestations and precautionary measures on blood donation, and organ/tissue transplantation. Data showed that detection of the WNV in mosquitoes usually preceded human and animal cases. The integrated surveillance plan permitted to improve risk evaluation, to better define risk factors and to foster coordinated prevention and control measures. It is important to define in advance the flow of information and to make data immediately available for a timely monitor of the situation. Effects of land use on the ecology of Arbovirus-aedes mosquitoes in oil palm plantation areas in southeastern Côte d'Ivoire Introduction Arbovirus-borne viruses (arboviruses) cause many diseases in Africa, and the ecology of mosquito vectors is likely to change with human-induced land use changes, including deforestation, agriculture, and urbanisation. Aim This study explored the effects of land use changes on the ecology of Aedes mosquitoes along an anthropogenic disturbance of landscapes in oil palm plantation areas within yellow fever and dengue foci in southeastern Côte d'Ivoire. Methods Between January and October 2014, Aedes mosquitoes were sampled as eggs, larvae, pupae and adults among four macrohabitats: rainforest, polyculture, oil palm monoculture, and housing area. We used standardized sampling procedures such as bamboo-ovitraps, metallic-ovitraps, larval surveys, and human-baited double-net trap methods. No Aedes-positive microhabitat, larvae and adults were found in oil palm monoculture. However, the highest abundance of Aedes mosquitoes was found in polyculture with 7359 specimens, while the highest species richness was observed in rainforest with 9 species. Aedes aegypti was the most abundant species. Aedes aegypti, Aedes dendrophilus and Aedes africanus were commonly encountered in all macrohabitats, except oil palm farm. Aedes females' egg-laying patterns and host-seeking behaviours varied significantly among macrohabitats. Significantly higher Aedes-positive microhabitats were artificial containers in villages (n = 49.6%), followed by agriculturally-occurring containers in polyculture (n = 38.9%), and naturally-occurring containers in rainforest (n = 26.7%). Aedes species also differed in oviposition site choice between bamboo-ovitraps and metallic-ovitraps. Adult Aedes mosquito females presented higher biting rates in polyculture (41.16 specimens/human/day) and villages (7.83 specimens/human/day), and showed two peaks; the first peak at 7:00 a.m., and the second peak at 5:00 p.m. However, the nycthemeral biting cycles were interrupted from 10:00 a.m. to 2:00 p.m. in village, but exhibited continuous patterns in polyculture. In southeastern Côte d'Ivoire, the agricultural land use/land cover changes as result of expansion of oil palm plantations significantly influence the ecology (distribution and behaviour) of several anthropophagic and non-anthropophagic Aedes mosquito vectors. This suggests the possible existence of multiple, mixed and still unidentified cycles yellow fever and dengue in the region. Arbovirus-Aedes vector control strategy should encompass integrated approaches. Surveillance of mosquito-borne viruses with honey-baited FTA cards in an area of low virus prevalence Introduction The threat of arboviral infections is reemerging in continental Europe as demonstrated by several locally transmitted chikungunya and dengue fever cases associated with the spread of the invasive Asian tiger mosquito, Aedes albopictus. The Asian tiger mosquito has also established stable populations in southern Switzerland with population levels sufficiently high that would theoretically allow for autochthonous disease transmissions. As part of the current surveillance efforts trapped mosquitoes are being analysed for the presence of arboviruses using RNA extractions and PCR diagnostics. However, the approach involves laborious processing of thousands of mosquitoes and requires a constant cold-chain to preserve the viral RNA. More recently, a new method using honey soaked Flinders Technology Associates (FTA) filter papers has been proposed to collect saliva from mosquitoes that may be analysed for arboviruses. Aim To evaluate whether FTA cards could be used to collect viruses from invasive mosquitoes in an area of low virus prevalence using different type of traps. Methods Within a variety of traps, mosquitoes were allowed to feed on honey-baited, nucleic acid preserving FTA cards from which viral RNA can be directly purified and detected by RT-PCR. In preliminary laboratory experiments, viable Zika and yellow fever virus was found to be promptly inactivated and stably preserved for more than one week on the FTA cards. In a field trial, honey-baited FTA cards were incorporated into CO 2 baited passive box traps as well as oviposition traps and set up in Recife, Brazil, where arboviruses are endemic. Several cards placed during the 2015 Zika outbreak in Recife were positive for dengue, chikungunya, western equine encephalitis and Zika. Based on these promising results, the approach of combining honey-baited FTA cards with mosquito traps was then implemented in the 2016 arbovirus surveillance in Ticino, Switzerland. In our presentation we will give the latest results on the recent survey and discuss how FTA cards could replace current practice of tedious processing of mosquito pools in an area of low virus prevalence. Methods Reported cases to the surveillance system between June-December 2014 were plotted and a Knox analysis used to measure space-time interaction at individual level. Additionally, we used trend-surface analysis (TSA) at a fixed distance of 100 meters and 3-weeks of time to describe the virus spatial dispersal. Results Eight hundred and sixteen chikungunya reported cases were mapped and 40 significant space-time clusters of disease were detected using Knox analysis. The majority of clusters were located in the most populated parishes of Carabobo state. Cases were distributed along epidemiological weeks (EW) 22 until EW 49 and showed a peak at EW 34. From EW 22 onwards the number of reported cases increased in a logistic-like manner showing a maximum intrinsic rate of expansion at EW 34. The epidemic followed a trend from northern to south-western Carabobo parishes, with an estimated velocity across the state of 147.45 m/day. This corresponds to a spread speed of around 1.5 neighborhood blocks per day. Conclusions This study is the first to describe the clustering, direction, and speed of the epidemiological wave of chikungunya across urban settlements of Venezuela. Antiviral drug-resistant Chikungunya viruses can be transmitted by their mosquito vectors Introduction The chikungunya virus (CHIKV) is transmitted by female Aedes aegypti and albopictus mosquitoes, mostly present in (sub)tropical regions. No antivirals are yet available to treat CHIKV infections. Several molecules with anti-CHIKV activity were recently discovered and for some resistant CHIKV variants could be selected in cell culture. However, no information is available about the replication and transmission abilities of these antiviral-resistant viruses in mosquitoes. Aim In this study, we explored whether antiviral drug-resistant CHIKV variants can be transmitted by their mosquito vectors. Methods We orally infected Aedes aegypti Paea mosquitoes with an artificial blood meal containing either WT CHIKV or resistant CHIKV variants (i.e. MADTP res CHIKV: mutation in nsP1 gene, and favipiravir res CHIKV: mutation in RdRp gene). Viral loads were quantified in bodies (infection), heads (dissemination) and saliva (transmission) of individual mosquitoes. The infection rate of the resistant viruses was mostly similar to that of WT. In contrast, the dissemination of favipiravir res CHIKV was markedly decreased as compared to WT and MADTP res CHIKV. Furthermore, favipiravir res CHIKV was only transmitted in the saliva at day 20 pi in contrast to WT (transmission starting at d3 pi). Similar results were obtained in field-collected species (Turkey and France). In body samples of mosquitoes infected with the resistant variants, the virus was still fully resistant to the antiviral, even at day 20 pi. Intrathoracic injections with WT or favipiravir res CHIKV showed that the midgut barrier alone is not solely responsible for the abrogated dissemination of favipiravir res CHIKV. The attenuated phenotype of this virus was confirmed in vitro in the mosquito cell line C6/36, whereas the replication fitness in Vero cells was similar as for WT virus. Characterization of the resistant viruses in a CHIKV-induced arthritis mouse model is currently ongoing. Our results indicate that some antiviral-resistant arboviruses can efficiently disseminate in mosquitoes and that these viruses retain their resistant phenotype in the mosquito. In addition, our results underline that the development of antivirals with a high barrier to resistance should be a priority for antiarbovirus molecules to decrease the risk of spreading drugresistant viruses by mosquito vectors. HarmVect: A simulation based tool for pathway risk maps of invasive arthropods in Belgium -Case study: Aedes albopictus Introduction HARMVECT is a generic tool used for simulating the introduction risk of arthropods into Belgium. By simulating the arrival and entry of the arthropod into Belgium via the exploitable introduction pathways, the tool calculates pathway risk indices for arthropods threatening the Belgian food safety, animal and public health. These risk indices are used to generate pathway risk maps. The tool is written in the open source R programming language with the Rstudio package 'Shiny' to ensure a user-friendly interface. Aim The tool was utilized to analyse the situation for the tiger mosquito, Aedes albopictus. This species has been detected in Belgium in the past in one lucky bamboo and several used tyre companies. Methods The tool is able to generate 3 pathway risk maps illustrating the spatial distribution and the magnitude of the arthropod's arrival. First, the Point-Of-Entry (POE) pathway risk map is based on entry at the national borders and indicates concentrated hotspots. Second, the Point-Of-Appearance (POA) pathway risk map is successive to the POE pathway risk map and points out the locations and level at which undetected propagules are exposed to the outside Belgian environment. The tool is also able to generate a total risk map combining the POA map with a climate-suitability, host-availability and sheltered environment map in order to provide information about the establishment capacity of the arthropod for Belgium. The resulting risk maps confirmed already known hotspots for Aedes albopictus and one new important hotspot, a tyre company that has not been monitored in the past, was indicated. Urbanisation drives the ecology of immature aedes mosquitoes in arbovirus-foci in south-eastern Côte d'Ivoire Introduction Several Aedes mosquito-transmitted outbreaks of dengue and yellow fever have been reported from rural and urban part of Côte d'Ivoire. Aim This study aimed to characterise immature Aedes mosquito microhabitat, and explore species dynamics along a rural-tourban gradient in arbovirus-foci in south-eastern Côte d'Ivoire. Methods Between January 2013 and October 2014, Aedes eggs, larvae, and microhabitats were sampled in rural, suburban, and urban areas of south-eastern Côte d'Ivoire using standardised sampling procedures: ovitrap and larval survey methods. Immature mosquitoes were reared in the laboratory and adult specimens identified at species level. Results Totals of 6159, 14 347, and 22 974 Aedes mosquitoes belonging to 17, 8, and 3 different species were sampled in rural, suburban, and urban settings, respectively. The samples included the common species such Aedes aegypti and Ae. vittatus in all areas, and wild vectors such as Ae. africanus, Ae. furcifer, Ae. luteocephalus, Ae. longipalpis, and Ae. opok in rural areas. Aedes albopictus, Ae. lilii, Ae. stokesi, and Ae. unilineatus were collected for the first time in the region. We found proportionally more positive microhabitats in urban (2136/3374; 63.3%), compared to suburban (1428/3069; 46.5%) and rural areas (738/2423; 30.5%). In the urban setting, the predominant breeding sites were industrial containers such as tyres and discarded containers. In suburban areas, containers made of traditional material such as clay and wood were most frequently encountered. In rural areas, natural containers (rock holes, snail shells, tree holes, fruit husks, and leaves) were common and represented 22.1% (163/738) of all Aedes-positive microhabitats, hosting 18.7% of Aedes fauna. Microhabitat positivity rate was higher during the rainy season, and in peridomestic eco-zone. Predatory mosquitoes Culex tigripes were commonly sampled, while Toxorhynchites and Eretmapodites were mostly encountered in rural areas. Aedes microhabitat positivity was associated with study areas, container type, shade, vegetal detritus, water turbidity, geographic location, season, and predators. Conclusion In south-eastern Côte d'Ivoire, urbanisation increases the abundance of Aedes populations, and the predominance of artificial containers as breeding sites. Nevertheless, natural containers are still common in rural areas harbouring several Aedes species and, therefore, limiting the impact of systematic removal of discarded containers on the control of arbovirus diseases. Invasive mosquito species surveillance in Belgium: towards a structural plan Introduction The increase in international transport, the growing tourism and travel, and climatic and environmental changes are responsible for the emergence and spread of mosquitoes and mosquito-borne diseases in temperate regions. Strengthening surveillance of invasive mosquito species (IMS) and their pathogens in areas at risk of importation or spread and risk of pathogen transmission is therefore required. Following the implementation of invasive mosquito surveillance in Belgium in 2012 (financed by the regional and the federal governments), to evaluate the guidelines of the European Centre for Disease Prevention and Control (ECDC), the routine surveillance continued in 2013, 2014, 2015 and partly in 2016 (temporarily financed by the Federal Agency for the Safety of the food Chain (FASFC)). Aim The main aim was the early detection of introduction of IMS into Belgium. The surveillance was implemented in Belgium at 23 potential points of entry (PoE) in 2012 and at 12 PoE the following years, except in 2016 when only three high risk PoE were surveyed. At each PoE one Mosquito Magnet trap and three to ten oviposition traps were set-up and larval search was performed every one to two months. An extra BG-Sentinel trap was placed at high-risk PoE from 2015 onwards. Results Since 2013, Aedes albopictus has been detected each year. In 2013 and 2016 Ae. albopictus was found at, respectively, one and two companies importing used tyres. From 2014 onwards this species has been found yearly at a lucky bamboo company. Control measures were not always implemented, or implementation was delayed because an exemption on the biocide legislation was not obtained in time. However, control measures when implemented, were successful. Conclusion Aedes albopictus is appearing yearly in Belgium with an increase in numbers and PoE. Political awareness has grown since 2012 and the first steps have been made towards a national and structural long-term IMS surveillance programme. However, control policies still differ between the regions and should be synchronised to make them effective. Finally, there is still a need for registration of public health pesticides in Belgium, especially for larval mosquito control. Expanding IR mapper: mapping insecticide resistance in Anopheles species, Aedes aegypti and Aedes albopictus Introduction The rapid and increasing spread of resistance to major classes of public health insecticides threatens current malaria vector control efforts, namely long lasting insecticidal nets and indoor residual spraying, which have contributed substantially to the reduction of malaria since 2000. Prevention of dengue, chikungunya, yellow fever, and Zika virus also relies heavily on insecticide based control of the primary vectors, Aedes aegypti and Ae. albopictus. Launched in 2012, IR Mapper is built on a systematic review of peer-reviewed, published literature on insecticide resistance. Aim To geospatially display reports of insecticide resistance of Aedes disease vectors, the IR Mapper platform was expanded in 2016 to include Ae. aegypti and Ae. albopictus. The user interface enables filtering by year, country, vector species, WHO or CDC assay, insecticide class and type, and resistance mechanisms. Additional fields added for Aedes included vector developmental stage and resistance ratio, where reported. Results As of February 2017, IR Mapper consisted of over 16 800 unique field records from 60 countries and 64 Anopheles species or species complexes. 84% of countries have reported resistance to at least one of the four classes of insecticides used for adult mosquito control. 96% of the countries that tested for pyrethroids reported confirmed resistance. The Aedes IR Mapper platform consolidated over 3700 unique field records of insecticide resistance in Ae. aegypti and Ae. albopictus, 71% of the countries and territories testing for resistance reported confirmed resistance to at least one of the four main insecticide classes approved for public health use. The highest proportion of confirmed resistance reports was to organochlorines (90% of tests) followed by pyrethroids (68% of tests). The majority of data were available from Asia followed by the Americas; very few data points were available from Africa. Conclusion IR Mapper is a useful tool for visualizing insecticide resistance trends in both Anopheles and Aedes and can be used to assist rational decision making for deployment of the most appropriate tools. Increasing reports of insecticide resistance in Anopheles and Aedes mosquitoes present a worrying trend, particularly in countries that continue to face a high burden of vector borne diseases. Opisthorchis viverrini and a novel sister species in ducks share the same intermediate snail and fish hosts in Central Vietnam  Human and animal trematode infections in a mobile pastoralist setting at Lake Chad: added value of a one health approach beyond zoonotic diseases research Introduction At Lake Chad in Central Africa mobile pastoralists face economic losses due to livestock trematodiases. Fasciola gigantica and Schistosoma bovistrematodes that affect livestockshare transmission ecology traits with Schistosoma haematobium and S. mansoni that cause human schistosomiasis. Aim This research aimed at assessing treatment strategies, access and availability, and at elucidating the predictive potential of human and animal trematode infections. If a predictive potential from livestock fascioliasis to human schistosomiasis can be identified, this would present scientific evidence for the use of animal health data (e.g. fascioliasis in cattle) as sentinel for human schistosomiasis in a setting where no schistosomiasis control programme is in place, as is the current situation at Lake Chad. Methods Schistosomiasis and fascioliasis were investigated concurrently in humans and cattle by repeated cross-sectional surveys in pastoralist groups. Urine and stool samples from humans and faecal samples from cattle were examined for trematode eggs. Treatment strategies were assessed in focus group discussions and in-depth interviews. Results Mobile pastoralists of four ethnic groups participated. Prevalence of human schistosomiasis and livestock trematodiases showed variation between ethnic groups, but correlated within ethnic groups. Among the schistosomiasis cases, more than 60% sought treatment in health centres and from the informal market. Fascioliasis awareness among pastoralists was high and self-mediated therapy using veterinary drugs is the common practice. Mebendazole and albendazole are the drugs locally available, which are used against human parasitic worm infections and for livestock fascioliasis treatment. Effective trematocidal drugs, praziquantel and triclabendazole, were however not available in the study area. Conclusions Mutual predictive potential of human schistosomiasis and livestock fascioliasis relates to distinct animal husbandry practices. Introducing efficacious strategic treatment against human schistosomiasis and livestock fascioliasis might impact on human and animal health, resulting in economic benefits by improved livestock productivity and reduced treatment costs. Our research provides evidence for the benefits of a One Health approach beyond zoonotic disease research by targeting diseases that share specific ecological traits. Dynamics of S. haematobium and s. mansoni infection and morbidity: an eight-year follow-up study in a rural community in the north of Senegal Introduction Schistosoma mansoni was introduced in the north of Senegal around 1990 upon dam construction, and rapidly spread throughout the Guiers Lake region. A decade later, this severe S. mansoni epidemic was followed up by an S. haematobium epidemic. Today, both Schistosoma species are wide-spread in the communities around the lake. Aim To study the dynamics of infection and morbidity due to S. mansoni and S. haematobium in one of the Guiers lake communities upon the S. haematobium outbreak. The entire community was surveyed in 2006, 2008, and 2014. Schistosoma infection was determined by standard microscopy on urine and stool samples. Ectopic egg elimination refers to elimination of Schistosoma eggs via the unusual routei.e. S. mansoni eggs in urine or S. haematobium eggs in stool. Single infection was defined as passing eggs of only one species, and mixed infection as passing eggs of both species, regardless of the route of egg elimination. Schistosoma-specific host morbidity was determined by ultrasound according to WHO guidelines. Results While S. haematobium remained stable at 53-57% S. mansoni infection prevalences gradually decreased from 52% (2006) to 4% (2014). Prevalences of mixed infections decreased from 34 to 3%. In accordance with previous studies, S. haematobium infection intensity was positively associated with mixed (versus single) infection, and ectopic (versus regular) egg elimination. In contrast, S. mansoni infection intensity was negatively associated with ectopic egg elimination. These associations were consistent over time and probably reflect biological interspecies interactions in the human host. Trends in morbidity in relation to different types of Schistosoma infection will also be discussed. Conclusion At population level, a shift from S. mansoni towards S. haematobium was observed. Trends observed at the individual level support the idea that biological interactions between the two Schistosoma species in the human host mightat least partly -underlie this shift. Further research is needed to confirm the hypotheses generated here, and to better understand how these and other factors shape disease dynamics in S. mansoni and S. haematobium co-endemic areas. This will be crucial for the development of better schistosomiasis control strategies, especially for co-endemic areas. Aim We aim at incorporating the climate and hydrology-driven snail ecology into spatially-explicit models of disease transmission to investigate the importance of seasonal snail abundance fluctuations in disease persistence and the efficacy of mass drug administration (MDA). Methods We study various natural and man-made habitats across Burkina Faso's highly seasonal climatic zones. We single out hydrologic drivers and density-dependence (or lack if it thereof) of ecological growth rates of local snail populations by contrasting novel ecological and environmental data with various models of host demography. We then use the ensemble model average to predict snail abundance fluctuations for the whole of Burkina Faso using remotely sensed environmental covariates and the previously identified ad hoc models of snail demography depending on habitat type (natural vs man-made) and hydrologic characteristics (ephemeral vs permanent). Finally, snail abundance spatio-temporal predictions are used as inputs into a spatially explicit model of schistosomiasis transmission calibrated against historical parasitological data and studied through stability analysis, including the effect of MDA. Our results link quantitatively hydrologic drivers to distinct population dynamics through specific density feedbacks, and show that statistical methods based on model averaging provide reliable snail abundance projections. Simulations of the calibrated spatially-explicit transmission model show that the climate and habitat-dependent seasonality of snail abundance fluctuations is an important factor in understanding spatial prevalence and intensity patterns in Burkina Faso. Moreover, we show that conditioning the timing of MDA campaigns with the spatio-temporal patterns of snail abundance could increase the efficacy of current available yearly stocks of praziquantel. Conclusion Seasonal snail abundance fluctuations should be taken into account when modelling disease transmission, and could provide an opportunity for tailoring spatial surveillanceresponse strategies at the national scale for schistosomiasis elimination. Transmission and hybridisation dynamics of Schistosoma haematobium in the Senegal River Basin: No barrier breakdown between human and cattle schistosomiasis? Introduction Hybridisation and introgression between schistosome species may strongly impact on the epidemiology and the evolution of a disease. In the Senegal River Basin (Northern Senegal) introgressive hybridisation between the human Schistosoma haematobium and the animal S. bovis has been detected. Aim Here we want to study the transmission and hybridisation dynamics of these two species in order to understand the impact on the epidemiology of human schistosomiasis. Methods We collected S. haematobium parasite genetic data in ten villages in the Senegal River Basin. We also included parasite samples from Southern Senegal, Mali and Corsica as outgroup. In Northern Senegal, adult S. bovis worms were collected from cattle. Schistosoma parasites (>800) were genotyped with 17 highly polymorphic microsatellite markers, a subset was also genotyped with a mitochondrial marker (partial cyctochrome oxidase 1 (cox1) fragment) and the nuclear ITS rDNA marker to define their species status (S. bovis, S. haematobium or hybrids). Results As expected, pure S. bovis parasites clustered strongly apart from the 'pure' S. haematobium parasites. Hybrid parasites, i.e. with a S. haematobium nuclear ITS rDNA profile and a S. bovis cox1 mtDNA profile) did however not cluster intermediate between the 'pure' S. haematobium and the pure S. bovis parasites. Within S. haematobium the clustering of parasite genetic variation was related to their geographical location but not to their hybrid status. These results clearly show that no first generation (F1, F2) hybrids are present. Hybridization is therefore either rare or 'old', unidirectional and followed by repeated backcrossing with S. haematobium ('mitochondrial capture'). Methods Rivers and streams were surveyed for blackfly breeding in January 2015 and June 2016 prior to adult blackfly surveys commencing. Sibling species were identified based on inversion polymorphisms in giant polytene chromosomes of lateinstar larvae. Identifications of larval and adult blackflies were verified by rDNA ITS1 amplicon size polymorphisms. Human landing collections of adult blackflies took place at seven rural villages across the transmission zone in June and July 2016. Blackflies were dissected and pools of heads and bodies were screened for O. volvulus transmission using species-specific realtime PCRs. The combined cytotaxonomic and molecular approach to identification revealed the presence of Simulium kilibanum, 'Nkusi', and 'Turiani' cytoforms. S. kilibanum was collected occasionally on human bait, whereas 'Nkusi' was biting abundantly at all seven collection sites. 'Turiani' was found breeding in rivers to the north and south of Mahenge, but appears to be non-anthropophilic. Simulium nyasalandicum was also collected, but in low numbers and is unlikely to contribute to transmission. In total, 17 120 adult female blackflies were collected on human bait, of which 12 452 were dissected and pool screened. Onchocerca volvulus infection was detected in 97/104 pools of bodies and 51/104 pools of heads. An estimated 0.57% (95% CI 0.41-0.77%) of blackflies were carrying infective stage larvae. Conclusion 'Nkusi' cytoform is the most likely vector of O. volvulus in Mahenge and blackfly infection rates appear similar to pre-control levels despite 19 years of annual ivermectin treatment. Onchocerciasis associated epilepsy in the Ituri and Tshopo province in the Democratic Republic of the Congo: a casecontrol study Introduction A recent study reported that the prevalence of epilepsy in villages in onchocerciasis endemic areas in the Democratic Republic of the Congo (DRC) was 2-10 times higher than in non-onchocerciasis endemic regions in Africa. The WHO recommended strategy for the control of onchocerciasis is mass drug administration through community-directed treatment with ivermectin (CDTi). Aim This study investigated the relationship between onchocerciasis and epilepsy in endemic regions for onchocerciasis in DRC. Methods In October-December 2015, a case-control study was performed in 3 rural health zones (RHZ) in DRC: RHZ Rethy (3 CDTi campaigns before study) and RHZ Logo (no CDTi), Ituri Province; RHZ Wanierukula (13 CDTi campaigns), Tshopo Province. Individuals who developed unprovoked convulsive epilepsy of unknown aetiology 12 months before the study were enrolled as cases (n = 172). Controls (n = 168) were randomly selected healthy members from the same village and age-groups as the cases. A validated questionnaire was used to collect sociodemographic, clinical, and neurological data. Physical and neurological examinations were performed by a physician and neurologist, respectively. Current infection with Onchocerca volvulus was assessed through detection of microfilariae in skin snip biopsies. Exposure to onchocerciasis was assessed by serology-based rapid tests (SD BIOLINE) detecting human OV IgG4 antibodies. In the RHZ Logo, onchocerciasis associated symptoms (e.g., itching and abnormal skin) as well as epilepsy indirectly related morbidity (e.g., burn scars) were more often present in cases compared to controls (respectively, OR=2.93, 95%CI (1.34, 6.40), P < 0.01 and OR=23.53, 95%CI(5.25, 105.38), P = 0.000). Furthermore, skin snip positivity (55.9% vs 25.8%, OR=3.66, 95% CI (1.72, 7.78), P < 0.0006), median number of microfilariae (56 vs 2, P < 0.007), and presence of OV IgG4 antibodies (OR=3.35, 95% CI (1.54, 7.32), P < 0.002) were significantly higher in cases compared to controls. The same trend was observed in RHZ of Rethy and Wanierukula. In general, persons with epilepsy were 2.71 times more likely to be onchocerciasis positive compared to controls 95% CI (1.73, 4.25), P < 0.0001). Conclusion The outcome of this study corroborates with the growing body of literature reporting a strong association between epilepsy and onchocerciasis in poorly controlled onchocerciasis endemic regions in Africa. Methods We developed and analysed three population-based models of the transmission dynamics of O. viverrini that include the worm burden in reservoir hosts and age-dependent worm burden in human hosts. We used prevalence data of the hosts and data on infection intensity in humans from two islands in Southern Laos to estimate the likely distributions of parameter values for these models; We defined threshold conditions such as the basic reproduction number to identify transmission potential of the different host types, and simulated the models to determine the impact of interventions strategies. Our analysis indicates that in Laos humans maintain the transmission cycle through snails and fish, and that interventions which increase the mortality rate of worms in humans, and of snails and of fish lead to the largest reductions in the intensity of infection in humans. Aim Given the potential impact of heterogeneity on the estimation of FOI, we estimate this quantity accounting for both observed and unobserved heterogeneity. Methods We used cohort data of children aged 0.5-10 years evaluated for the presence of malaria parasites at three sites in Uganda. Assuming a Susceptible-Infected-Susceptible model, we show how the FOI relates to the point prevalence, enabling the estimation of FOI by modeling the prevalence using a generalized linear mixed model. We derive bounds for varying parasite clearance distributions. The resulting FOI varies significantly with age and is estimated to be highest among children aged 5-10 years in areas of high and medium malaria transmission and highest in children aged below 1 year in a low transmission setting. Heterogeneity is greater between than within households and it increases with decreasing risk of malaria infection. Our study suggests that next to the individual's age, heterogeneity in malaria FOI may be attributed to household conditions. When estimating the FOI, accounting for both observed and unobserved heterogeneity in malaria acquisition is important for refining malaria spread models. Introduction Rabies is a viral disease that affects the central nervous system of humans and other mammals. The disease is transmitted by bite and is fatal after the onset of symptoms. Rabies is endemic in many countries and causes approximately 59 000 human deaths annually worldwide. The domestic dog is the primary vector for human rabies. In 2012 and 2013, two dog vaccination campaigns were conducted in N'Djamena, Chad, reaching a vaccination coverage of more than 70% in both years. The campaigns interrupted transmission for several months but there has been a resurgence in cases, earlier than suggested by previous homogeneous models of rabies transmission. Aim We use mathematical models to explore possible causes for this resurgence and to simulate the effect of different interventions on dog rabies transmission. Methods We develop population based and individual based models. The model parameters are calibrated to four years of geolocated weekly incidence data of dog rabies and subsequent human exposure. For the individual based models we use data on movement and contacts of dogs. We analyse the models to derive threshold conditions of vaccination coverage and importation of latent dogs. We conduct simulations to asses the long term effect of different vaccination scenarios. Results Sensitivity analysis suggests that underreporting of rabies cases is unlikely to lead to the early resurgence seen in N'Djamena. Incorporating heterogeneity shows that the reproductive ratio was underestimated in the previous homogeneous model. However our simulation results suggest that while spatial heterogeneity and the decrease of the vaccination coverage due to population turnover seem to facilitate the fast re-establishment of rabies in N'Djamena, the main cause for the recent cases is the importation of latent dogs. Conclusion In order to sustain the interruption of transmission after the vaccination campaigns reintroduction of rabid dogs from the surroundings of the city has to be prevented. Entomological indices of plasmodium falciparum transmission in Sahelian area before Panafrican Great Green Wall initiative implementation, Burkina Faso, West Africa Introduction The Panafrican Great Green Wall Initiative (PGGWI) 1 , whose purpose is to improve socio-economic conditions of the vulnerable populations, will pass through sahelian area of Burkina Faso (BF). This Initiative can cause ecological and environmental changes in Sahel including artificial water reservoirs and overpopulation, which could have an important impact on malaria transmission. Available entomological data on malaria transmission in the Burkina Faso sahelian area are more than 30 years old 2 . Aim We have therefore carried out an entomological survey in order to update the malaria entomological indices before the PGGWI implementation. Methods We conducted two cross-sectional entomological studies in the Gorom-Gorom health district, located at extreme north of BF, making border with Mali in August and November 2014. The mosquitoes were sampled with CDC trap and indoor residual spraying. After the morphological identification of Anopheles genus, An. gambiae complex composition, Plasmodium infection rate and insecticide resistance genes were determined using PCR. The blood meal source index was estimated by ELISA test on engorged females. Results A total of 3122 Anopheles specimens was collected, 78.9% represented by An. gambiae s.l. (An. coluzzii (99.01%), 0.8% of An. gambiae and 0.2% of An. arabiensis). The majority of vectors was zoophilic (62.8%) but anthropophilic tendency (21.9%) was not negligible, with 15.3% of mixed blood meal. The overall sporozoite infection rate was 3.6%. Only An. coluzzii was infected. The L1014F kdr mutation prevalence was 93.4%. No Ace-1 G116S mutation has been detected. Conclusion Anopheles coluzzii was found to be the major P. falciparum malaria vector in sahelian area of BF with a relatively high infection rate compared to previous studies 2 . The kdr mutation prevalence was excessively high in the Sahel, which could compromise long lasting insecticide net bed efficacy. In PGGWI implementation, it is therefore essential to integrate malaria prevention program. Introduction It was recently shown that the mosquitocidal effect on Anopheles gambiae s.s. populations feeding on malaria patients treated with high-dose ivermectin lasts for at least 28 days after the start of ivermectin administration when coadministered with 3 days of dihydroartemisinin-piperaquine (DP). Aim The current pharmacokinetic and pharmacodynamic analysis aimed to determine whether a drug interaction or an unidentified ivermectin metabolite could be contributing to the prolonged mosquitocidal effect of ivermectin. Methods In the main trial, 141 adults with uncomplicated malaria were randomly assigned to receive ivermectin 0, 300, or 600 mcg/kg/day for 3 days. During 28 days of follow-up, 1393 venous plasma samples were collected. Paired mosquito incidence rates for death (IDR) during 14-days post-feeding were available for 850 time points. Following liquid-liquid extraction, ivermectin concentrations were measured using liquid chromatography-mass spectrometry (LC-MS). Pmetrics â 1.5.0 was used for the population modelling of both PK and PD data. Results Ivermectin concentrations were above the lower limit of quantification for 534 time points, of which 246 had paired IDR's. The population pharmacokinetics of ivermectin were best described by a two-compartment oral absorption model. Based on the PK/PD model there was a consistent association between (1) predicted and observed ivermectin concentrations and (2) predicted ivermectin concentrations and observed mosquitocidal effect throughout the entire duration of the study (28 days). The half maximal effective concentration (EC 50 ) for incidence rate of death by day 14 was 17.1 ng/mL (IQR 15.1, 19.1). Predicted median concentrations remained mosquitocidal for at least 28 days. The PK/PD model accurately predicted mosquitocidal activity for the entire duration of the study (28 days) without the need to invoke unidentified variables such as an active metabolite. The effectiveness of a topical repellents and long-lasting insecticidal nets on mosquito populations in a malaria preelimination setting of Cambodia Insecticidal Nets (LLINs) malaria transmission can still persist due to malaria vectors biting outdoors or/and early in the evening. Mass use of mosquito repellents in addition to LLINs was suggested to tackle this residual transmission. However, as shown during a cluster randomised trial [1] , the mass use of an effective and safe mosquito repellant (picaridin) in addition to LLINs did not contribute to further decrease malaria in the province of Rattanakiri province, a pre-elimination setting of Cambodia. In parallel entomological surveys were done in some villages of the trial. Aim To assess the impact of the mass use of repellents on the malaria vector populations but also on other mosquito species. Methods Eight surveys were done over a period of 2 years in two control (LLINs only) and two intervention (repellents and LLINs) villages. Each survey was done at 7 houses per village during 10 consecutive nights. The Human Landing Collection outside those houses was done (5-10 p.m. and 5-8 a.m.). Mosquito density and parity rate, a proxy of survival rate, were the principal outcomes. Results Over a period of 2 years, 4801 Anopheles mosquitoes were collected belonging to 24 different species. A significant decline in densities was observed for Anopheles, Aedes, Mansonia but not Culex during the second year in the intervention villages compared to the control villages. However no significant interaction was observed for primary malaria vectors, i.e. An. dirus and An. minimus. For parity rates no interaction between treatment and year was found for An. dirus and An. minimus. Decrease in parity from year 1 to year 2 was higher in the repellent villages for Aedes albopictus, An. maculatus and An. barbirostris. Conclusion Although the mass use of repellents impacted some vector species, it did not change the density and the survival rate of the main malaria vectors. This can be explained by the lack of daily compliance and appropriate use of the repellents at community level. Present study confirms also the importance of early and outdoor biting malaria vectors in challenging the elimination of malaria in the Mekong region. Results MRS strain, without kdr mutation, is resistant to several pyrethroids and pseudo pyrethroids with resistance ratio greater than two. MRS strain is susceptible to carbamates and organophosphates. Transcriptomic analysis revealed that detoxification genes mainly from p450 oxidases family, cuticular genes from three different families are strongly expressed in MRS strain. Transmission electron microscopic analysis showed that MRS cuticle is significantly thicker than the susceptible one. Deltamethrin level recorded inside the body after topical application is also significantly limited in the resistant strain. Conclusion These results highlight the implication of cuticle in resistant mosquito phenotype. Determination of the components involved in cuticular resistance and how the different mechanisms of resistance interplay, will greatly contribute to our understanding of these mechanisms. This also could bring some new candidates to monitor resistance among natural populations.  Of 265 mosquitoes sampled and tested for resistance, 251 (167 exposed to DDT; 84 to bendiocarb) were successfully identified to species (Anopheles gambiae s.s. À69.3%; An. coluzzii-7.6%; An. arabiensis-23.1%). In contrast to earlier lab studies, there was not a significant increase in DDT susceptibility between nulliparous and parous mosquitoes v 2 df=1 = 0, P = 1. The proportion of mosquitoes carrying the Vgsc-1014F allele was higher in parous An. gambiaes.s. than in nulliparous (v 2 df=1 = 4.1, P = 0.04). Irrespective of parity status, target site mutations conferred a strong survival advantage to DDT, from Vgsc-1014F (OR 18, 95% CI 2-557, P < 0.01), and to bendiocarb, from Ace-1-119S (OR 41, 95% CI 4-1394, P < 0.01). The kdr Vgsc-1014F mutation was associated with DDT resistance in mixed age populations of An. gambiae s.s. The significantly higher frequency of Vgsc-1014F in parous mosquitoes explains the lack of association between insecticide susceptibility and physiological age. This observation suggests that resistance mechanisms may partially counteract the senescence phenomenon commonly observed in laboratory reared mosquitoes which normally become more susceptible to insecticides with age. Bringing quality assurance for indoor residual spraying (IRS) into the 21 st century: Improving IRS policy implementation Introduction Indoor residual spraying (IRS) is widely implemented in many vector control programmes, but is often poorly quality controlled. The Insecticide quantification kit (IQK) is a low cost method for measuring insecticide residues on walls. We developed field-tested, operational protocols for control programme use of the IQK. Aim Develop field-tested operational protocols for IQK use in vector control programmes. Methods DDT IQK tests were demonstrated to the Mpumalanga province malaria elimination programme, South Africa during October 2015. Feedback regarding potential utility was used to develop standard operating procedures (SOPs) for IQK use in the field. Programme staff in the malaria elimination programme tested the SOPs by using them to design and implement a one week pilot study during the 2016 IRS round. Results 10% of newly-employed IRS operators in Nkomazi district, Mpumalanga province were randomly selected for quality assurance evaluation. Three IQK samples were taken in each of four houses sprayed by each operator, for a total of 64 houses and 192 IQK samples. IQK tests were performed by the Nkomazi district entomology team in the local malaria field station. Data analysis was performed by the malaria elimination programme information officer. Average DDT insecticide residues found in houses sprayed by newly recruited IRS operators were 0.70 g/m 2 , below the target DDT concentration of 1.8 -2.2 g/m 2 . Focus group discussions conducted with elimination programme staff following the pilot study indicated: 1) the IQK was easy to incorporate into routine programme activities; 2) the SOPs were a useful guide for programmes unused to performing IRS quality assurance activities. Conclusion The IQK test can be easily incorporated into the routine activities of a vector control programme using the freelyavailable field-tested protocols. Viral pathogens at the human-wildlife interface in DRC: wild mammals as natural hosts of zoonotic viruses Introduction Many human infectious diseases are caused by pathogens in wild or domestic animals via cross-species transmission. The factors affecting zoonosis' persistence and emergence are not well known and thus studying them is important to understand their influence on zoonosis' spread. The significant epidemiologic, ecologic, demographic and anthropogenic changes have made DRC eligible for implementation of the PREDICT project starting in April 2010 to begin with active surveillance of wildlife pathogens. Aims To evaluate the diversity of wildlife viruses with potential for human infection in three taxa of wild mammals -bats, Nonhuman primates (NHP) and rodents and to characterize human and wildlife interactions on disease transmission and emergence. Methods The active surveillance of viral wildlife pathogens in bats, NHPs and rodents was conducted in 7 provinces -Bandundu, Bas Congo, Equateur, Kasai Orientale, Katanga, Kinshasa and Province Orientale. Samples (tissues and swabs) were collected in RNA-Later and whole blood on filter paper (DBS). All samples were tested by PCR for 21 viral families. The epidemiologic, ecologic, demographic and anthropogenic data were collected and uploaded to PREDICT GAINS database to better characterize the sites and different mammal species known to harbor zoonotic pathogens. In this study, new and previously reported viruses from 8 virus families were detected in bats, rodents and NHPs in several pre-defined targeted transmission interfaces; 41 Coronaviruses in bats; 5 Bocaviruses, 169 Herpesviruses, 2 Poxviruses, 6 SFV, and 18 Enteroviruses in NHPs; as well as 19 Herpesviruses, 12 Polyomaviruses and 4 Adenoviruses in rodents. The results of the current study reveals the presence of novel and diverse human viruses in wildlife and suggest the potential sharing of viruses between wildlife and humans at specific interfaces. Transmission of ESBL-producing Escherichia coli between humans and poultry -A one-health study from Ghana Introduction The increasing incidence of infections caused by extended spectrum beta lactamase (ESBL) producing Escherichia coli in sub-Saharan Africa is of serious concern. Studies from countries with a highly industrialized poultry industry suggested the poultry production-food-consumer chain as a potential transmission route. In Africa integrated studies at this human-animal interface are still missing. Aim To compare genomes of ESBL-producing E.coli, colonizing the intestinal tract of humans and poultry in rural Ghana in order to assess potential transmission routes. Methods During a six-months period, faecal samples from all children admitted to the Agogo hospital (Agogo, Ghana) and broilers at all eight poultry farms within the same community were collected. After screening on chromogenic ESBL agar, Whole Genome Sequencing (WGS) was performed on all ESBL isolates. All genomes were analysed using WGS-based Multilocus Sequence Typing (MLST), WGS-based ESBL genotyping and genome-wide SNP analysis. Results Faecal swabs from 140 broilers and 82 children revealed 45 (32%) and 38 (46%) ESBL E.coli isolates, respectively, with prevalences on farms ranging between 0% and 88%. While human isolates were equally distributed among 22 different sequence types (ST), ST10 was most prevalent among broilers (n = 30, 67%). CTX-M-15 was the predominant ESBL genotype among broilers (n = 43, 96%) and humans (n = 37, 97%). SNP analysis revealed three very closely related broiler/ human isolate pairs (7% of ESBL isolates) with chromosomal and plasmid mediated resistance. The findings demonstrate high colonization rates with ESBL-producing E.coli in rural Ghana. Considering that animal and human samples are independent specimens from the same geographic location, the number of closely related ESBL strains circulating across these two reservoirs is substantial. Hence, poultry farms or meat products might be an important source for ESBL-producing bacteria in rural Ghana leading to difficult-to-treat infections in humans. Vector-borne zoonoses surveillance in Piedmont region, northwestern Italy (2011-2016) Introduction Vector-Borne Diseases (VBDs) represent a threat for humans and animals, that is emerging worldwide due to climate and environmental changes and international trade/ travel. Given the complex epidemiology, a multidisciplinary approach is required for their surveillance. Aim This work reports the integrated surveillance system enforced in Piedmont region (northwestern Italy), on mosquito and tick borne diseases. Methods An information network was activated between local veterinary and human health authorities, to connect the surveillance of VBDs human clinical cases with entomological surveillance and veterinary monitoring in order to implement control measures in case of outbreak. Since 2011 a systematic entomological surveillance was carried out during the vector season: mosquitoes were collected by georeferenced traps, then identified and pooled by species, data and collection site and analyzed by PCR to detect viruses belonging to the Flavivirus genus. Ticks removed from bitten humans of different regional areas were identified and tested by biomolecular essays for the detection of Borrelia burgdorferi sl, Rickettsia spp., Anaplasma spp and Tick Borne Encephalitis Virus (TBEV). Results Through entomological surveillance, Usutu virus was detected in mosquitoes since 2011. West Nile virus was firstly detected in 2014 in mosquitoes of a regional southeastern area, then in following years an expansion of its activity was observed. Control and preventive measures were immediately applied, according to the national legislation and in collaboration with regional veterinary and human health services. Since 2011, 1070 ticks were collected from humans, mainly identified as Ixodes ricinus. Preliminary biomolecular tests performed on 504 ticks showed their infection with Borrelia burgdorferi s.l. (6.5% prevalence), Rickettsia spp. (16.6%) and Anaplasma spp. (2.4%). No TBEV was detected. Conclusion According to the One Health concept, interactions between different disciplines are needed for an effective early warning and management of VBDs. The integrated surveillance on arthropods of medical importance provides useful information to public health authorities, in order to apply control measures in collaboration with local veterinary and human health services and valuable data to medical centers, to address patients' diagnosis and therapy. Spatial patterns and abundance of rodents in Lassa fever endemic rural villages in Guinea Introduction Lassa fever is a severe hemorrhagic disease in West Africa, where up to 300,000 clinical cases are estimated to occur annually with a fatality rate of 1-2%. The etiological agent of the disease is Lassa arenavirus (LASV), of which the Natal multimammate mouse (Mastomys natalensis) is the reservoir host. Humans can become infected with Lassa virus by contact with this rodent or its excretions. Because there exists no vaccine for human use and therapeutic options are limited to the antiviral ribavirin, rodent control and behavioral changes are currently considered the only options for Lassa fever control. But in order to develop efficient rodent control programs, more information about the host's ecology is needed. Methods In this study, we investigated movement patterns and abundance of M. natalensis by performing two capture-markrecapture (CMR) and four dyed (rhodamine B) bait experiments in four rural villages in Upper Guinea. The experiments were performed during the transition from rainy to dry season (October-November 2015 and 2016), when we expected that rodents migrate to the houses to search for food and shelter. Results During the CMR studies, 210 individual M. natalensis were captured of which 51 were recaptured at least once. Movements between houses and proximate fields were observed for 23% (12/51) of the recaptured rodents. M. natalensis was present over the entire study grid (2ha), but most animals were found in the village center our near the proximate cultivations. The population density was estimated to be 95 AE S.E. 20 / ha. The average home range size was 390 AE S.E. 100 m 2 . During the dyed bait experiments, movements from the fields to the houses were observed for 11% (18/156) of the captured M. natalensis. Conclusion This study shows that commensal M. natalensis moves easily between the houses and the proximate fields in Guinea. We suggest that rodent elimination in houses alone is an unsustainable method to reduce the transmission risk of LASV to humans, as M. natalensis can reinvade controlled houses easily. A combination with other control strategies (e.g. make houses rodent proof, store food into rodent proof containers) could be more effective. Introduction Lassa fever is a viral haemorrhagic fever, affecting 200-300,000 persons with 5,000-10,000 fatalities per year in West Africa. Lassa virus (LASV) has a rodent reservoir Mastomys natalensis, and is transmitted to humans through direct contact, their body fluids or droppings. According to a mathematical model, the correlation between the reservoir abundance and viral prevalence in the reservoir can show 4 scenarios: (1) positive linear, (2) positive logarithmic with a threshold, (3) negative or (4) null. Consequently, the correlation between reservoir abundance and force of infection to humans can be: (1) positive exponential, (2) positive linear with a threshold, (3) null or (4) positive linear. Aim We therefore intended to investigate 3 outcome variables: rodent abundance, LASV prevalence in the rodent population and recent Lassa cases in humans, by conducting an experimental study in a high endemic zone in Upper Guinea, Guinea. Methods In 2013, 2014, 2015 and 2016 the rodent populations were sampled in 4-10 villages, all located in remote dry forest savannah. In 3 villages, the rodent populations were reduced by using anticoagulant once a year; and the level of abundance was checked before and after control. Necropsies were done each day in situ following the BSL3 procedure, and the blood was collected on filter papers. LASV testing was done with a double PCR targeted on S and L segments. In 2014, the human population was randomly sampled in 6 villages. Serology on human sera was performed by using ELISA and IFA tests. In total, 1030 rodents were collected of which 954 were M. natalensis. Their abundance, measured by the mean trapping success varied from 1.1% to 16.7%. LASV prevalence varied from 0.0% to 33.3%. First analysis showed no relationship between rodent abundance and Lassa prevalence (scenario 4). Nevertheless, the relationship between rodent abundance and force of infection was positively correlated (r = 0.56, n= 31, P=0.001) according to the mathematical model. Of 1306 human sera, 993 were IgG positive and 23 IgM positive. The Lassa incidence in humans could be amplified when rodent populations remain abundant. Evaluation of post-mortem detection techniques for bovine cysticercosis in Belgium Introduction A 3-year study on post-mortem detection techniques for bovine cysticercosis (cc) was conducted in Belgium. Cc is responsible for important economic losses in the meat sector. Diagnosis of cc is solely based on routine meat inspection (MI) at the slaughter line. The yearly taeniosis incidence (human tapeworm infections) is estimated at 11000 cases. Methods Three post-mortem detection techniques (MI, MI with additional incisions in the heart and monoclonal antibodybased antigen-detection (Ag-ELISA)) were compared. Serum samples and predilection sites (PS) (heart, tongue, masseter muscles, diaphragm and oesophagus) of 101 carcasses found positive for cc at MI and 614 carcasses negative for MI were collected in three slaughterhouses. Complete dissection of PS in 0.5 cm thick slices was considered a reference test. Using the obtained results, a model was developed to estimate the current situation in Belgium and the effect of using an improved diagnostic technique on the meat sector and public health. Results According to official MI results, the observed prevalence of cc is 0.28%. Our results show that out of 614 MInegative animals, 4 new cases (0.6%) of cc were found by making additional incisions in the heart, rendering this detection technique unprofitable. However, by completely dissecting PS of the same 614 animals, 144 (23.5%) carcasses were found to contain cysticerci. Ag-ELISA identified another 40 positive carcasses out of the remaining 470 (8.5%) carcasses (negative on MI and PS). Extrapolation of these results shows that out of 500,000 cattle slaughtered yearly, on average 200,684 (40.1%) contain cysticerci, while only 1429 infected carcasses are detected at MI. Implementation of the Ag-ELISA is likely to lead to a 40% reduction in the number of viable cysticerci passing the slaughterhouse undetected. Conclusion On a longer term, implementing Ag-ELISA as a detection test in slaughterhouses, would lead to an overall decrease in infections in bovines and humans. Comparison of laboratory and clinical Dengue virus strains reveals major differences in endothelial cell pathology Introduction Dengue is the most prevalent arthropod-borne viral disease in humans worldwide and is caused by 4 different serotypes (DENV 1-4). Despite decades of extensive research, the pathogenesis of DENV is poorly understood. Increased vascular permeability and subsequent plasma leakage are the main characteristics of severe dengue, but the extent to which endothelial cells (ECs) actively contribute to DENV pathogenesis remains debatable. Aim We aimed at characterizing and comparing the responses of microvascular and macrovascular ECs to infection with laboratory and clinical DENV 1-4 isolates. Methods DENV 1-4 infection of ECs was monitored using flow cytometry and real-time RT-PCR analysis. Endothelial cell death was analysed with Annexin V-FITC and propidium iodide, and caspase-3/7 activity was detected with flow cytometry and fluorescence microscopy. The cytokine production profile of 18 cytokines involved in the regulation of endothelial permeability and/or immune cell recruitment was determined by the Bio-Plex 200 system. The microvascular EC line HMEC-1 showed the highest susceptibility to laboratory DENV 1-4, whereas infection of primary ECs resulted in a comparable, lower infection rate. The infection rates in different EC types correlated with the cell surface expression of heparan sulfate (HS). Higher infection rates were also associated with increased caspase-3-dependent apoptosis. Conversely, increased secretion of cytokines involved in the regulation of EC permeability or immune cell recruitment/activation was found to be strain-specific and not strictly related to the degree of infection. Clinical DENV strains showed similar infection rates in different EC types, indicating that they are less dependent on HS expression on the cell surface. Moreover, while DENV-3 was the least infectious laboratory strain, it was by far the most infectious clinical strain in all cell lines tested. Surprisingly, and in contrast to the other clinical strains, the clinical DENV-3 isolate did not induce caspase-3 activation nor apoptosis in infected ECs. Our data indicate that EC responses to DENV infection are mainly determined by the infecting viral strain, and by the degree of adaptation of the virus to cell culture, suggesting that clinical isolates of DENV should preferentially be used to study EC pathology upon DENV infection. Methods Aruban residents with confirmed CHIKV infection were recruited. CHIKV was confirmed in serum collected within 10 days of symptom onset, by CHIKV-specific reversetranscriptase polymerase chain reaction (RT-PCR) and/or by antibody detection (Anti-CHIKV IFT Immunoglobulin M (IgM), Euroimmun, L€ ubeck, Germany). Selected samples with high viral load were genotyped. Chart review (demographic and clinical data at disease onset) was complemented with long-term followup and outcome data obtained by an interview, conducted 18-24 months after initial diagnosis. Results CHIKV infection was diagnosed in 113 sera (92 by detection of anti-CHIKV IgM and 75 by RT-PCR). Asian genotype was confirmed in 4 samples. 104 patients consented to be interviewed. Median age was 48 years (range 14-84 years); female-to-male ratio was 2.1. Symptoms during acute illness consisted of arthralgia (93.3%); myalgia (86.5%); fever (84.6%); headache (69.2%); rash (57.7%); gastro-intestinal upset (31.7%); dizziness (29.8%); sleeping (29.8%) and concentration disorder (23.1%), respiratory complaints (18.3%) and bleeding tendency (2.9%). In the 97 patients presenting with arthralgia, the following joints were affected: knees (58.8%), ankles (54.6%), fingers (49.5%), feet (46.4%), shoulders (37.1%), elbows (32.0%), wrists (32.0%), toes (32.0%), hips (30.9%) and spine (29.9%). Joints were stiff, edematous and red in 76.3%, 39.2% and 21.6%, respectively. Arthralgia lasted shorter than 2 weeks in 33.0%, longer than 6 weeks in 44.3% and longer than 1 year in 28. 9%  Detection of zika virus NS1 antigen in semen by a prototype rapid test Introduction Zika virus (ZIKV) is a vector-borne pathogen that can also be transmitted sexually. Viral loads of ZIKV in semen are typically 1000-fold higher than in serum and urine. Real-time RT-PCR and viral culture are the current diagnostic methods to demonstrate the presence of genomic ZIKV RNA and of replicative ZIKV particles respectively. As these methods require sophisticated laboratory support, a rapid diagnostic test (RDT) to detect ZIKV antigen in semen would be an asset. Aim To evaluate a prototype RDT for the detection of ZIKV NS1 antigen on a panel of stored semen and urine samples containing ZIKV as confirmed by RT-PCR. Methods A prototype immunochromatographic ZIKV NS1 RDT (TANAKA Kikinzoku Kogyo K.K.) was tested on ZIKV RNA-positive semen (n=10) and urine (n=10) samples. Viral loads were expressed by semi-quantitative cycle threshold (Ct)values of the RT-PCR. Semen (60 ll) or urine (30 ll) were mixed with 60 ll buffer of the test kit. The test strip was incubated in this mixture for one minute. Results were read after 15 and 30 minutes. In case of invalid results (i.e. no control line), extra buffer was added. The ZIKV NS1 RDT was positive in 3/10 semen samples with low Ct-values (19.6; 19.6 and 22.4). The 7/10 negative semen samples had a median Ct-value of 30.0 (range 25.2-33.2). All ten urine samples (median Ct-value of 31.3 (range 25.5 -36.4)) tested negative. Semen samples were difficult to process by the RDT; 5/10 samples required additional buffer to improve the flow and to obtain valid test results. Conclusion Only semen samples with a high ZIKV load were detected by the ZIKV NS1 RDT. Further research is needed to establish the relation between ZIKV NS1 positivity and quantitative RNA detection and the presence of replication competent ZIKV in semen. The ZIKV NS1 RDT failed to detect antigen in non-concentrated urine either because the ZIKV particle load may be too low, or because ZIKV antigens may not be excreted in urine. Epidemiological and clinical data of children exposed to zika virus registered in Spanish databasehow often is microcephaly? Introduction World Health Organisation (WHO) declared the spread of Zika virus (ZIKV) a public health emergency of international concern in February 2016. Since then, ZIKV has been associated to microcephaly and other neuro-developmental abnormalities. Spanish database to register ZIKV-infected paediatric patients and children born to ZIKV-infected mothers was created in May 2016. Aim To analyse epidemiological and clinical characteristics of ZIKV-exposed children followed-up in the main referral Spanish paediatric tropical medicine centres. ), and Spain 6.4%(3/ 47). One child developed microcephaly (-3SD for CC and GA) prenatally, her mother had positive ZIKV RT-PCR in serum and amniotic fluid, and foetal MRI showed cortical giral pattern simplification, periventricular calcifications, ventriculomegaly, and global thinning of the corpus callosum. After birth, all children born-to-ZIKV-infected mothers tested negative for ZIKV RT-PCR and IgM. Vector-borne infections were diagnosed by RT-PCR in 2 cases, by IgM (1 child) and by both RT-PCR/ IgM (1 child). Conclusion This is the largest series of children exposed to ZIKV in America, registered in Europe; most of them were born to ZIKV-infected mothers without definitive diagnosis (90.2%). Prevalence of microcephaly was of 2.1% among all children born to ZIKV-infected mothers. Aim We aimed to describe the epidemiological and clinical characteristics, and pregnancy outcomes in a cohort of pregnant travellers at risk of ZIKV as part of a surveillance system in Southern Europe, Spain. Methods All pregnant women attending to the Hospital Cl ınic of Barcelona with history of recent travel to a ZIKV affected area were invited to participate in the study. Screening for ZIKV infection was offered (RT-PCR, serology and microneutralization assay), and demographic, obstetric and clinical characteristics were collected. Pregnant women were followed-up throughout pregnancy and in the case of confirmed or suspected infection (defined as undetermined microneutralization assay or results pending), samples were collected at delivery and newborns were screened for ZIKV at birth. Results From 1 st January 2016 to 28 th March 2017, a total of 125 pregnant women at risk of ZIKV were enrolled and screened. Nine women were positive; 3 by RT-PCR and 5 by microneutralization, and 22 were categorised as suspected cases. They travelled primarily in the peri-conceptional period and in the first trimester, and most visited countries were the Dominican Republic, Colombia and Brazil. Seven out of the nine ZIKV positive pregnant women were symptomatic; being rash the most frequent reported symptom. Pregnancy outcomes among the confirmed and suspected cases included 15 live births at term, a miscarriage associated to ZIKV maternal viremia, 14 ongoing pregnancies and one termination of pregnancy not related to ZIKV. Conclusion Epidemiological surveillance of ZIKV among pregnant women is of major importance also in non-endemic areas for the early detection of imported cases. Close surveillance of pregnant travellers is needed to ensure best clinical care. Efforts should also include close follow up of infants to guarantee prompt management of potential complications. Incidence of travel-associated zika virus infection in 2016: preliminary results of a prospective cohort study in Belgian travellers to the Americas Introduction Zika virus (ZIKV) usually causes asymptomatic infection or mild illness but is also associated with neurological manifestations and poor pregnancy outcomes. The incidence of ZIKV infection in travellers is unknown. Aim To determine the incidence of ZIKV infection in a cohort of Belgian travellers to the Americas in 2016. Methods Belgian travellers, age ≥18 years, with destinations South America (SAM), Central America (CAM) and the Caribbean (CAR), were actively recruited in a larger prospective study of incidence and etiology of febrile illness during travel. Before travel, participants were trained to collect capillary blood on filter paper (BFP) when developing fever or skin rash during travel. All participants, having experienced illness or not, were offered post-travel consultations at our clinic. Sera of participants were obtained (at least 20 days post-travel when no illness was reported) and tested for ZIKV, using ZIKV ELISA. All positive antibody detection assays were subject to confirmation by Virus Neutralization Testing (VNT). When illness was reported ZIKV-specific RT-PCR was performed on serum or urine, or on available BFP. In the travellers who reported illness (n=12), four ZIKV cases were diagnosed, by RT-PCR on BFP (n=2) and urine (n=2). Their symptoms were headache 4/4; fever 0/4; rash 2/4; arthralgia 2/4; abdominal pain and diarrhoea 2/4. In the asymptomatic travellers (n=19), two ZIKV cases were detected, by positive ELISA and VNT. Conclusion Our preliminary observations suggest that ZIKV incidence was high in travellers to the Americas in 2016. The rate of asymptomatic ZIKV infections in travellers appears lower than previously reported. Methods In training sessions in Burkina Faso and Senegal, practice with PPE was observed and specific difficulties were systematically assessed and documented. Each of the PPE components was carefully reviewed both in theory (technical data/level of protection) and in practice (e.g. user-based tests like donning and doffing) at the Robert Koch-Institute. Results EFFO developed proper criteria for selection of PPE components and procurement. Qualitative observations, such as visual and mechanical tests of seams and zippers, proved to be as decisive as quantitative data such as the FIT test for users of filtering face pieces (FFP3 mask). Selecting PPE components solely based on technical data on physical performance or chemical permeation results provided by the manufacturer showed to be insufficient. Conclusion PPE components are not specifically manufactured for outbreak management. Therefore structured and weighted criteria are essential for a best possible decision making process. Results demonstrate that technical data sheets alone are not sufficient but qualitative and quantitative tests are crucial to select a safe, appropriate and applicable PPE. The context always must be taken into account if PPE components have to be selected. Further development of PPE components may facilitate the management in future. Methods Retrospective case series. Results For the therapeutic trials MSF considered potential teratogenic effects as irrelevant considering the 100% foetal mortality. Additionally denying one of the most at risk patient groups access to potentially lifesaving treatment was perceived as unjustifiable. While for the convalescent plasma trial, pregnancy did not constitute an increased risk of adverse effects and pregnant women were included, for the antivirals favipiravir and brincidofovir trial inclusion was not foreseen and access had to be negotiated. The manufacturer Toyama/Fujifilm (Japan) accepted the administration of favipiravir to pregnant women, but the research institute's trial insurance refused their inclusion. Therefore MSF took the responsibility to give access to favipiravir under monitored emergency use. The manufacturer Chimerix (USA) however did not allow any access to brincidofovir for pregnant women. The risk/ benefit balance in vaccination trials is different as experimental vaccines would be given to healthy pregnant women. Although MSF advocated for inclusion of pregnant women in the "Ebola c ßa suffit" trial with the rVSV ZEBOV, they were excluded on the ground of potential foetal harm of the alive vaccine. Nevertheless as pregnancy tests were not systematically done prior to inclusion, some women with early pregnancies were accidentally vaccinated. Discussion Pregnant women tend to be systematically excluded from clinical trials. Risk/benefit balance has to be carefully analysed, priority should be given to the pregnant woman's life over theoretical effects on an unborn foetus. Pregnant women should be given the informed choice about participating or not. Methods This study was part of the Neglected Infectious Diseases Diagnosis (NIDIAG) project and followed a cross-sectional design. Consecutive patients (>5 years) with neurological disorders (i.e. altered consciousness, severe increasing headache, gait disorders, sleeping abnormalities, new onset convulsions or focal neurological deficit) were recruited at Mosango hospital, Kwilu province in 2012-2014. In 2016, stored serum samples were tested for antibodies against HTLV using two ELISA (Avioq â and Murex â ). If at least one ELISA was positive, confirmatory line immunoassay (Inno-Lia â ) was performed. Results For 328 of 351 patients enrolled in the original study, serum was available for HTLV testing. Ninety-six percent (314/ 328) of the patients were classified as HTLV negative: 301 had two negative ELISA and 13 had discordant ELISA with negative confirmatory results. One percent (3/328) were classified as indeterminate: they had discordant ELISA and indeterminate confirmatory results. The remaining three percent (11/328) were classified as HTLV seropositive: based on line immunoassay, 5 were HTLV-1 positive, 3 were HTLV-2 positive and 3 were positive for HTLV but the type could not be determined. The mean age of the 11 HTLV-seropositive patients was 47 years (standard deviation 18); 7/11 were women. Gait could be evaluated in 242 patients: 56% (5/9) of HTLV-seropositive versus 23% (53/233) of HTLV-negative patients had abnormal gait (P = 0.04). Thirty-six percent (4/11) of HTLV-seropositive patients versus 2% (5/314) of HTLV-negative patients had a parasitologically confirmed diagnosis of stage-2 human African trypanosomiasis (HAT; P < 0.001). Conclusion Three percent of patients with neurological disorders had positive serology for HTLV. Whether the high frequency of HTLV-positive results in patients with stage-2 HAT reflects true HTLV infection or false-positive reactions due to HAT-associated polyclonal B-cell activation remains to be investigated. HTLV-seropositive patients had more gait problems than HTLV-seronegative patients. Presence of defective HTLV-1 provirus in Peruvian asymptomatic carriers Introduction Defective Human T-cell leukaemia virus type 1 (HTLV-1) provirus are classified as type I if lacks internal regions, and type II if retains 3 0 LTR, but lacks 5 0 LTR and internal regions. Even though HTLV-1 is associated with two main diseases, tropical spastic paraparesis (HAM/TSP) and adult t-cell leukaemia/lymphoma (ATLL), defective provirus has been reported mostly in acute cases of ATLL in Japan. To our knowledge there are no reports of defective provirus in Peruvians infected with HTLV-1. Aim The aim of this study is to assess the presence of defective HTLV-1 provirus. Methods First, DNA extracted from total blood of 118 HTLV-1-infected individuals, including HAM/TSP (n = 46), ATLL (n = 11), and asymptomatic carriers (AC) (n = 61), were studied. To assess the presence of defective provirus, conventional PCR (cPCR) was performed for gag, env and tax genes. Then, RT-PCR was performed using different primers directed to 5'LTR-gag (151 bp), env-pol (91 bp) and pX (97 bp) regions, for this purpose DNA extracted from PBMCs in 10 out of 18 AC samples was use. Results Eighteen out of the 118 samples (12.3%) had at least one region of gag, env and tax genes missing when tested by cPCR, all 18 samples correspond to AC (18/61, 29.5%). RT-PCR results in 10 out the 18 defective provirus in AC showed that two were type I and four were type II. Interestingly, four samples (either gag, env or tax defective accordingly to cPCR results) were positive for 5'LTR-gag, env-pol and pX regions. Results It was found that over 70% of participants had contact or consumed wild game. Lethargy and stupor were noted in 6% of patients; 68% had diminished activity level. Clinically, the following signs and symptoms were observed among symptomatic cases; malaise 83%; sore throat 77%; anorexia 50%; cough 50%; chills 46%; nasal discharge 30%. Fever was noted in 35%; lymph node enlargement was seen in 96%. Clinical status ranged from very mild to critically ill. Viremia (by PCR) ranged from undetectable to 6.3 9 10 7 genomes/mL blood. The proportion of patients with low albumin was 98% and low creatinine was 35%. The proportion with elevated ALT 12%; ALP 61%; AST 39%; GGT 12%. The case-fatality rate (CFR) was 1.4% compared to 14% among hospitalized patients from previous studies. For the subjects followed before illness onset, maximum viral load occurred prior to appearance of lesion, coincident with first onset of illness. humans is associated with malaise, sore throat, lymph node enlargement as well as a significant decrease in albumin levels among other features. AIDS-related systemic mycoses endemic to Western Cape, South Africa and clinical mimics: a cross-sectional study of adults with advanced HIV and recent-onset, widespread skin lesions Introduction Skin lesions are common in advanced HIV infection and are sometimes caused by serious diseases like systemic mycoses (SM). AIDS-related SM endemic to Western Cape, South Africa include emergomycosis (formerly disseminated emmonsiosis), histoplasmosis, and sporotrichosis, caused by the dimorphic fungi Emergomyces africanus, Histoplasma capsulatum, and Sporothrix schenckii, respectively. A retrospective report of patients with emergomycosis reported 95% had skin lesions, although these were frequently overlooked or misdiagnosed by clinicians 1 . Aim To prospectively characterize HIV-infected patients with cutaneous lesions caused by SM endemic to South Africa and clinical mimics thereof; and identify epidemiological and clinical findings that may help diagnose SM. Methods We prospectively enrolled 39 HIV-infected adult patients living in Western Cape, South Africa with CD4 counts ≤100 cells/lL, and widespread skin lesions that were present ≤6 months and deemed clinically suspicious for SM by infectious disease physicians, dermatologists, or HIV practitioners. We obtained skin biopsies for histopathology and fungal culture, and collected epidemiological and clinical data. Results SM was proven for 25 patients: 14 had emergomycosis, 3 each had histoplasmosis and sporotrichosis, and for another 5 patients, the pathogen could not be identified. One patient had a possible SM (Histoplasma antigenuria detected but negative cultures and a non-diagnostic skin biopsy), whereas 13 patients did not have SM. Antiretroviral therapy (ART) had been initiated in the preceding 4 weeks for 11/25 (44%) of patients with and none without SM, respectively (P = 0.006). Plaques and ulcers occurred more frequently in patients with SM (84% vs 38%, P = 0.009 and 72% vs 31%, P = 0.02, respectively). Abnormal chest x-rays were noted in 86% and 50% of patients with and without SM (P = 0.07). or ulcers should make clinicians consider SM in patients with advanced HIV infection in this geographic area. Clinical overlap between SM and dermatoses makes early skin biopsy critical for timely diagnosis and treatment.  Vivax malaria morbidity after radical treatment: a 2-year cohort study in central Vietnam Introduction In Vietnam, the public health importance of P. vivax has recently increased as a result of the successful malaria control program applied over the past 20 years and the recent country's commitment to malaria elimination by 2030. Aim We conducted a 2-year prospective cohort study to determine the risk of vivax recurrences after radical treatment with a high dose primaquine regimen and identify related risk factors. December 2011 in 4 neighbouring villages situated in a remote forested area of Quang Nam province, Central Vietnam. P. vivax infected patients were identified through active and passive detection, and invited into a 2-year monthly follow-up after radical cure treatment (chloroquine + primaquine) following national guidelines. Monthly blood samples were systematically analysed for malaria parasites by LM and PCR. Time to first vivax recurrence was estimated by Kaplan Meir (KM) survival analysis, and significant risk factors were identified using multivariate Cox regression and the categorical and regression tree (CART) method. 3S3.2 P. vivax recurrences after radical treatment in the Peruvian Amazon: a 2-year cohort study Introduction P. vivax malaria represents about 80% of all malaria infections and most of the burden is located in the Amazon region. Due to adherence issues to the 14-day primaquine treatment recommended by the WHO, the national guidelines in Peru include a 7-day primaquine course with high primaquine dosage. Amazon to determine the risk of P. vivax recurrence after radical treatment following national guidelines. in 29 peri-urban and rural communities near capital city of Iquitos city in Loreto Dept. P. vivax infected patients treated radically with chloroquine and primaquine were followed monthly for 2 years post-treatment. All blood samples were analysed for malaria parasites by light microscopy (LM) and PCR. Time to first vivax recurrence was estimated by Kaplan Meir (KM) survival analysis, and significant risk factors were identified using multivariate adjusted Cox regression and the categorical and regression tree (CART) method. Results A total of 302 P. vivax patients (sex ratio 1.1; median age 20y) were enrolled and completed primaquine treatment. Two late parasitological failures were identified at day 28 while another 17 (5.8%) patients were positive for P. vivax by PCR. 70% of cohort subjects experienced at least one PCR detectable vivax recurrence, and among the total 637 recurrences detected only 222 (35%) were detectable by LM. The median time to first PCR vivax recurrence was 6.5 months and the KM estimate for the risk of vivax recurrence by month 24 was 70% (95CI [65; 76]). The detailed risk factor and spatial clustering analysis will be presented. Conclusions A high number of P. vivax recurrences, mainly sub-microscopic and asymptomatic, were observed after the 7day radical cure. Malaria elimination efforts need to address this largely undetected transmission of P. vivax with improved diagnostic and treatment strategies. Introduction Primaquine is the only commercially available drug that kills mature P. falciparum gametocytes, the parasite lifecycle stage responsible for the transmission of malaria from the human to the mosquito. Primaquine can cause haemolysis in individuals with glucose-6-phosphate dehydrogenase deficiency (G6PD). The severity of haemolysis is dependent on the dose of primaquine used and the level of G6PD enzyme activity. The WHO recommends the use of a single low (0.25 mg/kg) dose of primaquine (SLD PQ) with an artemisinin-based combination treatment, without prior G6PD testing, to individuals with uncomplicated malaria in countries targeting elimination and/or facing drug resistance against artemisinin-based therapies. Adoption of the WHO recommendation to use SLD PQ has been slow, particularly in African countries where there is a perceived lack of evidence for its safety and efficacy. Numerous clinical trials have been conducted, presenting a valuable dataset for further scrutiny. Aim The objectives of the safety analysis are to quantify the reduction in haemoglobin between days 0 and 7 associated with the administration of SLD PQ and to investigate potential factors predicting these reductions. In addition, the analysis characterizes the incidence, type, and study drug relationship of reported serious adverse events and adverse events of special interest with particular attention to mortality, blood transfusion and reports of dark urine. The objectives of the efficacy analysis are to quantify the change in gametocyte prevalence and density and to assess the infectivity of gametocytes to mosquitoes as measured by membrane feeding assay, following administration of SLD PQ. The impact of age, sex, and G6PD status on the efficacy and safety of PQ given at single doses ≤0.75 mg/kg will be evaluated and modelled to generate a therapeutic dose range to inform safe deployment in Africa. Methods WWARN is undertaking an individual patient data meta-analyses of studies conducted in Africa testing SLD-PQ. Data for inclusion in the study were identified from a review of trial registries. Results Analysis is ongoing but will be complete by September. Results will be presented from a pool of 13 studies, representing a total of 5,017 participants. The consequences of censoring new infections when deriving antimalarial efficacy against uncomplicated P. falciparum malaria P. Dahal 1,2 on behalf of the WWARN Methods study group 1 1 WorldWide Antimalarial Resistance Network (WWARN); 2 Centre for Tropical Medicine and Global Health, University of Oxford, Oxford, UK Introduction The primary endpoint in efficacy trials of uncomplicated P. falciparum is polymerase chain reaction adjusted failure defined as the reappearance of the same parasite which caused the initial infection (recrudescence). Competing risk event (CE) of a new infection can be observed during the follow-up. These are censored in Kaplan Meier (K-M) analysis, the currently recommended statistical method for deriving failure. In the presence of CE, K-M is known to result in an overestimate of cumulative failure compared to Cumulative Incidence Function (CIF). Aim The overall aim of this work is to quantify the bias due to the use of K-M in estimating cumulative failure in studies with artemisinin combination therapies (ACTs) in uncomplicated P. falciparum. Methods Cumulative failure for recrudescence were derived using: 1 minus K-M estimate where competing events were censored, and CIF which accounts for competing event by still maintaining them in the risk set. The discrepancy between the two estimates was expressed as absolute and relative difference. The impact of study duration, proportion of recrudescences and new infections on the difference was investigated. Aim Achieving the aspirational WHO targets for malaria eradication and elimination will require an innovative drug discovery pipeline. The presentation will outline the MMV drug discovery strategy to deliver new drug candidates to support the malaria eradication agenda. The benefits of carrying out drug discovery activities within a global network of academic and industrial partners will be described, with a particular emphasis on the use of new open ways of working. The research programs leading to the discovery of several new drug candidates with activity across the malaria lifecycle will be presented. Conclusion Working with a global network of drug discovery partners, MMV has delivered an exciting pipeline of new drug candidates, with the potential to contribute towards both the treatment and eradication of malaria. Asymptomatic bacteriuria in pregnant women as a proxy for antibiotic resistance surveillance in the community: preliminary results from a study in Nanoro, rural Burkina Faso Introduction Antibiotic resistance is a public health concern in low resource settings but community-based surveillance data are rare. Asymptomatic bacteriuria (ASB) during pregnancy occurs in 2 -10% of women. Bacteria causing ASB in pregnancy may be considered as a valid proxy for the antibiotic susceptibility data of bacteria causing community-associated urinary tract infections. Aim To assess the antibiotic susceptibility data of bacteria causing ASB in a rural setting of the Nanoro health district, Burkina Faso. Methods A non-interventional, cross-sectional study was carried out among pregnant women attending 3 selected antenatal care centers, starting in October 2016. Demographic and clinical data were recorded. Clean midstream urine fraction was collected and inoculated on-site into URICULT MC/CLED (International Medical Products, Brussels, Belgium). After overnight incubation at 35°C, grown cultures were identified by standard bacteriological methods and antibiotic susceptibility testing was performed according to CLSI M100-S27 guidelines. ASB was defined as growth of ≥ 100.000 bacteria/ml. By February 2017, 1,000 women had participated; participating rate was 100%. A total of 65 (6.5%) women had ASB; species included Escherichia coli (55.1%), Enterobacter spp. (26.5%), Staphylococcus aureus (10.2%), Klebsiella spp. (6.1%), and Proteus mirabilis (2.0%). At the time of writing, antibiotic susceptibility data of 49 (75.4%) isolates were available. For Escherichia coli (n = 27), 18 (66.6%), 15 (55.6%) and 2 (7.4%) isolates were resistant to co-trimoxazole, amoxicillin, and ciprofloxacin respectively. One isolate was resistant to third generation cephalosporins and co-resistant to ciprofloxacin, cotrimoxazole, gentamicin and aztreonam. There was no resistance against nitrofurantoin, fosfomycin and meropenem. Among Enterobacter species (n = 13), 8 (61.5%), 6 (46.2%) and 1 (7.7%) isolates were resistant to amoxicillin, co-trimoxazole and ciprofloxacin respectively. One (7.7%) isolate was resistant to third generation cephalosporin; 2 and 1 isolates were resistant to nitrofurantoin and fosfomycin respectively. Staphylococcus aureus isolates (n = 8) were all methicillin-susceptible; 2 and 1 isolate were erythromycin and clindamycin resistant. Nanoro health district, antibiotic resistance rates among ASB bacteria (E. coli, S. aureus) were lower. However, final study results need to be awaited and continuous monitoring is warranted. Meta-analysis of proportion estimates of extendedspectrum-beta-lactamase-producing Enterobacteriaceae in East Africa hospitals Introduction The magnitude of ESBL-producing Enterobacteriaceae in East Africa is large but information is scarce and thus it is unclear how big the problem really is. Enterobacteriaceae, a literature review was performed. Methods A random-effects meta-analysis model was used to calculate the pooled (weighted) proportion of ESBL and the I 2 statistic (measure of inconsistency) as described by Nyaga et al. [1] . Results 4076 bacterial isolates were included. 24 articles were reviewed: 12 (50.0%) from Tanzania and 12 (50.0%) from Ethiopia, Kenya, Uganda, and Rwanda. No articles were found for Burundi. The overall pooled proportion of ESBL-producing Enterobacteriaceae was 0.42 (95% CI: 0.34-0.50). Heterogeneity (I 2 ) between countries' proportions was significantly high (96.95% and P < 0.001). The countries pooled proportions were: Ethiopia 0.30 (95% CI: 0.21-0.38), I 2 was 67.98% and P = 0.02, Kenya 0.47 (95% CI: 0.23-0.71); I 2 was 98.82% and P < 0.001, Tanzania 0.39 (95% CI: 0.30-0.48); I 2 was 93.16% and P < 0.001, Uganda 0.62 (95% CI: 0.38-0.87); I 2 was 97.83% and P < 0.001. The scarcity of studies available from the region warrants caution in drawing conclusions. This review finds high proportion of ESBL-producing Enterobacteriaceae across hospitals in the region but that is close to estimates for Ghana (49%), Cameroon (54%), Gabon (45%), Morocco (43%) and China (46%). However, the region's proportion is considerably higher than for resource-rich countries: Germany (10-15%) and USA (4-12%). Over-the-counter sale of drugs, counterfeit drugs, and non-adherence are very common in African settings; are among the factors that are unnecessarily fueling emergence of resistant microorganisms. These findings underscore an urgent need for antimicrobial resistance surveillance to help understand the actual epidemiology and aid in formulating national or regional guidelines.  Antibiotics under pressure Introduction Fluoroquinolones, macrolides and cotrimoxazole have therapeutic effects for a broad range of infections. They play important roles in the management of invasive bacterial diseases, but also in the management or prevention of (multidrug resistant) tuberculosis, malaria, trachoma, neonatal sepsis,. . . The access to some of those drugs has been made restrictive for certain programs only or conversely have become liberalized. In the absence of an overarching antibiotic stewardship program for these drugs, this may lead to 'competition' between the different disease control programs. Aim and Methods A comprehensive narrative overview of recent evidence and ongoing studies on 'new' indications for fluoroquinolones, azithromycin and co-trimoxazole will be discussed against a background of global antibiotic stewardship. Results Fluoroquinolones are key components in second line tuberculosis treatment. Over the past 20 years, they have also been promoted and used worldwide for a wide variety of other diseases. This popularity has come with a price of fast increasing resistance, in Gram-negative bacteria (e.g. Salmonella typhi) as well as in mycobacteria. By virtue of its broad spectrum, favorable pharmaco-dynamic and kinetic properties and safety profile, azithromycin is a widely used antibiotic in particular for respiratory tract infections, sexually transmitted diseases and diarrheal diseases. Recently, its use in mass treatment and prophylaxis is being advocated in tropical low-resource settings for a number of indications, including trachoma, non-venereal treponemal infections, neonatal sepsis and malaria respectively. However, over the past 5 years, azithromycin resistance has also been reported increasingly in key pathogens from several tropical low-resources settings, such as streptococci and Salmonella spp. Co-trimoxazole is one of the oldest and among the most widely used antibiotics for a wide variety of indications. With the emergence of HIV/AIDS, it has been increasingly positioned as a prophylactic drug. Co-trimoxazole may as well play an important role as reserve antibiotic in severe bacterial infections, e.g. invasive staphylococcal infections. The question arises to which extent these indications are mutually compatible. Conclusion With a growing number of competing indications for these niche drugs, many questions remain. There is an urgent need for enhanced inter-programmatic communication and an overarching policy. IP-10 kinetics in the first week of therapy are strongly associated with subsequent bacteriological confirmation of tuberculosis in HIV-infected patients Introduction Simple effective tools to monitor the long complex treatment of tuberculosis are lacking: Microscopy is insensitive and quantitative culture is slow and complex. Easily measured promising host derived biomarkers have been identified but need to be validated in larger diverse studies and different population groups. Aim We investigated the early response to IP-10 (between day 0 and day 7 of TB therapy) to identify bacteriologically confirmed and PCR/culture negative HIV positive patients starting tuberculosis treatment. Methods IP-10 levels were measured, at day 0 day 7 and day 60, using a commercial ELISA assay, in a cohort of 127 HIV positive patients starting TB treatment for any reason. All participants were then classified as responding or not responding to treatment blindly using a previously described IP-10 kinetic algorithm. The results of this classification were then compared to molecular and culture based diagnostics and resistance testing. Results There were 77 bacteriologically confirmed cases and 41 PCR and culture negative cases. The majority of participants had a measurable decline in IP-10 during the first 7 days of therapy. Bacteriologically confirmed cases were more likely to have high IP10 levels at D0 and in general had a steeper decline than clinically diagnosed cases (mean decline difference 2231 pg/dl, 95% CI 897-3566, P = 0.0013). Bacteriologically confirmed cases were more likely to have a measurable decline in IP-10 at day 7 than clinically diagnosed cases (48/77 (62.3%) vs 13/41 (31.7%), P < 0.001). Conclusion This study confirms the association between a decrease in IP-10 levels during the first week of treatment and a bacteriological confirmation at diagnosis is also present in a cohort of HIV positive patients. Further work should explore the use of IP-10 kinetics and other biomarkers to improve access to effective treatment monitoring for patients on TB therapy. New diagnostic tests for tuberculosis: Performance of LAM and Xpert MTB/RIF in urine of hospitalized patients on intensive phase of TB treatment, and its association with TB dissemination and HIV status. Preliminary results from an observational cohort study in Kigali, Rwanda Introduction TB diagnosis is presumed on clinical and medical imaging criteria in about 40% of hospitalized patients treated for TB. Measuring lipo-arabinomannan (LAM), a liposaccharide from the mycobacterial wall, and mycobacterial DNA by Xpert MTD/RIF in urine may be useful additions to the classic sputum exams. measured qualitatively in hospitalized patients treated for TB, in relation with TB disease dissemination, HIV coinfection and TB diagnostic confirmation by sputum microscopy. Patients starting TB treatment during hospitalization are included. Urine samples are taken soon at TB treatment initiation and again one and two weeks thereafter. Diagnostic workup includes chest X-ray, abdominal ultrasound, and sputum AFB by microscopy and/or Xpert MTB/ RIF. Urine samples are examined with a lateral flow POC LAM test on 60 lL of urine, and with an Xpert MTD/RIF assay on centrifuged precipitate of 40 ml urine. Results So far, 29 patients, 13 HIV coinfected, are enrolled. TB diagnosis was confirmed in 23/29 (79%), either by AFB microscopy and/or sputum Xpert in 19/29 (66%), or by LAM solely in 4/29 (14%). LAM readings (grade 1 or more) were positive in 16/29 (55%) and LAM grade 2 or more in 8/29 (28%). Compounded LAM readings in 6 patients submitting three urine samples was 8 at start, 11 at one week and 5 at 2 weeks. There was no significant association of LAM test results with HIV coinfection or with MTB positive sputum. LAM readings tend to be higher in HIV coinfected TB patients. Disseminated TB was associated with HIV coinfection, but not with a positive urine LAM test. Urine Xpert was positive in 4/19 (21%) patients analyzed thus far. Conclusions Although less performant than sputum MTB detection, the urine LAM test shows promising results both in HIV negative as is HIV coinfected patients, and in patients whose sputum MTB readings are negative or absent. LAM test scores tend to be higher in HIV coinfected TB patients and when taken 8 days after starting TB treatment. LAM results are not associated with TB dissemination. [Correction added on 12 December 2017, after first Online publication. Authors name B. Leopold, N. Samuel, D. Aimable and C. Joannes were corrected to L. Bitunguhari, S. Nkundibiza, A. Dukundane and J. Clerinx respectively]. Association between rpoB mutations and probe profiles, and potential application of WHO-endorsed rapid diagnostic tests for rifampicin resistant-TB control Introduction The unknown actual burden of rifampicin resistant tuberculosis (RR-TB) is attributed to cases being largely undetected and untreated. Recognizing the immediate need to rapidly detect RR-TB, WHO has recommended implementation of Rapid Diagnostic Tests (RDTs) as primary tool for detection. This has generated massive amounts of data which contains crucial information that could be utilised for RR-TB surveillance. Aim This study aimed to evaluate the association between rpoB mutations and grouping of mutant sequence profiles by RDT probes as well as discriminatory ability and congruence of RDTs as a means to maximise utilisation of RDT data and examine its potential application for RR-TB control. Methods 108 non-clustered RR-TB strains representing 32 different rpoB mutations situated within the 81 bp RRDR were selected from the Belgian Coordinated Collections of Microorganisms hosted at the ITM. These strains were subjected to Xpert MTB/RIF (Cepheid), MTBDRplusv2.0 (Hain), and GenoscholarTMNTM+MDRTB II (Nipro). Raw data from seven mutation profiles found in at least four strains, and four mutation profiles in two to three strains were analysed through Pearson's chi square test to determine associations between rpoB mutations and grouping of mutant sequence profiles defined by the RDT probes. Further, Simpson's indexand Hubert and Arabie's Adjusted Rand values were obtained from all mutation profiles to assess discriminatory ability and congruence of RDTs respectively. Comparison of observed and claimed RDT probe coverage revealed unique probe profiles for each mutant sequence as presented in Figure 1 , in which the consensus numbering system for M. tuberculosis H37Rv has been adapted. This figure, supported by Simpson's indices ranging from 0.88-0.92, exemplifies ability of the RDTs to discriminate between and among different mutant sequence profiles. Significant association was found between rpoB mutations and grouping of mutant sequence profiles by Hain and Nipro probes. Moroever, adequate congruence was found between Hain and Xpert. Conclusion Taken together, significant correlation between rpoB mutations and clustering defined by RDT probes as well as sufficient discriminatory ability and congruence of RDTs support the validity of its potential use for RR-TB control. Complementary testing with gold standard genotyping methods is recommended for definitive findings. Effectiveness and safety of long-term versus short-term treatment regimen of multidrug-resistant pulmonary tuberculosis in Burkina Faso Introduction The emergence of anti-tuberculosis drug resistance is of big concern in several countries and impede the effectiveness of tuberculosis control worldwide. The treatment protocol in Burkina Faso was a 21 months long-term regimen (LR) and it was costly and burdensome, both for patients and health staff. Methods We compared retrospectively two cohorts of patients who were followed for MDR-TB, from 1 January 2013 to 31 December 2015, in the Pulmonology Services of the University Hospitals Yalgado Ou edraogo and Souro Sanou in Burkina Faso. The first cohort was under LR, based on the following drugs: pyrazinamide, kanamycin, levofloxacin, ethionamide and cycloserine. The second cohort was under SR, based on: kanamycin, moxifloxacin, protionamide, isoniazid, clofazimine, ethambutol and pyrazinamide. Results A total of 80 patients were included in the study. 47 patients were under LR and 33 ones under SR. There were more retreatment failures in patients under LR than in those under SR (P = 0.00). Also, during follow-up, patients under SR had a higher mean weight than those under LR (P = 0.01). Patients with side effects under the SR (51.5%) were not significantly more numerous than those under the RL (51.1%). All SR patients had a smear negative during control of the last three months treatment. There was significantly more therapeutic success in patients under SR (87.9%) than in those under LR (51.1%) (P = 0.00). More deaths were observed in patients under LR than in those under SR (0.00). The nine months SR is well tolerated and more effective than the 21 months LR. This SR protocol has just been endorsed by the WHO in 2016 yet, a sufficient hindsight is needed to better appreciate its benefits. Identification of non-tuberculous mycobacteria isolated from clinical specimens at Dr George Mukhari Tertiary Laboratory, South Africa, using the genotype mycobacterium CM/AS assay and 16S RRNA gene sequencing Introduction Besides the burden of disease from Mycobacterium tuberculosis (Mtb), non-tuberculous mycobacteria (NTMs) are increasingly being isolated from pulmonary and extra-pulmonary sites 1, 2, 3 in both immunocompromised and immunocompetent individuals 1, 4 worldwide. Aim To measure the prevalence of different non-tuberculous mycobacterial species from patients with presumptive tuberculosis at the National Health Laboratory -Dr George Mukhari Tertiary Laboratory (NHLS -DGMTL). Methods Consecutive NTMs isolated from clinical specimens from 2012 to 2015 were included in the study. The MPT64 Ag detection test was used to exclude the Mycobacterium tuberculosis complex (Mtbc), followed by identification of NTMs using the GenoType Mycobacterium CM and AS assay methods, and 16S rRNA gene sequencing.  Early diagnosis of acute schistosomiasis by schistosome DNA detection in serum in a cluster cohort of 34 travelers exposed in South Africa Aim To compare the performance of standard diagnostic tests and molecular tools for the diagnosis of acute phase Schistosoma infection in a cluster of travellers exposed to infested freshwater in an endemic region. Methods Patients were subjected to eosinophil count, schistosome antibody tests (ELISA and IHA assay), ova detection in feces and urine by microscopy and PCR assays targeting the Dra1 sequence of the S. haematobium complex and the Sm1-7 sequence of the S. mansoni complex in serum samples from the early phase (week 4-5) and during week 7-8. Nineteen to 41 days after freshwater exposure in South-Africa, 32/34 (94%) travellers developed symptoms. Of the 33 patients evaluated at week 4-5, the eosinophil count was increased (>750/lL) in 12 (36%) and Schistosoma antibodies were detected in 3 (9%) by IHA but in none by ELISA. Ova were absent in all 33 urine and all 31 feces samples. The Dra1 PCR was positive in 24 (73%) travellers. The Sm1-7 PCR in serum was positive in only one, which was also positive with the Dra1 PCR. Sequencing is ongoing to identify the (hybrid) species. At week 7-8, all 34 travellers were tested, of which 22 (65%) demonstrated an increased eosinophil count and 12 (35%) seroconverted with ELISA. The IHA test was negative in 14 and invalid in 20 travellers. Eggs were still absent in all 34 urine and 32 examined fecal samples. By week 7-8, the Dra1 PCR was positive in the patient not initially tested, and turned positive in an additional 6, giving a total diagnostic yield for this test of 31/ 34 (91%) patients. In this cluster of exposed travellers, the schistosome infection rate was extremely high. PCR was able to diagnose infection at an earlier stage than any of the standard diagnostic tests. Whether the 3 patients with negative test results were not infected remains to be evaluated by follow-up. Introduction Prescription of on-demand antibiotics is recommended for immunocompromised travelers (ICTs) to prevent severe complications of diarrhea. The rationale for this recommendation is questionable since it is not established that ICTs suffer more, or more severely, from complications of diarrhea during traveling. Furthermore, antibiotic treatment increases resistance. Aim Our objective was to elucidate whether immunocompromised patients suffer more frequently from travel-related disease compared to healthy controls; whether they use more antibiotics, and seek more often medical care during travelling. Methods We performed a questionnaire based case-control study on ICTs and sex-and age-matched healthy travelers. We recruited participants from a (medical) pre-travel clinic. Telephone interviews were conducted 2-4 weeks after traveling using a structured questionnaire on exposures, health complaints, antibiotic use and need for medical care. We included 30 ICTs and 30 healthy travelers of which 38 (63.3%) were men; mean age was 49 years across groups. Of ICTs, 16 (53.4%) received immunosuppressive treatment due to auto-immune disease and nine (30.0%) due to kidney transplantation, three (10.0%) were HIV positive, two (6.6%) had another immunocompromising condition. Asia was most frequently visited (n = 39, 65%). Ten (16.7%) participants visited South-America and eleven (18.3%) Africa. Currently, interviews have been conducted in 21 cases and 12 controls; we expect to complete telephone interviews by 30 June 2017. We analyzed data available to date: 11/21 (52.4%) cases and 7/12 (58.3%) controls reported mild complaints during travelling. One case reported severe disease and was hospitalized directly after travelling. ICTs used antibiotics more often than healthy travelers (4/21, 19.0% versus 1/11, 9%). Two of those four ICTs started antibiotic treatment for another reason than advised during pre-travel consultation (mild coughing without fever). Conclusion Available data revealed no more gastrointestinal complaints, but more antibiotic use in ICTs compared to healthy traveler. However, the fact that one ICT suffered from severe illness and had to be hospitalized suggests that the recommendation for on-demand-antibiotics still is substantiated. Therefore, based on current evidence, ICTs should be instructed very carefully when prescribed on-demand-antibiotics. More research is needed on the prevalence and consequences of resistance patterns in ICTs after antibiotic treatment. Under-diagnosis of rickettsial disease in returning travelers Introduction Rickettsial diseases are zoonotic infections causing acute and potentially severe, but treatable, acute unspecified febrile illness. It is increasingly reported in travelers, the vast majority being murine typhus (Rickettsia typhi), Mediterranean spotted fever (Rickettsia conorii), scrub typhus (Orientia tsutsugamushi), and African tick bite fever (Rickettsia africae). One or more inoculation eschars at bite sites are typical, but not always present; and considerable under-diagnosis in case of non-eschar rickettsial disease (NERD) is suspected, because of the overlapping clinical spectrum with other acute imported infections, such as leptospirosis. Aim To estimate the prevalence of rickettsial disease as a cause of acute febrile illness in leptospirosis-negative travelers presenting at a specialized travel centre. Methods A retrospective cohort study was performed. All travelers returning from Africa, the Americas or Asia, who presented at the Center of Tropical Medicine and Travel Medicine in Amsterdam, the Netherlands, between January 2012 and August 2015, and tested negative for acute leptospirosis at the National Leptospirosis Reference Center, were included. An enzyme-linked immunosorbent assay (ELISA) was performed to detect IgM and IgG antibodies to typhus-group Rickettsia (R. typhi and R. prowazekii). Indirect immunofluorescence immunoassays (IFA) were performed to detect IgM and IgG antibodies to typhus group and spotted fever group (R. rickettsii and R. conorii) Rickettsiae, as well as to Orientia tsutsugamushi (scrub typhus). Results Ninety-two returned travelers met the inclusion criteria. The majority (n = 42) had traveled to Asia, followed by Africa (n = 30) and the Americas (n = 20). A confirmed diagnosis was obtained for five patients (5.4%). One patient, returning from Morocco, was found infected with spotted fever group Rickettsia; four patients had a confirmed typhus group (most likely R. typhi) infection (ELISA and IFA strongly positive) returning from French Guinea, Indonesia, Borneo and India. O. tsutsugamushi assays are currently being done. Conclusion Rickettsial disease is significantly prevalent in returning travelers. It should be considered in any traveler with acute unspecified febrile illness returning from endemic areas. If diagnostic methods are not available, treatment with empiric doxycycline should be initiated. Epidemiology of travel-related health events among HIV infected immigrants living in France and visiting their country of origin in sub-Saharan Africa -The ANRS-VIHVO morbidity sub-study  immigrants living in France planning to visit their country of origin in SSA (VIHVO) for a length of stay between 2 weeks and 6 months provided that HIV RNA were < 200 copies/ml at inclusion. Demographic, patients and travel characteristics were collected at inclusion. Health events were reported during the study follow-up visits at 1 week and 12 weeks after their return to France. We included in our analysis the VIHVO who attended at least one of the follow-up visits. Khi-2 or Fisher's exact tests were used to compare patients and travel prophylaxis characteristics to the first travel-related health event or febrile event. Univariates and multivariate Logistic regression models were used to identify factors associated with the first travelrelated health event. Results Of the 264 VIHVO travelers included, 157 (59%) were women and the mean age was 42 years (CI 20-69). Among them, 74 (28%) were CDC stage C, the CD4 ranged from 66 to 1680/mm3 with a median of 439/mm3 (IQR: 332-570), and 247 (94%) were undetectable. Up to 257 (98%) reported a VFR in 24 countries of SSA with 124 (47%), 129 (49%) and 11 (4%) journeys respectively in West, Central and East Africa. A lack of international vaccinations before departure and malaria chemoprophylaxis adherence (36%) were reported. Overall 111 travel-related events were reported, mainly digestive 25 (23%), neuro-functional 15 (14%), respiratory 14 (13%), dermatologic 14 (13%) and febrile 14 (13%) syndromes including 5 (5%) confirmed malaria cases with 1 lethal case. AIDS-defining illnesses were 3 (3%) (2 Kaposi and 1 tuberculous arthritis). Of them, 71 (70%) occurred during the journey. Febrile events were significantly less frequent in the VIHVO who received pre-travel advices against vectors bites or diarrhea, or malaria chemoprophylaxis prescription. HIV residual viral load at baseline increased the risk of travel-related health events with and adjusted odd ratio of 5.20 (1.51 -17.92), P = 0.0098. Our findings are absolutely original and give supports to an increased risk of travel-related health events among VIHVO, especially severe malaria. Travel advices among VIHVO should promote a suppressed HIV viral load before departure, an international vaccination status updated and a higher malaria chemoprophylaxis adherence. Epidemiological and clinical profile of imported strongyloidiasis from the REDIVI network Methods Observational retrospective study (2009) (2010) (2011) (2012) (2013) (2014) (2015) (2016) where all registered patients in REDIVI with the diagnosis of strongyloidiasis were included. The following information was retrieved from the REDIVI database: demographic information (age, sex, country of origin and country of residence, time of residence in our country), patient classification (immigrant, VFR, traveller), presence of immunosuppressant conditions, travelrelated information (country, duration, pre-travel advice, etc.), main symptoms, and diagnosis. Extra information of these patients was requested to the participant centres: HTLV-I coinfection, eosinophil cell count, and microbiological techniques performed (microscopic examination of stools, faecal culture, serology), treatment, and follow-up (eosinophil cell count and microbiological techniques). Results During the study period, 12796 patients were registered in the REDIVI database, from which 1279 (10%) have been diagnosed of strongyloidiasis: 1269 non-complicated strongyloidiasis and 10 Strongyloides hyperinfection syndrome. Six hundred and sixty-seven (52.2%) patients were women, with a mean age of 38.2 years, and 80 (6.3%) patients had an immunosuppression condition. Region of origin was Latin America in 857 (67%) cases and Sub-Saharan Africa in 267 (20.9%) cases. Regarding patient classification, 853 (66.7%) were immigrants, 351 (27.4%) were "visiting friends and relatives", and 75 (5.9%) were travellers. Additional information was under analysis at the time of abstract submission. Conclusions Strongyloidiasis was diagnosed in 10% of the patients from REDIVI during the study period, and most frequent profile was young patients, immigrants coming from Latin America, and without immunosuppression. Polymerase chain reaction for the diagnosis of Clostridium difficile infection in patients with persistent digestive disorders and asymptomatic controls in Côte d'Ivoire Introduction Clostridium difficile is an enteric bacterial pathogen that may cause a wide range of diarrhoeal diseases. Although C. difficile is the main causative agent of antibioticassociated diarrhoea, little is known about the epidemiology, clinical symptomatology, disease burden and transmission patterns of C. difficile in sub-Saharan Africa. Aim To assess the occurrence of C. difficile in patients with persistent digestive disorders in Côte d'Ivoire and age-and sexmatched asymptomatic controls. The study was carried out by the NIDIAG research consortium (www.nidiag.org). Between July 2014 and December 2015, stool samples from patients with persistent diarrhoea (≥2 weeks) and/or persistent abdominal pain (≥2 weeks) and matched asymptomatic controls were collected in Dabou, south Côte d'Ivoire. Stool samples were fixed in ethanol and stored in a freezer at -20°C. At the end of the sampling period, specimens were transferred to Homburg, Germany, where multiplex realtime polymerase chain reaction (PCR) was carried out for detection of non-pathogenic and toxin-producing, pathogenic strains of C. difficile (RIDAGENE C. difficile, R-Biopharm; Darmstadt, Germany). The final study cohort comprised 259 patients and 259 asymptomatic controls. C. difficile was detected in 13 stool samples, resulting in an overall prevalence of 2.5%. The detection rate of C. difficile was slightly higher in cases than controls (2.7% versus 1.9%) but differences were not statistically significant. Two C. difficile strains in symptomatic patients were toxigenic, whereas only non-toxigenic isolates were found among the controls. There was a trend toward lower C t values in symptomatic patients (median C t 32 versus 36 in controls). Conclusion Toxigenic and non-toxigenic C. difficile strains were found in a small number of stool samples obtained from patients with persistent digestive disorders and asymptomatic controls in Côte d'Ivoire. Further studies are warranted to investigate the occurrence of C. difficile infection in high-risk groups in sub-Saharan Africa, such as patients with nosocomial diarrhoea. Results Overall, 2,007 stool samples were collected from 1,108 participants (representing 88.6% of the population n = 1,250); median age (interquartile range) was 15 (7-35) years. Half of participants (n = 567; 51.2%) were Schistosoma mansoni positive. Schistosoma egg load was light, moderate and heavy in respectively 51%, 31% and 18% of Schistosoma-infected participants. A total of 40 (3.6%) participants were found carriers of Salmonella, of which 8 were identified as Salmonella Typhimurium, 7 Salmonella Enteritidis, 20 Salmonella sp. and 3 identified as Salmonella group C1; Group B and C2 Salmonella were isolated from one participant respectively. Antibiotic susceptibility testing showed 1 Salmonella isolate. with decreased ciprofloxacin susceptibility. Mean age AE standard deviation of Salmonella carriers was 25 AE 19 years and did not differ from the non-Salmonella infected participants 22 AE 19 years (P = 0.032); male-to-female rates were 1:1.5 and 1:1.1 respectively (P = 0.37). The proportion of Salmonella carriage among Schistosoma infected participants was higher (4.4%, 25/567) than among Schistosoma-noninfected participants (2.8% (15/541) but the difference was not statistically significant (P = 0.14). Egg loads among Salmonella-Schistosoma co-infected participants (n = 67) were mostly light (48%) and heavy (36%).Follow-up of 17 Salmonella carriers revealed a single participant with repeat culture for Salmonella, at week 4 after the initial sampling. Introduction Use of antibiotics prior to sampling affects yield of bacteriological culture results, but little is known about this practice in low resource settings. Aim To assess, among patients with persistent (≥7 days) fever presenting to healthcare facility in eastern Nepal (i) proportion of patients who were on antibiotics, (ii) class of antibiotics, (iii) route of administration, (iv) result of blood culture. Methods Patients ≥5 years presenting with persistent fever between January 2013 and October 2014 in two hospitals in eastern Nepal were included (part of NIDIAG project). Blood cultures were drawn (2 9 10 ml of blood in adults, and 4 ml in children <14 years, BacTec (Becton Dickinson, NJ, USA). Information about use of antibiotics was recorded. Antibiotics were grouped according to Clinical Laboratory Standards Institute (PA, USA) document M100-S27. Blood cultures were monitored for growth during seven days, identification and antibiotic susceptibility testing was performed according to standard methods (CLSI M100-S26). Of the 578 patients enrolled, 211 (36.5%) were on antibiotics at presentation, among them 86 (14.9% of all patients) were on ≥2 antibiotics. The 338 antibiotics used comprised (expressed per 211 patients) cephems (n = 136, 64.4%, particularly third generation cephalosporins (n = 96, 45.5%) and oral cephalosporins (n = 51 24.1%), macrolides (mostly azithromycin (n = 64, 30.3%), and fluoroquinolones (n = 42, 19.9%). The most common combination was cephems with macrolides (n = 41, 19.4%). Median duration (interquartile range) of administration of antibiotics was 5 (3-7) days. A total of 104 patients (49.2%) were on parenteral antibiotics. For 17/ 578 (2.9%) patients, blood cultures yielded growth of pathogens, comprising Staphylococcus aureus (n = 9, 52.9%) Salmonella Typhi (n = 5, 29.4%), Escherichia coli (n = 2, 11.7%) and Salmonella Paratyphi (n = 1, 5.8%) (expressed among the 17 positive blood cultures). Blood culture growth was observed in 4/211 (1.8%) patients who were on antibiotics versus 13/367 (3.5%) patients who were not on antibiotics (contaminants were subtracted, Χ 2 =1.27, P = 0.25). Conclusion More than a third of patients with persistent fever were on broad-spectrum antibiotics prior to blood culture sampling. In areas with no access to diagnostic microbiology, there is need for simpler, more robust and affordable diagnostic tests such as antigen-targeting or biomarker-detecting tests. Arthropod-borne pathogens as cause of non-malarial fever in rural Ethiopia Introduction The etiological diagnosis of a febrile patient in rural tropical areas, when malaria has been excluded and other microbiological facilities are limited, is very challenging and remains elusive. Bacterial arthropod-borne pathogens are a common cause of fever in Africa but its real impact is not well known. Aim To determine the role of arthropod-borne pathogens as a cause of fever among malaria smear-negative patients in rural Ethiopia. The study was performed at the Gambo Rural General Hospital located in a rural area at 2400 meters high in southeastern Ethiopia. During July-November 2013 a total of 246 blood samples from patients with malaria smear-negative thin films, 29 lice obtained from these patients and 90 fleas obtained from random houses of the area were included in this study. DNA extracted from whole blood of patients and arthropods was tested by two qPCR systems and species were identified by sequence analysis. The mean age of the 246 febrile patients was 21 years (range: 2 months-70 years) and 43% were males. A total of 11 samples (4.5%, 95% confidence intervals [IC]: 2.8-8.3) were positive for arthropod-borne pathogens. Rickettsia felis, Borrellia spp and R. belli were detected in 3 cases each (1.2%; 95% IC: 0.4-3.5%), Bartonella rochalimae and Francisella tularensis in one case each (0.4%; IC 95%: 0.07-0.22%). DNA from Rickettsia spp was found in 43 fleas (48%): R. felis (44%), R. monacensis (5%) and R. spp. (51%). From 29 lice collected, we found Bartonella quintana (13%), Ehrlichia muris (7%) and Borrelia recurrentis (3%). Conclusion In this rural area of Ethiopia fleas are frequently parasitized by Rickettsia spp and lice are parasitized by Bartonella, Ehrlichia and Borrelia. However, only 4.5% of febrile patients without malaria were diagnosed with these diseases. Introduction Non-traumatic paraplegia is neglected tropical syndrome. It is not uncommon in Malawi; however there are only scanty reports on its pathogenesis. Aim To study the most common causes of paraplegia and make recommendations for treatment. We studied 50 sequential patients with paraplegia of < 6 months duration. A full neurological assessment was made using the American Spinal Injury Association (ASIA) scale. An MRI scan and a lumbar puncture was done as clinically indicated. Serum samples and CSF were screened for viral infections, schistosomiasis, tuberculosis and syphilis. Results Tuberculosis was the most common diagnosis (36%), followed by malignancy (20%) and transverse myelitis (10%); 3 cases were diagnosed as presumed neuroschistosomiasis. The diagnosis of tuberculosis was based on clinical and radiological evidence; in none of the CSF samples M. tuberculosis could be demonstrated by PCR. Four patients had evidence of neurosyphilis. A novel cyclovirus was found 10% of 40 CSF samples examined; other viruses found in the CSF included HIV, EBV, HSV and hepatitis B virus. Conclusions Tuberculosis was the most common cause of non-traumatic paraplegia; the contribution of schistosomiasis was lower than expected. The role of cyclovirus needs to be confirmed. The current policy of empirical treatment for schistosomiasis seems still justified; evidence for tuberculosis should be sought in all patients. Point-of-care chest ultrasound in South African children with suspected pulmonary tuberculosis Introduction Chest ultrasound has increasingly been used for the diagnosis of paediatric lung diseases. Aim To describe the findings of a clinician-performed point-ofcare chest ultrasound in children with suspected pulmonary tuberculosis (PTB). Methods Children under the age of 13 years, presenting between July 2014 and September 2015, at a tertiary children's hospital in Cape Town with suspected PTB were enrolled. A clinician, who had 4-days of ultrasound training, performed chest ultrasound on a low-cost, grey-scale ultrasound machine, a linear transducer (5-10 MHz) was used to scan the chest in 8 planes, namely the left and right, upper and lower anterior, lateral and posterior chest and both apices for consolidation, pleural effusion or an interstitial pattern. In addition, the mediastinum was scanned through the suprasternal notch to detect lymphadenopathy (>1 cm). We compared the findings in 3 groups: confirmed PTB (microbiologically confirmed), unconfirmed PTB (clinical diagnosis) and unlikely tuberculosis (TB)/other respiratory diseases (no microbiological nor clinical diagnosis). We consecutively enrolled 169 children; 40 (24%) confirmed PTB, 88 (52%) unconfirmed PTB, 41 (24%) unlikely TB/other respiratory diseases. In children with PTB (confirmed and unconfirmed) positive findings on chest ultrasound were seen more often than in children unlikely to have TB but this was not statistically significant (83% versus 73%, respectively; P = 0.18). Consolidation was the most common finding (confirmed 65%; unconfirmed 61% and unlikely 56%; P = 0.71). Pleural effusions were the only statistically significant finding; it was more common in children with confirmed PTB (28% versus 11% unconfirmed and 7% unlikely; P = 0.02). Interstitial pattern was equally common in all three groups (confirmed 35%; unconfirmed 33% and unlikely 34%; P = 0.97). Mediastinal lymphadenopathy was not more commonly seen in confirmed PTB compared to unlikely TB/other respiratory diseases (respectively 23% and 29%; P = 0.56). Conclusion This study showed that mediastinal lymphadenopathy, the key radiological finding for PTB, is not diagnostic for PTB on ultrasound as it is also common in children with other respiratory diseases. In contrast, pleural effusions were more commonly seen in children with confirmed PTB. Results Among 378 patients enrolled in this study, 48.9% were male and 52.9% were older than 45 years; 55.3% were enrolled during the rainy season. 75% of patients had history of river/lake exposure, and 84.7% had taken antibiotics in the previous 2 weeks. 68.8% presented with fever for more than 2 weeks, and the main other symptoms were cough (73%) and abdominal pain (50%). Diabetes mellitus, HIV and liver cirrhosis were common underlying diseases with a prevalence of around 10% each. Tuberculosis (19.8%), melioidosis (4.2%), leptospirosis (4%), rickettsiosis (2%) and enteric fever (1.6%) were the most commonly diagnosed NIDs, while scrub typhus (n = 2) and relapsing fever (n = 1) were rare. Other common infections were pneumonia (27%), urinary tract infections (9.5%) and liver abscess (5.6%). The diagnosis remained undefined in 14% of patients, of them 77% being empirically treated for enteric fever. The mortality rate at week-4 follow-up was 12.2%. We found a significant prevalence of NIDs in patients presenting with persistent fever in a tertiary urban hospital in Cambodia. Raising awareness on conditions like melioidosis, leptospirosis and rickettsiosis among healthcare professional in Cambodia through continuous medical education and the development of evidence-based national clinical practice guidelines are necessary. Epidemiology of onchocerciasis and epilepsy in Ituri Province in the Democratic Republic of the Congo (DRC) Introduction Many studies have suggested an association between epilepsy and onchocerciasis. Aim To determine the prevalence of epilepsy and to investigate whether an association exists between epilepsy and onchocerciasis in a rural population in Ituri Province, DRC. Methods In August 2016, a population-based cross-sectional study was conducted in the rural health zone of Logo, Ituri Province, an onchocerciasis endemic area without a history of ivermectin mass distribution campaigns. To identify cases of epilepsy, a three-stage approach was used. All individuals of 258 randomly selected households were screened for epilepsy by nonmedical field workers using a validated 5-item survey. In a second and third stage, suspected cases of epilepsy were examined by non-specialist medical doctors and by a neurologist, respectively. A case of epilepsy was defined according to the International League Against Epilepsy guidelines. Exposure to onchocerciasis was assessed by detecting IgG4 antibodies to O. volvulus antigen (OV16 rapid test, SD Bioline, Inc) in individuals aged 3 years and older. Results Out of 1,426 censused household members, 82 (5.8%) were suspected of having epilepsy at 1st stage. 4 (7.2%) of 55 suspected cases examined at the 2nd stage were not confirmed. 40 (91%) of 44 suspected cases examined at the 3th stage were confirmed having epilepsy. Because of missing data we cannot determine the exact prevalence of epilepsy but the prevalence must be at least 2.8% (40/1,426) (5 times higher than in most non-onchocerciasis endemic regions in Africa). Of 915 individuals, for whom data was available on both OV16 testing and epilepsy, 40 (4.4%) were found to be confirmed cases of epilepsy. Median age of epilepsy onset was 12 years. Among confirmed epilepsy cases, OV16 positive test results were clustered by age-groups and locality, but not by gender. Age-adjusted OV16 positivity among persons with epilepsy was 1.6 times higher (P = 0.022) than among persons without epilepsy, respectively 47.5% (19/40) and 29.8% (261/875). Conclusion A high prevalence of epilepsy and a significant association between epilepsy and exposure to onchocerciasis was observed among the population of the Logo health zone in Ituri. Intestinal helminthiasis as a determinant of response to pentavalent antimony treatment in Peruvian patients with cutaneous leishmaniasis: a case-control study Introduction The outcome of treatment for cutaneous leishmaniasis (CL) depends essentially on the interaction between the drug, Leishmania parasite and human host. Coinfection with intestinal helminths may modulate immune responses and therefore also the outcome of CL treatment. Aim To assess the association between intestinal helminthiasis and CL treatment failure. We conducted an unmatched case-control study recruiting participants in four health facilities in the regions of Lima, Cusco and San Martin, Peru. Inclusion criteria were: (1) parasitologically confirmed CL, (2) having received standard treatment with pentavalent antimony drugs, and (3) well-defined outcome (failure or cure) within three months post-treatment. Cases were patients with treatment failure and controls were patients who were cured at three months post-treatment. The main exposure factors of interest were intestinal helminthiasis (any species) and strongyloidiasis. Up to three serial stool samples were examined at time of enrollment (i.e. after CL treatment) using direct examination, rapid sedimentation, Baermann test, Kato-Katz and culture in agar. We also collected information about demographics, CL lesion duration and characteristics, and other conditions modulating immune response, and treated these variables as potential confounders. Leishmania species identification and parasite load measurements are ongoing. Results Between December 2012 and November 2015, 221 patients were included: median age was 31 years (interquartile range 18-50); 70% (154/221) were men. There were 99 cases and 122 controls. Frequency of intestinal helminthiasis (any species) was 18% (18/99) in cases and 28% (34/122) in controls (P = 0.09). Frequency of strongyloidiasis was 6% (6/99) in cases and 17% (21/122) in controls (P = 0.01). There were no significant differences between cases and controls in site of recruitment, place of infection (Andean highlands versus Amazon basin), previous history of leishmaniasis, and sex (P > 0.05). The association with strongyloidiasis remained significant after adjustment for age, CL lesion type and reason/ duration of stay in CL-endemic region (adjusted odds ratio 0.24, 95% confidence interval 0.08-0.70). Adjustment for Leishmania species and parasite load is pending. Intestinal helminthiasis was not associated with CL treatment failure in this study. On the contrary, strongyloidiasis was less frequent in patients with CL treatment failure than in patients who were cured. Spain hosts the highest number (more than 50,000) of migrants infected with Trypanosoma cruzi in Europe, the parasite that causes this life-threatening disease. Another NTD, Strongyloides stercoralis (SS), is a soil-transmitted helminth that causes a chronic and life-threatening infection, especially in those immunosuppressed. In Europe, both parasites remain underdiagnosed. Aim 1. Assessing CD and SS prevalence among Latin-American migrants (LAM), describing their epidemiological profile; 2. Promoting early detection of asymptomatic patients in order to treat them and avoid Chagas disease vertical transmission. Methods We aggregated data from two screening and education campaigns aimed at LAM, conducted on Sundays in a hospital setting (Alicante) and outside of healthcare settings (Madrid) by multidisciplinary teams including health professionals, community health workers and patients in 2016. Community health workers specifically trained for that purpose built up an intense previous diffusion of information through media, cultural and sport events, among others. CD was confirmed by IFAT, conventional and recombinant ELISAs. SS was determined by Strongyloides IgG IVD-ELISA kit. Afterwards, patients were cited in the hospital for follow-up, SS infection confirmation, and treatment when indicated. Results 796 participants were informed and screened (129 in Alicante; 667 in Madrid), women 64.6% (over 70% were woman of childbearing age (15-45 years)), more than 70% from Bolivia. CD prevalence 16.6% (132/796), SS prevalence 10.3% (82/796). Fifteen had co-infection (10.3%). Most of the participants (more than 88%) had never been screened before. During educational activities, participants showed lack of knowledge about CD, mainly regarding ways of transmission. Moreover, they stated not having heard about SS. Conclusion These campaigns highlight that CD and SS are hidden among LAM. They detected an important number of asymptomatic patients and enhanced awareness among high-risk populations. Moreover, they can be replicated in different settings and regions. The community approach plays an essential role in tackling NTDs in Europe, particularly in improving access to care for patients. Accuracy of antigen detection in urine using Katex for noninvasive visceral leishmaniasis diagnosis and treatment monitoring in HIV-coinfected patients Introduction Visceral Leishmaniasis (VL) in immunosuppressed patients is routinely diagnosed by spleen aspirate. This procedure is painful and prone to complications. Parasite antigen detection in urine is a promising non-invasive alternative. It has never been validated in HIV patients. Results Median age was 32 years (inter-quartile range [IQR] 28-37), median CD4 count was 54.5 cells/lL (IQR 37-96), and 61% were on antiretroviral therapy. 25% of patients had treatment failures at day 28. Katex sensitivity and specificity for VL diagnosis was 83% (95% confidence interval [CI] 71-91) and 98% (95% CI 91-100) overall. Sensitivity was 81% (95% CI 61-93) and 84% (95% CI 67-95) in patients with and without previous VL episode; 100% (95% CI 85-100) and 72% (95% CI 55-86) in patients with aspirate parasite grade 6 and below 6; and 91% (95% CI 76-98) and 79% (95% CI 61-91) in patients with CD4 count below and above 50 cells/lL. Katex was positive at VL diagnosis in 93% of patients with treatment failure and in 74% among those with treatment success; and in 93% and 63% at day 7, in 85% and 41% at day 14, in 85% and 36% at day 21, and in 75% and 45% at day 28, respectively. For treatment failure, Katex sensitivity, specificity, positive predictive value, and negative predictive value was 75% (95% CI 43-95), 55% (95% CI 36-72), 38% (95% CI 19-59), and 86% (95% CI 64-97), respectively. Methods We aimed to enrol 300 CL suspects attending the National Malaria & Leishmaniasis Control Program's (NMLCP) clinic in Kabul. Slit skin samples from CL lesions were subjected to Giemsa's smear microscopy, and samples taken with a dental broach were tested with CL-Detect (raw sample) and LAMP (after DNA extraction). DNA samples and slides were further transferred to the Academic Medical Center (AMC), Amsterdam for qPCR analyses, Leishmania species identification, and quality control of LAMP and microscopy. For diagnostic performance analysis we used a combination of microscopy and PCR results as reference. Results 274 CL suspects were enrolled between April and June, 2016. The female: male ratio was 1.09, and mean age 24.8 years (5-73 years). Most of the lesions were nodular and of more than 2 months of evolution. Two hundred and four patients tested positive by microscopy and 252 by PCR. L. tropica was identified as the causative agent of CL in all the study samples. CL-Detect returned a sensitivity of 65.4% and specificity of 100%, while LAMP performed differently at the NMLCP (89.1% sensitivity and 70.6% specificity) than at AMC (92.2% sensitivity and 94.1% specificity). Conclusion Though the sensitivity of CL-Detect is lower than microscopy (79.4%), its high specificity enables this test to be used at the peripheral level and as part of active case finding. LAMP showed a very good diagnostic performance at AMC; though the performance at NMLCP was lower, further training could improve the performance of LAMP in Afghanistan. Post-Kala-Azar dermal leishmaniasis (PKDL) treated with ambulatory short course AmBisome  is a skin disease caused by Leishmania donovani, usually appearing 6 months to several years after apparently successful treatment of visceral leishmaniasis. In the Indian subcontinent, PKDL occurs in 5-10% of VL patients. It rarely poses other than cosmetic problems; however, untreated it constitutes a reservoir of infection. A safe and effective short course treatment for PKDL is a prerequisite for the elimination of VL. MSFsupported facilities have used short liposomal amphotericin B (AmBisome â ) regimens for clinically diagnosed PKDL in India and Bangladesh between 2010 and 2015. Aim To identify a safe and effective short course treatment for PKDL. Methods A 30 mg/kg AmBisome regimen was given on ambulatory basis over 3 weeks in 6 divided doses of 5 mg/kg. Medical photographs were taken of each patient at baseline and at 1, 3, 6 and 12 months after treatment. Main outcomes were the clinical assessment of lesions at 12 months compared to baseline and safety during treatment, with an emphasis on hypokalaemia. Following safety concerns in Bangladesh, a further clinical study was initiated to assess the effectiveness and safety of a lower 15 mg/kg total dose, administered in 5 doses of 3 mg/kg over 3 weeks. Results A total of 271 patients, 110 in Bangladesh and 161 in India, were treated with the 30 mg/kg regimen. In India, of 89 patients, 75 (84.3%) cases showed substantial or complete cure at 12 months, with excellent tolerance and safety. In Bangladesh, of 88 patients, and 70 (79.5%) showed substantial or complete cure at 12 months; however 6.5% developed severe hypokalaemia. Of 272 patients that were treated with the 15 mg/kg regimen in Bangladesh, 245 (90.1%) showed a significant improvement of lesions at 12 months, with the majority of lesions completely resolved in 213 (78.3%) patients. In 27 (9.9%) patients lesions did not improve and new lesions appeared in 13 (4.8%) patients. No severe adverse effects occurred. Moderate (2.5-3.0 mmol/L) hypokalaemia was found in 7 (2.5%) of patients. Conclusion Short-course ambulatory AmBisome regimens may be considered as an effective and safe option for treatment of PKDL patients in the Indian subcontinent.  South Sudan: a clinical severity scoring system for visceral leishmaniasis in HIV negative patients Introduction South Sudan is one of the most endemic countries for visceral leishmaniasis(VL), and is frequently affected by large epidemics. In resource-limited settings, clinicians require a simple clinical tool to identify VL patients who are at increased risk of dying, and who need specialised treatment with liposomal amphotericin B and other supportive care. The aim of this study was to develop and validate a clinical severity scoring system based on risk factors for death in HIV negative VL patients in South Sudan. Methods A retrospective analysis was conducted of data from a cohort of 6,633 VL patients who were treated in the M edecins Sans Fronti eres (MSF) hospital in Lankien between July 2013 and June 2015. Risk factors for death during treatment were identified using multivariable logistic regression models, and the regression coefficients were used to develop a severity scoring system. Sensitivity and specificity of score cut-offs were assessed by receiver operating characteristic (ROC) analysis. Results In multivariable models, risk factors for death in adult VL patients were: anaemia (odds ratio (OR) 4.46 (95% CI 1.58-12.6) for Hb <6 g/dL compared with ≥9 g/dL), nutritional status (OR 4.84 (2.09-11.2) for BMI <13 kg/m² compared with ≥16 kg/m²), weakness (OR 4.20 (1.82-9.73) for collapsed compared with normal weakness), jaundice (OR 3.41 (1.17-9.95)), and oedema/ascites (OR 4.86 (1.67-14.1)). For children and adolescents the risk factors were: age (OR 10.7 (6.3-18.3) for age <2 years compared with 6-18 years), anaemia (OR 7.76 (4.15-14.5) for Hb <6 g/dL compared with ≥9 g/dL), weakness (OR 3.13 (22.8-105.2) for collapsed compared with normal weakness), and jaundice (OR 12.8 (4.06-40.2)). Severity scoring predictive ability was 74.4% in adults and 83.4% in children and adolescents. Conclusion Our evidenced-based severity scoring system demonstrated sufficient predictive ability to be operationalised as a clinical tool for rational allocation of treatment to VL patients at MSF centres in South Sudan. Introduction In endemic regions, asymptomatic Leishmania infection is common. HIV patients are at increased risk of progression to symptomatic disease (visceral leishmaniasis (VL)), with high mortality. Thus, certain HIV patients might benefit from VL prophylactic treatment strategies by preventing VL disease progression. Aim To determine the prevalence, markers and determinants of asymptomatic infection in VL exposed HIV patients. Methods We conducted a cross-sectional analysis, consecutively enrolling HIV-infected adults followed at the HIV clinic of a district hospital in a VL-endemic area in North-west Ethiopia (9/2015-8/2016), excluding those with VL at/within five years before enrolment. Asymptomatic Leishmania infection was defined as positivity for any Leishmania markers tested: Direct Agglutination Test (DAT), rK39-Rapid diagnostic test (RDT), and urine antigen (KAtex) test. Risk factors for asymptomatic Leishmania infection were determined using logistic regression, including socio-demographic information on socio-demographics, Leishmania exposure, and clinical information. Results A total of 504 patients were included. The median age was 38 years (interquartile range (IQR) 30-44) years, 61% were male. Most were farmers (37%) or daily labourers (23%); 55.0% (271/496) slept outside regularly, 3.2% (16/502) had a VL case in the household ever, 5.4% (27/499) had a VL case in the neighbourhood. The median time of residence in a VLendemic area was 17 years (IQR 10-25). A history of VL was present in 2.6% (13/503). At enrolment, most (96%) were on antiretroviral treatment (ART) -for a median of 4 years (IQR 2-6); the median CD4 count was 380 cells/lL (IQR 254-521). The prevalence of asymptomatic Leishmania infection was 9.5% overall, 8.3% for rK39, 2.2% for DAT, and 0.8% for KAtex. The highest prevalence (15%) was seen in males aged 28-48 years. Independent risk factors were being male (odds ratio (OR) 4.0; 95% confidence intervals (CI) 1.7-9.3), not being on ART (OR 3.5; 95% CI 1.1-11.6) and a history of VL (OR 8.7; 95% CI 2.6-28.9). Conclusions Prevalence of asymptomatic Leishmania infection was high, justifying further longitudinal studies determining which patients are at highest risk of VL progression. Ultimately, this could result in a VL screen and treat strategy, with those at highest risk receiving VL prophylaxis. Visceral leishmaniasis and HIV co-infection in northwest Ethiopia: uptake of antiretroviral treatment and burden of disease amongst patients enrolled in HIV care ignored. While all VL cases should start antiretroviral treatment (ART), studies on ART uptake are missing. A complementary strategy to decrease VL-HIV burden/mortality entails preventing VL in HIV patients living in VL-endemic regions. However, we lack data on how common VL is observed in individuals enrolled in HIV care. Aim (1) Results We included 112 patients at the referral hospital and 58 at the district hospital. The median age was 30 years, 98% were male. The proportion of VL-HIV coinfected patients with VL diagnosed while in HIV care was 56% (63/112) and 19% (11/58) at the referral/district hospital respectively; with a median CD4 count at VL diagnosis of 45 cells/lL and 248 cells/ lL at the referral/ district hospital respectively. 76% (56/44) were on ART at VL diagnosis. Ten (13%) patients died during admission. Uptake of ART and CPT was high. The remaining 96 (56%) patients had both infections diagnosed concurrently, with a median CD4 count at VL diagnosis of 56 cells/lL and 143 cells/lL at the referral/district hospital respectively. Nineteen (20%) patients died during admission. Amongst cured patients, CPT uptake was 89% and 72% at the at the referral/district hospital, respectively; documented ART uptake was 67% and 36% at the referral/district hospital respectively. For the entire group (n = 96), ART uptake was 61% and 28% at the referral/district hospital respectively. At the district hospital, documented uptake was especially low in referrals. Conclusions A substantial proportion of VL-HIV cases occur amongst patients in HIV care, requiring further evaluation of preventive strategies. Amongst newly diagnosed VL-HIV coinfected patients, documented ART initiation was low, especially at district level. The reasons, including poor data collection/referral systems, should be assessed. Introduction Soil-transmitted helminths (STHs; Ascaris, Trichuris, hookworm) are responsible for the highest burden among all neglected tropical diseases. Mass drug administration (MDA) programs, in which a single-oral dose of albendazole or mebendazole are periodically administered to (pre)school-aged children are the main strategy to control for STHs. This drug pressure makes MDA programs highly vulnerable to the development of anthelminthic resistance (AR), as has been described in veterinary medicine. This necessitates thoroughly designed surveillance systems that allow detection of any changes in anthelmintic drug efficacy that may arise through the evolution of AR. We aimed to assess the performance of new diagnostic tools to monitor the efficacy of anthelminthic drugs. Methodology In Tanzania, Ethiopia and Laos, stool specimens from school-aged children (5-14 years) were collected during a baseline visit, where children received a single dose of albendazole. Stool specimens were analyzed for the presence of Ascaris lumbricoides, Trichuris trichiura and hookworm using different microscopic techniques (single Kato-Katz, duplicate Kato-Katz, Mini-FLOTAC and FECPAK G2 ). A follow-up stool sample was collected within two to three weeks for each child positive at baseline for at least one STH with at least one technique. A predefined number of 110 completed cases of Ascaris and Trichuris, and of 100 cases of hookworm, were included, for each site. DNA extraction of ethanol-preserved stool and qPCR assays for A. lumbricoides, T. trichiura, Necator americanus and Ancylostoma duodenale were performed. Eggreduction rates (ERR) were calculated for the different STHs using the different techniques. The time needed to process and analyze the samples using each microscopic technique was recorded. Results ERR for Ascaris and hookworm were comparable for each microscopic technique but differed markedly for Trichuris. Single Kato-Katz was the fastest technique in all settings. Overall, FECPAK G2 had the lowest sensitivity of the microscopic techniques. qPCR assays and analysis are currently performed and will also be presented. The choice of diagnostic techniques to monitor drug efficacy will depend on both the species present in endemic regions and the intensity of infection. Egg excretion indicators for the measurement of soiltransmitted helminth response to treatment Introduction Soil-transmitted helminths (STHs: Ascaris lumbricoides (Al) Trichuris trichiura (Tt) and hookworm (Hw)), affect more than a billion people, especially school-aged children in low-and middle-income countries, who are targeted for preventive chemotherapy with albendazole and mebendazole. However, treatment efficacy varies with the STH species, location and time, and questions remain as to how best express treatment outcomes. Aim To investigate egg excretion indicators that are best adapted to measure treatment outcomes for STH and detect treatment failures and resistance development. 12 treatment clinical trials, classed as albendazole and mebendazole (alone and combinations), and other treatments, including placebo. Only subjects infected with one or several species of STHs and with pre-and post-treatment data, and diagnosed using the Kato-Katz method, were included in the analysis. Baseline infection intensities were expressed as eggs per gram of faeces (EPG); treatment outcomes were expressed as egg reduction rates using arithmetic means (ERRam) and as distribution of individual-participant ERR. Results A total of 4981 patients were diagnosed with 9525 infections overall with one (35%) or several STH species (65%): Al 21%, Tt 45% and Hw 34%. Baseline infection intensity was significantly higher for each STH species in co-infections than mono-infections. The ERRam met the WHO minimal efficacy criteria of ≥95% for Al, ≥50% for Tt and ≥90% or ≥70% for Hw in just 55% of studies of albendazole and mebendazole alone or in combination, independent of whether mono-or multiple-infections. Considering individual responses, placebo achieved 100% ERR (hence cure) in 19% of Al and 11% of Tt and Hw infections. Albendazole alone gave ERR=0 in 1%, 27% and 8% of Al, Tt and Hw infections, and ERR=100% in 79%, 52% and 45%, respectively. The equivalent figures for mebendazole are 2%, 22% and 26%; and 93%, 25% and 21%. All treatments were compared through network meta-analysis. Conclusion Co-infections were frequent and had higher infection intensities, but did not influence treatment performance. Just over half of treatments meet the WHO minimal efficacy criteria. Individual ERR response distributions allow identifying the proportions of suboptimal responders and comparing treatment performances. Landscape of studies generating individual participant data on the efficacy of drugs for treating soil-transmitted helminthiasis and the case for data sharing Introduction Preventive chemotherapy by mass drug administration is the cornerstone of the World Health Organization (WHO)'s policy to control soil-transmitted helminthiasis (STH) caused by Ascaris lumbricoides (roundworm), Trichuris trichiura (whipworm) and hookworm species. These neglected tropical diseases (NTDs) affect over 1 billion people globally and, in 2015 alone, over 560 million children were treated with benzimidazoles, a number which is likely to rise year-on-year towards the WHO's 2020 targets. Despite consensus that drug efficacies should be monitored for signs of decline that could jeopardise the long-term effectiveness of preventive chemotherapy, it is difficult to derive clear information from currently available data. Drug trials primarily estimate efficacies as averages in groups of participants, but heterogeneities in trial design and reporting complicate classical meta-analyses based on aggregate data. Analysis of individual participant data (IPD) circumvent many of the problems associated with trial heterogeneity and permit more detailed powerful analysis of individual drug responses, offering a more sensitive means to identify atypical responses potentially caused by emerging drug resistance. Aim To quantify the volume and characteristics of IPD generated from studies which may be used to estimate the efficacy of the drugs used to treat STH. Methods We performed a systematic review and identified studies which generated relevant IPD since 2000. We standardised the extraction of variables describing locations, sample sizes, trial designs, participant characteristics and other aspects of these studies to create an overview of the trial landscape. We estimate that there exist data on approximately 35 000 participants from 129 trials conducted in 39 countries, including 34 out of 103 countries where preventive chemotherapy is recommended. We present data on trialled drug regimens, reporting methods and key participant demographic information, such as cohorts including pre-school age children and pregnant women. We argue that establishing a global IPD repository would greatly improve the capacity of the global health community to monitor and evaluate the efficacy of anthelmintic drugs, respond to changes and safeguard the ongoing effectiveness of preventive chemotherapy. Establishing a fair and transparent data governance policy will be key for the engagement of the STH community in this global effort. Evolution of anthelminthic resistance in the era of preventive chemotherapy Introduction Current control strategies for onchocerciasis, lymphatic filariasis, schistosomiasis and soil-transmitted helminths (STH) rely heavily on mass administration of a limited number of drugs. Although not (yet) widely observed, the development of anthelminthic resistance presents a severe threat to the effectiveness of control programs. Mathematical models allow us to synthesise current knowledge and understand the dynamics of the evolution of drug resistance under current and potential alternative intervention strategies, including those related to programmatic shifts from control to elimination. Aim Characterise and compare the evolution dynamics of potential polygenic drug resistance in the four major anthroponotic helminth species under various transmission and intervention scenarios. Methods We performed forward-simulation using a stochastic, individual-based model for transmission and control of helminth infections in humans, and use the quantitative trait model to simulate inheritance of polygenic drug resistance. The risk of polygenic drug resistance is generally highest in highly endemic settings, in highly aggregated parasite populations, and during deworming programmes implemented at high coverage and/or frequency. The risk of drug resistance emerging before interruption of transmission is relatively low for filarial infections, assuming that only embryostatic drug effects and not microfilaricidal drug effects are affected (as observed so far). For STH, the risk of resistance differs between species but is generally higher than for filariases, as the main effect of benzimidazoles on transmission is through killing of adult parasites. For schistosomiasis, the risk of drug resistance balances between the protective effect monogamous parasite mating and the negative effect of amplification in the intermediate snail host. Conclusion Although the recent shift from control to elimination of both onchocerciasis and lymphatic filariasis puts more selective pressure on filarial populations, the chance of significant drug resistance emerging before interruption of transmission is limited, as long as microfilaricidal effects are conserved. However, a potential future shift from control to elimination of STH and schistosomiasis will probably carry a significant risk of drug resistance emerging. This risk emphasises the need further quantification of the genetics underlying drug resistance in helminths, and the urgency of improved access to and uptake of water, sanitation, and hygiene. Hot topics in the diagnosis and management of strongyloidiasis In the last decade, the use of molecular biology for the diagnosis of Strongyloides stercoralis infection has been expanding, but there is still no global agreement on the role of this technique. Recently, a systematic review focused on this issue, with the aim of evaluating the accuracy of PCR. Thirteen studies were included in the review, in most cases evaluating real-time PCR. A meta-analysis is ongoing. Conventional PCR has also been tested on urine, and an ongoing study is comparing the performance of conventional versus real-time PCR on urines, and of real-time PCR on urines versus real-time PCR on feces. Ivermectin is the drug of choice for the treatment of strongyloidiasis. Both a single dose and a two-day course of treatment have been suggested, but no definitive evidence supports any of the two schedules. Strong Streat 1 to 4 study is a multicenter randomized clinical trial (involving sites in Italy, Spain and in the UK) which aims at demonstrating whether multiple doses of ivermectin have a better efficacy than a single dose for the treatment of chronic strongyloidiasis. Patients are randomized in two arms: single dose and four doses of ivermectin. An interim analysis of the first 206 patients enrolled is ongoing. Another drug, moxidectin, is under evaluation as an alternative to ivermectin. Innovative methods of case finding to achieve elimination of human African trypanosomiasis in the Democratic Republic of Congo Introduction Over the past decade there has been a substantial decrease in numbers of cases of Human African Trypanosomiasis (HAT) reported. The WHO goal to eliminate Human African Trypanosomiasis (HAT) as a public health problem by 2020 appears well within reach. Early case detection and treatment of patients is the main strategy, therefore increasing screening coverage of the population at risk is a key factor in accelerating elimination. In the project called "TRYPELIM" we want to increase coverage through a combination of innovative screening approaches in two pilot health districts in the Democratic Republic of the Congo. Objective Evaluate the feasibility of systematically and rationally increasing coverage of HAT screening with innovative approaches. Methods In this three-year project (2016-2018) we organize door-to-door screening with traditional mobile screening teams as well as motorcycle based mini teams. At the same time we introduce electronic data capturing through Android tablets. Instead of visiting only known endemic villages, the mini teams also visit surrounding villages within a radius of five kilometer. For this purpose we developed a GIS based planning tool. In addition, screening tests are made available in fixed health facilities with a referral mechanism for diagnostic confirmation. Results Procedures worked well. In 2016, 159 342 people were examined, of which 97% (n = 154 502) by active screening. Of these, 51% (n = 79 383) were examined by mini teams. The total number of cases diagnosed was 67, of which 38 (57%) through active case finding. Traditional mobile teams detected 31 cases, 7 more were found by mini teams. Fixed health centers diagnosed 8 cases, the remaining 21 were diagnosed outside the districts. The prevalence rate among the population actively screened was 2.5 per 10 000. Conclusion The introduction of mini mobile teams and screening tests in fixed health facilities has significantly increased the coverage of the population at risk. Currently the overall HAT prevalence in the two districts is still above the WHO elimination threshold of 1 case per 10 000 people. The effectiveness of the new approach will be evaluated after three years of consistent implementation. Methods 894 healthcare facilities were mapped and characterised. From these, 600 were equipped with HAT rapid diagnostic tests (RDTs) and trained about HAT cases management. From the 600, 23 facilities were upgraded to confirm HAT by microscopy. From these 23, 5 were upgraded to perform LAMP, a molecular test for parasite DNA. Patients with symptoms suggestive of HAT are screened with RDTs, and positive patients referred for confirmation by microscopy. If negative by microscopy, a blood sample is transported to a LAMP facility for testing. If positive by LAMP, the patient is recalled for further testing. Active screening was organised in selected villages that reported cases. The programme was rolled out from August 2015, and in March 2017, a data-driven review was conducted to scale down activities to levels that could still result in elimination of the disease. Facilities that had screened or diagnosed HAT cases, or were within 15 km of a HAT case, with no larger facility within 2.5 km, were retained. Results To December 2016, 45 299 patients were screened in healthcare facilities and 930 (2.1%) were found positive by RDTs, 559 (60%) were tested by microscopy, identifying 81 cases, of which 53 (65.4%) were in early stage disease. 6 (7.4%) cases were identified after a positive LAMP result. Following these results, the participating facilities were reduced to 140, excluding those in areas where no cases were reported, and in towns with multiple facilities offering HAT screening. Conclusion This programme has resulted in a substantial Conclusion The fact that two gHAT cases were identified among refugees settled in Uganda in less than 4 months since the crisis begun, is a demonstration that the crisis poses a serious threat to elimination of the disease in Uganda. gHAT control might not be high priority among NGOs working in the refugee camps, and it is therefore the responsibility of government and international institutions to ensure appropriate measures are implemented and sustained to prevent resurgence of gHAT in the region. A strategy combining passive screening and reactive screening to control human African trypanosomiasis during the Ebola crisis in Guinea individuals were tested with RDTs in peripheral facilities, of whom, 70 were RDT positive. However, only 13 RDT positive suspects (19%) were successfully referred and underwent parasitological testing, and 7 were confirmed as HAT cases. Interestingly, 44 HAT patients presented themselves directly to parasitology sites. In April 2016, the team of three people visited four villages, and after screening 1378 inhabitants with RDTs, identified 38 suspects. 31 (82%) of the suspects were tested by parasitology, and 4 HAT cases confirmed. Conclusion Although the Ebola epidemic was a major challenge affecting both the health system and communities, it was possible to maintain some HAT surveillance activities. While a significant number of patients were screened in peripheral sites, only a relatively small proportion of them were eventually tested by parasitology. On the other hand, a high referral rate was achieved by using the reactive screening strategy. Adding tsetse control to medical activities contributes to decreasing transmission of sleeping sickness in the Mandoul focus (Chad) Conclusion This work shows that tiny targets reduced the numbers of tsetse in this focus in Chad, which may have interrupted transmission and the combination of tsetse control to medical detection and treatment has played a major role in reducing in HAT incidence in 2014 and 2015. Developing and operationalizing national-level early warning and response systems (EWARS) for dengue and other Aedes-borne arboviral diseases Introduction Dengue and other Aedes-borne arboviral diseases are a growing global health threat. Country ability to identify an impending outbreak and deploy an early response is key to reducing the health, societal and economic burden of these diseases. However, outbreak alerts are not currently used to trigger early response. Developing, testing and adopting early warning and response systems (EWARS) will help countries mount effective outbreak response systems. Aim To provide countries with a toolset for accurate temporal and geospatial prediction of outbreaks. Methods WHO/TDR and its partners developed a model contingency plan for dengue surveillance, outbreak prediction/ detection and response, supported by an operational guidea computer-assisted programme to facilitate the practical use of the early warning tool at district level. These tools are being further developed towards including Aedes-borne diseases atlarge through consultations with stakeholders and partners. Results A WHO/TDR expert consultation examined the current opportunities and challenges of developing and operationalizing national-level, early warning and response systems (EWARS). It discussed experiences drawn from fieldtesting of the EWARS operational guide and the research needs to improve and evaluate this tool by country health systems. This presentation will summarize the recommendations emerged from this meeting and the future studies needed. Conclusions Well-functioning EWARS can, in principle, improve population health by translating early signals into a set of explicit and geographically-targeted response measures, and direct the mobilization of appropriate resources in a timely fashion at the appropriate scale (i.e. local, regional, national). EWARS developed for dengue should be refined and adapted to country needs; they should also be further developed for other Aedes-borne arboviruses. Both generic and disease-specific EWARS are required for Aedes-borne arboviruses. Why the outbreak of Ebola virus disease in West Africa could have been detected one month -not three -after patient zero and lessons learned for surveillance systems strengthening Results At least three times the chance was missed to detect this EVD outbreak. First, a radio journalist from Gu eck edou realized that something was wrong because in January 2014, more and more of obituary notices arrived at the radio stationbut he didn't ask health authorities for information "because this is politics." Second, at the end of January 2014, one case of Cholera in M eliandou was detected-but against the International Health Regulations (IHR) this information was not forwarded to the next level of health authorities and apparently never reached WHO's Disease Outbreak News, ProMED-mail or others. Third, one day in February 2014, eight people with diarrhea were hospitalized in Gu eck edou, again suspicion fell upon Cholera-but again no early warning was communicated. In the meantime, the employee responsible to collect monthly information about dozens of diseases from the prefecture of Gu eck edou, typed "zero" in an excel sheet-although he was aware of the situation. Conclusion The Statement of the G20 Science Academies "Improving Global Health" (1) highlights the importance of "robust public health services encompassing disease surveillance". Nevertheless, the Ebola epidemic showed that it wouldn't be enough to finally implement all IHR core capacities. Also, vigilance among lay persons should be heightened; and informal surveillance systems such as ProMED-mail, Twitter, media should be acknowledged more as early alert-systems. The example of Uganda can serve as a role model [2] . Introduction Continuous assessment of vaccination coverage is required to prevent the resurgence of measles and hence to create a window of opportunity for elimination and, eventually, eradication. Low incidence of measles disease, (religious) beliefs and disproportionate perceptions about sideeffects tend to decrease vaccination coverage. Given local socioeconomic and cultural contexts, this can give rise to clusters of susceptible individuals, which may enable measles resurgence when they are sparked by a re-introduction. Individual-based (or agent-based) models allow exploring heterogeneous between-host interactions, conditional on immune status. As such, each person in the population is represented as a unique entity with a set of individual characteristics and the implications of health state related clustering can be studied. Aim To analyze the relation between documented measles outbreaks in Flanders and to which extent susceptibility has to be clustered with current vaccine coverage. We calibrated our open-source individual-based model "Stride" to reproduce measles outbreaks in Flanders between 2010-2015. We fit our synthetic population and social contact patterns to census and survey data for Flanders. Finally, we used a Latin-Hypercube design-ofexperiment to obtain insights into model dynamics regarding the clustering of vaccine induced immune and/or susceptible individuals. The emergence of complex transmission dynamics based on social contact patterns and the distribution of immunological states, provide essential information on the extent of effective herd-immunity, i.e. the protection of susceptible individuals through the transmission disruption by immune individuals. Clustering (the probability to be connected with a person with an equal initial health state) of immune individuals has no effect on total incidence. At equal overall vaccination coverage, the threat to public health seems greater when susceptibles are spatially and socially clustered than when they are evenly dispersed among the population. We quantified this threat for Flanders. Aims The aims of this study were mainly to: 1) do the risk assessment for human infection; 2) follow exposed persons to monkeypox in the Mefou Primate Sanctuary. Methods A line list was generated and an assessment of the park workers' exposure was made, using risk assessment tools pre-designed by the Centers for Disease Control and Prevention (CDC), which allowed to determine the range of dates of the potential exposures as well as the persons who may have been exposed. Persons who had direct or indirect contact with a dead animal during the period of potential exposure were considered exposed. Results Forty five out of fifty (90%) of those present at the exhibition period were interviewed. Respondents were predominantly male (84.4%) and had a median age of 34 years [range; 22-52]. All twenty-two exposed individuals were followed for at least 21 days after their last exposure. No cases were reported in humans. Forty three out of fifty (86%) of the park staff and 3/4 (75%) of the heads of the surrounding health areas were educated on the prevention of monkeypox. Conclusion Although the risk to the general population was estimated to be low in relation to the types of exposure observed, we demonstrated that the follow-up of exposed individuals was effective to prevention monkeypox and was associated with improved detection of human monkeypox cases. Aim Train « One Health teams » wherever epidemic disease outbreaks are occurring and -due to the absence of power and phone network -develop cheap tools and easy-to-use methods for alerting authorities and quickly confirming infectious agent animal and human outbreaks. Province (DRC) a holistic approach is being tested to improve the efficiency of human Monkeypox outbreak response. A "One Health team" was formed and (1) a didactic tool developed allowing to distinguish different types of eruptions and a casetracking tool to report cases and refine the nature and number of infectious contacts, (3) simple kits provided to skin biopsies and bushmeat samples, (4) equipment provided (CMR, camera trapping, tick collection) to identify zoonotic sources of the MPX and their geographical location by means of GPS trackers worn by hunters. Preliminary Results Combining radio interview in the local language, training workshop and field trips involving doctor and biologists impacted the knowledge and perception of a whole heath zone. Upon first visit, a surveillance questionnaire using a refined HMPX case definition was developed, and skin biopsies transmitted to Kinshasa for molecular diagnostic. Potential wildlife sources of infected bushmeat were monitored and a series of hunting areas identified. Movements of domestic animals were observed far into the forest allowing for potential ectoparasite exchange and pathogenic agent transfer. Conclusion Cost effective human and animal health-related projects need to be developed for the community and by the community in collaboration with experts from the academia, members of NGOs and governments. The HMPX surveillance questionnaire if used by all the health zones of the country could improve the diagnosis and monitoring of this disease. The association of cholera outbreak with conflict-related factors in Yemen Aim To analyze the epidemiological trends of the outbreak and identify the correlation between the outbreak and the conflictrelated injuries and death. Methods The data was obtained from the national surveillance system of ministry of public health and population in Yemen. The data contains details of 15074 cases registered as suspected cholera patients per governorate from week 39 to 52 in 2016. To identify the correlation, the data on conflict-related injuries, population movement (numbers of Internally Displaced Persons -IDPs and number displaced returnees) were autolyzed using the Spearman's rho analysis. The analysis showed that the total casualty per governorate (conflict-related injuries and death) was significantly correlated with cholera cases per governorates (r 0.483, P = 0.026). The analysis also showed positive correlation for population movement indicators due to conflict (numbers of Internal displaced people (IDPs) and Returnees) with cholera cases. However, the P values were not significant for both indicators (r 0.389, P = 0.081) and (r = 432, P = 0.050) respectively. obviously demonstrated in this study, thus countries in conflict should have emergency preparedness system in place and should not wait for cholera outbreak to happen in order to respond. Introduction Current dengue vector control strategies focus on the use of insecticides, either in preventive or reactive actions based on response to the appearance of clinical cases. They are inefficient, have short-lived effects and are unsustainable in a scenario of worldwide recrudescence of dengue, Zika and chikungunya. Aim To evaluate the feasibility of using risk stratification at city level to proactively concentrate sustained efforts in areas at high risk for transmission. Methods In Colombia and Cuba, demographic, environmental, epidemiological and entomological characteristics over a period of 5 years in the past are used to construct a mathematical model that assigns different levels of transmission risk to specific outlined geographic areas within an urban environment such as for example neighborhoods. In Brazil and Mexico, spatial modeling was used with the number of reported dengue casesseparately for infants and all age groups (to verify case mobility) -over a period of 7 years, and resident population. Evaluation of each approach consisted in: (1) appraising retrospectively the stability of areas identified as at high risk for dengue transmission by comparing models constructed for three different 5 year-windows; (2) prospective validation of the model with the data on clinical Zika cases after recent introduction of the virus in the study settings. Conclusion Proactive approach for controlling urban Aedes spp. mosquitoes integrated in disease mitigation planning is highly needed, especially in view of the increasing geographical expansion of the chikungunya and Zika viruses. Control strategies targeting areas at high risk for transmission are an alternative, but still to be evaluated in terms of effectiveness, feasibility and cost-effectiveness. Digitalization and planning of active HAT screening in the Democratic Republic of Congo to reach elimination Introduction Active screening of Human African Trypanosomiasis (HAT) in DRC is conducted according to an annual planning elaborated by the National Program for Sleeping Sickness Control. WHO guidelines for HAT elimination call for yearly screening of villages with active transmission until no new cases are detected for 3 years, afterwards the screening interval increases to 3 years. If no more cases are detected for 5 years, active screening can be stopped and passive surveillance combined with reactive screening should take over. Electronic data capture and a digital decision support system can help rationalize this planning process, and improve data quality andcompleteness. Methods Our operational research project implements innovative approaches for active screening such as door to door screening with mini teams and electronic data capture in 2 health districts (Yasa Bonga and Mosango) in the former Bandundu province. We created an offline mobile application that allows to collect individual demographic-and georeferenced data of complete households in endemic villages while diagnostic results are added for those attending screening. Results of screening tests can be photographed with an inbuilt camera for quality assurance purposes. Results Between 2016 and 2017, we plan to screen approximately 180,000 people with mini teams. Because the screening capacity for both districts superseded the capacity required to adhere to WHO guidelines, a 5 km buffer surrounding the endemic villages was added to delineate the target screening areas. We present the successes and challenges of implementing these digital tools in a resource poor setting. Despite limited network coverage, we managed to put a (wireless) data transfer system in place to centralize all data in a data warehouse which is linked to a dashboard for performance monitoring, epidemiological tracking and planning of operations. Discussion A practical and user-friendly decision support system and planning tool is instrumental for increasing coverage and efficiency of active screening for HAT elimination. The customized mobile application allows tracking of nonparticipation and retracing of temporarily absent people in the same screening campaign. It also gives a more accurate population estimate at village level which is important to predict screening capacity for future screening rounds. Introduction Plasmodium falciparum and P. vivax malaria in southern Palawan are the principal challenge to malaria elimination in the Philippines because of populations which only recently began using modern health services, difficult terrain, highly mobile farmers living in temporary and incomplete shelters, and exophilic vectors. For these populations, community volunteers have been trained to use rapid diagnostic tests (RDTs) and mass blood surveys are done intermittently. In high transmission districts, long lasting insecticidal nets (LLINs) are combined with two-three rounds of indoor residual spraying (IRS). Aim To achieve malaria elimination before 2030, strategies must be further developed. Methods Malaria in Palawan was reviewed and using transmission simulation models, the costs and the potential impact of medicine-based and vector control interventions were assessed. Results Simulations showed that despite outdoor biting vectors, both LLINs and IRS have strong impact on transmission. While LLINs are much cheaper and the mainstay of vector control, the cost of IRS can be reduced by relying on one annual spraying round with a long-acting insecticide formulation at the beginning of the transmission season. Larval source management may be considered around market places, where people congregate weekly and often spend the night unprotected from bites. At the levels of transmission in Palawan, expanding case management will reduce transmission, especially in remote areas, where RDT positivity rates are relatively high. Reactive case detection is less important to curb transmission, but high prevalence in family members suggests this is useful to detect cases. Annual rounds of mass screening and treatment are affordable and also reduce transmission, especially when timed as the transmission season starts. Mass administration of dihydroartemisinin-piperaquine can have a transient effect on P. falciparum as a single pulse (3-day treatment course), and longer lasting suppression is expected with three pulses at monthly intervals. For P. vivax, a 14-day primaquine course would require testing negative for glucose-6-phosphate dehydrogenase deficiency. Chemoprevention in farmers traveling to remote fields appeared promising in simulations and merits further investigation. Conclusion Malaria transmission in Palawan may be reduced by focusing on remote populations, while maintaining health services in population centres. Mapping of leprosy cases as a tool for rationalizing contact screening Introduction The island of Anjouan, Comoros, has been hyper-endemic for leprosy since decades. For the last 10 years, every year 200-300 new cases are being diagnosed on a population of less than 400,000. To facilitate active screening of contacts we developed an application in Open Data Kit, which allows capturing data on an Android smartphone during home visits. Aim To ensure complete coverage of screening of household contacts and to rationalize screening of neighborhood contacts. Methods Staff of the leprosy control services were trained in use of the app. They visited leprosy affected households and recorded demographic data on each permanent household member, as well as data on examination for leprosy. The app also allows to record geographic coordinates of the households visited. Geographic coordinates recorded were plotted in Quantum GIS on a Google Satellite plugin. In the villages mapped so far various degrees of clustering became apparent. Based on the patterns observed contact screening will be expanded to cover not only the leprosy affected households (first circle) but also the other houses in hyper-endemic neighborhoods (second circle). Conclusion Mapping geographic coordinates of leprosy affected households is feasible under programmatic conditions and can help in rationalizing active case finding activities. Leprosy remains a stigmatized disease, targeting entire neighborhoods for screening avoids the need of having to inform members of non-leprosy-affected households on the fact that one of their neighbors was diagnosed with the disease. A spatial decision support system approach to implementing malaria surveillance as a core intervention activity in high priority Vietnam Introduction A spatial decision support system (SDSS) was developed and piloted in Phu Yen Province, Vietnam to support the implementation of malaria surveillance as a core intervention activity. Aim This paper examines the development and acceptance of a customized SDSS surveillance tool to address key operational challenges in Vietnam and the Greater Mekong Subregion (GMS) including locating active malaria transmission, guiding targeted response interventions, and supporting the identification and investigation of suspected forest transmission sites and associated high risk populations. Methods A customized SDSS was developed for three communes in Dong Xuan District, Phu Yen Province. Village health workers conducted household geographic reconnaissance (GR) operations to map and enumerate all households in the study site. Detected malaria cases were recorded in the SDSS between 2015 and 2016 and georeferenced to household residence locations. Case data were utilized in the SDSS to guide village level targeted response interventions. Remote area sleeping site surveys were also conducted during the study period and analyzed in the SDSS. Structured user acceptability surveys and semi-structured in-depth interviews were conducted with SDSS stakeholders in March 2017. Results A total of 4,667 households with a population of 17,563 were mapped during baseline GR operations. During the study period, 128 malaria cases were reported and automatically mapped in the SDSS. Twelve village level targeted response interventions were conducted, testing a total of 1872 individuals. Of those, 361 individuals were investigated during remote-area sleeping site assessments. Intervention and remote-area sleeping site data were mapped and analyzed in the SDSS. Overall, very high acceptability of the SDSS was reported by Vietnamese malaria personnel. They identified key areas for improvement, including field based data collection form standardization and further training and support. Conclusion The SDSS piloted in Phu Yen provided an effective and acceptable operational tool for Vietnam's malaria personnel to implement surveillance as a core intervention activity. Results from this study call for further operational research, streamlining and wider rollout of SDSS surveillance approaches throughout Vietnam and the GMS. Introduction Heterogeneity in malaria prevalence and incidence tends to increase as transmission intensity decreases but the determinants of these micro-geographical variations remain poorly understood. Conventional epidemiological studies are usually restricted to investigating quantifiable, previously identified risk factors and rarely assess the confluence of factors that drive transmission at small spatial scales. This could be addressed with mixed-methods study designs combining qualitative and quantitative research, which may yield insights into how local contextual factors contribute to heterogeneity in malaria risk. Aim To explore how local mobility patterns and behaviours affect malaria exposure at sub-village level, and compare the results of a mixed-methods micro-epidemiological study design to a classic cohort analysis. The study was set in a remote area of central Vietnam, where subsistence slash and burn agriculture requiring overnight stays in the forest is considered the main risk factor for malaria. An exploratory mixed methods study combining ethnographic research and a cross-sectional survey was embedded in a one-year cohort study (2014-2015) comprising bimonthly malariometric screenings in three villages. Qualitative data were coded and analysed abductively, and survey data were linked to malariometric outcomes and analysed using multilevel logistic regression. The primary outcome, recent exposure to infection, was defined based on an increase antibody levels to two Falciparum antigens (PfAMA1, PfGlurp2) and/or two Vivax antigens (PvAMA1, PvMSP1) between the first and last surveys, with optimal cut-points for seropositivity defined using the classification and regression tree method. Results 22 in-depth interviews and numerous participant observations were recorded during the ethnographic research, and 160 adults responded to the cross-sectional survey. Recent exposure to malaria was estimated at 25% by serology for participants in the cross-sectional survey. Ethnographic research led to the identification of possible risk factors for malaria exposure that were not included in the main cohort study, including evening outdoor activities and residence patterns at forest farms, that were significantly associated with recent exposure to malaria in the cross-sectional survey. Conclusion Micro-epidemiology studies using mixedmethods designs can lead to identification of novel determinants of malaria risk at fine spatial scales, which could inform the development of interventions for malaria elimination. * Results There was a significant negative relationship between the perception of stigmatizing attitudes and behaviours among co-workers, and willingness to use occupational healthcare for TB screening, treatment and ICT. Conclusion Our results demonstrate that stigma negatively impacts OHU use among healthcare workers which in turn can impact their health and increase hospital costs. Health policy makers should address the issue by combating stigma among healthcare workers in the hospital and ensure confidentiality within the occupational healthcare. Why would antiretroviral treatment adherence clubs work in the Western Cape Province, South Africa? Aim In the frame of a realist evaluation project, we set out to elicit the hypothesis underlying the adherence club intervention in the Western Cape Province. Methods The underlying hypothesis, called initial programme theory in Realist evaluation, was developed from (1) an exploratory qualitative study of programme designers' and managers' assumptions of the intervention; (2) a document review of the design, roll-out and implementation of the adherence clubs; (3) a systematic review of group-based ART treatment adherence support models in Sub-Saharan Africa; and (4) a scoping review of social, cognitive and behavioural theories that have been applied to explain adherence to ART. We used the realist evaluation Intervention-context-actor-mechanismoutcome (ICAMO) heuristic tool to synthesise the obtained information into a configurational map and then developed the theories using the "if. . .then. . ., because. . ." clause. We identified two rival theories: Theory one proposes that patients become encouraged, empowered and motivated through the adherence club intervention to remain in care and adhere to the treatment. Theory two suggests that stable patients on ART are being nudged through stringent club rules and regulations to remain in care and adhere to the treatment with the goal to decongest the primary health care facilities. The initial programme theory provides explanations of how (dynamics) and why (theories) the adherence club intervention is expected to work. These theories will be evaluated in further empirical research. Community participation in mosquito breeding site control: a multidisciplinary mixed methods study in Curac ßao Methods A cross-sectional mixed method study was performed in June and July 2015 using survey questionnaires (n = 339), in-depth interviews (n = 20) and focus group discussions (FDGs)( n = 7) in Curac ßao, a Caribbean island. These quantitative and qualitative methods were based on an integrated theoretical framework of the TPB and the HBM. Results Participants showed a high-level performance of, and good knowledge of MBSC practices. Personal protection against mosquitoes was perceived as less valuable than MBSC practices and was consequently applied to a lesser extent. The study presents three possible ways of improving community participation in MBSC. First, it highlights the importance of ongoing media coverage, grounded in communities' lived experiences. Second, it shows a two-directional influence of governments' policies on communities' actions, which should be addressed in campaigns. Third, it demonstrates the potency of key person involvement in mosquito control policies to improve MBSC of a community. communities' lived experiences. The latter gaps might be overcome with the proposed interventions, resulting in a higher performance of MBSC of the community in Curac ßao. Moreover, this study shows how interdisciplinary mixed methods research can provide comprehensive and in-depth understandings of mosquito control policies. Introduction With increased efforts to fight and eliminate malaria over the past decade, numbers of malaria deaths and cases in sub-Saharan Africa have decreased substantially. As the malaria burden shifts towards older children and adults and the spatial heterogeneity of malaria transmission increases, pregnant women attending antenatal care (ANC) are considered a pragmatic sentinel population for malaria surveillance. Aim The aim of this study was to investigate the practicability and representativeness of pregnant women attending ANC as a sentinel population for malaria surveillance in Tanzania. Tanzanian health facilities reporting to the national data warehouse DHIS2 between January 2014 and May 2016 was downloaded and compared to other available prevalence data. Results Among the 4,354,911 ANC attendances observed, the malaria testing rate was 49.6%. On average 7.6% (95% CI 7.2-7.9) of pregnant women were tested positive for malaria infection. In 2015, the malaria prevalence in pregnant women was generally lower than in school children and in children aged 6-59 months, with substantial variability between districts and regions. The correlation was strong between regionally aggregated ANC prevalence and prevalence in children aged 6-59 months (Spearman rho: q = 0.90; P < 0.0001) as well as school children (regional: q = 0.84; P < 0.0001; district: q = 0.80; P < 0.0001). However, a poor correlation was found with district aggregated prevalence predicted by the Malaria Atlas Project (q = 0.56; P < 0.0001). The correlation of all comparisons was substantially stronger in districts or regions with one rainy season compared to areas with biannual rain. Conclusion The results of this study strongly support the use of pregnant women as a sentinel population for malaria surveillance in Tanzania to assess trends of malaria transmission. However, it is not possible to use ANC malaria prevalence data to make direct predictions about the prevalence in other population subgroups. Further research is needed in order to identify factors that influence the relationship between ANC and other population subgroup prevalences particularly in areas of more intense seasonality. Harnessing the wisdom of crowds to inform health spending: the case of malaria eradication Introduction The economic case for malaria eradication is compelling. Though its cost will be high, success would mean massive recurring savings. However, estimating the likelihood of success if fundamental to understanding the expected value of eradication. Given that success is highly uncertain, we rely on a "wisdom of (informed) crowds" approach to approximate the likelihood of and time frame to eradication, through a survey of malaria experts. Aim To guide the optimal distribution of health resources by gauging opinion, estimating the likelihood ofand quantifying the time frame tomalaria eradication through a systematic survey of malaria research professionals from a wide array of academic disciplines. Methods We identified 7680 researchers who had published peer-reviewed malaria research over the last 7 years. 880 researchers answered questions regarding the perceived years until, likelihood of, and obstacles involved in global eradication. Our study reveals a striking gap between the public discourse on malaria eradication and the views held by malaria researchers. Approximately 3/4 of respondents believe that malaria will not be eradicated in the next 50 years. Aggregating perceptions, the collective likelihood of eradication does not pass the 50% until 45 years from now. Those from the field of bionformatics and chemistry were far more "optimistic" than others. Researchers largely disagreed on which areas required most attention in order for eradication to succeed. Our results, which suggest a disconnect between (optimistic) public discourse and (pessimistic) private opinion, have three implications: (1) that those working or investing in eradication-specific campaigns should factor in the low likelihood and long time frame when calculating those campaigns' expected value versus alternatives; (2) that champions of near-term eradication need to make a more compelling case to malaria researchers of eradication's feasibility, in order to better focus and inspire the latter; and (3) that discord among malaria researchers as to which areas need the most attention in order for eradication to occur suggests a need for open discussion and consensus-making, so that resources and focus are directed appropriately. School-based malaria prevalence survey: Important longitudinal surveillance tool to assess epidemiological impact of malaria control interventions in the Democratic Republic of the Congo Methods Biannual SMPS used a stratified, randomized and proportional sampling method. Schools were randomly selected from the entire pool of facilities within each Health Area (HA). Subsequently, school-children between six to 12 y.o. were randomly selected in a proportional manner. Initial point-of-care diagnosis was made using a malaria rapid detection test. A matching stained blood film was later examined by an expert microscopist and used in the final analysis. Data was stratified and analyzed based on age, survey time and location (rural, semi-urban). Methods Malaria data were stratified by the annual parasite incidence (API), over the six years and by municipality. Environmental and socioeconomic risk factors were obtained from remote sensing and the 2010 census, and analysed with the help of Geographic Information Systems. Time-series and spatial analysis were performed to analyse the API. General linear models (GLM) were used to assess the relationship between selected risk factors and malaria incidence. Results Malaria API has declined 61% from 2010 to 2015, and there was a 40% reduction of municipalities with high transmission (API higher than 50). This represents 9.4% of all the municipalities in the study site and 63% of all cases, in 2015. The time-series analyses showed different incidence patterns by region after 2012; some States have minimized the effect of the seasonality in their incidence rates. Morans' tests showed spatial autocorrelation locally and globally. GLM presented space-time divergences in the risk factors. Conclusion Brazilian National policy to control malaria was useful to achieve the national and millennium development goal for malaria control. However, it is necessary to plan more effective interventions that take into account the epidemiological profile of every municipality or local context, since environmental and socioeconomic risk factors presented different dynamics in the Brazilian Amazon. Further, this study presents the reduction of cases during malaria season, indicating that, even in a very suitable environment, malaria can be controlled when epidemiological adjusted interventions are applied. Seasonal malaria chemoprevention in Burkina Faso protects children against malaria and anaemia under routine program implementation (2) to evaluate its effectiveness in improving malaria-related outcomes (parasitemia prevalence, anaemia prevalence and occurrence of febrile episodes) in preschool aged children. Methods A panel study was carried out in the district of Kaya during the peak malaria transmission season in 2014 and 2015. In both years, all members of the panel (1266 randomly selected households) were administered a questionnaire to assess individual characteristics of children, their exposure to SMC, any history of recent fever and malaria-related practices, as well as general household characteristics. All children under six years of age were tested for malaria and anaemia. Rapid diagnostic tests were conducted using whole blood via a finger prick to detect parasitemia and hemoglobin was measured using a photometer. Analysis was conducted using a difference-indifferences approach with a propensity score weighting. In 2015, 1814 children out of 2275 (80%) were exposed to the first cycle of SMC. Children were significantly (P < 0.05) more likely to receive SMC if they lived in households with higher hygiene scores and in monogamous households. SMC was significantly associated with a reduction in the point prevalence of malaria (À3.6%), which translated into a protective effect of 53% for children. SMC also significantly reduced the prevalence of anaemia (À14%) and the occurrence of febrile episodes (À10%), with respective protective effects of 28% and 47%. Conclusion Despite the coverage of only 80% among children, SMC was effective and had an immediate protective effect on the prevalence of all malaria-related outcomes under study. Challenges for the control of strongyloidiasis in public health Introduction Strongyloides stercoralis is a neglected parasite that infects 100-400 million people worldwide but its prevalence and chronic disease burden are yet to be precisely estimated. In immunosuppressed patients, however, this helminth can have devastating consequences and lead to hyperinfection and death. Parasitological diagnosis is challenging and more difficult than for other common soil-transmitted helminths (STH). Ivermectin is the drug of choice for treatment but it is not widely available at affordable costs in most countries. Aim To address the epidemiological, diagnostic, treatment and operational challenges to include S. stercoralis in preventive chemotherapy public health interventions. Challenges and Way Forward Solid evidence and more precise estimates of global prevalence and related morbidity are needed to warrant the development of a control strategy. Userfriendly and sensitive diagnostic tools to be used in endemic countries are to be developed to be used as benchmark for diagnosis and as threshold to define associated morbidity. The efficacy of the best regimen of ivermectin given in single dose and its related benefits in terms of reduction of morbidity, as well as the potential of reinfections in endemic areas, should be assessed. Threshold for community treatment should be established by available evidence or mathematical modelling and target groups defined. Ivermectin has been recently included in the Essential Drug List of WHO for the treatment of strongyloidiasis and this drug should be made available at low cost or donated for public health interventions. The estimated demand for ivermectin should be established in order to foster its large-scale production. A pre-requisite for generic ivermectin to be pre-qualified by the WHO to be available for public health programmes, is the analysis of bio-equivalence that should be pursued. Beyond deworming, an integrated approach through improvement of health education, sanitation and safe water supply, would be essential to further reduce S. stercoralis transmission. Finally, advocacy from different platforms, international agencies and demand from endemic countries should create a critical mass that will stimulate WHO to lead the development of a public health strategy for the control of this most neglected parasite and include it in preventive chemotherapy programmes as for other STH. Introduction Onchocerciasis is targeted for elimination in Africa by 2025 through annual or semi-annual mass drug administration (MDA) with ivermectin. Current WHO guidelines for stopping MDA and verifying elimination require that the Ov16-antibody prevalence in 0-9 year old children is brought below 0Á1%, but the empirical evidence underlying the choice of age group and threshold value is still limited. Aim We aimed to investigate the predictive value of different Ov16 antibody prevalence thresholds in various age groups for elimination of onchocerciasis in a variety of endemic settings and for various MDA scenarios. Methods We used the individual-based stochastic ONCHOSIM model 1 to simulate trends in infection and Ov16 antibody prevalence levels during and after MDA. We simulated 750 scenarios, varying with respect to pre-control endemicity level and MDA characteristics (frequency, coverage and duration of MDA). Each scenario was simulated 10,000 times, and for each run we recorded the model-predicted Ov16 prevalence in various age groups (one year after the last MDA round) and the outcome in terms of ongoing transmission vs. elimination (nonzero vs. zero mf prevalence 50 years after the last MDA round). Results Sensitivity and specificity of Ov16 antibody prevalence for predicting elimination highly depends on the precontrol epidemiological situation, history of MDA, the age group that is sampled, and the chosen Ov16 antibody prevalence threshold. Still, threshold values can be defined such that positive predictive values for elimination are close to 100% regardless of the history of MDA. Importantly, the Ov16 antibody prevalence in school-aged children (age-group 5-14) performs best in predicting elimination. Conclusion Although exact estimation of thresholds remains difficult due to uncertainties regarding antibody response dynamics, our study indicates that 1) sampling school-age children instead of children under ten increases the accuracy of anti-Ov16 prevalence as a predictor for elimination; 2) the current threshold of 0Á1% is too stringent except for the most highly endemic settings; and 3) a differentiated approach to defining thresholds based on pre-control endemicity is pertinent.  The impact of semi-annual mass drug administration for multi-species lymphatic filariasis in Indonesia: a modelling approach Introduction The Global Program to Eliminate Lymphatic Filariasis (LF) has achieved an enormous decrease in LF infection prevalence in many countries through implementation of annual mass drug administration (MDA) for at least 5 years, but a number of countries lag behind due to problems in implementation. Acceleration strategies are needed to achieve the 2020 elimination goal worldwide. Mathematical modelling suggested that the required duration of interventions can be halved by switching from annual treatment to 6-monthly treatment. This needs confirmation by empirical data. Aim We aim to refine model-based estimates of the required duration of annual versus semi-annual MDA for achieving LF elimination, by analysing DOLF project data. These include a community intervention study in Sikka district, Flores, Indonesia that compared trends in brugian and bancroftian filariasis infection in 3 communities after 3 years of annual or biannual MDA with diethylcarbamazine and albendazole. Methods Using approximate bayesian computation techniques, we fitted the LYMFASIM simulation model to antigenaemia prevalence (W. bancrofti), antibody prevalence (B. malayi), and microfilaraemia (mf) prevalence and intensity (both species) at baseline. Thereafter we assessed whether the model-predicted trends are in accordance with the observed data. Lastly we tested what trends would have been seen if the other treatment regimen would have been used, in order to estimate the number of treatment rounds required to bring mf prevalence below 1%. The baseline prevalence in the community with biannual MDA was higher (8.7 and 10.3% for W. bancrofti and B. timori, respectively) than for the two communities with annual MDA (0 and 0.4% for W. bancrofti and 3.9 and 4.9% for B. timori). Our modelling approach accurately reproduced the observed trends. It suggests that elimination is probably already achieved in the communities that had biannual MDA, whereas interventions will need to continue for another 2-3 years in sites that were treated annually. Introduction A high prevalence of epilepsy has been reported in many onchocerciasis endemic regions. Nodding syndrome, a distinctive form of epilepsy has been reported to occur in onchocerciasis endemic regions. Although epidemiological studies underline the association between onchocerciasis and the onset of epilepsy, the causative mechanism is not yet understood. Aim To determine the prevalence of onchocerciasis, and prevalence and incidence of epilepsy following long-term use of ivermectin in control of onchocerciasis in the Mahenge area of the Ulanga district in Tanzania. The study was conducted in two rural and two semi-urban villages near Mahenge township in the Ulanga district. These villages, particularly the rural ones had been found to have a high prevalence of epilepsy during a survey in 1989. January 2017, we performed a door-to-door epilepsy survey using a 5 questions validated questionnaire, where persons with positive answer to one of the questions were seen by a neurologist. Clinical, neurological and laboratory examinations were performed in all epilepsy suspects. We also tested children 7-10y old for the presence of Onchocerca volvulus (OV) antibodies and performed a rapid epidemiological mapping of onchocerciasis (REMO). Results 5160 (median age 18.5y, 47.8% male) individuals from 1172 households were registered. 264 (5.1%) individuals were suspected to have epilepsy during screening and 2.04% were confirmed to have epilepsy, 2.84% in the rural vs 1.32% in the semi-urban villages, P < 0.001. Nodding syndrome was reported in 23(21.7%) of epilepsy. Incidence of new onset epilepsy was 63.8 per 100,000 person/year. In children 7-10y, prevalence of OV16 positivity was 42.6% in the rural and 4.7% in semi-urban villages, P < 0.001. Among men >20 years, the prevalence of OV16 positivity was 65% and 1.8% were found to have onchocerciasis nodules. Conclusion Despite the use of ivermectin for about 20 years, the prevalence of onchocerciasis and epilepsy remains high in the two rural villages with no substantial change in the incidence and prevalence of epilepsy compared to 1989 survey. These findings suggest a suboptimal functioning of the onchocerciasis control programme. Reasons for persistence of onchocerciasis and epilepsy needs further investigations and strengthening of the onchocerciasis control programme. The long-term impact of preventive chemotherapy on the burden of soil-transmitted helminth infection Results Nineteen studies from 17 countries were included in the review. All studies were conducted in school-age children, except for one study in Vietnam which included women of childbearing age. The average sample size was 3472 individuals and the average length of follow-up was 46 months. At baseline, the proportion of those with MHI infection was 14%. The average reduction in MHI infections increased from 73% after one year to over 95% after 10 years of treatment. Results were similar for A. lumbricoides and T. trichiura. For hookworm, the reduction in prevalence increased from 57% after one year to 78% after 5 years. can successfully reduce intensity of all STH infections and help to achieve the goal of eliminating morbidity in children by 2020. Long-term implementation is essential to maximize and sustain these benefits, particularly as reinfection will occur in the absence of adequate sanitation. These results will now be used to inform evaluations of DALYs saved through implementation of large-scale preventive chemotherapy programs globally. Efficacy, effectiveness and safety of measles vaccination below nine months of age: a systematic review and metaanalysis Introduction Measles remains a leading cause of child death, despite measles containing vaccines (MCVs) offered globally through routine immunization. The first MCV dose is recommended at 9 months in countries with ongoing measles transmission. Aim To provide evidence for the optimal age at MCV1, we conducted a systematic review and meta-analysis of the effects and safety of MCV1 in infants <9 months of age. Methods We systematically searched published and grey literature for studies in which MCV1 was administered to infants <9 months of age reporting the following end-points: proportion seroconverted (%SC), geometric mean titres (GMTs), avidity, cellular immunity, duration of immunity, vaccine efficacy, vaccine effectiveness (VE) and/or safety. Results 138 papers were eligible for data extraction, including five randomized controlled trials. All other included papers were observational. The %SC increased from 50% (95% CI 29-71%) at 4 months to 67% (51-81%), 76% (71-82%), 72% (56-87%) and 85% (69-97%) at 5, 6, 7 and 8 months, respectively. In head-to-head comparisons of MCV1 including the Edmonston-Zagreb strain or the Schwarz strain among 6 month old infants, the %SC was 18% (95% CI 3-34%) higher for the Edmonston-Zagreb strain. Limited evidence on avidity of measles specific antibodies and duration of protection suggested lower avidity following MCV1 vaccination at 6 months of age. The evidence regarding antibody waning was inconclusive. Limited evidence on cellular immunity did not suggest an effect of age at MCV1 vaccination. The estimated pooled VE of MCV1 < 9 months of age against clinical measles was 72% (95% CI 53-91%). The pooled VE-difference found in within-study comparisons of infants vaccinated with MCV1 < 9 months and ≥9 months was 18% (95% CI 15-20%). No reports of serious adverse events were found among 2,042 infants receiving MCV1 < 9 months. Conclusion MCV1 administration <9 months of age induces a good immune response, confers protection and is safe, although higher rates of seroconversion and protection are observed among infants vaccinated with MCV1 ≥ 9 months. Recommending MCV1 for infants <9 months at high risk of measles infections is therefore an important step towards reducing measles mortality and morbidity. Aim The aim of the present study is to determine the trend of cVDPVs strains isolated in DRC since the establishment of AFP surveillance.  The use of first void urine to monitor HPV vaccination impact, results from Bhutan and Rwanda Aim Virological end-points showing the absence of persistent HPV infection are accepted as a way of monitoring the impact of prophylactic vaccination programmes. In this study we wanted to show the feasibility of using first void urine, collected and processed in optimal conditions, to monitor vaccine effectiveness [1] . Method Detection of HPV DNA in urine was optimized and standardized leading to an urine collection device and DNA preservative. In 2013 two school-based HPV urine surveys were performed; 973 female students (median age: 19 years, 5th-95th percentile: 18-22) were recruited in Bhutan and 912 (19 years, 17-20) in Rwanda. Participants self-collected a first-void urine sample using the validated protocol. The urine collection was well accepted by the participants; 92.7% and 88.3% of the consented Rwandese and Bhutanese girls, respectively, also returned a vial of collected urine. 43% students in Rwanda and 92% in Bhutan reported to have been vaccinated (median vaccination age=16, 5th-95th: 14-18). HPV prevalence obtained using GP5 + /GP6 + showed that HPV positivity in urine was significantly associated with sexual activity measures. In Rwanda, HPV6/11/16/18 prevalence was lower in vaccinated than in unvaccinated students (prevalence ratio, PR=0.12, 95% confidence interval, CI: 0.03-0.51 by GP5 + /GP6 + ). Also in Bhutan, HPV6/11/16/18 prevalence by GP5 + /GP6 + was lower in vaccinated than in unvaccinated students but CIs were broad. Conclusion This study supports the feasibility of urine surveys to monitor HPV vaccination and quantifies the effectiveness of a HPV vaccine in women vaccinated after preadolescence. Introduction Measles continues to contribute to child mortality, especially in resource-poor and access-constrained settings where routine vaccination remains fragmented and often weak. In the remote areas of the Democratic Republic of Congo (DRC), M edecins Sans Fronti eres (MSF) responds to measles outbreaks with case management and reactive massvaccination. The classic MSF mass-vaccination response aims to rapidly obtain a high coverage, by first targeting the most densely populated and easily accessible areas. An innovative strategypiloted by MSF and termed "Coup de Poing (CdP)" utilizes epidemiological data to guide the vaccination intervention: the epicentre of the outbreak is targeted first with a rapid response, using a passive cold chain and multiple vaccination teams. This is followed by a general catch-up vaccination in the area. As such, CdP aims to have a "punch down effect" on the epicentre of the outbreak and rapidly defuse its potential and spread. Aim To compare the effectiveness of the classic and CdP measles interventions as implemented by MSF in DRC. Methods A comparative descriptive study using routinely collected programme data from 10 MSF measles responses (6 classic vs 4 CdP) in DRC (2012-2013). Interventions were conducted by an emergency unit dedicated to providing shortterm response to epidemic outbreaks. The median attack rate (AR) varied from 2.6% (Inter-Quartile Range 1.8-3.6) for classic responses to 1.3% (IQR 0.9-1.7) for CdP, and the median AR for children under 5 years varied from 10.2% (IQR 5.7-13.9) to 3.4% (IQR 2.8-4.8). With CdP, activities could usually be initiated prior to the epidemiological peak of the outbreak, in contrast to the classic interventions. Additionally, under CdP the outbreaks could generally be contained around the epicentre. Post-vaccination coverage remained similar between the two approaches. Logistic and human resource needs were also similar, while the cost per beneficiary was slightly lower with CdP. Conclusion The CdP strategy was at least equivalent to or possibly better than the MSF classic vaccination response. CdP represents a promising, rapid measles intervention strategy for areas that are confronted with recurrent measles outbreaks and that struggle with geographic and logistic barriers to achieving rapid outbreak control.  The studies from Guinea-Bissau and Denmark, two very different settings, both suggest that the BCG and smallpox vaccines could be associated with a decreased risk of sexually transmitted HIV-1. It seems essential to pursue this observation and explore possible protective mechanisms as part of the search for an HIV-1 vaccine. *Joint first authors. Extracting the incentives: vaccination behavior as a multicriteria decision Researchers have responded to these events by including behavioral features in models for infectious disease transmission, for example, by relating vaccine uptake to (perceived) prevalence of disease. The majority of these behavioral change models (BCM) are theoretical, i.e. unsubstantiated by empirical observations. The empirical assessment of the "vaccination black box" of the public remains unexplored. Aim To identify and quantify influential components in the decision-making process of individuals towards vaccination (in Flanders). Introduction Within the "WHO Global Action Plan to minimise poliovirus facility-associated risk after type-specific eradication of wild polioviruses and sequential cessation of oral polio vaccine use" (WHO GAP III 1 ), requirements and timelines are defined for phasing out activities with different types of poliovirus and vaccines. After type-specific eradication and containment of wild poliovirus and cessation of oral polio vaccination, minimizing the risk of poliovirus reintroduction is critical. To prevent reintroduction, the number of international poliovirus facilities will be reduced to the minimum necessary to perform critical functions of research, diagnosis and vaccine production and these will be defined as poliovirus-essential facility (PEF). Aim Assessing and supporting organisations, that have the intend to be certified as PEF. Methods Applying specific biorisk assessment methodologies in order to verify and perform a conformity check with regard to the WHO GAP III requirements. Results WHO GAP III safeguards, aim at reducing the likelihood of accidental or malicious poliovirus release from a PEF. All PEFs and operations will need to comply with the requirements. Key elements include: (1) Appropriate design, construction and operation principles of the facility; (2) Facility management, which practises continuous risk assessment and observance of biosafety and laboratory biosecurity procedures; (3) Immunisation of facility personnel, which can reduce the risk of infection in the facility and intra-or extra-household transmission, should infection occur; (4) Contingency plans for potential virus release or exposure, which specify actions and assign responsibilities. Conclusion In anticipation of the future WHO GAP III certification process, a roadmap is developed on how companies and universities can prepare themselves for compliance with the GAP III requirements using specific biorisk assessments focussing on: Physical layout, with attention to containment barrier integrity and biosafety critical equipment using various risk assessment methodologies; Biorisk management performance based on the WHO GAP III 16-point biorisk management plan, which is consistent with the CWA 15793:2011 and implies the implementation of biorisk management system. 4S8.4 The value and unexpected by-product of a community engagement strategy aimed at addressing the immunisation gap in north-west Ethiopia Aim To evaluate 'The Fifth Child Project' in terms of integration into the health system, utilisation and acceptability, community co-management, and contribution to improving routine immunisation system performance. Methods Routine immunisation data from two districts was analysed, and a series of interviews (46), focus groups (6) and observations of project activities conducted in three kebeles within these districts from May-July 2016. Qualitative data was transcribed, translated and uploaded to an NVIVO database where it was analysed thematically. A data verification exercise was conducted in November 2016. The project introduced new ways of working which helped health workers identify and connect with hard to reach families. Project tools decreased health workers workload and the calendar enabled mothers to maintain better control over their children's health. It also operated as a catalyst for healthrelated discussions within families and enabled more personalised interactions with health workers. Varying levels of support from kebele leaders were reported and there was a lack of clarity about their role in defaulter tracing. We also found evidence of community-agreed sanctions (monetary fines and cautions by local court) for non-compliance with the infant vaccination schedule. Interviewees wanted the project to expand but highlighted the need for infrastructural investment to improve the performance of the immunisation programme. Increased immunisation coverage was observed but cannot be attributed solely to the project. The project was well integrated within the Health Extension Programme and successful at engaging community members at household and kebele command post level. Whilst community co-management activities merited strengthening the establishment of community-agreed sanctions were evidence of community ownership, even though they constituted an ethical conundrum. Understanding girls' preference for human papilloma virus vaccination in Ethiopia: A study protocol for discrete choice experiment Introduction Cervical cancer is the second most common cause of cancer related death globally and the first in the common cause of cancer in Ethiopia. Prophylactic Human Papilloma Virus (HPV) vaccination is being introduced in several countries. Ethiopia is undergoing a pilot for HPV vaccine implementation at two major sites in Oromia and Tigray Regions with support from GAVI. Nevertheless, in that respect is no any evidence regarding the situation about encountering problems, receiver's attitude and acceptance and also parents or girls' preference for HPV vaccine. Aim The aims of this study are (1) to explore favorable combination of properties of HPV vaccine; (2) to explore the most important HPV vaccine characteristic; (3) to measure and quantify the girls' trade-off and choice between risks and benefits of HPV vaccination programs. Methods The study will be performed by using Discrete Choice Experiment (DCE) study design. An extensive literature review followed by a preliminary qualitative study has been conducted in order to identify attributes to refine the levels which affect girls' choice. Attributes finally considered in the choice sets are (1) degree of protection against cervical cancer, Introduction Vector control tools are needed to combat leishmaniasis. A semi-synthetic version of a Lutzomyia longipalpis aggregation/sex pheromone (9-methlygermacrene-B) has been developed, and shown efficacy to attract sandflies in the lab and to chicken sheds in the field. Here, we present results from a cluster-randomised trial performed in Brazil where we test the efficacy of the pheromone deployed with insecticide, a novel lure-and-kill intervention, to reduce leishmaniasis transmission to the canine reservoir. Aim Investigate the efficacy of sandfly sex pheromone baited + insecticide treated chicken roosts to reduce transmission of Leishmania infantum among the reservoir population (dogs). Methods We conducted a cluster-randomised trial across 42 communities in Brazil. Pheromone lures plus insecticide were applied in 14 communities, and outcomes compared to that of 28 other communities that received either a placebo (sham lure + insecticide) or deltamethrin-impregnated collars fitted to dogs. We quantify the primary intervention effects by comparison of the number of uninfected dogs that seroconverted in each arm over the course of the 2-year trial. Results A reduction in canine incidence is attributed to the pheromone + insecticide intervention, which is consistent across the levels of hierarchical analysis, though the errors are broad. The performance of the pheromone followed similar patterns as the collar arm which significantly reduced seroconversion incidence. Conclusion These data represent the first trial of a synthetic vector pheromone applied in public health control, and the first cluster-randomised trial of dog collars in Brazil. Both methods show potential for the control of zoonotic visceral leishmaniasis in the Americas; developments of the pheromone lure-and-kill strategy are underway. Methods The anti-phlebotomine activity of four systemic insecticides in dogs was evaluated using a randomized clinical trial. Thirty dogs were randomly allocated into five groups, four treatments and one control, of equal size. The treatments evaluated were: Guardian â SR, Elanco (moxidectin); Comfortis â , Elanco (spinosad); Bravecto â , Merck Animal Health (fluralaner); NexGard â , Merial (afoxolaner). All the treatments were administered to the dogs following the label indications. Blood from dogs was taken at days 2, 4, 21 and 31 post-treatment. Membrane feeding bioassays using Phlebotomus papatasi were used to evaluate the anti-phlebotomine efficacy of the different treatments. Sand fly mortality was observed 24 and 48 hr following the membrane feeding. Conclusion Fluralaner showed a rapid and significant killing effect on blood-fed sand flies. Results from days 4, 12 and 31 post-treatment should confirm this anti-phlebotomine activity. The use of fluralaner as a control tool for ZVL in endemic areas will be discussed. Background Leishmaniasis in Suriname is thought to be cutanenous leishmaniasis (CL) caused by Leishmania guyanensis, which is treatable with pentamidine. The sand fly vectors are poorly identified and a vertebrate reservoir is not established. Social factors related to the disease have not been studied at all. CL is an growing health problem in the country and there is concern about increasing treatment failures. Aim To update our knowledge on leishmaniasis in Suriname, in particular with respect to prevalent species, sand fly vectors, potential reservoir, treatment options and health care seeing behaviour. Methods Epidemiological and entomological surveys were conducted. A treatment trial with different courses of pentamidine was performed to determine the drug efficacy (monitored with molecular methods) and to identify infecting Leishmania species (in particular those not responding to treatment). A medical anthropology approach was undertaken to study patients' perceptions of the disease and health care seeking behaviour. There is an increasing incidence of CL in the country. Other Leishmania species than L. guyanensis and their vectors have been identified, including muco-cutaneous leishmaniasis (MCL) causing L. braziliensis. Treatment failures with pentamidine are frequent (>30%). The current 7 days course (with 3 injections) is preferred above a shorter cause with higher doses due to side effects. Dogs may be a reservoir, but needs to be confirmed. For Suriname 3 new sand fly species harbouring Leishmania parasites have been identified. Stigma is not a problem, and populations have basic knowledge about the disease. Patients in the interior opt for traditional healers. Alternative treatments (in particular harsh treatments with toxic products) are often employed: 'a cruel disease needs cruel treatment'. Costs associated with treatment are a barrier for people to seek health care. There is common fear for the injections. Conclusion Alternative treatment options for CL are urgently needed in Suriname. Public and Health authorities awareness of the disease should be increased, including the possibility of MCL, and this is appeals to entities outside the country, for example those who manage tourists. A country control programme for leishmaniasis should be developed. Suffering in silence: a qualitative study on reasons of delay in seeking care for visceral leishmaniasis in southern Gedaref, Sudan Introduction Gedaref state in eastern Sudan bears 80% of the visceral leishmaniasis (VL) burden in Sudan. Control of VL here mainly relies on provision of diagnosis and treatment services. However, many people may fail or delay in accessing VL care, as reflected in a relatively long duration between the onset of symptoms and the moment patient seeks treatment. VL is potentially fatal, thus reducing these delays is critical to save lives and the success of the control program. This study sets out to look into community and their health worker(s) perspective of VL and access to care, taking into account the various facets of health seeking behaviour and its influencing factors (cultural, socio-economical, medical pluralism). Aim To voice the community perception on VL access barriers and help to improve the timely use of available care through useful recommendations. Methods A qualitative study design is chosen. Data collection through focus group discussions (FGDs) and in-depth interviews (IDI) was conducted by trained local field team. A nonprobability purposive sampling of 9 villages located along Rahad and Atbara river basins was done (high and low number of cases). Maximum variation was ensured through participants' age, gender and ethnic/tribal origin. Key informants include former VL patients, caretakers/families, community members, leaders and health staff. Text data is analysed using NVivo, until data saturation is reached. Results Data collection is still ongoing. The preliminary results from 19 FGDs and 22 IDIs suggest a reasonable knowledge of VL (on fever, sandfly), yet local beliefs influence the disease perceptions (eating banana and chicken, among others). Reaching final VL diagnosis is problematic: money is depleted for various investigations and eventually delay proper treatment. Once diagnosed, experience abound of 'sometimes there is treatment, sometimes not'. Rainy season (June to August) blocks many roads and poses additional access problems. Conclusion We expect final results to be available by May 2017. Our data provides useful insights and better understanding of VL access barriers in this context, therefore further intervention(s) could be adjusted wherever feasible. The qualitative nature of the study provide a rare view from the community lens on this deadly disease. What are the true outcomes of patients declared lost to follow up in a visceral Leishmaniasis program in Sudan? Introduction Visceral leishmaniasis (VL), also known as 'kala-azar', is a life-threatening parasitic disease caused by the Leishmania donovani complex. In East Africa, first line treatment is with a combination of paromomycin and pentavalent antimonials, given in daily injections for 17 days. Patients are hospitalized during the entire course of treatment and at the end of treatment initial cure is established clinically and parasitologically. At discharge, patients receive a 6-month follow-up appointment. Patients are considered a 'definite cure' if no relapse has occurred within 6 months after discharge. However, as has been reported in MSF's kala azar clinic in Sudan, preliminary data suggest that a high proportion of patients are lost to follow-up and do not return to the clinic after 6 six months (>50%). As such, it is unclear what the true treatment outcomes of these patients are. This is vital to be able to correctly judge the effectiveness of the current regimen and 'real' program performance. No data from other VL programmes are reported on the issue. Aim To determine what the true treatment outcomes are of VL patients who are declared lost to follow-up (failure to attend the 6-month scheduled follow-up appointment) after an initial cure. Methods A retrospective cohort study using routinely collected program data combined with a telephone based questionnaire survey to understand the reasons for not turning up for the 6-month scheduled appointment. Results Preliminary result showed that the majority of patients reported as lost of follow up did not show up because they felt healthy, were too busy or had an access problem. Data collection is ongoing; full results will be presented at the time of the conference. Conclusion Obtaining data on definite cure rates of VL patients in a program setting in Sudan is challenging due to high loss to follow up. Methods To establish a sand fly colony, we collected wild P. argentipes from March through mid-December, 2015. Over 68 000 sand flies were collected from human dwellings and cattle sheds using 15 CDC-type light traps over 254 nights. Blood-fed and gravid Phlebotomus argentipes females were selected and placed individually in isoline-rearing vials for oviposition. Progeny were reared according to standard methods. To confirm the colony was permissive to infection with Leishmania donovani, we performed artificial membrane feeding experiments with serial dilution of parasites spiked with healthy human donor blood. To evaluate various human-subject groups for reservoir of infection, initially we screened and recruited 20 confirmed Visceral Leishmaniasis patients. We performed xenodiagnosis with 30 female sand flies per patient for 30 min and dissected flies after 60 hr to check presence of parasites in the sand fly gut. Results Once self-sustaining, the colony was closed to infusion with wild-caught material and certified free of specific human pathogens. Artificial membrane feeding experiments, proved susceptibility of colony flies for Leishmania donovani infections. Xenodiagnosis on VL patients provided significant correlation between patient splenic score and capacity of sand flies to develop infection. We are going to further use xenodiagnosis experiment to validated potential reservoir of parasites in various other human groups including sub-clinical or asymptomatic cases and Post Kala-azar Dermal Leishmaniasis patients. Elimination of visceral leishmaniasis on the Indian subcontinent: a comparison of multiple transmission models Introduction On the Indian subcontinent (ISC), visceral leishmaniasis (VL) is targeted for elimination as a public health problem by 2020. The elimination target is defined as an annual VL incidence of <1 per 10 000 capita at (sub-)district level. Interventions focus on vector control, surveillance and on diagnosing and treating VL cases. Aim To explore whether and within which timeframe current interventions may lead to reaching the VL elimination target. Methods We present multiple mathematical models of VL transmission on the ISC with structural differences regarding the main reservoir of infection, including those with a prominent role of asymptomatic infection, and fit them to recent case data from 8 endemic districts in Bihar, India. Following a rigorous geographical cross-validation of the models, we compare their predictions for achieving the WHO VL elimination targets with ongoing treatment and vector control strategies. Results All the transmission models suggest that the WHO elimination target will be met in Bihar, India, before or close to 2020 in sub-districts with a pre-control incidence of 10 VL cases per 10 000 people per year or less, when current interventions (60% coverage of indoor residual spraying (IRS) of insecticide and an average delay of about 40 days from onset of symptoms to treatment) are maintained. Conclusion Increasing the IRS coverage and to a lesser extent reducing the time from onset of symptoms to treatment will both decrease the time to elimination. However, in all cases the models suggest there is likely to be ongoing transmission after 2020 and so control measures will have to be kept in place for several years to achieve the longer-term aim of breaking transmission. Phlebotomus argentipes Sand Fly control in Bangladesh: a cluster randomized controlled trial Introduction The present study on a large sample investigated different options which have not previously been fully explored including: (1) indoor residual spraying (IRS) with alpha cypermethrin 5WP; (2) long lasting insecticide impregnated bed-net (LLIN); (3) impregnation of local bed-nets with slow release insecticide KOTAB 123 (KOTAB); (4) insecticide spraying in potential breeding sites using chlorpyrifos 20EC (OUT) and different combinations of the above. Aim To identify suitable vector control tool(s) for supporting VL elimination programme. The study is a controlled cluster randomized trial where 3089 houses from 11 villages were divided into 10 sections, each section having six clusters and each cluster having about 50 houses. Vector density was measured before and up to 22 months after intervention using CDC light traps. Results At baseline and nine post intervention surveys, 17 434 sand flies were collected. At baseline, the average Phlebotomus argentipes density per household was 10.6 (SD = 11.5) in the control arm and 7.3 (SD = 8.46) to 11.5 (SD = 20.2) in intervention arms. The intervention results presented as the range of percent reductions of sand flies and rate ratios in 9 measurements over 22 months. The effect of IRS with 2 rounds of spraying ranged from 13% to 75% reduction of P. argentipes density compared to the control arm (rate-ratio [RR] ranged from 0.25 to 0.87). LLINs caused a vector reduction of 9% to 78% (RR, 0.22 to 0.91). KOTAB reduced vectors by 4% to 73% (RR, 0.27 to 0.96). The combination of LLIN and OUT led to a vector reduction of 26% to 86% (RR, 0.14 to 0.74). The reduction for the combination of IRS and OUT was 8% to 88% (RR, 0.12 to 0.92). IRS and LLIN combined resulted in a vector reduction of 13% to 85% (RR, 0.15 to 0.77). The IRS and KOTAB combination reduced vector densities by 16% to 86% (RR, 0.14 to 0.84). The bioassays on sprayed surfaces or netting materials showed favourable results (>80% mortality) for 22 months (IRS-12 months). In the KOTAB, a gradual decline was observed after 6 months. Conclusion LLIN and OUT was the best combination to reduce VL vector densities for 22 months. Health seeking behavior of patients in Muzaffarpur-TMRC HDSS may hinder Kala-azar elimination in Bihar, India Methods From the available data we extracted information on number and types of health providers consulted by VL patients, diagnosis and treatment prescribed and individual and health system delay. We performed the trend analysis to study changes occurred in the health seeking behavior of the villagers over a period of 8 years. Results Between March 2007 and July 2015, 332 VL cases were registered (185 men (56%) and 147 women (44%)). We observed declining trend in annual incidence (from 15 per 10 000 in 2007 to 0.82 in 2014). Most patients (73%) first consulted unqualified providers; only 3% chose to go to government health facilities. Mean patient delay was 7.3 days and on average each patient visited more than three health facilities before being diagnosed. These trends did not improve much over the study period. During the course of health seeking, only 17% of the total visits were paid to government hospitals. Mean total health system delay (constituted as diagnosis delay: 37.7 days + treatment delay 6.3 days) was 44 days. Diagnosis was based on rK39 rapid test for 93.7%, Amphotericin-B (45.5%) and Miltefosine (23.5%) were the most common treatments while 19.3% received some combination therapy, 11.8% received abandoned antimonial treatment. Of 332 patients, though 35.5% were diagnosed at public hospitals, only 22.3% of them took final treatment there. Remaining patients moved to either NGOs (47%) or private qualified doctors (30.72%). Conclusions Incidence of VL in the HDSS area sharply declined over the past 8 years. Patients usually present early but most of the time they present to unqualified providers despite free diagnosis and treatment available and recent incentives introduced to make patients come to public hospitals. They still incur substantial health system's delays. An open source API for real time drug prescription monitoring at the point of care in low resource settings Introduction Drug prescription errors, such as ignoring relative or absolute drug contra-indications (DCI), often result in harm to patients. Exposure to a potential drug-drug interaction (PDDI) already happens in the case of the prescription or administration of two or more drugs that can interact, even if no harm ensues. Such interactions involve drug combinations for which physiological data exists from clinical studies pointing to a potential interaction or a potential interaction can be inferred based on extrapolation. Due to insufficient training of prescribers, inconsistent use of uniform prescription charts and the unavailability of automated drug prescription monitoring systems, these errors are common in low resource health facilities. Aim The purpose of this study was to develop an open source, standards based monitoring system for DCI and PDDI that can be integrated in clinical information systems at the point of care in low resource settings. Methods A middleware prescription monitoring API (PMAPI) was developed, accepting clinical information based on ICD10 codes and drug prescription data formatted in ATC and RxNorm codes. The input is submitted to a publicly available web service provided by the National Library of Medicine, interfacing to DrugBank and ONCHigh. The output, originally in English, is automatically machine-translated using the EURODICATOM API into 9 target languages matching the enduser interface. The middleware API has been integrated in the open source hospital information management system OpenClinic GA. It enables mapping of pharmaceutical products from local formularies onto ATC and RxNorm codes. The PMAPI monitors DCI and PDDI in real time in the background, caching results locally for better performance and to ensure system availability for already known DCI and PDDI even when the internet goes down. Warnings are generated for severe DCI and PDDI. Retrospective automated PDDI evaluation based on the PMAPI was performed on 311 844 patient encounters with at least 2 drugs prescribed in 4 national reference hospitals in Rwanda, Tanzania and Burundi. One or more severe PDDI were detected in 69.612 encounters (22.3%). The freely available open source PMAPI can be an important instrument for reducing drug prescription errors in low resource settings. Defining a supervision strategy using artificial intelligence (AI). The case of data supervision for the results based financing intervention in Benin Introduction To design Public Health intervention, Ministries of Health have to compile and analyze, wide variety of data types from many data sources (surveys, routine data, epidemiological reports, etc.). Making sense of this complex set of data and choosing the most appropriate interventions based on the available evidence, all of these tasks require complex data modeling, and the help of Artificial Intelligence (AI). In Benin, a RBF system has been introduced in 2012. The program has been progressively extended to 34 health districts in the country, covering around 23% of the population. Each month, health facilities send a report of the services they provided during the month. This data was systematically verified through on-site supervisions. One important question was related to the high cost of data supervision. These costs were reaching 30% of the total budget of the program, and 92% of the supervisions were more costly that would have been occurred by directly paying the reported data, and program managers were wondering what a less costly to data monitoring could be. Objectives The purpose of this study was to define AI processes to predict the results of different supervision strategies. Methods Data collected by the RBF team and available here (www.beninfbr.org), have been processed using 3 different algorithms. The algorithms we used have three parts: a data processing part where reported data is modelled and predicted, a trigger which defines pathological situations where a supervision seems necessary, and finally an implementation strategy that ensures regular supervision for each facility. For each algorithm, for each facility, we simulate what would have happened if this algorithm had been used in the past. We compared the overall cost of different algorithms and the distribution of different types of costs for each algorithm. It shows that all three supervision algorithms allow a diminution in total cost of the program. Meanwhile, two algorithms made this reduction happen through a limited diminution of supervision costs, still keeping overpayments to facilities in check, while in the meantime, the last algorithm achieved a quasi-similar result by lowering drastically supervision costs, and allowing undue payments to become higher. Aim The purpose of the study was to develop a set of simple metrics with predictive value for the performance of clinical data registration in hospitals, providing a building block for future quality of care measurement in HIMS. Methods A reference set of 1511 electronic patient records was manually scored for clinical data completeness. A series of 11 simplified, easy to measure candidate primitive metrics for predicting completeness of clinical documentation in health records have then been calculated on the same set of records and correlations between the candidate metrics and the manual clinical data completeness scores have been evaluated. The study resulted in the identification of 4 primitive metrics with statistically significant predictive value (r > 0.75 with P < 0.01 for F-Test, confidence level 95%), namely: (i) the clinical document density, (ii) the information density, (iii) the reason for encounter density and (iv) the diagnostic density. Reference values for each metric have been calculated for outpatient and inpatient settings, targeting >70% and >80% clinical documentation completeness. The study produced 4 primitive, easy to calculate metrics, predicting the completeness of clinical documentation. They have been integrated in the OpenClinic GA HIMS package that is being deployed by the Ministry of Health in the public hospitals of Burundi. The metrics are early building blocks for the future development of a more comprehensive solution for quality of care evaluation and their isolated or individual use is insufficient for measuring the quality of clinical services provided in health facilities. Connecting the unconnected in sub-Saharan Africa: nondiscriminating access for digital inclusion with an emphasis on health (DigI) Introduction Free access to information technology for everyone is of utmost importance to foster equitable distribution of digital health information. However, huge gaps need to be filled in sub-Saharan Africa that are partly due to the lack of sustainable health message distribution platforms. Thus, the main objective of DigI, a 3-year funded project from the Research Council of Norway (NFR) and the Norwegian Government, is to establish pilot projects for the InfoInternet access in Tanzania (TZ) and The Democratic Republic of the Congo (DRC). DigI collaborates with CYSTINET-Africa, a large health network in eastern Africa with a focus on neglected tropical diseases, exemplified by Taenia solium cysticercosis, funded by the German Ministry of Education and Research. Aim (i) Empower people by bridging the digital gap through free access to the Digital Global Health platform, (ii) encourage stakeholders to support a sustainable business model including free access to health information and (iii) pilot digital global health and establish key performance indicators (KPI) for the uptake of digital health information. Methods DigI encompasses 11 partner organisations from 7 countries, which will establish and promote digital health information and content at health posts. The above-mentioned pilot projects will be evaluated, and the InfoInternet will be established as an independent and self-sustainable information, communication and technology infrastructure for digital inclusion. Specific attention throughout the project will be given to diseases like HIV/AIDS, bovine tuberculosis, Taenia solium cysticercosis and anthrax. Mixed methods will be employed. Indepth interviews (qualitative) will be used to measure the experienced change in empowerment. Quantitative methods, such as a randomized control trial, will be used to measure the KPIs and the change in knowledge, attitudes and practice (KAP) with regards to the uptake of digital health information. Project status Digl has established the ontology for the Digital Global Health platform, and is currently translating this ontology into a framework. Main focus will be on open interfaces towards other Global Health platforms, opening for a distributed Knowledge Centre for Global Health. In parallel, the selection of villages is ongoing to allow for pilot installations of free health information access. Digitizing routine health facility assessment in low-resource settings A. Legrand and N. Nembetwa Bluesquare, Brussels, Belgium Introduction In low-resource settings, ministries of health (MoH) struggle to locate their health facilities. This situation prevents them from conducting efficient interventions to guarantee universal access to health services. In DRC, the national HMIS and PDSS (a Performance Based Financing project) teamed up to develop a tool that routinely assesses health facilities. Objectives The purpose of this project was to develop a tool and a process that allows the MoH to build and maintain a health facility registry. Methods A provider built mobile data collection application for staff to collect and send data using tablets. Data Collect is an offline ODK/ONA based application that is connected to DHIS. This application is linked to a DHIS2 database from which data are published on a public online dashboard. MoH staff and PDSS built a questionnaire to collect key information such as facility type, availability of drinking water, electricity, staff, geolocations, and pictures. The application and tablets are used by the staff in thirteen provincial health management units (DPS in French). These teams were trained on how to use the tool for quarterly facility assessments. Since the beginning of the project, more than 1700 health facilities were identified and were geolocalized. Conclusion A digital tool can speed-up data collection when building a health facility registry and make it easier to share information with all stakeholders. Is health protected: life histories of vulnerable groups in fragile and conflict-affected situations Introduction Health-seeking, availability of health services and health financing policies in Cambodia, Sierra Leone, Northern Uganda and Zimbabwe were examined pre, during and post-conflict. To cope during these periods, individuals and households had to devise health-seeking strategies to overcome unavailable and unaffordable services as well as insecure environments. Aim This study explored health-seeking pathways, and what and why different choices were made pre-, during and postconflict. It also sought to understand the implications on household budgets, the coping mechanisms and the role of health financing policy. Methods Primary data was collected over two years from Results Many respondents showed their resourcefulness and agency throughout the three periods. The absence of formal mechanisms during conflict meant they usually turned to traditional practitioners, borrowed or sold household assets or turned to their family and friends to meet costs, or avoided health care altogether. Other changes arose from being older, and especially having a chronic illness, which meant they were no longer able to fully engage in income generation. The implications were further impoverishment and a high dependence on kin/social networks for informal social protection. Post-conflict, the re-introduction of formal social protection mechanisms were important for recovery but poorly supported; these included the Health Equity Fund in Cambodia, free health care in Northern Uganda, the Free Health Care Initiative in Sierra Leone and the Assisted Medical Treatment Order in Zimbabwe. However, they were not adequately supported nor accessible to all vulnerable groups, particularly those who were chronically ill, disabled and/or elderly. Conclusion Life course changes explained some of the shift in health problems but the difficulties in seeking adequate care reflected more structural problems: poor governance, a failing economy and inadequate state social provisions before, during and after the conflict. Recent health policies intending to provide social protection have had limited or unsustainable success, suggesting the need for both more robust implementation of health financing policy but also a recognition of the range of vulnerable groups. Methods We systematically searched three databases for articles published between 2005 and 2016 on India's ASHA program. Articles that met the inclusion criteria underwent data extraction and synthesis using the framework we developed that identifies core CHW program elements. Results 117 academic articles were identified, of which 55 were quantitative, 27 mixed methods, 24 qualitative, and 11 commentary or synthesis. 47 articles reported on small-scale interventions that engaged ASHAs, such as mHealth trails, disease screening initiatives, or mental health support programs. While these interventions showcased innovation, they tended to take a vertical, technology-or disease-oriented approach that overlooked the complex health system requirements of a program at scale. Articles focusing on typical ASHAs highlighted their negotiation with family, community, and other health workers in order to perform their roles in the context of gendered expectations at home, caste-based social norms, and poverty. ASHAs value opportunities to earn remuneration, learn, enhance their family and community's health, and gain social standing. While health policymakers and ASHAs themselves are generally eager expand their role, ASHAs require improved incentives and payment systems, enhanced training to address significant knowledge gaps, and broader health system supports (e.g. functioning health facilities, supply chains, supervision). Conclusion Academic work on the ASHA program would benefit from greater application of systems thinking approaches that positions ASHAs within the broader health and social system. As the program continues to evolve, ongoing research is vital to address key knowledge gaps and provide insight into ground realities, including on program governance, intersectoral linkages, ASHA solidarity, and community capacity to provide support and oversight. Reasons for not attending a health care centre for soiltransmitted helminth infections in a rural village in Indonesia Aim To explore reasons why people do not attend health centres when they suspect STH infection. Methods We conducted a qualitative study in October-November 2016 and used in-depth interviews to gather information from community members, health care providers in the village and policy makers. We asked them about their knowledge of STH, their perception of STH as a health problem, and their preference for different treatment options. All interviews were audio-recorded and subsequently transcribed. Data were coded and categorised into several topics and themes. We then interpreted the themes that arose from the study. This study was carried out in the framework of an international study on persistant digestive disorders within the NIDIAG project (www.nidiag.org). Results Worms in stool, bloating abdomen, anal itching, and loss of appetite were considered as an indication of STH infection. This was perceived as a non-severe disease. Most of the study participants admitted that they (or one of their family members) had experienced STH infections. When they suspected that they had STH, they would immediately buy an antihelminthic drug (i.e. Pyrantel pamoat or Combantrin â ) at low cost in the village pharmacy. This drug was considered to be very effective to cure STH infections; people told that they would find worms in their stool the next day or even several hours after taking the medicine. Therefore, they argued that they did not need to go to a health centre unless a person develops fever, or when the symptoms persisted. Although the study participants considered that defecating outdoors is the most important risk factor for STH infections, this practice remains very common. Conclusion Villagers acknowledge that STH infections are very common. They consider that they are able to recognise and treat these infections without the help of a health care centre. Although they understand the risk factors for transmission, changing behaviour seems difficult. Mid-term evaluation results of improvement in medical interventions and midwifery care in five medical regions in Senegal Introduction This project (PRESSMN2) aims to enhance utilisation of facility-based services and to improve quality of care in maternal and neonatal health. It consists of facilitation of dialogue between health facility staff and community members, practice of evidence-based and humanised care, improvement of working environment with an idea of 5S-KAIZEN, and support for resources (financial, human, and material) from local administration body. The activity involves 5 regions (Dakar, Fatick, Tambacounda, Kedougou, and Kolda) since the year 2013. For the intervention, one district is selected from each region. A pilot unit, which consists of one health centre and three health posts, is selected as intervened site in each district. Main part of the interventions are training on evidence-based humanised care for health staff and trimestral supportive supervisions. Aim We carried out a mid-term evaluation survey, which intends to confirm changes in care to women during delivery and to neonates in the intervened health facilities. Methods Two types of evaluation methods were employed: one is to compare the changes before (baseline: December 2012) and during (midterm: March 2016) the intervention in the five regions; another is to compare the five intervention and three non-intervention regions in the year 2016. Pearson's chi-square test and multiple logistic regress test were applied for univariate and multivariate analyses. Results Routine application of potentially harmful interventions (e.g. restriction of drink and food, administration of analgesics and diazepam, administration of oxytocics during the first and second stages of labour, administration of continuous drip infusion, amniotomy, supine position in the second stage, massage of perineum, fundal pressure during the second stage, uterine revision) were significantly decreased in the mid-term survey compared to the baseline in the intervention area. Conclusion It has revealed that the project activity reduces unnecessary and potentially harmful medical acts during labour. It may be achieved through facilitation of dialogue with pregnant women and appropriate adjustment of demands and needs. It implies that quality of care during delivery process can be improved in a resource-limited setting in Sub-Saharan African countries with an external technical support. Methods We used a longitudinal mixed method on the monthly monitoring data collected from 12 months before the project start to the end. The outcome indicators were day 6-10 PPC, week 6-8 PPC, PP family planning counselling, the management of PP morbidity in mother and infant. We tested the significance level of the changes in the different indicators by performing an interrupted time series analysis with Newey-West standard errors and one lag. Additional data were extracted at the individual level that allowed to link infant immunization with maternal PPC from September 2013 to august 2014 in the health facilities (HF) PP and immunization registers. We also conducted a review of documents that allowed for a qualitative evaluation of the effects. Results Results show an increasing trend of all monitored indicators during the interventions, particularly at day 6-10 when PPC increased from 61% in 2013 to 81% in 2015 and especially in rural areas (P < 0.05). We found large improvements in the detection and the management of PP Hemorrhage, sepsis in the mother and newborn fever or low temperature. However, the intervention was less successful in raising PPC at week 6-8 and later due to the existence of structural barriers for instance due to lack of collaboration among health workers and high turnover in the staff of HF. Conclusion The overall package of community and facility interventions contributed to improve integrated PPC at day 6-10, particularly the role of community health workers. While the integration of maternal and Child health services seem to be a valid concept it needs to be rethought within the primary health care system. Supporting community health worker programs at scale: lessons from policy reforms shaping the evolution of India's ASHA program Aim To understand how ASHA government policy has evolved including issues of policy coherence, responsiveness to challenges and opportunities, and adaptation to changing priorities. Methods All policy documents in the public domain on the ASHA program were gathered (n = 96). Key informant interviews (n = 12) were conducted with policymakers and advisors involved in supporting the program from its inception. Data was extracted using a framework of core programmatic considerations including roles and activities, training, incentives, supplies, and governance. Synthesis involved examining the framework by theme, mapping policy events on a timeline, and integrating reflections from key personnel. The character of the program has evolved through a variety of policy reforms. From an initial focus on family planning, the ASHA's role broadened to linking communities with the health system, educating, providing basic healthcare, and engaging in local health activism. Similarly, an early focus on the ASHA as the centre of community health programming shifted to a comprehensive community processes strategy in which the ASHA is just one integrated component. The impetus for this evolution can be traced in part to civil society inputs. The number of incentivized tasks for ASHAs has grown and ASHAs require increasingly complex skills across a wide range of disease areas. Policy documents on ASHA selection grapple with the tension between including marginalized women and selecting women with sufficient education to perform their roles. ASHA wellbeing has been increasingly noted as a concern and is linked to the need for system-wide gender mainstreaming. Improving ASHA safety, career progression, and financial security remains on the policy agenda. Conclusion The policy document review and reflections from key personnel highlight that even with significant investments in policy and program design, national CHW programs face policy tradeoffs that require adaptive learning. Assessing and preparing health systems for integration of services in low-and middle-income countriesa systematic review Introduction Despite growing support for integration of frontline services, a lack of information about the pre-conditions necessary to integrate such services hampers the ability of policy makers and programme implementers to assess how feasible or worthwhile integration may be. This is particularly so in low and middle income countries (LMICs). Aim This review aimed to synthesise evidence relating to health system preparedness for successful health service integration in LMIC settings. Methods We adopted a modified systematic review incorporating aspects of realist review, including quantitative and qualitative studies that incorporated assessment of health service or health system preparedness and capacity to implement integrated services. We searched Medline via Ovid, Web of Science and the Cochrane library using terms adapted from Dudley and Garner's systematic review on integration in LMIC. An initial list of 10 550 articles were subject to two rounds of title and abstract review, with 206 articles selected for full-text review. Two reviewers independently reviewed articles and inductively extracted and synthesised themes relating to health system preparedness. Results Five 'context' related categories, and four health system 'capability' themes were identified. Mapping against traditional health system building blocks, contextual enabling and constraining factors for frontline service integration were: (i) the organisational framework of frontline services, (ii) health care worker preparedness, (iii) community and client preparedness, (iv) upstream logistics, and (v) policy and governance issues. The intersecting health system capabilities identified were the need for: (i) sufficiently functional front-line health services; (ii) sufficiently trained and motivated health care workers; (iii) availability of technical tools and equipment suitable to facilitate integrated frontline services and (iv) appropriately devolved authority and decision-making processes to enable frontline managers and staff to adapt integration to local circumstances. Conclusion Moving beyond claims that integration is defined differently by different programs and thus unsuitable for comparison, findings from this systematic review demonstrate that synthesis is possible. We present a common set of contextual factors and health system capabilities considered necessary to enable successful frontline health service integration. These findings could be adapted into a health system preparedness assessment tool for future integration efforts. *Joint first author. Models of engagement between the state and faith sector in Sub-Saharan Africa: a systematic review E. B. Whyle and J. Olivier Health Policy and Systems Division, University of Cape Town, Cape Town, South Africa Introduction In sub-Saharan Africa (SSA), many individuals rely on non-state health providers, and engagement between state and non-state providers is increasingly common. Faithbased health providers constitute an important source of care for many in the region, and are commonly being integrated into national health systems through various partnership arrangements. Little analytic research has been conducted on the various models of engagement, and research of sufficient depth to support the development of context-relevant guidelines is scarce. Aim The aim of this research is to identify and categorise the mechanisms for public-private engagement (PPE) involving the faith sector in SSA. Methods This reports on a secondary analysis and synthesis of two review projectsthe first, a Campbell systematic review on PPE in SSA, and the second, an ongoing systematic review and resulting database of materials on religion and public health (held by the International Religious Health Assets Programme). Together these provide a comprehensive collection of literature on the cross-cutting topic. Analysis consisted of the application of a developed typology of models of PPE (1). Results Forms of engagement with the faith sector align closely with generic PPE models (engagements between the state and secular non-state organisations). However, one particular type of partnershipthe relationship between national faithbased health networks (NFBHNs) and the stateis not captured by the original typology and is best described as a unique combination of two generic models. This relationship highlights the complexity of PPE with the faith sector, which presents a network of entities including various types of faith based organisations, donors and government bodies. The scale of faith-based involvement in SSA health systems is such that, for many countries, health systems strengthening necessitates strengthening relationships between NFBHNs and the state. This endeavour is hampered by the unique nature of the partnership, and by the common failure to account for the complexity of the faith sector. Methods We adopted realist evaluation approach, used the embedded case study design. We used the most comprehensive evaluation data available to date on this policy process, and collected additional qualitative and quantitative date within the FEMHealth research programme. Results Besides the state-owned facilities, government decided to include not-for-profit non-state actors, rather than engaging all the non-state actors, on the basis that the former shared the value of public oriented services and that they thus could be trusted to implement the policy. However, we found that nonstate facilities kept charging the patients €30 extra even though the reimbursement is higher than the previous tariffs. We found that in contexts where the public administration is seen as too bureaucratic, and unreliable in its financial procedures, managers perceive a fee exemption policy as a threat, especially if out-of pocket payment is a key financing mechanism. In such cases, charging an extra fee is a safety measure, grounded on mistrust in government. Fully free access of services requires trust between non-state actors and government. Trust is likely to be facilitated by (i) removing the risk of losing resources, for instance by setting up an agency, with simple, transparent and fast administrative procedures and refunds; (ii) compensating short-term financial loss in case of delayed reimbursements; (iii) fairness in resource allocation between state and non-state owned hospitals. This requires equity rather than equality, in contexts, where public investments in non-state facilities were low before the policy. Conclusion This study showed a dynamic interplay between political needs, power and trust at the interface between the public and private health sector in Benin, a low-income country. Trust plays a key role in this interaction and is a vital element for low-income countries to achieve universal health coverage. The politics of the basic benefit package reforms in Tajikistan: health governance constraints in neo-patrimonial settings E. Jacobs 1,2 1 KIT-Health, Royal Tropical Institute, Amsterdam, The Netherlands; 2 Instiute for Sociology, University of Basel, Basel, Switzerland Introduction Little regard has been given to the political dimensions of Tajikistan's health reforms in recent years. However, a consideration for the political factors at play, their effect on policy formulation and in turn the effects for policy implementation that this creates, can offer new insights for what matters in these processes, particularly in neo-patrimonial settings like Tajikistan. The Basic Benefit Package reform regulates entitlements to a guaranteed set of healthcare services for patient and social groups exempt from user fees, while strengthening primary health care and introducing co-payments for all other groups. Aim This study contextualises and assesses the design and implementation of this reform in order to identify the main governance constraints to health policy implementation. The study draws on literature review, focus group discussions, semi-structured and in-depth interviews conducted with government staff, health personnel and donor officials. The main factors that impede the BBP reforms in Tajikistan include weak bureaucratic capacity, severe underfunding and rigid input-based budgets, unclear and competing mandates between government actors at both central and local levels, and short term, fragmented planning and management. Conclusion The evidence suggests that policy fragmentation can be directly linked to the neo-patrimonial character of the regime and donor behaviour, the interplay of which poses challenges to premises underlying the aid effectiveness paradigm. Lessons for external donors and policymakers that can be drawn from this research include a need to for joint long term horizon planning, strong mandates and central support for new positions at local health reform implementation level, and a stronger alignment between health financing and service delivery performance with due flexibility for creative decision-making. Introduction Plasmodium falciparum malaria remains a major public health concern. Using good-quality antimalarials is a key component in controlling this disease. However, in Central Africa, over 25% of medicines (drugs) would be counterfeit or of poor quality (substandard), with the situation in peri-urban areas being even more dramatic. Aim In order to raise the awareness of the periurban populations, a study was carried out which aims at assessing the existing situation as for the level of health in periurban pharmacies of Kinshasa. Methods In the afore mentioned context, a preliminary and prospective study was conducted in the health zone of Mont Ngafula 1 located in the periurban area of Kinshasa, from February 22 to March 28, 2016. Thirty samples of powder for suspension of Artemether and Lumefantrine were collected. The quality analysis of these drugs was carried out using generic separative methods using the high-performance liquid chromatography (HPLC) technique with a diode-array detector. A characterization was also carried out in 127 pharmaceutical establishments, based on the standards laid out by the Congolese Ministry of Public Health. The results of analyses of antimalarial samples showed that one powder for suspension of artemether and lumefantrine out of three (33.3%) did not contain the expected artemether and/or lumefantrine concentration. Moreover, the results of the observations indicated that no pharmaceutical establishment complied with all the standards of the Ministry of Public Health. Conclusion This study showed that in the peri-urban areas of Kinshasa, one sample out of three (33.3%) of the Artemether-Lumefantrine combination is non-compliant, the suspensions are under-dosed. Existing pharmacies do not meet all the minimum standards set by the Ministry of Public Health of the DRC. The impact of local private distributors on quality of medicines available in non African low-and middle-income countries Methods We conducted a secondary quantitative analyses of data from the database of QUAMED (www.quamed.org), using the same evaluation tool used for the analysis of SSA data. The tool, inspired by the MQAS, includes 5 criteria representing the key-phases of a quality assurance system, i.e. Selection of Sources, Good Distribution Practices, Cold Chain Management, General Quality Requirements and Quality Control. Descriptive statistics were used to describe the distributors' compliance with each criterion. The MQAS-compliance was generally low, and this especially for Selection of Sources and Quality Control. Conclusion Poor-quality medicines is often considered as a problem typical of SSA. Although our results are based on a small, convenient sample, they suggest that private distributors in non-SSA LMICs may also have poor compliance with WHO quality standards, especially concerning the selection of products and suppliers, and the ongoing quality control. As long as this does not improve, there is a concrete risk that patients are exposed to poor-quality medicines, even when Good Distribution Practices are implemented. Adequate guidance for the quality systems of pharmaceutical distributors in the private sector, as well as strengthening the National Drug Regulatory Authority supervision, is urgently needed to ensure the quality of medicines within and outside Sub-Sahara Africa. Procurement Centers (APCs) must observe stringent quality management, systems and procedures to ensure availability of health and pharmaceutical products. Central Humanitaire M edico-Pharmaceutique (CHMP) was founded in 1992, as a pharmaceutical APC, to support access to quality medicines among the non-governmental sector in Kenya and across the region. Aim This experience describes gains realized by redirecting internal and external quality management and regulation systems towards strategic markets. Methods In 2012, CHMP revised its strategic focus towards strengthening internal quality policy, and internationally enhancing its external partner network across the region. The CHMP Quality Assurance (QA) budget increased by 70%. The investments targeted three priorities: the strengthening of human competences, the development laboratory controls and the validation of sources. CHMP has 3 people dedicated to the Quality Assurance, a partnership with three WHO approved laboratories and all suppliers are audited every 3 years. A rewarding choice which granted the ECHO and USAID certifications. Externally, the CHMP joined networks such as Quamed (www.quamed.org), joining together of NGOs and purchasing groups that pooled resources to audit their suppliers according to stringent quality criteria, and shared the gained knowledge, to further assured the quality of procured products. The investments in QA contributed to an increase of the sales by 60% near its strategic customers. Collaboration with partners allowed the pre-qualification of new manufacturers on the Asian market concerning 35% of the most required products by ONGs and shortens the supply chain allowing a reduction of purchase prices on average of 40%. Our experience shows that APCs must be anchored in a collective and participative approach where they shared information on validated sources. The economies of scale achieved allow a better resilience to the regulation and competition issues on the African pharmaceutical markets. Conclusion This approach highlights that quality assurance and control investments in APCs, though intially financially burdensome, improve central and end-user health systems, and therefore public health outcomes. Though this approach demonstrated successful in our setting, further research should examine cost-effective quality mechanisms and the participatory function of NRAs in public-private partnerships for improved health delivery. A health system perspective to improving pharmaceutical supply: lessons from Zimbabwe Introduction Assessments to improve pharmaceutical systems are typically limited to the WHO health system 'building block' of medicines, focusing on the procurement and supply chain management of medical products. This approach ignores the often-complex interconnections between medicines and the other health system blockslike health financing, human resources, or health informationand discourages an understanding of the dynamic linkages between them. In Zimbabwe, a health system assessment was conducted in 2016/2017. It included an in-depth analysis of the pharmaceutical system, human resources for health (HRH) and result-based financing (RBF) as the key cost drivers within the health sector, as well as interconnections between the different building blocks. Aim The presentation provides a description of this overall assessment from a medicine perspective, and draws out challenges and lessons learned. Methods The health system assessment was conducted by experts in the three focal areas and guided by a national technical steering committee chaired by the Ministry of Health. It drew on mixed methods, including analysis of key national documents and reports, key informant interviews, and primary data collection during field visits. Findings and options for reform were discussed with stakeholders in two national workshops. Results A wide range of immediate and longer-term actions were agreed with stakeholders, within and cutting across the three focal areas. For medicines, a number of recommendations were directly related to the other health system areas of HRH and RBF. These included a review of curricula and use of capacity development approaches to shift tasks to lower-level pharmacy cadres, the inclusion of relevant RBF indicators to incentivize proper stock management, and setting up long-term agreements with private wholesalers enabling facilities to procure medicines against competitive prices with RBF funding. Conclusions The assessment conducted in Zimbabwe used an integrated approach to health system strengthening, combining expertise in pharmaceuticals, HRH and RBF and encouraging linkages between three key building blocks. Recommendations in all three components were discussed with and agreed upon by a wide variety of stakeholders, thereby creating buy-in from decision-makers and donors, and increasing the likelihood of effective follow-up and implementation of agreed actions. Tracing Africa's progress towards implementing the Non-Communicable Diseases Global action plan 2013-2020: a synthesis of WHO country profile reports Introduction Half of the estimated annual 28 million noncommunicable diseases (NCDs) deaths in low-and middleincome countries (LMICs) are attributed to weak health systems [1, 2] . Current health policy responses to NCDs are fragmented and vertical particularly in the African region which is expected to experience the largest increase in NCD related mortality globally. The World Health Organization (WHO) led NCDs Global action plan 2013-2020 has been recommended for reducing the NCD burden but it is unclear whether Africa is on track in its implementation. reports were used for this analysis. We synthesized results by targets descriptions in the three reports and included indicators for which we could trace progress in at least two of the three reports. Results More than half of the African countries did not achieve the set targets for 2015 and slow progress had been made towards the 2016 targets as of December 2013. Some gains were made in implementing national public awareness programmes on diet and/or physical activity, however limited progress was made on guidelines for management of NCD and drug therapy and counselling. While all regions in Africa show waning trends in fully achieving the NCD indicators in general, the Southern African region appears to have made the least progress while the Northern African region appears to be the most progressive. Conclusion Our findings suggest that Africa is off track in achieving the NCDs indicators by the set deadlines. To make sustained public health gains, more effort and commitment is urgently needed from governments, partners and societies to implement these recommendations in a broader strategy. African institutions such as The African Union (AU) and other subregional bodies such as West African Health Organization (WAHO) and various country offices need to play stronger roles in advocating for more NCD policy efforts in Africa. Introduction Diabetes mellitus has become a public health issue in Cuba. Global diabetes prevalence is estimated at about 10% and it is currently the eight cause of death. Aim To describe the presence of key behavioural factors and clinical complications in the type 2 diabetic population of the Cuban municipalities of Cardenas and Santiago in order to pinpoint problems with diabetes care. Methodology A cross-sectional study using stratified 3 stage sampling was conducted. The strata were the 2 municipalities and the sampling units were policlinics, family doctor practices and diabetic patients. The total sample size was 1450 patients (750 in Cardenas and 700 in Santiago). Socio-demographic and clinical variables and the prevalence of key risk factors for complications were assessed. Compliance with treatment was measured using the Mart ın-Bayarre-Grau test. The most frequent age group in diabetic patients was 60-79 years (57%); 70.6% were female and 82.7% had completed secondary school or higher. The most frequent comorbidities were hypertension (73%), overweight or obesity (68.1%) and dyslipidaemia (26.6%). Thirty-nine percent of the patients had a disease duration of 10 years or more. Sugary drinks (66.8%), physical inactivity (64.3%), alcohol intake (34.1%) and smoking (18.7%) were the most important behavioural risk factors. The majority of patients (82.8%) was on pharmacological treatment but among them 54.8% was not compliant with the prescribed treatment scheme. The complications most frequently reported were peripheral neuropathy (40.2%), peripheral vascular diseases (29.7%), retinopathy (9.9%) and chronic renal failure (6%). Conclusions Low prevalences of complications such as retinopathy and renal failure may indicate adequate long-term control of diabetes by primary health care services. The majority of problems with diabetes care is related to behavioural factors, which may reflect the important medicalization of the health system. However, non-compliance with pharmacological treatment also warrants the attention. Improvement strategies should be mainly centred on increasing physical activity and on the control of sugary drinks. Aim This study aimed at assessing preparedness of lower level health facilities to manage hypertension in Tanzania. Service Provision Assessment survey. The primary outcome variable was 'preparedness' of facilities which was rated as an index and categorized into three domains: (i) availability of trained staff and guideline, (ii) availability of basic diagnostic equipment and (iii) availability of first line drugs. WHO approach was used to calculate a composite score. Facilities with index scores of at least 50% were considered to be prepared. Data were analyzed using Stata 14. An unadjusted logistic regression model was used to assess association between variables. All variables with a P value < 0.2 were fitted into the multiple logistic regression models using a 5% significance level. Results A total of 725 facilities were involved in the survey. Out of these, 95% were from mainland Tanzania, 68% public owned and 73% located in rural settings. Only 28% of the surveyed facilities had high level of preparedness/capacity for the primary care of hypertension. Guidelines were present in only 42% of facilities and 9% had trained staff. Only 5% of the facilities had all the required equipment; 18% of the health centres and 6% of the dispensaries had all the recommended first line drugs available during the survey. In multivariate analysis, private owned facilities (AOR 3. Conclusion The primary healthcare system in Tanzania is not adequately equipped to cope with the increasing burden of hypertension and other non-communicable diseases. Rural location, public ownership and absence of routine management meetings were associated with low preparedness. There is a need to strengthen the primary healthcare system in Tanzania to cope with the increasing burden of non-communicable diseases. Results Thirty-one relevant documents were included in the analysis. Diabetes features prominently within the wider context of NCDs in high national policy documents, also earmarked for action within Kenya's development agenda for health. Most documents and national strategies guiding the implementation process align strongly to international documents, however based on little locally generated evidence. The process was largely health sector driven. The non-health sector, despite its prominent role in disease risk factor modulation remained almost entirely excluded. This, in addition to weak monitoring systems continues to undermine existing gains and current efforts in fighting diabetes in Kenya. The UN declaration coincided with a period of political transition in Kenya, opening policy windows leveraged by civil society organisations and interest groups to trigger the political drive needed to get diabetes and NCDs more attention within the local agenda. However, the existence of policies to date does not translate into progress towards reversing the NCD burden. More emphasis on population-wide prevention that leverages existing structural systems, and more inclusion of the non-health sector in the process, especially from the onset could present opportunities to trickle down national efforts to the community level. Nurse mentoring as a means to improve quality of obstetric care in Bihar, India Care (BEmONC/CEmONC) are vital for improving management of obstetric and neonatal conditions leading to pregnancy-related morbidity and mortality. An intervention to improve quality of care provided at public health facilities was conducted in Bihar in 2014-17, by mentoring nurses in BEmONC/CEmONC through a nine month mobile nurse mentoring program. Mentoring was delivered in four phases to nurses in nearly 400 public health facilities. The program focuses on normal delivery, neonatal resuscitation and other essential BEmONC/CEmONC services. Aim The study aims to understand the effect of mentoring on nurse knowledge and skills. ) aligned with mentoring curricula were designed and administered to two groups of nurses (n = 315), one who had undergone training and one without. Vignettes were administered by trained nurse enumerators, using simulations on MamaNatalie and NeoNatalie. Respondent scores were averaged for critical indicators under the domains of history taking, physical examinations, diagnosis, and management for each case; these scores were then averaged to obtain case-specific scores. Case-specific scores were averaged to obtain overall competency (OC) scores. Propensity score matching (PSM) using different matching methods was conducted to obtain average treatment effect on the treated (ATET), for each case. Results Average scores were: mentored ND: 58.6%, PPH: 59.1%, NNR: 60.1%, PE: 43.5%, OC: 55.3%; comparison ND: 58.1%, PPH: 55.2%, NNR: 51.7%, PE: 40.9%, OC: 51.5%. In all cases and OC mentored group performed at par or better than comparison in completing necessary case management actions, with statistically significant improvements in management domains for all cases. Scores for the diagnosis domains under each case were similar in both groups. ATET estimates using kernel matching show that mentored nurses performed 5% more actions for PPH, 8% for NNR, and 5% for OC versus comparison nurses (P-value <= 0.05). Conclusion Competencies for BEmONC/CEmONC services are low for nurses at 51-55%. Mobile nurse mentoring has led to significant increases in knowledge and skills of mentored nurses for case management, which may translate into better quality of care. Factors associated with mental wellbeing of health workers in Malawifindings from a health worker survey using the WHO-5 Wellbeing Index Introduction In many low-income countries, health workers operate in an environment characterized by understaffing, resource shortages, and insufficient supervision and management support. Such conditions not only negatively reflect on patient care, but likely also affect health workers' own physical and mental health and wellbeing, posing a threat to the productivity of an often already short-in-supply workforce. To date, however, there is little research on this very relevant human resources for health (HRH) issue. Aim We assessed levels of and factors associated with mental wellbeing of mid-level cadres in Malawi. We conducted a structured health worker survey (n = 174) in 33 health facilities in 4 districts. Mental health was measured with the WHO-5 Wellbeing Index (WHO-5), an internationally validated screening tool which evaluates the full spectrum of mental health, capturing different levels of full or reduced mental wellbeing. We further included measures for a large range of individual characteristics and perceptions of and satisfaction with the working environment to assess their relationship with mental wellbeing. In addition to the health worker survey, we conducted facility infrastructure inventories to objectively capture health workers' working conditions. Results About 40% of our sample indicated relatively good mental health (i.e. scores of 75% or more of the maximum). In contrast, one third scored below the WHO-5 cut-off value (50% or less) for which WHO recommends more extensive testing for mental illness (particularly for depression). Factors significantly associated with mental well-being included availability of essential resources, higher staffing levels, more frequent supervision, fewer overtime hours, high job satisfaction, strong perceived social support and team work, and high perceived competence in regards to one's work. Conclusion Mental wellbeing of Malawian health workers appears to be a substantial burden that should urgently enter the HRH discourse given the severe health worker shortages in Malawi. Non-state providers responding to system changes: exploring the adaptive capacities of faith-based health providers in the Ecuadorian health system Introduction Responsive health systems require the engagement of different actors and sectors to improve systems capacity to adapt to changes and respond to people's needs. Existent evidence argues that faith based health providers (FBHP) can be adaptable, flexible and innovative and these characteristics make them good partners to build responsive systems. Some evidence on the adaptive capacities of FBHPs exists for Africa, yet little is known about the way FBHPs adapt and respond to system changes in Latin America and the Caribbean (LAC). Aim The aim of this research is to explore adaptive capacities of FBHP in the LAC region in respond to changes in health reforms, focusing on Ecuador. Methods This research responds to the findings of a twophase exploratory historical case study on FBHPs in Ecuador. This study explores the adaptive capacity of FBHPs in response to four national policies. The case was built on primary and secondary literary sources; surveys and interviews. Thematic analysis was conducted by following theories of organizational adaptation. Results FBHPs adaptability has been compromised by the impact that health reforms have had on their financial, administrative and operational capacities. This has pushed FBHPs to adapt their models of operation in order to legitimize their role in the system. The strengthening of organizational capacities has allowed FBHPs to align themselves to government priorities, reduce competition and become visible contributors in the health system. This ability to adapt was found to be related to the other common characteristics found in this sectorsuch as their ability to build on networks. Conclusion FBHPs have demonstrated adaptive capacities that have allowed them maintain their presence over time. They have shown greater flexibility in their structures and operations, which could be an important asset for health systems responsiveness, and makes them important potential partners for whole systems strengthening. However, in the current health system configuration this ability to adapt and innovate seems to be responding to a need to survive rather than to serve the health system. This has limited the responsiveness of this sector towards population needs. The ALMANACH Project: preliminary results and potentiality for Afghanistan Methods IMCI's algorithms were updated in considering latest scientific publications, national guidelines, innovations in RDTs, the target population's epidemiological profile and the local resources available. Before the implementation of the project, a direct observation of 599 consultations was carried out to assess the daily performance at three selected health facilities in Kabul. The baseline survey showed that deworming, vitamin A supplementation and nutritional screening were not systematically performed: few patients were diagnosed for malnutrition (1.8%), received vitamin A (2.7%) or deworming (7.5%). Physical examination was appropriate only for 23.8% of the diagnoses of respiratory or gastrointestinal diseases, ear infection and sore throat. Respiratory rate was checked only in 33.5% of the children with fever and cough, dehydration status was assessed in only 16.5% of the diarrhoea cases. Forty-seven percent of patients received incorrect treatment. Sixty-four percent of the children received at least one antibiotic, although for 87.1% antibiotic therapy was unnecessary. The review of 4859 paediatric consultations between May and February 2016 showed that with ALMANACH, malnutrition detection, deworming and Vitamin A supplementation dramatically increased. Antibiotic prescription decreased by 65% and all children were examined and treated in compliance with the protocols. Introduction Although quality antenatal care (ANC) is crucial for a positive pregnancy experience, resource constraints and weak health systems in rural Ghana hinder comprehensive ANC, necessitating diagnostic referrals for basic tests. Sociocultural barriers and poor service delivery further demotivate women from attending ANC, causing delayed identification and management of pregnancy complications. To address some of these challenges, an integrated non-invasive diagnostic mHealth kit-Bliss4Midwives (B4M) was launched to empower midwives in two districts of Northern Ghana. The kit facilitates instant informed point-of-care screening for pre-eclampsia, anaemia and gestational diabetes, for which women would otherwise have to travel long distances. The hypotheses that the kit is effectively adopted, that pregnant women are motivated to attend ANC and referral linkages are strengthened, is however yet to be tested. Aim Quantitative results of the pilot can tell us what works and the direction of effect, but cannot account for intended and unintended outcomes. A realist evaluation will therefore be conducted to explain B4M utilization, its influence on ANC quality and on referral linkages for women with high-risk pregnancies. Methods A before-and-after case study design is employed to test and refine program theories. Qualitative and quantitative data will be used to compare context (resources, structural and organizational norms), underlying mechanisms (responses and reasoning of users) and outcomes, within and between five health facilities in each study district. Results Data collection will be completed in July 2017 and subsequently analysed in line with realist methodology; identifying explanatory configurations of context-mechanismoutcome. Findings will be shared through dissemination meetings in project districts, and at the ECTMIH conference. Conclusion In light of implementation challenges in resource-limited settings, the promise that mHealth holds for maternal health requires further substantiation. Realist evaluation can provide explanatory evidence on how and for whom mHealth can be leveraged to improve quality of ANC, towards attaining global maternal health goals. Introduction Epidemics pose major threats in developing countries and surveillance tools for their early detection and response are often inadequate. In Senegal, since 2012, a disease surveillance team including the Institute Pasteur of Dakar (IPD) was organised to establish a sentinel syndromic-based surveillance system with the main goal of rapidly identifying outbreaks and issuing alerts. Aim To describe the steps involved in developing a sentinel surveillance system and the well-timed information it provides for improving public health decision-making. Methods The Senegalese sentinel surveillance network is currently based on data for fever and diarrheal syndromes collected by sentinel general practitioners (SGP). The SGPs were expected to communicate at least once a day encrypted short messages (number of fever cases, rapid test confirmed Malaria, Influenza Like illness and Dengue-like syndromes or Diarrheal disease) from smartphones. Standard WHO case definitions are used, to ensure comparability. Oropharyngeal swabs are randomly selected and analyzed for influenza and other respiratory viruses by multiplex PCR using CDC protocol and Anyplex II RV16 detection respectively. Malaria diagnosis requires biologic confirmation with a positive rapid diagnostic test in patients with fever syndromes. Blood samples was performed for all Dengue-like syndromes. Data are validated by the management team and analyzed daily at the IPD. In 2016, the sentinel surveillance system included 17 health centers and identified four (4) outbreaks confirmed: one with an increase in each of the following: Influenza-like illness indicators, RDT-confirmed cases of Malaria, Dengue-like syndromes and Diarrhea disease. Of the 184 971 visits to SGPs, 13.0% were related to fever syndromes. Of these 23 670 fever cases, 42.3% were related to Influenza-like illness, 7.1% to Dengue-like syndromes, 11.4% to malaria cases confirmed by a specific rapid diagnostic test and 5.5% to Diarrhea. Conclusion Senegal's sentinel syndromic surveillance represents the country's first nationwide 'real-time' surveillance system. It has proved the feasibility of improving disease surveillance capacity through innovative systems despite resources constraints. Implementation of a web-based health information system: lessons learnt from a pilot study in the Free State Province, South Africa priorities including a web-based information system. The District Health Information Software (DHIS) platform for reporting and analysis of data is used by at least 40 countries, including South Africa which has used desktop DHIS since 2000. Previously, patient information in the Free State was recorded daily and compiled monthly on a data summary form at facility level and captured in desktop-DHIS at the subdistrict level. Each subdistrict exported data to the district and each district in turn exported data to the province for amalgamation. This process was marked by hardware, software and other technical challenges, such as unavailability of antivirus software, but also by lack of data use by clinicians. Web-DHIS was piloted from 2014 in an effort to improve data management processes. Aim To describe lessons learnt during Web-DHIS pilot, changes in data management and quality and remaining challenges. Methods Action Research (AR) entailing four phasesproblem diagnosis, planning, intervention and evaluationwas applied. Due to poor connectivity at facility level, data was captured centrally at provincial office. Data was recorded and compiled daily on a data summary form at the facility level. Clinics sent the forms to the provincial level for weekly capturing in Web-DHIS. Missing data and errors were communicated to the facility for correction. Software and technical challenges were handled at provincial level. Results Each intervention was informed by challenges and opportunities identified in the preceding phase. Web-DHIS improved data availability, reliability and use through its visualisation features as well as collaboration on data verification between province and districts. This has resulted in reductions in the number of outliers, capturing errors and substantially improved data completeness, but non-use of the data by clinicians due to computer illiteracy remained a challenge. Conclusion System change requires an understanding of the context and active participation of associated actors. Although Web-DHIS improved data management process, data quality and active participation of actors enabled effective system change, the use of health information by clinicians remains a challenge. A new vision for travel medicine: using mHealth and datadriven analyses to drive innovation Aim To identify the range of health outcomes during travel using real-time monitoring and daily reporting of health behaviors and outcomes via smartphone application and identify traveler subgroups who may benefit from more targeted advice before and during travel. Methods We recruited a prospective cohort of travelers ≥18 years planning travel to Thailand for <5 weeks from the travel clinics in Zurich and Basel (Switzerland). Participants answered demographic, clinical, and risk behavior questionnaires pre-travel, and a daily health questionnaire each day during travel using a smartphone application. Environmental, social media, and location data were collected passively by GPS. Classification trees were used to identify predictors of health behavior and outcomes during travel. Results Non-infectious disease events were common, with 22.7% (17 out of 75 travelers) experiencing an accident, 40.0% (n = 30) a wound or cut, and 14.7% (n = 11) a bite or lick from an animal. Mental health events were widely reported, with 80.0% (n = 60) reporting lethargy, 34.7% (n = 26) anxiety, and 34.7% (n = 26) feeling tense or irritable. Classification trees identified several robust patterns in traveler behavior, with age, trip length, previous travel experience, and having experienced a sports injury in the past year as the most important discriminatory variables for health threats. Conclusion Travel medicine research utilizing mHealth technology has the potential to revolutionize our understanding of health during travel by creating an almost real-time timeline of health events and behaviors during travel. Our study suggests that travelers commonly deal with a wide range of health events during travel and certain traveler subgroups may be at higher risk for different health risks. In particular, non-infectious disease related health issues were more common than expected. These health issues are rarely addressed in traditional travel medicine research, and suggest a substantial potential for improving evidence-based travel medicine advice. Do patients who incur informal payments really receive care a better quality? Evidence from Cameroon H. Kankeu Tchewonpi Centre for Health Economics, University of York, York, UK Introduction Little empirical evidence exists on informal payments for health care in Sub-Saharan Africa, a region where health financing still mainly relies on out-of-pocket expenditure. Moreover, it is often reported that patients make informal payments in order to receive care of better quality, but no quantitative study has clearly highlighted this relationship. Aim This work aims at exploring whether the payment of nonofficial fees is actually associated with an improved quality of care for patients. We use data from the baseline survey of the impact evaluation of the Cameroon Results-Based Financing program (March-June 2012). 901 patients are included in our analyses and the occurrence of informal payments is defined for those who reported having paid 'additional money' on top of official consultation fees. Indicators of quality of care include the satisfaction of patient with (i) the overall quality of services received, (ii) the time spent with the doctor/nurse, (iii) the level of privacy during the visit. Whether her condition was well explained to the patient, whether the patient was weighted and whether a physical examination of the patient was carried out were also used as measures of quality. To account for the data structure (patients nested within health facilities), we used multilevel mixed-effects logistic models and controlled for various characteristics of the patient and the health facility. Results With all the model specifications, we find that patients who have incurred an informal payment during the consultation are not more likely to receive care of better quality or to be satisfied with the services they have received. Including additional control variables related to the health workers who provided care does not modify the results. Conclusion Contrary to an opinion often found in qualitative studies, there is no significant association between informal payments and better quality of care. This can be explained by the fact that health workers voluntarily lower the baseline quality of care to induce patients to pay. This rent seeking behaviour contributes to the dysfunction of health systems and there is a need to better address this issue, since informal payments are known to mainly affect the poorest patients. It takes two to ownthe policy process behind the implementation of PBF in Uganda Methods We performed a qualitative study, using semistructured interviews with the main stakeholders that were involved in the policy process (n = 15). We used Kingdon's multiple streams approach in order to guide these interviews. We found that when using Kingdon's multiple streams approach in a setting in which donors are very prominent, it is useful to add a fourth stream that relates to the role of these donors. More specifically, we found that although there was close cooperation between the BTC, the World Bank, the Ministry of Health and the medical bureaus, the BTC was the leading actor. This was mainly due to their technical expertise on PBF and the lack of this within the MoH, hence the MoH has had a modest influence on the design. Conclusion A lack of local ownership in PBF is not always due to the unwillingness of the donor, but may also be a consequence of an imbalance in the level of knowledge between the donor and the ministry. Increasing the PBF expertise within the local ministries is thus essential in order to secure local ownership. Catastrophic health expenditure and care-seeking practices in Afghanistan: a mixed-methods study Introduction Access to health care remains impeded by inability to pay, and high Out of Pocket Expenditure (OOPE) on health in Afghanistan. Despite much progress in public health since 2001, including the introduction of basic and essential packages of healthcare that are free of charge, unequal access to healthcare remains pronounced. A comprehensive consideration for the factors driving catastrophic payments obstructing universal health coverage in Afghanistan is still lacking. Aim The study analyses the factors affecting access to care and catastrophic health expenditure: care-seeking practices, the averages of OOPE on health per wealth group and in total, client perception of care and access barriers, the strategies that households employ to source the funds to pay for care, and the existence of community-based health insurance (CBHI) mechanisms. Methods This study employed a mixed methods approach with qualitative, semi-quantitative and quantitative research methods, conducted in 2015. Data from Focus Group Discussions (FGDs) in three Afghan provinces was triangulated with data from a nationally representative household survey. It is based on a multi-stage random sample of 23 137 households across all 34 provinces of Afghanistan. The results suggest that the conditions for catastrophic health expenditure in Afghanistan are present. CBHI initiatives were not found in the three selected provinces, bar one small example. Instead, OOPE is widespread. Private health providers, which is the choice for half the respondents seeking care, are an important driver of this. Debts and the sale of possessions feature prominently as strategies employed to source the funds for OOPE. 48.4% of hospitalized people reported a financially distressed situation as a result. 7.5% of those who were ill did not seek care because of cost considerations. Quality, affordability and reachability of care featured prominently among healthcare-related concerns, exacerbated by insecurity in the country, particularly for women. Conclusions In a context of poverty and high insecurity affordability of care remains a major concern for Afghan citizens and policymakers. Contracting of private providers to deliver the basic and essential packages of healthcare coupled with more effective supervision and oversight could make healthcare more accessible and reduce out of pocket, catastrophic health expenditure. Results In-facility HIV testing requires payment for consultation and/or other lab exams. Patients with advanced illness describe financial barriers to start treatment and to be adherent. Funding for OI-drugs is scarce, leading to major shortages at health facility level and high out-of-pocket payments. In system with low wages, (informal and formal) user fees are main source of revenue and health workers tend to limit the number of HIV patient slots, because perceived as 'lost revenue'. A voucher system empowers patients to obtain care free of charge and to subsidise health workers' care provided. Based on costing of existing services, proposed scheme includes a voucher for HIV testing (2$ per patient tested), for ART in stable patients (16$ per patient per year), for ambulatory patients with OI (30$) and for hospitalisation (depending on length of stay 80 to 200$). Local associations allocate vouchers and reimburse health facilities on basis of vouchers received. Conclusion In a context of a health system relying on patient fees, access to free ART and HIV testing commodities can only be assured through subsidies for other essential elements of care. Vouchers can give patients a tangible proof of their right to free care and remunerate health workers on a forfait base for services rendered; patient associations can monitor and manage system. Introduction Community health workers (CHWs) are increasingly recognized as an integral component of the health workforce needed to achieve universal health coverage in lowand middle income countries (LMICs). CHWs have a unique intermediary position between communities and professionals in the health sector. CHW performance is shaped by transactional processes between these different actors. Aim To analyse the multiple factors that influence CHW performance and develop a framework on CHW performance. Methods We combined systematically derived evidence from the literature with research outcomes and experiences from the multi-country REACHOUT consortium. The systematic review included 140 studies related to CHWs working in promotional, preventive or curative primary health services in LMICs, which were double-read and analysed. Empirical data came from a multi-country study on CHW performance in Ethiopia, Kenya, Malawi and Mozambique, in which focus group discussions (48) and interviews (154) were undertaken with CHWs, their supervisors, managers and community members. We present a framework on CHW performance in complex adaptive health systems, in which the main influencing factors relate to the programme design, health system and broader context. Characteristics of CHW performance are outlined as well. At both the programme and system level, influencing factors are divided into 'hardware' and 'software'. Hardware elements, such as supervision systems and accountability structures, continuously influence software elements: the ideas and interest, relationships and power, values and norms of the actors involved. This influence also exists the other way around. Conclusion The framework touches upon interesting considerations for policy, practice and research. The realization that hardware and software elements are both needed and meant to strengthen each other calls for the incorporation of programme or intervention elements facilitating this process, in order to build relationships and improve CHW performance. For example, the introduction of a supervision system should reflect and take into account power relations and values and norms of the people involved, including those in the community. Health systems research should take into account the software elements, as effective systems thrive on these elements, and performance, in particular CHW performance, correlates with the strength and nature of relationships between all actors. Health systems governance in conflict-affected settings: governing Kurdistan's health system during the ISIS-related conflict G. A. Zangana 1 and Z. Mangouri 2 1 Middle East Research Institute, Erbil, Iraq; 2 Parliament of Kurdistan, Introduction Little is known about health system governance in conflict-affected settings. The literature in such settings tends to focus on international aid and their interactions with local contexts. However, to improve the delivery of health services and enhance the outcomes and impacts of such services, it is essential to understand how systems are governed in settings that are affected by conflict. The conflict related to the so called Islamic State in Iraq and Syria (ISIS) provides an opportunity to assess health system governance in such settings. We used Kurdistan region of Iraq's health system as a case study. Aim The aim of this research is to assess health system governance in the conflict-affected setting of Kurdistan region of Iraq. Methods A qualitative methodology was adopted for the purpose of this study. Forty-five participants were surveyed using an instrument that was developed elsewhere to assess health system governance in Low and Middle Income Countries (LMIC) (Siddiqi, 2009 ). The second set of data was collected using 24 documents. The data was analysed using Nvivo. Results This study identified weaknesses related to the participation in the decision-making process, strategic vision, accountability, transparency, effectiveness and efficiency and rule of law. Participants highlighted the importance of exploring the historical antecedents rather than just the current situation alone. They also identified the significance of external influence on governance that are not adequately captured by such standardized instruments. Conclusion Health systems in conflict-affected settings can be assessed using standardized frameworks developed for other settings in LMIC. Such instruments can be improved by incorporating measures that account for external influence and historical features of the current health system. Translation of multiple health systems flows in the language of complex networks P. Eerens Living Health Systems, Brussels, Belgium Introduction The abundance of meaningful frameworks to disentangle structure, relation, or causation in and across subsystems is an encouraging evolution in our efforts to increase our understanding of health systems. For the volunteer, the health professional, the bureaucrat, or the entrepreneur, i.e. day to day actors within health systems, such frameworks are only accessible when proper time is taken to study them in depth. Their multitude reflects the multidimensional nature of the health system experience and our individual attempts to tame the fluidity that arises when we try to coalesce our multiple views. Aim The case for complexity and network thinking does not have to be made any more. Were it not for digital inequity, their science would be accessible to any citizen of the 21st century. But while we try to reduce that modern inequality, we also need to diversify our strategies to increase the application of these sciences in day-to-day practice. Methods The health systems and public health track sessions provide an example of interdependent domains, internally coherent and thus able to be studied separately, but also massively coupled and leaving the day-to-day practitioner in doubt about how to make them work 'together'. We remind participants of a few non-linear systems science fundamentals, e.g. boolean networks, and demonstrate the ease by which this triggers pathways to explore answers to the questions raised. In line with complex systems thinking we do not predict precise outcomes, but we expect to see more of the following collective behaviors: a greater self-confidence in addressing multidimensionality and reduction; a more playful approach towards the dynamics that characterize health systems; an eagerness to explore networks in one's own domain of expertise. Conclusion Frameworks that populate the field of health systems and public health are welcome. But, the day-to-day practitioner might not have time to keep abreast of the emerging jargon. Our role is also to ensure that the citizen of the 21st century is provided with the foundational concepts and empowered to craft an independent, coherent, valid, and actionable view of the health system of which he or she is a part. Health Initiatives such as the Global Fund, GAVI and PEPFAR has dramatically changed the field of global health. While these initiatives have been lauded for massively increasing the resources for priority diseases, they have also been criticized for having negative consequences on countries' health systems. This has led to a renewed debate on health system strengthening (HSS). This debate created a paradox in the international health assistance policies of European donors. The EU and most Member States are strong supporters of HSS in their bilateral development cooperation. However, at the same time they are contributing considerable budgets to the Global Fund and GAVI which are still mainly maintaining disease-specific approaches implemented in parallel with the country's public health systems. Aim This paper aims to understand this paradox by analyzing why EU donors are contributing to the Global Fund and GAVI, hypothesizing that EU donors are pushing these organizations to focus more on HSS. Methods The findings are based on document-analysis and 20 semi-structured interviews with EU and member states officials as well as Global Fund and GAVI representatives. The findings indicate a 'love-hate relationship' between the EU and the Global Health Initiatives. On the one hand the EU has been critical about the narrow focus of the Global health Initiatives while strongly advocating for a progressive shift towards more health system strengthening. On the other hand, European donors are also attracted by the Global health Initiatives, as their approach leads to quick results, which can easily be communicated as successes to the electorate. Introduction Global health donors increasingly embrace international non-governmental organisations as partners, relying on them not only to implement health services, but also to influence policy in recipient countries. Unlike the multilateral organisations that have traditionally transferred global norms and policies to national contexts, iNGOs lack a formal mandate to assist governments, raising questions about how they establish their legitimacy and influence within national policy processes. Aim We examine how donor-funded reproductive health iNGOs have worked to influence the restrictive policy environment for safe abortion and family planning in South Sudan and Malawi. Methods We conducted prospective policy analysis in both countries between 2013 and 2016, focusing on the advocacy and policy work of two leading donor-funded reproductive health iNGOs. We mapped national policy networks and developments, conducted repeated interviews with key policy actors and the NGOs, visited reproductive health clinics, observed policy events, reviewed policy and programme documents and traced popular and media debates. Results Despite important contextual differences, we observe similarities in how iNGOs operate within these countries. Drawing on prospective policy analysis, we describe how two leading reproductive health NGOs strategically broker alliances and resources, often working 'behind the scenes' to help counter legal and regulatory restrictions on women's access to services. In both settings, iNGOs downplay or even conceal their own agency, both to demonstrate adherence to global norms about country ownership and to protect themselves within a highly politicised policy domain. Concealing iNGOs' influence can also inadvertently incite tensions. Conclusion Analysing iNGOs strategies and agency reveals how the global-national transfer of policy is by no means a value-neutral technocratic process but is instead a thoroughly political process permeated by complex power relations. Introduction In the field of international health assistance, there is a growing consensus on the limits of disease-specific interventions and the need to focus more on health system strengthening (HSS). Despite this increased attention for HSS, there are several interpretations of this concept. It is often argued that donors such as the Global Fund, GAVI and the USA interpret HSS in a narrow way, which has much in common with past waves of 'verticality'. In contrast, the European Union and its member states are considered to use more 'horizontal' approaches. Nevertheless, literature on this is scarce and lacks empirical underpinnings. Aim This paper discusses to what extent there is a common EU approach on HSS and whether this approach is distinct from other health donors' approaches. Methods The research is built on document-analysis and 80 semi-structured interviews with representatives of development agencies, NGOs and government officials in the DRC, Uganda, Ethiopia and Mozambique. Results/conclusion The findings show that EU donors share a comprehensive approach to HSS, with an active role for the government institutions of the partner country. These horizontal HSS approaches differ from other donors' approaches, which are more disease-specific and often operate in parallel with the public health system. Nevertheless, due to an increased focus on value-for-money and an increasing distrust in partner countries' leadership, there is now a trend among several European donors in some partner countries to change to back to supporting issue-specific programs implemented by UN agencies or NGOs. Medical electivesa risky business for all? Results Students visited over 100 countries over a 4 year period. A total of 146 students reported high risk exposures, such as blood splash to skin (n = 121), needle-stick (n = 16), mucosal exposure to eyes or mouth (n = 7) and human bite (n = 2). 339 students were required to take malaria prophylaxis, however 20% did not complete the required course. Furthermore, only 60% slept under a bed net. 390 students became ill whilst on elective, with diarrhoeal illness, respiratory tract infections and travel sickness being frequent complaints. Students frequently reported risks encountered in their leisure time or in the environment, such as wild dogs and poor roads. 631 students reported performing exposure prone procedures, with the majority feeling confident. A minority of students reporting acting outside of their competencies when undertaking practical procedures, such as lumbar punctures. Students who were working within obstetric departments also reported performing episiotomies, C-section or managing post-partum haemorrhage. Conclusion Students encounter a myriad of risks on their elective. Though risk assessments may minimise some of this, it is dependent upon students being actively involved and researching potential risks. Improvements could be made in educating students on risks encountered in leisure activities, as well as basic personal safety advice. To improve the elective experience, Newcastle University is trialling an 'electives passport', a small document with safety information and guidance about the level of experience of our medical students. Learning curve characteristics for caesarean section among associate clinicians: a prospective study from Sierra Leone Introduction In response to the high maternal mortality rate, Sierra Leone has adopted an associate clinician surgical task-sharing training program. Little is known about learning curve characteristics for caesarean sections among associate clinicians. Aim The aim of this study is to evaluate the number of caesarean sections needed to be performed by associate clinicians until there is no further significant reduction in operative time. Method A structured needs assessment survey among HCPs searching for information on tropical diseases and among potential contributors to identify the motivation of the contributing experts is conducted. Results A preliminary survey during a TropNet conference at the Institute of Tropical Medicine in Antwerp in March 2017 showed important interest in the concept of a collaborative WikiTropica platform (half of the respondents agree 'very much so' with the idea of building WikiTropica; 19 on 33 respondents would be ready to contribute with their expertise). Detailed needs assessment results will be presented both for the 'expert'/ supply side as well as the 'HCPs'/client side of the platform. The construction of a trial platform and its lean development approach will be presented by specifying the development steps and demonstrating the steps taken to achieve the platform. The trial platform will be demonstrated in a live version. Conclusion There is a sizable interest for an online, easily accessible information system for healthcare practitioners in the field of tropical medicine and travel health. The integration of information systems will be important for future developments in the medical sciences, for instance by employing data-driven approaches to improve HCPs' education and medical practice. A knowledge management platform with accurate and up-to-date information, could be part of such a possible integration pathway for tropical medicine and travel health. Evidence-based guidelines and training materials for first aid by laypeople: the example of India water for diarrhoea) and 16 different preventive interventions (such as burning neem oil in a kerosene lamp to prevent malaria), relevant for India. Based on the evidence conclusions and expert opinions of a multidisciplinary panel of 12 Indian experts, final recommendations were formulated. In a next step, didactical materials based on these contextualized guidelines were developed and tested in a pilot implementation phase in different districts of India. Conclusion By searching for evidence from Indian studies and on alternative Indian interventions, we were able to develop evidence-based first aid guidelines adapted to the Indian context. The final materials based on these guidelines are now being implemented using a top down Training-of-Trainers methodology to spread the first aid knowledge from the National Headquarters via its state branches and district branches, with more than twelve million Red Cross volunteers, into the local communities of the 1.2 billion Indian citizens. †Deceased November 17, 2015. Mapping One health curriculum for better disease prevention and control: what and why Introduction An increasing number of One Health (OH) curricula has emerged with the intention to promote interdisciplinary and cross-sectoral collaborations to handle complex health issues. Although, developing transdisciplinary/ interdisciplinary training and career development breaking traditional educational boundaries is viewed as important in prevention and control of zoonotic diseases, no systematic analysis of curriculum design has been done to critically review what needs to be trained and for which target groups. Aim The current study reveals the prioritized training content for whom and why as well as OH education obstacles, which is a part of a project whose overall objective is to identify the training gaps and develop contextual core competencies frameworks for OH education. Methods An online questionnaire was sent to expert panel members in Ethiopia, Ghana, Indonesia, Nepal, South Africa, Sri Lanka and Vietnam. These experts were selected as representatives of a diverse group of stakeholders from various sectors with various positions and occupying different roles in terms of their involvement in interdisciplinary or cross-sector collaborations in zoonotic disease control programs, research projects, training programs or other OH related activities. Results 171 out of 289 people completed the questionnaire. Specific target groups across multiple sectors/disciplines were identified. Besides animal and human health professionals, general public, environmental and social science professionals and government were recognized as the stakeholders requiring training and motivation for adopting the OH approach. As to training content, beyond technical training on fundamentals of zoonotic disease/infectious diseases and OH concepts and research methods, pedagogy and transversal skills such as leadership and system thinking & problem solving were highlighted. These needs mirror well with the identified major obstacles and bottlenecks. Moreover, each country has its unique OH priorities. Conclusion Community engagement is one of the training gaps which merits attention to ensure timely response for disease prevention and control. Training of different target groups for specific OH related activity calls for a wider collaboration beyond the health professionals. Involving education, environment and social scientists could effectively address the lack of trained personnel issue. OH approach should also be advocated for developing appropriate content and training methodology of OH education. Inequities in investments: a systematic analysis of global funding trends for malaria research in sub-Saharan Africa Introduction Domestic and international funding for malaria is inadequate to achieve WHO global targets in burden reduction by 2030. Aim We describe the global trends of investments for malariarelated research in sub-Saharan Africa (SSA), and compare investment to national disease burden to identify areas of relative funding strength and potential neglected populations. We also considered funding for malaria control (FMC). Methods Research funding data related to malaria from 1997-2013 was sourced from existing datasets, directly from 13 major public and philanthropic global health funders and from funding databases. Investments (reported in US dollars) were considered by geographical area of focus and compared to data on parasite prevalence and populations at risk in SSA. 45 SSA countries were ranked by research funding received. Results There were 333 research awards totaling $814.4 million. Public health research covered $308.1 m (37.8%) and clinical trials $275.2 m (33.8%). Tanzania ($107.8 m; 13.2%), Uganda ($97.9 m; 12.0%) and Kenya ($92.9 m; 11.4%) received highest sum research investment and the most individual research awards. Malawi, Tanzania and Uganda remain highly-ranked after adjusting for national GDP. Countries with relatively high malaria burden but receiving little research or FMC investment include Central African Republic and Sierra Leone (ranked 40th and 35th respectively). Congo and Guinea had relatively high malaria mortality rates, yet ranked 38th and 25th, respectively, receiving little investment. Conclusion Some countries receive relatively large investments overall (Tanzania, Kenya, Uganda) whilst others receive little to no investments for research (Sierra Leone, Central African Republic). Research investments are typically highest where there is also greatest FMC. Investment strategies should consider more equitable research and operational investments across countries to include currently neglected and vulnerable populations. Introduction Miltefosine, the only oral drug available for leishmaniasis, is considered as a success story in clinical drug development by a public-private Product Development Partnership (PDP). Originally developed as an anti-cancer agent, its potent antileishmanial activity was discovered by academics in Germany and UK. The 2002 approval of miltefosine for kalaazarthe fatal form of leishmaniasisin India, was a breakthrough in the quest for better drugs for resource-poor settings. It marked the substantial R&D investment made by the public sector with a clear vision to impact VL control 15 years ago. Yet, today, access to miltefosine in low-and middle-income countries with the highest disease burden remains compromised. Methods We reviewed the clinical development and postregistration access to miltefosine through: systematic review in PubMed for 'miltefosine', archival and documents review from key stakeholders' documentations, and in-depth interview with experts and key informants involved with the PDP. Results Post-registration, miltefosine access was inconsistent, despite the initial agreement for the drug 'to be made available in sufficient quantities to meet the needs of public sector agencies and at the lowest possible price, in return for the substantial public investment in R&D costs'. Despite several incentives such as orphan drug designation, a priority review voucher, and subsidies from national programmes, access for the patients who need the drug remain as an afterthought. Very unfortunate was the incident in Bangladesh, where the marketing of an ineffective counterfeit product caused the death of many VL patients. A large minimum purchase requirement, bureaucratic tender mechanism and long lead-time compounded supply problem. Meanwhile, the company owning the proprietor drug changed several times (AstaMedica, Zentaris, Paladin, Endo, and latest: Knights) and indeed affect access to treatment of leishmaniasis patients worldwide. Conclusion The miltefosine case exposes certain flaws in the current drug R&D landscape. Its anticipated public health impact was hindered not by a single barrier, but an entire spectrum of factors. Innovative mechanisms for neglected disease R&D has to be accompanied with better access provisions downstream. Benefits of medical research should increase patients' accessthe neglect and imbalance should not be the end of the story. Introduction Taenia solium cysticercosis/taeniosis (TSCT), an emerging but neglected zoonosis caused by the number one food-borne parasite, represents a potentially eradicable disease complex in many countries of sub-Saharan Africa with huge impact on human and animal health. To fill gaps on the way to control/elimination of TSCT a multidisciplinary research platform will be developed integrating basic, epidemiological, clinical, digital and educational research as well as capacity building and international networking at various levels. Four African partnersone in Mozambique (M), two in Tanzania (T) and one in Zambia (Z)and two German partners (both TUM) are involved and linked with an international advisory board including, amongst others, the WHO, CDC Atlanta and CYSTINET-Europe. Furthermore, the development of an IT platform that comprises a Virtual One-Health Centre with a research school as well as tools for electronic case management and networking are other key elements. CYSTINET-Africa officially started in October 2016 and has received funding from the German Federal Ministry of Education and Research (BMBF) for activities planned until 2021. -Assessment of prevalence and co-infections of TSCT/neurocysticercosis (NCC) in large-scale community based studies in T,M, Z -Evaluation of the pathomechanisms involved in the development of symptomatic NCC in immunocompetent and immunocompromised individuals as well as pathomechanisms involved in different treatment responses in people with symptomatic NCC on standard treatment in longitudinal studies in T and M -Establishment of an experimental pig model for T. solium cysticercosis for human and veterinary research needs as well as investigation of pig breed susceptibility to T. solium in Z -Development, evaluation and implementation of a low-cost health education intervention package for the prevention and control of TSCT in T Project outlook CYSTINET-Africa will create impact by linking human, animal and community health (based on the "One-Health" principle) with respect to zoonotic diseases at various levels in sub-Saharan Africa. A rapid expansion of this network and its activities is envisaged and a promising new collaboration in the field of mobile health in association with a project on digital inclusion funded by the Research Council of Norway is already underway. Introduction Visceral leishmaniasis (VL), affects the most vulnerable populations in some of the poorest regions of the world and is fatal if left untreated in over 95% of cases. The efficacy of current therapeutic options is affected by reported factors such as antileishmanial drug resistance, co-morbidities such as malnutrition or HIV co-infection, drug-drug interactions and substantial geographical variation. Over 35 000 patients have been enrolled to VL clinical trials internationally in the past decades, providing a rich resource that could fill knowledge gaps, inform treatment optimisation and improve future research. However, only summary statistics of these trials are available. The data are scattered across geographical regions and published trial reports lack standardisation, making comparison of efficacy between drugs, regimens and regions almost impossible. Aim The aim of the project was to assess the feasibility of establishing a VL data sharing platform to facilitate individual patient data (IPD)-based meta-analyses of clinical trials. Such a repository would enable the pooling, harmonisation and standardisation of diverse clinical trial datasets to produce the robust clinical evidence needed to optimise treatment across regions and populations. Methods An initial pilot project and systematic review of published and unpublished literature were undertaken. A total of 2271 documents from studies published between 1983 and 2016 were screened. The reviewers identified 145 VL clinical trials with sufficiently consistent methodology to support poolingdata from 26 986 patients. Methodologies varied for diagnosis and treatment outcomes, but overall the volume of existing data identified for different drugs and dose regimens, suggests that there are sufficient patients per arm suitable for IPD pooled meta-analyses. Methods The first framework was derived from guidelines such as the Declaration of Helsinki and the Council for International Organizations of Medical Sciences. In 2003, the ERB adapted a framework previously developed by the US National Institutes of Health, to provide more structured advice to field researchers and to facilitate standardized reviews. This was replaced in 2013 by a framework that covers much of the same ground but, instead of being prescriptive, encourages conversation about ethical issues. The use of open questions requires researchers to engage in reflection and defend how they address the identified issues. Four-year experience demonstrates that the new framework facilitates standardized and coherent reviews, is generally well-received by researchers, and is effectively applicable for all research designs. It is publicly available on MSF's Field Research website, and in an academic repository. Conclusion An ethics framework that stimulates ethical reflection (rather than being an expression of theoretical ideals or a list of absolute statements) may improve research design and deliberation, especially for researchers confronted with dilemmas not considered in traditional guidelines. It may be of interest for research groups in similar contexts. Introduction Over the last decade control efforts made significant strides in curbing malaria in Sub-Saharan Africa. These efforts and their impacts have not been distributed equally across the continent and within countries. Aim To estimate economic gradients in distribution of malaria services and evaluate their relevance for targeting and deployment of malaria interventions in sub-Saharan African countries. Methods Using Demographic and Health Surveys we replicate standard equity metrics to characterize distribution of malaria services in 28 countries, proxying economic position with survey-derived asset-wealth index. Gradients in distribution of services are summarized in a concentration index, tabulated against the level of service, and compared between interventions, across countries, and against respective historical trends (both the level of change and distribution of change across wealth strata over the last decade). Within countries there is a vast difference in level, relative ranking, and distribution of malaria services across wealth strata. In most, economic gradients are lacking or favour the poorest for vector control while displaying pro-rich bias for interventions deployed through the formal health-care sector. A handful of countries including Ghana and Sierra Leone appear to have circumvented the inverse care law, consistently prioritizing the poorest when deploying and scaling-up malaria interventions. Expansion of control programs over the last decade also generally narrowed service gaps between poor and rich; economic gradients persist in countries where growth was pro-rich or baseline inequality in distribution of services was large. Despite progress in service coverage, malaria burden is consistently concentrated in the poorest; the degree of inequality in burden far surpassing that expected given gradients in distribution of services. Conclusion Ranking of countries by level and distribution of services across asset-wealth quintiles establishes a benchmark for performance of control programs. It shows that there is capacity within countries to deliver malaria services to the poor. However, compounding of health systems failures weakens the link between program performance and disease burden; equitable service coverage does not eliminate disparities in distribution of burden. This highlights the need for multispectral approaches to ensure that improvements in service coverage prioritize disadvantaged populations who suffer the greatest malaria burden. Methods Study participants were adult women of reproductive age (18-55 years old) living in one of the six study districts, two from each country. The indicators selected for the analysis were: use of contraceptive methods, access to HIV testing and a minimum of four antenatal care visits. The associations between these indicators and socioeconomic factors, such as wealthmeasured with an asset indexor education, were assessed by performing multivariate logistic regressions. To enable comparisons between districts and countries, Human Opportunity Indices (HOI) and dissimilarity indices (D-index) were calculated. The HOI is a measure of coverage rate discounted by inequality, which was developed by the World Bank. Results Use of contraceptives, access to HIV testing and antenatal care visits are significantly associated (95% confidence) with being in a relationship (OR = 1.5, OR = 2.0 and OR = 1.3, respectively) and educational level (secondary education OR = 2.2, secondary education OR = 1.4 and higher education OR = 2.8, respectively; reference category = no education) Wealth and type of occupation (salaried/not salaried) are also significant determinants of access to HIV testing. The HOIs show remarkable inequalities across districts and countries. For the reproductive health indicators, Mozambican and Tanzanian districts display higher HOIs and lower inequalities (D-indices) than Gabonese districts. Conclusion Maternal and reproductive health indicators are unequally distributed across different socioeconomic factors. Disparities among districts and countries are also relevant and demonstrate that SSA comprises many different realities that deserve particular attention. To achieve the global targets set by the SDGs, the expansion of maternal and reproductive health services should progress under an equitable perspective taking into account vulnerable groups such as the poor and the least educated. Inequities in global health: easy to see, hard to define O. Gorik London School of Hygiene and Tropical Medicine, London, UK Introduction Inequities are inequalities that are also unjust. Although the terms 'equity' and 'inequities' are frequently used in global health scholarship, there is no common understanding of what they mean. The lack of a common understanding of the goal hampers progress towards the goal. Aim To explore the difficulties associated with applying, at the global level, the principles on which inequity in health at the national level are based. Methods I analysed the authoritative texts that describe what inequity in health means at the national level, to identify the underlying principles, and tried applying them at the global level, to find out where the problem lies. Results At the national level, equity in health means the absence of inequities. Inequities are inequalities that are also unjust, because they are remediable, within a context of a more or less predefined budget, which is allocated through a fair and inclusive progress, in accordance with agreed norms. Inequalities that persist because they are not remediable, or because their remedy does not fit within the available budget, allocated through a fair process, in accordance with agreed norms, are not considered inequities, rather as 'bad luck'. At the global level, there is no predefined budget, and there is no fair and inclusive progress to allocate that budget. There are some agreed 'hard law' norms (the human right to health), and some agreed 'soft law' norms (the MDGs, the SDGs), but they are ambiguous, not enforceable and not even widely accepted. Conclusion Global health scholars should engage more systematically with the normative underpinnings of the term equity, try to achieve some consensuseven if incompletely theorisedif they want to contribute to equity in global health. Introduction Women in sub-Saharan Africa (SSA) accounted for 201 000 deaths in 2015. Despite progress for all essential maternal interventions in SSA, substantial disparity remains in coverage levels of interventions among and within countries. As a result, the most vulnerable women are not accessing life-saving interventions and undergo their pregnancies and childbirths outside the health system. Aim To determine the extent to which maternal and reproductive health-related opportunities and outcomes are unequally distributed among women in SSA and to identify the groups of women most strongly affected by these inequalities. Surveys were used to analyse 15 opportunities for women of reproductive age (15-49), pregnant women and older adolescent girls (15-19), across 29 SSA countries. The tool employed was the Human Opportunity Index (HOI), a composite indicator that combines the availability of an opportunity (coverage rate) with a measure of how equitably it is distributed among groups of women with different characteristics (dissimilarity index or Dindex). Decompositions of the D-index are used to assess the contribution of each individual circumstance to inequality. The maternity care package of services is found to have the lowest average HOI (26%), while six months of exclusive breastfeeding has the highest HOI (77%). The other indicators show low HOIs, in some cases lower than 50%, indicating both low coverage and/or high inequality. Wealth, education and area of residence are the main contributors to inequality for women of reproductive age. Among adolescent girls, marital status is the major contributor. Conclusion Reproductive and maternal health opportunities for women in SSA are scarce and far from reaching the global goals set by the post 2015 agenda. Further progress in improving women's and adolescents' health and well-being can only be achieved by accelerating expansion of coverage of essential interventions with an equity-focused approach. Failure to do so will compromise the likelihood of achieving the Sustainable Development Goals. New metrics such as the HOI allow better understanding of the nature of challenges to achieving equity in perinatal and reproductive health, and offer a tool for monitoring progress in implementing a strong equity agenda. Of those with physical injuries (n-231), the great majority (215, 86%) were perpetrated by State authorities in Europe; almost all (93%) occurred within EU member states (namely Bulgaria, Hungary and Croatia). State authorities allegedly perpetrated physical injuries also on minors (<18 years, 27%) and children (8%). There were a total of 72 reported deaths (including 8 children) during the last winter. The causes included hypothermia due to exposure to cold, inhaling fumes from fires used for heating, drowning in rivers while trying to cross over, electrocution by train lines, denial of access to medical care, and suicide. Qualitative evidence corroborated with quantitative findings. Conclusion Over half of the migrants/refugees seen in MSF clinics experienced violent events including physical trauma. State authorities within the EU member states were the perpetrators in the majority of such events. Deaths could be attributed to individuals taking more dangerous and risky routes to travel and/or the predicament of inhumane living conditions. There is 'a crisis of protection and the lack of humane treatment' which needs to change towards one of respect for the principles of international human rights and refugee law. Introduction Since 2015, Europe has been facing an unprecedented arrival of refugees and migrants. More than one million people has entered Europe via land and sea routes. With the closure of the FYROM border and the EU/Turkey deal, around 60 000 refugees and migrants are stuck in Greece (UNHCR). During their journey, refugees and migrants often face harsh conditions, forced detention and violence in transit countries. However, there is a lack of evidence on their experiences and their mental health status. equity, tropical and neglected diseases and cultural competence) and a volunteer mission in the framework of a CCM project. During the mission, the resident joins and supports clinical officers and nurses in the daily delivery of care at PHC level, tutored by a specialist with long-term experience in developing countries. Results Three Family Doctor residents took part in the project. After attending the Global Health course, they engaged in clinical and training activities working closely with PHC staff in Kenya and Ethiopia. They gained knowledge and practical experiences in the management of tropical diseases and, at the same time, guided clinical officers and nurses in the critical analysis of cases through the review and synthesis of different clinical protocols. Conclusion The dialogue and collaboration between Italian family doctors and local health professionals in sub-Sharan Africa can enable the first to respond more efficiently to the needs of an ever-expanding multicultural community due to the high migrant influx in Italy, and support the latter in enhancing the quality of care provided, eventually reversing the inverse care law. Comprehensive care for migrants and refugees who have suffered torture and other forms of ill-treatmentthe MSF experience in Athens Introduction In order to prevent the adverse consequences of malaria in pregnancy (MiP), a community-based scheduled screening and treatment of malaria in combination with intermittent preventive treatment with sulfadoxinepyrimethamine (CSST+IPTp-SP) has been proposed as potential alternative to the standard IPTp-SP 1 . In this study, we investigated the effect of CSST+IPTp-SP on the risk of malaria and non-malaria fevers (NMFs) during the first year of infant's life. Methods Between June 2014 and October 2016, a birth cohort study (n = 734) was conducted in Nanoro, a high seasonal malaria transmission area in Burkina Faso. Clinical malaria episodes were recorded by passive case detection from birth until 12 months of age. In addition, 4 cross-sectional surveys were carried out at 3, 6, 9 and 12 months to detect asymptomatic infections. Multivariate models were used to assess the effect of CSST+IPTp-SP strategy on time to first clinical malaria episode, incidence of malaria episodes, asymptomatic infections and incidence of all NMFs. Background Since 2008, artemisinin-based combination therapy (ACT) has been adopted as first-line treatment for malaria in the second and third trimester of pregnancy in Burkina Faso. ACTs are contra-indicated in first trimester unless the life of the woman is at stake. As ACT is increasingly available, a growing number of women will be inadvertently exposed to an artemisinin compound before they are aware of their pregnancy. There is increasing need for data to inform policy makers and treatment guidelines on the safety of ACT when used during the first trimester. Methods Pregnant women at any trimester of pregnancy were recruited from two Reproductive and Child Health (RCH) clinics in Bobo Dioulasso, Burkina Faso from August 2012 to July 2014 and followed prospectively until delivery. All medications taken by participants were reported, using several sources. A Birth Defects Panel reviewed and classified all major and minor congenital anomalies, without knowledge of medication exposure, later classified by ICD code. Results Overall, 2371 pregnant women were recruited and 2054 (86.6%) were followed until delivery, 317 were lost to follow up. Of women followed up, 372 (18.1%) were exposed to antimalarial drugs in their first trimester, 44 (11.8%) with ACT, and 328 (88.2%) with quinine. ACT exposure during the first trimester was not associated with an increased risk of low birth weight (HR = 1.1, 95%CI: [0.27, 4.45]) compared nonexposed women, controlling for mother's age, child's gender and delivery complications in the Cox regression. Major congenital anomalies were 0/44 in first trimester ACT exposed and 4/2009 in first trimester non-ACT women. Conclusion Use of ACT in early pregnancy in Burkina Faso occurs but in this small series of exposures was not associated with low birth weight or major congenital malformations. Optimal duration of follow-up for assessing efficacy of drugs for uncomplicated falciparum malaria in pregnancy in Asia: a systematic review and individual patient data metaanalysis Introduction Pregnant women are more vulnerable to falciparum malaria and even asymptomatic infection can adversely affect both mother and fetus. In non-African settings, early diagnosis and prompt treatment with effective drugs is the key strategy. However, pregnant women have been systematically excluded from regular efficacy studies, and there are no agreed standards to assess antimalarial efficacy during pregnancy. Aim We aim to establish an optimal methodology to determine antimalarial drug efficacy during pregnancy. The optimal duration of follow-up for assessing the efficacy of antimalarial drugs in pregnancy was assessed, as it can differ from that for the non-pregnant population due to placental sequestration, altered immunity and altered pharmacokinetics. Methods We conducted a systematic review of efficacy studies of uncomplicated falciparum in pregnancy in Asia using seven search engines and two clinical trial registries. Individual patient data (IPD) were sought and a pooled meta-analysis was conducted. The distribution of recrudescence over time was assessed by estimating the probability density of recrudescence based on an accelerated failure time model and the Cox proportional hazard model. We identified 20 studies on efficacy in pregnancy conducted in Asia. Two randomised control trials were completed in 2016 and were unpublished. Only ten published studies, all conducted on the Thailand-Myanmar border, used polymerase chain reaction (PCR) for differentiating recrudescence from reinfection. Patients were followed up until delivery. From these studies, 427 episodes of PCR-confirmed recrudescence were included in this IPD meta-analysis. Median (range) time to recrudescence was 26 (12-120) days for artemisinin-based treatment (n = 92) and 21 (8-126) for quinine (n = 299). Based on an unadjusted accelerated failure time model, 6% and 22% of recrudescence was predicted to occur 42 days after treatment with artemether-lumefantrine and dihydroartemisinin-piperaquine, respectively. We will present results based on models adjusted for patient characteristics and assess the effect of pregnancy-specific variables on the time to recrudescence. The optimal duration of follow-up for assessing the efficacy of antimalarials may be longer than the conventional follow-up recommended for the non-pregnant population. Standardisation of methodology for efficacy studies in pregnancy is warranted to allow comparison and interpretation of evidence from individual studies. Introduction One of the current strategies to prevent malaria in pregnancy is intermittent preventive treatment with sulfadoxine-pyrimethamine (IPTp-SP Conclusion CHWs are capable of performing RDTs with high specificity and acceptable sensitivity. Furthermore, CHWs showed excellent adherence to test results and treatment guidelines, suggesting this is a feasible approach. However, the effect of this intervention on malaria-related morbidity during pregnancy needs to be elucidated before firm conclusions can be drawn. Malaria is more prevalent than iron deficiency among anemic pregnant women at the first antenatal visit in rural South-Kivu Introduction Anemia is common during pregnancy particularly in low-income countries. It is associated with poor outcomes for pregnant women and the foetus. WHO estimates that half of all cases of anemia are related to iron deficiency (ID). However, to our knowledge, the contribution of ID to the burden of anemia among pregnant women from South-Kivu has never been evaluated. Aim The present study wanted (i) to determine the prevalence of anemia and iron deficiency but also (ii) to identify others factors associated with anemia in pregnant women from rural Miti-Murhesa health zone in South-Kivu province in the eastern DR Congo. Methodology Between November 2013 and April 2014, 531 women attending the first antenatal visit in their second trimester of pregnancy were recruited into the study. Sociodemographic, clinical and biological data were collected. Hemoglobin was determined by a portable photometer (Hemocue â ) and anemia was defined as altitude adjusted hemoglobin < 110 g/L. Iron deficiency was defined as serum ferritin < 12 lg/L or < 30 lg/L in case of inflammation (CRP > 5 mg/L and/or a-1-acid glycoprotein ˃ 1 g/L) while hypoalbuminemia was defined by a serum albumin < 3.5 g/dl. A Giemsa stained blood smear was used to diagnose malaria. Conclusion Iron deficiency (ferritin-based) was not highly prevalent and not associated with anemia. Effective control of anemia during pregnancy in this region should consider fighting malaria and other infectious diseases in combination with measures to improve women's nutrition. This should be applied to all women of childbearing age even before they become pregnant. Delivery strategies of malaria chemoprevention for postdischarge management of children with severe anaemia in Malawi Methods This is a cluster-randomized trial with 5 arms, each representing unique delivery strategies Convalescent children aged less than 5 years weighing more than 5 kg with severe anaemia are included. All eligible children will receive dihydroartemisinin-piperaquine at 2,6 and 10 weeks after discharge either: 1) in the community without an SMS reminder; 2) in the community with an SMS reminder; 3) in the community with a community health worker reminder; 4) at the hospital with an SMS reminder; or 5) at the hospital without an SMS reminder. For community-based strategies, mothers will be given all the PMC doses at the time of discharge while for hospital-based strategies mothers will be required to visit the hospital each time. Each arm will consist of 75 children and will be followed up for 15 weeks. The primary outcome measure is uptake of complete courses of PMC drugs. The study is actively recruiting and we expect that the findings will inform policy decisions about the most effective, cost-effective, acceptable and feasible strategy for delivering intermittent preventive therapy post discharge for management of severe anemia in under-five children in the quest for new strategies for malaria control in children. Impact of a malaria rapid diagnostic test detecting Plasmodium falciparum-specific histidine-rich protein-2 (RDT-PfHRP2) on the management of febrile children under-5 years of age in a high seasonal malaria transmission area Introduction The World Health Organization recommends to screen febrile patients by microscopy or malaria rapid diagnostic test such as Plasmodium falciparum histidine-rich protein-2 (RDT-PfHRP2) before initiation of treatment (1) . But persistence of the diagnostic target in blood after successful antimalarial treatment can affect the performance of this RDT and may result in missing true cause of fever in a malaria endemic area (2) Conclusion The use of a malaria RDT-PfHRP2 in a malaria endemic area may cause misdiagnosis of the actual cause of fever due to false positive test results. The development of practical diagnostic tool to screen for other causes of fever in malaria endemic areas is required to save lives and to improve the performance of the RDT. treatments between D0 and D2 and were followed up on D3, D7, D14 and D28. Detailed findings of the study will be presented and discussed at the conference. A qualitative study of the acceptability of weekly iron supplementation prior to the first pregnancy in Burkina Faso Introduction Reducing anaemia in women of reproductive age is a global priority as iron deficiency anaemia (IDA) is a leading cause of years lived with disability. To reduce IDA iron supplementation for menstruating women is recommended. This includes adolescent girls as adolescence may be the optimal time to build iron stores in readiness for pregnancy. The success of such interventions largely depends on their feasibility and acceptability to adolescents and their communities. Aim This study explored the acceptability of weekly iron supplementation given periconceptionally for up to 18 months to non-pregnant adolescents (mean age 16 years) enrolled in a randomised controlled trial. Methods Before and during the trial systematic information on the role of iron in health was provided. In-depth interviews were conducted with young women, selected according to their level of adherence in either trial arm (iron and folic acid versus folic acid alone) by field workers who had provided directly observed capsule intake. Tape recorded transcripts were translated from Moor e into French and analyzed thematically. Results 38 interviews were conducted with young women, some of whom had become pregnant during follow-up. At the outset, the research focus on adolescents suggested to communities that supplements were contraceptives and this lead to drop out by some, but not other, interviewees. Adolescents expected curative and health benefits from the supplements which, when not experienced, engendered negative views. Commitment to the intervention was affected by mobility. Some were students who returned to homes outside the study area during holidays. Unplanned pregnancy and domestic assistance to relatives living elsewhere affected the mobility patterns of other interviewees. Conclusion Despite health education, iron supplementation was not seen as a high priority by communities nor did the benefits persuade adolescents themselves of its importance. Malaria risk in young children after periconceptional iron supplementation of mothers in rural Burkina Faso Introduction Pregnancy iron deficiency anaemia (IDA) is common and a leading cause of morbidity in children and adolescents. Iron supplementation is recommended by WHO in pregnancy and for menstruating women where IDA is common. Observational studies indicate some level of protection against malaria among iron-deficient children. Iron supplementation prior to and during pregnancy might affect Plasmodium falciparum infection risk in mothers and their offspring. Aim To assess malaria risk and iron status in young children after periconceptional iron supplementation of mainly adolescent mothers. Methods A cohort of children was followed up born to primigravidae who participated in a randomized controlled trial of periconceptional weekly iron supplementation in a malaria endemic area in rural Burkina Faso. A cross-sectional survey was conducted, when children were aged between 1 and 21 months. Medical and vaccination history were recorded. After clinical examination a venous blood sample was collected for malaria rapid diagnostic test, microscopy, hematology, and iron biomarkers. Definition of iron deficiency was either by adjusted ferritin (ferritin<12 lg/L if CRP≤5 mg/L and <30 lg/L if CRP>5 mg/L), or by the ferritin index (sTfR/log ferritin >5,6). Variables were compared by trial arm and sub-group analysis by iron status and malaria infection. Results 180 children were assessed, 96 (iron, 53.3%), and 84 (control, 46.7%). Median age was 9.1 months, 67.2% were 6 months or older. P. falciparum parasitaemia prevalence was 34.6% and did not differ between arms (37.9% iron, 31.0% control, RR=0.9 P = 0.17). Rapid diagnostic test positivity was 72.1%. Mean number of malaria episodes since birth was similar in both groups, 1.01 (iron) and 1.04 (control). Among children aged 6 months or more, 95.9% were anaemic (Hb<11 g/dL), and 21.5% severely anaemic (Hb<7 g/dL). Childhood iron deficiency prevalence was 15.6% by adjusted ferritin and 67.7% by ferritin index, and was not associated with P.falciparum infection (non adjusted RR=0.81; 95%CI 0.64; 1.02; RR=1.14; 95%CI 0.91; 1.42), nor was IDA. Childhood parasitaemia was associated with maternal peripheral malaria infection at ANC1 (RR=1.25; 95%CI 1.01; 1.55), but not with maternal iron deficiency or anaemia. Conclusion Burden of malaria and anaemia was high in these children but not modified by iron supplementation of mothers. Introduction Anaemia is common in preschool African children, and is mostly due to iron deficiency and Plasmodium infection. Combining iron interventions with interventions against malaria may be more efficacious and safer than iron interventions alone. We examined the impact of home fortification with micronutrient powders, delivered alongside seasonal malaria chemoprevention, parenting education through community-based preschools, on malaria, anaemia and cognitive development in early childhood in rural communities in Southern Mali over a two-year period. Methods Sixty communities with community preschools were randomly allocated to the intervention and control group. All 60 study communities received two rounds of seasonal malaria chemoprevention during the peak malaria season (Oct-Dec each year), targeting all children aged 3-59 months. The 30 intervention communities then received daily home fortification with micronutrient powders containing 12,5 mg of elemental iron for four months (Jan-April each year) targeting all children aged 6-59 months. Two cross-sectional surveys were conducted at baseline (June 2014) and endline (June 2016) to compare Plasmodium infection, nutritional indices and cognitive performance in two groups of children aged 3 and 5 years (n = 1,105 and n = 1,033 respectively). Results At baseline in 2014, 63% and 53% of children aged 3y and 5y were anaemic, 49% and 60% had Plasmodium infection and 43% and 34% were stunted. Despite high reported coverage for both malaria chemoprevention and home fortification, the preliminary unadjusted results from June 2016 found that after two years of intervention there was little discernable difference in anaemia (<110 g/L) between the two intervention groups; 51.8% vs. 48.9% in children aged 3 years, and 46.6% vs. 40.6% in children aged 5 years; and negligible effects for stunting. The full results of the 2016 survey, including performance in tests of cognitive function, will be presented at the conference. Conclusion Home fortification with iron-containing micronutrient powders is recommended by WHO where the prevalence of anaemia is over 20%. This study found that micronutrient supplementation, when given in addition and subsequent to seasonal chemoprevention against malaria, had limited impact on childhood anaemia in an area of high prevalence, despite good uptake of both interventions. Critical reflections on SRHR policies and law M. Bosmans, K. Gyselinck, S. Van Bastelaere and P. Bossyns BTC-Belgian Development Agency, Health Unit, Brussels, Belgium Introduction Ever since the 1994 Cairo Conference governments worldwide invested in the development of an appropriate normative framework aimed the promotion of sexual and reproductive health and rights (SRHR). Evidence abounds that SRHR remains a sensitive issue. Worldwide the reinstatement of the Global Gag Rule, created a strong reaction in defence of SRHR. But although the SRHR community loudly applauds the reaffirmation of strong pro-SRHR political commitments, intellectual sincerity compels us to reflect on the unintended side effects of well-intended political initiatives. Aim The objective of this presentation is to feed the reflection on how international development stakeholders involved in the promotion of SRHR can learn from the experiences since 1994. Method This presentation is a critical reflection based on yearlong and diverse professional experience in the field of SRHR at different levels and with/for a variety of stakeholders (national and international governments, multilateral agencies, bilateral agencies, national and international NGOs and the broader civil society, and the academic world) in Latin America, Africa, the Middle East and Asia. Results With support of multilateral and bilateral agencies developing countries invested in the development of SRHR specific policies that are often linked with SRHR specific programmes (e.g. mother and child health, family planning, adolescent health, PTME, HIV/AIDS). The implementation scope is often limited in time, restricted to a limited number of geographical areas and targeting only part of the population (i.e. "vulnerable populations"). Once the programme funding ends sustainability is at stake and scaling up is not guaranteed. Moreover, the implementation of these policies and programmes tend to run parallel with national health system strengthening (HSS) programmes. Although WHO experts agree that investment in Universal Health Coverage is the most effective way for sustained and sustainable promotion of SRHR, political prioritisation of SRHR tends to create unsound "competition" between the HSS and the SRHR community over access to ever more scarce financial and human resources, distorting the whole system. Conclusion Though continued advocacy for SRHR is needed, it must be disconnected from the development of SRHR specific initiatives that are not thoroughly grounded in the strengthening of the overall health system. Results Four contribution pathways at the global level were identified: (a) engagement in negotiations in international treaty bodies, (b) engagement within the context of the EU and its global role, (c) support to multilateral agencies in rights-based advocacy, (d) support to engagement of Danish and international NGOs in rights-based advocacy. The evaluation showed Danida's continuing leadership in forming coalitions in international bodies to protect the full meaning of the ICPD Programme of Action; its support to UNFPA which acted as an ally in international negotiations; its support to a network of NGOs to advance the SRHR agenda. The Ministry of Foreign Affairs relied on an effective network of SRHR advocates including Permanent Representatives. However, the reduction of specialized staff within the Ministry is a potential threat for Denmark's forerunner role. There has been no effective translation of Denmark's global leadership to a similar position at LMIC country level. Conclusion Contribution analysis provides an innovative approach for donor governments to appreciate their own role in the global policy context, their contribution and their accountability to stakeholders. It highlights dominant mechanisms and processes of influence while avoiding overclaiming impacta common trait of much donor or donordriven analysis. Body & Rights -E-learning on sexual and reproductive health and rights for stakeholders of development cooperation W. Van de Voorde 1 , K. Blondeel 2 and the working group on sexual and reproductive health and rights of Be-cause health, the Belgian platform on International Health 1 Sensoa, Flemish Expertise Centre for Sexual Health, Antwerp, Belgium; 2 University of Ghent, Faculty of Medicine and Health Sciences, Gent, Belgium Introduction An evaluation of the Belgian policies on sexual and reproductive health and rights (SRHR) revealed a lack of awareness and understanding of the topic amongst the stakeholders of Belgian development cooperation. Stakeholders were insufficiently aware why and how to promote SRHR in the bilateral relations with other countries, in supranational decision-making bodies or during the development, monitoring and evaluation of programmes and projects. An e-tutorial was developed to remediate this. Aim The e-tutorial 'Body & Rights' (bodyandrights.be) improves the stakeholders' understanding of SRHR, their skills to advocate SRHR and their capacity to find accurate and evidence-based information and reference documents on SRHR. The tool contributes to the promotion of SRHR in realizing the 2030 Agenda on sustainable development, human rights and gender equality. Methods Guided by the ADDIE model: (Analysis, Design, Development, Implementation and Evaluation) a user-friendly, intuitive and graphically appealing and responsive web application in three languages (NL, FR, ENG) was created. The e-learning content was developed according to a set of learning objectives and uses different media elements (graphics, audio, video and animation). Additional learning support (e.g. through examples, interactivity, references, etc.) to increase selfsufficiency is provided. Results The e-tutorial consists out of 7 modules of around 30 minutes each. Through presentation videos with professional actors SRHR topics are being addressed from the angles of public health, education, human rights, gender equality and sustainable development. Conclusion Promoting SRHR in the context of development cooperation requires awareness and specific knowledge and skills. This is a necessary condition to advance SRHR at the supranational and national level and to realize the SRHR related goals and targets of the 2030 Agenda on sustainable development. E-learning provides opportunities for acquiring specific knowledge, cognitive (e.g. understanding of the concept 'sexual rights') as well as interpersonal skills (e.g. negotiating SRHR of young people in an 'unfriendly' environment) on SRHR. Self-paced e-learning represents an easy and comfortable method to achieve the required knowledge and skills, especially for development stakeholders such as diplomats and NGO staff who are geographically dispersed and who can't afford the time and money to take real training on SRHR. An evaluation of the e-tutorial and translation is foreseen in the near future. Introduction In September 2015, 193 governments formally approved a set of 17 Sustainable Development Goals (SDG) as a follow-up to the Millennium Development Goals (MDG) that expired last year. In light of this, governments across the world will be required to develop and implement new policies in order to achieve the targets set for these goals. Sexual and Reproductive Health and Rights (SRHR) lies at the immediate intersect of SDG3 (ensure healthy lives), SDG5 (achieve gender equality) and SDG10 (reduce inequalities), and has a direct link to many other goals. As a consequence, SRHR should have a central position in these new policies. The development of these new policies necessitates an evidence base to ensure their adequacy and effectiveness. Also, the success of their implementation is closely linked to reliable follow-up and monitoring. Finally, regular exchange of knowledge and sharing of experiences between different types of stakeholders and different countries can contribute to improving approaches and policies. Aim In light of the above, Ghent University established an Academic Network for Sexual and Reproductive Health and Rights Policy that aims to become a global resource for SRHR policy research, education and service delivery. Methods ANSER will achieve its aims by establishing an international platform for research on SRHR policy related topics; by developing a portfolio of education and training programs on SRHR policy; and by fostering interaction between SRHR researchers and policy makers. The network consists of 23 academic institutions from around the world. The ANSER network was officially launched on 30 November 2016, and a first ANSER conference was held on 1 and 2 December. During this conference, future collaboration was discussed and action plans were developed on specific topics. The establishment of ANSER created a new worldwide actor that aspires to narrow the rift between the realm of science and the realm of policy, and by doing so contribute significantly to the realization of the sustainable development goals. Addressing unsafe abortion in Benin: why is the current policy inappropriate? Aim Understand how the current policy response to unsafe abortion affects the abortion care seeking behaviour and the UA burden in Benin. We used a mixed explanatory study design at national level in Benin with focus on the biggest cities in the south and the north of the country. We conducted 55 semistructured interviews, one focus group and extracted data from the literature. Excel 2011 and NVIVO 10 supported the data analysis. The policy which addresses UA in Benin includes three strategies: i) reduce unwanted pregnancies through contraception; ii) limit access to abortion to preserve woman life, in cases of rape, incest or foetal impairment; iii) provide post-abortion care (PAC). Our study shows that those strategies are not operational. First, the modern contraceptive prevalence rate stagnates below 10% and 19% of pregnancies are unwanted. Second, that a woman is more likely to decide to terminate the pregnancy when the perceived psycho-socioeconomic consequences of pregnancy exceed those of abortion. In addition, the fear of the legal consequences was not a key obstacle to the abortion decision. In her abortion care seeking behaviour, the woman mobilizes a "health management" group that can be limited to herself or enlarged to its partner, relatives, friends, care providers and legal representatives of the society. This group influences decisions on how and where to abort according to financial resources, its social network and information available on abortion practices. Accessible abortion practices are of poor quality and rarely prosecuted in court. Finally, the fear of stigmatization prevents access to a limited number of currently available PAC services. The current policy to address UA in Benin is a failure from a public health perspective. A policy change is required taking into account actors, processes and contents of the chain of critical decisions around UA in Benin context. Sexual practices among men who have sex with men in Kinshasa, DRC Introduction HIV and other STIs responses must be based on vulnerability factors related to sexual practices and risky situations especially in key-populations. In Democratic Republic of Congo, MSM are considered as a key-population, however, data related to sexual practices in this group is limited. Aim To describe sexual practices and behaviors among MSM in Kinshasa. Methodology From March 2014 to December 2016, we recruited, consented and interviewed 324 MSM in Kinshasa social hotspots through a cross-sectional study using a snowball technique. We collected information on sexual practices and behaviors related to HIV and STI transmission. Of 324 participants recruited, the mean age was Aim To explore the socioeconomic extent of Intimate Partner Violence (IVP) in India the study analysing, the effect of IPV on use of reproductive health services among currently married women (CMW). The published data of most recent round of National Family Health Survey 2015-16 has used to fulfil the study objective. Univariate and bivariate analysis has performed to see the prevalence and extent of IPV across socioeconomic status of women. Further correlation analysis and binary logistic regression has done to understand influence of IPV on utilization of reproductive health services among CMW. Results Every one out of three CMW were ever experienced of IPV in India. Moreover, the prevalence of IPV ranged from 20-43% in the major states. Extent of IPV was more or similar across place of residence, however educated women were more likely to be experienced IPV than uneducated women. Women married at younger ages are more likely to experience IPV. While, multivariate analysis indicates that women who experienced IPV are less likely to use 4 + antenatal check-up, institutional delivery, and receive postnatal care for self and the new-born. IPV has also a significant negative influence on use of modern contraceptive use. The association between exposure to IPV and use of reproductive health care services suggests that partner violence plays a significant role in lower utilization of services among CMW in India. Findings suggest that, in addition to a wide range of socio-demographic factors, preventing maternal physical and sexual IPV need to be considered as an important psychosocial determinates for the higher utilization of reproductive health care services in the country. Timely action on this would be imperative to achieve the Sustainable Development Goals 5.2 elimination of violence against women and 5.6 universal access to reproductive health services. Introduction Safe male circumcision is an important biomedical intervention of the comprehensive HIV prevention programmes implemented in 14 sub-Saharan African countries. Over two million men have been circumcised under the national safe male circumcision program between 2010 and 2014 in Uganda. To sustain its partial protective benefit, it is important that perceived reduced HIV risk does not lead to behavioural risk compensation among circumcised men and their sexual partners. Aim This study explored beliefs that may influence post circumcision sexual behaviours among newly circumcised men in a program setting in Uganda. Methods Twenty-five men seeking circumcision services at public health facilities in the district were recruited from May to June 2015 and followed up for six months in a qualitative longitudinal study. They were interviewed at two and six months. Participants' beliefs and sexual behaviours were compared just after circumcision and at follow up to explore changes. Forty-eight interviews were held. Data were managed using atlas.ti7 and analysed following a thematic network analysis framework. Results Four themes were identified. Beliefs related to: (1) sexual cleansing, (2) healing, (3) post SMC sexual capabilities and (4) continued HIV transmission risk. Most men maintained or adopted safer sexual behaviour; being faithful to their partner after circumcision or using condoms with multiple sexual partners following the knowledge that there was continued HIV risk after circumcision. The most prevalent risky belief was regarding sexual cleansing post circumcision, and as a result of this belief, some men had one off sexual intercourse with a casual partner, without condom. A few resumed sex before the recommended period due to misunderstanding of what comprised healing. Many men however were able to reject the misconceptions even though they were prevalent in the study. Conclusion Although most men maintained safer sexual behaviour, there were instances of risky behaviour resulting from beliefs or misunderstandings of what comprised wound healing. Such beliefs need to be addressed because they may be widespread beyond the context of this study population and/or area. If so, they may expose some of the SMC clients to HIV infection.  "Never trust an open door" -Controversies of sexual pleasure, pain and female genital mutilation among African migrants in Belgium, the Netherlands and the UK Introduction Previous studies on African men's attitudes towards FGM in northern Europe and the US found that migrants rejected the practice. As far as the attitudes of African migrants in Belgium, the Netherlands and the UK are concerned, only limited data are available. Our study explored the lives and sexual experiences of men and women from FGM practicing communities living in diaspora in Belgium, the Netherlands, and the UK. Aim The research aimed to get a better understanding of men's perceptions how FGC/M might be related to sexuality. Methods During this qualitative research 9 focus group discussions and 60 individual interviews were undertaken among African men and women from FGM practicing communities in Belgium, the Netherlands and the UK. Research participants were recruited using a combination of purposive and snowball sampling techniques. Results Across all three countries, men suggested that FGM affected their female partner's and their own sex life negatively. Commonly mentioned effects of FGM were that cut women had less desire for sex, were in pain during intercourse or did not feel a lot of pleasure. Others reported not having noticed any difference in sexual relations between cut and uncut women and some mentioned that women with FGM enjoyed sex just as much as uncut women. Most male study participants suggested that sexual relations with uncut women were completely different to sex with women who have undergone FGM. Uncut women were reported as having a lot of sexual desire À sometimes more than men. The majority of female respondents in the Netherlands and in Belgium said that they did not enjoy sex very much. Women and men suggested that better communication about sexuality could drastically improve their sexual experiences. Conclusion Most respondents reported that FGC/M had a negative effect on the sex lives of women as it caused them physical pain and psychological problems, which could also affect their male partners. Most respondents thought that uncut women were more desirable for sex but less desirable for marriage. Women and men felt that their sex lives were improved through communication between couples as well as sexology. Introduction In most studies, less than 50% of individuals who test positive during home-based HIV testing link to HIV care at a facility. The CASCADE trial tests if proposition of same-day start of antiretroviral therapy (ART) improves linkage to care and viral suppression in individuals who are diagnosed HIV positive during home-based testing in Lesotho 1 . Aim To assess if same-day home-based ART start after a positive HIV test improves 3-months linkage to care and 12months viral suppression. Methods This open-label randomized controlled trial randomly assigned individuals who were newly tested HIV positive during home-based HIV testing to either same-day ART start (intervention) or referral to nearest clinic for preparatory counselling and ART start after ≥2 pre-ART clinic visits (standard of care (SOC)). Consenting individuals aged ≥18 years, who tested HIV-positive and were ART-naive were eligible. Linkage to care was defined as the participant presenting him-/ herself at the facility within 90 days of the home-based HIV test. Viral suppression was defined as viral load <100 copies/mL 12 months after the positive HIV test result. At time of abstract submission only final 3-months linkage data were available. By October 2017 viral suppression data will be available too. Trial registration: NCT02692027. Results A total of 276 ART-na€ ıve individuals were enrolled during home-based HIV testing from February 21st to July 7th, 2016 (137 intervention, 139 SOC). Baseline participant characteristics were balanced between arms: 65.8% were female, median age was 39 years (interquartile range (IQR): 28-52), median CD4 cell count 380 cells/lL (IQR: 249-530), 78.3% were staged as clinical WHO stage 1, median travel-time to nearest facility was 60 minutes (IQR: 10-240). Linkage to care within 3 months was 93/137 (67.9%) in the intervention versus 59/139 (42.5%) in the SOC group (P < 0.001). Full data on viral suppression will be available by October 2017. Conclusion In this trial offering same-day ART-initiation during home-based HIV testing campaigns increased subsequent linkage to HIV care at the facility. Same-day ART start may be used as a strategy to improve linkage from community-based testing to subsequent clinic-based HIV care in similar settings. Background Since 2012, the WHO has recommended Option B+ for the prevention of mother-to-child transmission of HIV. This approach entails the initiation of lifelong antiretroviral therapy in all HIV-positive pregnant women, also implying protection during breastfeeding for 12 months or longer. Research on long-term adherence to Option B+ throughout breastfeeding is scarce to date. Therefore, we conducted a prospective observational cohort study in Uganda to assess adherence to Option B+ until 18 months postpartum. Methods We recruited 67 HIV-positive, Option B+ enrolled women six weeks after giving birth in Fort Portal, Western Uganda and scheduled them for study follow-up after six, twelve and 18 months. Two adherence measures, self-reported drug intake of the previous month and rate of drug refill visits, were combined to define adherence, and were assessed together with feeding information and infants 0 HIV status at all study visits. Risk factors for postpartum adherence were analyzed. Results At six months postpartum, 51% of the enrolled women were considered to be adherent, and 91% of the babies had been exclusively breastfed for 6 months. Until twelve and 18 months postpartum, adherence for the respective follow-up interval decreased to 19% and 20.5% respectively. No woman was completely adherent until 18 months. At the same time, 76.5% of the women breastfed for 12 months or beyond. Longer breastfeeding duration was not linked with drug adherence. Risk factors for postpartum adherence to Option B+ were older age of the mother (P < 0.01), higher travel costs (P = 0.02), and higher number of previous deliveries (P = 0.04). We found no case of vertical transmission in our cohort. Conclusion Our results imply that postpartum long-term adherence is a challenge in Option B+ implementation, while at the same time, prolonged breastfeeding until 12 months or beyond is widely applied. This needs to be taken into serious account by healthcare providers, because poor postpartum adherence might eventually cause a setback in prevention of vertical transmission during the breastfeeding period. HIVpositive mothers require intense support for postpartum adherence to Option B + . Effectiveness in terms of low transmission despite suboptimal adherence needs to be verified in further research. Factors associated with loss to follow-up among women in Option B_PMTCT programme in northeast Ethiopia: A retrospective cohort study Introduction Ethiopia has recently adopted lifelong antiretroviral therapy (ART) for all HIV-positive pregnant and breastfeeding women (Option B_ strategy), regardless of CD4 count or clinical stage. However, the exact timing and predictors of loss to follow up (LFU) are unknown. Aim To examine the levels and determinants of LFU under Option _B among pregnant and breast feeding women initiated on lifelong ART for prevention of mother to child transmission (PMTCT) in Ethiopia. We conducted a retrospective cohort study among 346 pregnant and breastfeeding women who started ART at 14 public health facilities in northeast Ethiopia from March 2013 to April 2015. We defined LFU as 90 days since the last clinic visit among those not known to have died or transferred out. We used Kaplan-Meier and Cox proportional hazards regression to estimate cumulative LFU and identify the predictors of LFU, respectively. Of the 346 women included, 88.4% were pregnant and the median follow-up was 13.7 months. Overall, 57 (16.5%) women were LFU. The cumulative proportions of LFU at 6, 12 and 24 months were 11.9, 15.7 and 22.6%, respectively. The risk of LFU was higher in younger women (adjusted hazard ratio (aHR) 18 to 24 years/30 to 40 years: 2.3; 95% confidence interval (CI): 1.2 to 4.5), in those attending hospitals compared to those attending health centres (aHR: 1.8; 95% CI: 1.1 to 3.2), in patients starting ART on the same day of diagnosis (aHR: 1.85; 95% CI: 1.1 to 3.2) and missing CD4 cell counts at ART initiation (aHR: 2.3; 95% CI: 1.2 to 4.4). The level of LFU we found in this study is comparable with previous findings from other resource-limited settings. However, high early LFU shortly after ART initiation is still a major problem. LFU was high among younger women, those initiating ART on the day of HIV diagnosis, those missing baseline CD4 count and those attending hospitals. Thus, targeted HIV care and treatment programmes for these patients should be part of future interventions to improve retention in care under the Option B_ PMTCT programme. Background Cervical cancer stands for the major cause of cancer death in Africa. Here we wanted to assess whether screening for human papillomavirus (HPV) strains could identify women with premalignant cervical lesions. We also wanted to get a broader understanding in the underlying risk factors for the establishment of HPV infection. Methods 206 HIV+ women, 172 HIVÀ women and 22 women with unknown HIV status were recruited at the University Teaching Hospitals of Kigali (CHUK) and of Butare (CHUB) in Rwanda. After interview, participants underwent cytological sampling from the cervix for a Thinprep Pap test and a screening test analyzing 37 HPV strains. Results HIV+ women were more commonly infected by possible high-risk (HR)-and HR-HPV infections (21.4% vs 8.1%; P < 0.01) and had more often multitype HPV infections than HIVÀ women. The sensitivity was 78% and the specificity 87% to detect high-grade squamous intraepithelial lesions (HSIL) with HPV screening. Only 27% of HIV+ women and 7% of HIVÀ women had ever been cervical cancer screened. Lack of knowledge about screening and poor economy were reasons not to have undergone a previous screening test. Among HIVÀ women, being divorced was positively correlated to PHR/HR-HPV infection, while hepatitis B, Trichomonas vaginalis and PHR/HR-HPV were factors positively correlated to squamous intraepithelial lesions (SIL). Among HIV+ women, ever having a genital gonorrhea infection and not knowing if being ever infected by chlamydia were factors positively correlated to PHR/ HR-HPV infection. Being infected by PHR/HR-HPV and the number of live births were positively correlated to SIL. ARV treatment and a CD4 count >500 cells/mm 3 were negatively correlated to PHR/HR-HPV infection and SIL. Conclusions HPV screening may be an effective method to identify women at risk of developing cervical cancer in Rwanda. Information and economical support need to be given, particularly to patients with risk factors, to increase screening frequency and reduce cervical cancer mortality. HIV prevalence declines in southern Africa: have we misread the landscape? Introduction That sexual behaviour change is largely responsible for declining HIV prevalence in southern Africa is an accepted fact of HIV epidemiology. However, a recent study found that prevalence declined during the Malawi Famine 2001-03 as a result of migration from villages where prevalence was relatively low to towns and cities where it was higher. Migration was positively related to local levels of hunger and involved women <25 years disproportionately. The implications for how control is conceived are important if migration linked to food and livelihood insecurity is a significant driver of HIV epidemics. Aim To assess the extent and quality of evidence for migration as a contributor to HIV prevalence declines in southern Africa. Methods Systematic review of peer-reviewed articles documenting and seeking to account for prevalence declines in southern Africa 1998-2010. Comparison of evidence for the migration and behaviour change hypotheses in two articles assessing the decline in Malawi using the Hill framework. Results Besides the Malawi Famine study, 18 articles met the search criteria. Seventeen concluded that behaviour change was primarily responsible for the declines. One reached no definite conclusion. Only one article, from Eastern Zimbabwe, analysed migration into the study area, finding that it had contributed to prevalence decline but made no further mention of it. In all, 6 studies (33%) contained evidence, under-or unanalysed by the authors, suggesting migration contributed to prevalence declines. Women <25 years were prominent in these apparent migration streams which occurred mostly around the regional food crisis of which the Malawi Famine was part. In Malawi, the migration hypothesis appears to be better substantiated than the behavior change hypothesis notably in the strength of the association between prevalence decline and key explanatory variables, the presence of a dose-response relationship and extensive corroboration. Malawi, still suggestive elsewhere. Research must clarify this. Coping behaviours like migration occur at lesser intensity during 'normal' years however extreme events like the food crisis are becoming more frequent. A more thorough-going cross-sectoral response, as the SDGs envisage, is essential to address these critical health-livelihood linkages. Seasonal variation in child mortality in rural Guinea-Bissau Introduction Vaccines have played a major role in the decline in childhood mortality during the last decades. Vaccines are designed to protect against specific diseases, however, accumulating evidence support that vaccines may also have non-specific effects affecting mortality from other infections. Measles vaccine (MV) is associated with beneficial non-specific effects, whereas the Diphtheria-Tetanus-Pertussis (DTP) vaccine is associated with negative non-specific effects. DTP is recommended in 3 doses at 6, 10 and 14 weeks and MV at 9 months of age, but in practice many children receive DTP delayed and therefore DTP with or after MV (out-of-sequence). Recent studies suggest that the sequence of vaccines may be important. Aim We evaluated the non-specific effects of out-of-sequence vaccination of DTP and MV on mortality overall and stratified by sex. Methods Bandim Health Project runs a health and demographic surveillance system in rural Guinea-Bissau. Women of fertile age and their children are followed through biannual village visits. Children aged 9 to 18 months, who had their vaccination status assessed at a visit between April 9, 1991 and December 31, 1996 were included in the analysis. We assessed mortality until the next visit or for a maximum of 6 months. Using a Cox-proportional-hazards model with age as underlying time-scale, we compared the mortality rates of children vaccinated out-of-sequence with children vaccinated in-sequence. We included 5783 children contributing with 7145 observations in the analyses, 1929 observations for children who received DTP and then MV (in-sequence), and thus had MV as the most recent vaccine, 2274 observations for children who had DTP > = MV and 2251 observations with no MV. Children vaccinated out of sequence tended to have higher mortality compared with children vaccinated in sequence (MRR: 1.31 (95% CI: 0.85-2.01). Children, who had received DTP but no MV had significantly higher mortality compared with children vaccinated in-sequence (MRR: 1.75 (1.21-2.52). Adjusting for maternal education, region or ethnicity did not affect the estimates. Conclusion Out-of-sequence and missing measles vaccination was associated with higher mortality. Introduction Despite rapid progress in reducing under-five mortality (U5M), Sub-Saharan Africa still accounts for about half of all under-five deaths in 2015. Though the role of socioeconomic determinants has been widely highlighted, pathways from socioeconomic determinants to U5M and how these may differ between countries have not been well described. Aim To assess and compare pathways from selected socioeconomic determinants to U5M. Methods A conceptual framework of U5M was developed with the assistance of sub-Saharan African public health professionals. The relationships between key variables present in this framework were tested with data from national surveys in the Democratic Republic of the Congo (DRCongo), Ghana, Kenya and Lesotho. Poisson regressions and generalised structural equations for U5M were used to describe the pathways. The conceptual framework and both analytical approaches highlighted the role of distal determinants such as rural residence and mother's education. These socioeconomic determinants operate primarily through intermediate determinants such as safe drinking water (DRCongo), birth interval (DRCongo and Kenya), and skilled attendance at birth (Lesotho). Conclusion Testing conceptual frameworks with data from national surveys and appropriate statistical models can deepen our knowledge about possible country-specific pathways from socioeconomic determinants to U5M. Methods We performed a community-based cross-sectional survey of children aged 4-6 years in Chikhwawa District, Southern Malawi, utilising a village-level cluster design. Participants underwent a structured clinical assessment, including video-otoscopy and screening audiometry performed by a Malawian Clinical Officer. Middle-ear diagnoses were made remotely by two otolaryngologists who reviewed clinical data and images collected in the field. Hearing impairment was classified as failure to hear a pure tone of 25 dB at 1, 2 or 4kH. We recruited 281 children across 10 village-clusters. The prevalence estimates of CSOM, unilateral hearing impairment and bilateral hearing impairment were 5.4% (95% CI 2.2-8.6), 24.5% (95% CI 16.3-30.0), and 12.5% (95% CI 6.2-16.9) respectively. Treatable middle ear disease was seen in 46.9% of children with hearing impairment. Tele-otoscopy produced diagnostic middle ear data in 87.7% (493/562) of ears. Conclusion We found a high burden of treatable ear disease and hearing impairment in our study. Identification and management of middle ear disease and hearing impairment represent major unmet needs in this population. Protocolised tele-otoscopy assessment may facilitate extension of otolaryngology services to rural communities, and is worthy of further evaluation. Prevalence and incidence of schistosome infection and morbidity in pre-school children aged 6 months to 5 years Background For a long time, pre-school children have been considered low-risk for schistosomiasis, received lower research focus and have been excluded from mass drug administration. Aim Here, we describe the prevalence and incidence of first schistosome infection and morbidity in children aged 6 months-5 years. Methods This is part of a larger longitudinal study of schistosome infections in children aged 6 months-5 years in selected villages in Zimbabwe. A total of 1502 children were recruited in February 2016. Basic demographic and anthropometric measurements was gathered. Stool and urine samples were taken from each child (in triplicates) for parasitological diagnosis of S. haematobium (urine-filtration) and to rule out S. mansoni and soil-transmitted helminths (Kato-Katz) respectively. Markers of morbidity including haematuria (macro, micro) and faecal occult blood (FOB) were assessed using reagent dipsticks and rapid tests. S. haematobium negative children were split into two groups, followed up quarterly and annually. hippurate as well as the common urinary metabolite, creatinine, contributed most prominently to the differences. Conclusion These analyses provide insights into the metabolic phenotype of schistosomiasis and treatment with praziquantel. These findings, along with comparisons with microbial and pharmacokinetic studies from the same cohort, could provide a holistic systems-level illustration of pathology and clearance of schistosomiasis, host-parasite-microbiome interactions and praziquantel pharmacodynamics in an important demographic. Etiologies of fever episodes among children under 5 years in a seasonal malaria transmission area, Burkina Faso Introduction Fever remains a major public health problem and a key symptom at clinic level, especially among children under 5 years of age (1) . With the reduction of global malaria prevalence, it becomes critical to determine the actual etiology of a febrile episode. However, in Sub-Sahara Africa there is limited data available on fever etiologies (2) (3). Aim To contribute to a better understanding of the etiologies of fever episode in children under 5 years of age living in malaria endemic areas. Method A prospective etiology study was conducted in Nanoro (Burkina Faso) in 2015 among febrile children under 5 years of age. Blood, urine, stool and nasopharyngeal swab were collected and viral, bacterial and parasitological assays were performed on these samples. Results A total of 684 febrile children were included. Plasmodium falciparum malaria was found in 49.7% (340/684) and other Non-Malaria Infections (NMIs) in 49.1% (336/684) of the febrile children. The NMIs included gastro-intestinal infection (GII), bacterial respiratory tract infection (bRTI), bacterial bloodstream infection (bBSI) and urinary tract infection (UTI) in 37.0%, 24.3%, 6.0% and 1.8% of the cases, respectively. Nearly 46% (154/336) of the NMIs group were coinfected with malaria. However, only 7.1% (11/154) of these the NMI could be considered to be an alternative explanation for the fever. In contrast in the malaria negative group 34.1% (62/ 182) of the NMIs could explain the fever episode. No pathogens were isolated in 23.5% (162/684) of the febrile cases. Conclusion Malaria remains the predominant pathogen isolated in febrile children in Burkina Faso. Our data indicate that the malaria test could also be used to estimate the chance that an alternative etiology, often needing treatment, should be considered. However, there is still a need for the development of a point-of-care test to screen for (treatable) NMIs. Introduction Worldwide caesarean section rates are rising, in high-income and low-income countries. 1 The WHO described a percentage of 5-10% within a population as ideal, whereby rates above 10% show no improvement on maternal and neonatal mortality rates. 2 Since caesarean sections are associated with increases in severe maternal outcomes, caesareans without proper medical indication should be avoided, especially in lowresource areas. 3 It can be useful to analyse facility indications and pre-operative decision-making in order to improve the quality of care. Malawian hospital, in order to find opportunities in reducing the number of unnecessary procedures. Methods In a rural hospital in Malawi with a relatively high percentage of caesarean sections (23% in 2015), an analysis of indications was performed. Patients files and adherent partograms of caesarean section cases in the selected period were analysed, whereby indications were audited and compared to national protocols. Results From a 2-year period, 531 case files of caesarean sections were obtained and reviewed. The most frequent indication was cephalopelvic disproportion (CPD; 26%). In 54% of the cases in which the indication was CPD, there was no sign of prolonged labour. In 38.6% of cases in which CS was performed because of prolonged first stage of labour membranes were still intact and in less than 10% of these cases augmentation with oxytocin was done. In prolonged second stage of labour, an assisted delivery attempted before proceeding to caesarean section in only 12% of the cases. In the designated facility, which resembles others in rural Malawi and surrounding countries, indications for caesarean section for presumed prolonged labour are often made without clear signs. Furthermore, interventions during labour which might improve chances of vaginal delivery, are not being used frequently. In a low-resource setting, where complications of major surgery are not uncommon, this could lead to increased maternal morbidity and mortality. Auditing cases and better adherence to international and local protocols could reduce the number of unnecessary caesarean sections and therefore have a positive effect on maternal and neonatal outcomes. Introduction Collecting longitudinal data from marginalized individuals remains an enormous challenge, especially in geographies where there is limited access to health care and poor infrastructure. Mobile technology is widespread, and may simply follow-up among such hard to reach populations, facilitating low-cost participant retention in facility-based studies once participants return to their home communities. Aim To describe our experience using mobile phone follow-up in a longitudinal study of women surgically treated for obstetric fistula in Uganda. Methods We conducted a longitudinal study among 60 women operated for obstetric fistula at Mulago Hospital, Kampala, Uganda, following them for 12 months post-repair and capturing data every 3 months in-person (baseline) or via mobile telephone (all subsequent). We analyzed data on participant retention at all data points, the number of calls required for securing data capture, any special follow-up required, and alternative costs to mobile data collection. Results Over the 12-month follow-up period, participant retention was high, with 59 participants at 3 months, 59 at 6 months, 55 at 9 months, and 58 at 12 months. Most data collection points required only one call to the primary number; however, mean numbers of calls to both primary and secondary numbers were increased at 6 and 9 months. Other challenges experienced included loss or breakage of phone (n = 2), poor mobile network and occasional difficulty reaching participants during a regular work schedule, requiring staff flexibility. Study staff followed-up with one participant at their residence at each follow-up data collection period. Participants lost to follow-up were out of touch with family members (n = 1) or had left the country (n = 1). Participant acceptance of mobile phone followup was high; the majority preferred mobile follow-up as it did not require travel. Use of this technology was cost savings for the project. Conclusion Overall, use of mobile phones for data collection within the context of a year-long longitudinal study among Ugandan women operated for obstetric fistula at Uganda's national referral and teaching hospital resulted in high participant retention and cost savings. Technology-based data capture may assist with participant retention in other studies among geographically dispersed subjects in low-resource settings. The effect of improved trends in use of the partograph to actively monitor labor on newborn outcomes in southwestern Uganda K. G. Ndagire 1 , I. Kirunda 2 , P. Kagurusi 3 and P. Mudiope 4 1 Reproductive Maternal Newborn and Child Health, USAID RHITES SW Amref Health Africa, Mbarara, Uganda; 2 Quality Improvement, USAID RHITES SW Elizabeth Glaser Pediatric AIDS Foundation, Mbarara, Uganda; 3 Repoductive Maternal Newborn Child and Adolescent Health, Amref Health Africa, Kampala, Uganda; 4 Clinical Services USAID RHITES SW Elizabeth Glaser Pediatric AIDS Foundation, Mbarara, Uganda Introduction Uganda's newborn mortality was at 27/1000 live births in 2011 1 . Although there has been a slight decline over the years, achievements are less than the desired targets nationally and globally. Reasons cited include poor quality of care at health facilities 2 . In 2011 Southwestern Uganda recorded the 2nd highest perinatal mortality rate in the country of 48/ 1000 2 . Baseline USAID RHITES SW project data collected at the beginning of 2016 revealed that just only 40 (21%) of the 190 health facilities had more than 95% of deliveries monitored using correctly and completely filled Partographs. Aim To analyse the effect of adopting the correct use of partographs for monitoring maternal and foetal wellbeing during labour on newborn outcomes. Methods Between April and September 2016, the project distributed partographs to 233 facilities in 15 districts of Southwestern Uganda. Subsequently, program technical teams conducted CMEs and performed one-on-one coaching for health workers on use of a partograph to monitor labour at the sites over a period of 4 months. For selected high volume sites, training in BeMONC was done. Monthly qualitative and quantitative data on partograph use was collected from the 43 sites over the four quarters of the projects first year. Results At the end of September 2016, 43 randomly selected high volume sites were assessed. Monthly partogram use at these sites was found to have increased from 10% in October 2015 to 52% in September 2016. The average proportion of mothers monitored during the four quarters was 7%, 8% 27% and 47% respectively. Data on fresh still births (FSBs) at the same facilities for the period under review was extracted from DHIS2 and compared with trends in partograph use. A decline in proportion of FSBs of correlation of 49 (1.37%) in October 2015 to 17 (0.57%) of total deliveries in September 2016 was observed. Conclusion Knowledge gaps significantly contribute to limited use of the partogram to monitor labor progress. Building capacity and ensuring availability results into increased use and consequently improved newborn outcomes. Results Vector research requires flexibility and persistence to overcome the challenges of working with under-studied systems. The lack of pre-existing research into parasite transmission between vectors and hosts means it presents an enticing opportunity for new researchers. However, the difficulties can be significant; the lack of specialised equipment or reagents specific to our needs often requires expensive custom products or the ability to make our own. Working at LSTM, a world leading institute in tropical medicine, I have an unparalleled opportunity to meet and work alongside eminent scientists from around the world in an exciting and driven research environment. This training stands NTD researchers in excellent stead to be highly competitive scientists. Additionally, outcomes from NTD research have the potential to drastically improve health and quality of life, often in the poorest, most marginalised populations. Knowing that the contribution I make to the field may have such positive impacts, the work I do feels valuable and rewarding. However, concerns about the future of NTD research in the UK, particularly considering the increasingly inwardlooking nature of our political climate, could affect how many students remain in this field in the long term. Conclusion Where funding and opportunities are limited, barriers to progression may force researchers to change paths. Public engagement is vital, communicating the value of tropical medicine outside of the tropics will help to ensure the continued survival of the discipline, and should be a key component of training programmes. NTD research can be a rewarding and dynamic career choice, but without continued investment by funders, governments and institutes, this path could become unsustainable for the next generation of scientists. 
