1c8677db11d0984021120e5eddd2e765250deee3
S13 REFERENCE(S). 1. Squara P, Denjean et al (2007) Noninvasive cardiac output monitoring (NICOM): a clinical validation
R B G E Breukers A B J Groeneveld C  Den Uil A  Maat W  Lagrand M  Van Der Ent L  Jewbali R  Van Thiel P  Spronk M  Simoons D  De Backer G  Marx A  Tan C  Junker M  Van Nuffelen L  Hüter W  Ching F  Michard J.-L  Vincent A J Jordan M  Jonas C  Allen M  Celinski D  Richardson E  Abitbol S  Janower J.-C  Dib A  Nguyen P  Squara D  Rotcajg D  Denjean P  Estagnasie A  Brusset N J Lees M  Singer 

Intensive Care Intensive Care Intensive Care Intensive Care University of Amsterdam Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care University of Amsterdam George Washington University Medical Center Intensive Care Jena University Hos-pital  Intensive Care Intensive Care University of Amsterdam University of Amsterdam University of Amsterdam University of Amsterdam Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care 
BACKGROUND. Mathematical coupling may explain why cardiac filling volumes obtained by transpulmonary thermodilution may better predict and monitor responses of cardiac output to fluid loading than pressures obtained by pulmonary artery catheters (PAC). METHODS. Eleven consecutive patients with hypovolaemia after coronary surgery and a PAC, allowing central venous pressure (CVP) and continuous cardiac index (CCIp) measurements, received a femoral artery catheter for transpulmonary thermodilution measurements of global end-diastolic volume index (GEDVI) and cardiac index (CItp). One to five fluid loading steps of 250 mL were done in each patient (n = 48 total). RESULTS. Fluid responses were predicted and monitored similarly by CItp and CCIp, whereas CItp and CCIp correlated at r = 0.70 (p \ 0.001) with a bias of 0.40 L min -1 m -2 . Changes in volumes (and not in CVP) related to changes in CItp and not in CCIp. Changes in CVP and GEDVI similarly related to changes in CItp, after elimination of two patients with greatest CItp outliers (as compared to CCIp). Changes in GEDVI correlated better to changes in CItp when derived from the same thermodilution curve than to changes in CItp of unrelated curves and changes in CCIp. CONCLUSIONS. After coronary surgery, fluid responses can be similarly assessed by intermittent transpulmonary and continuous pulmonary thermodilution methods, in spite of overestimation of CCIp by CItp. Filling pressures are poor monitors of fluid responses and superiority of GEDVI can be caused, at least in part, by mathematical coupling when cardiac volume and output are derived from the same thermodilution curve. Bland-Altman plot for cardiac index measurements with help of the transpulmonary (CItp) and pulmonary (CCIp) continuous thermodilution techniques Scatterplots showing relationship between the fluid-induced changes of global end-diastolic volume index (GEDVI) and transpulmonary (panel A) or pulmonary continuous (panel B) thermodilution techniques OBJECTIVES. To evaluate the effects of active mechanical circulatory support on sublingual microcirculation as a model for body tissue perfusion. METHODS. Between May 2008 and January 2009, nine consecutive patients received a mechanical support device (HeartMate II, TandemHeart, or extracorporeal membrane oxygenation) for end-stage chronic heart failure or cardiogenic shock. Microcirculation was investigated using a hand-held sidestream dark field imaging device. Perfused capillary density (PCD) and capillary red blood cell velocity (cRBCv) were assessed before device implantation (T0), immediately after implantation (T1), and one day post implantation (T2). Data are presented as median (interquartile range). RESULTS. Median age of the patients was 44 (37-54) years and 67% were male. Circulatory support devices significantly decreased pulmonary capillary wedge pressure (p = 0.04). Cardiac power index increased [0.31 (0.19-0.35) W m -2 at T0 vs. 0.50 (0.42-0.54) W m -2 at T1, p = 0.008) as well as central venous oxygen saturation [52 (46-61) % at T0 vs. 76 (65-85) % at T1, p = 0.01). There was a fourfold increase in tissue perfusion index, defined as sublingual PCD 9 cRBCv, during mechanical circulatory support [544 (384-671) at T0 vs. 1,932 (1,854-2,842) at T1, p = 0.008; Fig. 1 ). Microcirculatory parameters remained improved at T2. CONCLUSION. Mechanical circulatory support for severe heart failure is associated with a consistent, significant and sustained improvement in tissue perfusion, as measured at the bedside by a two-dimensional microcirculation imaging technique. INTRODUCTION. The second generation FloTrac software has been shown to reliably measure cardiac output (CO) in cardiac surgical patients. However, concerns have been raised regarding its accuracy in vasoplegic states, so that a new software has been developed (third generation). OBJECTIVES. The aim of the present multicentre study was to investigate the value of the third generation software in patients with sepsis, particularly when systemic vascular resistance (SVR) is low. We studied 58 septic patients with a pulmonary artery catheter and a radial (n = 32) or femoral (n = 26) arterial catheter. Reference CO was measured by bolus pulmonary thermodilution (iCO) using 3-5 cold saline bolus injected randomly through the respiratory cycle. Simultaneously, CO was computed using the second (CO G2 ) and the third generation FloTrac software (CO G3 ) from the arterial pressure curve recorded on a computer. CO was also measured by semi-continuous pulmonary thermodilution (CCO). A total of 401 simultaneous measurements of iCO, CO G2 , CO G3 , and CCO were available for comparison. RESULTS. The mean bias between CO G2 , CO G3 , CCO and iCO were -12 ± 16% (-1.0 ± 1.2 l/min), -3 ± 15% (-0.2 ± 1.1 l/min), and 8 ± 13% (0.6 ± 1.1 l/min). The percentage errors were 33% for CO G2 , 29% for CO G3 , and 29% for CCO. The bias between iCO and CO G2 was significantly correlated with SVR (r 2 = 0.37, p \ 0.0001). A very weak (r 2 = 0.05) relationship was also observed for the bias between iCO and CO G3 . The bias between iCO and CCO was not correlated with SVR. CONCLUSION. In patients with sepsis, the third generation FloTrac software is more accurate, more precise (percentage error \ 30%) and much less influenced by SVR than the second generation software. INTRODUCTION. The use of cardiac output (CO) values to provide a more detailed overview of the patient's circulation has driven the development of less invasive CO monitoring and allowed applied physiology to guide treatment. The LiDCO TM plus, monitor has been extensively validated in the ICU setting. It combines two systems; (1)The PulseCO system which uses a signal analysis (autocorrelation) to calculate continuous beat-to-beat CO from the arterial waveform (2) lithium dilution calibration to give a stat CO value. A unique calibration factor (CF) is derived from the combination of the software analysis and stat CO values, The CF is patient specific and scales the stroke volumes [vol = CF 9 250 9 (1 -exp(-k 9 P)]. The CF is proportional to aortic compliance which is known to be strongly influenced by the demographic differences between individuals. OBJECTIVES. To explore the relationship between CF and gender, age, weight and height and to determine if the CF can be estimated using this data. METHOD. 22 patients in ITU who had a LiDCOplus in clinical use were studied and relevant data, were recorded. LiDCO calibrations were performed as per our ICU protocol. Two initial calibrations at set up (avgCF) and at 24 h intervals thereafter (more frequently in the face of major haemodynamic changes). Data were collected from the obs chart and by electronic download from the LiDCO monitor. RESULTS. Gender, age, height and weight had moderate to good association to the avgCF. Using multivariable regression an equation was developed to estimate CF. (AvgCF = 0.391-0.176 9 sex -0.006 9 age ? 0.002 9 weight ? 0.511 9 height). Using this equation a Bland Altman graph was plotted which shows good agreement between the estimated and LiDCO generated values for CF. Mean bias was -0.007 and was not statistically significant (p = 0.853). 95% of the data lies between ±0.4-the majority of differences lying between ±0.2. CONCLUSION. Gender, age, weight and height all have a relationship to the average of the initial two CF's. The estimated value of the CF derived from an equation using multivariable regression showed good agreement with the actual LiDCO generated CF. Further analysis using this new data is ongoing and is being used to validate this equation further. REFERENCE(S). 1. Remington JW, Noback CR, Hamilton WF, Gold JJ (1948) Volume elasticity characteristics of the human aorta and prediction of the stroke volume from the pressure pulse. Am J Physiol 153:298-308. Bland Altman: estimated CF versus LiDCO Derived CF INTRODUCTION. Changes of cardiac output (CO) during passive leg raise (PLR) have been proposed as an easy, reproducible and reversible method for selecting patients that would benefit or not from fluid administration. A non invasive bioreactance-based technology (NI-COM) has proved to be accurate, precise and responsive for continuous CO monitoring [1]. OBJECTIVE. This study was designed to compare the PLR-induced change in CO as assessed by the NICOM and by trans thoracic echo-doppler (ECHO). We included patients programmed for major (cardiac, vascular and abdominal) elective surgery or during the recovery period of these operations. All patients were in stable normal hemodynamic conditions without any drug infusion. Values of CO were collected: before PLR (baseline), after 2 min of PLR made with a 45°angle (test) and 5 min after test return to baseline. NICOM values were obtained continuously and 3 min were averaged for comparison with ECHO. ECHO analyses were performed by seniors experienced cardiologists and three measurements were averaged. For each patient, predicted CO from physiological normative tables was also collected using a validated computer software. Since all patients were in stable steady state, this predicted CO at basal metabolism was taken as reference value for baseline and return to baseline. We obtained complete data form 50 patients, 39 men 11 women, age 63 ± 28 years, LVEF = 56 ± 9%. NICOM and ECHO values of CO were close at baseline (5.59 ± 1.32 vs. 5.51 ± 1.22, NS) and also very close to predicted values: 5.50 ± 0.91. During PLR and after PLR (return to baseline 2) (NS for all differences) NICOM and ECHO CO values were close (6.28 ± 1.50 vs. 5.96 ± 1.39, NS) and well correlated (NS from the identity line). The mean bias was = 0.08 L/min and the limits of agreement were 1.8 L/min giving a coefficient of variation of 32%. During PLR mean CO absolute increase tended to be higher for NICOM than for ECHO but did not reach significance (p = 0.11) as well as for proportional increase (13 ± 14 vs. 8 ± 6%, p = 0.07). The mean difference in PLR-induced CO changes between NICOM and ECHO was 5 ± 14%. In 68, 86 and 94% of the patients the discordance between the two devices was B10, B20 and B30%, respectively. The discordance was due to higher NICOM CO changes than ECHO during PLR is a vast majority of cases: 94, 98 and 100% for discordances [10, 20 and 30%, respectively. CONCLUSION. In this cohort of 50 volunteers in stable hemodynamic status before major cardiac surgery, CO was acceptably comparable at baseline and during PLR using NICOM and ECHO. INTRODUCTION. Cardiac output (CO) monitoring is limited by the need for invasive, expensive, or time-consuming methods. A new, noninvasive, system for continuous CO monitoring, based on chest bioreactance, has proved to be easy to use, accurate, precise and responsive [1]. OBJECTIVE. The objective of this study was to compare CO and stoke volume (SV) monitoring capabilities of this transthoracic bioreactance-based monitor (NICOM) with those of a pulse contour-based system (PICCO PC) using transpulmonary thermodilution (PICCO TD) as reference method. We designed a prospective, single center study in Intensive care unit, including consecutive, post-cardiac surgery, adult patients. Continuous minute-by-minute hemodynamic variables obtained from NICOM and PICCO PC were recorded and compared in 15 patients at baseline, during a lung recruitment maneuver (applying 20 cm H 2 O of PEEP) and following withdrawal of PEEP. PICCO TD measurements were also determined at baseline and during and after PEEP. The NICOM system uses an independent autocalibration process. PICCO TD was used automatically for calibration of PICCO PC. At baseline, we evaluated the accuracy (bias with the reference) and precision (2SD/mean) of these devices to measure CO and SV. During PEEP application and removal, we then assessed time responsiveness, amplitude responsiveness and reliability for detecting expected CO and SV changes. Mean CO values (PICCO TD) ranged from 1.6 to 8.0 L min -1 . At baseline, CO values were comparable for NICOM, PICCO PC and PICCO TD: 5.3 ± 1.2, 5.0 ± 1.5 and 4.8 ± 1.3 L min -1 , respectively (NS). The CO precision was 8 ± 7 and 9 ± 5% for NICOM and PICCO PC, respectively, NS. When PEEP was applied, CO was reduced by 33 ± 13%, 31 ± 15% and 35 ± 13%, for NICOM, PICCO PC and PICCO TD, respectively (NS). Time responsiveness was 3.2 ± 0.7 min for NICOM versus 2.6 ± 0.5 min for PICCO PC (NS). In all patients, the two studied technologies and the reference method showed a decrease in CO. SV results were comparable to CO. When all interpatients averaged points at baseline, during PEEP application and after PEEP removal were plotted together, the correlations NICOM versus PICCO TD and PICCO PC versus PICCO TD were comparable and not significantly different from the identity line. The mean bias of NICOM and PICCO PC was small (0.25 vs. 0.10 L min -1 , respectiveiy) and limits of agreement shown were quite large due to rapid and large changes in CO but comparable for NICOM (1.83 L min -1 ) and PICCO PC (1.93 L min -1 ), despite automatic recalibration of the PICCO PC. CONCLUSION. In this study, bioreactance and pulse contour analysis calibrated by transpulmonary thermodilution have comparable CO and SV monitoring capabilities. A huge variability in excess risk of death, ranging from 0 to 40%, from ventilator associated pneumonia (VAP) have been reported in the literature [1] . This large between-study variation can be attributed to difference in definitions but also to incorrect estimation by standard statistical methods, i.e. inappropriate adjustment for informative censoring and time dependent confounders. The aim of this study was to take into account above statistical shortcomings and to assess the excess risk of VAP by using an extension of a recently developed techniques from the field of causal inference [2] . MATERIALS AND METHODS. Data was retrieved from a large longitudinal, high quality multi-centric ICU database from France (OUTCOMEREA). A random sample of consecutive patients ventilated [48 h from 17 ICUs over a 10 year period were included. VAP was defined as clinical suspicion plus at least one positive proximal or distal sampling with quantitative count using classical thresholds. Only the first VAP episode was taken into account. We considered discharge from the ICU as a competing risk and estimated the attributable 30-day ICU mortality of VAP by comparing the counterfactual cumulative incidence of death for the entire population under different hypothetical infection paths. Baseline characteristics indicating underlying co-morbidity and longitudinal (daily measured) severity of illness indicators together with all other known confounders until VAP developed were taken into account through the use of a marginal structural model [2] . RESULTS. A total of 4,333 ICU patients were included. Mean (SD) age and SAPS II score were 63 (17) and 49 (18), respectively. Seventeen and 21% were admitted after scheduled and emergency surgery respectively, 62% were medical patients. Forty-two percent had an underlying chronic illness (Knaus). Nine percent received dialysis in the ICU. A total of 647 (15%) patients developed VAP within 30 days of admission (48 and 82% within 7 and 14 days, respectively). Crude ICU-mortality rates in patients with and without VAP were 35 and 25%, respectively. When taking into account all the confounders, we found a 3.5% increase (95% CI 1. 7-5.3 , p = 0.0002) in the hazard of 30-day ICU-death per additional day since the development of VAP. Provided VAP could have been prevented in the whole population 30-day mortality would have decreased by 0.7%. CONCLUSION. The excess risk of death from VAP estimated by marginal structural models is lower than commonly reported in the literature. This indicates that underlying comorbidities and the evolution of severity of illness until VAP are insufficiently taken into account by current standard statistical methods. REFERENCE (S) . 1. Rello et al (2003) INTRODUCTION. The intensive care society (UK) has recently published national guidelines regarding many aspects of percutaneous tracheostomy management [1] , however, these guidelines do not make any recommendations regarding antibiotic prophylaxis during the procedure. We recently audited UK practice and have established that only 9% of the units give prophylactic antibiotics for patients known to be colonised with Methicillin-resistant Staphylococcus aureus. The low rate of antibiotic use is surprising given that pneumonia and/ or bacteraemia following PT is frequently caused by organisms (non-MRSA) that colonise the patients' skin and/or airway [2, 3] . OBJECTIVE. To establish the incidence of MRSA positive sputum and/or blood cultures following PT in patients colonised with MRSA in their nose or throat. METHODS. We audited all the patients who had PT performed between 2005 and 2009 who were known to be colonised with MRSA in their nose or throat, (but who had negative sputum cultures) before PT was undertaken. We wanted to find how many of these patients developed MRSA positive sputum and/or blood cultures in the first week following their PT. RESULTS. From a total of 2004 patients admitted to critical care between 2004 and 2009 only seven MRSA colonised patients required PT. All of these 7 patients had MRSA colonised throat or nose with negative sputum and blood cultures prior to the PT. No patients were given prophylactic antibiotics during the PT as this was our standard practice. Four (57%) developed MRSA positive sputum cultures in the first week following the procedure. One (14%) developed MRSA bacteraemia on day 4 following PT. Over the same period there were no case of MRSA bacteraemia in the 118 MRSA colonised patients who did not undergo PT. Microbiology Bacterial biofilm has been observed in the surface of the endotracheal tube (ETT) in mechanically ventilated patients and recent studies relate the presence of biofilm with the incidence of ventilator-associated pneumonia (VAP). Acinetobacter baumanii is a Gramnegative opportunistic nosocomial pathogen involved in the production of VAP, and capable of biofilm formation on abiotic surfaces. OBJECTIVE. To analyse the presence of biofilm in the ETT by using scanning electron microscopy (SEM) and to identify the microorganisms contributing to its formation in patients admitted in an ICU endemic for A. baumanii. METHODS. From March to September 2008, 86 consecutive patients admitted to our unit and mechanically ventilated were included in the study. ETTs after extubation were (a) sent to microbiological culture, and (b) fixed with 4% paraformaldehyde-2% glutaraldehyde for one hour, dehydrated with increasing ethanol concentrations, and processed for SEM. ETTs were observed under SEM to assess the presence and extension of the biofilm, and to recognize bacterial or fungal forms. RESULTS. There were 57 males (66%) and 29 females (44%) with a median age of 60 years (range 16-86).The median APACHE II score in the first 24 h was 20 (range 14-45). The median duration of intubation was 6 days (range . Causes of intubation were coma in 41 patients (48%), respiratory failure in 34 (40%), and heart failure in 11 (13%). The microbiological isolations showed: A. baumanii (24%), Staphylococcus non aureus (16%), pseudomonas spp. (16%), Streptococcus viridans (13%), Staphylococcus aureus (12%), Enterococcus faecalis (9%), Candida albicans (8%), and others (15%). Under the SEM, biofilm was identified in the 79% of all cases and was abundant in 29 (34%), regular in 25 (30%), and scarce in 13 (15%). Morphological identification of microorganisms observed under SEM showed: cocci in 11 (13%), bacilli in 15 (17%), and yeast in 5 (6% INTRODUCTION. Hospital-acquired infection is often linked to the standard of ward cleaning however the impact of increased quality of cleaning and deep cleans are unknown. OBJECTIVES. This study aimed to determine the effect of enhanced cleaning on local contamination rates of hospital pathogens and whether this results in a reduction in patient colonisation. A cross-over one-year study was performed in the intensive care units (ICU) of two teaching hospitals, which screened patients weekly for MRSA. In randomized two-month periods and in addition to conventional cleaning using detergent and mops, high contact areas were cleaned twice daily by a team of trained hygiene technicians using microfibre cloths. Using contact plates, samples were taken at nine sites around the bed area and ward over 12 bed-days per week. Hand hygiene was encouraged and compliance audited. RESULTS. Only 2.5% of the planned 20, 736 local samples were missed and this was equal between study phases. Average hand hygiene compliance was similar between enhanced and standard phases [Hospital A 47.8% (261/546) vs. 56% (268/478) and Hospital B 57.3% (259/ 452) vs. 52.7% (266/505)]. Patient characteristics were similar during standard and enhanced cleaning periods. Of the sites tested, samples taken from bed rails were most likely to be contaminated with MRSA (OR = 4.16; 95% CI: 2.65-6.54) followed by nurses' hands (OR = 1.89; 95% CI: 1.14-3.11). Analysis of these site-samples also confirmed that enhanced cleaning significantly reduced environmental contamination (OR = 0.45; 95% CI: 0.34-0.61; p \ 0.001). The effectiveness of enhanced cleaning in removing MRSA contamination did not vary with the sample site. A sub-group analysis of samples only taken from nurses' hands showed a non-significant reduction in MRSA hand contamination associated with enhanced cleaning although associated uncertainty was large (OR = 0.56; 95% CI: 0.29-1.08; p = 0.077 CONCLUSIONS. This is the first prospective controlled study examining the effectiveness of enhanced cleaning in preventing spread of multiresistant pathogens within ICU. Although both environmental and hand contamination were reduced, enhanced cleaning of high contact surfaces was not associated with a reduction in cross infection. CONCLUSIONS. ISD of secretions reduces the incidence of VAP in patients receiving. CSS alone, or in combination with ISD has no significant effect on incidence of VAP. Hence, ISD may be recommended for VAP prevention, considerations other than prevention of VAP should determine the choice of the suction system in a mechanically ventilated patient. To show a mortality benefit, larger, multi-center trials may be required. Decreasing incidence of ventilator-acquired pneumonia (VAP) is increasingly regarded as a priority in ICU quality programs. Subglottic secretion suctioning (SSS) has been associated with a decreased risk of VAP. A previous metaanalysis concluded that SSS reduces the risk of VAP, but it included only five randomized controlled trials (RCT), and SSS is still underused, perhaps considering the available evidence is insufficient. We planned a systematic review and metaanalysis of SSS for VAP prevention. PubMed, Embase and CDSR were searched for RCT studying the influence of SSS on VAP incidence. Additional outcomes were mortality (within ICU or hospital), ICU and hospital stay, mechanical ventilation duration and time from intubation to VAP diagnosis. Additional references and sources of information were searched, and authors were contacted as necessary. 11 RCT were found, but one of them was excluded for not having enough data for analysis. 10 RCT were analysed, including 2,019 patients. Quality of the RCT was only moderate. Qualitative outcomes were homogeneous between studies, so were analysed by a fixed effects model; quantitative outcomes were very heterogeneous, and were analysed by a random effects model. Compared to control, SSS decreased VAP incidence (RR 0.53; 95% CI 0.43-0.66), but not mortality (RR 0.97; 95% IC 0.80-1.16). SSS delayed VAP onset for 4.08 days (95% CI 2.63-5.52), shortened mechanical ventilation for 1.58 days (95% CI 0.71-2.45) and decreased ICU length of stay for 1.97 days (IC 95% 0.02-3.91). In two RCT, no differences were found in the hospital length of stay. CONCLUSION. SSS reduces VAP incidence and delays VAP onset, shortening mechanical ventilation and ICU length of stay, but not decreases ICU or hospital mortality. Data from 10 RCT support the use of SSS as an adjunctive tool to prevent VAP. INTRODUCTION. In comparison to ventilator-associated pneumonia (VAP), less data are available on ventilator-associated tracheobronchitis (VAT). However, VAT may be associated with considerable morbidity [1] . AIM. To investigate prospectively the incidence and outcomes of VAT. We studied prospectively all patients who received mechanical ventilation in the general Intensive Care Unit of a tertiary hospital in Greece between September-November 2008. VAT diagnosis required Temperature ([38°C) or leukocyte count [12.000 per mL or leukopenia \4.000 per mL) (at least one of these) plus new onset/change of purulent endotracheal secretions. VAP diagnosis required the aforementioned criteria plus appearance of new and persistent pulmonary infiltrates on chest radiography. Microbiological documentation was based on the growth of microrganisms in bronchial aspirations ([100.000 cfu) or BAL ([10.000 cfu) . RESULTS. Forty-six patients were included, median (IQR) age was 57 (49. years. Eleven (24%) patients presented VAT, 11 presented VAP and 24 patients presented none of these two disorders (NP). There were no significant differences between VAT and VAP cases in terms of baseline characteristics (diagnosis, respiratory compliance, APACHEE, Murray score), occurrence of sepsis or ARDS and microbiology; pseudomonas aeruginosa, acinetobacter baumannii, staphylococcus aureus and klebsiella pneum. were the most common bacteria in both VAT and VAP. Patients who presented VAT or VAP had significant longer hospitalization and mechanical ventilation duration (days) compared to , 24 (14-33) vs. 6 (4-7), (p = 0.01)] and [18 (9-25) , 19 (10-26), 5 (3-6) , (p = 0.01), respectively]. ICU mortality was 36, 9, 8%, for patients with VAP, VAT and NP, respectively (p = 0.1). CONCLUSIONS. Incidence and microbiological pattern was similar in VAP and VAP in these case series. Both VAT and VAP were associated with longer hospitalizations and mechanical ventilation duration. Further analysis with a larger cohort of patients is required to give conclusive remarks. REFERENCE (S) . 1. Nseir S et al (2002) Nosocomial tracheobronchitis in mechanically ventilated patients: incidence, aetiology and outcome. Eur Respir J 20:1483-1489. G. C. Choutas 1 , V. G. Nolas 1 , A. Kalantzi 1 , A. Moutzouri 1 , G. K. Anthopoulos 1 1 Intensive Care Unit, \ \251[ [ General Air Force Hospital, Athens, Greece INTRODUCTION. Endotracheal suctioning is an essential part of care for patients receiving mechanical ventilation, to keep the airways free from bronchial secretions, assuring ventilation and oxygenation. There are two types of suction systems. In the open system, endotracheal suctioning requires disconnecting the patient from the ventilator and introducing a single-use sterile suctioning catheter into the endotracheal tube. Closed systems are changed every 24 and 72 h. To determine whether ventilated patients treated with CSS in an intensive care unit (ICU) differ as to airway bacterial colonization and colonization of the suction system based on cultivation of both bronchial secretion and suction catheter tip and if cultivation of suction catheter tip is adequate in place of bronchial aspirate cultivation. METHODS. 164 patient, incubated and ventilated in the ICU ward were studied in a period of one year (2007 to 2008) , on admission to the ICU a CSS (Trach Care MAC) was connected. Closed multi-use catheters were changed daily. Two-pass endotracheal suctioning was performed as needed. BA cultures were obtained on admission and the next day. Radiographs taken before, during, and after BA and CSS cultures were graded for pneumonia and a modified score for VAP. Of the 164 patients CSS samples 104 (63.4%) and BA samples 99 (60.4%) were sterile. Airway colonization with Gram-negative bacteria and fungi occurred in the majority of the patient 24.1% and Gram-positive bacteria in 20%. Cultivation of CSS revealed Gramnegative bacteria and fungi occurrence 31.5% and Gram-positive bacteria in 11.5%. With the current sample no significant difference was found between the positive results of Trach Care tip cultivation and BA cultivation p = 0.568. OBJECTIVES. To reduce the use of sedatives and to decrease the amount of time spend on a ventilator by specific Ramsay-instructions and checks for sedation-protocol-adherence. METHODS. In April 2008, after introductional lessons to doctors and nurses, we started and collected data for 8 months. A yellow reminder was attached to the medical-instructions-form and doctors were requested to fill in the Ramsay-score on a daily basis. Once in a week patients and records were screened to assess protocol-adherence. Each nurse and each intensive care-unit received feedback on their compliance to the bundle-elements. The total amount of sedatives per month was divided by the number of ventilator days, resulting in an average dose midazolam/propofol per ventilator day. The median and interquartile range of ventilator days/patient was also calculated and all data were compared with the same period in 2007. We accomplished a reduction in the use of sedatives and costs. INTRODUCTION. Ventilator associated pneumonia (VAP) often occurs in patients who are mechanically ventilated. The incidence rate varies between 23 and 34% for patients in the intensive care unit. It has been the second most common hospital-associated infection after that of the urinary tract. The diagnosis of VAP is difficult because of different existing definitions. HYPOTHESIS. Our hypothesis was, that lowering VAP incidence rate, could be done by a bundle of five interventions. The purpose of introducing multiple ventilatory interventions as a bundle, was to lower VAP incidence rate by 10%. METHODS. During the last 6 months of 2007 all patients who were ventilated [48 h, were investigated for VAP. The diagnosis of VAP was done according to the criteria supposed by the Dutch Working Group on Infection Prevention. A new infiltrate on chest X-ray after 48 h ventilatory support in combination with fever, leucocytosis, increased need for oxygen and culture of blind bronchial secretion C10 5 CFU/mL. A ventilator bundle was introduced on all ICU wards as inspired by the Institute of Healthcare Improvement. Five interventions were introduced: head of bed [30°, reduction of sedatives as low as possible according to prescribed Ramsay score, assessment of readiness to extubate, cuff-pressure measurement 3 times a day with application of cuff pressures between 25 and 30 cm H 2 O, and oral care with chlorhexidine 0.12% 2 times a day. ICU nurses were trained in the first 6 months of 2008. The last 6 months of 2008 were used to evaluate the bundle intervention in comparison with the last 6 months of 2007. RESULTS. 63 patients were included in 2007 and 72 in 2008. After introduction of the ventilator bundle, the incidence per 1,000 ventilator days decreased from 23.3% to 9.6% per 1,000 ventilator days. INTRODUCTION. Continuous positive airway pressure (CPAP) may improve oxygenation in patients with mild to moderate acute hypoxemic respiratory failure (AHRF) and avert further deterioration and need for intubation. OBJECTIVES. Aim of our study was to assess the physiologic effects produced by the addition of periodic hyperinflations (sigh) to CPAP in patients with AHRF. We studied 10 patients with non-cardiogenic AHRF. Four trials of one hour each were performed at a constant FiO 2 60% during (1) spontaneous breathing (SB) via a Venturi mask, (2) CPAP 1 , (3) CPAP ? 1 sigh/min of 25 cm H 2 O for 8 s (CPAP sigh ), (4) CPAP 2 . CPAP, via helmet, was maintained at 10 cm H 2 O troughout the whole study period. PaO 2 /FiO 2 ratio (P/F), PaCO 2 , pH, respiratory rate (RR), arterial blood pressure (ABP), heart rate (HR), dyspnea and patient comfort (by means of 2 separate visual analog scales) were measured at the end of each trial. RESULTS. Overall, P/F was significantly (p \ 0.05) improved by CPAP (CPAP 1 192 ± 53 mmHg, CPAP sigh 227 ± 56 mmHg, CPAP 2 214 ± 75 mmHg), as opposed to SB (113 ± 9 mmHg). Overall, the sigh did not significantly improved P/F. In the six patients with bilateral infiltrates, however, the rate of improvement in P/F significantly (p \ 0.05) augmented with the introduction of a sigh as compared with those with monolateral infiltration (150 vs. 107% respectively, being 100% the increase from Venturi to CPAP 1 ). PaCO 2 , pH, RR, HR, ABP, dyspnea and comfort were not significantly different between trials. CONCLUSIONS. In patients with AHRF, CPAP improves oxygenation without affecting hemodynamics. The addition of a sigh to CPAP further improved oxygenation only in patients with bilateral pulmonary infiltrates. BACKGROUND. Adaptive support ventilation (ASV) is a novel electronic ventilator protocol that incorporates the recent and sophisticated measurement tools and algorithms. The target tidal volume and respiratory rate are continually adapted to patient's respiratory physics and varying medical conditions. In injured lung, the ASV should actively adjust ventilatory parameters achieving minimal work of breathing to meet the lung protective strategies. But there were little literatures describing its efficacy when applied to Korean population. METHODS. From May 2008 to January 2009, we observed initial mechanical ventilation parameters in 114 patients receiving ASV due to various causes (48 lung injuries including 27 community acquired pneumonia, 9 hospital acquired pneumonia, 5 interstitial lung diseases, 4 pulmonary tuberculosis and 3 idiopathic cases; 66 without lung injury which comprise 33 trauma cases, 18 strokes, 9 suicidal attempts and 6 other cases). The mean age of studied population was 57.5 years (male:female = 42:15). The data were collected within the first 12 h of mechanical ventilation. CONCLUSION. As expected, adaptive support ventilation delivered smaller tidal volume and higher respiratory rates for injured lungs. ASV efficiently operated in Korean ALI patients without any serious drawbacks and favorably adjusted the tidal volume and respiratory rates combination in relation with RCexp to meet lung protective strategies. INTRODUCTION. Neurally adjusted ventilatory assist (NAVA) is a mode of mechanical ventilation that uses the electrical activity of the diaphragm to control the ventilator obtaining an improved patient-ventilator synchrony and an efficient unloading of the respiratory muscles. NAVA is characterised by a variability of the breathing pattern and the absence of a constant flow, which makes impossible the determination of reliable data of respiratory mechanics by using the rapid occlusion method. We have previously demonstrated that the least squares fitting method (LSF) could be used during pressure support ventilation (PSV), provided that the level of PS is sufficiently high to unload the inspiratory muscle. Hence we made the hypothesis that (1) reliable data of respiratory mechanics can be obtained by applying the LSF method during NAVA and (2) the LSF method should work better during NAVA because of the characteristics of the flow and pressure traces. METHODS. Ten patients undergoing mechanical ventilation for acute respiratory failure were enrolled. They were ventilated using randomly either PSV or NAVA with the the same PEEPe and tidal volume (V T ). Data of resistance (R rs ), elastance (E rs ) and total positive end expiratory pressure (PEEP tot ) were obtained by fitting the equation Paw = R rs 9 V 0 ? V T / C rs ? PEEP tot during inspiration, because of the possible presence of expiratory flow limitation. The coefficient of determination (CD) of the applied equation was used to compare data obtained during NAVA and PSV, the higher being the CD, the better the quality of the data. Moreover patients were sedated and ventilated in volume controlled ventilation (ACV) with the aim of calculating data based on rapid occlusion method and compare them with those obtained with LSF method by using the Bland-Altman analysis. (1) Data obtained with LSF were statistically more reliable during NAVA (mean CD: 0.98 ± 0.01) than during PSV (mean CD: 0.90 ± 0.1; p \ 0.001). (2) The CD obtained at every level of NAVA was always higher then 0.96. On the contrary, the CD obtained at low level of PSV was less than 0.90 due to the presence of inspiratory muscle activity. (3) The Bland-Altman analysis demonstrated lower bias and higher precision between traditional data and those calculated during NAVA (bias: 2.8; limit of agreements: -2.4/ 8.9) compared to PSV (bias: 5.2; limit of agreements: -17/6.5). CONCLUSION. The application of the LSF method during NAVA allows calculation of reliable data of Rrs, Ers and PEEPtot, which are independent of the level of NAVA applied. This is of clinical relevance since PSV allows calculation of reliable data only at high level of pressure support. It appears that the influence of inspiratory muscle activity on respiratory mechanics is less relevant during NAVA ventilation, suggesting a more physiological ventilation during NAVA both in terms of timing and of delivering adequate level of assist throughout each breath. INTRODUCTION. NAVA is a new spontaneous-assisted ventilatory mode based on the detection of diaphragmatic electrical activity (Eadi) and its feedback to adjust ventilator settings. NAVA uses the Eadi, an expression of the respiratory center's activity, to initiate pressurization, set the level of pressure support and cycle the ventilator into exhalation. Therefore, NAVA should theoretically allow near-perfect synchronization between the patient and the ventilator. However there are few data documenting these effects in intensive care patients. To determine whether NAVA can improve patient-ventilator synchrony compared to standard pressure support (PS) in intubated intensive care patients. Comparative study of patient-ventilator interaction during PS with clinician determined ventilator settings and NAVA with NAVA gain (proportionality factor between Eadi and the amount of delivered inspiratory pressure) set as to obtain the same peak airway pressure as the total pressure obtained in PS. A 20 min continuous recording with each ventilatory mode was performed allowing determination of trigger delay (T d ), patient neural inspiratory time (T in ), duration of pressurization by the ventilator (T iv ), excess duration of pressurization (T i excess = T iv -T in /T in 9 100) and number of asynchrony events by minute: non-triggering breaths, auto-triggering, double triggering, premature and delayed cycling. Results are given in mean ± SD. p is considered significant if \0.05. 12.9 ± 19.6 2.2 ± 0.6 70.8 ± 37.8 n asynchrony/minute 7.6 ± 6.4 4.1 ± 3.7* 47.5 ± 17.0 Respiratory rate (min -1 ) 16.8 ± 2.6 20.4 ± 4.7 NA * p \ 0.05 CONCLUSION. Compared to standard PS, NAVA improves patient ventilator interaction by reducing Td and the overall incidence of asynchrony events. There is also a strong trend in reducing delayed cycling. This ongoing trial should provide evidence that NAVA can indeed improve patient-ventilator synchrony in intubated patients undergoing PS. INTRODUCTION. High FiO 2 and hyperoxia may induce pulmonary injury and may increase oxidative stress. Guidelines suggest a target arterial oxygen tension of 8 kPa [1] . A Canadian questionnaire study found considerable variation in the attitudes, beliefs and practices of intensivists in the management of oxygen therapy [2] . However, the actual response of intensivists to hyperoxia in patients has never been studied. In this retrospective database study we investigated adherence to guidelines concerning oxygen therapy in a Dutch academic intensive care. All arterial blood gas (ABG) data from mechanically ventilated patients from 2005 to 2009 were drawn from an electronic storage database (Metavision) of a mixed 32-bed ICU in a university hospital in Amsterdam. Mechanical ventilation settings at the time of the ABG as well as the successive ABG were retrieved. The statistical analysis was carried out with SPSS 16.01. RESULTS. 126.778 ABG's from 6251 mechanically ventilated patients were retrieved including corresponding ventilator settings. In 28.222 (22%) of the ABG's PO 2 was[16 kPa. Initial ventilator settings and adjustments based on ABG's of this group are shown in Table 1 [data represent median (10th/90th percentile)]. In 88% of the lowest FiO 2 group, FiO 2 was exactly 40%. In only 25% of cases with PO 2 [ 16 kPa the FiO 2 was decreased. Hyperoxia was accepted with no adjustments in ventilator settings if FiO 2 was 40% or lower. INTRODUCTION. Major patient ventilator asynchronies are frequent during non-invasive ventilation (NIV) especially due to leaks.NIV can be delivered using ICU ventilators or specifically designed NIV ventilators. Although ICU ventilators are traditionally used for invasive mechanical ventilation, specific NIV modes have been recently implemented. The impact of these NIV modes as well as NIV ventilators on patient ventilator asynchrony is unknown. Our objective was to compare the incidence of patient ventilator asynchrony between invasive or NIV mode of ICU ventilators and NIV ventilators. PATIENTS AND METHODS. ICU patients with acute respiratory failure requiring NIV were studied during three randomized consecutive 20 min-periods of NIV: ICU ventilator with and without NIV mode and NIV ventilator. We used two ICU ventilators: Evita XL (Dräger) and Engström (General Electrics) and 1 NIV ventilator: BiPAP Vision (Respironics). Flow and airway pressure were continuously recorded to determine breathing pattern. To detect major patient ventilator asynchrony we used surface diaphragmatic and/or sternocleidomastoid electromyogram allowing to assess neural patient's inspiratory time and to define asynchronies: ineffective triggering, auto-triggering, double-triggering, prolonged and short cycles. Asynchrony was quantified using an asynchrony index as previously described. RESULTS. These preliminary results concern ten patients (9 males and 1 female) with a mean age of 71 ± 8 and a SAPS 2 of 52 ± 21. Reason for NIV was acute exacerbation of COPD (n = 4), acute pulmonary edema (n = 2) and post-extubation (n = 4). At time of study, pH was 7.37 ± 0.08, PaCO 2 50 ± 16 mmHg and PaO 2 80 ± 28 mmHg. Ventilatory settings were set by the clinician and kept constant during the three periods with a PS level of 9 ± 2 cm H 2 O and a pressurization ramp of 110 ± 32 ms, a PEEP level of 5 ± 1 cm H 2 O and a FiO 2 of 36 ± 14%. Using ICU ventilators, inspiratory trigger was 1 l/min and cycling off was 40% when adjustable. Median asynchrony index was 5.9% (3.0-12.1) using ICU ventilators versus 4.2% (1.8-6.6) using NIV mode and 0.6% (0.4-1.0) using BiPAP Vision (p = 0.20 between invasive and NIV mode, p \ 0.01 between NIV mode and BiPAP Vision). Asynchrony index was greater than 10% in three patients using invasive mode, two patients using NIV mode and no patient using BiPAP Vision. Auto-triggering was the main asynchrony. CONCLUSION. NIV ventilator (BiPAP Vision) allowed a marked reduction in patient ventilator asynchrony during NIV as compared to NIV mode currently available on new generation of ICU ventilators. GRANT ACKNOWLEDGEMENT. This study was supported by a research grant from Respironics. A. Armaganidis 1 , K. Stavrakaki-Kallergi 1 , C. Sotiropoulou 1 , A. Koutsoukou 1 , J. Milic-Emili 1 , C. Roussos 1 1 Athens University, Athens, Greece Prevalence of expiratory flow limitation (EFL) was estimated using the negative expiratory pressure method (NEP) in 96 anesthetized, paralyzed mechanically ventilated patients in ICU. Patients were studied in supine position at zero positive end-expiratory pressure (PEEP). A NEP device especially designed and in build in an Evita 2-Draeger respirator, allowed the application of a pressure equal to-5 cm H 2 O, starting at 8 ms after the onset of expiratory flow and sustained throughout the end of the expiratory time set on the ventilator. Patients were categorized in two groups: 1. NON EFL (47 patients without flow limitation), in whom NEP elicited an increase of expiratory flow over the entire expiratory flow-volume (V 0 -V) curve. 2. EFL (49 patients with EFL), in whom part or the expiratory V 0 -V curve during NEP was superimposed on the baseline V 0 -V curve. Half of our patients (51%) were flow-limited. No patient without pulmonary disease was found flow-limited, except of a percentage of morbidly obese patients (57%). EFL was recorded in 65% of ICU patients with pulmonary diseases: 65 % of ARDS patients, 75% of patients with respiratory infection, 75% of asthmatics and 85% of patients with COPD. Time constant (s) and inspiratory flow (V 0 insp) were found to predict the severity of flowlimitation expressed as EFL % V T . OBJECTIVE. Tidal volume (V t ) administered to ARDS patients can be adjusted depending on body weight. Body weight may be estimated, measured or calculated for an ideal or a predicted value based on different formulas [1, 2] . Besides, those formulas require the measurement of height and may differ depending on gender. We hypothesized that V t value (ml/kg of body weight) may be different and show intrameasure variability depending on the method used. METHODS. ARDS patients were included prospectively in the first 72 h after ICU admission. The ventilatory parameters were selected by the attending physicians that were foreign to the study. All patients were ventilated by volume controlled-assisted mode. Five independent observers estimated the weight (EstW) of each patient. They also measured height with a metric tape for calculate the predicted body weight (PBW) [1] and the ideal body weight (IBW) [2] . After previous measurements, patients were weighed once with a calibrated scale (ScaW). Results were compared using analysis of variance. RESULTS. 18 patients were studied, 45% women (age 52.5 ± 15.9, SAPS II 49.6 ± 17.6; Apache II 23.4 ± 9.1). Ventilation parameters at inclusion: V t /ScaW (ml/Kg) Mean ± SD 5.6 ± 0.86 6.7 ± 1.05 5.9 ± 0.87 5.8 ± 0.93 0.001** Mean ± SD mean ± standard deviation, min minimum, Max, maximum, PBW 50 (men) or 45.5 (female) ? 0.91 9 (height in centimetres -152.4), IBW 25 9 (height in meters) 2 , Mean diff average of the intraindividual differences of calculated/estimated weight, range intraindividual difference in weight (estimated/calculated) expressed as minimum and maximum * EstW versus PBW p \ 0.001, PBW versus IBW p \ 0.001, PBW versus ScaW p = 0.005 ** V t /EstW versus V t /PBW p \ 0.001, V t /PBW versus V t /IBW p \ 0.001, V t /PBW versus V t /ScaW p \ 0.002 CONCLUSIONS. Our data show that there is no gold standard method for estimate or calculate body weight to adjust tidal volume in ARDS patients. Recommendations based on PWB and IBW not guarantee that tidal volume administered is really those that we want to administrate. REFERENCE (S) . 1. ARDSnet. NEJM 2000; 342:1301 -8. 2. Stewart TE et al (1998 3 Hôpital Raymond Poincaré AP-HP, Service de Réanimation Médicale, Garches, France, 4 Hôpital Saint-Louis, Paris Diderot University, Paris, France, 5 Centre Hospitalier d'Etampes, Etampes, France, 6 Université Versailles Saint Quentin en Yvelines, Versailles, France RATIONALE-OBJECTIVES. Dyspnea is a major respiratory symptom, which can reveal a severe disease. Additionally, it can also result from an inappropriate ventilator setting in mechanically ventilated patients. If these patients are nowadays more and more conscious, prevalence of dyspnea and its clinical, biological and radiological correlates has never been assessed in this population. Prospective cohort study conducted in two medical intensive care units (ICU) during 6 months. All patients intubated more than 48 h and conscious have been included. The first day when the patient regained consciousness, dyspnea, anxiety and pain were assessed using a visual analogic scale (VAS). If dyspnea was found, patient was asked if he experienced ''air hunger'', and/or ''excessive respiratory effort'' and if dyspnea VAS was improved after ventilator setting has been changed. Demographic, clinical, biological and chest X-ray data and ventilator settings have been collected. RESULTS. 96 patients were included (age: 61 ± 18 years; simplified acute physiology score II (SAPS II): 43 (IQR 31-60). Reasons for mechanical ventilation included acute respiratory failure (n = 46, 48%), neuromuscular diseases (n = 29, 30%), coma (n = 10, 10%), and exacerbation of chronic obstructive pulmonary disease (n = 7, 7%). Dyspnea was present in 45 (47%) patients and was qualified as ''air hunger'' in 31 patients (32%), ''excessive effort'' in 23 (24%) and both in 4 (5%). Age, SAPS II, reason for mechanical ventilation, respiratory rate, clinical examination, X-ray chest, PaO 2 /FiO 2 ratio, PaCO 2 were not statistically different between patients with and without dyspnea. Anxiety .0); p \ 0.0001), assist controlled ventilation [4.77 (1.60-14.3) ] and diastolic blood pressure ; p = 0.038) were independently associated with dyspnea in multivariate analysis. ''Air hunger'' tended to be associated with controlled ventilation (p = 0.051) whereas ''inspiratory excessive effort'' was significantly associated with low inspiratory flow, severe hypoxemia (median PaO 2 /FiO 2 ratio: 166, p = 0.044) and marked hypercapnia (median PaCO 2 : 48 mmHg, p = 0.019). In 35% of breathless patients, of ventilator resetting decreased dyspnea. Length of ICU stay was greater in patients with dyspnea (p = 0.017) whereas extubation within three days and ICU mortality did not differ between the two groups. CONCLUSIONS. Dyspnea is frequent in mechanically ventilated patients and is strongly associated with anxiety, more frequently when controlled ventilation is used and is often reduced after ventilator resetting. Assessment of dyspnea in conscious mechanically ventilated patients should be routinely performed in order to improve patients' comfort. METHODS. An experimental study design was used with a group of 66 first year health care provider students. The students were divided into two groups related to familiarity of the location of exam. A part of students (n = 35) were examined in demonstration room (DR) and the other part of students (n = 31) in public place (PP) . Every student received the same number of training hours (28 h) and the same training method in demonstration room. During this exam the students performed a 2 min long, single person CPR related to ERC 2005 guideline. Their performance was measured with calibrated AMBU CPR software and the adapted point system of Brendan B. Spooner's scale. v 2 and T test were used for comparison. p values less than 0.05 were considered statistically significant. We did not find difference between DR and PP groups in the correct sequence of BLS steps, hand position, adequate frequency and depth of chest compression. Between groups of characteristics of ventilation were not significant differences observed. It is first critical point in BLS process to assess the quality of patients' spontaneous breathing; therefore it is crucial that the duration of check breathing may be sufficient long. The duration of checking for breathing was significantly (p = 0.001) shorter in DR groups than PR groups. In the PP groups time interval between 30 chest-compression cycles were significantly (p = 0.016) longer-more than 2 s-than in DR group. CONCLUSIONS. The altered location of BLS final exam shortens duration of checking for breathing which determines BLS providers' decision making on starting chest compressions. The students may be full of confident in the well-known place represented by the shorter time of checking for breathing. The changed place of exam extended time interval between chestcompression cycles, therefore weaken the continuity of chest compressions, and decrease the chance of return of spontaneous circulation. AIMS. This paper reports an evaluation of the student experience of using a clinical competence assessment tool (CCAT) in postgraduate critical care nursing education. The focus is on the perceptions of students in relation to the validity, reliability and usability of the assessment tool. The domains of competence assessed are based on five domains outlined by An Bord Altranais (2000) . They are: professional/ethical practice, interpersonal relationships, practical and technical skills, utilising a holistic approach to care, clinical decision making and critical thinking skills and organisation and management of care. The assessment process encompasses three clinical assessments and clinical competence is measured using the developmental process of novice, advanced beginner, and competent as described by Benner (1984) . Students are asked to reflect on their own learning needs prior to each assessment. The assessment includes a discussion on the knowledge that underpins practice thereby showing the integration of theoretical and practical knowledge. Questionnaire was administered to all students who recently completed a Graduate Diploma in Nursing Studies (Critical Care) at a specific third level institution. RESULTS. The evaluation of the CCAT as a mode of competence assessment in postgraduate critical care nursing education was generally positive from the students' perspective. Some students considered the holistic nature of the CCAT document to be a limitation, suggesting that their level of competency could have been better addressed with a tool that was more oriented toward critical care rather than being so 'broad' in nature. Overall respondents considered that the CCAT helped them to identify learning needs and found the use of the tool to be a positive experience and easy to use although some respondents considered that the wording of some of the sub-domains and indicators was difficult to interpret. Competence assessment is about ensuring the delivery of safe and competent patient care. In order to determine competence a valid and reliable tool is needed. This small scale study presents the views of post registration critical care nursing students on using a competence assessment tool. The findings of this study cannot be generalised, however they do provide insight for educators and students using competence assessment tools in programmes preparing registered nurses for specialist nursing practice. The use of a holistic assessment process needs further explanation. Students need to be encouraged to move away from the reductionist approach, which is focussed on tasks and move towards a broader understanding of competent practice. REFERENCE (S) . 1. An Bord Altranais (2000) Requirements and standards for nurses registration education programmes, 2nd edn. 2. Benner P (1984) From novice to expert excellence and power in clinical nursing practice. Addison-Wesley, California.  To assess the usefulness of a web-based interactive learning package designed to supplement an undergraduate acute care course (very BASIC) taught to final year medical students. A web-based interactive learning package was developed to supplement a highly rated traditionally taught 8-day acute/critical care course consisting of pre-course reading, lectures, skill stations and interactive tutorials [1] . The additional web-based package consisted of narrated lectures, interactive lessons, videos and animations to demonstrate practical procedures and clinical signs, self assessment quizzes and a question and answer forum. Topics covered included arterial blood gas sampling and interpretation, acute metabolic disturbances, non-traumatic coma, acute respiratory failure and sepsis. Both the package and the course are available to other medical schools free of charge. Usefulness of the package was assessed by examining activity logs, a student questionnaire, formal focus group (conducted by an investigator not involved in course preparation or teaching), comparing the results of a post-course MCQ based summative assessment with historical controls and comparing results of formative assessment included in the package with the summative assessment. RESULTS. Over 50,000 student-activities were logged by 135 students during the two week course. 107 students completed the questionnaire. With regard to usability, [60% agreed or strongly agreed that interactive lessons and self assessment ran smoothly without faults, with a corresponding score of [80% for narrated lectures and ease of browsing. With regard to usefulness, C80% agreed or strongly agreed that the question and answer forum was useful in clarifying areas of doubt and narrated lectures improved understanding of the course material; [90% agreed or strongly agreed that the content as a whole was useful in preparing the respondent to work as a doctor, interactive lessons improved their understanding of how to apply their knowledge, and their understanding of arterial blood gas interpretation and self assessment exercises improved their understanding of the course material. Participants in the focus group indicated that the resources provided in the website were useful for learning, specifically the animations, narrated lectures and the question and answer forum. Suggestions for improvement included improving the quality of the video and animations, increasing the range of topics covered and ensuring consistency with the printed course manual. There was no correlation between formative and summative assessments but, compared to 36 historical controls, performance in the summative assessment improved (75 vs. 67%, p \ 0.001). CONCLUSIONS. The package provided a useful supplement to a traditionally delivered acute care course. INTRODUCTION. Faculty development refers to that broad range of activities that institutions use to renew or assist faculty in their roles. It includes activities that improve an individual's knowledge, skills and attitudes in important areas in teaching, education, research, leadership, administration and career development. In this abstract we will introduce one of the most important methods of faculty development programs. A meeting by the authors ''organizing group'' was conducted to decide on a topic for our workshop and discussed the planning and designing process. We decided on conducting a workshop on clinical teaching methods. A scientific and organizing committee was established, and accordingly work loads and assignments were distributed among them. We gave this workshop a title of ''I am the Best Clinical Educator…are you!? Our target audience was acute care management providers, with a capacity of up to 45 participants. We gave a specific time and location of this event. Venue was arranged. Computers for group work, audiovisual and other logistics were provided. After summarizing the main points for the workshop the organizing committee distributed an invitation letters throughout the higher management and educational leaderships. An address remark was done through invitation from the organizing committee. Hot and cold beverages and break lunch meals were provided. Posters on the workshop were distributed through out the institution. Folders with educational materials were provided for each candidate. Pre-course registration was done. Once the program for the workshop was finalized a reminder was sent out to the participants on the date and venue for the workshop. Participants attended on time, folders, badges with USBs were handed out. A questionnaire was distributed to the audience to estimate their learning experiences and approaches towards teaching styles and methods which were used in their practice. Certificates of attendance with CME credit hours were distributed. RESULTS. 45 candidates attended this faculty development workshop. 70% were nurses and 30% were physicians, during this workshop, three topics were distributed over three groups, one group on how to break bad news. Second group about how to conduct microteaching and the third group about how to give feedback. Each group was evaluated by three members of the organizing committee, each group was ranked accordingly. All were performed by role play. At the end of the workshop an evaluation form was filled 100% responders. A five performance scale was used. The strength of the workshop was innovativity and ranked as strongly agree. The only weakness was the place constraint. CONCLUSION. We concluded that a well organized workshop using role play, interactive sessions are effective modality for faculty professional development programs among acute care providers with high satisfaction rate. Only 35 of the respondents (17%) indicated they did understand the statistics they encountered in journal articles and 90% felt it was important to understand these concepts and that they would like to access more easily to biostatistics training.  A patient is referred to a higher centre when services are needed to maintain continuity of care.There are guidelines for the safe inter and intrahospital transport of critically ill patients but no guidelines are available for the minimal mandatory content of interhospital referral notes of critically ill patients.This problem is manifold in developing countries. OBJECTIVE. To educate the critical care physicians regarding the deficits in the physicians referral notes with which critically ill patients are referred from one centre to another. It is a prospective observational study on 96 out of hospital referred patients transferred to our intensive care unit (ICU) over a period of 1 year. After permission from the institutes ethical committee we reviewed the referral summaries of these patients at the time of ICU admission regarding the information available of clinical details, course in the previous hospital and therapeutic interventions. Patients with more than 24 h of hospitalization before transfer were included in the study. INTRODUCTION. In Japan, closed ICUs have been gradually increasing at university hospitals. A closed ICU is necessary for a university hospital not only for the hospital activity but also the education of medical students and the training of fellows. They can learn how to manage the circulation and respiration status of severely ill patients in ICU. It is indispensable for effective education to ensure sufficient proper ICU staffs. But the present condition of our country is that there are not so many intensivists enough to perform both of clinical duties and education of students and fellows. Each ICU of university hospitals is endeavoring to increase the number of intensivists. One of the popular methods is the announcement on web site to promote interest of young fellows. Regrettably, the homepage of the Japanese Society of Intensive Care Medicine has no such specific pages. Each ICU of university hospitals has to create attractive its own pages in the homepages of the hospitals. [1] . Most subjects are taught using lectures and group tutorials and the theory is applied in clinical areas to facilitate greater understanding of the newly acquired knowledge. There is no reported best practice mechanism for teaching medical ethics in a practical setting to medical students. OBJECTIVES. The routine use of an ethical checklist has been proposed as a tool for the medical team to consider ethical issues on critical care [2] . Its use as a tool for teaching medical ethics within critical care has not previously been reported. The aim was to use this checklist to facilitate learning providing clinical case material for discussion in daily tutorials. One medical student (SM) undertook a one week period of study to learn about ethics in critical care practice. The checklist was used to review patient notes, guide further discussion with patients, when observing the professional behaviours and communication of the multidisciplinary team, and as a guide for case based discussions. RESULTS. The complexity and severity of patient conditions in critical care makes it the ideal setting for learning about ethics. SM considered more ethical dilemmas in this practical attachment than in the previous 2 years of clinical placements. The checklist allowed identification of possible ethical issues relating to each patient and a deeper understanding of the patient's health care needs. It was used for daily tutorials to discuss the ethical principles and observed professional behaviours in a similar way to a discussion of clinical diagnosis and management of a patient case with a supervising doctor on a normal clinical attachment. Complex issues such as capacity to consent, end of life treatments or resource allocation were seen in relation to ongoing care. On ward rounds it was observed that their conduct in an open environment could at times potentially compromise patient confidentiality. There was also a benefit from the consideration of ethics issues in a real time basis which allowed exploration and reflection on personal moral or spiritual beliefs and how they may differ from those of the patients and other medical professionals. CONCLUSIONS. Using an ethical checklist allowed application of theoretical lecture and workshop material to real life situations. By discussing the cases and observed behaviours with a senior critical care doctor it is possible for trainee staff to appreciate how difficult medical management decisions are made, and to improve the acquisition of the skills necessary to start to assess and discuss ethical issues surrounding a patient's care confidently. INTRODUCTION. Accurate data on patient's weight and height are important for management in intensive care units (ICUs). Unfortunately, weight beds or bed scales are not available in a significant number of ICUs and these variables are often estimated by health care personnel. The accuracy of such estimations is poorly described. OBJECTIVE. To investigate the accuracy of visual estimation of weight and height in critically ill patients. METHODS. Prospective study conducted in a 10-bed mixed medical and surgical ICU. Patients were consecutively weighed by an unblinded physician with a stretcher scale (T3 metric), and measured by a physical therapist using a measuring tape. The ideal weight was calculated using the ARDSnet's formulas for predicted body weight. Medical staff (MS), internal medicine resident (IMR), nursing staff (NS), physiotherapist (PT) and nutritionist (NU) were asked to estimate patient actual weight, ideal weight and height. They were blind to the estimations during all the protocol. Estimations in each healthcare group were computed as means, medians and percentage of error from actual and ideal weight and height, respectively. ANOVA test was used to compare mean estimations between the groups. There were no significant differences between the groups in estimation of either weight (p = 0.73) or height (p = 0.68). CONCLUSION. Weight estimations from healthcare personnel are often inaccurate. There are no significant differences in accuracy between the estimations of weight and height in different healthcare groups. An effort should be made to weigh all critically ill patients. Intraabdominal hypertension (IAH) is often diagnosed in ICU and it can lead to abdominal compartment syndrome, multiple organ failure and death [1] . In clinical setting biochemical signals based on which IAH is considered severe or detrimental on visceral tissues are scarce. Currently, the only clinically relevant signal is decreasing hourly diuresis. In an attempt to find an early sign of metabolically relevant signal on clinically marked IAH we investigated abdominal wall metabolite concentrations. Previously high lactate/pyruvate has been detected in dialysate from rectus abdominis muscle (RAM) in animal models of IAH [3] . In the present experiment we hypothesized that laparoscopic surgery which induces IAH could lead to clinically significant increase of L/P ratio as a signal of anaerobic metabolism caused by IAH and insufficient tissue perfusion. INTRODUCTION. Among the techniques proposed to assess microperfusion and oxygenation, NIRS sounds to be convenient [1] . If baseline measurements do not provide useful information for outcome of micro-vascular impairment, functional evaluation using vascular occlusion test (VOT) seems to be promising [1] . Technological development of the NIRS device (InSpectra Models 325 and 650, Hutchinson Technology, Hutchinson, Minn) proposes to use a new probe measuring hemoglobin saturation at less depth than previously (15 vs. 25 mm between fiberoptic) with more data output (1 value/2 s vs. 1 value/3.5 s) associated with an automated software to compute occlusion and reperfusion slopes. OBJECTIVE. To compare NIRS results obtained, using the two different probes, at day 0 of septic shock (SS) in two groups of patients having similar clinical characteristics. METHODS. 43 patients (G1) and 30 patients (G2) were included within the first 24 h of SS. Macrohemodynamic: heart rate (HR), mean arterial pressure (MAP), central venous pressure (CVP), cardiac output (CO) and SvO 2 (mixed venous O 2 saturation), pH, Base Excess, and lactate were collected as SAPS II and SOFA scores. Baseline StO 2 at thenar eminence was continuously monitored and a 3 min upper arm(brachial artery) VOT was performed. StO 2 occlusion and reperfusion slopes were calculated manually in G1 (probe 25 mm) using linear adjustment (R 2 C 0.90 to be valid) or calculated by the software in G2 (probe 15 mm) using the same method, p \ 0.05 was considered significant. RESULTS. Median ± IQR. The two groups did not differ for macrohemodynamic nor for metabolic data (Table 1) . NIRS data surprisingly were largely significantly different between the two groups for both baseline and slopes ( BACKGROUND. Hypovolemia and hypovolemic shock are life-threatening conditions that occur in numerous clinical scenarios. Near-infrared spectroscopy (NIRS) has been widely explored, successfully and unsuccessfully, in attempt to function as an early detector of hypovolemia by measuring tissue oxygen saturation (StO 2 ). In order to investigate the measurement site-and probe-dependence of NIRS in response to hemodynamic changes, such as hypovolemia, we applied a simple cardiovascular challenge; a posture change from supine to upright, causing a decrease in stroke volume (as in hypovolemia) and a heart rate increase in combination with peripheral vasoconstriction to maintain adequate blood pressure. METHODS. Multi-depth NIRS was used in nine healthy volunteers to assess changes in peripheral vascular tone in the thenar and forearm in response to the hemodynamic changes associated with a posture change from supine to upright. A posture change from supine to upright resulted in a significant increase (***) in heart rate. Thenar StO 2 did not respond to the hemodynamic changes following the posture change, whereas forearm StO 2 did. In the forearm, StO 2 was significantly lower (***) in the upright position with respect to the supine position. CONCLUSION. The primary findings in this study were that (1) forearm StO 2 is a more sensitive parameter to hemodynamic changes than thenar StO 2 and (2) Cerebral hyperperfusion syndrome, caused by inflow at normal blood pressure into maximally dilated fine vessels, is a recognized complication of carotid endarterectomy (CEA) Strict blood pressure control in the early postoperative period can minimize the risk of cerebral hyperperfusion. Until yet, diagnosis of cerebral hyperperfusion mainly relies on intermittent postoperative examinations (SPECT; CT angiography). Non-invasive absolute cerebral oxygen saturation (SctO 2 by Fore-Sight technology) was validated to jugular bulb saturation (SjO 2 ) monitoring with a constant difference of 10% higher for SctO 2 values. Previously, SjO 2 monitoring after severe head injury indicated cerebral hyperemia. In this study, we evaluated SctO 2 monitoring after carotid surgery as possible continuous on-line monitoring of cerebral hyperperfusion. Fourteen pts scheduled for CEA were monitored for 12 h postoperatively after CEA. Bilateral SctO 2 monitoring was started before induction of anesthesia and maintained until 12 h postoperatively. Intra-operative EEG monitoring guided the decision to intraluminal shunt insertion. Strict blood pressure control was applied at maintaining normotensive levels throughout the clamping procedure. Early postoperative care focussed on strict maintenance of normotensive blood pressure. In no pt, any change in EEG was observed after carotid clamping. In all pts, ipsilateral SctO 2 significantly decreased after carotid clamping, without any SctO 2 value below 55%. We observed no changes in contralateral SctO 2 . Mean clamping time was 28 min (19-37 min). In all pts, clamp release restored ipsilateral SctO 2 to baseline values. In all pts, emergence from anesthesia was uneventful, without any new neurological deficit. In 6 of 14 pts, significant increases (SctO 2 [ 85%) in ipsilateral SctO 2 were observed in the postoperative period (m SctO 2 87.5%), without any changes in contralateral SctO 2 . This increase occurred at a mean of 3.4 h after carotid declamping with a mean duration 5.3 h. In these 14 pts, we could not make any significant correlation to arterial blood pressure, as none of these 6 pts needed more aggressive antihypertensive control. We noted that 4 of these 6 pts suffered from diabetes mellitus, while 5 of 6 pts revealed high ([90%) contralateral stenosis. Further data will have to reveal the importance of these comorbide factors. Non-invasive cerebral oximetry, enabling absolute cerebral oxygen saturation monitoring, could provide on-line estimation of cerebral perfusion state after CEA. This could allow bedside detection (and eventual therapeutic interventions) of cerebral hyperperfusion after CEA. INTRODUCTION. Analysis of microcirculatory alterations obtained by side-stream dark field (SDF) is time consuming. Automated analysis with modern softwares could accelerate this process and help to quantify blood flow velocity. However, perfusion detection is based on the contrast between pixels and this may be influenced by image settings. OBJECTIVE. We aimed to compare data obtained with a new software to the traditional semi-quantitative analysis of SDF images. METHODS. We selected from our database six images of poor sublingual microcirculatory perfusion and six images of good microcirculatory perfusion registered by the SDF technique (MicroScan; MicroVision Medical, Amsterdam, The Netherlands). The proportion of perfused vessels [PPV = (number of vessels with continuous flow/number of all vessels) 9 100] \ 70% was used to define microcirculatory perfusion. Total vessel density (TVD) was determined automatically by the software AVA 3.0 (MicroVision Medical) and also by the semi-quantitative technique, considered as the gold-standard (number of capillary crossing three equidistant vertical and horizontal lines divided by the total length of these lines). AVA Software was also used as default definitions or set to optimize analyses according to manufacturer instructions. Vessels falsely detected (false positive = FP) or missed (false negative = FN) by the software, in comparison to the semi-quantitative evaluation, were also counted. RESULTS. TVD was significantly higher by the AVA software either on default or on optimized mode than by the semi-quantitative method, and these differences were present with good or poor perfusion images (Table 1) . Overall FP rate was 22%, and it was greater in poor perfusion images (40%). Optimization of the AVA set parameters attenuated FP rates both in poor and good perfusion images, at the expense of increasing FN rates (Table) . Due to intrinsic characteristics of the software, the mean total grid length was significantly lower in the AVA than in the semi-quantitative analysis (3.8 vs. 5.6 INTRODUCTION. Perfusion index (PI) is the proportion of constant absorbed light compared to pulsatile absorbed light emitted from a pulse oxymeter. It ranges from a value below 1 up to 20 depedant of peripheral perfusion. It is measured primarily to evaluate the signal quality for the pulse oxymeter and is displayed by some pulse oxymeters to be acknowledged by the clinician. The PI changes with vasodilation and vasoconstriction. However, intubation is a stimulus able to increase endogenous catecholamines and thus leading to vasoconstriction possibly declining the perfusion index. Therefore we found intubation with a double lume tube in a thoracic surgery setting as a suitable setting to evaluate changes in perfusion index as a reaction to intubation. After informed consent, we enrolled seven patients undergoing lung surgery requiring an double lume tube. They were monitored as it is standard of care in our institution with invasive blood pressure, ECG, and a pulse oxymeter displaying the PI. (Radical 7, Masimo, Irvine, CA) The patients received the medication to induce anesthesia calculated adequately to their body weight. Midazolam, Propofol and Fentanyl where used to anesthetize the patient, Cisatracurium was used for muscle relaxation to facilitate intubation. PI, pulse and arterial saturation were recorded every minute from prior to induction until after successful intubation. A baseline value was recorded prior to induction and compared to the value 3 minutes after induction. Then the PI measured next to intubation was compared to the PI after induction and analysed using Students t test. INTRODUCTION. Anticoagulation strategies for albumin dialysis suppose a difficult compromise between risk for bleeding and a high tendency to clot in the circuit. Even thought the sessions are short, a premature clotting is a serious event because the lost of blood (high priming volume) and a high cost of the systems. We intended to demonstrate that the classical approach based in heparin is not adequate in these patients and should be substituted for a different strategy (mixed low dose of heparin plus epoprostenol). METHODS. Data of a prospective registry of all cases treated in our centre (a third level, teaching hospital) with albumin dialysis (MARS system). Initially we used non-fractionated heparin at 5-7 U/(kg h) in patients without coagulation problems, epoprostenol [4-6 ng/ (kg min)] in cases with risk or thrombocytopenia and no anticoagulation when high risk for bleeding or contraindication for anticoagulation. After an intermediate analysis of our registry we detected a high number of filters clotted when heparin was used and changed our approach to use as first indication a mixed protocol with non-fractionated heparin [3 u/(kg h) ] plus epoprostenol [4 ng/(kg min) ]. Data are presented as percentages. Analysis was performed with Chi-square test. To detect variables related to coagulation a stepwise backward logistic regression analysis was performed. We registered 72 patients with a total of 216 sessions. Selecting only the first session for each patient to validate the first choice for anticoagulation, we used heparin in 26 cases and detected the loss of 11 filters (42.3%) because clotting. After the change to mixed anticoagulation we used this as first indication in 17 patients and in only 4 (23.5%) the sessions were prematurely ended because clotting (p ns). The rest of patients received isolated epoprostenol in 19 cases (with 4-21%-cases of premature clotting) and no anticoagulant in five cases (with 3-60%-premature clotting). Between the 26 cases with heparin as first choice, three episodes of mild and one episode of severe bleeding were detected while no patients in the mixed group presented bleeding complications (p ns). In a logistic regression analysis over all registered sessions using coagulation of filters as dependent variable and type of patient, anticoagulant, arterial pressure, INR, TPTa, platelets, haematocrit or bilirubin as independent variables, none of these was included in the regression model. Even though more studies are necessary to validate this conclusion, a mixed protocol based in low dose heparin plus epoprostenol could be adequate as first indication for non-complicated patients submitted to a MARS treatment with lower risk for bleeding than the classical approach of isolated non-fractionated heparin.  Optimizing oxygen delivery in critically ill patients is vital for the promotion of aerobic cellular metabolism. Current practice includes the measurement of variables such as partial pressure of arterial oxygenation (PaO 2 ), cardiac Index (CI) and percentage of oxygenated haemoglobin in arterial blood (SaO 2 ). These parameters reflect global oxygen delivery. The real point of interest is the end point of the oxygen cascade; oxygen utilisation in tissue mitochondria. Near Infrared Spectroscopy (NIRS) has been developed in an attempt to measure tissue oxygen saturation (StO 2 ) in peripheral muscle microcirculation. Manufacturers state normal values as 87 ± 2%. It uses four wavelengths near the infrared spectrum (680-800 nm) to measure StO 2 , a ratio of oxygenated haemoglobin to total haemoglobin. It is continuous and non-invasive. StO 2 has proven efficacious in predicting oxygen delivery in trauma patients and claims to have been successfully used to guide early resuscitation [1] . OBJECTIVES. We were interested in assessing whether StO 2 had a role in measurement of oxygen delivery in the intensive care population, and how it compared to the parameters currently used to predict oxygen delivery. We had particular interest in the usefulness of NIRS in septic patients, where the pathophysiology of tissue oxygen utilization is disrupted. Patients from a general, adult intensive care unit were enrolled over an 8 month period. All patients had LiDCO monitoring. Exclusion criteria were GTN, atrial fibrillation and patient refusal. 15 mm StO 2 probes were sited on the thenar eminence. Serial recordings of StO 2 , Cardiac Index, HR, SaO 2 , MAP, and PaO 2 were recorded. StO 2 results were compared to more traditional parameters of oxygen delivery. Sixteen patients were recruited, all met criteria for SIRS and shock. Four were excluded with incomplete data. Results were analysed for individual patients and as a collective series. We found: • No statistical correlation between NIRS and SaO 2 or PaO 2 . • A weak and clinically insignificant correlation between cardiac index and NIRS (p \ 0.001). • Supra normal NIRS readings (normal [ 75%) were not infrequently gained in patients where all other parameters were indicating severe shock and poor oxygen delivery. CONCLUSION. Theoretically NIRS has potential to be beneficial in measuring oxygen delivery. Our results demonstrate that NIRS is not accurate for our septic population. We found poor correlation with current methods used to predict oxygen delivery and it may well be more misleading than beneficial. More traditional methods of intensive care monitoring, although sometimes invasive, appear to provide a more accurate representation of a patient's oxygen delivery. BACKGROUND. Urine output is a crucial parameter of renal function and fluid balance. Conservative urine output monitoring harbors problems such as subjective reading, sampling time errors and nursing workload. An electronic urine collection device was introduced into the ICU and connected to a computerized information system. This created a more reliable and accurate means for urine output monitoring and the ability to develop new calculated parameters. 1. To evaluate the effects of introducing an electronical urine collection device into a fully computerized ICU. 2. To evaluate new parameters that were created by the combination of the device and a computerized data management system. Patients included were all admitted to the ICU at Rambam Medical Center, Haifa, Israel, during the years 2007-2008. Urine production and Flow were monitored continuously by the URINFO2000 Ò device (Med-Dynamix, Israel), a novel electronic urinometer, connected to a Patient Data Management System (iMDsoft, Israel). Graphical analysis of urine production was done and derived parameters continuously calculated. Comparison was done to the conventional mechanical urine collection system. Variables studied were: measurement accuracy, sampling time accuracy, nursing workload before and after the implementation process. Correlation between derived parameters and conventional renal function measurements such as Plasma Creatinine and Creatinine Clearance Time. RESULTS. The conservative urine output measuring system demonstrated percentage error span in range of 68-100%, compared to a range of 25-32% percentage error in measurement after implementation of the computerized system. Before implementation, sampling time error span was found to be 12-59 min, while no sampling time error was present after implementation due to the automated recording system. Time consumed by the workload of the conservative urine output monitoring system was measured at 32-64 min per nursing shift (8 h). The computerized system eliminated this workload completely. Derived Parameters evaluated were Continuous Urine Flow (in cc/min or cc/h), Urine Production Acceleration Rate (calculated via the slope of the ''up-rise'' in cc/min 2 ) and the Peak Urine Production Rate (cc/min). These parameters were able to demonstrate immediate changes in renal function, hours before conventional measurements and calculations would show them. CONCLUSION. Implementation of a computerized urine monitoring system can lead to improved accuracy in renal function monitoring and eliminate a significant amount nursing workload. Use of derived calculated parameters may lead to earlier detection of renal malfunction and thus lead to earlier intervention. (40 g/1,000 ml), CiCa Dialysate K2 TM (Na 133 mmol/l, K 2.0 mmol/l, Mg 0.75 mmol/l, Cl 116.5 mmol/l, HCO3 20 mmol/l, Glucose anhydrous 1.0 g/l, pH * 7,4) and Calcium Chloride Mayrhofer TM CaCl 2 0,5 mol/l. The filter was an Ultraflux AV 1000S TM , the material of the bloodline tubing system was medical grade soft PVC. In three circuits used in two different patients we found an opaque white precipitation starting at the CaCl 2 side port growing along the line with the direction of the bloodflow up to a maximal 2 mm wide and 80 mm long stripe. To identify the composition of the white stripes we included histological examination of hematoxylin-eosin stained sections and lyophilisation with wet chemical analysis. Blood samples were simultaneously taken from the venous port of the CVVHD circuit and the arterial line of one patient. RESULTS. Histology showed **an organic material in form of calcific deposit, covered with coagulated blood. Chemical analysis identified this deposit as calcium phosphate. The results of the blood samples are shown in Table 1 . Calcium phosphate precipitates may have reached patient circulation and been deposited in the capillary bed of the lungs or other organs. No histological examinations of tissue were taken and adverse events could not be attributed to the described phenomenon. Citrate anticoagulation was stopped and switched to combined heparin-epoprostenol sodium anticoagulation. CONCLUSIONS. The combination of the fluids and materials used in this specific CVVHD circuit with citrate anticoagulation resulted in some patients in a detectable calcium phosphate formation in the circuit. Physicians using the described setting should be aware of the phenomenon and stop citrate anticoagulation as soon as a deposit occurs. In vitro studies, using different compositions and concentrations of dialysate and substitution fluids and simulating different patient conditions (pH, Ph, Hb, Alb,…) should clarify, which solutions could safely be used. In addition the material of the circuit should be investigated, since surface characteristics have been identified to influence the formation of a calcium phosphate layer [1] . REFERENCE (S) OBJECTIVE. The aim of this study was to assess, in a medical population of critically ill patients, whether intraabdominal pressure at admission was an independent predictor for mortality and to evaluate the effects of intraabdominal hypertension on organ functions. All patients admitted to the medical ICU of the HGU Gregorio Marañón over a period of 45 days were studied prospectively. Patients who fulfilled two or more risk factors for WSACS (diminished abdominal wall compliance, increased intra-luminal contents, increased abdominal contents and/or capillary leak /fluid resuscitation.) were included. IAP was measured via a Foley bladder catheter, according to the modified Kron technique. Data recorded on admission were the patient demographics with, acute physiology and chronic health evaluation II score (APACHE II), and type of admission; during intensive care stay, sepsis-related organ failure assessment score (SOFA) and clinical concomitant factors and conditions. Intraabdominal pressure were measured at least daily together with fluid balance. Patients were followed throughout their hospital stay. Forty-four patients were included in the study (age 58 -17, APACHE II 20. . Half were admitted for cardiopulmonary disease. Twelve (27%) had pancreatic or gastrointestinal disease. Twenty-two (50%) had severe sepsis or septic shock. The incidence of IAH was 80%. Mortality was 50%. The cause of the IAH was capillary leak syndrome/fluid resuscitation in 51% of cases. There was no relationship between the presence of IAH and the number of organ failure during admission. The only variables associated with mortality of the patients were SOFA and APACHE II. The presence of IAH was not a factor associated with increased mortality, although these results may be confounded by sample size. CONCLUSIONS. There is an unusually high incidence of IAH in the population of critically ill medical patients with two or more medical risk factors for WSACS. However, unlike in other populations, our study does not demonstrate that the IAP monitoring allow detecting a group at higher risk of developing multi-organ failure or death. BACKGROUND. Drainage of ascitic fluid is a common practice in order to relief the respiratory discomfort of patients. The aim of the present study was to determine abdominal compliance after ascitic fluid removal by transcutaneous drainage. METHODS. Twelve patients presenting with ascitic fluid were included. All patients had transcutaneous blind drainage with a wide catheter. The ascitic fluid removed was recorded, while the intraabdominal pressure (IAP) was measured as proposed by WSACS. IAP was measured before and 15 min after the puncture. Abdominal compliance (Cabd) was calculated. RESULTS. The pre-drainage IAP was 10.33 mmHg (ranging from 8.82 to 13.24 mmHg, SD 2.02 mmHg), while the post-drainage was 5.90 mmHg (ranging from 5.15 to 8.82 mmHg, SD 1.32 mmHg). The mean volume of ascitic fluid removed was 1774 ml (ranging from 430 to 3,000 ml, SD 977 ml). Cabd after drainage was 307 ml/mmHg (ranging from 67 to 333 ml/ mmHg, SD 144 ml/mmHg). A linear correlation was found between ascitic fluid removal and IAP variations. CONCLUSION. The drainage of ascitic fluid reduces IAP, facilitating in this way respiration. Moreover, IAP variation seems be in linear relation with the volume of ascitic fluid removed. This linear relation between IAP and volume may probably predict the Cabd quite accurately and vice versa. However, larger studies are necessaries in order to safely draw predicting DIAP-DV (Cabd) diagrams, and determine the optimal ascitic fluid removal in order to achieve best comforting of the patient and slower fluid reformation. INTRODUCTION. Use of stroke volume variation (SVV) to guide fluid therapy in preload responsive state has been studied well in patients undergoing cardiac or neurosurgery during anaesthesia. Use of this dynamic monitoring variable has not been studied much in septic shock. We undertook this prospective study to evaluate utility of SVV to optimize preload in patients with septic shock and ARDS. Setting. 40 bedded medical surgical ICU of a 350 bedded tertiary care centre in Pune, India. Inclusion criteria: (1) Patients with ARDS (PO 2 /FiO 2 B 200), SVV readings were taken every 3 h with Flotrac-Vigileo system after confirming abolishment of spontaneous breaths by sedation or paralysis and increasing tidal volume transiently to 8 ml/kg. Fluid boluses were given to keep SVV \ 13% for 24 h after enrollment. Attempts were made to reduce vasopressor doses keeping MAP C 70 mmHg. RESULTS. 20 patients with average age 57.9 ± 16.55 years and APACHE II score 22.2 ± 5.14 were studied. Each patient received an average 6.22 ± 2.54 l fluid in 24 h after enrollment to keep SVV below 13%. SVV at 24 h after enrollment was 10.1 ± 6.13% Improvement in microcirculation was evident as Plasma lactate reduced from 5.43 ± 3.64 (at 0 h) to 3.09 ± 2.78 mmol/l (at 24 h) There was no worsening in pulmonary edema as PO 2 / FiO 2 increased from 165.3 ± 106.1 (at 0 h) to 224 ± 100.66 (at 24 h) Only 6 out of 20 patients needed Renal Replacement Therapy. In 13 patients, vasopressors could be stopped completely in 49.7 ± 19.02 h. 12 of them survived till discharge from the ICU and 1 died of ARDS. In 7 patients, vasopressors could not be weaned off completely and all of them succumbed. Overall survival rate was 60%. CONCLUSION. SVV guided fluid therapy is a promising modality for pre load optimization in mechanically ventilated patients with septic shock and ARDS. INTRODUCTION. Cardiovascular function is an important determinant of outcome in sepsis, and heart rate (HR) has been associated with cardiovascular risk and mortality in large patient cohorts [1] . To investigate the association between HR and 28 or 90 day mortality in septic shock. METHODS. This study is a post hoc analysis of 358 septic shock patients who were included in the control group of a multicenter trial [2] . Demographic and clinical data, average HR and catecholamine requirements during septic shock, occurrence of acute circulatory failure, 28 and 90 day mortality were documented. A binary logistic regression model adjusted for the simplified acute physiology score II (excluding HR) was used to investigate the association between mean HR and acute circulatory failure or 28/90 day mortality. A multiple logistic regression model was applied to identify independent risk factors for developing HR critical for outcome. CONCLUSIONS. HR is associated with 28 and 90 days mortality in septic shock. HR persistently exceeding 110 bpm during septic shock seems associated with a significant risk of death. INTRODUCTION. Different colloids can be used for treatment of hypovolaemia in septic pts. Recently, small-volume resuscitation was introduced for initial therapy of severe hypovolaemia and shock. The concept of small-volume resuscitation encompasses the rapid infusion of a small dose of 7.2% NaCl/colloid solution [1] . However, in septic pts hypovolaemia often associates with acute lung injury (ALI). Therefore in these pts great importance has influence of colloids on oxygen transport. OBJECTIVES. The aim of the study was to evaluate and compare the effects of HHES and HES on oxygen transport in pts with sepsis and SS. METHODS. 34 hypovolaemic pts with sepsis and SS were enrolled in the study. 17 pts received 3-5 ml/kg (250 ml) HHES (7.2% NaCl ? 6% HES) (Fresenius Kabi) within 45 min and 17 pts received HES 130/04 (Voluven, Fresenius Kabi) 15 ml/kg. In all pts before and after infusion the parameters of Oxygen transport was measured by pulmonary arterial catheter and transpulmonary thermodilution (Pulsion Medical System). After infusion of HHES oxygen delivery index (IDO 2 ) increased because of increase of cardiac index (CI) despite of decrease of hemoglobin (Hb) levels and absence of changes of arterial oxygen content. Extravascular lung water (EVLW) and shunt increased significantly immediately after HHES infusion, but this increase was not accompanied by deterioration of PaO 2 /FiO 2 . INTRODUCTION. Severe sepsis is characterised by a wide array of haemodynamic changes including increased capillary leak, vasodilatation, vascular hyporeactivity and myocardial depression. The resultant tissue hypoperfusion is an important catalyst of multi-organ failure [1] . To further develop our understanding of the underlying mechanisms, we have developed and characterised a fluid-resuscitated mouse model of intraperitoneal polymicrobial sepsis. OBJECTIVES. To assess alterations in cardiac performance in mice at 0, 3, 6 and 24 h following faecal peritonitis. METHODS. Sepsis was induced in 25 week old male mice (n = 25) by intraperitoneal (i/p) injection of dilute faecal slurry. Sham animals (n = 10) received n-saline i/p. Animals were fluid resuscitated at time 0 (30 ml/kg 0.9% saline), and at 6 and 18 h (50 ml/kg 0.8% saline-5% dextrose each time). Under a minimum concentration of isoflurane to achieve light anaesthesia, peak velocity, stroke distance, heart rate and fractional shortening were measured in the short axis plane by echocardiography at the 0, 6 and 24 h timepoints. In separate sham and severe septic mice (n = 6 per group) the cardiac response to intravenous colloid boluses was assessed at 6 and 24 h. RESULTS. We clinically characterised septic animals into 'mild' and 'severe'. Mice with severe sepsis showed a 65% drop in peak velocity and cardiac output at 6 h (vs. 30 and 14% falls in the mild septic and sham-operated animals, respectively, p \ 0.05). While mild septic animals showed recovery by 24 hr, cardiac output in severely ill mice remained significantly depressed (due to both low heart rate and stroke volume) compared to mild septic and sham animals [*p \ 0.05 ( Fig. 1) ]. Stepwise 0.5 ml boluses of intravenous fluid at 6 h in severe septic animals led to restoration of cardiac output to baseline (0 h) values. However, in the 24 h septic animals, fluid challenge produced an initial improvement in cardiac output followed by deterioration [ Fig. 2 PURPOSE. Myocardial dysfunction has been well-documented in sepsis even in hyperdynamic state, and may develop and contribute to morbidity and mortality. Nicaraven, a radical scavenger, has been shown to protect the coronary endothelial and myocardial function from ischemia and reperfusion injury due to hydroxyl radical scavenging activity. The purposes of present study were to determine the effects of nicaraven on cardiac function and cytokine production in lipopolysaccharide (LPS) induced sepsis. METHODS. This protocol was approved by our institutional committee. Following arterial and venous cannulation and tracheostomy, rats (330-350 g) were anesthetized with pentobarbital, and mechanically ventilated with a control mode (V T = 12 ml/kg, RR = 40 rpm). After baseline measurements, rats (n = 20) were administrated with LPS (10 mg/kg, intravenously) and randomly assigned to following two groups: the nicaraven group treated with nicaraven [3 mg/(kg min), intravenously] and the control group treated with saline. The left ventricular pressure and volume were measured with the pressure and conductance catheter every one hour. Cardiac function, including cardiac output (CO), ejection fraction (EF), and maximal elastance of left ventricle (E max ) were analyzed with a computer soft. Blood was collected, centrifuged (2,000 g, 15 min, 92) , and stored (-80°C) from rats every 2 h after operation to measure plasma concentration of TNF-a, IL1-b and macrophage migration inhibitory factor (MIF) using enzyme-linked immunosorbent assays kits. Blood lactate concentration was also measured. Data were analyzed by repeated measure ANOVA. RESULTS. The CO in the nicaraven group was kept significantly higher than the control group (p \ 0.05). The EF and E max in the nicaraven group were also kept significantly higher than the control group (p \ 0.05). Arterial lactate, TNF-a, IL1-b and MIF were significantly lower in the nicaraven group versus the control group (p \ 0.05). CONCLUSION. The current study indicates that the treatment with nicaraven improved cardiac dysfunction and reduced plasma concentration of cytokines, and improved lactic acidosis in septic model. METHODS. This protocol was approved by our institutional committee. Following arterial and venous cannulation and tracheostomy, rats (330-350 g) were anesthetized with pentobarbital, and mechanically ventilated with a control mode (V T = 12 ml/kg, RR = 40 rpm). After baseline measurements, rats (n = 20) were administrated with LPS (10 mg/kg, intravenously) and randomly assigned to following two groups: the oxytocin group treated with oxytocin (15 IU/kg IV and followed by the continuous infusion of 5 mg/(kg min), intravenously) and the control group treated with saline. The left ventricular pressure and volume were measured with the pressure and conductance catheter every 1 h. Cardiac function, including cardiac output (CO), left ventricular peak pressure (LVPP), and cardiac work (CW) were analyzed with a computer soft. Blood was collected from rats every 2 h after operation to measure plasma concentration of blood lactate. Data were analyzed by repeated measure ANOVA. RESULTS. The CO in the oxytocin group was kept higher than the control group but there is no significance (p \ 0.15). The LVPP and CW in the oxytocin group were kept significantly higher than the control group (p \ 0.05). Arterial lactate was significantly lower in the oxytocin group versus the control group (p \ 0.05). CONCLUSION. The present study indicates that the treatment with oxytocin improved cardiac dysfunction and reduced plasma concentration of lactate in septic model. INTRODUCTION. Conventional hemodynamic monitoring parameters like heart rate, mean arterial pressure (MAP), and central venous pressure may be misleading in assessment of circulating blood volume in severely septic patients. Inadequate blood volume may compromise renal blood flow leading to acute kidney injury (AKI). Stroke volume variation (SVV) is a sensitive indicator of relative preload responsiveness and has high sensitivity and specificity when compared to conventional indicators of volume status and their ability to determine fluid responsiveness. To assess the efficacy of SVV guided fluid therapy in preventing AKI in patients with severe sepsis on ventilatory support. Mechanically ventilated patients with septic shock who had undergone resuscitation based on surviving sepsis campaign guidelines and still requiring vasopressor support were enrolled. Patients with pre-existing renal failure were excluded. A total of 101 patients were randomized to receive fluid therapy according to conventional indices or SVV, in the first 24 h after mechanical ventilation. SVV was measured with Flotrac Vigelio after abolishing spontaneous ventilation by sedation and paralysis if required. Fluid boluses were given to keep SVV less than 13%. Vasopressor therapy was optimised to maintain MAP [ 70 mm Hg. Patients were followed during their ICU course with respect to development of AKI, need for renal replacement therapy (RRT), length of ICU stay and ICU mortality. AKI was diagnosed as per the RIFLE criteria. Primary outcome measure was development of AKI. RESULTS. Patients in both groups were similar with respect to age (p = 0.6), sex (p = 0.7), and admission APACHE II score (p = 0.6). Incidence of AKI was 29/48 (60.4%) and 21/53 (39.6%) in conventional and SVV groups, respectively (p = 0.037). There was no statistically significant difference in terms of need for RRT, ICU length of stay and ICU mortality ( [1] . Moreover, PNU-37883A (PNU), an inhibitor acting through the poreforming subunit of the channel, did not affect BP in our awake peritonitis rat model [2] . Given that vasoconstrictors, including NE, inhibit K ATP channel activity [3] , we speculate that the high sympathetic tone seen in sepsis [4] OBJECTIVES. The goal of this study was to determine if HFAV improves microcirculatory alterations in SS patients. METHODS. By using side dark field videomicroscopy (Microscan Ò , Microvision medical) we evaluated sublingual microcirculation in 12 SS patients who according to our local protocol care [1] underwent a 12 h-HFAV as rescue therapy for refractory septic shock. Hemodynamic parameters and microcirculation were assessed at baseline, after 12 h of HFAV, and 6 h after stopping HFAV. Microcirculation assessments were performed at 3 to 6 different sublingual areas (10-20 s/image). Images were analyzed according to recent consensus [2] by semiquantitative scores of flow (MFI, Mean flow index and PPV, proportion of perfused vessels), density (TVD, total vascular density; PVD, perfused vascular density), and heterogeneity (Het MFI) of small vessels (\20 lm INTRODUCTION. Disturbances within the microcirculation represent an important factor in the pathogenesis of multiple organ dysfunction in sepsis and septic shock [1] . Gender-specific effects may modulate the septic pathophysiology [2] . Therefore, we studied sepsis-induced changes within the intestinal microcirculation in randomly cycling and ovariectomized female rats. OBJECTIVES. We hypothesized that estradiol (E2) and dehydroepiandrosterone (DHEA) may have a beneficial effect on the microcirculation during experimental sepsis and resubstituted these hormones in the ovariectomized animals. METHODS. Fifty female rats were divided in to five groups of ten animals. Group 1 received sham laparotomy without further treatment. In group 2-5 we induced experimental sepsis (colon ascendens stent peritonitis-CASP model). Animals of groups 3-5 were additionally ovariectomized 3 weeks before sepsis induction. In group 4 we administered 10 mg/kg estradiol immediately after and 12 h following CASP surgery. The animals of group 5 received 50 mg/kg DHEA immediately after sepsis induction. Twenty-four hours after CASP surgery intravital microscopy was performed to study leukocyte-endothelial interactions and functional capillary density. Blood samples were taken for the measurement of estradiol, DHEA and inflammatory cytokines. RESULTS. In ovariectomized rats subjected to CASP the number of activated leukocytes was significantly increased in comparison to sham and not ovariectomized CASP animals (p \ 0.05). In ovariectomized rats treated with E2 leukocyte adhesion was significantly reduced in comparison to untreated ovariectomized rats subjected to CASP (p \ 0.05). The same observation was made in ovariectomized rats treated with DHEA. In addition, in ovariectomized rats subjected to CASP the functional capillary density was significantly decreased in comparison to sham and CASP groups (p \ 0.05). In ovariectomized rats treated with E2 or DHEA functional capillary density was completely restored. The results demonstrate the role of E2 and DHEA in the sepsis-induced changes within the microcirculation. A rapid, non-genomic effect of both E2 and DHEA is suggested [3] . DHEA may play a role through conversion to E2 or through direct acting on the E2 receptor. Further investigations should be done to elucidate the underlying mechanisms. Both E2 and DHEA appear to be a promising adjunct for the prevention and treatment of sepsis-induced multiorgan failure. Liver is involved in the production of NO. The aim of this experimental study was to evaluate the time course of hepatic NO production at the onset of hypotension occurring during septic shock. METHODS. Male Wistar rats were anesthetized with ISOFLURANE Ò , and mechanically ventilated. A first group (sepsis group) underwent a cecal ligature and puncture (CLP) peritonitis, the second one (control group) a laparotomy only. Animals were euthanized at different times: 2 h after surgery, at shock onset, 2 and 3 h after shock. Shock was defined by systolic blood pressure lower than 80 mmHg. Each rat of sepsis group was matched with rat of control group. Liver perfusion was measured using a direct laser Doppler flowmetry probe. NO generated in the liver was measured using a pulse voltametric method. RESULTS. 38 rats were studied (19 in each group). In sepsis group, shock occurred at 233 ± 51 min after CLP. In sepsis group, a significant decrease of hepatic perfusion was identified 2 h after CLP ( Fig. 1 ) whereas hepatic NO production was increased only at the time of shock onset (Fig. 2 ). Intra hepatic NO production CONCLUSION. This study shows a time shift between hepatic perfusion disturbance, hepatic NO production and shock onset in a septic animal model. INTRODUCTION. Microvascular blood flow alteration is a key element of severe sepsis and septic shock [1] . One study show that microvascular alterations in septic patients could be improved with a nitric oxide donor nitroglycerin [2] . Studies in human have shown that infusion of magnesium sulphate has endothelium dependent and independent vasodilation properties, increase of red blood cells deformability in specific conditions. We hypothesized that combination of nitroglycerin with magnesium sulphate and order of priority influence microvascular improvement in patients with severe sepsis and septic shock. METHODS. Ten septic patients who had already been fluid resuscitated randomly assigned to one of two groups. One group received magnesium sulphate infusion 2 g/h with nitroglycerin 0.5 mg/h infusion added after 30 min. Another group received nitroglycerin 0.5 mg/h infusion with additional magnesium sulphate 2 g/h infusion after 30 min. If required we added crystalloids and use norepinephrine. Sublingual microcirculation was evaluated using side dark field videomicroscopy (MicroScanÒ, MicroVisionMedical) . Each patient's microcirculation was evaluated by examining 5 different sublingual areas (10-20 s/image). In all patients measurements were obtained at baseline, at 30 and 60 min. Images were analyzed by semiquantitative scores of flow (MFI, Mean flow index; PPV, proportion of perfused vessels) and density (TVD, total vascular density; PVD, perfused vascular density). Capillaries were defined as microvessels with a diameter \ 20 lm. Data are presented as median values (percentiles 25; 75). . The median age of the patients was 60 (50; 71) years. In both groups we see tendency progressively increase of PVD, PPV and MFI after drug alone and combination after 60 min, but PVD has tendency to be higher [9.2(9; 9.8) n/mm 2 vs. 8.0 (7.8; 8.3) n/mm 2 , p = 0.05] after 60 min. in group, where magnesium sulphate infusion was given first. Combination of magnesium sulphate with nitroglycerin, when magnesium sulphate is given first, has tendency to higher potential for improving of microcirculation in severe sepsis and septic shock patients, but further studies are needed to obtain more detailed results.  Severe sepsis remains one of the leading causes of death in critical care, with around 30% of patients dying within one month of diagnosis. Rapid diagnosis and therapy of sepsis improves survival [1] . In November 2007 the Whittington Hospital introduced a hospital severe sepsis guideline, based on the first Surviving Sepsis Campaign guideline [2] . The sepsis guideline was published on the hospital intranet and specified 20 actions to be completed within the first 24 h of the diagnosis of severe sepsis or septic shock [3] . OBJECTIVES. To assess whether publication of a sepsis guideline on the hospital intranet, coupled with departmental educational campaigns, improved the management of severe sepsis. The Whittington Hospital is a university associated general hospital in London. We audited the early management of severe sepsis and septic shock before and after the introduction of the new hospital sepsis guideline. The 'before' phase comprised 22 patients with severe sepsis or septic shock admitted to critical care between November 2004 and November 2007. The 'after' phase comprised 30 patients with severe sepsis or septic shock admitted to critical care between January and November 2008, after introduction of the guideline. Data was retrospectively collected from case notes and observation charts. The audit tool compared immediate, 1, 6 and 24 h actions following diagnosis against the hospital guideline. The main outcome measures were compliance and 28 day mortality. Compliance was defined as the average of the percentage compliance with each of the 20 items specified in the guideline. Results were compared by chi squared. Compliance with the severe sepsis guidelines was only 64% after publication of the hospital sepsis guideline, compared with 68% before publication (p. 71)! There was similarly no significant difference in 28 day mortality (before 32%, after 30 %, p. 88). Publication of a sepsis guideline on the hospital intranet, coupled with departmental teaching sessions, failed to improve compliance with Surviving Sepsis recommendations, perhaps because the guideline competes for attention with over 475 other guidelines on the intranet. Next we will implement an interdepartmental educational programme to try and improve guideline compliance. As guidelines proliferate it is difficult to ensure they are followed, but failure to implement a published hospital guideline may represent a significant clinical and medicolegal risk. METHODS. The ICU is an intensivist-led 10 bed Intensive Care in a 500 bed non-academic teaching hospital. Hospital mortality from sepsis in ICU-patients was 27.7% in 2007. Patients are treated under modern ICU conditioning, including continuous venovenous hemofiltration and a lung-protective ventilation strategy including prone position. An intensive insulin therapy protocol for glycemic control is used. In the period between March until June 2008, we prospectively screened all patients admitted to the ICU for (severe) sepsis, without the knowledge of the nurses and most of the doctors. All severe septic patients were included in our Surviving Sepsis Database. After 24 h, we examined how many targets of the resuscitation and management bundles were applicable and reached. In the period between March until June 2008, 154 patients were admitted to the ICU. Twenty-two of them were suffering from severe sepsis (14.3%), of which 18 had a septic shock. Focus of the sepsis was abdominal in 10 patients (46%), pulmonary in five patients (23%), urogenital tract in five patients (23%), meningitis in one patient (4%) and catheterrelated in one patient (4%). Table 1 shows us the applicability and achievement of the bundle elements. Only in one of the 22 patients all targets were reached. However, mean individual bundle element performance was 65.3% (SD 39.7). All patients received fluid resuscitation when indicated, and all patients on mechanical ventilation were ventilated in a lung-protective manner with plateau pressures \30 cm H 2 O. Only 33 percent of patients had glucose levels within the target range. ScvO 2 was never measured, though it was indicated in 18 patients. One patient had an APACHE IIscore C25 and had no contraindications for administration of activated protein C. Treatment was not considered for this patient by the attending physician. Of these 22 patients suffering from severe sepsis, three died within 30 days after the diagnosis (13.6%). INTRODUCTION. The Surviving Sepsis Campaign (SSC) Guidelines give a group of interventions (''sepsis bundles'') expected to improve the outcome of patients with severe sepsis [1] . OBJETIVES: The aim of this study was to evaluate the impact of the implementation of the SSC Guidelines on the mortality in our intensive care unit (ICU). METHODS. Prospective, observational study. During one year period (January 2008-January 2009) the sepsis bundles were applied to each patient with severe sepsis-septic shock and they were followed up until discharge. We considered as ''time O'' (the time of delay of the implementation of the sepsis bundles) the time of admission of the patients in the ICU. For each severe septic patient the following data was registered: time delay, APACHE II and SOFA scores at ICU admission, diagnosis, the rate of compliance with the resucitation and management bundles, microbiological data, evolution of levels of serum lactate, empiric antibiotic therapy, length of stay and mortality in ICU. The application of guidelines impact on mortality was compared with historical data years before implementation in our ICU (46.3%) and Spanish ICU (48.2%) [2] . A total of 61 severe septic patients were included in the study. 7 (11.5%) patients had severe sepsis and 54 (88.5%) septic shock. The median age was 70 years. The mean APACHE II was 21.7 (±8) and SOFA was 8.5 (±4.3). The main sources of infection were abdomen (59%), lungs (21%), urinary tract (11.7%) and soft tissues (3.27%). The most common clinical diagnosis related to an episode of severe sepsis was peritonitis (59%). A microbiological diagnosis of the infection was reached in 75.4% and the infections were mostly caused by Gram-bacilli. Once the antibiogram was obtained, the initial treatment was considered appropriate in 96.7% patients. The rate of compliance with sepsis bundles was 100%. The length of ICU stay was 15.3 days. Mortality was 21.3%. The implementation of the sepsis bundles decreased ICU mortality significantly (48.2% before implementation vs. 21.3% after implementation). Non survivors were older (median age 77 ± 4.8), had higher APACHE II (mean 29.3 ± 9) and SOFA (mean 14 ± 3.6), 100% had septic shock, 61.5% had negative cultures and an increased on the levels of serum lactate in 24 h. Age, APACHE II and SOFA scores and the increased on the levels of the serum lactate were useful tools to predict mortality. CONCLUSION. Implementation of the Surviving Sepsis Campaign Guidelines was associated with a reduction in ICU mortality. INTRODUCTION. The objective of this before-after study is to assess the impact of a protocol of care for severe sepsis in a French emergency setting. METHODS. Two 4 months periods were surveyed before and after the initiation of a protocol of care for severe sepsis and septic shock. After the control period (P1: November 2004-February 2005), a procedure for early recognition, aggressive treatment and standardized antibiotherapy of severe sepsis was initiated. A campaign to raise medical physicians and nurses awareness concerning this new strategy of care was performed. The intervention period (P2: November 2006-February 2007) assessed the impact of these actions. . 82 patients with severe sepsis or septic shock were included during P1 (20% of patients with a suspected infection and 1.2% of all non trauma admissions) and 105 during P2 (22.8% of patients with a suspected infection and 1.3% of admissions). The age and the proportion of patients with co-morbidities were similar during the P1 and the P2 periods (82 years in median versus 82 years, and 49 vs. 50%, respectively). 39 and 41% of the patients lived in long term care facilities. Severe sepsis and septic shock were correctly identified by the emergency team in 25/82 (30.4%) during P1 and in 57/105 (54.3%) in P2 (p = 0.002). The delay between the admission in the emergency department and the administration of antibiotics was in median equal to 4 h 28 min in P1 and 2 h 45 min in P2 (p = 0.0015). Adequate IV fluid resuscitation was administered to 40% of patients in P1 and 63% of patients in P2 (p = 0.002). During P1, 20% of patients did not qualify for admission to the intensive care unit compared to 44.7% in P2. Hospital mortality did not change from 29.3% (24/82) in P1 to 26.7% (28/105) in P2 (p = 0.81). CONCLUSION. The introduction of a standardized treatment protocol in an emergency department allowed a better recognition of severe sepsis with earlier adapted treatment . The study was not powered to demonstrate a reduction of the mortality in this elderly population.  Multiple studies have shown that early detection and therapy is crucial for the prognosis of a severe septic patient. Many hospitals have joined the Surviving Sepsis Campaign and its fight for the decrease of mortality in severe sepsis and have implemented the Severe Sepsis Bundles into their daily practice. Other institutions such as ours had so far not taken this step, perhaps because the process is hard and time consuming. We have tried to find an easy way to audit the implementation of Severe Sepsis Bundles and its change in time in an institution without a set system and database for the implementation of Severe Sepsis Bundles to help us prove, that a systemic change in clinical practice is essential. We have decided to use the first step of the Resuscitation Bundle-the measurement of lactate and audit the lactate requests in blood samples with elevated inflammatory markers in our hospital laboratory information system. We retrospectively audited the number of lactate requests in blood samples with C-reactive protein (CRP) C 200 mg/l and its evolvement in time between 2004 and 2007before and after the introduction of Surviving Sepsis Guidelines and Severe Sepsis Bundles in our regional hospital with 980 beds. We compared the total number of blood samples with elevated CRP C over 200 mg/l with or without procalcitonin request in our institution with the number of blood samples with CRP C 200 mg/l and lactate request (both arterial and venous) in the hospital laboratory information system. . The total number of lactate requests in samples with CRP C 200 mg/l had increased in time, the incidence widely differed between departments. The main increase was in patiens from intensive care units, the number of lactate requests in samples from general wards, emergency department and intermediate (step down) units had also increased (18 lactate requests in 1667 samples with CRP C 200 mg/l-1,1 % in 2004 and 104 lactate requests in 1857 samples-5.5% in 2007) but still remains insufficient. Surprising was that procalcitonin was in non ICU patiens with CRP C 200 mg/l requested more often than lactate. Although many lectures and seminars on Severe Sepsis Bundles and the guidelines for the management of severe sepsis were organised in our intitution between the year 2004 and 2007, it was not sufficiently effective. CONCLUSION. Retrospective audit in the hospital laboratory information system of the number of lactate requests in samples with elevated inflammatory markers appears to be a fast and a very easy first step for auditing how the Surviving Sepsis Guidelines and Severe Sepsis Bundles are implemented in your institution. The results help to quantify the present state, its change in time and may serve as an impulse to make systemic changes in the system of early detection and therapy of septic patients. INTRODUCTION. Early goal-directed therapy (EGDT) is the accepted gold standard for resuscitation in septic shock [1, 2] . International guidelines for the treatment of septic shock [2] set an initial 6 h limit to accomplish this goal. To test the hypothesis that EGDT with fluids and vasopressors has better patient outcomes if each intervention is completed within 6 h. Thirty septic shock patients from the Spring of 2006 and 32 from Spring 2008 were reviewed prospectively (n = 62). Septic shock was defined as a lactic acid C 4mMol/L and/or hypotension unresponsive to fluids. Apache II and SOFA scores were calculated. Patients were subjected to the hospital septic shock protocol according to guidelines [2] . Firstly, EGDT compliance was met if the following 3 interventions were achieved within 6 h: lactate levels drawn, MAP C 65 mmHg and CVP C 8 mmHg; and secondly, if antibiotics were given\3 h, blood cultures were taken before antibiotics and if 20 mL/kg fluid bolus was administered prior to vasopressors. In 27 patients 5/6 interventions were performed in time (''EGDT-Compliant''). The other 35 were deemed ''EGDT-Noncompliant''. Outcomes were mortality rate and discharge destination. Fisher test was used in statistical analysis. . MR was 30% amongst the Compliant and 43% amongst the Noncompliant and admission to long-term care facilities (LTCF) was 52 and 40%, respectively. Neither one of these differences was statistically significant. A power analysis revealed that 248 patients are required to attain statistical significance for mortality. Discharge home was the same in both groups. There was no difference between groups in the number of new tracheostomies or new hemodialysis. CONCLUSIONS. In a US community teaching hospital, compliance with guidelines in the treatment of septic shock had a trend towards lower mortality and higher discharge rates to LTCF but the difference was not statistically significant. Larger numbers are needed for the benefits/effects of EGDT-compliant therapy to reach statistical significance in the treatment of septic shock in this hospital setting. improve the survival rate of septic patients by means of education and implementation of a sepsis operative protocol including the activation of a specific consultation by an intensivist and an infectious disease specialist (i.e. sepsis team, ST). Aim of this study was to describe the first 30 months activity of ST, with a focus on the patients not admitted in intensive care unit (noICU). METHODS. The sepsis operative protocol, introduced in clinical practice in June 2006, provides for specific instructions for the early identification and management of septic patients and for the early activation of the ST for patients with severe sepsis or septic shock admitted in non-intensive departments. The ST consultation ought to support the departmental health personnel in the management of septic patient and allows an early intensive care admission in case of shock or if mechanical ventilation is needed. To assess ST activity, we evaluated in noICU patients the correct ST activation rate, the number of ST activations for each patient, the rate of central venous catheter insertion (CVC) and the 30 days mortality. RESULTS. From June 2006 to December 2008, the ST was activated for 222 patients (7.4 patients per month) whose 109 (49%) were admitted to ICU and 20 (9%) were considered too sick to benefit. In 60 (64%) of the remaining 93 patients, ST was properly activated: 57 patients with severe sepsis and 3 with septic shock. Thirteen patients (14%) had no sepsis and 20 (22%) had sepsis without organ dysfunction. 74% of ST activations originated from medical departments (including emergency department) and 26% from surgical departments. The number of ST activations for each single patient was 2 ± 1. The 30 days mortality was 0.05% in patients with sepsis, 23% in patients with severe sepsis and 33% in patients with septic shock. CONCLUSION. The rate of correct activation of ST and the number of activations for each patient were acceptable considering that more than 80% of the activations refers to septic patients and that a mean of 2 activations was sufficient for patient management. Mortality rates observed are slightly lower than those reported by others, but further data are needed to evaluate the impact of ST on patient outcome. A. Estella 1 , L. Pérez Fontaiña 1 , J. I. Sanchez Angulo 1 , E. Moreno 1 1 Hospital of Jerez, Emergency and critical care unit, Jerez, Spain Clinical evidence suggests that an early diagnosis and treatment of severe sepsis has been shown to improve outcome. Frequently the initial management of septic patients occurs outside of the ICU. OBJECTIVE. To describe clinical characteristics and outcome of septic shock patients admitted in ICU and to compare mortality according origin prior admission in the ICU (emergency department versus medical or surgical wards). Consecutive patients with septic shock admitted in ICU from July 2007 to November 2008 were registered. Age, ICU length of stay, source of infection, isolated bacteria, blood lactate concentration, APACHE II score and mortality were collected. Patients were classified according the origin prior admission in ICU. . 97 consecutive septic patients were admitted in ICU during the time of study, global mortality was 34%. 58 patients were admitted from medical or surgical wards and 39 patients from the emergency department. Mean age was 64 years, 58 male and 39 female, ICU length of stay was 8.4 ± 5.8 days, the mean APACHE II score at admission in ICU was 20.3 ± 7. Abdominal infection, 44.3%, was the commonest source of infection followed by pulmonary and urinary infection, 21.6 and 20.6% respectively. 33 patients (34%) had a positive bacterial culture, the mean baseline lactate level was 3.8 ± 3.5 mmol/l p \ 0.05 (3.6 ± 4 mmol/l in the medical and surgical wards group versus 4.1 ± 2 mmol/l in the emergency department group).There were not differences in clinical characteristics according origin prior admission in the ICU except for lactate level, and mortality, 56.9% in the medical and surgical wards group and 17.9% in the emergency department group (p \ 0.05). CONCLUSION. There were not differences in clinical characteristics, ICU length of stay, source of infection, isolated bacteria and APACHE II score between groups. Mortality was lower in the group of patients admitted in ICU from the emergency department than the group admitted from medical and surgical wards. Although very high circulating concentrations are detectable in plasma, it is not known which organs actually produce the cytokines. We hypothesized that key abdominal organs affected by sepsis such as the kidney and liver produce cytokines and tested this hypothesis by measuring cytokine flux. MATERIALS AND METHODS. 12 pigs (15-26 kg) were randomised to control (n = 5) and endotoxin (n = 7) groups. Hemodynamic measurements using PiCCO and pulmonary arterial catheters and arterial blood gases were collected hourly. Portal, hepatic and renal arterial blood flows were measured with transit time probes. Arterial and venous cytokine concentrations (TNFa, IL-1b, IL-6 and IL-10) were measured from samples taken from each respective organ. Cytokine flux was calculated as: organ blood flow 9 (venous-arterial cytokine concentration difference). Endotoxemic pigs had significant increases in heart rate (p \ 0.01) and mean pulmonary arterial pressure (p = 0.03) and decreases in cardiac output (p = 0.04). In contrast, these hemodynamic variables remained stable in the control animals. Renal, hepatic and portal vein flows decreased significantly in all endotoxemic animals but remained stable in the control group. Renal [ml/(kg min)]:Control 5.5 ± 0.4, 5.4 ± 0.1, 5.4 ± 0.3, 5.3 ± 0.4 versus endotoxin 5.8 ± 0.6, 5.9 ± 0.9, 3.0 ± 1.0, 3.0 ± 0.4 for baseline, t = 2, 4, 6, respectively. Portal [ml/(kg min)]: control 38.6 ± 3.0, 38.8 ± 5.8. 39.8 ± 5.0, 41 ± 6.7 versus endotoxin 42.7 ± 8.5, 15.1 ± 3.5, 12.4 ± 3.4, 12.4 ± 3.3 for baseline, t = 2, 4, 6, respectively. Hepatic [ml/(kg min)]: control 5.1 ± 1.0, 5.3 ± 0.9, 5.5 ± 1.5, 5.2 ± 1.2 versus endotoxin 5.6 ± 0.9, 4.8 ± 1.4, 2.5 ± 0.7, 2.6 ± 0.1 for baseline, t = 2, 4, 6, respectively plasma cytokines TNFa was detectable in very low concentrations (\20 pg/ml) in 2 of the 7 endotoxemic animals, and none of the control animals. IL-1b, IL-6 and IL-10 increased significantly with time peaking at t = 6, 4 and 2 respectively in the endotoxin group. In the control group only few animals showed a cytokine response, in numbers insufficient for statistical analysis. In the endotoxin group there was a negative cytokine flux in the renal circulation, maximal at t = 6 [-290.0 ± 429.6 for IL-1b and -5210.7 ± 5865.6 for IL-6 (pg/ml), respectively]. There was a positive cytokine flux for IL-10 reaching its peak at t = 4 (9.1 ± 156.6 pg/ml). A similar pattern was seen in the hepatic ? portal circulation with maximal flux for IL-1b and 6 at t = 6 (-291.0 ± 690 and -1346.4 ± 2687.4 pg/ml, respectively). For IL-10 there was a positive flux peaking at -= 6 (1203.1 ± 1112.3 pg/ml). Although there was a negative IL-1b and IL-6 cytokine flux in the renal, portal and hepatic circulations indicating net uptake, and vice versa for IL-10, none of these values reached statistical significance. CONCLUSIONS. These data do not support that cytokines are produced nor consumed in the kidney and liver during endotoxemia. DISCUSSION. Non-survivors show more severity at the beginning and during their ICU stay, more altered biological markers and a higher mean glycemia, but do not show significant difference either at initial glycemia, history of diabetes, hypoglycemia event or insulin treatment. Elevated mean glycemia appears to be a factor independently associated with higher mortality. Hyperglycemia prevalence in critically ill patients is very high and the controversy whether it is a mortality marker or a mediator still remains. Our results would justify starting an intensive insulin protocol and its subsequent analysis. The interest of continuous ScvO 2 was proven in the management of severe septic patients [1] , but the place of discontinuous ScvO 2 remains unclear. OBJECTIVES. To compare continuous ScvO 2 to discontinuous ScvO 2 concerning the number of therapeutic interventions in the management of severe sepsis (SS) and septic shock (SSC). METHODS. Prospective randomized comparative study. Inclusion criteria: age [ 16 years, SS or SSC [2] . Two groups were defined: continuous scvO 2 (C group) monitored by a central venous oximetry catheter (Edwards lifescience X3820HS, Irvine, USA), and discontinuous ScvO 2 (D group) measured on blood samples drawn every 4 h and at the request of the treating physician. The hemodynamic management of these patients was based on the algorithm established by Rivers [1] . The primary endpoint was the number of therapeutic interventions (fluids, transfusions, inotropic drugs) triggered by a ScvO 2 \ 70%. Non parametric tests (Chi-square and Mann Whitney) and repeated-measures ANOVA were used in statistical analysis (p \ 0.05 was considered significant). RESULTS. 31 patients were included in a polyvalent intensive care unit (ICU). The two groups were comparable concerning age, sex, weight, height, APACHE II score, MODS on admission and mechanical ventilation (MV). There were no statistical differences between the two groups concerning: mortality, duration of ICU stay, duration of MV and the evolution of MODS and plasma levels of lactate from day 1 to day 5. The therapeutic interventions data are shown in Table 1 . INTRODUCTION. The calcium activated potassium channel (BKCA) exists in smooth muscle cells in most vascular beds and is believed to be important in sepsis induced hypotension and vascular hyporeactivity [1] and also in neutrophil killing and macrophage production of proinflamatory cytokines. However the latter two roles have been disputed [2] and we have found that BKCA expression is not upregulated in aorta from septic mice using real time polymerase chain reaction. As its role in sepsis remains uncertain we sought to determine whether null mice for the BKCA channel were (a) resistant to hypotension and (b) showed improved survival in a clinically relevant model of fecal peritonitis. METHODS. BKCA null mice (based on BALC) were obtained from JAX Ò Mice. Agematched litter mates homozygous for BKCA were wild types (WT). Mice (age 18-24 weeks) had tethered arterial and venous lines inserted under isoflurane anesthesia. The tether enabled mice to roam cages freely whilst continuous blood pressure (BP) traces were obtained. 24 h post surgery, echocardiogram and intraperitoneal injection of rat slurry was administered under anesthesia. Fluid resuscitation of 0.3 ml/h voluven/5% dextrose (50:50) was given. At 6 and 24 h echo was recorded and mice culled with mesenteric arteries dissected for myography. Data expressed as mean(sem) and statistical analysis ANOVA. RESULTS. Genotypic study and whole cell patch clamp recording in aortic smooth muscle cells confirmed BKCA current was absent in null mice. Fecal peritonitis induced equivalent hypotension in both WT (n = 5) and BKCA null mice (n = 4) at 3-12 h (Fig. 1a ). Echocardiography at 6 h post slurry showed no difference in cardiac output between WT-23.1 (3.1) and BKCA null mice-23.4 (2.6) ml/min and no difference or improvement cf time 0 (Fig. 1b) . Thus this fall in BP is due to reduction in total peripheral resistance not myocardial depression. In addition 3/4 of the BKCA null mice died prior to 24 h as opposed to 1/5 WT. Hence myography was only performed on WT mesenteric arteries which were hyporeactive to norepinephrine (p = 0.005, Fig. 1c ). CONCLUSION. There is no evidence from this transgenic mice study of fecal peritonitis that inhibition of the BKCA channel would be beneficial for the treatment of hypotension in septic shock or would improve survival. REFERENCE(S). INTRODUCTION. Pro-and anti-inflammatory responses play a key role in the pathophysiology of sepsis [1] . Phosphodiesterase (PDE) inhibition could play an anti-inflammatory role in this setting [2] . Previously, it was shown that among the three inhibitors of PDE five currently available (sildenafil, vardenafil, tadalafil), only tadalafil could exhibit anti-inflammatory properties on endothelial cells (EC) stimulated by modified oxidized LDL or TNF alpha [3] . To assess the potential anti-inflammatory role of tadalafil in EC stimulated by LPS. METHODS. THP-1 cells (2.10 6 /ml in RPMI) were incubated alone (control group) or in the presence of either tadalafil (3 lM; Eli Lilly, IN, USA), LPS from E.coli 0111:B4 (100 ng/ml; Sigma-Aldrich, Inc.) or both. TNFa production, as a marker of inflammation, was measured in the supernatant (ELISA assay; Roche, Mannheim, Germany) after 16 h of incubation (3 independent experiments in quadruplet). Comparisons were made by one-way ANOVA, with Bonferroni's post hoc test (Mean ± SEM). RESULTS. Production of TNFa increased significantly after stimulation by LPS alone compared to control (49.9 ± 7.7-fold over the control, p \ 0.05) or tadalafil (49.9 ± 7.7 vs. 1.0 ± 0.2-fold over control, p \ 0.05). Levels of TNFa were significantly reduced in the LPS ? tadalafil group, compared with the LPS group (14.8 ± 2.1 vs. 49.9 ± 7.7-fold over the control, respectively; p \ 0.001) (Graph 1). We hypothesized that DAA provides varying protective effects in different organs as indicated by higher amounts of ePCR in early murine sepsis. METHODS. Sepsis was induced by cecal ligation and puncture (CLP) in male NMRI-mice (n = 21, body weight 30 ± 3 g). Animals were randomly assigned to vehicle infusion (control), or CLP sepsis with DAA infusion [DAA; 24 lg/(kg hr)]. A third group received only sham operation and vehicle infusion (Sham). 48 h prior to CLP all mice were given a permanent central i.v.-line and an arterial transmitter (PA-C10, St. Paul, MN, USA) to measure heart rate (HR) and mean arterial pressure (MAP). CLP was adjusted to survive 24 h. After 12 h hearts, livers and kidneys were fixed in formalin and embedded in paraffin. Immunohistochemical analysis of the paraffin sections was performed using the avidinbiotin-peroxidase complex (ABC) method. For analysis an anti-mouse ePCR antibody (clone 1560, NatuTec, Frankfurt, Germany) was used (dilution 1:100) after heat pretreatment. Anti-ePCR positive cells were counted in 10 fields in light microscopy (original magnification: 62.5) of each tissue and the average was recorded. Data are presented as mean ± SD. *p \ 0.05 was considered significant. RESULTS. There were no significant differences in HR between the groups (Sham 650 ± 38 per min; DAA 547 ± 175 per min; control 530 ± 143/min). MAP was significantly higher in sham group (137 ± 15 mmHg; p = 0.031) and non-significantly higher in DAA group (111 ± 26 mmHg) when compared to control (97 ± 4 mmHg). Anti-ePCR positive cell count in heart tissue was significantly higher in sham-treated mice (6.3 ± 0.9 cells; p \ 0.001) and DAA mice (6.0 ± 3.9 cells, p = 0.007) compared to controls (1.8 ± 1.3 cells). In kidney tissue ePCR positive cells were significantly more in sham group (9.5 ± 4.0; p = 0.036) compared to control, but not in DAA group (6.8 ± 2.5). Liver samples showed no significant differences (Sham 8.0 ± 2.3; DAA 7.2 ± 3.8; control 6.3 ± 5.1). CONCLUSION. Our data showed higher amounts of ePCR in murine sepsis undergoing DAA therapy in heart and kidney tissues, but not in the liver when compared with control animals. This suggests that DAA provides different effects in early experimental sepsis. BACKGROUND. Caspofungin treatment is often initiated in hypovolemic shock patients, what could affect its pharmacokinetics and efficacy. The present study investigated the influence of hypovolemic shock and fluid loading on the plasma pharmacokinetic parameters and the pulmonary penetration of caspofungin in a pig model. After anesthesia and mechanical ventilation, 8 pigs (40 ± 3 kg) were bled to induce a 2-h deep shock and resuscitated for 2 h using normal saline based on hemodynamic goals. A 1-h perfusion of 70 mg caspofungin was started at the beginning of the resuscitation period. Lungs were removed 6 h after the initiation of hemorrhage. Sixteen animals were used as controls without hemorrhage. Caspofungin concentrations were measured using high performance liquid chromatography method. In the shock group, the volume of removed blood was 39 ± 7 ml/kg and a volume of 90 ± 17 ml/kg of saline was infused through the resuscitation period. CONCLUSION. Hypovolemic shock followed by fluid loading in pig results in a significant decrease in plasma caspofungin exposition. It resulted in a decrease in the pulmonary concentration of caspofungin without affecting its diffusion to the lung. Future investigations should focus on the interest for monitoring of plasma caspofungin concentrations in ICU patients and on optimal dosing in these patients. OBJECTIVES. The present study was designed to assess the effects of MPs from septic origin on systemic hemodynamics as well as on the inflammatory, oxidative and nitrosative stresses. METHODS. Forty healthy rats were randomly allocated to three groups: 10 animals inoculated with MPs isolated from control rats (cMPs), 15 animals inoculated with MPs isolated from sham rats (shMPs) and 15 animals inoculated with MPs isolated from rats with peritonitis (sMPs). Rats were anesthetized, mechanically ventilated and were infused with the same amount of cMPs or shMPs or sMPs. We measured heart rate (HR), mean arterial pressure (MAP), carotid artery blood flow (CBF) and portal vein blood flow (PBF). Hemodynamic parameters were recorded during 7 h, and then animals were sacrificed. Aorta and heart were harvested for further in vitro tissue analyzes. 1. The cellular origin (phenotype) but not the circulating concentration of MPs was different in septic rats, characterized particularly by a significant increase in leukocyte derived MPs. 2. sMPs but not cMPs or shMPs decreased mean arterial pressure without any effect on carotid artery and portal vein blood flows. All rats survived in the cMPs and shMPs groups whereas three rats died before the end of the experiment in the sMPs group. 3. Rats inoculated with sMPs exhibited an increase in superoxide ion production and NF-kB activity, over-expression of iNOs with subsequent NO overproduction and decrease in eNOs activation. Pulse blood pressure recordings CONCLUSIONS. Rats with sepsis induced by peritonitis exhibited a specific phenotype of MPs which could play a detrimental hemodynamic effect as a systemic vasodilatation. Inoculation of sMPs in healthy rats decreased MAP likely by up-regulating NF-kB activity with subsequent iNOS, NO and superoxide anion overproduction. These data confirm a proinflammatory detrimental role of MPs in the vascular pathophysiology of septic shock. INTRODUCTION. Heat shock proteins (HSPs) play an active part in modulating intracellular responses to stress. In the classical model for their activation de-repression of heat shock transcription factor 1(HSF1) occurs as a result of the titration of HSPs away from HSF1 by misfolded proteins [1] . However, HSPs may change in many diseases without any changes in the levels of denatured proteins [2] . OBJECTIVE. We propose that HSPs are activated, in part, by a membrane dependent calcium channel receptor, possibly transient receptor potential vanilloid type-1 (TRPV1). Capsaicin, a known inducer of TRPV1, and Capsazepine, a selective antagonist, were used on different mammalian epithelial cell lines. Cells were pre-treated with micromolar concentrations of Capsaicin or heat shock (HS) followed by treatment with Capsazepine. RESULTS. Capsaicin or HS induced HSF1 activation and the consequent accumulation of Hsp70, 90 and 25 chaperones. Pre-treatment with Capsazepine prior to HS or Capsaicin abolished the heat shock response (HSR). Capsazepine treatment prevented Capsaicininduced stabilization of IkB and cell to cell adhesion and induced apoptosis. Capsazepinemediated blockage of the heat shock response was reproduced with EGTA. Moreover, treatment with TRPV1 siRNA resulted in a similar response to Capsazepine. CONCLUSION. HSR-sensing and signaling in mammalian cells depends, in part, on the transient entry of calcium by way of membrane dependent calcium channel receptor. These HSR modulators may hold promise in treating inflammation in the future. INTRODUCTION. Hydrogen sulphide gas, or its intravenous donor-sodium hydrogen sulphide (NaHS), are promising therapeutic agents in ischaemia-reperfusion and haemorrhagic shock [1] . We studied NaHS in a short-term endotoxaemia model as relatively little is known about its effects during sepsis. METHODS. Under isoflurane anaesthesia, male Wistar rats (approx 280 g weight) underwent left common carotid and right jugular venous cannulation for blood sampling/continuous BP monitoring and fluid administration, respectively. Animals were kept normothermic on a heating mat. Tissue oxygen tension (tPO 2 ) was monitored using Oxylite probes (Oxford Optronix, Oxford UK) placed in thigh muscle. After a 30-min stabilization period, fluidresuscitated rats [10 ml/(kg h)] were subjected to iv LPS (20 mg/kg over 15 min). Comparisons were made against animals receiving NaHS (0.2 mg/kg bolus given immediately after LPS, followed by a 2 mg/(kg h) infusion). Echocardiography (Vivid 7, GE Healthcare, Bedford) and blood gas analysis were sequentially performed. Sham-operated, non-septic animals also received NaHS (n = 5) or placebo (n = 7). At the doses given, NaHS had no effect on either sham-operated animals (data not shown), nor on the endotoxic rats (Table 1) . Data shown as mean (±SE). Timepoints chosen reflect the biphasic response to endotoxin: 0 = baseline, 15 = initial hypotensive phase, 120 = maximal recovery, 240 = end of experiment. CONCLUSION. NaHS does not improve haemodynamics, tissue oxygenation nor shockrelated biochemical parameters in a severe model of fluid-resuscitated endotoxaemia. We will further investigate the effects of dose and time of therapeutic intervention in this model, in addition to testing it in a long-term septic model.  Intestinal endothelial and epithelial barrier dysfunction remain severe clinical problems as they may contribute to the development of sepsis and multiorgan failure. We have recently established an isolated rat small intestine model with access to vasculature, lumen and lymphatics for study of inflammatory changes in fluid balance [1] stable for 140 min, rendering it less suitable for examination of changes in gene and protein expression profile. The aim of this study was to assess the long term functional and metabolic stability of this model. Adult female Wistar rats were anaesthetized, small intestines cannulated and perfused vascularly (7.5 ml/min) and luminally (0.15 ml/min) and placed in a warm humidified chamber for up to 6 h. Arterial, venous and luminal pressures as well as venous, luminal and lymphatic effluent flows and intestinal weight were recorded continuously. As measures of metabolic integrity, oxygen consumption, lactate/pyruvate ratio and galactose uptake from luminally administered lactose were analysed every 30 min. Structural and barrier integrity were assessed as histostability score (mesenteric and antimesenteric fraction of fully epitheliated villi), wet/dry weight ratio and translocation of vascularly applied FITC albumin to lumen and lymphatics. Data were compared using paired t tests. 34 ± 0.03/0.29 ± 0.04 ml/(min g) dry weight (**)) as well as galactose uptake (0.24 ± 0.07/0.25 ± 0.07 mg/(min g) dry weight (n.s.)) were very stable with time pointing towards high metabolic stability. During the whole experiment, luminal effluent flow was slightly lower than applied (0.13 ± 0.01 ml/min, 240 min) resulting in net liquid absorption over the whole time period (0.022 ± 0.018/ 0.017 ± 0.012 ml/min (n.s.)), and lymph production stayed in the physiologic range (0.014 ± 0.010/0.035 ± 0.039 ml/min (n.s.)). The organ weight did not change with time which, together with the balanced luminal fluid flow and end experimental wet/dry weight ratio of 4.38 ± 0.17 (compared to 3.97 ± 0.08 at the beginning of the experiment (**)), indicate absence of edema. Minimal leakage of vascular FITC albumin to the lumen (0.4 ± 0.3%) and a histostability score of 0.97 ± 0.04 show integrity of the vascular-luminal barrier until the end of the experiment. The isolated small intestine model presented earlier [1] displays excellent long term physiologic, metabolic and histologic stability and opens up a wide field of applications including inflammatory gene transcription and protein expression. INTRODUCTION. Mitochondria play a major role during ischemia-reperfusion as well on cytotoxic pathways as protective such as ischemic preconditioning. The aim of this study is a better understanding of the mitochondrial pathophysiologic response to several oxygen regimens in an isolated mitochondria model. Mitochondria were isolated from rat heart. Enriched mitochondrial pellets were conditioned in presence of glutamate (5 mM) and malate (2 mM) inside the oxygraph chamber during 15 min. Oxygen partial pressures were: 155 mmHg for control group; 0 to 4 mmHg for hypoxia group and 0 mmHg for anoxia group. Then, after a 5 min oxygenation period, several measurements were realized: oxygen consumption (VO 2 ) were measured with or without ADP (5 mM) (state 3 and 4 of mitochondrial respiration); calcium retention capacity (CRC); mitochondrial membrane potentiel (Dwm). To explore the involvement of reactive oxygen species (ROS), mitochondrial VO 2 were measured in presence of a specific mitochondrial antioxidant drugs (XBJ). All results were expressed in percent of variation in comparison to control group [median (minimum-maximum)]. The different groups were analyzed using a Kruskal-Wallis, a Mann-Whitney with a Bonferroni correction or a Sign test when necessary.  After hypoxia and reoxygenation the mitochondrial function was altered. This impairment of mitochondrial function was not found after anoxia and reoxygenation. This difference in mitochondrial function between hypoxia and anoxia suggests the involvement of ROS. This hypothesis was confirmed by the effect of the antioxidant XBJ that reestablished after hypoxia the same level of VO 2 than after anoxia. [1] . Superoxide dismutase (SOD) catalyses the dismutation of superoxide oxygen free radicals to oxygen and hydrogen peroxide (H 2 O 2 ). The therapeutic potential of exogenous SOD administration in ARDS is evidenced by demonstrations of efficacy in acute lung injury models [2] . Anti-oxidant defenses, particularly the extracellular SOD isoform, Extracellular SOD (EC-SOD), are downregulated by endotoxin [3] . We proposed that EC-SOD delivered via a novel viral vector would ameliorate lung injury caused by lipo-polysaccharide (LPS) pulmonary instillation. METHODS. Three groups with nine rats per group were randomised to receive either adenoassociated virus expressing EC-SOD (AAV-EC-SOD), adeno-associated virus coding for no product (AAV-NULL), or vehicle control, 5 days prior to planned LPS instillation. A model of lipo-polysaccharide (LPS) induced acute lung injury by pulmonary instillation was established in male Sprague Dawley rats. Twenty-four hours following LPS delivery, animals were anaesthetized and mechanically ventilated and their baseline compliance and oxygenation recorded. There was a statistically significant improvement in the oxygenation of animals recieving AAV-EC SOD as compared to AAV-NULL or vehicle control (mean PaO 2 = 14.348 vs. 9.756 and 8.679, respectively). There was a significant increase in amount of EC-SOD as determined by real time PCR in the group who were administered AAV-EC SOD. No significant differences in static compliance or bronchoalveolar lavage cells counted were noted. CONCLUSION. AAV delivered ECSOD is protective in a animal model of LPS induced acute lung injury. The down regulation of the EC SOD system seen in the systemic inflammatory response [3] and its subsequent replacement exogenously may explain our findings. Further work will focus on other components of cellular anti-oxidant pathways and confirmation of down regulation of EC SOD in our injury model. AIMS. The endothelial specific angiopoietin (Ang)-Tie2 ligand-receptor system has been identified as a non-redundant mediator of endothelial activation in experimental sepsis. Binding of circulating Ang-1 to the Tie2 receptor physiologically protects the vasculature from leakage, whereas binding of Ang-2 antagonizes Tie2 signaling and disrupts endothelial barrier function. We tested whether administration of exogenous recombinant Ang-1 improves survival and attenuates multi organ failure in a lethal murine sepsis model. To induce septic acute kidney injury and to evaluate survival time cecal ligation and puncture (CLP) was performed in twenty SV129 mice. Half of the mice received an intravenous application of recombinant human Ang-1 (50 lg) immediately before CLP and every 8 h thereafter. In the other half, saline was administered in the same fashion. For tissue assessment (western blot, immunohistological) CLP was induced in 5 versus 5 (Ang-1 vs. saline) additional mice; animals were sacrificed after 24 h. Laparotomy served as SHAM control (n = 5). Further, a panel of cytokines has been assessed with a cytometric bead array (CBA) system after 24 h. 23.1 ± 3.6 mmol/L, p \ 0.01) were lower in Ang-1 treated septic mice compared to controls. Similar results were obtained at 16 h after CLP. Renal tissue revealed that saline treated mice exhibit a marked loss of expression of vascular endothelial (VE)-cadherin, a major component of endothelial adherens junctions. In contrast, loss of VE-cadherin expression was prevented by Ang-1 (pre-) treatment (WB densitometry: Ang-1: 0.82 ± 0.2; Saline: 0.5 ± 0.1; p = 0.05). However, contrary to previous reports, intravenous injection of exogenous Ang-1enhanced not only the expression of adhesion molecules (ICAM-1, VCAM-1) in renal vasculature, but also circulating cytokine levels (TNFa, MCP-1, IL-6, IL-12). CONCLUSIONS. Our study demonstrates that administration of exogenous recombinant Ang-1 improves survival time in a lethal experimental sepsis model. Enhanced survival was accompanied by an improvement in microcirculatory function, probably via stabilization of adherens junctions. However, Ang-1 injection deteriorated expression of vascular adhesion molecules and raised plasma cytokine levels. Although Ang-1 may have utility as an adjunctive agent for the treatment of septic multi-organ failure, additional dose-finding and efficacy studies are required.  adaptive immune responses to infection. In contrast to neutrophils, macrophages or lymphocytes, there are virtually no data on the time course of circulating DCs in septic shock (SS). Using a novel specific and sensitive assay, we analyzed the evolution of circulating myeloid (mDCs) and plasmacytoid (pDCs) DCs in SS. We enrolled immunocompetent adult patients with SS (n = 43), shock from other etiologies (NSS, n = 29) and with sepsis without organ dysfunction (S, n = 15). 16 age-matched healthy controls (HC) served as reference for mDCs and pDCs. Blood samples (200 lL) were drawn on the day of shock, then after 3 and 7 days. DCs were counted using the DC-labelling kit Trucount Ò assay (BD Biosciences). CD11c? CD123-(mDC) and CD11c-CD123? (pDC) cells were selected by flow cytometry (FACSCanto TM , BD Biosciences). HLA-DR mean fluorescence index (MFI) was measured. Age, sex ratio, SAPS II, SOFA score, nosocomial infection (NI) and mortality rates did not statistically differ between SS and NSS pts. At day 1, mDCs and pDCs counts were significantly lower in SS and NSS pts as compared to HC and S ( Fig. 1 ). Pts with SS had significantly lower mDCs and pDC counts than NSS at days 1 and 3. HLA-DR MFI of mDCs and pDCs was lower in SS pts compared to HC (p = 0.005 and 0.037, respectively). Interestingly, 10 of the 43 SS pts developed NI after a median time of 9 (7.5-11) days in the ICU. Whereas mDCs increased in pts without NI, mDCs counts remained low at day 7 in pts who developed NI: mDCs counts and their relative variation between day 1 and 7 were significantly lower in pts who developed NI than in those who did not (p \ 0.05). Logistic regression analysis indicate that a negative mDCs relative variation is associated with an increased risk of nosocomial infection with an OR 22 (2.53-191) (p = 0.005). Figure   CONCLUSION . SS is associated with quantitative and qualitative abnormalities of circulating mDCs and pDCs as early as day 1, independently of the haemodynamic injury. The persistence of low counts of mDCs after SS is associated with the advent of nosocomial infection during the ICU stay, suggesting that DCs play a role in the development of sepsisinduced immunosupression. INTRODUCTION. Liver dysfunction is common in sepsis but its mechanisms are unclear. The aim of the study was to evaluate the effects of LPS on cultured primary human hepatocyte respiration over time. METHODS. Human hepatocytes were isolated and cultivated from human liver resection specimens. Cultivated cells were exposed to LPS (1 lg/ml) for 4, 8 and 16 h. After incubation, cells were trypsinized and respiration rates were measured using a high-resolution oxygraph (Oxygraph-2 k, Oroboros Instruments, Innsbruck, Austria). Glutamate ? malate (G ? M), succinate (S) or ascorbate/TMPD (A/T) were used as substrates to test the function of complex I, II and IV, respectively. Human hepatocyte mitochondrial function in the cells treated with LPS for 8 h exhibited a significant reduction in the maximal complex II-dependent mitochondrial respiration [control: 464 ± 142 vs. LPS: 406 ± 163 pmol/(s 9 million cells) ( Table 1) ]. After 4 and 16 h of LPS incubation no significant reduction in cellular respiration was observed (4 and 16 h: n = 5 and 8 h: n = 4). Statistics: paired t test, *p = 0.028 control vs. LPS (8 h incubation). INTRODUCTION. Acute kidney injury (AKI) in critically ill patients is a frequent clinical problem and a rising incidence has been reported over the past several years. Recently two consensus definition for AKI have been developed: RIFLE [1] in 2004 by the acute dialysis quality initiative workgroup (second conference) and AKIN [2] in 2007. Insofar AKIN and RIFLE criteria have been applied in large retrospective studies, limited to the initial days of ICU. NEFROINT is an Italian initiative for an observational prospective multicenter study to evaluate epidemiology of AKI in Italian ICUs employing RIFLE and AKIN classifications. A pilot study has been performed in one of the centers enrolled. OBJECTIVES. Primary endpoints of NEFROINT are: application and comparison of RIFLE and AKIN criteria for AKI definition in a prospective observational study; estimate, along such criteria, of AKI incidence in critically ill patients; correlation of AKI stages with prognosis. METHOD. An observational prospective multicenter study has been designed, in Italian adult ICUs (medical and surgical). All incident ICU patients have been enrolled over a 6 month period. Exclusion criteria was age \15 years, or ICU stay \24 h. Data collection about patients was performed on a web-based electronic case report form. Data included ICU admission diagnosis, daily urine output (3 h interval), daily laboratory data. Sepsis events diagnosed on clinical and/or microbiological basis where as well marked for each patient. Severity scores have been calculated at admission and daily. AKI patients had higher severity of illness scores and higher serum creatinine values on admission. They also were older and more likely to have a respiratory diagnosis as reason for ICU admission. CONCLUSIONS. NEFROINT is an initiative aimed at comparing RIFLE and AKIN scores to promote a uniform use of a single definition of AKI that will render subsequent studies comparable. Early AKI recognition could potentially allow implementation of timely corrective interventions, and hopefully prevent progression to more severe stages. AIM. Sepsis and septic shock remain the most important causes of acute kidney injury (AKI) in critically ill patients and account for more than 50% of cases of acute renal failure (ARF) in intensive care units (ICU). Its mortality varies with the severity of sepsis from 21% to 57%. The aim of this preliminary study was to investigate the differences in the course and prognosis of AKI that was induced by community and hospital acquired sepsis. METHOD. Patients with sepsis induced AKI were included in the study. RIFLE criteria were used to define AKI. Clinical and laboratory characteristics of the patients were compared with student t test and chi square tests. RESULTS. Forty-one patients were included in the study and 24 of them had community acquired septic AKI (AKIc). Ninety percent of the patients received mechanical ventilation (MV). Etiologies of sepsis were mostly community acquired pneumonia and ventilator associated pneumonia. Age, gender, admission APACHE II scores and SOFA scores at the time of AKI diagnosis were similar across the groups (p [ 0.05). Hospital acquired septic AKI (AKIh) developed later when compared to community acquired septic AKI (10th and 3rd days of sepsis respectively, p 0.004). AKIh was significantly and more frequently associated with oliguria (73 vs. 35%, p 0.020), bacteremia (47 vs. 4%, p 0.001), nephrotoxic antibiotic usage (59 vs. 21%, p 0.013) and tend to progress more frequently to acute renal failure(63 vs. 18%, p 0.005) compared to AKIc. AKIc episodes were more frequently (74 vs. 41%, p 0.37) and rapidly (7 vs. 12 days, p 0.44) reversible. Mean blood pressure and ScvO 2 % were significantly lower and more vasopressor and steroid therapies were required during AKIh episodes compared to AKIc (p \ 0.05). While length of MV and mortality rates were similar, duration of hospitalization was significantly longer in the AKIh group (32 vs. 18 days, p 0.045). CONCLUSION. These results suggest that, AKIh has worse clinic and prognosis than the AKIc so further and larger studies are necessary to investigate the preventive and therapeutic approaches. INTRODUCTION. Severity-of-illness or organ dysfunction scores are inaccurate to predict outcomes in patients with acute kidney injury (AKI), even when specific AKI scores are used. In recent years, the third versions of simplified acute and physiology score (SAPS 3) [1] and of mortality probability model (MPM0-III) [2] scores were developed, and information on their use in patients with AKI is scarce. OBJECTIVES. To validate the use of SAPS 3 and MPM0-III at the start of renal replacement therapy (RRT) in patients with AKI. Prospective cohort study conducted in the ICUs of three tertiary-care hospitals. Data used to calculate the scores were collected at start of RRT. Discrimination was assessed by area under receiver operating characteristic (AROC) curves and calibration by Hosmer-Lemeshow goodness-of-fit test. A total of 244 consecutive patients were included between January 2007 and July 2008. The mean age was 69.5 ± 16.6 years. The main contributing factors for AKI were ischemia/shock (75%), sepsis (74%), contrast/nephrotoxins (33%), rhabdomyolysis (5%) and urinary tract obstruction (2%) (a patient could have more than one contributing factor). Eightnine (36%) patients received RRT on the first day of RRT and 155 (65%) thereafter; continuous RRT was used as first indication in 206 (84%) patients. The ICU and hospital mortality rates were 63 and 68%, respectively. The mean SAPS 3 score at the start of RRT was 70.0 ± 13.0 points. Both the standard equation of SAPS 3 and MPM0-III scores tended to underestimate mortality. Discrimination was better for SAPS 3 [AROC = 0.82 (95% CI, 0.76-0.88)] than for MPM0-III [AROC = 0.73 (95% CI, 0.66-0.80)], as was the calibration. However, mortality prediction and calibration improved when the customized equation of SAPS 3 for countries from Central and South America was used. In multivariate analyses, both higher prognostic scores and length of ICU stay prior to RRT were the main predictive factors for hospital mortality. CONCLUSIONS. The SAPS 3 score at the start of RRT was accurate in our cohort of patients and seems a promising instrument for predicting hospital mortality critically ill patients with AKI. OBJECTIVES. The aim of this study was to investigate the effect of HES administration on kidney function compared with other colloids or crystalloids. METHODS. Systematic review and meta-analysis of the effects of HES administration on kidney function. Inclusion criteria for the study were prospective randomized trials comparing HES to control with reporting on variables of kidney function. AIMS. During the initiation phase of experimental acute kidney injury (AKI), subtle but devastating changes, such as loss of brush borders, disruption of tubular cell polarity and cytoskeletal changes are detectable only to a certain extent by routine histologic methods. For this reason, subjective and moderate reproducible semi-quantitative scoring of tubular changes (e.g. vacuolization, detachment, cast formation, and necrosis) still remains the method of choice to quantify the extent of experimental AKI. Lectins are glycoproteins which are able to bind carbohydrate structures specifically. It has previously been shown that immunolabeling of the lectin phaseolus vulgaris erythroagglutinin (PHA-E) is highly specific to the brush border of proximal tubular epithelial cells of rats, mice, and humans. The aim of this study was to (1) develop a simple and fast lectin (PHA-E) based staining protocol (2) to objectively quantify, and (3) to analyze brush border loss in a murine model of septic AKI. METHODS. Septic AKI in mice (n = 10) was induced by cecal ligation and puncture (CLP). Animals were sacrificed 24 h after CLP.Sham operated (n = 5) and healthy animals (n = 5) served as controls. In order to specifically stain the tubular brush border, binding of biotinylated lectin PHA-E was visualized by the biotin-avidin-complex (ABC) glucose-oxidase (GO) method coupled to tetranitroblue tetrazolium (TNBT) in 1-lm paraffin sections of renal tissue. The mean brush border area of five randomly chosen, non-overlapping cortical highpower fields was analyzed by planimetric software. Lectin PHA-E staining was highly selective for brush border of proximal tubules (black colour). Virtually no staining was present in glomeroli and medulla. The xx software reliably identified lectin-positive areas, as confirmed by image overlay controls. We found a significant difference between sepsis induced AKI, sham operated animals, and healthy mice (CLP: 0.091 ± 0.019; SHAM: 0.141 ± 0.048; healthy controls: 0.266 ± 0.14 pixel ratio; p \ 0.001). Our findings with the PHA-E staining protocol correlated significantly with the conventional semi-quantitative scoring system (r = 0.67, p \ 0.01). CONCLUSION. The here presented lectin PHA-E staining method followed by computerassisted planimetric quantification of brush border area is a highly reproducible and objective tool to analyze early histological changes during septic AKI in mice.  When an imbalance between oxygen supply and demand exist, anaerobic respiration commences and a metabolic acidosis develops. Base excess and lactate have been used to identify a higher risk group of patients who should be admitted in ICU prior to development of multiple organ failure. And at a time when appropiated therapy may previne the decline to death. Acute kidney injury failure is a common complication in critically ill patients and it always difficult separate the acid base effects of critical illness per se from those of AKI. The aim of this study was to examine wheter values of base excess or lactate taken on admission of patients with AKI to a intensive care unit indicate prognosis and if wheter this can be used as screening tool for future intensive care admissions. We restropectively examinated data from 100 patients with AKI. To define the unique acid base characteristics of AKI patients, we used a control group. The matched group consisted of 80 ICU patients wihtout AKI matched for APACHE II score. The base excess and lactate were collected at admission and then at 24 h. A total of 180 patients were enrolled at study over a 10 month-period. There were no difference with respect age, sex and APACHE score between groups. The ICU survival rates were 72% to the AKI group and 78% to control group. The value of base excess with the best predictive prognosis ability was -9 mmol/l to the AKI group and-3.5 (p \ 0.001) to the matched group and the corresponding value for lactate was higher than 2.6 to both groups. The combination of these two markers on admission to the intensive care unit led to a sensitivity of 82% and specifity of 58% for mortality. CONCLUSION. Both base excess and lactate, or the combination of the two, can be used to predict 28 day mortality in patients admitted to the intensive care unit. In patients with AKI a different cut off of base excess should be used.These variables could be utilized to identify patients who have a higher risk for mortality to whom resources could be better directed. Nonthyroidal disease (NTD) is a common finding in patients who are critically ill or on dialysis or with cardiovascular disease. Its presence has been associated with inflamatory conditions. The aim of this study was to analyse the posible association of NTD with the development of acute kidney injury (AKI). Secondary targets where to estimate the incidence of NTD in a polyvalent ICU and observe the realationship between the levels of T3 and some inflamatory markers: C reactive protein (CRP), albumin and cortisol. During 7 months in 2008, after approval of the local Ethical Committee, we prospectively determined the following parameters in every patient admited to the ICU: T3, T4, TSH, serum creatinine (SCr), CRP, albumin and cortisol. After excluding patients who died or were discharged before 48 h, 107 patients were studied. The degree of AKI was calculated using the RIFLE scale. At admission the values of the analysed parameters were (mean ± SD): T3 1.63 ± 0.8 pg/ml; T4 1.13 ± 0.4 ng/dl; TSH 1.14 ± 1.5lIU/dl; SCr [1] . Its incidence (5-38%) is rising due to increasing numbers of CT scans and contrast studies conducted, and the higher prevalence of risk factors such as chronic renal impairment, diabetes mellitus and old age. Although usually selflimiting, CIN can be associated with a need for ongoing dialysis or increased mortality [2] . To highlight the problem of contrast induced nephropathy and the difficulties in interpreting the current evidence for possible prevention strategies. We present the case of a 75 year old man admitted to intensive care with acute pancreatitis. He underwent eight contrast-enhanced abdominal CT scans and received Nacetylcysteine (NAC) for all but one of these, after which he developed acute renal failure which did not recover. We also present a review of evidence for various proposed strategies. RESULTS. Several studies have examined possible renal protective strategies around contrast administration. Saline and bicarbonate have been shown to be beneficial when given pre-contrast [3, 4] . Theophylline has been shown in meta-analysis to have a significant beneficial effect, but heterogeneity of methodology between studies makes it difficult to clarify the degree of benefit achieved [5] . NAC has shown benefit in 8 of 22 trials. Twelve meta-analyses showed inconsistent results, with 7 showing NAC to be beneficial. None showed harm. We analysed the heterogeneity of methods, endpoints and patient groups that makes these studies difficult to compare. Critically ill patients may be considered at even greater risk of CIN. Only one study has specifically looked at this group. Strategies such as volume loading may be inappropriate in some patients and there may not be time for NAC for 24 h pre-contrast. We were unable to find specific guidelines for the prevention of CIN in critically ill patients. CONCLUSION. The evidence for strategies to prevent CIN specifically in critically ill patients is unclear. We review the current literature and propose renal protective strategies including hydration, NAC and theophylline for this patient group based on the evidence available. OBJECTIVES. The present study addresses the issue of how the different modes of RRT are currently used and performed. We conducted a prospective observational study in three Portuguese intensive care units (ICU). Patient demographics, type of RRT used and outcomes were collected. We studied 84 patients who were treated with RRT for RF, with a median age of 58 years and a SAPS-II score of 51.9 ± 15.9, a SOFA score of 9.8 ± 4.1 at admission; 59 patients (70.2%) were treated with continuous replacement therapy (CRRT), 14 patients (16.6%) with sustained low-efficiency dialysis (SLED)and 11 patients (13.2%) were initially treated with CRRT and latter with SLED. Using the RIFLE criteria for the stratification of acute renal dysfunction at the beginning of the RRT we observed: risk-2 (2.4%), injury-18 (21.4%), failure 52 (61.9%), Loss-1 (1.2%), ESRD-11 (13.1%). We used anticoagulation in almost all patients (83.3%). Among patients who received anticoagulation, heparin was the most common choice (71.4%), followed by low molecular weight heparin (18.6%), and by sodium citrate ( INTRODUCTION. In the intensive care unit (ICU), severe sepsis and multiple organ failure are frequently associated with renal failure. Continuous veno venous hemofiltration (CVVH), which is used as renal replacement therapy, also removes circulating inflammatory mediators. Standard CVVH is currently prescribed with a substitution flow of 35 ml/(kg min). Theoretically, when hemofiltration is performed with higher volumes, buffer balance will be restored more rapidly, while also more inflammatory mediators will be removed. This may result in faster stabilisation from septic shock. Indeed, animal-and some human studies show promising results, but have several (methodical) limitations. To evaluate hemodynamic and metabolic changes during HV-CVVH in patients with septic shock in comparison to (standard) CVVH. We performed a retrospective, observational, single-center study. All patients admitted with septic shock who were treated with CVVH in the period 2005 until 2008 were included. CVVH was defined as a substitution-flow B3,000 ml/h, HV-CVVH as[3,000 ml/h. The decision to start with LV-CVVH or HV-CVVH was made by the attending ICU-physician on an intention-to-treat basis. Statistical analyses were performed with SPSS 13.0 INTRODUCTION. Haemostatic changes in critically ill patients are complex due to simultaneous pro-and anticoagulant processes. Routine PTT and aPTT assays monitoring clot formation poorly reflect hypo-or hypercoagulant state, especially during anticoagulation. endogenous thrombin potential (ETP) comprises an in-vitro system for measuring thrombin generation beyond clot formation and may be more informative. OBJECTIVE. To assess whether ETP has a role in monitoring systemic anticoagulation and predicting circuit clotting in critically ill patients receiving CVVH. METHODS. In a prospective study in an 18-bed general ICU, we included 14 patients with acute renal failure (ARF) requiring CVVH (postdilution, 2-4 L/u). Patients received a bolus of 2,850 IU of nadroparin followed by 380 IU/h. Samples of arterial and postfilter blood were taken at baseline and 1, 6, 12 and 24 h after start of CVVH to measure aPTT, PTT, anti-Xa and ETP. We compared patients with early circuit clotting (circuit life £ lower quartile) and those with normal circuit life. Median baseline arterial ETP-area under the curve (AUC) was 277 mA (IQR 175-385 mA) (normal values 346-520 mA). Baseline ETP-AUC was positively related to antithrombin and inversely to PTT, aPTT, anti-Xa (p \ 0.01) and SOFA score (p = 0.001). Median circuit life was 24.5 h (IQR 12-37 h). At baseline, the four patients with early filter clotting (£12 h) had prolonged PTT and aPTT, higher SOFA score and a tendency to lower ETP (Table 1) . During CVVH and nadroparin infusion, arterial and postfilter PTT and aPTT were prolonged (p \ 0.001), antiXa lower (p = 0.003) and ETP-maximal concentration (cmax) lower (p \ 0.004) when circuits clotted early. While arterial ETP-AUC tended to be lower (p = 0.08), postfilter ETP-AUC was not different between groups. In critically ill patients with ARF requiring CVVH with nadroparin anticoagulation, baseline ETP is lower than normal and inversely related to organ failure and (a)PTT, probably reflecting consumption of coagulation factors. Within the CVVH circuit, ETP-AUC and anti-Xa show opposing patterns. The concurrence of early filter clotting with prolonged (a)PTT, lower antiXa, lower ETP and higher SOFA score emphasizes the role of severity of disease and associated coagulation activation and heparin resistance in circuit clotting. INTRODUCTION. Nadroparin is a low-molecular-weight heparin (LMWH) used to prevent clotting in the extracorporeal circuit during CVVH. In renal failure LMWH accumulates and is associated with more bleeding (ref) . Whether nadroparin is removed by hemofiltration and whether the anticoagulant activity accumulates during continuous infusion is controversial. OBJECTIVE. To study the kinetics and removal of anti-Xa activity during continuous infusion of nadroparin in patients requiring CVVH using a cellulose tri-acetate filter. METHODS. In a randomized crossover trial in an 18-bed general ICU, patients with acute renal failure (ARF) were randomized. In group 1, postdilution CVVH was initiated at filtrate flow of 4 L/h (blood flow (BF) 220 ml/min), which was converted to 2 L/h (BF150 ml/min) after 60 min; in group 2, 2 L/h was converted to 4 L/h. Patients (\100 kg) received a bolus of 2,850 IU nadoparin followed by 380 IU/h. Samples of arterial blood, postfilter blood and ultrafiltrate were taken at baseline, 1 h after the start and 15 min, 6, 12 and 24 h after the conversion to measure anti-Xa activity. RESULTS. Fourteen patients with ARF were equally randomized. Patients in group 1 had higher median SOFA scores (14 vs. 9, p = 0.004), baseline coagulation markers were not significantly different. Arterial and postfilter anti-Xa values are presented in Fig. 1 . During CVVH arterial anti-Xa tended to decrease in time (p = 0.05). The median ratio of postfilter to arterial anti-Xa was 1.7 (IQR 1.4 to 2.1). There were large differences between patients; differences between groups were not significant, except for postfilter anti-Xa at 6 h, which was significantly higher in group 2 (4 L/h) (p = 0.02) . Anti-Xa activity was not detectable in the ultrafiltrate. CONCLUSIONS. Critically ill patients receiving nadroparin during CVVH showed no signs of accumulation of anticoagulant activity, although extracorporeal removal of anticoagulant activity could not be demonstrated. Apparantly, nadroparin is cleared by these patients despite renal failure. The differences in anti-Xa between patients may be related to severity of disease. INTRODUCTION. Unfractionated heparin (UFH) is used as the first-line agent for anticoagulation of the extracorporeal circuit during continuous renal replacement therapy (CRRT) in 96% of ICUs in the UK (UK) [1] . Its use is monitored with serial measurements of activated partial thromboplastin time (APTT) or its ratio (APTTR) in 83% of ICUs [1] . There is, however, considerable variation in practice [1] . Anticoagulation is useful for prolonging haemofilter life and facilitates the provision of continuous therapy, but must be balanced against the risk of haemorrhage, which has been correlated with increasing APTTR [2] . Most ICUs in the UK use an APTTR target of 1.5-2.5 [1] , despite recent guidance that a target range of 1.0-1.4 provides adequate filter life with less risk of bleeding [3] . OBJECTIVES. To investigate the adherence to our local target range for UFH therapy (APTTR 1.8-2.2) and the occurrence of over-anticoagulation in our patients. ]. There were 241 APTTRs (39%) which were above our target range, and 43 incidences (7%) where the APTTR was greater than or equal to 5.0. The APTTR was greater than 1.4 on 512 occasions (83%). CONCLUSIONS. This study was conducted in an ICU which delivers CRRT at a higher than average frequency [4] , and which consistently has a standardized mortality rate below the national average. Despite this, there was wide deviation from our target APTTR range and a considerable incidence of significant over-anticoagulation, which may place our patients at risk of haemorrhage. The vast majority of APTTRs were in excess of recent guidance [3] . Regional citrate anticoagulation (RCA) may provide longer filter life with a lower incidence of bleeding [3] . Its use is increasing worldwide [5] , though it is not commonly used in the UK [1] . We are investigating the possibility of introducing RCA in our ICU. In the meantime, we will set a lower APTTR target for our patients.  We prospectively studied patients who received CVVH from July 2005 to December 2008. Age, gender, admission diagnosis, and APACHE-II were obtained and the patients were divided into three groups: low dose heparin group, low molecular weight heparin group (LMWH), and no anticoagulation group (normal saline washing) based on assessment of coagulation status. For each circuit, circuit life, bleeding, platelet count, PT, INR, APTT, Creatinine and Urea were collected before and after CRRT. RESULTS. Seventy-seven critically ill patients with acute renal failure were treated with CRRT and 226 circuits were observed. Among these circuits, 50 received unfractionated heparin (UFH) anticoagulation, 78 received LMWH anticoagulation and 98 received no anticoagulation. The mean circuit life (44.6 ± 23.9 h) in low dose UFH group, was significantly longer than in LMWH (31.5 ± 21.3 h) and in no anticoagulation group (31.9 ± 20.8 h). There was no significant difference in baseline patient pre-CRRT HB, Creatinine and Urea among three groups. The INR and PT and APTT in baseline were significantly higher in no anticoagulation group compared to the other two groups (p \ 0.05). The Platelet count was significantly lower in the no anticoagulation group compared to UFH group and LMWH group in baseline and during CRRT. There was no significant difference in the filter PT, APTT, among the three groups during CRRT. The clearance of Creatinine and Urea during CRRT were no significant difference among the three groups. Bleeding complication secondary to CRRT were no significant difference among the three groups. OBJECTIVES. The purpose of the study was to assess the duration of time spent off therapy during the first five days of CRRT in post-traumatic ARF, and to identify the reasons for this. Ullevaal between 1 January 1997 and 31 December 2007, were retrospectively reviewed. The hospital is the regional trauma referral centre for approximately 1.93 million adult ([18 years) persons. According to the local treatment protocol, dialysis filters were routinely changed after 72 h due to time-out. Individuals were identified and data collected using several institutional registries. Patients were grouped according to presence of rhabdomyolysis based on peak serum creatine kinase levels exceeding 10,000 U/L or not. Categorical data were compared employing two-sided Pearson chi-square test, whereas continuous data were analyzed utilizing two-tailed Mann-Whitney U test. RESULTS. 39 patients were included during the study period. During the first five days of therapy there was a total of 162 dialysis days, and the total number of pauses was 131. The median duration of CRRT was 20.0 h per day, giving a downtime of 4.0 h per day. The number of pauses per day was significantly larger in patients with rhabdomyolysis compared to patients without rhabdomyolysis (71 pauses in 66 dialysis days vs. 60 pauses in 96 dialysis days, p \ 0.01). This resulted in a shorter duration of CRRT in rhabdomyolytic compared to non-rhabdomyolytic persons (18.5 vs. 22.0 h per day, p \ 0.01). Overall the reasons for pauses during CRRT were filter clotting (53%), therapeutic procedures (24%), catheter problems (11%), filter time-out (7%) and diagnostic examinations (5%). Patients with rhabdomyolysis had more pauses due to therapeutic procedures (32 vs. 15%, p = 0.02), whereas non-rhabdomyolytic persons had more pauses due to catheter problems (17 vs. 6%, p = 0.04) and filter time-out (13 vs. 1%, p \ 0.01). The number of pauses per day stayed relatively stable during the first five days of CRRT, but the reasons for pauses changed during the study period. CONCLUSIONS. This study indicates that trauma patients with rhabdomyolysis had more frequent dialysis pauses during the first days of CRRT than those without rhabdomyolysis, resulting in shorter duration of dialysis therapy. The reason for this was more frequent use of therapeutic procedures, i.e. surgery and radiological interventions, in rhabdomyolytic compared to non-rhabdomyolytic persons. GRANT ACKNOWLEDGEMENT. The author is supported by institutional grants. INTRODUCTION. Treatment of acute pancreatitis is aimed at correcting any underlying predisposing factor and at the pancreatic inflammation itself. Hypertriglyceridemia is an uncommon cause of pancreatitis. A serum triglyceride level of more then 1,000 to 2,000 mg/ dL is an identifiable risk factor. Interestingly, serum pancreatic enzyme levels may be normal or only minimally elevated in such cases. Severe necrotizing pancreatitis is associated with a high rate of complications and significant mortality. The reduction of triglyceride level to below 1,000 mg/dL effectively prevents further episodes of pancreatitis. This study aimed to determine the effectiveness of plasma exchange (PE) in reducing triglyceride levels during an acute attack of hyperlipidemic pancreatitis (HLP). METHODS. Prospective, observational study including six patients hospitalized with hyperlipemic pancreatitis treated with plasmapheresis between 2005 and 2008 in the medical ICU of a teaching hospital in Malaga. Demographic data, APACHE II score, organ support needed and prognosis were prospectively collected. A total of 6 hypertriglyceridemic patients with the complication of acute pancreatitis received one or two consecutive sessions. Mean age was 38 ± 11 years and mean APACHE II was 12 ± 4. ICU mortality was 33%. We performed 9 sessions. The development of multiorgan failure in patients with hyperlipemic necrotizing pancreatitis was associated with grave prognosis (33%), needed mechanical ventilation, vasoactive agent and renal replacement therapy. However, we had a good outcome in the majority (67%) with a effective reduction of triglycerides after the session of plasmapheresis (PE). Four of six patients (66%) recovered completely in a single session. Two patients developed intraabdominal abscess, requiring more than one consecutive session and surgical debridement of infected necrosis and died due to both septic shock and multi-organ failure. The respective mean removal rates during a single PE for triglyceride were 76%. CONCLUSIONS. The best treatment of hypertriglyceridemic PA is a drastic reduction of TG-s to normal. Experiences with plasmapheresis are limited. We report six patients of hypertriglyceridemic necrotizing pancreatitis with mildly elevated amylase and lipase, treated successfully with plasmapheresis. In summary, PE treatment is an effective method to clear lipids and enzymes from plasma in a single session for most HLP patients. The presence of multisystem organ failure appears to be a more important indicator of outcome than does the presence of infection. RESULTS. Sixteen (61%) patients were female and ten (39%) were male. The median age was 42 years old. The median APACHE II score was 16.5. Mechanical ventilation (57%), vasoactive agents (42%) and renal replacement therapy (34%) were the most common forms of organ support needed. 71 sessions of plasmapheresis were performed. 10 (38%) patients had been diagnosed with thrombotic thrombocytopenic purpura (TTP), six (23%) patients had hyperlipemic pancreatitis, five (19%) patients had pulmonary-renal syndrome (PRS), three (11%) patients had Guillain-Barré syndrome (GBS) and two (7%) had myasthenia gravis. We obtained a decreased in the values of APACHE II score following the plasmapheresis performed. There were six death (23% mortality) due of the severity of the disease. The number of complications were minimal and commonly described in the literature and there was a low mortality as a result. CONCLUSION. Results indicate that the performance of plasmapheresis was on a heterogeneous sample of patients with neuroimmunological diseases, rheumatology diseases and hyperlipemic pancreatitis. We conclude that plasmapheresis is a safe treatment which can be made by the staff trained in intensive care in any moment with a wide spectrum of clinical indications and with a minimum adverse effect. The aim of the study is to evaluate that early treatment of septic shock with CPFA may improve patient outcome. METHODS. Twenty septic patients who were admitted to the ICU have been enrolled in this study. CPFA treatment was performed immediately after septic shock was diagnosed (early group 6 h after diagnosis). Every patient had 3-4 CPFA treatments for 8 h with Q blood = 220 ml/h, Q ultrafiltration = 30 ml/(kg h) and Q plasma = 20% of Q blood. We measured the plasma concentration of procalcytonin (PCT), blood lactic acid levels, CRP, serum creatynine, WBC and PaO 2 /FiO 2 ratio. The APACHE II score, hemodynamic parameters, norepinephrine dosage were evaluated before CPFA (T 0 ), T 1 (after first cycle), T 2 (after second), T 3 (after third cycle) and T 72 (after 72 h). INTRODUCTION. The development of electrolyte disturbances in intensive care patients could be prevented by the use of better adapted dialysis fluids. A common problem is hypophosphatemia which has been shown to occur in up to 80% of the patients. Correction by intravenous phosphate supplementation is known to improve respiratory muscles, cardiac index, oxygen delivery to tissues and insulin resistance. Lately it has been reported that phosphate can be added directly to the dialysis fluid. This facilitates phosphate handling, but there is a risk of precipitation with calcium. An additional problem is that the amount of phosphate required to correct total body deficit varies and repeated serum measurements are needed to establish phosphate insufficiency. The process is time consuming and leads to treatment delay and excessive cost. OBJECTIVES. This study evaluated the possibility to achieve and maintain normal phosphate balance over time by using a new phosphate-containing dialysis fluid. OBJECTIVE. The purpose of this study was to evaluate the impact of different dialysate and replacement flows in the acid-base balance of the blood. Furthermore we tried to assess the way partial pressure of oxygen (PO 2 ) in the blood is affected by high flow CRRT. METHODS. This was a prospective observational study. Thirty consecutive critically ill patients that were admitted in our ICU and required CRRT during their course were enrolled in the study. For each patient, blood flow, dialysate and replacement flow as well as ultrafiltration adjustments were performed by the responsible intensivist. Any time that the clinical condition required a modification in any of these parameters, and after a period of time of no less than 1 h, a simultaneous blood sample was drawn from both the arterial and the venous part of the circuit and the samples were analysed by a blood gas analyzer. Arterial and venus samples were then compared for differences in pH, PO 2 and PCO 2 concentration. RESULTS. In total we performed 113 measurements in 30 patients. Mean patient age was 62.1 years, mean APACHE II score was 18, mean ICU stay was 22 days and mean CRRT days was 6 days. Overall, pH in the venous line of the circuit was higher, PCO 2 was lower and PO 2 was lower as well compared to the respective values in the arterial line of the circuit, with no difference reaching a statistical significance. Concerning the blood flow, we observed that when using high hemodiafiltration flows the difference in oxygen partial pressure between the arterial and the venous line of the circuit was greater, but again it did not reach statistical significance. CONCLUSION. The use of CRRT may influence the PO 2 in the returning blood. Although we did not reach statistical significance in our study, there was a definite trend towards lower PO 2 in the venous line of the circuit when high flow CRRT was applied. INTRODUCTION. Renal failure (RF) is a common complication in critically ill patient and is associated with high mortality and has a separate independent effect on risk of death. The continuous renal replacement therapy (CRRT) is physiologically superior; however, there is lack of strong evidence to prove a clinical benefit. Hybrid therapies (SLED) that combine the benefits of intermittent haemodialysis and continuous therapies have emerged in the past few years. OBJECTIVES. The aim of this study was to assess what type of renal replacement therapy (RRT) used and relate them to severity of the illness and outcome We conducted a prospective observational study in three Portuguese intensive care units (ICU). Patient demographics, type of RRT used, SAPS II and SOFA score at admission and when we started the RRT and outcomes were collected. We studied 84 patients who were treated with RRT for RF, with a median age of 58 years and a median SAPS-II score of 52; 59 patients (70.2%) were treated with continuous replacement therapy (CRRT), 14 patients (16.6%) with sustained low-efficiency dialysis (SLED) and 11 patients (13.2%) were initially treated with CRRT and latter with SLED. AIM. Tetanus is traditionally treated with very high doses of diazepam and morphine. It often required prolonged periods of paralysis and was associated with very high mortality and prolonged periods of ventilation. Magnesium sulphate (MgSO 4 ), due to its effects on neuromuscular and autonomic system should be effective in controlling muscle rigidity, spasm and autonomic instability in patients affected with tetanus. We introduced an ICU protocol using MgSO 4 as first line treatment. We wanted to evaluate our patient outcome following the introduction of our protocol. We retrospectively analysed the effects of introduction of MgSO 4 in our intensive care for management of tetanus. AIM. Electrolyte disturbances were often seen in patients in intensive care unit (ICU). Hypomagnesemia is not enough described but can be contributed in ICU mortality. The aim of this study was to define the prevalence of hypomagnesemia in critically ill patients and to evaluate its relationship with duration of mechanical ventilation day, length of ICU stay and mortality. A prospective study was done on 60 patients with respiratory failure admitted to the ICU between 01.01.2008 and 01.07.2008. Total serum magnesium level, electrolyte levels, albumin, total protein, and lactate levels were evaluated at the admission. Patients demographic features, accompanying neurological and cardiac diseases, APACHE II score, duration of mechanical ventilation, and the length of ICU stay and mortality were recorded. At admission 27% of patients had hypomagnesemia. A positive correlation was found between serum magnesium and calcium level (p = 0.03), but there was no relationship between other laboratory tests. Also there was no relationship determined between hypomagnesemia and duration of mechanical ventilation, and the length of ICU stay and mortality (p [ 0.05). CONCLUSION. Electrolyte levels are important in critically ill patients. However routine monitoring of serum magnesium level is not necessary. So we should increase the case number and also evaluate the serum magnesium level with urine magnesium level to see the effects of hypomagnesemia.  METHOD. Medical records of COPD patients who underwent invasive mechanical ventilation (IMV) were reviewed. The patients' age, sex, body mass index (BMI), APACHE II scores at admission, previous diagnosis of hypothyroidism or hyperthyroidism, history of thyroid replacement therapy or antithyroid medications, and the serum thyroid stimulating hormone (TSH), free triiodothyronine (fT3), and free thyroxine (fT4) at admission were recorded. The primary outcome measure was prolonged MV (PMV), which was defined as dependence on MV for [7 days. The outcome and the relation between the serum thyroid levels were evaluated. RESULTS. Ninety-five COPD patients were included, 80% were male, with a mean age of 65.25 ± 11.3 years. BMI's of the patients were 29.62 ± 4.7 and the mean value of APACHE II score was 27.36 ± 10.36. Only two patients (2%) had a history of hypothyroidism. Two more patient were diagnosed hypothyroidism at admission and treated with thyroid medications. The patients treated with thyroid replacement therapy were liberated from MV successfully. 50 patients (52.6%) could not be weaned. Serum FT3 level (1.52 ± 0.10) of the patients, who could not be weaned, was statistically lower than other group who could be liberated (p = 0.034).However there was no statistical difference between serum FT4 and TSH levels and two groups. Hypothyroidism is an uncommon cause of ventilator dependent respiratory failure with an incidence of 3%, but it is treatable, so it should be considered in patients who can not be liberated.More prospective studies are also needed to evaluate the significance of hypothyroidism in patients with respiratory failure and failure to wean. Smoke inhalation injury represents an important prognostic factor in patients admitted in the hospital after smoke exposition. OBJECTIVES. We determined whether initial antithrombin (AT) levels help in diagnosis and prognosis of sepsis after smoke inhalation. Smoke inhalation was diagnosed according to classical clinical and laboratory findings in 34 patients admitted in the hospital with suspected inhalation after smoke exposition. AT levels, coagulation parameters (fibrinogen levels, prothrombin time (PT), activated partial thromboplastin time (aPTT) and liver function tests were determined on admission and correlated each other and with outcome of the patients. . Initial AT and fibrinogen levels were significantly lower in patients with severe smoke inhalation compared to control (p \ 0.05). Initial AT levels were lower in the ones who developed septic complications with disseminated intravascular coagulation (DIC) compared to those without DIC (p \ 0.05). Initial AT levels were significantly lower in patients who died as compared to survivors (p \ 0.05 INTRODUCTION. X-ray finding of pleural effusion is fairly common in ICUs. This may vary from mild to massive effusions and of different etiologies. Epidemiological and outcome data for this ICU problem are scarce in literature. The objective of this study was to find how common this finding is in our ICU, their respective etiologies and any bearing on ICU mortality. A single centre, prospective, observational study conducted in two mixed Medical and Surgical ICUs in Kolkata, India. Over six month period (October 2008 to March 2009) all consecutive patient admissions to these two ICUs were screened for a X-ray evidence of pleural effusion, either on admission or during their ICU stay. As per ICU protocol APACHE II scoring were done in all patients. Those with effusions were grouped according to etiology. Finally in ICU mortality were observed for those with or without an effusion. A total of 617 ICU admissions were studied. Among these 212 patients were found to have X-ray evidence of pleural effusion. Median APACHE II score was 19 (IQR 18-20) among the study population with predominant (86.8%) Medical admissions. Incidence of bilateral effusions were a total of 87 (41%). The common causes of pleural effusion include chronic kidney disease (n 91-42%), Heart failure (n 33-15%), Pneumonia (n 28-13%), post operative (n 23-10%), Chronic liver disease (n 13-6%) and rest others (e.g. trauma, pancreatitis, PTE, malignancy). The overall ICU mortality was 81 (38.2%) and 61 (15.1%) in groups with and without effusion respectively with a p value of \0.0001, showing number of deaths in pleural effusion group were significantly higher. Our study showed X-ray finding of pleural effusion quite common in ICU patient population even many a times being bilateral. In this small study the overall ICU mortality were also higher in pleural effusion group, but a wider multicentric study is needed. INTRODUCTION. Acute lung injury (ALI) is a clinical manifestation of respiratory failure caused by lung inflammation and the disruption of the alveolar-capillary barrier. To prevent alveolar edema, it is of critical importance to preserve the physical integrity of the alveolar epithelial monolayer which is regulated by the balance between centripetal forces arising from cytoskeletal tension and cell-cell and cell-matrix tethering forces [1] . Intercellular junctions, such as tight junctions are closely related to actin cytoskeleton-related barrier regulation. Proteins of the coagulation cascade such as Thrombin (THR)-that stiffens [2] and contracts [3] alveolar epithelial cells (AEC)-or Activated Protein C (APC)-an endothelial barrierprotective agent [4] -could modulate this balance of forces in the epithelial monolayer. To study the combined effects of THR and APC on the barrier integrity through the tight junction ZO-1 of AEC by western blotting and immunofluorescence. METHODS. AEC (A549) were incubated for 3 h with APC (50 lg/ml) or vehicle (control). Subsequently, THR (50 nM) or medium was added to the cell culture. For ZO-1 western blotting, cell lysates were first ultracentrifuged (100,000g, 30 min, 4°C) to obtain membrane and cytosol fractions. Then the samples were subjected to western blotting and the amount of ZO-1 fractions was calculated by densitometry. For ZO-1 immunofluorescence, AEC were grown on glass coverslips and fixed in 3.7% formaldehyde solution. ZO-1 antibody was used to localize the tight junction and the ZO-1 integrated optical intensity was then measured. . Treatment with APC did not induce significant changes in any ZO-1 amount of fraction protein analyzed by western blot. THR induced a *fivefold increase (543 ± 90% of control values) in ZO-1 membrane fraction while no changes were detected in ZO-1 cytoplasm protein content (97 ± 13% of control values). By contrast, APC concentration of 50 lg/ml showed a clear tendency to reduce the effects induced by THR on ZO-1 membrane fraction (209 ± 65% of control values). For ZO-1 inmunofluorescence, APC and THR treatments resulted in different patterns of ZO-1 in the cell-cell contacts. After THR challenge cells showed discontinuous staining of ZO-1 compared to untreated cells indicating a disruption of alveolar monolayer. CONCLUSIONS. The increase in ZO-1 amount of membrane fraction after THR challenge lends support to a protective mechanism avoiding cell-cell contacts disruption. Treatment with APC reduced the increased ZO-1 amount of membrane protein induced by THR suggesting an improvement of the barrier integrity in this model. (2001) Interleukin-18(IL-18) is said to be involved in organ injury. We investigated the IL-18 values of septic acute lung injury (ALI) and acute respiratory distress syndrome (ARDS) patients. The subjects were 38 patients during the 3-year period from 2004 to 2007 from whom it was possible to collect a blood specimen within approximately 6 h of the onset of septic ALI or ARDS. Their mean age was 67 years, and their mean APACHE II score was 29. Their SOFA score was 13, and their mean PaO 2 /FiO 2 (P/F) ratio was 170. The P/F ratio was 246 in the ALI group and 135 in the ARDS group. There were 4 cases (10.5%) in the 28-day mortality group, and 6 cases (15.8%) in the 90-day mortality group. The value of IL-18 in died group was significantly higher than in survived group (1,649 ± 1,056 vs. 4,523 ± 2,798 pg/ml; p \ 0.05), and in the ARDS group also significantly higher than in ALI group (2,467 ± 1,880 vs. 1,314 ± 800 pg/ml; p \ 0.05). These results suggested that IL-18 may play an major role in progression of ARDS in respiratory disorder as multiple organ failure (MOF). [1] . It is well-known that the pathophysiological mechanisms and factors involved in the liberation of NO and the activation of inflammatory responses differ between AUD and non-AUD patients. OBJECTIVES. The main hypothesis of this study is that ARDS patients with AUD and non-AUD differ in their response to the application of evidence based algorithms with respect to NO response (AUD patients are more frequent non-responders). Patients with ARDS (meeting AECC criteria) were included in this ethically approved study. Patients with severe chronic lung fibrosis and/or bridging for lung transplant were not included. Patients were allocated to AUD and non-AUD patients. The AUDdetection was performed by the published algorithm [2] . Statistical analysis: Wilcoxon-Mann-Whitney and Chi-quadrat test was used. RESULTS. So far, 23 patients with ARDS were included. Prevalence of AUD was 52% in our ARDS patients. Baseline characteristics are given in Table 1 . Frequencies of NO nonresponse, extracorporeal lung support and mortality are given in Table 1 . Frequency of NO non-response was in tendency different: 67% in AUD patients versus 36% in non-AUD. Overall mortality was 50% in AUD patients versus 45% in non-AUD patients. INTRODUCTION. Acute lung injury (ALI) is a critical illness characterized by increased vascular permeability and impaired gas exchange leading to death in some cases. Inflammation plays a pivotal role in the induction and maintenance of ALI and is therefore therapeutic target to treat ALI. Rho, a small GTPase, is involved in the regulation of inflammation through the activation of recruitment of neutrophils to the site of inflammation and through activation of transcription factors such as NF-kB. We hypothesized that a Rho kinase (ROCK) inhibitor, Y-27632 may be beneficial to dampen the inflammatory response in ALI. Male SD rats were intravenously pre-treated with either saline or ROCK inhibitor (Y-27632, 5 mg/kg). ALI was induced by intratracheal instillation of 1 mg/kg E. coli lipopolysaccharide (LPS). Control rats received saline intratracheally. 24 h after the induction of ALI, lungs were harvested and analyzed for myeloperoxidase (MPO) activity and expression of the proteins IjB, iNOS and eNOS. Bronchoalveolar lavage fluid (BALf) was used to assess total protein concentration as a measure of vascular permeability. Pre-treatment with the ROCK-inhibitor resulted in significantly decreased levels of LPS-induced MPO expression and prevented the upregulation of both LPS-induced iNOS and eNOS expression. Furthermore, LPS-induced degradation of IkB was attenuated by pretreatment with Y-27632. Finally, Y-27632 improved vascular permeability by decreasing the LPS-induced protein concentration in the BALf. CONCLUSION. Inhibition of Rho-kinase decreases lung inflammation and vascular permeability in acute lung injury and may therefore be a good approach to treat patients suffering from ALI. We hypothesized that due to the cyclic changes of pulmonary air content there are PO 2 oscillations also in the mixed venous blood (PvO 2 ), potentially influencing PaO 2 oscillations. In each of three healthy pigs of 30 kg, anesthetized and ventilated with constant minute volume we studied three different tidal volume settings (5, 8 and 11 ml/kg) resulting in different respiratory rates. A calibrated oxygen probe (fiber optic, fluorescence-quenching probe, FOXY-AL300; Ocean Optics, Dunedin, FL, USA) was inserted into the pulmonary artery through a 4 Fr catheter. The catheter position was previously controlled by pressure tracing. PvO 2 was sampled with temperature compensation at 10 Hz with a multi frequency phase fluorometer (MFPF 100, Tau Theta, Fort Collins, CO, USA) after a generated timestamp to synchronize with the electric impedance tomography (EIT) signal (Goettingen GoeMF II, Viasys Healthcare, The Netherlands) sampled at 13 Hz. EIT and PvO 2 were simultaneously recorded for 3 min during each tidal volume setting and analysed with and without low pass filtering at the heart rate. We obtained PvO 2 oscillations with amplitudes between 3 to 10 mmHg with the main frequencies matching the respiratory rate. Ventilation with tidal volumes of 11 ml/kg provided higher PvO 2 amplitudes than ventilation with 5 ml/kg. These results are preliminary and the source of the measured PvO 2 oscillations is not clear. Alternate backflow from the superior and inferior vena cava due to changes in intrathoracic pressures during mechanical ventilation may be responsible for these oxygen partial pressure oscillations in the mixed venous blood. CONCLUSION. Mixed venous oxygen partial pressure oscillates in accordance to the respiratory rate. Whether arterial PO 2 oscillations are due to cyclic recruitment and derecruitment of the lung or to corresponding mixed venous oscillations remains to be evaluated. [2] and in neonates [3] . To our knowledge this is the first validation of the model using a large cohort of samples from intensive care patients. AIM. To assess the ability of the Severinghaus equations [1] to estimate values for pO 2 and SO 2 in critically ill adult patients. METHODS. 34,191 sequential blood gas samples were analysed to validate the Severinghaus oxygen dissociation curve, of these 14,228 measurements had a SO 2 B 96.5% and were included in subsequent analyses. Bland-Altman plots were used to examine the agreement between measured pO 2 and that calculated from the Severinghaus equations, and between measured and calculated SO 2 , both with and without correction for pH. The differences between measured and estimated values were analysed using paired t tests with a p value \ 0.05 considered significant. RESULTS. The Severinghaus oxygen dissociation model accurately reflects the relationship between pO 2 and SO 2 observed in clinical samples. There is reasonable agreement between the measured and calculated values for pO 2 and SO 2 , with the majority of values falling between the lines of 95% agreement. There was a statistically significant difference between observed and calculated values of pO 2 even when adjustment for pH was made (p \ 0.0001), however the mean difference between the groups was not clinical significant (5.4 mmHg when pH adjusted). There was also a statistical difference between measured and calculated values of SO 2 (p \ 0.001), again, however, this difference may not be considered clinically significant (1.6%). Patient data and Severinghaus oxygen dissociation CONCLUSIONS. The Severinghaus equations accurately reflect the oxygen dissociation curve in critically ill adult patients and whilst they provide values for pO 2 INTRODUCTION. Zinc (Zn) is an essential trace element, which plays a role in many biological functions including immune function. Development of respiratory infections and changes in respiratory tract cells may be affected by low Zn levels. In critically ill children mortality of septic shock and degree of organ dysfunction were associated to low blood Zn levels 1,2 . Our aim was to study serum Zn in the beginning of acute respiratory failure (ARF) and its association to development of organ failures and day 90 mortality. During an 8-week study period (from 16 April 2007 to 10 June 2007) 958 adult patients with ARF were treated in intensive care units (= FINNALI-cohort). After consent blood sample for Zn analysis was drawn at baseline). Samples were taken in Zn-free tubes, freezen and stored in -80°C for analysis. All samples were analyzed with an atomic absorption spectrophotometry in the Oulu University Hospital laboratory. The range of normal values is 11-22 lmol/l. Organ failures were assessed by daily maximal sequential organ failure assessment (SOFAmax) score. RESULTS. 551 serum Zn samples were obtained during 24 h after the baseline with median time of 6 h. Only 21 Zn values were within and two over the normal range. Median (IQR) serum Zn levels were 4.7 (2.9-7.0) and 5.0 (3.3-6.9) lmol/l for survivors (n = 393) and nonsurvivors (n = 158), respectively, with no significant difference (p = 0.38). In patients with or without infection (pneumonia, respiratory infection or sepsis) during 48 h prior to ARF, Zn levels were 4.9 (2.8-6.9) and 5.0 (3.0-7.1) lmol/l, respectively (p = 0.09). Zn levels were significantly lower (p \ 0.001) in patients with cardiovascular SOFA 3-4 than 0-2, 4.3 (2.8-6.1) and 5.9 (3.7-8.0) lmol/l, respectively. A significant correlation of Zn level and daily SOFAmax (Spearman's q -0.151, p \ 0.001) was found (Fig. 1) . CONCLUSIONS. Low serum Zn levels were detected in almost all patients with ARF. No association to day 90 mortality was detected to support the earlier findings with pediatric critically ill patients. However, we found a significant correlation to organ failure development in adult patients with ARF. Mountaineering is closely related to a range of adverse influences. The overriding factor that affects a climber may be the hypobaric hypoxia, which is compensated by hyperventilation and other adaptive changes in the pulmonary and systemic circulation. West (1993) theoretically predicted hypoxemia combined with respiratory alkalosis [3] , and low oxygen saturation (59…88%) has been observed on Peak Broad, Karakorum [4] . Lack of adaptation is known as mountain sickness (occurrence 27…47% [1, 2] ), which may be alleviated by acetazolamide. The importance of understanding pathophysiology of mountaineering is dictated by the gradual expansion of Western consumer-oriented society to higher altitudes. The goal of our study was to obtain precise information on changes in arterial blood gas composition, acid-base status, and degree of hemoglobin desaturation relative to altitude. MATERIALS AND METHODS. Experienced athletes-four males between 32 and 57 years and 1 female 38 years attempted to ascend Mt. Makalu (8,463 m) in April-May 2008. Acetazolamide 0,125 bid was used from April 21 till May 21. Femoral arterial blood rather than radial arterial blood was analyzed before reaching base camp ( BACKGROUND. Ventilator associated lung injury is a complication of mechanically ventilated patients. Knowledge about pathological pathways comes from animal studies, which are necessary to generate hypotheses to be tested in humans. Various experimental methods of inducing acute lung injury (ALI) have been used in animal models. The results of animal studies and human research appear to be conflicting; however, this may be a consequence from the different animal models used as such for comparison. We hypothesized that effects on gas exchange, respiratory mechanics, histo-pathologic lung damage and systemic inflammation are depending on the model of ALI used. In five groups of pentothal anesthetized rats acute lung injury was induced by either lung lavage or hydrocloric acid aspiration. Rats were then ventilated with lung protective settings in pressure controlled mode with positive endexpiratory pressure (PEEP) of 4 cm H 2 O or breathing spontaneously with continuous positive airway pressure (CPAP) = 4 cm H 2 O for 4 h. Blood pressures, cardiac output, pulmonary mechanics and gas exchange were measured. RESULTS. The tidal volume was 9.3 ± 2.5 ml/kg in ventilated and 6.6 ± 1.1 ml/kg in CPAP groups. Respiratory rate and minute ventilation were constant in ALI animals and controls, but showed variability in spontaneous breathing animals. Only half of the CPAP animals with ALI survived [ 2 h. No significant differences were found for PCO 2 , cardiac output or blood pressure between models, but mean arterial pressure decreased in ALI. In the lavage and aspiration model, PaO 2 was lower after induction of ALI (151 ± 65 and 162 ± 34 mmHg, respectively) than controls, and increased in lavage (394 ± 65 mmHg) but not the aspiration model (198 ± 100 mmHg) after 4 h (p \ 0.05). Dynamic compliance of the respiratory system decreased permanently after induction of ALI to 0.22 ± 0.03 ml/cm H 2 O (lavage) and 0.34 ± 0.11 ml/cm H 2 O (aspiration) as compared to controls, which maintained at 0.66 ± 0.16 ml/cm H 2 O after 4 h. The lungs from five additional anesthetized, unassisted breathing animals, taken directly after induction, showed significant atelectasis, neutrophil infiltration and interstitial and alveolar edema (diffuse alveolar damage (DAD) score 5.5 ± 1.0), as compared to control animals without ALI (DAD 3.0 ± 2.7 in ventilated, 3.8 ± 2.9 in CPAP, respectively). The DAD was higher in aspiration (7.2 ± 1.6) than in lavage (4.3 ± 2.2) induced ALI, with no significant differences between ventilated and CPAP animals. No hyaline membranes were observed. CONCLUSIONS. Anesthesia induces significant alveolar inflammation, which is partially reversible by use of PEEP. The ALI model of acid aspiration induces persistent changes in gas exchange, respiratory mechanics and alveolar damage, which are more severe and consistent than those induced by the lavage model. BACKGROUND. Acute lung injury (ALI) is characterized by exaggerated inflammation and a high metabolic demand. Mechanical ventilation can contribute to ALI, resulting in ventilator induced lung injury (VILI). A suspended animation-like state induced by hydrogen sulfide (H 2 S) may reduce metabolism and CO 2 production, allowing for a lower minute ventilation to maintain gas exchange, thereby decreasing VILI. H 2 S may also limit lung injury via reduction of inflammation. The effect of H 2 S-induced suspended animation on myocardial function is unknown. METHODS. In rats, VILI was induced using a peak inspiratory pressure (PIP) of 25 mmHg and zero PEEP. Controls were ventilated with a PIP of 13 and PEEP of 5 mmHg. Respiratory rate was adjusted to maintain normocapnia. Suspended animation was induced by infusion of a H 2 S donor, controls received saline. Blood gases were drawn, bronchoalveolar lavage fluid (BALF) was collected, lungs were removed. Aortic flow was measured. Statistics include Kruskal-Wallis and Mann-Whitney U. INTRODUCTION. Alveolar oedema is a hallmark of ARDS and ALI. Fluid clearance and the influence of anaesthetics on oedema resolution are poorly understood on a molecular level in the injured lung. Oedema resolution is mediated by osmotic water reabsorption, following active sodium reabsorption via the apically located epithelial sodium channel (ENaC), driven by sodium-potassium-adenosin-triphosphatase (Na ? /K ? -ATPase). OBJECTIVES. Our aim was to investigate the influence of 1 MAC (=2.2 vol%) sevoflurane on mRNA and protein levels of ENaC and Na ? /K ? -ATPase in injured alveolar epithelial cells (AEC). METHODS. Primary culture of AEC was stimulated with lipopolysaccharide (LPS, 20 lg/ ml) and exposed to normal air containing 5% CO 2 with or without sevoflurane. mRNA levels were measured at 8 h using the Taq-man real-time PCR method. Additionally, proteins for Western blotting were analyzed at 4, 8 and 24 h (n = 6). In the presence of sevoflurane mRNA level of the a 1 -subunit mRNA of Na ? /K ? -ATPase in control cells was downregulated by 15% (p \ 0.05). a-subunit Na ? /K ? -ATPase protein expression, however, was not influenced by LPS or sevoflurane at all time points. mRNA of c-ENaC was decreased by 30% in the presence of sevoflurane and by 70% upon stimulation with LPS. In the LPS-sevoflurane group downregulation was even more pronounced with 79% (p \ 0.05) after 8 h, but not statistically different from the LPS group. On the protein level of c-ENaC protein expression a first change was observed at 24 h with a downregulation of 27% upon LPS exposure (p \ 0.05). Sevoflurane did not have an effect of this transporter protein. Previous studies have shown that halothane decreases Na ? /K ? -ATPaseand sodium channel activities in alveolar epithelial type II cells [1] . Despite this finding for halothane, we could not see similar effects for the volatile anaesthetic sevoflurane. Our results suggest that neither the driving force of alveolar oedema resolution, the sodium potassium ATPase, nor c-ENaC, which is considered the rate limiting step in sodium coupled water reabsorption are influenced by sevoflurane and LPS in an in vitro model of ARDS. To further characterize the impact of sevoflurane on water transport, functional analysis of these two transporters have to be performed. GRANT ACKNOWLEDGEMENT. OBJECTIVES. We evaluated the effects of two nebulised SFA Perfluorohexyloctane (F6H8) and Perfluorobutylpentane (F4H5) at different dosages (1 ml/kg vs. 0.1 ml/kg) on pulmonary mechanics and gas exchange in healthy lungs. Design. After approval by the local animal care committee, prospective, randomized animal study. Subjects. Thirty-five New Zealand White rabbits. Interventions: Tracheotomised and ventilated juvenile rabbits were nebulised intratracheally with either a high or a low dose of two different SFA (F6H8 low/high and F4H5 low/high ) or saline (NaCl). Ventilated healthy animals served as controls (sham). Arterial blood gases, lung mechanics, heart rate and blood pressure were recorded prior to nebulisation and in 30 min intervals during the 6-h-study period. RESULTS. Immediately after starting aerosol therapy p a O 2 /F i O 2 -ratio and dynamic lung compliance decreased in all groups, with the exception of the F4H5 low group which behaved like the sham group. Although p a O 2 /F i O 2 -ratio showed a continuous improvement in the other groups over time respiratory mechanics still remained impaired. High dose groups with nebulisation of liquid Perfluorohexyloctane (F6H8 high ), Perfluorobutylpentane (F4H5 high ) or saline (NaCl) showed no significant differences neither in oxygenation, blood pressure nor in pulmonary compliance and resistance. In contrast to F6H8 high , there were no residues of F4H5 high detectable in bronchoalveolar lavage. Regarding F4H5 low we were not able to detect any adverse effects on gas exchange or pulmonary mechanics. Additionally, wet-dry-ratio of apical lung tissue samples revealed no significant edema. CONCLUSIONS. High dose aerosolized SFA (1 ml/kg), either F6H8 or F4H5, equals effects of high dose inhalation of saline. When comparing the low-dose SFA-groups, there is a convincing discrepancy in favour of F4H5. F6H8 low impairs pulmonary function, whereas a low dose application of F4H5 (low) shows no interference. This may be due to the faster evaporation of F4H5. A new SFA-based pulmonary drug delivery system for lipophilic or water-insoluble substances could be developed on the basis of a low-dose application of F4H5. OBJECTS. Hypertonic exposure reduces cell volume and thereby creates a relative excess of plasma membrane (PM). As a result the lipid bilayer of the PM can simply unfold with a minimal increase in lateral tension when an externally imposed shape change demands it. To test this hypothesis, we determined the effects of osmotic pressure on the susceptibility of deformation injury and PM wound repair. We measured deformation injury and repair responses of A549. Cell culture media were consisted of 1x HMEM and mannitol (v/v 50/50) with osmolarity of 300 (iso), 440 (hyper) and 170 mOsm (hypo). Cells conditioned with media were either stretched or deliberately injured with a scalpel. The fraction of wounded and healed cells was measured using a dual label method. . (1) Exposure to a hypertonic environment tends to lower the susceptibility of A549 to deformation injury (5.35 ± 1.15% for iso, 4.36 ± 1.16% for hyper), while exposure to a hypotonic environment uniformly increases it (6.23 ± 1.51% for hypo) in stretch injury. INTRODUCTION. The migration of polymorphonuclear leukocytes (PMNs) into the lung plays a critical role in the development of acute lung injury (ALI). Adenosine receptor A3 (A3AR) is one of four G protein-coupled adenosine receptors that has been demonstrated to modulate PMN trafficking in various models of inflammatory disorders including sepsis and asthma. However, the role of A3AR in ALI has not been investigated systematically yet. The objective of this study was to determine the role of the A3AR in a murine model of LPSinduced lung injury and in an in vitro transmigration system with human cells. METHODS. The migration of PMNs into the different compartments of the lung was determined by flow cytometry in adult male C57BL/6 mice (wildtype [WT] ) and homozygous A3 receptor knockout (A3KO) mice. We used chimeric mice that were generated by transferring bone marrow between wild-type and A3 KO mice to differentiate the role of A3 on hemopoietic and nonhemopoietic cells. Furthermore, microvascular permeability was assessed by the extravasation of Evans blue and the release of chemotactic cytokines into the alveolar airspace was determined by ELISA. Paraffin-embedded sections of the lung were stained for PMNs after LPS inhalation to illustrate their accumulation in the lung. In a human in vitro assay, we quantified neutrophil transmigration across an epithelial monolayer (A549 cell line). In all murine in vivo experiments and in the in vitro transmigration assay, we assessed the effectivity of the specific A3-Agonist Cl-IB-MECA. All statistical analyses were performed by using ANOVA. p \ 0.05 was considered statistically significant. RESULTS. Inhalation of LPS significantly increased the number of PMNs in WT and A3KO mice in all lung compartments. No differences in PMN counts were observed between WT, A3KO, and chimeric mice. Pretreatment with Cl-IB-MECA led to a significant decrease of PMNs in all lung compartments of WT mice but not in A3KO mice. Pharmacological activation of A3AR diminished the LPS-induced microvascular permeability in WT mice but not in A3KO mice. Upon LPS-inhalation, A3KO mice exhibited significantly higher levels of the cytokines CXCL1 und CXCL2/3 in the alveolar airspace than WT mice. In WT mice, pretreatment with Cl-IB-MECA reduced levels of TNFa and IL-6 significantly. Transmigratory activity of human PMNs across an epithelial monolayer was reduced when A3 was activated in PMNs. In contrast, pretreatment of the epithelial cells did not inhibit migration of PMNs. INTRODUCTION. Lung overdistention during mechanical ventilation causes an increase in pulmonary vascular permeability, which is characterized by interstitial and alveolar edema secondary to a diffuse endothelial and epithelial injury. Thrombopoietin (TPO), a humoral growth factor that stimulates the proliferation of megakaryocytes, has also been identified as a pro-inflammatory mediator in various clinical conditions. The receptor of TPO, c-Mpl, is constitutively expressed on endothelial cells and may modulate the permeability of the endothelium. We investigated the contribution of TPO in the development of acute alveolar edema formation by mechanical stretch. In an ex-vivo model of mechanical ventilation (MV), lungs of C57bl6 mice were ventilated for 2 h with high stress pressure cycled ventilation (end inspiratory pressure = 20 cm H 2 O, PEEP = 0 cm H 2 O, I:E ratio = 1:1) and perfused with 4% bovine serum albumin RPMI medium at a rate of 1 ml/min, in the presence or absence of TPO (1 mg/ml). Following ventilation, lung elastance was measured and protein concentration was analyzed in the bronchoalveolar lavage. Data are mean ± SE.  Mechanical ventilation (MV) to treat patients with ARDS or Acute Lung Injury (ALI) has the end objective to increase the dynamic functional residual capacity (dFRC), thus increasing overall functional residual capacity (FRC). Simple methods to estimate dFRC at the end of expiration for a given positive end expiratory pressure (PEEP) would provide a valuable metric to track and modulate therapy. However, such methods do not exist and current methods are time-consuming and relatively invasive. METHODS. This study utilizes a constant stress strain ratio for an individual patient's volume responsiveness to PEEP to estimate dFRC at any PEEP. The estimation model identifies two population parameters from clinical data to estimate a patient-specific dFRC, b and mb, where b captures physiological parameters of FRC, lung and respiratory elastance and varies depending on the PEEP level used, and mb is the gradient of b versus PEEP. dFRC was estimated at 5 different PEEP values (5, 7, 10, 12, 15 ) cm H 2 O, and compared to the measured dFRC for 12 ALI/ARDS patients to validate the model. PATIENTS AND METHODS. In a 4 years period 24 patients (12 males, 12 females) with haematological malignancies were admitted in ICU. Malignancy type, reason for admission, haematological profile, requirement for invasive ventilation, bronchial and blood cultures and survival rate were recorded. RESULTS. Patients suffered from: Hodgkin's lymphoma (4), non-Hodgkin's lymphoma (12), chronical lymphocytic leukaemia (3), acute myelogenous leukaemia (3) and multiple myeloma (2) . Admission to ICU was precipitated by: emergency surgical procedure (3), respiratory failure (14), sepsis (5), pulmonary oedema (1) and coma (1) . Pulmonary infiltrates was the main finding in chest x-ray. Bronchial secretions cultures were positives in 12 patients while blood cultures were positives in 8 patients. Apache II score ranged from 10 to 31 (average 21.85) and the ICU days ranged from 1 to 36 (average 11.29). All the patients required invasive ventilation. All the patients with sepsis and serious neutropenia were died, while the total mortality was 15/24 (62.5%). CONCLUSION. The admission of patients suffering from haematological malignancies in ICU is associated with high mortality. Immunosupression that renders them susceptible to infections, thrombocytopenia, and invasive ventilation are factors that contribute to this. Early recovery of bone marrow and non invasive ventilation could improve the outcome in these patients.  In liver transplanted patients, immunosuppressive therapy can increase the risk of infections and post-operative ARF. NIMV has been proposed as an alternative technique to reduce complications related to endotracheal intubation. The aim of our study was to evaluate NIMV in liver transplanted patients, developing ARF in the post-operative period. MATERIALS AND METHODS. In this study we evaluated 24 liver transplanted patients, developing postoperative ARF. Measurements of respiratory and haemodynamic parameters were performed at baseline, after 1 h and at the end of the treatment. We evaluated intubation rate, NIMV tolerance, length of stay in the ICU (LoS), ICU and Hospital mortality. RESULTS. 18 (75%) out of 24 patients were successfully treated with NIMV, while 6 (25%) failed and were intubated. We observed no significant differences among groups in gas exchange, but RR was significantly reduced in the success group during treatment (p \ 0.01). In both groups we found no significant differences in PaO 2 /FiO 2 initial improvement, but the success group showed a significantly higher rate of PaO 2 /FiO 2 sustained improvement (p \ 0.01). No significant differences between the two groups were found in terms of hours and days of NIMV. Success and Failure groups were significantly different in SAPS II (p \ 0.02) LoS (p \ 0.02), ICU and Hospital mortality (6 vs. 50%, p \ 0.001, 17 vs. 50%, p \ 0.03). Reasons for NIMV failure were not related to respiratory causes, but acute systemic causes such as septic shock and MODS. CONCLUSIONS. NIMV can represent a valid alternative to invasive mechanical ventilation for the treatment of postoperative ARF in liver transplanted patients; in NIMV success patients reduced LoS and mortality can be expected. The influence of body posture on expiratory flow-limitation (EFL) was estimated in 44 flowlimited, mechanically ventilated patients using the negative expiratory pressure (NEP) method. A device especially designed and in build in an Evita 2-Draeger respirator allowed the application of a pressure equal to-5 cm H 2 O, starting at 8 ms after the onset of expiratory flow and sustained throughout the end of expiration. Patients were considered flowlimited, if despite the application of NEP part or the expiratory flow-volume curve was superimposed on the baseline curve. Patients were studied in supine and in semi-seated position (45) at baseline and then 30 min after administration of bronchodilators (5 mg of inhaled salbutamol) with a nebulizer connected to the inspiratory port of the ventilator. Supine position was significantly related to the occurrence of EFL (p = 0.001). EFL was abolished in 9% of our patients when changing from supine to semi-seated position, while in general a significant improvement of EFL was noticed (from 41 to 36% of V T , p = 0.001). Significant improvement of EFL was achieved as well (p = 0.002) after bronchodilative therapy. PEEPi was the only variable significantly related to EFL improvement when changing body posture from supine to semi-seated, while for bronchodilative therapy, none of the variables studied was significantly related to EFL improvement. L. C. Woodson 1,2 1 University of Texas Medical Branch, Anesthesiology, Galveston, USA, 2 Shriners Hospital for Children, Anesthesiology, Galveston, USA AIMS. Laryngeal injuries are common among burn patients and can result in long term functional deficits. We have included careful laryngeal examination with our initial fiberoptic bronchoscopic evaluation of burn patients. The goal has been to allow early identification of laryngeal injuries and to facilitate laryngology consultations. METHODS. Digital video recordings were made of upper airway endoscopies performed during airway management on admission or at the time of anesthesia for initial wound excision. These recordings were used to identify laryngeal injuries and to facilitate laryngology consultations. A wide variety of laryngeal injuries were identified and the digital recordings (which can be communicated by email) greatly facilitated laryngology consultations. In many cases these recordings guided therapeutic interventions and were often sufficient to avoid a separate exam under anesthesia. Diagnosis of thermal necrosis provided an indication for early tracheostomy. Identification of the mechanism of mechanical airway obstruction (e.g. supraglottic edema, fibrinous exudates, granulomas, vocal fold dysmotility) resulting in failure of a trial of extubation frequently guided therapy. Early identification of posterior glottic damage provided more timely corrective laryngological interventions. Educational use of these videos helps increase awareness of risks of laryngeal injury in thermally injured patients. AIMS. The most used weaning predictor f/V T ratio, is not a consensual predictor. When it was reported on the first time, this ratio was considered highly sensitive and specific. But others papers seems to disagree with it, suggesting other cutoff values to determine weaning failure in specific populations, as the elders. Advanced age is thought to be an import associated factor in the intensive care unit (ICU), but its effect on the weaning process is unclear. No studies have found strong evidence that conventional weaning parameters are reliable for this population. The widest used weaning criteria, f/V T ratio, does not seems to keep the same performance in this kind of population. The main purposes of this study were to identify the possible differences of the f/V T ratio measured in a spontaneous breathing trial, between an adult and an elderly group. We designed a protocol to study the variation, sensibility and specificity of the frequency-to-tidal volume ratio between an adult group (AG; up to 65 years) and an elderly group (EG; older than 65 years) in a daily weaning screening trial. METHODS. The study cohort comprised 239 patients ready to undergo weaning trial. The parameters studied were: weaning success (48 h of spontaneous ventilation after extubation), respiratory rate (f), tidal volume (V T ), frequency/tidal volume ratio (f/V T ), gasometric and ventilatory parameters. The weaning method was spontaneous breathing trial (SBT). Measurements were made in the beginning of SBT (T0) and 30 min after (T30). We analyze possible differences in the sensibility and specificity of the f/V T ratio between elderly and adults and compare with previous values already published. The chi-square test, ANOVA and the t test were used in the statistical analysis. Weaning success was 74.8% in EG and 78.1% in AG (p = 0.552). The baseline characteristics were similar. Comparisons of AG and EG at T0 and T30 showed statistical differences in weaning criteria: f, V T and f/V T ratio. CONCLUSION. Weaning success in our study was low, but similar to the described in other trials. Elderly patients showed higher f and lower V T . Consequently, f/V T ratio was lower too. The area under the ROC curve for f/V T ratio was smaller than already published. RESULTS. 562/645 (87%) were successfully extubated and 83 patients required re-intubation. The demographic data showed no differences in age, BMI, APACHE II, ICU admission diagnosis or sex distribution between groups (Table 1) . Patients who failed extubation had small but statistically significant differences in vital capacity (VC), peak negative inspiratory pressures (PNIP), PaO 2 /FiO 2 ratios (PF) and were ventilated longer prior to extubation. Paradoxically, patients failing extubation had positive end expiratory pressures that were statistically but not clinically significant higher. The ratio of respiratory rate to tidal volume (f/Vt) was not significantly different. Patients failing extubation were also more likely to have weaker cough, gag, level of consciousness as measured by Glasgow coma scale and more secretions ( Table 2 ). Having no cuff leak did not predict failure of extubation. The most common reasons for reintubation were secretion retention and/or absence of cough (90%). Pressure support ventilation (PSV), a widely used assisted mode, has the purpose to avoid diaphragm disuse allowing the patient to generate spontaneous inspiratory efforts optimizing comfort and work of breathing. However, still little is known about the individual response of respiratory muscles under these conditions. We hypothesized that respiratory muscles of patients ventilated with clinic PSV might result, at least sometimes, excessively unloaded. We performed an observational study in the intensive care unit on patients ventilated with PSV set by the clinician in charge. Twenty intubated, mechanically ventilated patients (71 ± 9 years old) during the weaning phase entered the study. The patients had no sedation at least for the last 24 h. Respiratory timing, tidal volume (V T ), peak airway pressure (Paw peak ), electrical activity of diaphragm expressed as percentage of its maximum (Edi/ Edi max ), inspiratory (PTPes) and diaphragm (PTPdi) muscle effort were measured during 30 min of clinic PSV. RESULTS. We found that seven out of twenty patients generated a negative Pes swing only during the PSV inspiratory triggering phase (PSV T ) in comparison with the remaining 13 patients in whom Pes was negative throughout most of the mechanical breath (PSV N ). In the PSV T group, Pes swing was either flat or positive after inspiratory triggering. Therefore, in the PSV T group both PTPes /min and PTPdi /min were fivefold lower than normal values. V T / predicted body weight (PBW) was significantly higher in the PSV T versus PSV N group (see Table 1 ).  During weaning with PSV: (1) a significant number of patients (35%) showed a Pes shape similar to that observed during pressure assist/control modes, and inspiratory muscle effort abundantly lower than normal, both indicating excessive inspiratory muscle unloading; (2) among the variables used to set PSV, only a high V T /PBW (higher than 8 ml/kg) hallmarked excessive unloading; (3) due to the ample prevalence of the phenomenon, the question whether high levels of inspiratory muscle unloading can cause detraining and prolonged mechanical ventilation merits an answer from further research. INTRODUCTION. The liberation from mechanical ventilation (MV) should be done as soon as possible in order to avoid complications and the risks associated with prolonged unnecessary MV, such as ventilator-associated pneumonia, ventilator induced lung injury, and increased ICU and hospital stay. This procedure should be carried out properly and safely. OBJECTIVE. Evaluate the extubation success rate, MV time and weaning time using a daily weaning screen followed by a spontaneous breathing trial (SBT). Patients who were ventilated for more than 24 h were subject to this procedure, which was carried out by respiratory therapists. METHODS. In our ICU, between February and August of 2008, all intubated patients who were ventilated for more than 24 h underwent a daily weaning screen, which contained variables such as hemodynamic, gas exchange, consciousness and resolving the need for MV. If these variables were stable, these patients were submitted to a SBT and were extubated if they did not show any signs of respiratory discomfort or hemodynamic changes for at least 30 min. CONCLUSION. The use of a daily weaning screen followed by a SBT was associated with a high extubation success rate and a very short weaning duration with 11% of unsuccessfully extubations. C. Chatt 1 , D. Pandit 2 , G. Raghuraman 2 1 Birmingham Heartlands Hospital, Critical Care, Birmingham, UK, 2 Birmingham Heartlands Hospital, Birmingham, UK AIM. The aim of the study was to assess the impact of PMV on the course of weaning in mechanically ventilated patients. We wanted to assess the optimal pressure support at which PMV can be initiated which would enable prolonged use of PMV without affecting the duration of respiratory support. METHOD. Data on all patients who were mechanically ventilated for greater than eight days were obtained from ICNARC database, who underwent tracheostomy as part of their weaning process. Satisfactory level of pressure support was achieved (between 10 and 15 cm H 2 O) PMV was introduced into the patient's breathing circuit and spontaneous ventilation was attempted. We applied Mann Whitney U tests for parametric data, Fisher exact tests for non-parametric data and ANOVA was used to compare the three groups with different pressure supports at initiation of PMV. A p value \ 0.05 be statistically significant. RESULTS. 157 patients who were ventilated for greater than eight days identified. Of these, 29 patients were excluded because they did not have a tracheostomy during their period of ventilation. Of the remaining 128 patients, PMV was used in 92 patients (72%). There were no significant differences between the demographic data (sex, age) or the data on admission to intensive care (APACHE II score, ratio of medical to surgical patients) and duration of mechanical ventilation between the two groups. However, there were significant differences in the mortality, total respiratory support days after tracheostomy and length of stay in intensive care and length of hospital stay between the two groups. In the group on PMV, no record of aspirations was found documented on the intensive care charts. In patients in whom PMV was used (n = 92), PMV was initiated at CPAP (continuous positive airway pressure) in 40 patients (44%). 30 patients (33%) had PMV initiated at a pressure support of B10 cm H 2 O and in 21 patients (23%) PMV was initiated at a pressure support of [10 cm H 2 O. There was a significant difference in the duration of mechanical ventilation post tracheostomy (p = 0.04) and the length of hospital stay (p = 0.02) between the two groups, with the CPAP group being ventilated for a shorter duration but with a longer stay in hospital The same difference was shown when comparing three groups of pressure support when PMV was commenced (CPAP, Pressure support B10 cm H 2 O and pressure support [10 cm H 2 O). However, in the pressure support [10 cm H 2 O group we observed that the duration of use of PMV was lower than in the other two groups despite longer duration of mechanical ventilation and total respiratory support days. Although this was not statistically significant, it could be clinically significant. Our study suggests that use of PMV at pressure support B10 cm H 2 O could increase the duration of its use without affecting the length of mechanical ventilation. We would therefore recommend weaning to a pressure support B10 cm H 2 O before PMV is commenced in the acute setting.  No data are available concerning the oxygenation target to aim during the weaning phase from mechanical ventilation. Also, in opposition to ARDS patients there is no clear recommendation for the upper limit of SpO 2 to maintain during weaning. This study is part of a research project on PEEP and FiO 2 settings automation during mechanical ventilation. METHODS. This observational study was designed to assess the SpO 2 target aimed during the weaning phase of invasive mechanical ventilation (FiO 2 B 0.60 and PEEP B 10 cm H 2 O). Patients were recruited in ICUs from several countries (Canada, France, Italy, Tunisia, Argentina). The following data were prospectively collected by the respiratory therapists at each round during a 3 months period: SpO 2 , FiO 2 , PEEP level, ventilatory mode, anatomic site of the pulse oxymetry sensor, quality of the SpO 2 signal. RESULTS. Data from 3 centers (5 ICUs) from Quebec City, Canada, and 1 center from Créteil, France are available. 687 patients were prospectively included. 12,907 observations were performed. The mean level of FiO 2 was 0.43 ± 0.10 with FiO 2 C 0.50 and 0.70 in 24.8% and 3.5% of observation times respectively. The mean level of PEEP was 5.6 ± 1.6 cm H 2 O and was below, equal or above 5 cm H 2 O in 3.1, 71.5 and 22.2% of the cases respectively. The most frequent ventilatory modes were pressure support (56%), SIMV (27%) and ACV (12%). The pulse oxymetry sensor was applied on a finger of the hand in 94.5% of the cases and was deemed of good quality in 91% of the time. The mean SpO 2 was 97.1 ± 2.7% for the whole population and was 97.3 ± 2.8% for patients with FiO 2 C 0.70. SpO 2 was higher than 95% in 66% the observations. Desaturation with SpO 2 below 92% were recorded in 2.6%. The SpO 2 signal was deemed available by the bedside nurse in 94.4 ± 10.2% of the time. CONCLUSION. This study demonstrates that SpO 2 levels may be maintained at high levels unduly. This may have an impact on the weaning phase of mechanical ventilation. This study also shows that the SpO 2 signal availability was high enough to be used in a closed-loop oxygenation system. INTRODUCTION. Automated weaning systems are viewed as a challenge to weaning decision-making autonomy by some clinicians. Clinician perceptions of the utility of such systems may influence uptake in to practice. To assess the perceived utility of the automated weaning system, SmartCare/ PS. A survey was generated based on comprehensive literature review and 1-year's experience using SmartCare/PS. Survey pilot testing was conducted with 5 senior clinicians experienced in SmartCare/PS weaning in an independent ICU. Questions addressed perceived system usability and appropriateness of automated weaning, system benefits and disadvantages, as well as patient indications deemed suitable and unsuitable for SmartCare/PS weaning. Participants were also asked to indicate if they would continue using SmartCare/PS on trial completion. The survey was administered to clinicians on completion of a randomized controlled trial conducted to compare SmartCare/PS to non-protocolized weaning 1 . Of 85 staff surveyed, 34 surveys were returned by 27 nurses and 7 doctors (response rate 40%). Eight respondents had no experience with SmartCare/PS despite the 1year trial duration, leaving 26 surveys with evaluable responses. The majority of respondents perceived SmartCare/PS was easy to activate (19/26, 73%) and to use once activated (23/26, 88%). The system was observed to wean appropriately by 13/26 (50%) respondents; 13 experienced SmartCare/PS to wean inappropriately. Comments on inappropriate weaning identified clinically unacceptably increases of pressure support (PS) for patients with profound tachypnea and complicated lung pathology. SmartCare/PS' ability to reduce the overall duration of weaning was questioned by all but 3/26 (12%) respondents. PS adjustment according to patient requirements was the most frequently perceived benefit (15/26, 58%). Most respondents did not perceive any advantage of Smartcare/PS for patient comfort 22/26 (86%), assessment frequency (15/26, 58%) and automated control of weaning (15/26, 58%). Less control over weaning was the most regularly cited disadvantage of SmartCare/PS (12/26, 46%). System issues such as program abortion without identifiable reason and mandatory PEEP reduction prior to a spontaneous breathing trial to assess readiness for separation were less frequently cited disadvantages [10/26 (38%) and 7/26 (27%) respondents respectively]. Most respondents (18/26, 69%) felt SmartCare/PS was best suited for weaning postoperative patients and should be avoided for patients with neurological dysfunction (18/26, 69%). Only 4/26 (15%) respondents stated they would not continue to use SmartCare/PS. Clinicians demonstrated moderate acceptance of SmartCare/PS. More work is needed to identify those patients more likely to benefit and confirm the overall utility of SmartCare/PS as a weaning tool. INTRODUCTION. Physician approaches to ventilation withdrawn varies among physicians whereas the prompt recognition of respiratory failure reversal and usefulness of weaning protocols in reducing duration of mechanical ventilation (MV) have been largely demostrated As nursing staff attend patients 24 h a day its leadership in this process can be effective and safe. OBJECTIVE. To demonstrate that a nurse-directed protocol to withdraw MV could reduce a 25% its duration. Prospective sequential study performed in two periods. During de first period (6 months) data concerning weaning definite criteria appearance, duration of MV, reintubation or need for nonninvasive ventilation (NIMV) and demographic data were collected to all mechanically ventilated patients blinded by attending nurses and physician. After a three months phase of staff training there was a second 6 months period where weaning criteria were checked al each nurse working shift during the first 10 days of MV. When criteria were fullfilled a 120 min of spontaneous breathing trial was perfomed and tracheal tube removed if there were no intolerance criteria. Same data as the first phase were collected. We used Mann-Whitney 0 s U test to compare MV duration, time to reach weaning criteria (TRWC) and extubation delay (MV duration minus TRWC). Weaning failure was compared using X square. Data are presented as median (25-75 percentile). RESULTS. 203 patients were screened (114 in the first period and 89 in the second) but only 164 patient reached weaning criteria in the first 10 days (96 in the first period 68 in the second), 63.5% men, aged 69 (55-76) years. Aim of this study is present our experience about elective bedside PDT with the Blue-Rhino kit over an 1 year period, in order evaluate its efficacy in terms of intraoperative and postoperative complications. PATIENTS AND METHODS. The study included a total of 73 consecutive ICU patients requiring tracheostomy. All PDT were performed by ICU staff physicians at patients' bedsides, using a Blue Rhino kit. The following data were recorded: age, sex, Simplified Acute Physiology Score (SAPS) II, fraction of inspired oxygen (FIO 2 ) before the tracheostomy, days on mechanical ventilation before the tracheostomy, bleeding, tracheal tear, subcutaneous emphysema, pneumothorax, wound infection, hypotension, lowering SaO 2 during the procedure, inability to complete the procedure, and procedural mortality. Distance follow-up included fiberoptic bronchoscopy to evaluate tracheal stenosis. RESULTS. There were a total of 2 (2.73%) complications (tracheo oesophagel fistula and bleeding). Forty -one patients died in the ICU (41%), although none of these deaths were related to technique complications. Mean duration of the procedure was 7.5 ± 1.2 minutes. The PDT performed at bedside in the ICU, using the Blue Rhino kit is a simple and safe procedure that offers many advantages in terms of safety and efficacy. OBJECTIVES. Questioning the need for several specialized physicians or extra assistance to perform a single percutaneous tracheostomy using fibrescopic tracheoscopy, we performed a prospective study into the complication rate of percutaneous tracheostomy without tracheoscopy on our mixed medical and surgical ICU. , 99 consecutive patients were included after having received a percutaneous tracheostomy. Indication for tracheostomy was always a long anticipated duration of mechanical ventilation. If no contra indications were present, percutaneous tracheostomy was performed. If contra indications against the use of percutaneous tracheostomy without tracheoscopic control were present, tracheoscopy was performed to ensure maximum patient safety. The mean age at the time of receiving a tracheostomy was 66.9 (17-83) years. The cohort consists of 69 male patients en 30 female patients. Only tTwo percutaneous tracheostomy were performed under fibrescopic control due to contra-indications for an uncontrolled procedure. In 99 procedure, sixteen minor, and no major complications were encountered. This resulted in a 16.2% minor complication rate. CONCLUSIONS. The number of complications in our group is approximately the same as those which are suggested in international literature where tracheoscopy was performed during percutaneous tracheostomy. None of the complications encountered could have been prevented by the use of tracheoscopy. Therefore we postulate that in the hands of an experienced team and in adherence to strict guidelines, percutaneous tracheostomy can safely and successfully be performed without tracheoscopy. OBJECTIVE. To assess the risks and complications associated with the bedside PDT in our 9 years experience of over 1000 PDTs in ICU. PDT is a relatively newer technique and has been introduced as an alternative to open tracheostomy as a safer and convenient procedure. However, the risks and complications of the PDT have not been highlighted in the ICU of a developing country. A retrospective analysis of the data gathered from patients undergoing PDT was done in a 40-bedded tertiary level multidisciplinary ICU of a teaching hospital. The data was collected between April 2000 and March 2009. All intubated patients with indications for elective tracheostomy, as well as patients who required emergency tracheostomy were included in the study. Demographic and other clinical details of the patients who underwent PDT were collected. Griggs [1] technique was most commonly adopted while other adopted techniques were Ciaglia [2] , white tusk/blue rhino tapered dilator and Percutwist technique. A total of 1,010 PDTs were done in 1,005 patients, over a period of 9 years. Of the 1,005 patients 710 (71%) were males and 295 (29%) were females. The mean age of patients was 53.9 years. The average duration of intubation before PDT was 9.3 days. 970 (96%) PDT were done bedside in ICU while 40 (4%) were done in wards, Coronary care unit, High-dependancy unit and Liver transplant unit. Griggs technique was adopted in 841 (83.26%), Ciaglia in 92 (9.12%), white tusk/blue rhino tapered dilator technique in 69 (6.83%) and Percutwist technique in 8(0.80%) patients. Long-term ventilation was the most common indication in 602 (59.60%) followed by airway protection in 547 (54.14%), facilitation of weaning in 75 (7.42%) while airway obstruction/difficult intubation was observed in 5 (0.50%) patients. Pre-procedure coagulopathy was observed in 126 (12.47%) patients, 11 (1.08%) were morbidly obese while 12 (1.18%) required emergency tracheostomy. No complications were observed in 890 (88.11%) patients. Procedural complications were seen in 120 (11.88%) patients. Bleeding from the site was the leading complication affecting 60 (5.94%) patients. Difficult tube placement was seen in 25 (2.54%) patients, premature extubation in 12 (1.18%), false passage in 4 (0.39%), guidewire dislodgement in 4 (0.39%), subcutaneous emphysema in 5 (0.50%), arrhythmia in 3 (0.29%) and bleeding requiring transfusion was seen in 6 (0.59%) patients. No procedure related mortality was observed. CONCLUSION. On the basis of this large single centric study we found that PDT is a safe, reliable and convenient procedure which can be easily performed bedside by experienced intensivists. RESULTS. Of the 16 recipients who underwent PDT, 11 were liver, 3 kidney and 2 heart transplant recipients. The respective mean values for age, weight and APACHE II score were 42.7 ± 14.7 years, 61.5 ± 11.9 kg, and 28 ± 7. All PDTs were performed at bedside by experienced staff anesthesiologists with direct bronchoscopic guidance. In all cases, the indication for PDT was prolonged mechanical ventilation due to acute respiratory failure. The mean time from transplant to PDT was 13 ± 22 months and the mean duration of endotracheal intubation before PDT was 3 ± 2 days. Twelve patients had coagulopathies. The calculated lung compliance and PaO 2 :FiO 2 ratio improved after PDT (39.3 ± 27.6 vs. 54.4 ± 37.6 mL/cm H 2 O, p = 0.038 and 194 ± 55 vs. 248 ± 80, p = 0.005 respectively). Transient hypoxemia (n = 2) and mild extratracheal bleeding (n = 2) were the only early complications. There were no procedural failures and no PDT-related late complications and deaths. CONCLUSION. The results suggest that percutaneous dilational tracheotomy is an efficacious and safe technique for prolonged airway management with improved ventilatory mechanics in solid organ transplant recipients. A. Vianna 1 , G. Cabral 1 , R. Azambuja 1 , G. Carleti 1 , T. Balbi 1 , G. Pereira 1 1 Clinica São Vicente, Rio de Janeiro, Brazil AIMS. We studied diferent aspects of tracheostomy procedures performed in Intensive Care Units (ICUs) located in the municipality of Rio de Janeiro and compared them with the medical literature. A questionnaire was elaborated and sent through email to the coordinators of every ICU in the city of Rio de Janeiro in the period of July to August 2008. The questionnaire was sent to the coordinators of the 87 ICUs located in Rio, and was answered by 39 (44.82%) of them. Among the studied ICUs, 11 (28.2%) are public, 25 (64.1%) are private, and 3 (7.7%) are part of university hospitals. 36 (92.3%) are medical/ surgical, 2 (5.1%) are medical, and 1 (2.6%) is a surgical unit. The average number of beds is 16 ± 7.3. The decision to perform the procedure is taken by the ICU team in 38 (97.4%), by the patient's primary team in 11 (28.4%), and by both in 10 (25.6%). Tracheostomy is performed by a surgeon in 36 (92.3%) units, by an intensivist in 2 (5.1%), and by both in 1 (2.6%). The procedure is performed at the bedside in 35 (89.7%) of the ICUs. The most frequent indications for tracheostomy are: prospect of prolonged mechanical ventilation, coma, and airway protection. 53.8% of are performed between the first and second week of mechanical ventilation, and 41% between the second and third week. Control chest X-ray is performed in 87.1% of the units. Surgical tracheostomy is available in all the studied units. Only 7 (17.9%) units perform percutaneous tracheostomy. The reasons given for the preference for surgical tracheostomy were the lack of a qualified team for performing the percutaneous tracheostomy or material needed for this procedure. All ICUs that perform the percutaneous procedure use the Ciaglia technique with bronchoscopic guidance. Late followup is performed in 15 (38.5%) of the studied units. The study showed great differences between the tracheostomy protocols used in the hospitals of Rio de Janeiro and those found in the medical literature. In particular, the use of percutaneous tracheostomy is still infrequent in the ICUs of Rio.  On all the patients, aged at least 80 years or more, admitted to our postoperative ICU since January 1994 through December 2006, we collected demographic profiles, operative data and short and long-term outcomes. SPSS 13.1 was used for statistical analysis and p \ 0.05 was considered the level of significance. A total of 428 patients (4.8%), 53.5% males and with a median (IQR) age of 83 (82-85) were admitted to our post-operative ICU over the study period. IDDM was recorded in the 19.6% of the population, COPD in the 13.8%, hypertension in the 64.5%, chronic renal failure in the 21.7% and arteriopathy in the 37.9%. Out the total population, 51.6% of patients, with a median (IQR) pre-operative CRS of 7 (5-8) underwent a coronary-artery bypass grafting (CABG) surgery, whereas 20.7% of them, with a preoperative median (IQR) NYHA of 3 (2.25-3) needed a valve replacement (VR) and 16.1% of them combined (CABG ? VR) operations; moreover, 11.6% of patients underwent other type of cardiac and aortic surgery. Overall median (IQR) post-operative mechanical ventilation length was 15 (10.75-22) hrs. While no statistically significant difference was recorded in terms of MV duration among the four surgical groups. Overall recorded mortality rate was 10%, with the lower 7.7% for CABG and the higher 12.6% for VR (p = 0.388). Kaplan Meier curves showed no differences in survival likelihood at 28th (Log Rank = 0.404, p = 0.817) 60th (Log Rank = 0.707, p = 0.702) and 90th (Log Rank = 0.742, p = 0.690) days after surgery among the different surgical groups. CONCLUSIONS. The outcome after heart surgery in octogenarians is excellent; the operative risk is acceptable and the late survival rate is good. Therefore, cardiac surgery should not be withheld on the basis of age alone. INTRODUCTION. Re-do cardiac operations have been reported to be increasing in incidence and are associated with a higher operative risk [1] . This study aimed to determine the impact on intensive care provision. METHODS. Data from 15,346 procedures spanning twelve years (April 1996-March 2008) was examined. The 798 re-do operations were further analysed by gender, age, pathology (new, progressive, combined) , duration between procedure, theatre time, length of stay, complications and mortality. As the number of cardiac operations performed has increased over the twelve year period, the relative incidence of re-do procedures have remained stable at 5.2%. Operative length at re-do was significantly longer (mean 316 min vs. 253) however anaesthetic time pre surgical incision was not significantly increased. Subsequent length of stay on the intensive care or high dependency unit increased by 25% (mean 3.9 vs. 4.9 days), with higher complication rates affecting all systems (except post operative myocardial infarction). Renal and pulmonary complications showed the most significant increases. Renal related complications occurred in 14% and pulmonary in 20.1% of cases which represents an 80 and 25% increase on first operation rates. Infection rates were also significantly increased at double that of the initial procedure. The total hospital stay was found to be 24% longer (by 11.5 vs. 14.2 days, respectively) while in hospital mortality increased from 2.4% at initial procedure to 7.6% at re-do. Mortality rates were further elevated in the presence of renal failure post operatively, as re-do valve mortality increased from 6.3 to 20% and re-do CABG from 3.1 to 50% in this subgroup. CONCLUSION. These results, combined with the stability of percentage re-do surgery over the twelve year period, enable specific planning and management of intensive care provisions. The knowledge of extended theatre times and subsequent stay in intensive care/high dependency units has a further impact on the throughput of routine cases. The data also highlights the increased costs associated with these patients, as they not only require longer hospital stays but also suffer increased complications requiring more investigations and interventions. Specific costing therefore applies to this subgroup of intensive care patients. OBJECTIVES. We aimed to assess HRQOL at 30 days after surgery in relation to preoperative HRQOL. We compared patients with decreased HRQOL to patients with unchanged or increased HRQOL to identify disparities between these two groups. A prospective cohort study including patient scheduled for cardiac, vascular, abdominal and orthopedic surgeries in a tertiary hospital was performed. Patients filled-out a HRQOL questionnaire (SF-12) the day before surgery and 30 days after. Preoperative, intraoperative, postoperative data were collected. Changes of pre-and postoperative physical component summary (  Simultaneus kidney-pancreas transplantation is the best treatment option for type 1 diabetic patients with chronic kidney disease. Currently, the medical and surgical complications have decreased significantly, although these represent a high risk of morbidity and mortality in the short term. OBJECTIVES. This study sought to investigate the incidence of medical and surgical complications, the clinical characteristics and prognostic factors influencing graft and patient's survival in a recent cohort of pancreas-kidney recipients. PATIENTS AND METHODS. The present study included 40 patients who received simultaneous pancreas-kidney transplantation in our center from January 2004 to February 2008. We studied demographic, clinical and immunological characteristics of patients, and surgical and medical complications during his admission to intensive care unit. RESULTS. The average age of recipients was 38.8 years and mean age of donors was 24.8 years. The median cold ischemia time was 10.7 h (95% confidence interval 5-14). The average stays on the waiting list was 98.5 days. 75% of patients were extubated within the first 10 h. 52% of patients required transfusion during their ICU admission, amine infusion was started at 25% patients in the early hours. During follow-up, surgical reintervention in the immediate postoperative occurred in 30% of the patients. Major surgery complications reported in the literature are graft thrombosis, although in our serie there have been only 2 kidney graft thrombosis and 2 pancreas graft thrombosis. Only 5% of patients died within the first 3 months posttransplantation surgery. CONCLUSION. Surgical complications after pancreatic transplantation remain a significant concern. Hence we our results add further evidence to support the notion that the double and simultaneous pancreas-kidney transplant is in fact the treatment of choice in selected patients with end-stage renal failure due to type 1 diabetes mellitus. A. Shono 1 , T. Mihara 1 , Y. Murakami 1 , J. Ota 1 , F. Kono 1 , Y. Saito 1 1 Shimane Universiy Hospital, Anesthesiology, Izumo, Japan Pulmonary catheter is widely used for cardiac surgery. The complications of indwelling pulmonary catheter, such as perforation of pulmonary artery, pulmonary embolism, are well known. However, the thrombosis associated with introducer sheaths has received much less attention. We evaluated the incidence and risk factors for internal jugular vein thrombosis (IJVT) associated with introducer sheaths for pulmonary catheter after cardiac surgery. METHODS. The patients who underwent cardiac surgery and insertion of introducer sheaths (8.5F) at right internal jugular vein (IJV) were included. Ultrasonographic evaluations of IJVT were performed prior to insertion and daily until introducer sheaths removal. We investigated demographic data, underlying disease, length of surgery, use of CPB and IABP, complications during cannulation and duration of catheterization. Coagulation status (PT, APTT, Platelet count, D-dimer) and cardiac index at before and after surgery were also recorded. The Student's t test, v 2 test, and Fisher's exact test were used for statistics and P value of \0.05 was considered significant. RESULTS. 53 patients were included in this study. Mean age of patients was 70 ± 9 years (range 47-88), mean duration of catheterization was 4 ± 2 days. 19 (35.8%) patients developed IJVT which occurred only one day after insertion. The incidence of IJVT was related to presence of underlying disease (relative risk, 3.9; 95% confidence interval, 1.02 to 14.85) and was unrelated to emergency operation, the use of IABP and CPB, number of insertion attempts. There were significant differences between patients with or without IJVT in duration of catheterization (4.5 ± 2.2 vs. 3.4 ± 1.7 days, p = 0.044), cardiac Index at 1 day after surgery (2.5 ± 0.4 l/(min m 2 ) vs. 2.9 ± 0.5 l/(min m 2 ), p = 0.002), the value of D-dimer at 1 day after surgery (5.3 ± 5.3 vs. 2.7 ± 3.1 lg/ml, p = 0.044). No clinical symptoms related to IJVT were found in observation period. Our results demonstrated that IJVT associated with introducer sheaths was a frequent complication and cardiac index was significantly lower in patients with IJVT. Though the incidence of IJVT was higher in patients with prolonged catheterization, it developed even on 1 day after surgery and was usually asymptomatic. This risk should be carefully considered when the insertion of pulmonary catheter is chosen for cardiac surgery. METHODOLOGY. It is a prospective study of patients admitted to our ICU after undergoing robotic radical prostatectomy (DA VINCI) in the time interval going from January 2007 up to April 2008. We analyzed clinical and demographic data, the length of stay in the ICU and hospital, the need for blood transfusion, surgical times and the complications suffered during hospital stay. Data are expressed as mean, median or percentage, using the Student's t test and chi-square to compare averages and detect possible associations between variables. RESULTS. Seventy three patients underwent surgery with a median of 60 years. Mean surgical time was 240 min. In recent months this time is reduced to 180 min. The mean haemoglobin at admission (12.5 g/dL) was significantly higher than when dismissed (11.7 g/ dL), p \ 0.001. An average of two units of concentrated red blood cells was transfused in the surgery room in 13.7% of patients. Only one patient required transfusion at the ICU. Cardiac or renal mild complications appeared in 5.5% of patients. This could not be associated with age. The median of mechanical ventilation length was 2 h. One patient required conversion to open surgery due to profuse bleeding. There was no hospital mortality and no need for reoperation. Mean stay at ICU was 1 day, significantly less than those patients who suffered complications (p \ 0.001). The median stay in ward was 4 days. CONCLUSION. Robotic radical prostatectomy (DA VINCI) has a very low associated morbidity, minimal blood transfusion requirement and short is the stay at the ICU and hospital, in contrast to published data with open surgery. There was no hospital mortality. OBJECTIVES. To evaluate short-and long-term outcome in patients undergoing coronary artery bypass grafting (CABG), who received an intra-aortic balloon pump (IABP) prior to surgery. METHODS. Between January 1990 and June 2004, all patients (N = 154) who received an IABP prior to on-pump CABG in our center were included. Patients received the intra-aortic balloonpump for vital indications (i.e. either unstable angina refractory to medical therapy or cardiogenic shock; group 1; N = 99) or for prophylactic reasons (group 2; N = 55). A Cox proportional hazards model was used to identify predictors of long-term all-cause mortality. Compared with the EuroSCORE predictive model, observed 30-day mortality in group 1 (15.2%) was not significantly higher than predicted (10.3%). A dramatic decrease in 30-day mortality occurred in group 2 (median predicted mortality was 7.2% and observed was 0%, p \ 0.05; Fig. 1 INTRODUCTION. Physiological abnormality is associated with adverse outcome and a high percentage of patients admitted to ICU have abnormal physiology in the hours prior to admission [1] . Track and trigger systems are used to enable timely intervention to a deteriorating patient. The MEWS system is used in our level 1 care general wards with more intensive monitoring in our level 2 care facilities. OBJECTIVES. We hypothesised that the MEWS for patients admitted from the general wards were being inadequately documented and that this be may influencing outcome. We therefore also hypothesised that patients admitted from the level 1 care general surgical and medical wards in our hospital had a poorer outcome following ICU admission than those admitted from sites of level 2 care, such as the high dependency unit (HDU), emergency department and theatre recovery. We undertook a prospective 10 week audit of all patients admitted to our district general ICU. All patients' case notes and monitoring charts were reviewed by an ICU consultant with additional data (e.g. APACHE II scores) obtained from the Ward Watcher ICU database. 30 day mortality data was obtained from the hospital's SCI patient database. We then compared the data with that available for patients admitted over the previous year (2007) BACKGROUND AND AIM OF STUDY. Aorto-femoral bypass (AFB) is widely used for the patients with peripheral vascular disease (PVD). Nevertheless, there is no consensus about the type of anesthesia for this difficult group of patients. We hypothesized that continuous spinal anesthesia (CSA) will be more secure and suitable for the patients with PVD combined with pulmonary and cardio-vascular co-morbidities. The aim of our study was to compare alterations of the mean arterial pressure (MAP) and delivery of oxygen (DO 2 ) during AFB and in the early postoperative period under the influence of GA and CSA. After approval of our hospital Helsinki committee prospective randomized study was performed between 2004 and 2008: 34 male patients with PVD were included in our work. Risk of anesthesia was equal to the third degree according to ASA Scale. In the first group of patients (n = 15) GA with mechanical ventilation was employed. In the second group of patients (n = 19) CSA was used. Both groups of patients were similar with respect to age and co-morbidities (COPD 100% in both groups, ischemic heart disease and arterial hypertension). For GA we used propofol, midazolam, fentanyl, and isoflurane. Bupivacaine was used for CSA. in combination with mental sedation by intravenous midazolam. MAP was measured directly through radial artery catheter and DO 2with the help of tetrapolar rheovasography. Both parameters were measured during fixed 7 points: before the operation, at the end of induction of anesthesia, after cross clamping of the aorta, after release of aortic clamp, first hour after operation, 12 h after operation and 24 h after operation. Mann-Whitney test was used for statistical analysis of our results. In the patients with CSA during the operation and in the early postoperative period, MAP was lower but statistically non significant. MAP was lower statistically significant only during the cross clamping of the aorta and in the first postoperative hour, most probably due to the influence of the sympathetic block. At the same time DO 2 had almost no difference in both groups. Only in induction stage it was lower in the GA group that most probably was connected with negative influence of propofol on cardiac output. CONCLUSIONS. Both methods of anesthesia GA and CSA gave us opportunity to preserve stable MAP and DO 2 during AFB that we performed in this difficult PVD patients with COPD and cardiovascular co morbidities.  Over the last few decades, several scoring system have been developed for use in critically ill patients, not only to assist therapeutic decision making but also to guide resource allocation and quality of care. To evaluate the TISS-28 in surgical intensive care unit (ICU) patients and the possible relationship between TISS-28 and the type of surgery, severity of illness, and outcome in these patients. Prospectively collected data from all patients admitted to a postoperative ICU between 1st March 2004 and 30th June 2006 were analyzed retrospectively. A-priori subgroups were defined according to gender, age, SAPS II score, SOFA score, surgical procedures, and the occurrence of major morbidity or death in the ICU or in-hospital. A total of 6,903 patients were admitted during the study period (63.5% male, mean age 62.3 years) constituting 29,140 observation days. The highest TISS-28 scores were observed on the day of admission. The highest TISS-28 was observed in patients who underwent cardiothoracic surgery, the lowest in neurosurgical patients. During the first week in the ICU, TISS-28 was correlated to the severity of sepsis syndrome; however TISS-28 scores remained elevated only in patients with severe sepsis/septic shock. TISS-28 score was correlated to SAPS II (R 2 = 0.42, p \ 0.001) and SOFA score (R 2 = 0.48, p \ 0.001) throughout the ICU stay and was consistently higher in non-survivors than survivors during the first 2 weeks in the ICU. CONCLUSIONS. The highest TISS-28 scores are observed on the day of admission to the ICU with marked variations according to the type of surgery. TISS-28 correlates well with the severity of sepsis syndrome and outcome in these patients. Our data could be helpful in ICU planning, risk stratification, and resource allocation in the surgical ICU setting. INTRODUCTION. Pain and opioids for treatment of pain can affect immune function in cancer patients, which may in turn influence metastatic capability of a primary tumour during and after surgical excision. It is also been shown morphine has a direct effect on cancer cells, but results of these studies have been conflicting. We therefore aimed to determine effect of morphine, commonly used in anaestehsia and intensive care, on in vitro breast cancer cell migration using two breast cancer cell lines. We used two cell lines: MCF7 is ER positive breast cancer cell line while MDA-MB-231 is ER negative, less differentiated and more invasive. Cells were incubated with or without morphine (concentrations 10-100 ng/ml) for 12, 24 and 36 h, corresponding to clinically relevant concentrations and exposure times. Cell proliferation was determined using an MTS (Promega Inc.). 24 h cell migration was determined using a 96-well flourescent kit (Chemicon). Results were compared using independent sample t test for differences between the groups. Morphine had positive effect on cell proliferation, which was greater in MDA-MB-231cells. Proliferation of MDA-MB-231 was increased the most at 12 h incubation and higher concentrations (100 and 75 ng/ml caused 41 and 26% increase in proliferation at 12 h incubation and up to 25% increase at 36 h incubation). Proliferation of MCF7 cells was increased by 4% in 24 and 36 h incubation periods. Morphine caused an increase in migration of both cell lines, which was again more evident with MDA-MB-231 cells at higher concentrations of morphine (23, 10% and 44% increase with 100, 75 and 50 ng/ml respectively). Our experiments have shown morphine has potential to directly stimulate breast cancer cell proliferation and migration in vitro, especially in less differentiated breast cancer cell line. Further studies are needed to determine its effect on other metastatic mechanisms such as invasion and gene expression as well as the implication of these results for clinical practice. OBJECTIVES. Aim of this study was to evaluate the predictive value of NT-proBNP levels and inflammatory markers (CRP, IL-6, TNF) on late mortality in patients who underwent thoracic surgery for lung cancer. METHODS. 21 patients median age (61 ± 11 years) without history of heart disease or renal failure. The blood tests for NT-proBNP, CRP, IL-6 and TNF analyses were drawn one day preoperatively, 1 h, 48 h and 7 days postoperatively. Patients' demographic data, laboratory results and mortality were collected and assessed. RESULTS. NT-proBNP at 48 h was significant higher in non-survivors (1,330 ± 1,489 pg/ ml) compared to survivors (364 ± 231 pg/ml, p = 0,026). Furthermore, NT-proBNP at 48 h was associated with survival in the cox-regression analysis (p = 0.038, HR = 1,073, 95% CI: 1,004-1,147, units: 100 pg/ml). CRP preoperatively was significant higher in non-survivors (64 ± 49 mg/dl) versus survivors (12 ± 18 mg/dl, p = 0,002). IL-6 preoperatively was significant higher in non-survivors (61 ± 42 pg/dl) compared to survivors (20 ± 16 pg/dl, p = 0.011). CONCLUSIONS. High NT-proBNP levels at 48 h postoperatively, associated with increased mortality in patients undergoing thoracic surgery but there was no relation ship between CRP, IL-6 and mortality. INTRODUCTION. The occurrence of post-operative delirium in elderly orthopaedic patients is associated with neurological complications and cognitive decline [1] . Although the etiology of the decline is less understood, cerebral ischemic events may be involved [2] . High plasma concentration of N-methyl-D-aspartate (NMDA) receptor antibodies (NR2Ab) has been proven highly predictable for occurrence of the postoperative neurological events in cardiac surgery [3] . OBJECTIVES. The aim of the present study was to investigate the predictive value of blood levels of NR2Ab for postoperative delirium, cognitive dysfunction or any other neurological complications after hip and knee replacement surgery. METHODS. The study enrolled 47 consecutive patients, aged over 65, requiring acute or elective knee or hip replacement surgery. Cognitive impairment was evaluated by minimental state evaluation (MMSE) test administered before and after surgery. Daily postoperative delirium was evaluated by confusion assessment method for intensive care unit (CAM-ICU). Plasma levels of NR2Ab were recorded before surgery, at the moment of hospital discharge (10-14 days postoperative) and 6 weeks after discharge. All other possible risk factors for postoperative delirium were also recorded. Cognitive decline was present in 16 patients (34%) before surgery and in 35 patients (74%) at the moment of hospital discharge (p \ 0.0002). Plasma levels of NR2Ab were 1.30 ± 1.85 ng/mL preoperatively, 1.28 ± 1.01 ng/mL at the moment of hospital discharge and 1.61 ± 0.95 ng/mL 6 weeks postoperatively, with no significant differences. CONCLUSIONS. The incidence of cognitive decline in elderly patients after othopaedic surgery was significantly higher when compared with the preoperative status but there was no correlation between the cognitive decline and the plasma levels of NR2Ab. METHODS. Patients older than 18 years, whose performed endoscopic, colonoscopic or both procedures, under sedation performed by the Intensive Care Deparment of the Hospital del Tajo. Data were collected for 6 months. Demographic characteristics, medical history, ASA (American Society of Anesthesiologists classification), drugs bolus and total dosages, respiratory and hemodynamic data, the length of procedure and recovery, and complications were collected. Tolerance was assessed by endoscopist, with a 1 (very bad) to 5 (very good) scale. Quantitative data are expressed with mean and standar desviation, and qualitative data with percentage. RESULTS. 93 procedures were included. Table 1 shows main characteristics. Tolerance and complications are referred in Table 1 . The 91.4% of the procedures were appropriate (4 or 5) . The main complications were Vomiting (5.4%) and Hallucinations (12.9%). There were only 2 incidences of Respiratory Depression and 2 of Hypotension. BACKGROUND. The authors hypothesized that the efficacy and quality of a Remifentanil (R)-based regimen versus a Piritramide (P)-based analgosedation in major post-surgical patients with renal and hepatic impairments still more potent even if prevention of Narcotic Induced Hyperalgesia (NIH) [1] was done. The NIH was made by sulphate Magnesium (M), Ketamine(K) or Clonidine(C). METHODS. 66 patients were randomly allocated to receive a blinded infusion of either R at a rate of 0.15 l/(kg min) (±0.10) (G1: n = 33) or P at 0.2 mg/(kg h) (±0.15) (G2: n = 33) coupled to an hypnotic sedation of propofol. R and P were titrated in ICU after surgery, to achieve an optimal sedation as defined by a Sedation CONCLUSIONS. The remifentanil-based regimen allowed a more rapid emergence from sedation and facilitated earlier extubation diminishing total ICU hospitalisation time and cost. Even if we prevent the narcotic induced hyperalgesia by used of Magnesium, ketamine or clonidine, needs of tramadol in rescue still lower in the remifentanil group due to its high power coupled with its high fexibility compared to piritramide. Its reducing, by the way, risks of tramadol's metabolites accumulation in case of renal or leaver impairment.  A ''fast track'' approach to cardiac surgery has significantly shortened the length of ICU stay. However, quick awakening from anesthesia and subsequent extubation after discontinuation of sedative drug sometimes cause instability of hemodynamics, such as increase of BP or HR. Dexmedetomidine (DEX), a 2 agonist, is a sedative drug that can be continuously infused during weaning and extubation. The aim of this double-blind study was to evaluate the effect of DEX on time to extubation and hemodynamics during weaning from mechanical ventilation after cardiac surgery. With IRB approval and informed consent, the patients undergoing cardiac surgery were randomly divided into two groups, DEX group [infusion of 0.5 lg/(kg h) of DEX] and saline group. Drug administration was started at sternal closure and continued 24 h. Ramsay sedation score, times to extubation, systolic blood pressure, heart rate, respiratory rate, pulmonary artery pressure, central venous pressure, cardiac index were examined. We analyzed these parameters on ICU admission, when the patients opened their eyes on order, at immediately before extubation, 30 min, 3 h, and 6 h after extubation. Unpaired t test was used for statistics and p value less than 0.05 was considered significant. RESULTS. 24 patients were included in this study (n = 11 in the DEX group, n = 13 in the saline group). There were no significant differences between two groups in age, length of surgery, length of anesthesia, and total dose of propofol and fentanyl. Time to extubation was 625 ± 332 min in the DEX group and 446 ± 309 min in the saline group (mean ± SD), which were also no significant differences. Ramsay sedation score were maintained33 and no patients needed additional sedative drug during assisted ventilation in the DEX group. Althought mean systolic BP and mean PA, mean CVP, RR were similar in both groups during infusion. HR at eye opening, immediately before and after extubation were significantly lower in the DEX group than in the saline group. CONCLUSION. Our results demonstrated that the infusion of 0.5 lg/(kg h) of DEX decreased HR during weaning from mechanical ventilation. DEX could not only provide adequate sedation but also suppress the stress response after cardiac surgery. DEX is a useful sedative drug for preventing instability of hemodynamics on fast track approach. However, most anxiolytics impair intellectual function. Dexmedetomidine (Dex) is an alpha 2agonist that may offer sedation without overt cognitive decline. We performed a comparison between Dex and propofol (Pro), a drug often used for ICU sedation. METHODS. Prospective, randomized, double-blinded, cross-over study of 30 awake and intubated brain-injured (BI, n = 18) and non-BI (12) ICU patients, each receiving Pro and Dex using a cross-over design with periods of baseline (analgesic use fentanyl only), Drug A, interval washout (fentanyl only), Drug B. Sedation was titrated to a score of 0 or -1 (calm, cooperative) on the RASS and Hopkins NICS scale. Cognitive testing was performed at each study period using the validated 100-pt Hopkins ACE cognitive battery. OBJECTIVES. We evaluated the effect on final outcome of a treatment regimen with lowdose haloperidol initiated when a positive CAM-ICU occurred as a quality improvement project. METHODS. The CAM-ICU was previously implemented in daily care in all patients who stayed[48 h in our 10 bed medical-surgical ICU. In the first 9 months of the study (period 1), the CAM-ICU was used as an adjunct to daily care and the treatment of delirium was left to the physician on an intention to treat basis. Subsequently, a 2 month study pause was defined. Thereafter, in the second 9 months of the study (period 2), the CAM-ICU was judged to indicate the presence of delirium and haloperidol was directly started with a loading dose of 5 mg iv with subsequent daily dosing of 2.5-2.5-5 mg iv (age \ 70) or 1-  Oversedation is still common in many intensive care units (ICU) despite the demonstrated benefits associated with sedation sparing strategies, including shorter duration of mechanical ventilation, and shorter length of stay in the ICU and hospital. Our aim was to observe whether a minimal sedation policy could be feasible in a multidisciplinary Department of Intensive Care. Prospective observational study over a two month period (December 1, 2008 to January 31, 2009) in a 35-bed medico-surgical Department of Intensive Care of a university tertiary hospital. All adult patients who stayed in the ICU for more than 12 h were included. Data were collected on duration, type, dose, and indication for sedative and opiate analgesic agents. Self extubation was used as a safety surrogate. Disease severity was assessed by the APACHE II score within the first 24 h of admission. Statistical analysis was performed with SPSS software (SPSS incorporation, Chicago, IL, USA). A total of 335 patients (male 57%) with a median age of 61 years were included; 142 (42.4%) received some sedation, the majority [131 (92.3%)] during mechanical ventilation. Midazolam (54%) and propofol (49%) were the most frequently used sedative agents. The most common indications for sedation were: Early postoperative (50%), severe respiratory failure (19.7%), short term procedures (19.7%), and withdrawal syndrome (9.9%). The median percentage of time during which patients received mechanical ventilation without sedation was 87.5%, and was not related to severity as assessed by the APACHE II score (rho 0.10-p = 0.2). In the group of patients who required sedation for longer than just short procedures or uncomplicated postoperative care ([2h), the median percentage of time during which patients received mechanical ventilation without sedation was 73.6%. Analgesic opiates were often required (65%), predominantly by continuous infusion (56%). Morphine was the most frequently used agent (54%). Self-extubation occurred in 6 patients, but only 1 needed re-intubation. CONCLUSION. In a mixed medical-surgical population of critically ill patients, a strategy of minimal or no sedation (''sedationless'') is feasible and without major adverse effects. We propose that comfort, hemodynamic instability, and mechanical ventilation should be abandoned as usual indications for sedation. GRANT ACKNOWLEDGEMENT. DRS received grants from the doctoral fellowship program of CAPES/ Brazilian Ministry of Education and from the Federal University of Rio de Janeiro. R. Russai 1 1 The Royal Free Hospital, Anesthetics, Northwood, UK Postoperative cognitive dysfunction (POCD) is reported to occur frequently after cardiac surgery, even in low-risk patients. Predictors of neurocognitive deficits can suggest the potential etiology and outcome of patient that has developed POCD. There is a wide range of neurological manifestations from subtle cognitive impairment to deadly stroke. Over a period of 20 weeks a population of 376 patients underwent cardiac surgery in our hospital. We have looked for any signs of POCD in correlation with the possible etiology. Data have been collected prospectively focusing on Past Medical History (PMH), Possible Contributors, Manifestation, Complications and Treatment. POCD has occurred in 25 patients (21 male, 4 female) with age range of 45 to 90 years (median age 73 years), of whom 28% has had PMH of neurological impairment (predementia; cerebrovascular disease). Multifactorial etiology was found: Respiratory Failure 32%, Morphine 26%, Tramadol 15%, Renal Failure 12%, Remifentanyl 9%. In 2 patients no related causes were recognised. All 25 patients showed confusion as leading manifestation, although in 20 patients confusion presented in combination with aggressive behaviour (11), cognitive dysfunction (6), paranoia (3). In 15 occasions POCD resulted in major complications such as difficulties in airway management (5), removal of CVP line (4), removal of Arterial line (6). The majority of patients (22) required pharmacological treatment with single or multiple drugs therapy, the most common used was Haloperidol (48% pts). The average length of stay in ITU was 6.7 days, and the average length of hospital stay was 22.5 (6-102) days. CONCLUSION. POCD is a common and potentially devastating complication with a complex and broad etiology, which may affect the rehabilitation process and the final outcome. Early diagnose is essential for personalise treatments and therefore preserve in both life quality and life expectancy. INTRODUCTION. Sedation and analgesia is given to the ICU patient for adaptation to the intensive care environment. However, side-effects of drugs used are increasingly acknowledged as negative factors increasing the risk of delirium, vasopressor therapy, prolonged ventilation and length of stay. OBJECTIVES. The purpose of the proposed study was to study the practice of sedation in Norwegian ICU's and the challenges experienced by nurses and physicians. A national postal survey for clinicians in all Norwegian ICU's was conducted in September and October 2007. All intensive care units treating mechanically ventilated patients for more than 24 h (N = 54) were included. Two respondents from each unit (1 intensive care nurse and 1 ICU physician) were invited to answer the questionnaire. The survey was based on two previous Danish surveys. Questions on practice and perceived problems were scored on a numeric rating scale and a Lickert scale, as well as a few questions with response categories based on theme. RESULTS. The response rate was 93% (n = 100). All 54 ICUs were represented with 53 nurses with formal education in intensive care and 47 physicians specialized in anesthesiology as respondents. Written protocols are not routine in Norwegian ICUs, but half of the departments titrated sedation according to a scoring system, most commonly MAAS. The most commonly used sedatives were propofol and midzolam, while fentanyl and morphine were the most used analgesics. The main indication for sedation was to achieve tolerance to ventilation and to treat other bothersome symptoms. Side-effects were reported to be frequent with both sedatives and analgesics. The most frequent side effects (% reported as often present or always present) with sedative agents were circulatory instability (74%), delayed awakening (64%) and sleep disturbances (48%), while the most frequent side effects experienced with analgesics were gastrointestinal problems (75%), circulatory instability (53%) and delayed awakening (47%). The main indication for tracheostomy was reported as longterm ventilation and the wish to reduce sedation. DISCUSSION/CONCLUSION. Written protocols were not routinely used. Side-effects of sedation are perceived as a problem by the majority of clinicians, leading to circulatory instability and delayed awakening. Tracheostomy is used first of all to be able to reduce longterm ventilation and sedation. These results indicate a potential for new sedative agents and analgesics with fewer side-effects and more focus on the use of sedation protocols. [1] and has been associated with GABA agonist use [2] . Delirious patients may not be overtly agitated, so signs of delirium must be actively sought. The Confusion Assessment Method for the Intensive Care Unit (CAM-ICU) is a validated and easy to use screening tool [3] . In a recent study on this 13 bed medical and surgical intensive care unit (ICU), more patients who had received GABA agonists were delirious compared with those who were sedative free [4] . However, the percentage of patients having at least one episode of delirium was lower than expected (24%), perhaps because they were screened only once daily and in the daytime. We repeated this study with twice daily assessments (morning and after dark) and a larger number of patients in order to obtain a more accurate prevalence of delirium and confirm an association with GABA agonist use. METHODS. Two doctors attached to the ICU received a 30 min tutorial on using the Richmond Agitation and Sedation Score (RASS) and the CAM-ICU assessment tools. The CAM-ICU was performed on all rousable patients (RASS score [ -4) twice daily (morning and after dark). The following information was also noted: ( CONCLUSION. This study shows that the prevalence of delirium on this unit is comparable with published research [1, 2] and higher (44.3 vs. 24%) [4] when patients were screened after dark as well as in the daytime. The study shows that any sedating drug was associated with significantly increased prevalence of delirium. The unexpected higher prevalence of delirium in the patients receiving non-GABA agonists versus GABA agonists cannot be explained by haloperidol use to treat delirium. RESULTS. There were 93 patients in the 11 ICUs. The mean age was 61.2 years old with a predominance of Chinese (76.3%) and a slight male predominance of 57.0%. Forty-six per cent of the patients were mechanically ventilated and 14.0% had tracheostomy done. There were an average number of 4 devices per patient. Sedation was administered in 25.8% of the patients with no sedation scales used in a quarter of these patients. Only 20.8% of the sedated patients were on sedation protocol. The majority of patients (58.3%) were monitored hourly and on propofol (50%) and midazolam (37.5%). Up to 41.2% of sedated patients did not have daily interruption of sedation. There were no significant difference noted in the use of sedation between medical and surgical ICUs. Slightly more than a third of patients were given analgesia (n = 33) with no analgesia scales used in a third of these patients. One third of them were administered with paracetamol and about a third with morphine. Patients in surgical ICUs were more likely to receive analgesia compared to medical ICUs patients. Most of these patients (81.8%) were monitored hourly. Only 2 patients were on neuromuscular blockade. There was no usage of any formal delirium assessment tools at all with 38.8% of the patients being assessed for delirium based on clinical judgement of the caring team. Only 24% of the patients had some form of sleep promotion in the ICU. CONCLUSIONS. This national multi-center study reveals several deficits in the adult ICU with regards to sedation, analgesia and delirium assessment and management. Several initiatives should be implemented to improve patients' safety and quality of care in the ICU. METHODS. This study was conducted in 41 patients who visited emergency care center following caustic ingestion during a period ranging from January of 1998 and August of 2008, in whom a retrospective analysis of medical records was performed. Findings for the esophageal lesion were classified according to the change of the esophageal wall and the infiltration of periesophageal soft tissue. Also, clinical, laboratory, and endoscopic data from this patients were reviewed. The correlation between the degree of esophageal damage seen on CT scans and esophageal constriction seen on esophagography were then evaluated. A total of 41 cases of caustic ingestion were identified (age range, 20-82 years). The most common caustic agent ingested was acid (70%). The most frequent cause for ingestion was attempt of suicide (70%) as opposed to accidental (30%). The findings of thoracic CT in 41 patients were follows: first-degree esophageal injury in 4 (9.8%), seconddegree in 8 (19.5%), third-degree in 17 (41.6%), fourth-degree in 12 (29.3%). Fourteen patients (34.1%) developed caustic esophageal stricture. The degree of esophageal damage got closer to grade IV, the more prevalent esophageal constriction became. This correlation was statistically significant (p \ 0.001). Of the total 41 patients, 26 underwent endoscopy in the early stage after they visited emergency care center. An analysis of the correlation between the degree of esophageal damage seen on endoscopy and that seen on CT scans was performed. This revealed a significant correlation (p = 0.002, r = 0.585). CONCLUSIONS. Thoracic CT grading suggesting periesophageal soft tissue infiltration and fluid collection (grade III to IV) rather than only edema (grade I) may be associated with stricture formation. Early CT grading was very safe and useful for predicting the development of stricture induced by caustic ingestion. CONCLUSION. In our area critical care transport teams provided safe transfers for critically ill patients.Adequate preparation, strict adherence to checklists and adequate personal are the key of optimal solving of problems. INTRODUCTION. Although endovascular repair of traumatic aortic injury (ERTAI) has revolutionized the practice of vascular surgery, many questions still remain unanswered. Endoleaks, coverage of the left subclavian artery, stent fold/collapse, access complications and durability are the most important complications associated with the procedure. We describe our experience with stent fold/collapse after endovascular repair of blunt aortic injury in otherwise healthy and young patients. From January 2005 to December 2008, 14 patients (mean age 39 years, mean APACHE score 11, mean length of stay 13 days) who underwent endovascular repair of a blunt aortic injury were admitted in our ICU. Every day clinical examination and invasive blood pressure monitoring were employed for all our patients. When persistent hypertension was detected, transthoracic (TTE) and transoesophageal echocardiography (TEE) were initially used, followed by spiral computed tomography (CT) and angiography as confirmatory methods. Of the 14 patients, 4 (28%) developed a pressure gradient of [50 mmHg at the level of the stent that was initially investigated with Continuous Wave Doppler at the descending thoracic aorta (suprasternal view). The complication presented with refractory hypertension (requiring more than two classes of antihypertensives in high doses) and difficult weaning. The cause of hypertension in 1 of those 4 patients was a stent collapse, while in the other 3 patients the stent appeared folded but not collapsed. Endograft revision by open surgery was necessary in 1 of the 4 patients. CONCLUSION. The absence of especially designed grafts for the treatment of blunt aortic injury and the subsequent use of oversized grafts are associated with severe complications. Refractory hypertension after ERTAI can be a manifestation of poor stent alignment and/or stent collapse. Echocardiographic monitoring proved to be a useful tool in the early diagnosis of this kind of stent-graft complication. As far as we know, it is the first time that echocardiography is described in the relative literature as an early diagnostic technique for this serious complicationction.  Facing an aging population, the number of interventions of the French Emergency Medical Service (EMS) among very elderly is increasing. A previous retrospective study showed that except from out-of-hospital cardiac arrest survival to discharge was remarkably high after EMS intervention for life-threatening pathology [1] . The aim of the present study was to evaluate prospectively outcomes of very elderly patients managed by EMS. METHODS. After IRB approval, we conducted a prospective study over 1 year, including all patients aged 80 years or more managed by our physician staffed EMS department. Characteristics of patients including previous medical status (McCabe and Knaus scoring systems), functional independence (Katz ADL scale), clinical conditions, the Index de Gravité Simplifié Ambulatoire (IGSA) severity score were recorded. Patients were followed until their hospital discharge. The 3-month mortality was recorded as well as the ADL score. Data are expressed as mean ± SD, median [IQR] or percentage of patients and compared using univariate and multivariate analysis. A p \ 0.05 was considered the threshold for significance (*). RESULTS. Of the 523 patients included, 53 died on-scene, 440 were transferred to the hospital and 30 patients were left on scene because of significant improvement in medical status making hospitalization unnecessary, or on the contrary in near-death situations. Mean age was 86 ± 5 years (214 men). Their ADL was 2 (0-9) and 63% of patients were living at home. Main conditions were pneumonia (n = 80), acute coronary syndrome or chest pain (n = 76) and acute pulmonary oedema (n = 67). At 3 months, survival rate was 66% (n = 273). The proportion of patients living at home was 64% and ADL among survivors was 2 (0-8) (vs. 1 (0-6) initially for this subpopulation, p = 0.01]. When compared with deceased patients, survivors were significantly younger (86 ± 5 vs. 87 ± 5 years*), had lower ADL Penetrating anterior chest wounds causing cardiac injury are typically fatal, with only 6% of patients surviving to reach hospital. While the majority of patients with thoracic trauma can be managed conservatively or with simple intercostals catheter, a small but significant number of blunt (10%) and penetrating (15-30%) injuries, require Emergency Resuscitative Mediam Sternotomy as a component of initial resuscitation. CASE REPORT. A 35 years old men, fall from 20 meters high, while working in a truss. He was immobilized with semirigid cervical collar and backboard in the scene and transport to our trauma center, witch was a 1 h car-distance. Anesthesiologist Team was present since the initial management in Emergengy Room (ER) and act according to Advanced Trauma Life Support principles. In primary survey, patient was paraplegic, had a GCS of 14/15, a normal respiratory rate, a slight hypotension and a slight tachycardia. When Surgeon places a chest drainage, it drains immediately more than 1,500 ml blood, and the patient vital signs started to fade, to extreme bradicardia. The patient was then intubated with a rapid sequence intubation, with a single lumen endobronquial tube, and ventilated with protective lung ventilation. Hypotension postinduction was promptly treated with vasoactive drugs (nor-adrenaline and dobutamine) and ongoing volume resuscitation. An Emergency Resuscitative Mediam Sternotomy incision was perfomed in the ER and reveled a Clavicule and Sternum fracture and laceration in the Braquiocephalic artery which has repaired. Maintenance was performed with total intravenous anesthesia with fentanyl and nondepolarizing muscle relaxant. Monitoring include standard monitoring plus direct arterial and central venous pressures. During the surgical procedure we treat massive blood loss, with multiple transfusions of 17 units of red blood cells (unmatched type-specific), seven units fresh plasma, and 2 pools of plaquets, fibrinogen and cryoprecipitate. At the end of the surgery, still ongoing blood loses, made us suspect of coagulopathy, and to use Octaplex Ò . It was also performed a nasal tamponade, to stop severe epistaxis and suture a major scalp wound with evidence of basal skull fracture. Patient was transferred to an intensive care unit (ICU) ventilated.We was extubated at the 18th day post-operative. After 27 days, he still remains in ICU, because he is recovering from lumbar spine fixation for a total fracture-dislocation of D8-D9. DISCUSSION. Although he remains paraplegic, we think Emergency Sternotomy have had a significantly impact in this life-threating situation. The use of Cell-Saver Ò would have been beneficial, but it was unavailable in ER. We included only patients attended in this Unit by ICU personnel. These patients belonged to the area assigned to Cruces which has been reference centre of the northern area of Spain until December 2008. We collected all the information needed from the clinical history and the treatment sheet, and used the SPSS 15.0 programme to perform the statistic analysis. RESULTS. We found 83 patients that meet the severely burned patients criteria and that were attended by the ICU personnel in colaboration with the Plastic Surgey Unit. Their medium age was 49.88 ± 19.29 years, 77% of those patients were men, and the medium burned body surface was 32 ± 21.59%. These patients remained hospitalized in this unit during a medium time of 28.43 ± 21.7 days. During their stay, the 100% of them needed mechanical ventilation, 36% presented acute renal failure, 57% had a PaO 2 /FiO 2 less than 300, and 75.9% suffered some kind of infection. METHODS. Prospective and observational study developed in a Burn Unit, in which were included all patients with Total Surface Body Area burn (TSBA) [ 20% and/or Inhalation Syndrome who were admitted in our Unit from March 2007 to December 2008. We used transpulmonar thermodilution by means of monitor PiCCO Ò in a total of 10 measurements per patient (admission and every 8 h). We collected measurements of Cardiac Index (CI), Intrathoracic Blood Volume (ITBV), Extravascular Lung Water (EVLW), Inhalation Syndrome or not (it was diagnosed by broncoschopy), percentage of TSBA and Abbreviated Burn Severity Injury Score (ABSI) in a total of 40 patients.The average change of measurements of CI, ITBV and EVLW was studied in the following determinations and their association with few factors with a general and lineal model of mixed effects longitudinal data unbalanced. RESULTS. The evolution of thermodilution measurements was the following (Graphic 1) Cardiac Index: CI 1 = 2.83, CI 2 = 2.6, CI 3 = 2.86, CI 4 = 3.14, CI 5 = 3.41, CI 6 = 3.7, CI 7 = 3.95, CI 8 = 4.13, CI 9 = 4.37, CI 10 = 4.37. Intrathoracic Blood Volume: ITBV 1 = 753, ITBV 2 = 733, ITBV 3 = 783, ITBV 4 = 742, ITBV 5 = 757, ITBV 6 = 813, ITBV 7 = 890, ITBV 8 = 896, ITBV 9 = 923, ITBV 10 = 908. Extravascular lung water: EVLW 1 = 6.78, EVLW 2 = 7.3, EVLW 3 = 7.82, EVLW 4 = 8.74, EVLW 5 = 8.71, EVLW 6 = 8.65, EVLW 7 = 9.31, EVLW 8 = 9.13, EVLW 9 = 8.71, EVLW 10 = 8.37. In our serie, 75% of patients were male and the average age was 50.12 (20-86). Nine out of all the patients (22.5%) suffered inhalation syndrome, the average ABSI was 8.69 (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) and the average of TSBA was 37% (20-95%). Mortality in our serie was 25% (10 patients).CI and ITBV measurements increased significantly while the reanimation advanced (CI p 0.0001) (VSIT p 0.0001). In EVLW we only find significantly differences in post hoc study between first measurements and fourth one (p 0.03), 5th (p 0.04), 6th (p 0.04), 7th (p 0.007), 8th (p 0.01) and 9th (p 0.04).In the EVLW/ITBV ratio (permeability Index = PI) we did not observe significantly changes in the evolution.The inhalation factor did not change CI outcomes neither magnitude nor in the measurements evolution (p 0.48 and p 0.71 respectively), the same form, ITBV (p 0.73 and p 0.28 respectively), but inhalation modified EVLW (p 0.04) and the Permeability Index was in the signification stadistic limit (p 0.06).Mortality was higher in patients who CI was lower and EVLW was in higher values. CONCLUSIONS. Thermodilution in the reanimation period in critically ill burn patient shows significantly haemodynamic changes in the evolution that can help to adapt the treatment.The inhalation syndrome only modified the measurements of EVLW significantly in this period but it influenced neither CI, ITBV nor PI. INTRODUCTION. One major issue in trauma management is to get every patient directly from the scene to the appropriate hospital for the injury he sustained. Patterns of interfacility transfers have been thouroughly investigated in trauma system settings, but scarce data are available about transfers in non trauma system settings. OBJECTIVES. This study aims to assess interfacility transfers that eventuate in the abscence of a formal trauma system and to estimate the potential benefits from the implementation of a more organized process. The 'Report of the Epidemiology and Management of Trauma in Greece' is a one year project of trauma patient reporting throughout the country. It provided data concerning the patterns of interfacility transfers. In Greece there is no formal trauma system employed and to our knowledge, all available data concerning the epidemiology of trauma in the country are either extrapolations of relevant data from other countries or based on police reports and individual hospital reports. In this study, we attempted to evaluate the paterns of interfacility transfers, Information reviewed included patient and injury characteristics, need for an operation, intensive care unit (ICU) admittance and mortality. Trauma patients were devided in two groups, the transfer group was compared to the non-transfer group. Analysis employed descriptive statistics and Chi-square test. Interfacility transfers were furthermore assessed according to each health care facility's availability of five requirements; Computed Tomography scanner, ICU, neurosurgeon, orthopedic and vascular surgeon. RESULTS. Data on 8,524 patients were analyzed; 86.3% were treated at the same facility, whereas 13.7% were transferred. In transferred group there were more male, the mean age was lower than that of the non transferred group and the injury severity score was higher. Transferred patients were admitted to ICU more often, had a higher mortality rate but were less operated on compared to non-transferred. The transfer rate from facilities with none of the five requirements was 34.3%, whereas the rate of those with at least one requirement was 12.4%. Facilities with at least three requirements transferred 43.2% of their transfer volume to units of equal resources. CONCLUSIONS. The assessment of interfacility transfers can reflect current trends in a nontrauma system setting and could indicate points for substantial improvement. RESULTS. 1,090 patients included, 2,172 injuries analyzed. Average age was 36.5, 79.5% men. 43.3% were car accidents, 20% falls, 13.8% motorcycle, 6.6% run over and 2.2% bicycle. 49.9% had one injury, 30.8% two and 15.1% three. Most frequent injury was TBI (33.7%), thoracic traumatism (20.2%) and ortophaedic (15.6%); severe TBI was 56.4%. CTrate according to Marshall classification was 38.1% II, 20.3% V and 12.6% III. ISS averaged 20, higher in dying patients than in the survivors (43 ± 21.6 vs. 20.1 ± 10.9; p \ 0.001). Of the non mechanical-ventilated patients, 43.2% were so in the first 12 h following admittance. During this, 31.6% patients were given blood transfusions, platelets 6.3%, plasma 14.6% and prothrombinic complexes 2.2%. In the first 24 h 36.4% underwent surgery, most frequent was neurosurgery (52.8%). Complications: nosocomial pneumonia (25.3%), catheter related bloodstream infection (6.9%), acute kidney injury (6.3%), ARDS (10.3%), CNS infection (0.9%). 2.4% renal replacement therapy. Invasive ventilation was used in 67.3% with 7.32 ± 11.7 days, non invasive ventilation in 0.8%. Average stay in the ICU was 4 days. 76.4% of the patients were transferred to a ward. 8.6% were transferred to another hospital. GOS on discharge was higher than 3 on 67.3%. 15% died in ICU, 7% brain death. TBI as a main injury showed a 32.4% mortality rate. Depending on trauma type, mortality was higher in fall (40%) and run over (27.1%). If due to car accident (14.4%), motorcycle (27.1%) or bicycle (4.3%), mortality in ICU was lower (p \ 0.001). Prehospitalary variables related to mortality were age, GCS \ 7 and a motor component \ 5, pupil alteration, shock, respiratory failure, prehospitalisation intubation and ISS (p \ 0.001). On arrival to hospital, the variables were: haemodynamic instability in the first 12 h, transfusions need and number, Marshall IV-VI, mechanical ventilation (p \ 0.001) and initial fibrinogen (p \ 0.05). Evolutive variables related to a higher mortality rate were days of stay, invasive ventilation, tracheostomy and the show up of complications (catheter related sepsis -p \ 0.01-, nosocomial pneumonia, acute kidney injury, ARDS, renal replacement therapy (p \ 0.001). In a logistic regression model, prehospitalisation variables having an influence on ICU mortality rate were age (OR 1.05; p \ 0.001), mydriasis (OR 2.9; p \ 0.005), GCS-motor component (OR 0.7; p \ 0.001), shock (OR 3; p \ 0.001) and ISS (OR 1.1; p \ 0.001). CONCLUSIONS. Multiple trauma patients show a high need of resources, with many peaks of treatment involving a high monitorization and handling. Many of the variables are related with a higher mortality rate in ICU: ISS, mydriasis, GCS motor component and shock. INTRODUCTION. Trauma systems are multifactorial modules that incorporate any aspect of traumatic injury from the very moment of the injury to the final outcome. A significant prerequisite for the development of a trauma system is the trauma registry. Trauma registries are the actual core of any trauma system since they provide valuable information about the standard of care offered to the patients and are amenable to quality control and statistical evaluations, which in turn allow improvements and amendments in the definite care. Contrary to what is common practice in the USA, trauma registries in European countries are in embryonic stage. In our country with no actual trauma system, the epidemiology of trauma and the reports on care outcomes are based on police reports and National Emergency Service reports. OBJECTIVES. The purpose of this study was to assess the possibility of a National Trauma registry in Greece and to provide accurate data on the epidemiology of trauma in the country. METHODS. The project, entitled ''Report of the epidemiology and management of trauma in Greece'', was initiated in October 2005 and lasted for twelve months. All the national representatives of the Hellenic society of Trauma were invited to participate. The representatives are certified surgeons employed in hospitals receiving trauma. Data presented here are those reported from two tertiary care facilities in Athens and twenty eight other primary and secondary hospitals around the country. Inclusion criteria were defined as trauma patients with documented need for admission in the hospital, patients that arrived dead or died in the emergency department of the receiving hospital and patients that required transfer to a higher level center. In total 8.862 trauma patients were included in the study in twelve months time. Of them 68.7% (n = 6,084) were male, aged 41.8 ± 20.6 (mean ± SD) and 31.3% were female (n = 2778), aged 52.7 ± 24.1 (mean ± SD). As expected and reported in most trauma registries, males are leading in all subcategories of ISS. The age group 0-54 years incorporates 68.4% of the total injuries, in accordance to the axiom that trauma is the disease of the young. CONCLUSIONS. Trauma registries are the cornerstone of any trauma system. Even in a non-trauma system setting, registries are a valuable tool for quality control of the provided health care and for further development of the health care system. OBJECTIVES. Determine the impact of rurality in epidemiology, injury severity, health care facilities, length of stay (LOS), mortality, functional outcome and quality of life in trauma patients. Retrospective study in trauma patients that were admitted in our Emergency Room(ER) between 2001 and 2008. Data was collected from the prospective trauma registry and follow-up registry 6 months after the accident. We classified patients according to Statistical National Institute classification: Urban areas-areas with more than 500 inhab/km 2 or have a place with more than 5,000 inhabitants; Semi-urban areas-areas with more than 100 inhab/km 2 and less than 500 inhab/km 2 or have a place with more than 2,000 inhabitants and less than 5,000 inhabitants; rural areas-areas that were not classified as semi-urban or urban areas.Patients were divided in three groups according to residence area: R (rural), SU (semi-urban), U (urban). We studied several variables in order to find a relation with rurality: sex, age, type of injury, LOS in hospital and intensive care (ICU), anatomic severity (AIS), politrauma severity (ISS), physiologic severity (RTS), surveillance probability (TRISS index), pre-hospital care, previous admission in other hospital, ICU admission and mortality. We report two outcome measures: Euroqol to evaluate quality of life and Extended Glasgow Outcome Scale for functional outcome. We used Qui-square test, T test, Mann-Whitney test, Kruskal-wallis test for statistic analysis. RESULTS. 1,311 patients were admitted in the ER. 161 patients (12.3%) were excluded with missing data related to residence area. We studied 1150 patients, where 214 patients were from rural areas (18.6%), 219 from semi-urban areas (19%) and 717 from urban areas (62.3%). We find a statistical significant relation between rurality and pre-hospital care, previous admission in other hospital and ICU admission. Urban area patients had a higher incidence of pre-hospital care(R: 12.2%; SU: 17.7%; U: 70.1%, p \ 0.01). Semi-urban and rural patients were admitted more frequently in other hospitals before admission in ER (R: 89.2%; SU: 85.8%; U: 61.9%, p \ 0.01) and also had higher admissions in ICU (R: 82.2%; SU: 78.5%; U: 72.4%, p \ 0.006). There were no statistical differences in the other variables studied. CONCLUSIONS. Rural trauma patients are similar from those that live in urban areas concerning epidemiology, injury severity and outcome. Despite lack of pre-hospital care and higher previous admission in other hospital in rural patients, mortality between groups did not differed in our trauma centre. INTRODUCTION. Metformin-associated lactic acidosis (MALTA) is a rare but severe complication (0.08/1,000 patients/year) of metformin treatment in type-II diabetes. Metformin impairs neoglucogenesis and liver lactate clearance in the presence of a disease that enhances its production. Although frequently used, there is no recommendations regarding hemodialysis in this poisoning. To study the prognostic factors of MALTA and the interests of blood metformin measurement. . On admission, patients presented profound lactic acidosis with arterial pH 7.19 (6.84-7.31), serum bicarbonate 11.0 mmol/l (6.8-15.6) and plasma lactate 17.2 mmol/l (9.8-19.7). Early symptoms associated coma (50%), asthenia (47%), vomiting (27%), abdominal pain (27%), and diarrhoea (20%). Renal function was significantly altered [creatinine clearance: 37 ml/ min (14-54); p \ 0.001). All patients received massive alkalinization, 12/16 (75%) were hemodialyzed while 10/16 (63%) were mechanically ventilated and received catecholamines. Six patients (38%) died in the ICU. Duration of ICU stay was 3 days [3] [4] [5] [6] [7] [8] [9] [10] . There was no significant differences regarding MALTA severity and treatments between suicidal and accidental poisonings. Neither lactic acidosis severity nor acute renal failure were predictive of death. There was no correlation between prognosis and the time-course of plasma metformin concentrations, with or without dialysis. Toxicokinetics showed significant tissue distribution when the patient was early admitted or plateaued concentrations if he was later admitted and survived, even though his situation improved and his lactates decreased. Metformin dialysance suggested an interest for extra-renal elimination enhancement although its impact on survival could not be analysed based on this limited study. Our study showed that MALTA is severe with elevated mortality in ICU whatever the poisoning is accidental or intentional. Metformin toxicokinetics are useful case by case to better understand the patient's outcome. The most important guidelines [1] for Trauma Care recommend (US)-FAST as the first step investigation to rule out major bleedings. However, US is less sensitive and accurate than multislice computed tomography (CT). The spreading concept that ''moderrn CTs require little time'' often brings surgeons to ask for total body CT also in haemodynamically unstable patients. To understand how long it really takes to perform a total-body CT in patients suffering from major Trauma (MT) we analysed the data of the RITG project, a pilot multicenter study to define the national standards for trauma care and establish a National Trauma Registry. METHODS. 3 Italian Level 1 Trauma Centers were involved into the first stage of the RITG project. Data of all Major Trauma patients (ISS [ 15) who were admitted to either one of the three hospitals during a 12 months period of time (01 July 2004-30 June 2005) were prospectively entered into the RITG database. Time between hospital admission and the first scan were recorded for all patients. Patients who, for any reason, were submitted to a CT with a delay of 120°or more were excluded. The time elapsed between the first scan and the patient's exit from the CT room was measured in a subset of 235 pts from a single Center equipped with a new generation CT next to the Emergency Room. During the Study period 753 MT patients were admitted to the three Trauma Center. 486 patients were submitted to an emergency total body CT scan within 120 0 . 12 patients died before arrival in the ED. 11 more died soon after admission and before the secondary survey. The interval times are shown in Table 1 . Seven patients died in the CT room. The average interval between hospital admission and the first available scan was 45°. However, even where a new generation CT next to the ER was used, the average time needed to stabilize the patients, get a correct position on the CT and start the scanning process was 34°as an average. In the most severely injured patients, who are frequently artificially ventilated, the time required to stabilize the patient and perform a total body CT scan is longer than expected and to a certain extent, independent from the CT scanner itself unless the very last technology as the sliding CT scanners are employed [2] , thus CT should be considered with extreme caution in the unstable patients. In univariate analyses, survival to discharge was significantly lower with two of 11 acute conditions (acute coronary syndrome and acute inflammation), and with five of 10 chronic conditions (chronic heart failure, diabetes mellitus, kidney failure, hepatic cirrhosis and malignancy). Recent surgery was strongly associated with higher odds of survival. The most consistent multivariate predictors of survival to discharge were liver cirrhosis (OR 0.32; 95% confidence interval 0.15-0.70) and malignancy (OR 0.40; 0.25-0.63). Malignancy was not predictive for outcome after CPR attempts, whereas liver cirrhosis was predictive both in all dispatches and in dispatches involving CPR. Recent surgery was strongly associated with higher multivariate odds of survival (OR 6.1; 2.2-16.4) after cardiac arrest. In dispatches without CPR, absence of chronic conditions was associated with higher likelihood of survival (HR 6.9; 95% CI 5.2-9.3). Increasing numbers of chronic conditions were significantly and continuously associated with lower survival (p for trend \ 0.0001). Advanced age only weakly predicted survival, but age C75 years was, along with malignancy, the strongest predictor of not attempting CPR in patients with cardiac arrest. CONCLUSIONS. Comorbidities are important determinants of survival after in-hospital MET dispatches, with and without cardiac arrest. Survival odds are lowest with malignancy and liver cirrhosis. Recent surgery increases odds of survival by exclusion of those most severely ill. Advanced age at best weakly predicts worse survival, but strongly predicts not attempting CPR. DESIGN. Retrospective, cohort study. SETTING. Emergency department (ED) and intensive care unit in a university hospital. MEASUREMENTS AND MAIN RESULTS. The study subjects included of 314 consecutive severe trauma patients. A systematic review of the computer-based medical records of the patients was conducted to provide the base line characteristics and DIC-related variables. The worst data of these variables were obtained at 4 time points within 24 h after arrival to the ED; Time Point 1, immediately after arrival at the ED to 4 h after the arrival; Time Point 2, 4 to 8 h after the arrival; Time Point 3, 8 to 16 h after the arrival; Time Point 4, 16 to 24 h after the arrival. One hundred and forty one patients (141/314, 44.9%) diagnosed as JAAM DIC showed significant differences in the prevalence of multiple organ dysfunction syndrome (MODS) and the outcome in comparison to the non-DIC patients. A stepwise logistic regression analysis showed that the maximum JAAM DIC scores during the study period independently predicted the patient death (odds ratio 1.338, 95% confidence interval 1.070-1.672). All of the patients who developed ISTH overt DIC during the study period could be identified by the JAAM DIC criteria at early time points. The mortality rate and the incidence of MODS of the patients with the ISTH overt DIC were higher than those only met the JAAM DIC criteria. Stepwise increases in the ISTH overt DIC scores and the incidence of the ISTH overt DIC were observed in accordance with the increases in the JAAM DIC scores. While the mortality rates were identical, there were marked differences in the incidence of MODS and Sequential Organ Failure Assessment scores between the DIC patients associated with trauma and sepsis. CONCLUSIONS. The JAAM scoring system has acceptable validity for the diagnosis of DIC at an early phase of trauma. The JAAM DIC further exists in a dependent continuum to the ISTH overt DIC. In addition to MODS, other factors may affect the prognosis of the trauma patients associated with DIC. INTRODUCTION. In the UK, more than 300,000 units of fresh frozen plasma (FFP) are transfused every year. Since 2004 there has been a reduction of 16% in its use, but it has been suggested that as many as 47% of transfusions in critical care may be inappropriate. There is significant morbidity associated with the transfusion of FFP. Guidelines for the use of FFP do exist, but the indications for its use are limited. Coagulation studies, such as prothrombin time (PT), abnormalities are often assumed to be a risk factor for bleeding prior to invasive procedures, but evidence suggests that FFP may not have a prophylactic role. In addition to this the PT or International Normalised Ratio (INR) were not intended to assess haemostasis in patients without a history of bleeding. Review of the blood bank database between 1st January 2008 and 31st December 2008 revealed all prescriptions of FFP for patients on intensive care (ITU). The case notes were analysed to find the indication and timings of administration and weight of the patient. The pathology database was examined to find the clotting studies immediately before transfusion. In 2008 98 patients received FFP; this was only 6.8% of the total admissions to the ITU. There were 170 prescriptions and a total of 462 units transfused. The mean prescription of FFP was 2.7 units and overall each patient received a mean of 4.7 units. The mean dosage of FFP was 9.96 ml/kg. The PT pre-transfusion mean was 24.0 ± 13.6 s with a median of 19.7 s. The APTT pre-transfusion mean was 52.1 ± 20.0 s with a median of 46.1 s. Only 6.5% of transfusions had not had a clotting screen done prior to administration of FFP. 32% of administrations were given prior to procedures being undertaken on the ITU and a further 10% were given in preparation of the patient for the operating theatre. A significant number of patients are receiving FFP outside international guidelines. A third of transfusions were given for prophylactic correction of coagulopathy prior to an invasive procedure where there is least evidence for using FFP. Most patients received a sub-therapeutic dose of FFP; there is ongoing debate on the correct dosage required to normalise coagulopathy, but it is likely to be greater than 15 ml/kg. [1] . Little data exists on the demographics of MT and subsequent demand on a hospital's blood bank. We examined the MT requirements of a 1071 bedded tertiary referral hospital over a 20 month period. OBJECTIVES. To establish the MT demographic, speciality distribution, PRBC demand and associated mortality; within a tertiary referral hospital over a 20 month period. To assist with future MT logistics, planning, implementation and audit. METHODS. The hospital blood bank database was reviewed for cases of MT from Jan 2007 to Aug 2008. Inclusion criteria were the administration of C 10 units of (PRBC) within a 24 h period. Cross referencing with the laboratory records and medical notes was undertaken to establish patient demographics, hospital specialty, diagnosis, outcome and number of PRBC transfused. RESULTS. 59 patients received MT over a 20-month period; 34 male (57.6%) 25 female (42.3%). Median age 71 years (range 16-95). Median MT of PRBC was 12 (range 10-50) units. 881 units of PRBC were transfused in the treatment of MT during the study period, accounting for a hospital expenditure of over €175,000. The main specialties associated with MT were the: Emergency Department (17 patients, 28.8%), Cardiothoracic Surgery (13 patients, 22.0%), and 11 General Surgery (11 patients, 18.6%). 25 of the 59 patients receiving massive transfusions (42.3%), did not survive to hospital discharge. 56% of those patients who died, did so in the first 48 h with a further 4% dying in the next 24 h. 20% of the further deaths occurred within and 20% after thirty days. CONCLUSIONS. MT in our establishment is associated with a high mortality and predominantly early deaths. Recipients were generally elderly with significant co-morbidity. Provision of PRBCs and blood components for Massive Transfusion recipients, is challenging for blood bank services [2] . The demand of MT, within our establishment, was predominantly within the acute specialties; emphasizing the need for close communication between them and the laboratory services. In light of this data we propose the implementation of a MT protocol together with continuous audit, to assess its effect on outcome.  In 2007 the Department of Health updated the 'Better Blood Transfusion' circular, a drive to decrease the use of blood products which have become increasingly scarce and expensive [1] . There is evidence that blood product transfusions in ICU patients are associated with an increase in morbidity, length of stay and mortality. There has been concern over the increasing use blood products and despite guidelines [2] for their use, both national and local audits have demonstrated a high degree of inappropriate transfusion [3] . Derriford hospital is a 1071-bedded tertiary referral centre. The blood bank database was examined for the use of blood products on ICU from 1st January 1998 to 31st December 2008. There was a steady rise in ICU admissions from 1,131 patients in 1998 to 1,443 patients in 2008. During this time there was a marked decline in both the transfusion of fresh frozen plasma (FFP) and cryoprecipitate. The decreased use of these blood products has occurred with only a very modest introduction of new pro-coagulant therapies, prothrombin complex concentrate (PCC) and recombinant factor VIIa (rFVIIa). Usage of rFVIIa and PCC CONCLUSIONS. Our usage of blood products does not reflect the national trends of increasing use of cryoprecipitate and PCC with a small reduction in FFP transfusion, and is more in line with the HSC requirements for better use of blood products. This has been achieved with little use of the newer rFVIIa and PCC. The evidence for the use of all these blood products is not strong, particularly in critically ill patients. National guidelines exist for their use, but these are poorly adhered to.  To test the hypothesis that transfusion of PRBCs has a deleterious effect on clinically relevant outcomes in patients with septic shock receiving early goal directed therapy (EGDT). Retrospective cohort study of 93 patients who presented in an academic center in septic shock and received EGDT. Data was collected on patients identified via the Surviving Sepsis Campaign Chart Review database and linked to the Project IMPACT database. Pearson chi square and Fisher's exact test were used to test for clinical significance. Primary outcome was mortality and secondary outcomes included mechanical ventilation days, intensive care unit (ICU) length of stay, and hospital length of stay. . 89/93 patients presented via the Emergency Department. 34/93 patients received at least one PRBC transfusion during their hospital stay. The two groups were balanced with respect to age, gender, APACHE II, and baseline lactate levels. The PRBC group had a mortality of 41.2 vs. 33.9% in the no PRBC transfusion group (p = NS). The PRBC group also had more mechanical ventilation days (11.2 vs. 5.0 days, p = \ 0.05), longer hospital length of stay (25.9 vs. 12.5 days, p = \ 0.05), and longer ICU length of stay (11.4 vs. 3.8 days, p = \ 0.05). CONCLUSIONS. In this study, transfusion of PRBC was associated with worsened clinical outcomes in patients with septic shock treated with EGDT. This trial is limited by its small sample size and retrospective nature. However, the results are consistent with data from previous trials pointing to a deleterious effect associated with PRBC transfusion. Further studies are needed to determine the impact of transfusion of PRBC within the context of early resuscitation of patients with septic shock, as the beneficial effects gained by an early and goal oriented approach to resuscitation may be lost by the negative effects associated with PRBC transfusion. INTRODUCTION. Blood transfusion therapy (BTT) is thought as one of transplantation of living cell, that means BTT includes several risk such as infection and BTT should be thought to derived from precious material by courtesy of donors. Patients with traumatic cardiopulmonary arrest on arrival on the hospital (T-CPA) usually suffered from lethal hemorrhage and required rapid supplement of red blood cells for resuscitation of circulation and oxygen transport, that is to say BTT. However, the prognosis of T-CPA patients is well known hopeless. The aim of this study is to evaluate the propriety of our strategy concerning BTT for T-CPA patients. We retrospectively examined the medical records of T-CPA patients for the past 10 years. We do BTT until 1998 (the first period) for T-CPA patients regardless of ROSC without any restriction. After then (the second period), we do BTT case by case but only after ROSC in principle. The rate of ROSC, admission to ICU, survive to discharge were compared between these two period, and were compared within the first period between the patients group who underwent BTT (BTT group) and the group who did not underwent BTT (non-BTT group). In 477 blunt T-CPA and 29 penetrating T-CPA patients, 34 and 59% achieved ROSC, 18 and 38% admitted to ICU, and 3 and 14% were survive to discharge. In penetrating T-CPA in the first period, 12 units of packed red cells (PRC) were used before ROSC for 1 non-survivors. In the second period, no PRC was used for non-survivor before ROSC. In blunt T-CPA in the first period, PRCs were used for 29 non-survivors before ROSC. In the second period no PRC was used for non-survivors before ROSC. Concerning the effect of BTT on the prognosis of T-CPA in all cases, the rate of ROSC and admission to ICU were statistically higher in the first period than in the second period (p = 0.0003 and 0.032). However, there was no statistical difference in the rate of survive-to-discharge between these periods. There was a same tendency in witnessed cases. In cases with electrical rhythm on the scene, only the rate of ROSC were higher in the first period (p = 0.007). Restricted in the first period, only the rate of ROSC was statistically higher in non-BTT group than BTT group in all cases, in witnessed cases, and in cases with electrical rhythm on the scene (p = 0.005, 0.008, and 0.003). However, there was no statistical difference in the rate of admission to ICU and survive-to-discharge between these groups.. Our retrospective serial study showed a possibility that BTT before ROSC for T-CPA improves the success rate of ROSC but add no effect on the improvement of survival rate. BTT is thought to be futile for T-CPA before ROSC. MANAGEMENT OF REFRACTORY COAGULOPATHY DUE TO ADULT ONSET ACQUIRED AUTOIMMUNE HAEMOPHILIA. D. Hendron 1 , G. Allen 1 , M. Brady 1 , G. Benson 2 1 Belfast City Hospital, Intensive Care, Belfast, UK, 2 Belfast City Hospital, Department of Haematology, Belfast, UK We report a case of life-threatening haemorrhage occurring as a result of a rare acquired condition caused by the production of an antibody to clotting Factor VIII. This necessitated administration of recombinant activated Factor VIIa (Novoseven) to bypass this step of the clotting cascade. A 71-year-old man presented to intensive care following OGD for acute upper gastro-intestinal haemorrhage, with recent haemoptysis and haematuria. OGD had demonstrated a large clot obstructing the oesophagus and extending through stomach into duodenum. This could not be removed and no bleeding points were identified. A coagulopathy was detected which failed to correct with administration of appropriate amounts of fresh frozen plasma, cryoprecipitate and activated prothrombin complex concentrate (APCC), necessitating clotting factor studies. This demonstrated a Factor VIII level of 2% with a detectable antibody inhibitor. Acquired haemophilia was diagnosed and activated Factor VIIa was administered resulting in rapid correction of coagulation studies and arrest of haemorrhage. It was necessary to continue daily Activated Factor VIIa at a dose of 40 mg a day in addition to anti-inhibitor coagulant complex (FEIBA-VH)-an activated prothrombin complex with Factor VIII inhibitor bypassing activity. Definitive treatment of the coagulopathy was chemotherapy with Cyclophosphamide, Vincristine and Rituximab. This destroyed the Factor VIII inhibitor and returned his Factor VIII levels to almost 100%. Laparotomy and gastrotomy were required to relieve the oesophageal obstruction from the accumulated clot. He was eventually discharged from hospital and remains well. Acquired haemophilia is a rare haematological condition that presents with refractory haemorrhage and coagulopathy and these patients are likely to be referred to critical care services for ongoing support and management. It has an incidence of approximately 1.5 cases per million per year [1] . Underlying medical conditions can be identified in up to 50% of patients and include autoimmune disease, solid tumours, lymphoproliferative malignancies and pregnancy [2] . International recommendations on the diagnosis and treatment of patients with this condition have recently been published and advise recombinant activated Factor VIIa to control bleeding followed by a combination of corticosteroid and chemotherapy [2] . The paucity of cases presents an obstacle for randomised controlled trials and therefore these recommendations are based on anecdotal evidence and expert opinion. REFERENCE (S) OBJECTIVE. To analyze the application of blood transfusion in critically ill trauma patients after Wenchuan earthquake. A retrospective study was made in ICU of Huaxi hospital on patients who had received transfusion at least once during 1 month after the earthquake. Their primary diagnosis and clinical features and APACHEII score were obtained at admission. Non-active bleeding patients were classified into S group if operation was done during his ICU stay, otherwise N group. The function of liver and kidney, and the state of circulation and oxgenation were compared between groups, as well as the hemoglobin level before each transfusion were investigated. A total of 75 patients (52.8%) had received transfusion at least once, among which 55 were non-active bleeding. The average frequency was 9.6 ± 5.7 and 2.0 ± 1.5, amount was 7302.6 ± 5402.8 ml and 921.8 ± 709.9 ml, the incidence of transfusion-related complication was 10.4%(19/182) and 13.0%(14/108) in active and non-active bleeding patients respectively. The APACHEII score, mean arterial pressure, AST, serum creatinine, oxgenation index and hemoglobin level on day 1, 7, 28 after admission to ICU showed no statistically significant difference between S and N group. The frequency and amount of transfusion were similar also, while the Hb level before each transfusion was significantly lower in N group (87.4 ± 17.3 g/L)than in S group (75.6 ± 9.6 g/L) (p \ 0.05). The incidence of transfusion-related and infectious complications, time with ventilator and the 28-day mortality were similar. CONCLUSION. Transfusion strategy is more strict in ICU doctors than surgeons, while the similar result on organ function, incidence of complications and outcome raises the need for a more wide-accepted transfusion trigger. KEYWORDS. Earthquake trauma transfusion trigger.  Extracorporeal life support (ECLS) represents an ultimate rescue technique in poisonings. The optimal anticoagulation protocol remains unclear. OBJECTIVES. We aimed to investigate the coagulation status at ECLS decision in order to validate the best heparin protocol to administer. [5 packs (2-12) ] and fresh plasma [4 packs (2-12) ] transfusions were required within the first 24 h. Hemorrhages (9/57), thrombosis (3/57) or lower limb ischemia (4/57) seemed equivalent to previous series using more complicated anticoagulation protocols. CONCLUSIONS. Poisoned patients present at ECLS time with important alteration in their clotting tests, associated with various degrees of hepatocellular failure, DIC, defibrination, as well as dilution. A simple heparin protocol appears optimal to reduce complications in these critical situations. Henna is the dried and powdered leaves of the Henna plant. The plant is Lawsonia Alba and the powdered leaves are used to apply decorative designs over the skin. Henna application is widely practiced in the Arab and Asian communities. They create fascinating designs over the skin, especially over the hands and feet. It is widely practiced during wedding ceremonies and at childbirth. G6PD deficiency is common in the community of the Arab world. Lawsone, the chemical compound in the Henna leaves, is capable of inducing severe acute hemolysis in G6PD deficient cases. The compound is chemically related to Naphtha. We report a case of acute sever hemolysis in a young girl who presented with dizziness and jaundice and diagnosed to have acute severe hemolysis. Her symptoms had started while preparing for her wedding by henna application. The girl was G6PD deficient, and found to have severe hemolysis resulting from Henna application on her skin. Very few cases have been reported of similar nature. The matter is also of tremendous practical implication in areas of G6PD deficiency. The relevant literature is reviewed as well. BACKGROUND. Lactate has prognostic use in critically ill medical and trauma patients, and is a core component in identification of early sepsis. Elevated lactate levels in these patients prior to ICU admission, e.g. in an A&E setting or pre hospital setting identify patients at risk of death and can trigger an earlier optimization of triage decisions and earlier targeted treatment. A range of POC methodologies for lactate measurement are available but there is little standardization between methodologies. Stat Sensor Lactate is a new POC Lactate meter based on a patented multiwell and multilayer electrochemical technology that incorporates control wells that measure and correct for common interfering substances. The electrochemistry technology is layered onto a gold platform providing a stable and robust surface for the electrochemical reaction kinetics. The aim of this study was to assess the performance and functionality of Stat Sensor Lactate. Whole blood venous samples were collected from 100 adult patients admitted to A&E. Samples were tested for lactate using StatSensor Lactate (Nova Biomedical) and the Omni B221 BGA (Roche) routinely used for lactate measurement. Precision was assessed using donated whole blood and spiked with a concentrated lactate solution. RESULTS. Within run precision was acceptable at all levels tested. For the lowest level sample (mean 1.5 mmol/L) %CV for the two meters tested was (6.7 and 7.0%) at the three other levels tested (mean 5.8, 10.4, 23 .9 mmol/L) % CV precision was \4%. Lactate values during the method validation ranged from 0.6 to 11.1 mmol/L by the reference method (Nova 0.8 to 10.6 mmol/L BACKGROUND AND OBJECTIVES. This research work's intention is to describe the epidemiology in patients suffering from anemia who were interned into Emergency Room (ER). A preliminary work will be conducted in which three days in June will be randomly chosen. During these days, all patients satisfying certain criteria will be registered. The criteria fitted to this work are the following: be using the Emergency channel of the hospital, score any diagnostic and be over 14 years old. Paediatric, gynaecologic and traumatic cases fall out of this research. Anemia was diagnosed according to WHO criteria. OUTCOME. 861 patients were interned through the aforementioned ER channel. 44.6% were subject of blood analysis using classification proceedings. From the latter, 17.7% were diagnosed with anemia. Age, intake of clopidogrel and/or aspirin, admission and place of admission resulted statistically significant among anemia patients versus non-anemia. Anemia was to be found in 8.5% of patients younger than 65 years old, 23% of the times in patients between 65 and 74 and 30.6% among patients above 74 years old. According to VCM, 41.7% were microcitic-anemia, 48% were normocític-anemia and 10.3% resulted macrocític ones. CONCLUSION. Anemia is among a large share of patients coming into the hospital through emergency proceedings. Its likelihood increases accordingly to the risk group analysed and dominating among the elderly population and among patients suffering from renal disfunction and non aggregated. Most common are normocitic and macrocitic anemia-types. Early identification and valuation could bear prognostic consequences. A. S. Omar 1 1 Tawam Hospital, Critical care medicine, Al Ain, United Arab Emirates INTRODUCTION. An elevated serum creatinin phosphokinae (CPK) and the presence of myoglobin in the urine characterize rhabdomyolysis. Rhabdomyolysis had been described in various traumatic and non-traumatic conditions [1] , there are few reports of its association with anaphylaxis. In this paper, we report 2 cases of anaphylaxis both complicated with rhabdomyolysis. AIM OF THE WORK. To discus the association between rhabdomyolysis and anaphylaxis and the value of early screening of CPK in such cases. SETTING. Two patients were included in this review in multidisciplinary intensive care unit of Tawam Hospital/UAE. The two patients survived, both developed rhabdomyolysis shortly after admission, evidenced by fivefold or greater increase in serum CPK [2] . Both patients had transient hypotension through the presentation, but none of them had persistent shock requiring vasopressors or complicated with acute renal failure. CONCLUSION. We observed rapid increase in serum CPK in our two cases suggesting the potential benefits of early assessment of CPK in such patients which may amplify early goal guided management and avoiding logistic organ dysfunction. KEYWORDS. Rhabdomyolysis, anaphylaxis.  The blood oxygen and carbon dioxide levels are a direct measure of the effectiveness of ventilatory support in patients on mechanical ventilation. Head injury patients require strict control of the cerebral homeostatic state. These patients also need careful management of sedation, maintaining a fine balance between patient comfort, hemodynamic instability and ability to assess conscious levels. Biphasic intermittent positive airway pressure (BIPAP) ventilation is thought to be better tolerated by the patient allowing for spontaneous breathing at any point, thus reducing the amount of sedatives and muscle relaxants used. But the effectiveness of this ventilatory mode in achieving stable blood oxygen and carbon dioxide levels in this group of patients is not known. We hypothesised that BIPAP is more labour intensive to adapt to the target blood gas parameters as the volume delivery is not constant and that the blood gases may be more unstable in the initial resuscitation phase of head injury patients without conferring much advantages in terms of usage of sedatives and muscle relaxants. Retrospective data collected from case record review of 13 head injury patients with no primary respiratory insult, requiring mechanical ventilation with volume controlled synchronised intermittent mandatory ventilation (SIMV) was compared to the data from 13 similar patients treated with BIPAP ventilation. Both the data groups specifically looked at two time periods, the first 24 h and 24-72 h after intensive care admission. Blood gas parameters classified as hypocarbic, hypercarbic and/or hypoxic, use of muscle relaxants, Number of episodes of raised intracranial pressure (ICP) above 20 mmHg as recorded in the intensive care chart every hour, number of episodes of cerebral perfusion pressure (CPP) below 70 mmHg as recorded in the chart every hour was noted. Need for muscle relaxant in the first 24 h of admission was noted. The outcome was recorded as either ''alive'' or ''dead'' at the end of ITU stay. The data was checked for normality of distribution and compared using non parametric tests (SPSS 15 for windows). RESULTS. Baseline characters were comparable between the groups. Increased episodes of hypoxia (9.3 ± 12.5 vs. 6.9 ± 12% p = 0.53) and hypocarbia (32.9 ± 18.5% vs. 20.7 ± 20.1% p = 0.046) in BIPAP mode, compared to SIMV volume control mode. All measurements being percentages of total blood gases for that patient in the first 24 h. There was no difference in the usage of muscle relaxant (35.7 vs. 66.7% p = 0.214), raised ICP, reduced CPP or mortality between the groups. CONCLUSION. BIPAP mode of ventilation requires more intensive monitoring and changes in ventilatory settings before adapting to the target blood gas parameters in the first 24 h of admission. At the same time the quoted advantage of using less sedatives and muscle relaxants is not significant. Acute post-traumatic brain swelling is one variety of the pathological forms, which needs emergent treatment following traumatic brain injuries. We investigated the effects of clinical effects of decompressive craniectomy (DC) in patients with acute post-traumatic brain swelling (BS). Seventy-four patients of acute post-traumatic BS with midline shifting more than 5 mm were divided randomly into two groups: DC group (n = 37) and routine temporoparietal craniectomy group (control group, n = 37). The vital sign, the intracranial pressure (ICP), the Glasgow outcome scale (GOS), the mortality rate and the complications were prospectively analysed. The mean ICP values of patients in DC group at 24, 48, 72 and 96 h after injury were much lower than those of routine temporoparietal craniectomy group (15.19 ± 2.18, 16.53 ± 1.53, 15.98 ± 2.24 and 13.518 ± 2.33 mmHg vs. 19.95 ± 2.24, 18.32 ± 1.77, 21 .05 ± 2.23 and 17.68 ± 1.40 mmHg, respectively). The mortality rates at 1 month after treatment were 27% in the DC group and 57% in the control group (p \ 0.01). Good neurological outcome (GOS Score of 4 to 5) rates 1 year after injury for the groups were 56.8 and 32.4%, respectively (p = 0.041). The incidences of delayed intracranial hematoma and subdural effusion were 22 and 5%, respectively (p \ 0.05). In conclusion, DC has superiority in lowering ICP, reducing the mortality rate and improving neurological outcomes over routine temporoparietal craniectomy. However, it increases the incidence of delayed intracranial hematomas and subdural effusion, some of which need secondary surgical intervention. Therefore, the effects of DC in patients with acute post-traumatic BS should be further evaluated. We analyze among others variables: age, injury severity score (ISS), abbreviated injury score (AIS); admission and discharge Glasgow coma score (GCS), extended Glasgow outcome score (GOSE), complications, ICU and hospital mortality. Differences between groups were tested with Students t test and v 2 testing for statistical analysis. RESULTS. Fourteen patients with intracranial hypertension were treated with decompressive craniectomy . Compared with control group, patients with DC had a better GCS (9 ± 5 G1; 5 ± 4 G2 p = 0,004) and GOSE index not only at ICU discharge (4 ± 3 G1; 2 ± 2 G2 p = 0,008) but also at hospital discharge (4 ± 3 G1; 2 ± 2 G2 p = 0.03). The mortality rate was lower in the craniectomy group (G1: 14%, G2; 73% p = 0.05). CONCLUSIONS. In our Center, the use of DC for treat patients with severe TBI and refractory cranial hypertension (GCS B 8 and PIC C 25) improved outcome and mortality significantly compared with medical conventional approach. METHOD. In this retrospective study we present 10 patients who underwent decompressive craniectomy following traumatic brain injury at King's College Hospital between 2003 and 2008. RESULTS. 60% of these patients presented at A&E with a Glasgow Coma Scale of 8 or below whereas the remaining 40% presented with GCS above 8 and deteriorated following admission. The patients underwent decompressive craniectomy to reduce raised ICP resistant to medical treatment (barbiturate coma excluded). The procedure resulted in significant decrease in ICP. 6 out of 10 patients had the operation within 24 h following their injury. We also found that DC in younger patients (\40 years) was correlated with lower ICP following the operation compared to older patients ([40) . Our study also showed that early DC (\24 h) is correlated with a shorter stay in ITU. CONCLUSIONS. The findings of the present study are limited by its retrospective nature and small sample size which does not permit any definitive conclusions from these results. However, they form the basis for further investigation. We present the study with a review of the recent literature. INTRODUCTION. The objective is to study the correlation of secondary ICP indices with CT Findings and outcome in TBI. A cerebrovascular pressure reactivity index (PRx) can be determined as the moving correlation coefficient between mean ICP and mean arterial blood pressure . It is a surrogate marker of cerebrovascular reactivity. The RAP coefficient was calculated as the running correlation coefficient (R) between slow changes in pulse amplitude (A) and mean ICP (P). It is a surrogate marker of pressure-volume compensatory reserve. All components of the ICP waveform that have a spectral representation within the frequency limits of 0.05 to 0.0055 Hz can be classified as slow waves. METHODS. Prospective observational study of 38 patients with TBI at the Royal London Hospital. All patients were managed according to the local Guidelines for the management of TBI . Secondary indices derived from the ICP waveform were analyzed by ICM ? software. An initial CT was performed in all patients before admission to ICU.  Marshall classification has been shown to predict mortality in TBI. We found a strong association between ALL these secondary indices and the initial CT findings. ALL these markers of cerebral haemodynamics correlate significantly with outcome in headinjured patients. CONCLUSIONS. Surrogate markers of cerebrovascular reactivity and pressure-volume compensatory reserve correlates with CT findings and outcome in TBI. These secondary ICP indices may be used in the management of TBI. INTRODUCTION. Following the introduction of national guidance [1] on the management of patients with head injury, the use computed tomography (CT) imaging of the head has increased markedly. The impact on anaesthetic and critical care services is unknown. 1. Determine the impact of national guidelines on CT scanning in the head injured patient upon anaesthetic and critical care services in a university teaching hospital. 2. Determine the incidence of acutely abnormal CT appearances in patients referred for CT scanning under the guidelines. 3. Estimate in-hospital mortality in this population and its sub-groups. A case-note analysis was performed in October 2008 of 300 consecutive emergency department (ED) patients who were recorded as having a CT head. Of the 300 cases, 10 did not actually have CT head. Details of the 290 analysed subjects, indications for the scan and 30 day mortality rates are reported in Table 1 .  In patients with severe traumatic brain injury pro-and anti-inflammatory mediators are released into the systemic circulation. However, the relationship between the inflammatory response and the kind and duration of secondary insults remains unclear. OBJECTIVES. The aim of this study was to investigate in severe traumatic brain injured patients the relationship between the systemic concentrations of pro-and anti-inflammatory mediators and the total duration of secondary insults occurring during the ICU stay. METHODS. Ten consecutive traumatic brain injury patients admitted to the ICU were included. Physiological variables were continuously recorded and analyzed minute-by-minute to identify the occurrence of secondary insults (intracranial hypertension, systemic hypotension, hypoxemia and hyperthermia) according to the Edinburgh University secondary insult grading scale. Serum samples were obtained at admission, 24, 48 and 72 h, in which pro-and anti-inflammatory mediators were analyzed by a bioplex assay. RESULTS. Ten male patients were enrolled, mean age 35 ± 15, GCS 7 ± 1, APACHE II 13 ± 4, ISS 32 ± 9. Patients were monitored for 3.5 days (median value, range 1-5; 46,442 total minutes recorded); intracranial hypertension occurred for 7,099 min (15.3% of total period recorded, range 0.3-99%), hypotension occurred for 6,176 min (14.8% of total period recorded, range 0.75-43%), hypoxemia occurred for 180 min (0.4% of total period recorded), not enough data were validated for fever. Interleukin (IL)-6, IL-1beta, IL-8, IL-10 and IL-1ra were in the detectable range. A significant correlation was found between the total duration of intracranial hypertension and the median value of IL-6 (p \ 0.01, R 2 = 0.48), IL-1beta (p \ 0.05, R 2 = 0.37), IL-8 (p \ 0.05, R 2 = 0.34), IL-10 (p \ 0.05, R 2 = 0.42), and IL-1ra (p \ 0.05, R 2 = 0.34) measured during the period of observation. No correlation was found between these inflammatory mediators and the occurrence of hypotension or hypoxemia. No significant correlation was present between the baseline values of these inflammatory mediators and the severity indexes (GCS, ISS and APACHE II). CONCLUSIONS. These results suggest that the duration of secondary insults such as intracranial hypertension was associated with a systemic inflammatory reaction, while the severity of injury on admission was not related to the initial concentrations of these inflammatory mediators. GRANT ACKNOWLEDGEMENT. AIM. Assessing behavioral responses to pain is difficult in severely brain-injured patients recovering from coma. We here propose a new scale developed for assessing pain in vegetative (VS) and minimally conscious (MCS) coma survivors: the coma pain scale (CPS) and explore its concurrent validity, inter-rater agreement and sensitivity. METHODS. Concurrent validity was assessed by analyzing behavioral responses of 48 postcoma patients to a noxious stimulation (pressure applied to the fingernail) (28 vs. and 20 MCS; age range 20 to 82 years; 31 non-traumatic and 17 of traumatic origin). Patients' were assessed using the CPS and four other 'pain scales' employed in non-communicative patients: the 'Neonatal Infant Pain Scale' (NIPS) and the 'Faces, Legs, Activity, Cry, Consolability' (FLACC) used in newborns; and the 'Pain Assessment In Advanced Dementia Scale' (PA-INAD) and the 'Checklist of Nonverbal Pain Indicators' (CNPI) used in dementia. For the establishment of inter-rater agreement, fifteen patients were concurrently assessed by two examiners. RESULTS. Concurrent validity assessed by Spearman rank order correlations between the CPS and the four other validated pain scales was good. Cohen's kappa analyses revealed a good to excellent inter-rater reliability for the CPS total and subscore measures, indicating that the scale yields reproducible findings across examiners. Finally, a significant difference between CPS total scores was observed as a function of diagnosis (i.e., VS or MCS). CONCLUSION. The CPS constitutes a sensitive clinical tool for assessing pain in severely brain injured patients with disorders of consciousness. This scale constitutes the first step to a better management and understanding of pain in patients recovering from coma. METHODS. Study group: 75 consecutive patients with cervical spinal cord injury admitted to ICU. Mean age: 35, 4 years. 51 patients ASIA A, 18 ASIA B, 6 ASIA C. The more frequent neurological level was C6 (50%). The requirement of mechanical ventilation was considered the key sign for establishing the diagnosis of severe respiratory failure. The blood gas values (pO 2 , PCO 2 , and paO 2 /FIO 2 ) before and after connection to mechanical ventilation [MV(if needed)], were used to estimate the more probably mechanism of respiratory insufficiency. The increase of pCO 2 levels was considerate as a sign of neuromuscular weakness; the low pO 2 level before ventilation, and the persistence of paO 2 /FIO 2 below normal values was considered a sign of V/Q mismatch. For this purpose statistic analysis (mean values comparison using Student t test) comparing blood gases before and after mechanical ventilation treatment was performed. RESULTS. 39 (52%) patients developed severe respiratory failure. Mean delay between admission and mechanical ventilation was 108 h. Previously to mechanical ventilation 22 patients developed pulmonary atelectasis, and four pneumonia. The incidence en respiratory failure was significantly higher in patients with neurological level above C6 (p \ 0.05). CONCLUSIONS. The incidence of respiratory failure is related with the severity of neurological deficit (relationship between incidence of respiratory failure and neurological deficit level). In addition, our data support that, besides the neuromuscular weakness (moderate increase of CO 2 levels), a significant V/Q mismatch with shunting phenomena associated (significant hypoxemia no completely solved after MV) is involved in the respiratory failure of cervical spinal cord injured patients. 1. Moderate and severe traumatic brain injury is more likely in middle aged men; more than one third present other major trauma and intensive first level medical treatment is required in most of them. 2. The most frequent complications found were infectious diseases like ventriculitis and VAP. 3. Independent mortality risk factors in moderate and severe trauma brain injury were age, high APACHE II score, neuromuscular blocking drugs and ICU LOS. 4. Outcome was significantly improved after six months, and most of the patients only present mild disability and good recovery. Nosocomial infections are leading causes of increased morbidity and mortality of severe brain injured patients [1] . The mechanism underlying the susceptibility to the infections is a subject of great scientific interest and still to be clarified [2] . It has been recently recognized that injury of brain induces a disturbance of balance between the central nervous and immune system [3] . OBJECTIVE. The aim of this study was to investigate changes in frequency of lymphocytes subpopulation in peripheral blood of patients with severe brain injury during the course of intensive care treatment. Human peripheral blood samples were taken from the severe brain-injured patients at day 1, 4 and 7 and peripheral blood mononuclear cells (PBMC) were immediately isolated by gradient density centrifugation. The percentage of lymphocytes subpopulation were analyzed by simultaneous detection of surface antigens using fluorochrome conjugated monoclonal antibodies directed toward CD3, CD56, CD16, CD4, CD8, CD5, CD19. T lymphocytes were distinguished from the other lymphocyte subpopulation as cells labeled with anti-CD3 monoclonal antibody but negative for CD56 staining (CD3? CD56- PATIENTS. Eighty-seven patients with head injury, Glasgow Coma Scale \ 9. MEASUREMENTS AND MAIN RESULTS. Clinical and demographic data, and head CT scan were taken at admission. Patients underwent advanced neuromonitoring and were treated according to Brain Trauma Foundation guidelines. S100b concentration was quantified at admission and 24, 48 and 72 h post-TBI (Days 0, 1, 2 and 3). Outcome was assessed 12 months after discharge using Glasgow Outcome Score. Significant negative correlations were found between 1-year GOS and S100b concentrations on days 1-3, but not on day 0 (day 0, p = 0.1; day 1, p = 0.003; day 2, p \ 0.0005; day 3, p \ 0.0001). Patients who deceased showed higher S100b concentration than survivals for all the samples. Good versus poor outcome (GOS = 1-3) differed significantly on days 2 and 3. Logistic regression analysis showed that samples 24, 48 and 72 h post-TBI sample predicted death outcome. ROC curve analysis showed 72-h sample was the strongest predictor for decease. Poor outcome was only predicted by the 72-h sample. CONCLUSIONS. S100b levels 72 h post-TBI was the strongest predictor for poor and fatal 1-year outcome, whereas levels at admission do not. A temporal profile of S100b release from admission to 72 h post-TBI is strongly recommended for use in identifying the subset of patients liable of developing a worse outcome. According to our results, S100b protein might be an early, sensitive, accurate and useful biomarker for predicting long-term outcome in patients with acute severe TBI. GRANT ACKNOWLEDGEMENT. This research was made possible in part by the generous donation of protein S100b Electrochemiluminescence assay kits by Roche Diagnostics, Mannheim, Germany. INTRODUCTION. Brain intercellular fluid glycerol concentration as measured by microdialysis catheters has been recognized as an index of glial and neuronal cellular destruction. We present a data analysis correlating glycerol levels with intracranial pressure (ICP), cerebral perfusion pressure (CPP), brain tissue oxygen partial pressure (PbtiO 2 ), lactate to pyruvate concentration ratio (L/P) and outcome. METHODS. Data of 30 head injured patients is presented. All had simultaneous monitoring of ICP, PbtiO 2 and metabolic biochemistry by three brain intraparenchymal bolt catheters inserted via the same one burrhole (ICP Codman or Camino, PbtiO 2 LICOX and Microdialysis-CMA). There was not a clear straight correlation of raised glycerol levels with bad outcome. However, glycerol elevation seemed to be a predictor of intracranial hypertension together with L/P raise. In subarachnoid hemorrhage patients glycerol elevation was an early sign of secondary ischemic insult. CONCLUSION. Multimodal monitoring with intracranial catheters is a useful clinical tool for management of critical neurosurgical patients. Metabolic biochemistry as measured by microdialysis, and specially L/P and glycerol levels, can early predict incoming intracranial hypertension as well as secondary ischemia. The pulsatility index (PI), a parameter derived from the blood velocities along the cardiac cycle, has been used as an indirect way to evaluate intracranial pressure. The aim of this research has been to evaluate the accuracy of transcranial Doppler sonography (through pulsatility index) in the inference of intracranial pressure. METHODS. Population of the study group (High-PI-group): 50 severe head injured patients (GCS at admission \ 9; mean age 37.7 years; patients with diffuse injury (traumatic Coma Data Bank) type II (43%) and III (29%)) who presented episodes of increase of pulsatility index (PI [ 1.2) in the acute phase of head injury. Control group (normal-PI-group): 50 severe head injured patients, with TCD recordings of normal PI (PI B 1.2). In all the patients the intracranial pressure (ICP) was continuously monitored using a intraparenchymal device. All the TCD recordings are referred to the Middle Cerebral Artery of the cerebral hemisphere were ICP catheter was inserted. In the transcranial Doppler recording, the Pulsatility Index was automatically calculated derived from the formulae: Pulsatility index = (systolic velocity -diastolic velocity)/mean velocity. 100 transcranial Doppler sonography recordings of with pulsatility index C 1.2 (high normal value of pulsatility index) were correlated with the simultaneous ICP value. The incidence of intracranial hypertension (ICP [ 20 mmHg) was analyzed in the High-PI-group, and compared with the incidence of intracranial hypertension in the normal-PI-group. METHODS. In a double-blind, randomized, placebo-controlled clinical trial, 80 patients scheduled for elective CABG was randomly assigned into two groups. After matching inclusion and exclusion criteria and induction of general anesthesia, one group received intrathecal sufentanil (S) and the other group received the same dose of sufentanil plus supplemental bupivacaine (SB). Except for this, all the cases were similar regarding anesthesia and surgery. Mean arterial blood pressures were measured before and after induction of anesthesia, during the bypass time and after weaning from bypass were checked. Also, the need of the patients for administration of inotropic agents after weaning was compared. RESULTS. There was more stable mean arterial blood pressure and less inotropic need after weaning from cardiopulmonary bypass in the SB group. Also, the SB patients had a more stable hemodynamic profile during the bypass period; especially after the initiation of the bypass. Less inotropic agents were needed after weaning in the SB patients. There was no difference between the two groups regarding the extubation time. DISCUSSION. The administration of intrathecal sufentanil plus bupivacaine seems to keep the hemodynamic status of the patients more stable than intrathecal sufentanil alone. METHODS. This study was approved by the Hospital 0 s Ethics Committee. Prospective observational study including 20 consecutive patients. Preoperatory and postoperatory data were collected. Interventions included blood samples for NT-pro BNP taken prior to operation, and 18 and 36 h in postoperative. Troponin-I was taken 12 and 36 h postoperatively. Blood obtained was processed for NT-proBNP with Cobas H 232 system Ò Point of Care (POC) by Roche Diagnostics, with range from 60 to 3,000 pg/ml. The serum NT-proBNP level was also correlated with the logistic Euroscore and ejection fraction (EF). Serum NTpro-BNP and troponin I values were compared between patients with and without postoperative length of stay in the intensive cardiac unit (ICU) [ 48 h. and hospital [7 days. All results are in median ± SD * p \ 0.05, **p \ 0.01 Tables 1??? and 2??? CONCLUSIONS. Preoperative Euroscore and NT-proBNP levels were higher in patients with EF \ 40%. The troponin I after surgery increased more in patients whose length stay in icu was longer. After surgery NT-proBNP levels increased significantly,and they differ significantly between patients with length stay in ICU for more than 48 h and 7 days at hospital. Our data collection confirmed that measurement of NT-proBNP is useful and helpful during postoperative period and it also predicted a higher possibility for a long stay in ICU and a later hospital discharge. However, owing to the small size sample, these results must be regarded as preliminary. CONCLUSIONS. In spite of the limitations of our trial, percutaneous aortic valve implantation appears to be safety. A high rate of MACCV events were observed, essentially due to a disruption of the A-V conduction, in most cases transitional. Despite the definition of ''inoperability'' is difficult, less-invasive aortic valve procedures will undoubtedly find a place within current cardiac surgical practice. OBJECTIVE. To describe the evolution of cardiac transplant patients, presenting clinical low cardiac output in the immediate postoperative period, and after handling routine, they are treated with levosimendán (LV). Descriptive, prospective and observational in a postoperative care unit for cardiac surgery from a terciary hospital. Study period: January 2006-December 2008. LV was used when the patient had inotropic dependence over 72 h, to try to remove the amines or added to them in those cases that do not get these drugs with an adequate hemodynamics. Bolus was used in 4 occasions and then infusion of 0.1-0.2 mcg/ (kg min). We analyzed demographic variables, hemodynamic response to the input of the drug if you can reduce or discontinue other medications, clinical tolerance and side effects, overall development, the ICU and hospital stay. We studied 13 patients (6 women and 7 men). Presented a mean age of 48.85. Before surgery, all of whom were in NYHA functional class III-IV. Three patients were transplanted in emergency. In this series, there is a case without pulmonary hypertension (PAH) pre-transplant, 5 patients with mild HTP and HTP 7 moderate to severe, with a transpulmonary gradient(GTP) between 9 and 21 mmHg. The 3 patients with GTP [ 15 mmHg had a positive reversibility test with sildenafil. Ischemia time of surgery was 195.46. In the immediate post, all the patients studied had low cardiac output syndrome by graft postoperative ventricular dysfunction, cardiac index measured by pulmonary artery catheter. In all patients echocardiography was performed to rule out a pericardial effusion with hemodynamic deterioration in cardiac cavities and showed ventricular dysfunction, right dominance in 10 patients. In all patients we observed a good tolerance to the drug. In 11 LV cases facilitated the withdrawal of the remaining. 2 patients were used LV only after the withdrawal of treatment with inotropic dependence on it. In the remaining cases to be associated with other drugs. Only two cases could not withdraw inotropic treatment after the LV infusion. In five patients with pulmonary arterial hypertension and prevalence of right ventricular failure, to reduce poscarga also added pulmonary arterial vasodilators. Patients have a stay in ICU between 4 and 6 days. One patient mortality. 1. The primary graft failure is a severe potential complication of post-cardiac, which is associated with a worse prognosis. 2. LV shows good tolerance, without serious adverse effects attributable to the drug, and facilitated the removal of amines and clinical recovery. 3. It is necessary to expand the case to confirm the results, and to establish the most appropriate indications and patterns of use of this drug. Post-infarction ventricular septal defect (infarctVSD) is a rare but serious complication of myocardial infarction, usually quickly followed by low cardiac output. Repair of infarctVSD is still a challenging procedure with a high risk of mortality. Improvement of surgical outcome depends on results of large studies in this setting. The aim of this retrospective study was the evaluation of preoperative and surgical parameters influencing the 30-day mortality following surgical repair. CONCLUSIONS. In this large study, pre-operative left ventricular function and troponin level were found to be the best predictors identifying patients at high risk for 30-day mortality following surgical closure of infarctVSD. Both parameters may be helpful in deciding on the time of the operation and preoperative preparation. In contrast to other findings, in our cohort the location of the VSD (anterior vs. posterior) did not affect mortality. This may be due to improvement of surgical technique and perioperative management over time.  Adequate fluid therapy is the first step of hemodynamic optimization after cardiac surgery [1] . Cardiac surgery exposes patients to ischemia and reperfusion, which are well known risk factors for a systemic inflammatory response and increased capillary permeability in the lungs [2] . It is still unclear what type of fluid should be given in the presence of increased pulmonary vascular permeability at hypovolemic status. OBJECTIVES. Aim of this study was estimate the optimal type of fluid for intravascular volume deficit treating without evoking pulmonary oedema. A prospective clinical study at the intensive care unit was performed on 24 mechanically ventilated patients within 1 h after elective cardiac surgery involving cardiopulmonary bypass. Patients, divided into four groups, were subjected to fluid challenge according to the global end-diastolic volume index (GEDVI) measurements with normal saline 1,000 ml or the colloids 4% gelatin, 6% HES 130/0.4 or 5% albumin 250 ml in 20 min. Hemodynamic and extravascular lung water index (EVLWI), GEDVI measurements were performed exactly before fluid challenge, afterwards and 30 min after challenge. RESULTS. The change in EVLWI did not differ between saline and colloid fluid challenge. GEDVI increased by 12% in saline group, by 15% in 4% gelatine, 16 in 6% HES 130/0.4 and 17 in 5% albumin. CONCLUSIONS. All colloid fluid infusion leads to the greater increase in cardiac preload compare to normal saline (saline in four times larger volume). The change in EVLWI did not differ between saline and colloid fluid groups and did not increase pulmonary oedema despite in the presence of increased pulmonary vascular permeability, when fluid overloading is prevented. INTRODUCTION. The annual incidence of prosthetic valve thrombosis is up to 1-2% (patients-year) despite the anticoagulant therapy. Conventionally, the treatment of choice for this event was the surgical valve replacement. However, fibrinolytic therapy has become a valid alternative for the treatment of this serious complication, especially in high-risk surgery patients. To analyze the clinical factors, diagnosis and treatment management of patients with prosthetic valve thrombosis admitted to the Acute Cardiac Care Unit. We designed an observational-descriptive study, including patients admitted between 1998 and 2008. Clinical factors were analyzed: sex, age, prosthetic valve position, time from valve replacement, INR at admission, clinical features, diagnostic technique and treatment used. RESULTS. 14 patients were included. 35.7% were women, 64.3% men. Mean age was 57.2 ± 4.15 years. The highest incidence was at the tricuspid prosthetic valve position (57.1%), followed by the mitral (35.7%) and the aortic position (7.1%). When a triple valve replacement was performed, the tricuspid position was the most often affected. Mean time from the first valve replacement surgery was 5.9 ± 2.7 years. Clinical features which led to the diagnostic were: acute heart failure (71.42%), peripheral embolization (14.28%), chest pain (7.14%) and syncope (7.14%). The diagnostic techniques used were transesophageal echocardiography (TEE) and cinefluoroscopy in all the patients. INR at admission time was lower than adecuate anticoagulation recommendations in 71.42% of patients. The most widely used treatment was the systemic fibrinolytic therapy (78.57%), followed by surgery (14.28%) and conservative treatment with heparin alone (7.14%). The most widely used thrombolytic was rtPA in 90.9% of patients, with a mean dosage of 89.3 ± 15.4 mg. One patient was treated with 1.4 mil. UI of streptokinase. Unfractionated Heparin was added to all patients whom received fibrinolytic therapy, with a mean dose of 683 ± 331 UI/h. A 57.1% incidence of minor bleeding was found in the fibrinolytic group. There were no major complications due to fibrinolytic. Total mortality rate was 14.28%. Our experience, suggests that systemic fibrinolytic therapy is safe and effective in patients with prosthetic valve thrombosis. OBJECTIVE. To describe the outcomes of patients with acute, refractory, non-ischaemic and not postcardiotomy, cardiogenic shock treated with extracorporeal membrane oxygenation (ECMO) and to evaluate whether survivors and non-survivors differed with respect to clinical characteristics, pre-ECMO treatment and laboratory values. DESIGN. In this retrospective cohort study, information is collected from a database with additional review of medical records. PATIENTS. 20 consecutive adult patients, 14 males, mean age 39.7 ± 12.7 year, presenting to hospital with non-ischaemic acute severe, refractory cardiogenic shock, supported by central or peripheral venoarterial (VA) ECMO. MEASUREMENTS AND MAIN RESULTS. Characteristics of survivors and non-survivors were compared using chi square test. Twelve patients (60%) were transported to our institution on ECMO. Eleven patients (55%) were weaned from ECMO, seven (35%) bridged to ventricular assist devices. In two patients (10%) ECMO support was withdrawn. Mean duration of ECMO support was 145.5 ± 69.7 h. Overall survival was 70%, and did not differ between patients with myocarditis (n = 10), cardiomyopathy (n = 7) and acute on chronic non-ischaemic cardiogenic shock (n = 3). A larger proportion of the three patients with 2 or more complications died as compared to the seventeen patients with less than 2 complications (67% versus 24%, p = 0.133). Pre-ECMO intra-aortic balloon counterpulsation (IABP) was used in 11 patients, 91% survived, as compared to 44% of those who did not receive IABP (p = 0.024). We have not identified any other significant differences between survivors and non-survivors. CONCLUSION. The survival of patients on ECMO in this unique heterogeneous patient cohort is similar to the survival of ECMO support for fulminant myocarditis in the literature. We recommend to institute ECMO early in all medical patients with acute non-ischaemic cardiogenic shock, refractory to conventional therapy, or to refer these patients in time to an ECMO centre. INTRODUCTION. Human Parvo B19 virus is associated with a broad spectrum of clinical manifestations, mostly in children or immune-compromised patients. In adults, severe myocarditis due to this viral agent is a rare disorder, presenting as acute congestive heart failure. We describe a patient with rapidly progressive heart failure, needing circulatory support by extracorporeal membrane oxygenation (ECMO). METHODS. Case report. A 24-year-old previous healthy female was admitted to our ICU with nausea, vomiting, bradycardia and hypotension with a blood pressure of 80/40 mmHg. Two weeks before admission, patient had signs of erythema infectiosum. On physical examination the patient was pale, with venous congestion, third heart sound and hepatomegaly. The initial electrocardiogram showed a slow, regular, ventricular rhythm. Admission chest X-ray showed normal heart size with bilateral pleural effusion. Echocardiography revealed dilated ventricles (RV and LV) with depressed systolic function and a thrombus in the RV apex. Patient was initially treated with intravenous medical therapy, but unfortunately developed progressive cardiogenic shock. Troponin levels, serum transaminases and BUN were extremely elevated. It was therefore decided to implant a percutaneous ECMO by femoro-femoral cannulation which permitted to stabilize hemodynamic conditions while peripheral organ functions returned to normal range. Progressive cardiac recovery was observed after 7 days with a circulatory assistance with a mean flow rate of 4.1 l/min. As myocardial function improved, ECMO was gradually weaned and removed after 10 days of support. However, atrioventricular conduction did not recover, necessitating implantation of temporary VVI-pacemaker, which was later replaced by a permanent DDD pacemaker system. Pathology of the endomyocardial biopsy showed extensive lymphocytary infiltration with destruction of myocytes. Parvo B19 DNA-PCR was positive in both the biopsy and serum. These findings suggest that this patient developed severe myocarditis induced by parvo B19 viral infection. To our knowledge, Parvo B19 viral infection is an uncommon cause of severe myocarditis in adult patients. Sparse literature is available describing the use of ECMO in these adult patients. CONCLUSION. This case report shows that Parvo B19 virus should be recognised as a potential infective agent in adult patients presenting with severe myocarditis. Furthermore, ECMO can be safely used to stabilize hemodynamics and peripheral organ perfusion in expectation of myocardial recovery in these patients. Copeptin is easier to measure than vasopressin, and could be used as a marker of vasopressin release [1] . The aim of the study was to compare plasma concentration of AVP and Cop during cardiac surgery, and specifically during post cardiac surgery vasodilatory syndrome (PCSVS). METHODS. Two-month consecutive patients scheduled for cardiac surgery with cardiopulmonary bypass (CPB) were included in the study except patients suffering from chronic renal failure and under dialysis. Blood samples were obtained from blood withdrawals routinely operated before CPB, during CPB and after surgery, at the postoperative hour 8 (H8). These samples were used for AVP and Cop measurements. PCSVS, assessed as hypotension unresponsive to volume replacement therapy and without cardiogenic shock features, was treated with norepinephrine (NE). Patients treated with NE have been compared to the others. Statistical test consisted of variance analysis, non parametric test (Mann Whitney or Wilcoxon) and linear regression. A P value of less than 0.05 (p \ 0.05) was considered statistically significant. RESULTS. 64 patients have been included, out of which 10 have been treated with NE. Correlation between AVP and Cop plasma concentrations is significant (r = 0.70, p \ 0.01). AVP and Copt concentrations increased significantly at H8 but the increase is less pronounced in NE-treated patients (Fig. 1) . NE-treated patients had lower preoperative left ventricle EF (45.0 ± 14.9 vs. 55.5 ± 10.5%, p = 0.03), longer CPB (123. 1 ± 46.4 vs. 200 .0 ± 80.7 min, p \ 0.01) and clamping times (87.7 ± 41.5 vs. 157.1 ± 70.2 min, p \ 0.01), higher incidence of low output syndrome (8/ 10 vs. 4/54, p \ 0.05) longer extubation time (27.5 ± 14.8 vs. 8.0 ± 7.0 h, p \ 0.01) and higher plasma Cop before (T0) and during CPB (Fig. 1) . AVP (ng/ml) et copeptin (Cop, pmol/l), in patients. *p \ 0.05 NE versus others DISCUSSION. Correlation between AVP and Cop is similar to that observed in other studies [1] . The correlation coefficient is rather weak that is possibly related to AVP dosage limitations (binding of AVP to blood platelets, lack of antibody-specificity). Increased Cop plasma concentrations before and during CPB is observed in sicker patients undergoing more complex surgery, which seems to expose them to relative postoperative vasopressin deficiency and PCSVS. BACKGROUND. Waiting list for heart transplantation has been growing up. High doses of cathecolamines has been an exclusion criterion for heart donation and norepinephrine use is still controversial. To assess if norepinephrine used on heart donors modify receptors outcome. METHODS. Historical Cohorts study from April 1991 to March 2007. Patients were divided in two groups: group 1: patients with local donors treated with norepinephrine (n = 58). Group 2: patients with local donors managed with other cathecolamines (n = 39).Cathecolamines were used at least for 1 h and doses were between 0.05 and 5 mcg/(kg min) if Norepinephrine and between 1 and 20 mcg/(kg min) if Dopamine or Dobutamine. Mortality risk factors published on the last International Society for Lung and Heart Transplantation guidelines were recorded. Graft dysfunction risk factors were also collected. Heart transplant outcome was measured by 30-day mortality, mortality rate at first, second, fifth and tenth years; and graft dysfunction incidence. Chi-squared and T student test was used. Multivariate logistic regression was used to evaluate norepinephrine impact on the outcome. Mortality in group 1 was 36.2 and 41% in group 2. No differences in mortality or graft dysfunction incidence were found in multivariate analysis. CONCLUSIONS. Norepinephrine used for donors management compared with dopamine and dobutamine does not increase mortality or graft rejection incidence in heart transplantation. Groups were not uniform so further studies may be made to determine this association. INTRODUCTION. Coronary artery bypass surgery on cardiopulmonary bypass is associated with significant morbidity and mortality. With present technology, all arteries on the heart can be bypassed off-pump. The benefit of this technique is higher for patients whom are at increased risk of complications from cardiopulmonary bypass, such as those who have heavy aortic calcification, carotid artery stenosis, prior stroke, and compromised pulmonary or renal function. To evaluate the short-term follow up results of off-pump coronary artery bypass (OPCAB) and postoperative management of these patients admitted to our Coronary Care Unit. We designed an observational study that included patients who underwent OPCAB from July 1998 to December 2008. Data were collected on preoperative age, sex, major cardiovascular risk factors, history of prior AMI, number of affected vessels and ventricular function. After the surgery we evaluated: the extubation time, postoperative bleeding, troponin maximum level, need for blood transfusion, use of vasoactive drugs and intra-aortic balloon pump, development of renal failure, atrial fibrillation, neurological complications and reintervention. RESULTS. 69 patients were included. 79.9% were men and 20.3% women. Mean age was 65.3 ± 8.7 years. 100% of patients had one or more cardiovascular risk factor: hypertension was present in 73.9%, smoking 55.1%; diabetes mellitus 37.7% and dyslipidemia in 62.3%. There was prior myocardial infarction in 53.6% of patients. Prior coronary angiography showed 26.1% of patients with 2 vessels disease and 73.9% of 3 vessels disease. Mean LVEF was 53%. Mean number of grafts was 1.7. Mean extubation time was 9.6 h. Mean postoperative bleeding was estimated in 410 cc. 37.7% of patients needed blood transfusion; 36.2% vasoactive drugs; and 2.9% needed an intra-aortic balloon pump. 39.1% of patients developed troponin T elevation with a mean level of 6.3 ng/ml. 23.3% of patients developed atrial fibrilation, and 10.1% renal dysfunction (two patients needed hemodialysis). There was no neurological complications. 1 patient needed a reintervention. Mean of intensive care unit stay was 3.7 ± 5.3 days. Total mortality rate was 2.76%. Our experience shows that the off-pump coronary artery bypass graft surgery is a safe and effective technique for coronary revascularization, with low mortality and morbidity rates and reduced postoperative complications. OBJECTIVES. To assess if deterioration of left atrial function in patients with severe sepsis and septic shock could predict mortality. We studied 30 patients with severe sepsis or septic shock with mean age of 49.8 ± 16.17. Underlying echocardiographic parameters were measured on admission, 4th and 7th day, which comprised left ventricular ejection fraction (EF), and atrial function which is expressed as atrial ejection force (AEF), with AEF defined as the force that the atrium exerts to propel blood into the left ventricle (LV). All patients were subjected to BNP assay well. Multivariate analyses adjusted for acute physiology and chronic health evaluation score II (APACHE II score) was used for mortality prediction. RESULTS. Underlying source of sepsis was lung in 10 patient (33%), blood in seven patient (23.3%), abdomen in seven patients (23.7%), while three patient (10%) had Urinary tract infection (UTI) as a cause of sepsis. Only one patient had CNS infection. Severe sepsis was admission diagnosis for 20 patients, 10 patients were labeled as septic shock. Look for 28 days mortality. In-hospital mortality was 23.3% (7 patients) . Admission EF showed significant difference between survivors and non-survivors 49.01 ± 6.51 versus 56.44 ± 6.93% (p \ 0.01), on the other hand admission AEF showed insignificant changes between the same groups 10.9 ± 2.81 versus 9.41 ± 2.4 k/dynes p = 0.21, while BNP was significantly higher in the non-survivors 1,123 ± 236.08 versus 592.7 ± 347.1 pg/ml (p \ 0.001). Multivariate logistic regression, the predictable variables for mortality was APACHE II score, BNP then EF. CONCLUSION. In septic patients, left atrial function unlike the ventricular function and BNP levels cannot be used as independent predictor of mortality. OBJECTIVES. to analyse the relationship between plasma levels of NT-proBNP and LCD diagnosed by echocardiograph during SS. METHODS. Prospective observational cohort study. Inclusion criteria: consecutive patients with SS [3] . Non inclusion criteria: creatinine clearance \ 60 ml/min, 60 years \ age \ 18 years, cardiac surgery patients, pre existing coronary or cardiac insufficiency, neoplasia and systemic diseases. The evaluation of the left ventricular function was realised by a trans-thoracic or a trans-oesophageal echocardiograph on day 2. The LCD was defined by a left ventricular fraction of ejection \40% evaluated by Teicholtz. The blood tests for NT-proBNP analyses were drawn on days 0, 2, 4 and 7. Serum NT-proBNP measurements were made automatically by Elecsys 2010 analyser with the truss NT-proBNP (Roche diagnostics, myelan, France) by the electrochemiluminescence immunoassay method (Eclia). Data are expressed as mean ± SD and percentages. Statistical analysis was performed by repeatedmeasures ANOVA and ROC curves (p \ 0.05 indicated statistical significance). . 36 patients were included in a period of 30 months (medical patients n = 16, surgical patients n = 7 and trauma patients n = 13), age = 53 ± 10 years, BMI = 24 ± 2 kg/m 2 , APACHE II = 15 ± 9, IGS II = 35 ± 16, duration of intensive care unit stay = 24 ± 32 days, mortality = 50%. LCD was observed in 11 patients. The statistical analysis showed a significant elevation of NT-proBNP in patients with LCD (Table 1) . On day 2, the area under ROC curve was 0.79, and the cut off value of NT-proBNP predictive of LCD was 2,600 pg/ml (sensibility = 72%, specificity = 74%). INTRODUCTION. Fluid responsiveness can be predicted by the respiratory variation of arterial pulse pressure (PPV) or of pulse contour-derived stroke volume (SVV) as well as by the changes in pulse contour-derived cardiac index during a passive leg raising manoeuvre (PLR) or a tele-expiratory occlusion (TEO). We evaluated the ability of an infrared photoplethysmography arterial waveform (CNAP device) to estimate PPV. We also tested the ability of this non invasive estimate of PPV to predict fluid responsiveness compared to the invasive measure of PPV, to SVV and to the PLR and TEO tests. In 29 patients with septic shock (63 ± 13 years of age, 25 receiving norepinephrine, SAPS2 = 65 ± 22, lactate = 3.3 ± 3.1 mmol/L), we measured the response of cardiac index (pulse contour analysis, PiCCO device) to fluid administration (500 mL saline over 20 min). Before fluid administration, we recorded the PPV directly calculated from the non invasive arterial pressure signal (PPV ni ), the PPV directly calculated from the invasive arterial pressure signal (PPV i ), the PPV automatically provided by the PiCCO device (PPV PiCCO ), the SVV automatically provided by the PiCCO device, the changes in cardiac index induced by a PLR test and the changes in cardiac index induced by a 15-s TEO. RESULTS. Five patients were excluded because the arterial curve could not be obtained by the CNAP device due to excessive vasoconstriction. In the remaining 24 patients, fluid administration increased cardiac index by more than 15% (31 ± 19%) in 8 ''responders''. The fluid-induced changes in invasive (?20 ± 36%) and non invasive (?20 ± 29%) mean arterial pressure were correlated (r = 0.79, p \ 0.05). At Bland-Altman analysis, PPVni accurately reflected PPVi (bias 1%, limits of agreement ±8%). For predicting fluid responsiveness in the 24 patients, the receiver operating characteristics (ROC) curves for PPV ni , PPV i , PPV PiCCO , SVV, PLR and TEO were 0.83 ± 0.10, 0.82 ± 0.10, 0.86 ± 0.09, 0.77 ± 0.11, 0.92 ± 0.07, 0.94 ± 0.06 (all non significantly different). When considering only the 15 patients ventilated with a tidal volume B7 mL/kg predicted body weight, 2 were falsely classified as non responders by PPV ni , PPV i and two others by PPV PiCCO and SVV, but all four were well classified by PLR or TEO. In septic shock patients, provided that vasoconstriction is not excessive, the non invasive assessment of arterial pulse pressure seems valuable for predicting fluid responsiveness. INTRODUCTION. Mechanical ventilated patients often require inotropic support. However, the role of mechanical ventilation (MV) in myocardial depression is not well understood. Septic patients often have impaired cardiac function and are in need of mechanical ventilation. We hypothesized that MV enhances sepsis-induced myocardial depression. OBJECTIVES. In this study we investigated the influence of mechanical ventilation on cardiac function in an acute sepsis model. Sepsis was induced in male wistar rats using ip injection of LPS. Healthy and septic rats were randomized to one of three ventilation groups; (1) non-injurious ventilation with a tidal volume of 6 ml/kg and 5 cm H 2 O PEEP (low tidal volume, LTV), (2) injurious ventilation with a tidal volume of 19 ml/kg and 5 cm H 2 O PEEP (high tidal volume, HTV) and (3) spontaneous breathing. Arterial pressure was kept at least at 60 mm Hg. Cardiac output (CO, thermodilution method), central venous pressure (CVP) and mean airway pressure were measured in vivo. After 4 h of ventilation, animals were sacrificed and cardiac function was measured ex vivo in a Langendorff setup and expressed as developed pressure and ?dP/dt. Cardiac wet to dry weight ratio was calculated. RESULTS. Cardiac output in vivo was lower during HTV ventilation than during LTV ventilation (p \ 0.001). CVP did not differ between ventilation strategies while mean airway pressure was higher in HTV ventilation than in LTV ventilation (p \ 0.001). Ex vivo, cardiac function of septic animals was depressed compared to healthy controls (p \ 0.001) In septic animals, cardiac function was better in HTV ventilated animals than in non ventilated animals (p \ 0.05). Ventilation lowered cardiac wet/dry ratio (p \ 0.05). Developed pressure (p \ 0.01) and ?dP/dt (p \ 0.05) correlated inversely with cardiac wet/dry ratio. [1] . Perfusion may be also evaluated by other parameters such as lactate or venous-arterial pCO 2 gradient (delta pCO 2 ). OBJECTIVES. To evaluate if early normalization of ScvO 2 after emergency intubation in septic patients persists over time and if it is associated with similar trends in lactate and delta pCO 2 . METHODS. Ten septic patients subjected to emergency intubation for respiratory or circulatory failure and in whom ScvO 2 increased to [65% after the procedure. These patients were included in a large prospective study published elsewhere [1] . Patients used a common intubation protocol and we evaluated several perfusion related parameters before, 15 min and 6 h after emergency intubation. Statistical analysis included Friedman and Wilcoxon tests. RESULTS. Evolution of perfusion parameters after intubation is presented in Table 1 . Five patients died during ICU stay. As a whole, ScvO 2 remained stable in 5 pts and decreased dramatically at 6 h by[20% in 3 non-survivor patients (lowest 29%). Only 2 pts had a high lactate before intubation that did not normalize at 6 h (both non-survivors). Delta pCO 2 exhibited erratic changes over time with no correlation with ScvO 2 changes and with mortality ( Fig. 1 ). INTRODUCTION. Venous to arterial carbon dioxide difference (Pv-aCO 2 ) could reflect the sufficiency of blood flow in shock states. Time evolution of Pv-aCO 2 during early phases of resuscitation in septic shock has not been widely characterized. We proposed to describe the association between time course of Pv-aCO 2 during the initial resuscitation and outcomes in septic shock. METHODS. Patients with a new septic shock episode admitted to ICU were included. General management was guided according Surviving Sepsis Campaign recommendations. Time 0 (T0) was set when a central venous catheter was inserted to guide reanimation. Simultaneous measurements of lactate and arterial-venous gases were obtained at T0 and 6 h after (T6). Pv-aCO 2 was calculated as the difference between venous CO 2 (blood samples drawn from a central catheter) and arterial CO 2 . A value of Pv-aCO 2 [ 5 was considered as high. Survival at 28 day was described for four groups: persisting high Pv-aCO 2 (high at T0 and T6), increasing Pv-aCO 2 (normal at T0, high at T6), decreasing Pv-aCO 2 (high at T0, normal at T6) and persistently low (normal at T0 and T6). Survival probabilities were estimated using Kaplan-Meier method. Log-rank test was use to estimate a two-tailed p value for the differences in survival among groups. RESULTS. Sixty septic shock patients were analyzed. Mortality rate was 36.7%. No demographic differences at baseline between survivor (S) and non-survivors (NS) were found. There were no differences in the amount of fluids administered at T0 and T6. No significant differences in ScvO 2 at T6 for S INTRODUCTION. Septic shock (SS) has been defined as sepsis related hypotension despite adequate fluid resuscitation ? perfusion abnormalities such as lactic acidosis [1] . Despite this, an operationally simplified definition overlooking perfusion parameters, has been utilized in several landmark studies during the last decades [2] [3] [4] [5] . More recently, a new consensus reemphasized the pivotal role of hypoperfusion in SS definition and added low SvO 2 as a surrogate [6] . Several problems emerge from these apparently interchangeable definitions, including pathophysiologic and epidemiologic (incidence, outcome) issues. OBJECTIVES. Our aim was to evaluate if applicating different commonly used SS definitions to vasopressor-requiring septic patients leads to distinct outcomes. METHODS. We applied the two most utilized SS definitions to hypotensive septic patients managed with a NE-based algorithm [7] for 10 years, generating two major subgroups for analysis (Fig. 1) . Statistical analysis included chi-square test. (Fig. 1) . 102 pts of subgroup 2, exhibited persistent normal lactate levels with a mortality of 15.2% which was similar regardless of SvO 2 [ or \70: p = 0.22. (Fig. 2) . CONCLUSIONS. Commonly used SS definitions are not interchangeable and when applied to the same vasopressor requiring septic patients lead to statistically different mortalities. Our data suggest that lactate and SvO 2 cannot be used indistinctly to define shock condition. A reappraisal of clinical septic shock definition appears to be necessary. OBJECTIVES. To assess intra-and inter-observer agreement of ECG interpretation in adults with septic shock (VASST, NEJM 2008; 358:877) . METHODS. Patients were randomised to receive a blinded infusion of low-dose vasopressin or norepinephrine in addition to open-label vasopressors. Eight ICUs participated in this ECG sub-study; and 12-lead ECGs were recorded at baseline (prior to study drug infusion), and 6 h, 2 and 4 days after initiation of study drug. An intensivist (reader 1) and a cardiologist (reader 2), blinded to patient data and randomization group, interpreted all of the ECGs in duplicate, using a checklist. Prior to ECG interpretation, a calibration exercise was performed to refine definitions and maximize inter-observer agreement; both readers reviewed 25 ECGs (from the current study) representing the spectrum of normal to abnormal. Cohen 0 s Kappa statistic was used to assess intra-and inter-rater reliability. METHODS. The model consists of eight elastic chambers including the heart and circulations. Identification of the parameters is made only from measured pressures in the aorta and pulmonary artery, and the volume in the right ventricle. Septic shock was induced in (N = 6) healthy pigs with endotoxin infusion over 30 min. Right ventricular pressure-volume loops were recorded by conductance catheter and end-systolic ventricular elastance was assessed by varying right ventricular preload. Consent was obtained from the University of Liege Medical Ethics Committee. Errors for the identified model are within 8% when the model is identified from data, re-simulated and then compared to the clinically measured data. Even with a limited amount of available experimental data to identify the parameters of the model, all simulated parameters trends match physiologically expected changes during endotoxic shock. In particular, a close match of the trends of the right ventricular end-systolic elastances are obtained, when compared to previously reported experimental results [1] , including capturing of the peak after 30 min and a decaying oscillation after 30 min. CONCLUSIONS. Pig-specific parameters for the CVS model were accurately identified using a significantly reduced data set. This research shows the ability of the model to adequately and realistically capture the impact of pressure-volume changes during endotoxic shock. In particular, the model is able to aggregate diverse measured data into a clear, clinically and physiologically relevant diagnostic picture as the condition develops. This research thus increases confidence in the clinical applicability and validity of this overall diagnostic monitoring approach. BACKGROUND. Conflicting data exist concerning the effects on the microcirculation of increasing mean arterial pressure (MAP) with norepinephrine (NE) in septic shock. Nearinfrared spectroscopy (NIRS) has been proposed as a tool to quantify microvascular dysfunction in patients with sepsis. By inducing a vaso-occlusive test (VOT), a variety of NIRSderived variables can be measured to assess local metabolic demand and microvascular dysfunction. This trial was conducted to test the effects of increasing MAP by NE on microvascular reactivity in patients with septic shock. After Local Ethical Committee approval and informed consent, we enrolled 10 patients in septic shock with an arterial pressure stabilized by NE. In addition to hemodynamic measurements, SvO 2 and blood lactate level, we measured thenar muscle oxygen saturation (StO 2 ) and muscle tissue hemoglobin index (THI) by a tissue spectrometer (InSpectra TM Model 650, Hutchinson Technology Inc, MN). Serial VOT (upper limb ischemia induced by a rapid pneumatic cuff inflation around the upper arm) were performed. We also recorded during the VOT: basal StO 2 , THI, the slope of the decrease in StO 2 during the occlusion (desc slope; %/min) and the slope of the increase in StO 2 following the ischemic period (asc slope; %/s). Muscle oxygen consumption (nirVO2I) was calculated as the product of the inverse of the slope value by the mean of THI over the first minute of arterial occlusion and is expressed in arbitrary units (U) (Skarda Shock 2007). All these data were obtained at 5 different times: baseline 1 and 2 with MAP of 65 mmHg, then at 75 mmHg and 85 mmHg of MAP by increasing the NE doses and finally to baseline 3. We report here data corresponding to the mean and SD of baseline 1 and 2 versus MAP 85 mmHg analyzed by repeated measures analysis of variance (at 5% level) with Bonferroni adjustment to account for multiple comparisons. Increasing NE dose induced an increase in cardiac output (from 6.08 ± 1.20 to 6.81 ± 1.62 L/min, p \ 0.05) without any changes in heart rate and an increase of SvO 2 (from 70.9 ± 3.2 to 77.7 ± 5.8%, p \ 0.05 OBJECTIVES. To investigate: 1. The effects of ''successful'' protocolised resuscitation (EGDT) on microvessel perfusion (particularly density). 2. Whether there is different effects of EGDT on the microcirculation of septic compared to critically ill non-septic patients and 3. Whether there is a difference in the behaviour of ''true'' capillaries (i.e 1-10 lm) compared to larger microvessels (11-20 lm) at baseline or after resuscitation. Prospective observational study in the emergency and Intensive care departments of an urban teaching hospital. Subjects: 20 septic and 10 critically ill control patients requiring shock resuscitation (MAP less than 65 mmHg, ±CVP less than 8 mmHg, ±central venous saturations less than 75%). All patients had invasive monitoring and identical cardiovascular targets. Patients with known cardiogenic shock or pre-stabilised trauma were excluded. We performed Sidestream Dark field (SDF) videomicroscopy of sublingual microcirculation at the point of EGDT initiation and again on attainment of at least 2 out of 3 cardiovascular goals. Three sites were imaged for 15 s and the clips were analysed randomly off-line to provide an average value for capillary density (total length and count per mm) and a semi-quantitative description of microvessel flow (continuous, intermittent or stopped) as previously described. Vessels were grouped according to diameter as small (0-10 lm) and medium (11-20 lm). Non parametric analysis was used for all within or between group comparisons, data is displayed as median values with [range]. *p \ 0.05 was considered significant. 2 (11) 6 (33) 1 (5) 12 (67) Duration of occlusion (min), mean ± SD 5.4 ± 2.8 3.0 ± 0.0 6.7 ± 3.9 3.0 ± 0.0 Minimal StO2 (%), mean ± SD 40 ± 0 5 2± 14 40 ± 0 5 4± 13 As expected, all septic shock patients, except one (for the VOT FA40% ) and two (for the VOT A40% ) had a recovery slope lower than normal when StO 2 decreased to 40% during arterial occlusion. By contrast, when occlusion lasted 3 min, many patients including patients who eventually died, were misclassified since their recovery slopes were in the normal range. These results could be due to the smaller decrease of StO 2 and in turn a less strong hyperemic response when ischemia lasted only 3 min. Additionally, a significantly (p \ 0.03) shorter time to reach 40% was required when arm (compared to forearm) occlusion was performed. CONCLUSION. When a VOT is required for assessing microcirculatory disturbances in septic shock, we recommend performing it using an arm occlusion until StO 2 reach 40%. AIMS. To analyze the correlation between StO 2 (and its changes derived from a transient ischemic challenge) and global oxygen delivery (DO 2 ) parameters measured invasively using a pulmonary artery catheter (PAC). Observational study, performed in a 26-bed medical-surgical ICU, at a university hospital. We recruited adult patients with cardiovascular insufficiency that required a PAC placement for hemodynamic monitoring and resuscitation. We collected demographic data, and hemodynamic and oxymetric data derived from the PAC. Simultaneously, we measured StO 2 and its changes derived from a vascular occlusion test (VOT). RESULTS. Twenty-two patients were studied. All the patients had a mean arterial pressure (MAP) above 65 mmHg. The DO 2 index (iDO 2 ) range in the studied population was 212-674 mLO 2 /(min m 2 ). The mean SvO 2 value was 57 ± 9%, mean cardiac index (CI) 2.7 ± 1 L/ (min m 2 ), and blood lactate 4.5 ± 3.1 mmol/L. The correlations found between StO 2 and invasive oxygen delivery-related variables are shown in Table 1 . The StO 2 -deoxygenation slope (DeOx) during the VOT showed a significant correlation with SvO 2 (r 0.6, p 0.02).  We did not find any correlation between StO 2 and global flow measurements, such as cardiac index (CI), but we found a correlation between StO 2 and iDO2. This correlation seems related to the arterial oxygen content, and not to global flow. Normal StO 2 values could not rule out low iDO2 and low IC states. Therefore, StO 2 seems to be poorly sensitive to exclude hypoperfusion states.  In clinical practice there remains issues over the appropriate prescribing of antibiotics in patients with unproven sepsis. The prescribing of antibiotics is not without risk and creates a selective pressure on existing bacterial flora resulting in the emergence of virulent and resistant organisms [1] . There is also a cost issue from the inappropriate prescription of antimicrobials [2] . The diagnosis of SIRS can be made with confidence [3] , sepsis cannot and requires confirmation from microbial tests. Empirical usage of antibiotic therapy is commonplace but not ideal. Rapidly detectable, reliable markers of sepsis would help in directing antimicrobial therapy. OBJECTIVES. The aims of this study are to determine the significance of % band forms in SIRS patients suspected to have sepsis. Can they be used as a diagnostic tool in conjunction with procalcitonin in order to direct antimicrobial therapy? METHODS. This is an observational study aiming to assess the ability of serum Procalcitonin and percentage band forms in identifying nosocomial sepsis in patients with SIRS. 32 patients were recruited over an 18 month period in a mixed medical-surgical university teaching ICU. All patients had suspected sepsis arising 'de novo' and had not received prior antimicrobial therapy. Patients had a septic screen performed along with baseline, 24 and 72 hPCT and % band form count. INTRODUCTION. Pneumonia is the most frequent infectious complication after successfully resuscitated cardiac arrest (CA). However, diagnosis is difficult because of many clinical, biological and radiological confounding factors as well as the widespread use of therapeutic hypothermia. This could lead to a broad antibiotic prescription. To assess the utility of plasma procalcitonin (PCT) measurements for diagnosis of early-onset pneumonia in successfully resuscitated CA. Monocentric study (July 2006 -March 2008 with retrospective review of a prospectively acquired ICU database focusing on all consecutive patients admitted for CA and surviving more than 24 h. Patients with an infection prior to CA or with an extra-pulmonary infection developing within 5 days following admission were not studied. All files were reviewed to assess the diagnosis of early-onset pneumonia P(?), or not P(-) during the first 5 days of ICU stay. P(?) was defined by the presence of a new pulmonary infiltrate on chest radiography, persistent for at least 48 h, associated with either positive quantitative culture of the endotracheal aspirates, either, in case of lack of bacteriological sample, conjunction of purulent sputum and hypoxemia (P/F \ 200). PCT was measured at admission, days (D) 1, 2 and 3 (Brahms Kryptor Ò ). Among 245 patients admitted for CA, 132 were studied (48 death before 24 h, 11 evolutive infections and 54 incomplete samples). Pneumonia was diagnosed in 86 patients (65%), and antibiotics were prescribed in 115 during the first 5 days of ICU stay. Characteristics of P(?) and P(-) patients were (median, IQR): age 60 (47-70) versus 60 (50-70) (p = 0.9), ''no flow'' 3 (0-10) versus 6 (1-10) min (p = 0.06), ''low flow '' 15 (5-20) versus 15 (6-23) min (p = 0.95), shockable rhythm 47 versus 37% (p = 0.16), cardiac etiology 68 versus 48% (p = 0.02), therapeutic hypothermia 99 versus 100% (p = 0.46), post-resuscitation shock 51 versus 48% (p = 0.72) and ICU mortality 55 versus 54% (p = 0.9). Using a threshold value of 0.5 ng/mL, negative predictive values were 39% at admission, 42% at D1, 52% at D2, whereas positive predictive values were 72, 68 and 70%, respectively. Patients with post-resuscitation shock had higher PCT levels than those that did not require vasopressors: 6.66 versus 0.95 ng/mL at D1 (p \ 0.001), 6.58 versus 0.82 at D2 (p \ 0.001) and 5.2 versus 0.95 at D3 (p = 0.03). CONCLUSION. Diagnosic value of PCT is poor in survivors of CA and PCT should not be recommended to assess early-onset pneumonia. Post-resuscitation disease could play a major role in the lack of specificity and predictive values. In acute community respiratory infection, low levels of procalcitonin (PCT) have been shown to allow a marked reduction of antibiotic use. The aim of the study was to look for the same efficacy in case of suspicion of infection during ICU stay. METHOD. From April 2008 to December 2008, 529 patients hospitalized in the five intensive care units (ICU) of the university hospital of Liège in Belgium, were prospectively randomized to either a procalcitonin guided approach to antibiotic therapy (PCT group, n = 268) or to a standard approach (Ctrl group, n = 261) when they were suspected of developing an infection. For PCT group guided therapy only, the use of antibiotics was more or less strongly discouraged (PCT level \0.25 or\0.50 lg/ml, respectively) and more or less recommended (PCT level [1 or[0.5 lg/ml, respectively) . Number and duration of antibiotic treatments were recorded. Diagnosis and treatment decisions were reviewed by infectious disease (ID) specialists at the end of ICU stay. RESULTS. There were no differences between groups in terms of age (66 vs. 65), SAPS II score (40.3 ± 16.3 vs. 39.2 ± 16.7), type of patients (medical: 61 vs. 58%, scheduled surgery: 8 vs. 10%, emergency surgery: 21 vs. 21%, trauma: 10 vs. 11%), ICU length of stay [8 (IQR 4-18) vs. 7 days (IQR 4-16)] for PCT and Ctrl group respectively. Suspicion of infection was either evoked on admission (in 41 and 44%) or during ICU stay (in 61 and 59%) in PCT group and Ctrl group respectively. At the time of suspicion, PCT levels was\0.25 lg/ l in 26.8% of the infectious episodes in PCT group and 24.1% in Ctrl group. 79 episodes of suspected infection with PCT level \0.25 lg/ml were recorded. Clinicians decided not to treat 38% of these episodes (n = 30). The remaining 49 episodes were treated, of which 65 % were eventually considered as probable or confirmed infections by ID specialist (n = 32). At the end of ICU stay, ID specialists classified 635 infectious episodes of both groups as confirmed (n = 262; 46.3%), probable (n = 140; 22%), possible (n = 70; 11%) or absent (n = 163; 25.7%). For confirmed episodes of infection, PCT levels were \0.25 lg/ml in as much as 28.1% and above 1 lg/ml in 63.6%; for absence of infection, PCT levels were \0.25 lg/ml in only 56.8% and above 1 lg/ml in 28.8%. The ability of PCT to discriminate between confirmed and probable infections on the one hand and possible or absent infection on the other hand, was tested by the measurement of the surface under the ROC curve, which was 0.67, which is too low to recognize PCT as a valuable marker of infection. There were no difference in the number of treated patients (88 vs. 87%) nor in the number of antibiotic days (64 vs. 60%) between PCT and Ctrl group respectively. CONCLUSIONS. Procalcitonin level as an aid for the decision to treat infection in ICU patients appeared not to be helpful. Antibiotic consumption was not reduced using this tool in our study. INTRODUCTION. Respiratory infections, pneumonias in particular are a common cause of mortality in the intensive care unit (ICU) patients worldwide. Early identification and prompt management of these patients especially with associated Sepsis is crucial in reducing the mortality. Many clinical and laboratory markers have been studied extensively to predict the outcomes in them. There have been numerous studies on the clinical utility of Serum Procalcitonin (PCT) in the past decade, in systemic inflammation, infection and sepsis. OBJECTIVE. To evaluate the role of Serum Procalcitonin, in predicting the outcomes of patients admitted in the ICU with Respiratory infections associated with Sepsis. Setting: 10 bedded ICU of a tertiary referral hospital. Study design: Prospective observational study. Subjects: 85 adult ([18 years) patients admitted in the ICU with lower respiratory tract infections with associated Sepsis during the period July 2007 to January 2009 were prospectively followed up. Primary outcome measure: 28 day mortality. We measured PCT levels using the BRAHMS immunochromatographic technique(semiquantitative estimation) on the first day of admission into the ICU . Normal PCT was taken as \0.5 ng/ml. Patients were grouped into four groups-group A (PCT \ 0.5 ng/ml), group B (PCT [ 0.5 -2 ng/ml), group C (PCT [ 2 -10 ng/ml),group D (PCT [ 10 ng/ml). Sepsis, severe sepsis, septic shock are defined according to the 1992 ACCP/SCCM criteria. RESULTS. The overall mortality was 25.8% with mortality of 3.1, 7.6, 50, and 50% in Groups A, B, C and D, respectively. There is a statistically significant difference (p \ 0.05) in the mortality rates of Groups C and D as compared with Group A and B, but no difference was observed in the mortality rates between Groups A and B and Groups C and D .Also significant statistically are the APACHE II Scores, Septic Shock and Multiorgan failure incidence in the Groups C and D as compared to Groups A and B. CONCLUSIONS. Serum Procalcitonin level [2 ng/ml on the first day of admission in ICU appears to be a good predictor of mortality in patients admitted with lower respiratory tract infections and associated Sepsis. METHODS. In a retrospective study we assessed 458 acutely ill patients investigated for PCT and treated by a physician blinded for PCT value. For each patient we also calculated New Simplified Acute Physiology Score (SAPS II). We evaluated many clinical and instrumental parameters and diagnosis was done upon our usually clinical practice RESULTS. The mean age of patients (pt) was 73.9 yeats, shock was found in 129 patients (28.4%),median value of SAPS II score was 33 (IQR 40-26), and median estimated mortality from SAPS II was 14% (IQR 24-27). Bacterial infection was found in 77.3% (septic shock 16.7%, pneumonia 51.1%, cholecystitis 3.7%, pleural empyema 1.4%, other infections 27.1%) non infective disease in 22.7% (pulmonary embolism 7.7%, acute coronary syndrome 9.6% Heart failure 18.3% other disease 64.4%. A PCT value [ 0.25 ng/ml was considered positive: so PCT was elevated in 59.6% of bacterial infection patients and in 30.8% of non infective disease patients. We also compared PCT values with antibiotic therapy and considered appropriate the administration if PCT [ 0.25 ng/ml: there was discrepancy in 39.1%. The review of these cases found medical decision wrong in 72 cases versus 248 (38.2%); 70 pt with PCT \ 0.25 ng/ml had antibiotic therapy without BI and 2 cases with PCT [ 0.25 ng/ml did not have antibiotic therapy but had a bacterial infection. Subsequent to this review discrepancy felt to 23.1% (CI 95% 19. 3-27.3) and was found especially in pt with PCT \ 0.25 ng/ml. At cut off point of 0.25 the sensitivity was 0.87 (CI 95%:0.82-0.90) specificity 0.33 (CI 95%:0.27-0.40) OR 3.1 and at point 5.0 the sensitivity was 0.90 (CI 95%:0.92-0.95) specificity 0.26 (CI 95%:0.22-0.30) OR 3.1, with high predictive positive value. All-causes mortality was 19.4%. Mortality if PCT \ 0.25 ng/ml was 9.8%, if PCT 0.25-5.0 ng/ml was 24.5%; if PCT 5.0-10.0 lg/ml was 38.2% and if PCT [ 10 ng/ml was 31.0% without significant difference between bacterial infection and non infective disease group. Comparing PCT with SAPS II score, area under ROC-curve was not significantly different (PCT 0.68-CI 95%: 0.60-0.74) (SAPS II 0.75-CI 95%: 0.68-0.80). CONCLUSIONS. PCT in acutely ill patients is a useful marker to discriminate bacterial infections with high sensibility but low specificity and it may be useful to guide the therapy also with values higher than 0.25 ng/ml. Our data suggest a real prognostic utility of PCT in these patients, regardless of bacterial infections, but our efforts to elaborate a mathematical predictive model aren't still satisfying and further data are required in this setting. H. Taniuchi 1 , T. Ikeda 1 , K. Ikeda 1 , S. Suda 1 1 Tokyo Medical University, Hachioji Medical Center, Division of Critical Care Medicine, Tokyo, Japan INTRODUCTION. Its apparent that detection of the causative bacteria is useful for the therapeutic strategy. However, conventional tests for the detection of the causative bacteria are not high sensibility. In order to diagnose sepsis or septic shock and start appropriate therapy rapidly, it's also important to know whether the infection is cause of gram negative bacteria, that is to say, whether the infection is cause of endotoxin. In this study, we investigate the severity level of sepsis and initiation criteria of direct hemoperfusion with polymixin B immobilized fiber column (PMX-DHP) treatment from the result of severity level by using Endotoxin Activity Assay (EAA) and using measurement of procalcitonin (PCT). SUBJECTS AND METHODS. 26 patients who developed severe sepsis or septic shock and admitted to ICU were included. On the day of ICU admission, a general blood biochemistry, EAA and PCT levels, and APACHE II and SOFA score were measured. Patients were evaluated retrospectively the relationship between the severity of sepsis and each measurements and investigated the relationship between the measurements and PMX-DHP. Serum EAA level was measured using Smart Line EAA Luminometers. Serum PCT level was measured using immune luminometric assay. RESULTS. The average age of the patients is 72 ± 12, APACHEII score was 23.5 ± 6.5, SOFA score was 9.0 ± 3.1, the median PCT was 26.0 ng/ml (range 0-200), EAA was 0.52 ± 0.26. The underlying diseases of the enrolled patients were the abdominal infection (12 patients), the urinary tract infection (3), pneumonia (3), the meningitis (2), the soft tissue infection (2) and other infection (5) . The causative bacteria were gram positive bacteria (7), gram negative bacteria (9), virus (1), and unknown (9). There was no statistical correlations between EAA or PCT level and APACHEIIscore. There was no statistical correlations between EAA level and SOFA score. Although there was no statistical correlation between PCT level and SOFA score, the PCT level tended to rise as PCT level rises. We investigated the relationship between EAA and PCT levels. There was also no statistical correlations between EAA and PCT. We investigated the relationship between the causative bacteria (gram positive bacteria, gram negative bacteria and the others) and EAA or PCT level. There was no statistical correlations between the causative bacteria and EAA level nor PCT, that was contrary to our expectation that EAA level should be high for gram negative bacterial infection. We further investigated the relationship between whether or not the PMX-DHP was implemented and EAA or PCT level. There was no statistical relationships. CONCLUSION. High levels of the EAA and PCT would not indicate the severe infection with gram negative bacteria, and the initiation of PMX-DHP. Further study is needed, in which more patients will be enrolled and evaluated. INTRODUCTION. Sepsis still the major cause of death in the late post traumatic period in patients with major burns. Early diagnosis of sepsis is crucial for management and outcome of critically burn patients. Attempted in this Study to assess whether plasma procalcitonin (PCT) level was related to diagnostic and prognostic of sepsis in burned patients. PATIENTS AND METHODS. PCT was measured over the entire course of stay in patients with predictive signs of sepsis according to American College of Chest Physician. The patients were assigned to two groups depending on the clinical course and outcome: A = no septic patients, B = septic patients. Optimum sensitivity, predictive values, and area under the receiver operating characteristic (ROC) curve were evaluated. RESULTS. Over a 6 month period starting from 1 July 2008 to 31 December 2008, 157 patients were admitted. 62 were investigated. 40 in group A et 22 in group B. Procalcitonin was significantly higher in septic group 7.26 ± 7 ng/ml compared to no septic group 0.25 ± 0.32 ng/ml. Area under the curve was 0.94 on the day of sepsis diagnostic. PCT cut-off value of 0.75 ng/ ml was associated with the optimal combination of sensitivity (85%), specificity (87%), positive predictive value (91%), and negative predictive value (73%). In survived septic patient the PCT value was significantly lower than in deceased septic patients 3.5 ± 0.87 versus 10.18 ± 9.6 ng/ml. PCT cut-off value for optimum prediction of outcome in septic patients was 3.66 ng/ml with sensitivity (91%), specificity (75%), positive predictive value (78%), and negative predictive value (90%). CONCLUSION. Procalcitonin appears to be a powerful marker of sepsis in burn patients. It is sensitive, specific, reliable and easy to measure. A high PCT concentration ([3.66 ng/ml) would indicate poor outcome in septic patients. N. V. Beloborodova 1 , A. S. Khodakova 1 , A. Y. Olenin 1 , S. T. Ovseenko 1 1 Bakulev Scientific Center for Cardiovascular Surgery, Moscow, Russian Federation OBJECTIVES. Accurate and timely diagnosis of sepsis remains challenging for clinicians. The diagnosis of sepsis is defined as typical symptoms of systemic inflammation (temperature, tachycardia, respiratory rate, leukocytosis) with clinical evidence of an infection site, but the criteria are met by a large number of intensive care unit (ICU) patients. Among studied biomarkers, serum procalcitonin (PCT) has been described as one of the most promising predictors of bacterial sepsis, but in some clinical situations it is not enough. The search of reliable markers of sepsis is still in progress. In present study the significance of raised levels microbial phenylcarboxylic acids in serum of patients with sepsis are assessed. METHODS. The present study evaluated 22 serum samples of patients (pts) with documentary sepsis, according to well known consensus criteria. The comparison groups were: No. 1-16 clinically healthy volunteers, No. 2-36 pts. with acquired heart diseases, No. 3-19 pts with ventilator-associated pneumonia. Blood concentrations of phenylcarboxylic acids were determined by gas chromatography-mass spectrometry (GC-MS). Results are presented as median and range of 25th and 75th percentiles. The statistically significant differences between the various groups were calculated using Mann-Whitney test. RESULTS. Increased levels of phenyllactic (PLA), p-hydroxyphenylacetic (HPAA), p-hydroxyphenyllactic (HPLA) acids were observed in group of pts with sepsis. The level of HPAA was increased up to two orders in comparison with groups No. 1 and 2 [14.1 (7.8-35.9) vs. 0.5 (0.4-0.6) and 0.7 (0.3-1.4) lM, p \ 0.0001). The levels of HPLA and PLA were increased up to one order [(7.6 [2.9-15.5] Table 1 for illustration of importance of phenylcarboxylic acids blood level monitoring. INTRODUCTION. Acute kidney injury (AKI) is a frequent complication of sepsis, and is associated with high mortality and morbidity rates. Routinely used measures of renal function, such as levels of blood urea nitrogen (BUN) and serum creatinine, increase only after substantial kidney injury occurs, resulting in delayed diagnosis of AKI. Therefore biomarkers, which enable early diagnosis, are needed. OBJECTIVES. This clinical study was designed to investigate whether human interleukin-18 (IL-18) and neutrophil gelatinase-associated lipocalin (NGAL) are early predictive markers for sepsis-induced AKI. Urine and blood samples have been collected prospectively from ICU patients, who met defined clinical criteria of severe sepsis. AKI was defined by RIFLE criteria. Urinary and serum levels of N-GAL and IL-18 have been quantified by ELISA in patients with sepsis without AKI (n = 11) and in patients with sepsis induced AKI (n = 13). RESULTS. Both, urinary IL-18 and serum IL-18 considerably increased (respectively, 7.22 and 19.54-fold over the baseline) two days before the patients reached RIFLE risk. Urinary NGAL raised significantly (1.72-fold over the baseline) one day before occurrence of AKI, whereas serum NGAL did not show any prior elevation. No increase in the levels of any of these markers could be found in patients who did not develop AKI. CONCLUSIONS. Both urinary and serum IL-18 seem to be sensitive early biomarkers for sepsis associated AKI, while urinary NGAL has less accuracy for AKI prediction. OBJECTIVES. To define a biomarker panel able to predict infection in case of severe acute dyspnea in emergency situations. We designed a prospective observational study of patients admitted in the Emergency Department (ED) and in medical polyvalent Intensive Care Unit (ICU) in a university hospital. Inclusion criteria were acute dyspnea with SpO 2 B 92% and/or respiratory rate (RR) C 25 b/min. Patients with an immediate need of coronarography or with obvious spontaneous pneumothorax were excluded. Five biomarkers were measured from blood sample at admission on ED or ICU: NT B type Natriuretic Peptide (NT proBNP), cardiac troponin I (cTNI), DDimeres (DD), C-reactive protein (CRP) and procalcitonin (PCT). All clinical and biological data were recorded. An independent blinded data monitoring committee classified the patients according to all the available data including response to treatment and outcomes but blindly to biomarkers. The roles of biomarkers were assessed quantitatively and then using terciles of the distribution. The contribution of the biomarkers in the diagnosis was assessed using multiple logistic regression taking into account other clinical and biological explanatory variables. . 172 patients were enrolled consecutively. The final diagnosis was: severe sepsis (n = 50), acute heart failure (n = 42), pulmonary embolism (n = 11), COPD (n = 21), other causes (n = 48). The 28 days mortality was 17%. There was no significant association between infection diagnosis and DD, cTNI, NT proBNP. Interestingly, a CRP value of less than 5 mg/l was not discriminant in predicting infection. Adjusted on clinico-biological covariates selected, both PCT with cutpoints of 0.1 and 0.4 ng/ ml (discrimination AUC 0.850; p = 0.008) and CRP with cutpoints of 30 and 100 mg/l (discrimination AUC 0.857; p 0.001) were significantly associated with the diagnosis of sepsis. Both biomarkers used simultaneously lead to a discrimination of the model (AUC 0.879). CONCLUSION. Both CRP and PCT are able to predict the diagnosis of infection in case of severe acute dyspnea independently of clinico-biological variables. In this particular subpopulation, the best threshold for CRP is higher than the standard one. An external validation is needed to prospectively validate the clinical utility of these findings. T. Trefzer 1 , I. Nachtigall 1 , A. Weimann 2 , C. de Grahl 1 , C. Spies 1 1 Charite Universitaetsmedizin Berlin, Campus Virchow, Department of Anesthesiology and Operative Intensive Care Medicine, Berlin, Germany, 2 Charite Universitaetsmedizin Berlin, Campus Virchow, Zentralinstitut für Laboratoriumsmedizin und Pathobiochemie, Berlin, Germany AIMS. Infections are the most relevant ICU-admission complication. CRP and PCT are labvalues used for diagnosis of infections. However, their use is often not evidence based. This study aimed to access whether the adherence rate increased after introducing an evidencebased standard operating procedure (SOP). In 2008 an evidence-based SOP was approved by experts of our department. In July 2008 it was made available to ICU-physicians via Intranet, which is accessible from every work station. Altogether, we assessed SOP-adherence rates of 602 patients: 188 in June 2008 (pre-SOP), 204 patients in August 2008 (one month post-SOP) and 194 in January 2009 (6 months post SOP). Every CRP and PCT measurement was assessed for adherence to the standard operating procedure (SOP). At first, the three periods were assessed for significant differences concerning the adherence. According to the percentage of SOP-conform measurements the patients were then divided into two groups: the SOP-group (C70% of measurements SOP conform) and the non-SOP (NSOP) group (\70% conform) In a second step, patients in the SOP-and NSOP-group were compared concerning ICU scores (SOFA, TISS, APACHEII, SAPS) and outcome parameters (length of ICU-stay, length of hospital stay, duration of mechanical ventilation, hospital mortality). Statistics: p B 0.05 was considered as statistically significant; hospital mortality was assessed by a v 2 test, ICU scores and outcome parameters were compared using the Mann-Whitney U Test. All parameters with p \ 0.1 were included into a logistic regression analysis. No change was observed concerning the implementation of the SOP pre and postintroduction: 33.5% in June 2008, 36.3% in August 2008 and 33.0% in January 2009. The non-conform PCT-and CRP-measurements resulted in additional costs of approximately 40.000 Euros/year. The univariate analysis revealed significant differences in the SOP-and NSOP-group: the NSOP-group had higher SAPS-, SOFA-and TISS-Scores, as well as increased length of ICU-stay, length of hospital stay and duration of mechanical ventilation. Logistic regression analysis revealed TISS Score and length of hospital stay as an independent predictor for low SOP adherence. CONCLUSION. Distribution of an evidence based SOP without further education did not lead to a significant increase in adherence rates, but TISS Score and length of hospital stay have shown to be independent predictors for low adherence to the SOP. The significant higher TISS-Scores in the NSOP group might be a indicator for actionism of clinicians in the face of more severely ill patients. OBJETIVES. To asses the evolution of the risk-adjusted mortality rates of Sepsis and Septic Shock in our ICU in a ten years period. PATIENTS AND METHOD. Analisys of prospectively recorded data of all pacients admitted with Severe Sepsis and Septic Shock in a 10 bed ICU during a period of 10 years. Patients were followed up until death or discharge from the hospital, excluding those with unknown outcome. Mortality prediction was made using APACHE II model with 95% Confidence Intervals. Statistical analisys was made with SPSS 16.0 using ANOVA test or T Test to compare means and Chi square test to compare categorical variables. RESULTS. From January 99 to December 2008 a total of 733 patients with sepsis were admitted, with an anual increase to reach 20% of all ICU admissions. Age and severity of illness increased anually as did SOFA in the first 24 h (SOFA1) thus rising up calculated risk of death. From 1999 to 2004 mortality rate was between 95% ICs of calculated risk of death, falling below inferior IC from and after 2005. (Fig. 1 ). Hospital mortality versus risk of death per year Mortality was 51.6% in the pre-2005 period and 44.4% from 2005 and on (p = 0.05) with non significant differences in APACHE II, risk of death nor SOFA1, but with significantly greater age in the post-2005 period (62.6 vs. 58.3 years p = 0.01). This non significant difference between the two periods of the study became significant when we analized the outcome in both sex. being significant in women (mortality 41.1% in pre-2005 period vs. 31.4% in post-2005 p = 0.02) but not in men (57.3 vs. 52.5% p = 0.2). Overall Sepsis moratlity is lower in female without significant differences in Age, APACHE II score nor risk of death (Table 1) , being the only signifficant difference found in SOFA1 (8.63 in male vs. 7.92 in female p = 0.03). INTRODUCTION. Low-grade systemic inflammation has been shown to play a key role in the pathophysiology of several chronic noncommunicable diseases [1, 2] and may be attenuated by anti-inflammatory treatments such as administration of statins [3] . So far, the association between acute systemic inflammation experienced during critical illness and long-term mortality after hospital discharge has not been investigated in intensive care unit (ICU) patients. OBJECTIVES. To assess the association between acute systemic inflammation, assessed by CRP levels, and post-hospital mortality in non-surgical ICU patients. METHODS. The study was performed as a prospective, observational follow-up study and included non-surgical critically ill patients with an ICU length of stay [24 h. Patients who died during the ICU or hospital stay, were \18 years or pregnant, as well as patients discharged from the hospital with the plan to limit life support were excluded. Demographics, chronic diseases, admission diagnosis, the Simplified Acute Physiology Score II, length of ICU stay, maximum CRP levels during the ICU stay (CRPmax) and CRP levels at ICU discharge (CRPdis) were documented. After a mean ± SD follow-up time of 2.04 ± 1.08 years, mortality and causes of death were determined. Adjusted Cox models were calculated to investigate the association of CRPmax and CRPdis with post-hospital mortality. A receiver operating characteristic analysis was used to identify optimal cut-off levels to predict post-hospital mortality. BACKGROUND. The prevalence of HIV infection is increasing worldwide as a public health problem. Survival of HIV/AIDS patients has improved since highly active antiretroviral therapy, but sepsis has grown as an important cause of ICU admission in this population. An international conference has set a system composed of specific risk factors, site and microbiology of severe infections and host response and organ dysfunctions (PIRO) to help identify patients at risk for sepsis. PIRO factors have not been classified for HIV/AIDS population yet. OBJECTIVES. To identify predisposing factors, microbiology of infections, host clinical response and incidence of early organ dysfunctions of severe sepsis on HIV/AIDS patients, admitted to a specialized infectious diseases ICU; to analyze long-term survival of HIV/AIDS critically ill patients. A prospective case-control study of septic and non-septic HIV/AIDS patients admitted between June 2006 and May 2008 was performed. Demographic data, causes of admission, time since AIDS defining condition, CD4 cell count, and opportunistic infections were evaluated as predisposing factors to sepsis. Microbiology and site of infections were registered. Clinical response to severe infections was evaluated by ALI/ARDS and shock incidence on day 1 of ICU admission. Organ dysfunctions (SOFA score) were reported soon after ICU admission. ICU length of stay, hospital and 6-month mortality were compared between septic and non-septic groups. A multivariate regression analysis was done to identify risk factors for ICU mortality. Kaplan-Meyer survival curve was built. . 108 ICU admissions of 101 HIV-infected patients were studied. Half (54) fulfilled criteria for severe sepsis diagnosis. Septic group was younger (39.0 ± 11.8 vs. 43.4 ± 11.7 years, p \ 0.05) and had more female patients (35 vs. 17%, p \ 0.05). Time since AIDS diagnosis, CD4 cell count and opportunistic infections prevalence were not different. Sites of infection were predominantly pulmonary (48%) and catheter-related (19%). Ninety percent of infections were nosocomial. Forty-three percent of septic patients presented bacteremia. Pseudomonas sp, S aureus and Enterobacteriacae were commonly identified, but five patients had Mycobacterium tuberculosis isolated (2 on blood cultures). Multiple organ dysfunction syndrome was frequent, and incidence of cardiovascular, respiratory and hematological dysfunctions was significantly higher in septic group. Longer length of ICU stay (19.6 ± 20.5 vs. 9.4 ± 8.7 days, p \ 0.01) and ICU mortality (61 vs. 18%, p \ 0.01) was observed for septic patients. Severe sepsis also influenced long-term survival, as mortality continues significantly higher after 6 months (log rank 17.3, p \ 0.001). CONCLUSIONS. PIRO system is applied to septic HIV/AIDS patients. Shock, ALI/ARDS and hematological dysfunctions are prominent for septic HIV/AIDS population. Septic HIV/ AIDS patients are at severe risk of short and long-term mortality.  International guidelines for management of severe sepsis and septic shock suggest the use of recombinant human activated protein C (rhAPC) in adult patients with high risk of death (APACHE II C 25 or multiple organ failure). The objective of this study is to analyse the characteristics and outcome of patients treated with rhAPC in our medical intensive care unit. Retrospective study of patients with severe sepsis/septic shock treated with rhAPC between January 2005 to December 2008. All of them were C18 years, with APACHE II C 25 and two or more organ dysfunction, and were treated on basis of a bundle for severe sepsis management: complete early goal-directed therapy, early administration of broadspectrum antibiotics; corticosteroids in vasopressors unresponsive patients and monitor for lactate clearance. Chi-square analysis were used to compare categorical data. Continuous data were compared using Student's t test. Prognostic factors of mortality were studied by means of multivariable logistic regression analysis. RESULTS. Forty-one patients were studied. 80% were male. Their mean age was 55 ± 18 years. 44% had comorbidities (26% immune pathology). Severity scores. APACHE II 29 ± 7, SOFA 11 ± 3, 39% of patients had three o more organ dysfunction. 93% had septic shock. Serum lactate level was 5.1 ± 2.6 mmol/l. The primary location of infections was: respiratory 71%, abdominal 15%, urinary 7%. 31.7% were positive blood culture. 83% of patients needed mechanical ventilation (18 ± 15 days). 26% of rhAPC infusions were not completed, mainly for bleeding risk (36%) and death (27%). 2.4% of patients had bleeding event. At the end of the infusion 58% of patients remained with two or more organ dysfunction and 56% were vasopressors dependent. Mean hospital stay was 31 days and 19 days in ICU . 28 days mortality was 39%, ICU mortality 41.5% and Hospital mortality 48.8%. Analyzed data included age, comorbidities, primary location of infections, severity scores and serum lactate level. Univariable analysis showed that statistically significant factors related to mortality were: APACHE II (31 ± 7 vs. 27 ± 6, p = 0.04), organ dysfunction number: 2 vs. [2 (25 vs. 58%, p = 0.02) and primary location of infections: pneumonia versus others (59 vs. 25%, p \ 0.05). A multivariable logistic regression analysis showed that age (OR 1.10, 95% CI 1.01-1.12, p = 0.03), organ dysfunction number (OR 14.75, 95% CI 1.81-117.38, p = 0.01) and serum lactate levels (OR 1.50, 95% CI 1.01-2.21, p = 0.04) had statistically significant relationship to mortality. CONCLUSION. In our study the patients with severe sepsis and septic shock remained with high vasopressors dependency and organ dysfunction at the end of the rhAPC infusion. Despite of rhAPC therapy the mortality of patients was very high. The age and the severity at ICU admission were independent prognostic factors of mortality. A higher incidence of severe sepsis in blacks compared to whites is well documented, however prior analyses do not discriminate whether this is due to a higher incidence of infections, a higher risk of developing organ dysfunction once infected, or both. OBJECTIVES. We sought to understand whether higher severe sepsis incidence in blacks is due to higher infection susceptibility, higher risk of organ dysfunction once infected, or a combination of both. We analyzed 11,430,630 hospitalizations from 2005 hospital discharge records of 7 US States (25% of US population). We linked these records to US census data to generate age and sex-standardized incidence rates. We identified infections of bacterial and fungal etiology based on ICD-9 CM criteria, including characterization by site and type of infection (gram negative vs. gram positive). We defined severe sepsis as documented infection plus acute organ dysfunction based on previous work by Angus et al We estimated the risk of organ dysfunction among those hospitalized with infections using logistic regression, adjusting for age, sex and comorbidities (Charlson score). Fig. 1b ]. The combination of both events led to a 66% higher severe sepsis hospitalization rate for blacks (9.3 vs. 5.6 per 1,000 population, IRR: 1.40-2.05). These differences persisted when stratified by sex, comorbidities, site and type of infection. Infection Incidence and severe sepsis risk CONCLUSION. The higher incidence of severe sepsis among blacks is due to a higher hospitalization rate for infections, as well as a greater likelihood of organ dysfunction once infected. Future interventions to reduce racial disparities in severe sepsis incidence should target both distinct events. GRANT ACKNOWLEDGEMENT. Dr. Mayr was supported by T32 HL007820-10. OBJECTIVE. To describe recent epidemiological data and mortality risk factors of patients admitted to ICU for severe pneumococcal pneumonia (PP). Multicentric retrospective study (January 2001-June 2008). Prospective acquired data from patients admitted in 37 French medical ICU for severe PP were considered. Patients with concurrent meningitis, severe COPD with known SP colonization, HIV or aspiration pneumonia were not included. PP was defined by the combination of a suggestive clinical context, the presence of a new pulmonary infiltrate on chest radiography and a S.pneumoniae positive bacteriological sample (pulmonary quantitative culture, pleural fluid, blood culture or urinary antigen assay). All files were reviewed and approved by two independent investigators (NM, AM). . 224 patients were included. Median age was 60 ± 16. Hospital survivors were significantly younger (58 ± 16 vs. 66 ± 15, p = 0.001). Sex ratio M/F was 151/73, but male sex was associated with higher risk of death (male: 59 vs. 83%, p = 0.001). Active tabagism (39%) or alcohol abuse (29%) were more common than asplenia (1%). Organ dysfunctions were mainly respiratory (82%), haemodynamic (70%) and renal failures (30%). Low doses steroids were prescribed in 44% of patients with septic shock. ICU mortality rate reached 25% (22% in the first 5 days); hospital mortality rate was 30%. Univariate analysis demonstrated that age, male sex, cirrhosis and organ failure support were strong predictors for ICU mortality. Multivariate analysis only highlighted age [OR 1.5 (1.01-1.08)], cirrhosis [5.27 (1.28-21.66) ] and renal replacement therapy [3.56 (1.56-8. 14)] as independent mortality predictors. Activated protein C treatment was associated with decreased mortality [OR 0.27 (0.08-0.77)]. Bacteremia had no impact on outcome. CONCLUSION. This is the most important cohort of PP requiring ICU admission. Despite adequate antibiotherapy, mortality is still preoccupant. Determination of factors related to the bacteria (virulence) or to the host (genetic susceptibility) could allow a better understanding of this important health problem. INTRODUCTION. To identify the risk factors of mortality for patients with severe community-acquired bacteremic pneumococcal pneumonia. Retrospective study realised in the intensive care units of two Hospital Medical Centers. The studied population was 70 patients with serious community-acquired bacteremic pneumococcal pneumonia. All the patients entered the intensive care units between January of 1997 and December of 2008. Study variables were: age, sex, concomitant pathology, toxic habits, pre-vaccinal (1997-2001) and postvaccinal periods (2002) (2003) (2004) (2005) (2006) (2007) (2008) , serotype and sensitivity of Streptococcus pneumoniae to penicillin, the initial use of the Non-invasive mechanical ventilation, the development of empyema pleural, APACHE II and SOFA scores during the first 24 h after admission. RESULTS. The age average was of 55 years. Forty one percent of our patients required mechanical ventilation, and 31% had acute renal failure that required hemofiltration. Average values of APACHE II and SOFA were 19.8 and 7.6 respectively. In hospital mortality of the series was of 25%.  In patients with severe community-acquired bacteremic pneumococcal pneumonia: (1) The presence of empyema pleural is an independent risk factor for mortality. INTRODUCTION. Procalcitonin (PCT) is an interesting marker of pulmonary infection [1] . It is useful as an help for infection diagnosis but also for treatment follow-up [2] . Besides, initiation of effective antimicrobial therapy is the strongest predictor of outcome in patients with septic shock [3] . The aim of the study was to analyse whether kinetics of PCT decline may reflect sensitivity of identified infectious agents to initial antimicrobial therapy (AT). Patients with diagnosis of severe pneumonia following major cardio-thoracic or vascular surgery were retrospectively included in the study. Severe pneumonia was suspected as a combination of several manifestations including fever or hypothermia, hyperleucocytosis or leucopenia, new radiological infiltrate, and/or a clinical pulmonary infection score [6, PCT [ 1 ng/mL and PaO 2 /FiO 2 \ 200. Initial antimicrobial treatment was chosen according to the guidelines in use in our institution for community-acquired or nosocomial infections. Microorganism identification from endotracheal aspiration or bronchoalveolar lavage, and antibiotic susceptibility testing, allowed to classify patients according to appropriate (aAT) versus inappropriate initial AT(iAT). PCT was measured daily over 14 days and its kinetics compared between both groups. Data are expressed as median (extremes) or mean ± SD (decrease rate). RESULTS. 28 patients aged 69 ± 9 (66-73), operated on vascular (n = 6), thoracic (n = 7), or cardiac surgery (n = 15) have been studied from october 2007 to July 2008. Pneumonia occurred within the 1st to the 31st postoperative day (median 6.7 days), with a septic shock in 8 cases and 4 deaths at day 14. Initial AT was appropriate in 75% (21/28) patients. PCT peak was not statistically different between aAT versus iAT patients (17.7 ± 42.2 ng/mL vs. 12.7 ± 26.6, respectively) but PCT decrease was significantly steeper and constant in iAT patients (Fig. 1 ). PCT decrease (%) from peak value over days Discussion: The results suggest that absence of early decrease in PCT within 2 days may reflect failure of the AT. Conversely, an average decrease in PCT plasma concentration of 50% in 2 days seems to be a good marker of sensitivity of the causative infectious agent to the initial AT. In case of unchanged PCT within 2 days AT change should be considered. ICU mortality was 43% for pts with RB early VAP while it was 22% (16 of 72 cases) in those with SB or negative cultures (p = 0.04). Mortality was higher than the predicted according to APACHE II score in pts with RB VAP (43 vs. 30 ± 22%, p \ 0.01). However, it was lower than predicted in those with negative or sensible isolates (22 vs. 27 ± 24%, P = 0.08). CONCLUSIONS. RB were the most common cause of early VAP among our patients. The burden of illness, LOS in ICU before intubation and previous use of antibiotics were associated with early VAP due to RB. Inappropriate empiric therapy and mortality were higher among patients with early VAP due to RB.  To evaluate the performance of the SAPS 3 PIRO model in patients with severe Community Acquired Pneumonia (CAP), over a period of 5 years (2003-2008) , in a General ICU in a central Hospital. MATERIAL AND METHODS. We analysed data prospectively registered in an informatic data base, which contains information referring to all patients admitted in this unit. Analysed were 74 patients. Discrimination was accessed by the area under the ROC curve (aROC). Calibration was evaluated by the by the Hosmer-Lemeshow Ĉ test. CONCLUSION. Implementation of a sedation protocol requires constant follow up and regular adaptation to prove efficient over time. Constant feed back information to both the medical and nursing staff is mandatory. Treatment of hyperactive delirium. Hal haloperidol, Bzd benzodiazepine, Pro propofol, AA atypical antipsychotic, ND no drugs, NA not answered DISCUSSION. There tends to be a general pessimism regarding obese patients within the intensive care community. Our data indicates that this opinion could be misplaced. Reduced ventilator days may reflect a reluctance to invasively ventilate obese patients. The APACHE II scoring does not take into account the BMI which would eliminate any severity scoring bias. High BMI alone should not be a consideration in the decision regarding suitability for admission to critical care. During the last decades, a growing medical knowledges have changed the clinical approach to elderly patient diseases. They receive major surgery or intensive treatment for acute medical illness but often the recover is condictioned by the previous chonical diseases. This determines a long period to stay in Intensive Care Unit (ICU) because the slow improvement and cause an occupation of bed places. In our Hospital, after a period of training performed by an Intensivist (BC) and an Internist (AG), ICU patients who need a Non Invasive Ventilation (NIV) or tracheostomized elderly patients who have difficult weaning were admitted in a dedicated area in a Medical Department (MD). This study desribes the results of one year of observation. In the last year, forty nine patients (age 70.2 ± 12.3; M 26 F 23) were transferred from ICU to MD. Twenty three patients were treated with NIV (age 67.2 ± 12.5; M 12 F 11), fourteen tracheostomized patients (age 72.2 ± 10.8; M 9 F 5) receive positive pressure ventilation because the difficult weaning in ICU while twelve don't need any respiratory support. At the admission was performed a multidisciplinary plan and many specialists were involved (dietist,physiotherapist, pneumologist) and in invasively ventilated patients (IVP) was done a program of weaning. We follow all the patients until the discharge at home where someone need oxigenotheraphy, NIV or mechanical ventilation. For the invasive ventilated patients we try to identificate significative differences beetween patients discharged at home and patients who died in hospital. Data are given as mean ± SD and statistical analisis t test was performed RESULTS. Patients underwent NIV stay in hospital for 21.3 ± 19.2 days (7.0 ± 4.9 days in ICU-15.1 ± 9.2 in MD) and ventilation was performed for the entire period in ICU while for 8.4 ± 5.6 days in MD. All the patients were discharged at home: twelve with NIV, fourteen with oxygen. The lengh to stay in hospital for the IVP in wich weaning was failed in ICU was 91.2 ± 25.4 days (36.0 ± 18.4 days in ICU-55.1 ± 23.6 in MD). In MD they continue the invasive ventilation for 44.4 ± 34.7 days. Seven were weaned from ventilation after 20.9 ± 14.2 days, one was discharged at home with the ventilator while six died in hospital. Patients who died were older (79.2 ± 7.7 vs. 67.8 ± 11.2 years-P 0.05), have more chronical diseases (3.0 ± 0.7 vs. 2.2 ± 0.44-P 0.03), longer hospitalization (112.2 ± 12.0 vs. 81.5 ± 20.3 days-P 0.005), Glascow Coma Scale (8.2 ± 3.8 vs. 15). Elderly patients often require a long period of recovery from acute ilness. In selected patients MD could be a useful place where continue the treatment started in ICU. In our study IVP who died had more chronical diseases and a more significative cognitive compromission. AIM. Documenting the qualitative and quantitative properties of administered and lost fluids is a common critical care monitoring practice. These nurse-registered fluid balances (FB) are used to optimize patient care and in clinical decision-making. This ''good clinical practice'' has also found application in research: recent studies reporting superior outcomes expressly refer to (negative) FB. We prospectively assessed the accuracy (review of all fluid balance charts and correction of arithmetic errors) and consistency (gold standard: body weight changes [BWC] registered with standardized measurements of body weight on admission and discharge [precision ± 50 g]) of nurse-registered cumulative FB. Total (TFB) and daily FB (DFB = total FB/LOS) were calculated. We analysed the unadjusted cumulative FB (UnaFB: without considering additional losses, i.e. perspiration/fever/liquid faeces) and the adjusted cumulative FB (AdjFB: considering the above as proposed in the literature) in all patients (ALL) and in three subgroups (cardiaccerebral:CARD; septic:SEPTIC; OTHERS). Exclusion criteria: lack of admission/discharge weight, incomplete FB data. We calculated 1L = 1 kg. Among 385 patients admitted during the study period 147 were eligible and analyzed. FB were inaccurate in 49 cases (33%) (error range: -3.61 to ?2.02 L, mean arithmetic error ± SD: ?0.03 ± 0.81 L, mean absolute error: 0.45 ± 0.6 L). The body weights at admission and discharge were 78.58 ± 18.92 kg and 79.29 ± 18.77 kg, with a BWC of 0.75 ± 3.25 kg (0.30 ± 1.27 kg per day). UnaTFB were 2.01 ± 4.02 L, UnaDFB 0.66 ± 1.25 L. AdjTFB was 0.57 ± 3.45 L, AdjDFB 0.20 ± 1.23 L. Correlation (R 2 ) and Bland and Altman was poor between BWC and UnaTFB (0.552 and -1.26 ± 5.41 kg) and slightly better between BWC and AdjTFB (0.714 and ?0.18 ± 3.68Kg). The SD of the difference between BWC and FB per day of the ICU stay was always [1 kg. A multiple regression model including UnaTFB, duration of intubation, maximum temperature, estimation of liquid faeces, age and the calculated caloric deficit during the ICU stay, only modestly improved correlation (R 2 0.773). Compared to the two other groups, SEPTIC were significantly more severely ill, had a higher and longer fever, a longer LOS, larger BWC and cumulative FB, and presented larger differences between BWC and cumulative FB (poor correlation and Bland and Altman). Though, consistency betwenn BWC and cumulative FB in CARD and Other was still scarce. Conversely, another multiple regression model (including only UnaTFB and the maximal temperature) in SEPTIC yielded an R 2 of 0.988. CONCLUSION. FB are often inaccurate and they are not consistent with the gold standard of BWC. The correlation and the agreement with BWC of both AdjTFB and UnaTFB are poor, with SD per ICU day-stay[1 kg or L. Multiple regression models including several variables slightly improve correlation, yet remaining disappointing. Consequently, clinical decisions should rather be based on other methods than FB.  A prolonged HDU LOS was associated with a high SOFA score for respiratory, hepatic and coagulation variables, preoperative ECG alterations, an increased urea and BMI and important bleeding. SOFA score should be use in the first 24 h to assess organ failure and a possible ICU transfer for patients with an elevated score. 
