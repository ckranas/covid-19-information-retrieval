51680e77f78028aa628dc13c088774903bd5a0ed
EVALUATION OF THE EFFICACY OF CORTICOSTEROIDS IN PATIENTS WITH AN ACUTE EXACERBATION OF CHRONIC OBSTRUCTIVE PULMONARY DISEASE RECEIVING VENTILATORY SUPPORT: A PROSPECTIVE, INTERNA- TIONAL, RANDOMIZED DOUBLE BLIND CLINICAL TRIAL
I  Alía M Á De La Cal A  Esteban R  Ferrer F  Molina R  Piñer A  Anzueto 

Hospital Universitario de Getafe Hospital Universitario de Getafe Hospital Universitario de Getafe    
award winning session: The best selected Type 2 diabetes and preadmission use of antidiabetic drugs INTRODUCTION. Venous to arterial carbon dioxide difference (Pv-aCO 2 ) could reflect the adequacy of blood flow during shock states. However, time-course of Pv-aCO 2 and their relationship with organ dysfunction has not been widely characterized. We proposed to describe the association between Pv-aCO 2 evolution during early phases of resuscitation and multiorgan dysfunction in septic shock. METHODS. Patients with a new septic shock episode admitted to ICU were included. Early resuscitation and general management were guided according Surviving Sepsis Campaign recommendations. Time 0 (T0) was set when a central venous catheter was inserted to guide reanimation. We draw blood samples for arterial-venous gases at T0 and 6 h after (T6). Pv-aCO 2 was calculated as the difference between venous CO 2 and arterial CO 2 . A value of Pv-aCO 2 [ 6 was considered as high. SOFA score at day-2 and day-3 were described for 4 groups: 1. Persisting high Pv-aCO 2 (high at T0 and T6) 2. Increasing Pv-aCO 2 (normal at T0, high at T6) 3. Decreasing Pv-aCO 2 (high at T0, normal at T6) 4.Persistently low (normal at T0 and T6). Evolution over time was assessed by analysis of variance followed by a Student's t test with Bonferroni correction for multiple comparisons. RESULTS. Sixty septic shock patients were analyzed. Mortality rate was 36.7%. There were no differences in the amount of fluids or vasoactive dose administered at T0 and T6. No significant differences in ScvO 2 for the 4 groups at T0 were found (one-way ANOVA, p = 0.68). Patients with persistent high Pv-aCO 2 at T0 and T6 had a significant higher SOFA score at Day-2 and Day-3 than patients with normal Pv-aCO 2 at T0 and T6 (one-Way ANOVA, day-2: p = 0.03; day-3: p \ 0.01) (Figs. 1, 2). CONCLUSION. Persistence of high Pv-aCO 2 difference during the early reanimation of septic shock is related to significant higher multiorgan dysfunction. Pv-aCO 2 could be used as perfusion goal during early phases of resuscitation of septic shock. 18) , 583 (55%) were male. The mean MET score was 5.9 (SD 2.2). Results of the MET activation are presented in Table 2 . CONCLUSIONS. The patients identified in the wards by the MET procedure are indeed at risk. Transfer to the ICU is necessary for more than half of the patients, advice on treatment while the patient stays in the ward is necessary for most of the remaining patients. Overall hospital mortality is 26%. INTRODUCTION. In October 2008 a Medical Emergency Team (MET) was set up in our 770 bedded hospital, driven by the realisation that our acutely ill patients needed to be rapidly identified and reviewed. The changing shift patterns of doctors following the European time Working Directive (EWTD) has made the need for prompt senior review at the bedside, 24 h a day, even more imperative. OBJECTIVES. To assess the workload of the MET calls and subsequent patient outcomes over a 12 month period. The number of cardiac arrests and survival to hospital discharge was used as end points. We collected data prospectively during each MET calls via a Critical Care Outreach database (MedICUs-Outreach, Mela Solutions Ltd, UK). Outcome data was obtained retrospectively using Trust databases and ICNARC data. A total number of 880 patients were audited over a 12-month period, and we demonstrated a significant and sustained 40% reduction in cardiac arrests. On average there are 2 MET calls per weekday and 3 per day at weekends, increasing to 4 on bank holiday Mondays. On average the MET team is at the bed-side for 30 min during a mid-week daytime call and 60 min out-of hours. Survival to discharge data was analysed after dividing patients into 4 main groups, based on whether they remained on the ward, (with or without a DNAR order), were admitted to a high dependency unit or were admitted to ICU.Admission to a level 2 or 3 area was considered a surrogate marker of a reversible critical illness in a patient with potential for recovery. 30 patients were admitted to ICU following the target MET call, of which 19 (63%) survived to discharge from hospital. 85 patients went to level 2 care (high dependency) of which 51 (60%) were discharged from hospital. Of 552 patients who stayed on the ward with no DNAR or critical care admission at the time of the target MET call, 292 (52%) were discharged from hospital. Finally of the 213 patients who were managed on the ward with DNAR completed by the MET, 171 (80%) died. In-hospital cardiac arrest prior to ICU admission dropped from 6.9 to 1.2% during the study period. CONCLUSIONS. The MET team has made a significant contribution to reducing cardiac arrests, and has resulted in prompt critical care admission, with good outcomes. However this comes at a cost as in terms of senior staff man-hours (2-4 man-hours per call) Appropriate DNAR orders placed earlier by parent teams would significantly reduce the workload our MET team. We are now targeting further educational programmes to feedback information to parent teams. Anecdotal evidence suggests the high mortality amongst patients who remain on the ward without DNAR order reflect the it not only contains relatively well patients with minor physiological abberations but also a significant proportion of patients in whom the MET felt survival was unlikely and escalation of treatment would not influence outcome. INTRODUCTION. Sepsis is common in hospitalised patients and contributes to morbidity and mortality. Severe sepsis is associated with an in-patient mortality of approximately 40%. Hospital Medical Emergency Teams (MET) were introduced to identify and treat acutely unwell ward patients in order to reduce serious adverse events. We hypothesised that the MET might play a role in triaging septic patients. Accordingly, we performed a retrospective observational study to evaluate what proportion of MET calls was associated with septic patients, and their disposition after MET review. OBJECTIVES. To estimate the proportion of MET reviews involving septic patients and management by the MET as well as outcome of such patients. We obtained Hospital Research Ethics Committee approval. We performed a retrospective observational study over 5-year (August 2005 -March 2010 ) in a single tertiary Australian hospital. We obtained information on demographics, details of MET review and hospital outcome. We analysed 4508 MET reviews in 3354 patients over a 5-year period. Overall 177/ 3354 (5.3%) of MET patients had sepsis. Table 1 summarizes major epidemiological findings after exclusion of patients with limitations of medical treatments (LOMT) in non septic MET patients and in septic patients. The three most common MET triggers in septic patients were respiratory distress, multiple physiological derangements and neurologic impairment, accounting for more than three quarters of activations in septic patients. Fluid resuscitation was performed in 44 patients, vasopressors were used in 13 patients. Non-invasive ventilation was commenced in 10 patients. Pneumonia was the most common cause of sepsis and it was diagnosed in 45 patients. INTRODUCTION. Respiratory mechanics are monitored at the bedside and provide useful information about disease evolution and efficacy of therapeutic interventions. Ventilatory settings are adjusted in order to ameliorate patient-ventilator synchrony. In this interaction, the role of the Endotracheal Tube (ETT) Resistance (R ETT ) is often overlooked, since traditionally pressure is measured from the Y-piece of the ventilatory circuit. The issue of R ETT has been evaluated in the past years through several methods, among which the rapid end-inspiratory occlusion method was not included. 1. To measure inspiratory Resistance of different sized adult ETTs (Portex) via the above method, under variable in vitro conditions (artificial lung). 2. To calculate Rohrer's coefficient of nonlinear resistance, k 2, from the graph of inspiratory Resistance over Flow for each tube, so as to understand its behaviour, since previous studies have resulted in diverse results. METHODS. Peak and plateau pressures were recorded at both proximal and distal sites of the ETT after applying inspiratory occlusion (for 3 s) under constant flow. Resistance was calculated from (Peak pressure-Plateau pressure)/inspiratory flow, at both sites. Distal pressure was obtained via an intraluminal catheter with 1.2 mm inner and 1.7 mm outer diameter. R ETT value resulted from the difference Rproximal-Rdistal. Line graph of R ETT over inspiratory Flow was plotted and Rohrer's constants were calculated by first fitting Flow to Resistance by the method of least squares. Two additional Resistances and five different compliances were tested. RESULTS. For ETTs with inner diameter 9.0, 8.5, 8 .0, 7.5, 7.0 and 6.5 mm, k 2 was 2.42, 3.05, 4.65, 6.01, 9. 17 and 12.80 cmH 2 O/L/s, respectively. R ETT value was independent of both externally applied resistance and Test Lung compliance. INTRODUCTION. Age-related declines in pulmonary function have been described in humans, with consequent alterations in respiratory system mechanical properties and gas exchange. OBJECTIVES. To evaluate possible age-related changes in respiratory system mechanics of ARDS patients and consequent differences in selection of ventilatory settings. Prospective clinical study in two ICUs of Athens during a 2-year period. Fiftyeight consecutive patients meeting criteria of early ARDS were enrolled in this study and were stratified in two groups based on age (of the patients) with 65 year to delineate younger (Group A, n = 40) from older (Group B, n = 18) patients. Data compiled for each patient included anthropometric characteristics, ARDS origin, severity scores, ventilator settings, arterial blood gases, respiratory system mechanics, ICU length of stay (LOS) and outcome. RESULTS. Severity of underlying illness measured by APACHE II score (corrected for age) did not differ among the two study populations (16.5 ± 5.7 vs. 17.8 ± 6.6, p = 0.536, in Group A and B, respectively). Also, severity of lung insult, as judged by LIS (2.74 ± 1.31 vs. 2.55 ± 0.68, p = 0.56) and multiorgan dysfunction, as measured by SOFA score (9 ± 3 vs. 10 ± 4, p = 0.4) were similar in the two groups. Although younger patients revealed a higher incidence of pulmonary ARDS, no significant difference among the study groups was identified (62.5 vs. 50%, p = 0.37). Concerning the ventilatory settings, no differences were identified, apart from inspiratory to total breathing cycle duration ratio (Ti/Ttot) which was higher in Group A (0.34 ± 0.065 vs. 0.30 ± 0.067, p = 0.03). Total PEEP was comparable among the two cohorts (9 ± 3 vs. 8 ± 3, p = 0.37). Elderly patients presented with lower PaO 2 (87.5 ± 27 vs. 75.4 ± 11.9 mmHg, p = 0.022), but this statistical difference disappears after calculating the PaO 2 /FiO 2 ratio (134.16 ± 47.46 vs. 127 ± 40.2 mmHg, p = 0.58). Ventilation, as judged with PaCO 2 , was similar in the two ARDS groups (42.55 ± 6.97 vs. 41.68 ± 8.74 mmHg, p = 0.95). Respiratory system mechanics were also comparable (static elastance of respiratory system E st,rs : 39.4 ± 15.7 vs. 38.7 ± 15.7 cmH 2 O/ml, p = 0.87, resistance of respiratory system R max,rs : 8.23 ± 3.7 vs. 7.44 ± 3.1, p = 0.55). ICU LOS (10 ± 9 vs. 14 ± 8 days, p = 0.27) and mortality (35 vs. 61.1%, p = 0.063) did not differ significantly. CONCLUSIONS. Elderly ARDS patients present with a predilection for extrapulmonary ARDS. No differences in ventilator settings were identified, apart from the longer expiratory time used in these patients. Elderly ARDS patients did not present with worse arterial blood gases or respiratory mechanics in comparison with younger ones. No impact on ICU LOS and mortality has been clearly documented in our study. INTRODUCTION. If changes of functional residual capacity (FRC) could be estimated by end-expiratory lung impedance (EELI) provided by electrical impedance tomography (EIT) is under debate [1, 2] . OBJECTIVES. We studied the accuracy of FRC as measured with EIT (FRC EIT ) compared with direct measurements of FRC with the oxygen washout technique (FRCO 2 ) in ventilated postoperative cardiac surgery patients. METHODS. Following approval of the local ethics committee, we studied 54 postoperative ventilated cardiac surgery patients after alveolar derecruitment, i.e. open endotracheal suctioning, and alveolar recruitment (RM). Patients were ventilated with biphasic positive airway pressure, positive end-expiratory pressure of 10 cmH 2 O, and a tidal volume of 6-8 ml/kg. All patients received a standard suctioning procedure with disconnection of the ventilator (20 s, 14 F catheter, 200 mmHg negative pressure). The patients were randomized into two groups, receiving either a RM (PEEP 15 mbar, PIP 35-40 mbar for 30 s, group RM) or no RM, in which ventilation was resumed without a RM (group NRM). Measurements were conducted at the following time points: Baseline (T1), after suctioning (T2), after RM or NRM (T3), and 15 and 30 min after T3 (T4 and T5). We measured FRCO 2 using the oxygen washout technique (LUFU System, Dräger Medical AG, Lübeck, Germany) [3] . By means of EIT (EIT Evaluation kit, Dräger Medical AG, Lübeck, Germany) we measured global impedance tidal variation (TV) and end-expiratory lung impedance (EELI). FRC EIT was calculated in two ways: 1. at each time point using TV and simultaneous measured tidal volume (V T ): FRC EIT_Vt = EELI 9 V T /TV; and 2. using absolute FRC values at T1: FRC EIT_T1 = EELI Tx 9 FRCO 2 (T1)/EELI(T1). FRC EIT_Vt and FRC EIT_T1 were compared with FRCO 2 using Bland-Altman analysis. OBJECTIVES. Aim of the study was to evaluate the Stress versus Strain (S/S) relation of five lung Regions of Interests (ROI) in supine, mechanically ventilated patients by using computed tomography (CT). METHODS. During sedation, ten intubated and ventilated patients without pulmonary pathologies, were transported to CT unit. We collected the tracings of flow, volume and pressure at airways opening together with esophageal pressure. During volume controlled mechanical ventilation we executed 8 end-inspiratory hold maneuvers (IHM) at different inflation volumes (from 4 to 11 ml/kg in steps of 1 ml/kg). Simultaneously with each IHM and at FRC, we performed CT scans at a level between heart and diaphragm. Each scan was divided 4 regions of interest (ROI) into nondependent, intermediate, dependent and sub-cardiac. By the gas content of the ROIs and of the entire slice, we calculated regional and global strains. Stress was estimated by Ptp. Exponential regression of the single S/S curves was performed, tested for statistical significance and compared by Fisher test. RESULTS. Global and regional S/S curves are exponential and described by statistically different equations. At the same stress, dependent ROIs show a fourfold higher strain than nondependent regions. Lung is inherently inhomogeneous. While titrating mechanical ventilation, it is necessary to be cautious in using parameters derived from global lung strain because it can be very different from the strain of single ROIs. INTRODUCTION. Anaesthesia induction determines a reduction of functional residual capacity (FRC) [1] . Furthermore, the surgical insult is associated with an increased extravascular lung water mainly because of the pro-inflammatory response induced by surgery itself and the administration of intra-operative fluids. The decrease of FRC associated with increased extra vascular water could be responsible of oedema of the small to medium airways, and hence of an increases of inspiratory and expiratory resistances up to the development of expiratory flow limitation (EFL) [2] . OBJECTIVES. The aim of this prospective randomized trial was to determine whether different quantitative strategies of fluids administration could have different effects on perioperative respiratory function, particularly on the development of EFL. METHODS. Including criteria: adult patients undergoing elective major abdominal surgery. Exclusion criterion: the presence of EFL before surgery, evaluated through the NEP test both in seated and supine position [2] . On the day of surgery, patients were randomized in two groups on the basis of the volume replacement strategy: Group A: 12 ml/kg/h and Group B: 18 ml/kg/h. They were ventilated in volume controlled mode. An inspiratory pause of 20% allowed the calculation of the quasi-static compliance of respiratory system (Cqst, rs) whilst the determination of the peak inspiratory pressure and the pressure at the point of 0 flow (V 0 ) allowed the calculation of the resistance of the respiratory system (Rmin, rs).The presence of EFL during general anaesthesia was assessed with PEEP test which consisted of the rapid subtraction of 3 cmH 2 O of PEEPe immediately before expiration (i.e. passing at the beginning of exhalation from a value of PEEP of 3 cmH 2 O to ZEEP). In patients with EFL, no difference of expiratory flow was detected between the breath at ZEEP and PEEPe, while in patients without EFL, a difference in expiratory flow (DV 0 ) was found. This difference of V' was quantified and calculated at mid-expiration. We enrolled 22 patients, 11 in Group A and 11 in Group B. Cqst, rs (47 ± 3.3 vs. 36 ± 1.6 l/cmH 2 0), Rmin, rs, (8 ± 2.6 vs. 10 ± 4.8 cmH 2 0/l/s) the PaO 2 /FiO 2 ratio (372 vs. 338) and DV 0 (0.09 vs. 0.07 l/s) were statistically worse in the group B. Moreover the presence of EFL was detected only in four patients of the group B. CONCLUSIONS. The main result of our study is that differences in terms of quantity volume replacement strategy seem to influence both changes in of the respiratory system compliance and reduction in expiratory flows up to the development of expiratory flow limitation. used the transpulmonary pressure, calculated from the oesophageal balloon to set the PEEP in a recent randomized controlled study. This strategy aims at preventing alveolar collapse by counterbalancing the gravitational force of the lung by an equal or higher PEEP. The purpose of this study was to use electrical impedance tomography and evaluate the relation between ventilation distribution and transpulmonary pressure during a PEEP trial in porcine acute lung injury. METHODS. Eight Yorkshire/Landrace pigs (28-31 kg) were studied during an incremental and decremental PEEP trial before and after the induction of acute lung injury (ALI) with oleic acid injected in the right atrium. Global lung parameters, regional compliance, and oesophageal pressure were recorded at the end of each PEEP step. Regional compliance was calculated by dividing the tidal impedance variation (EIT evaluation kit 2, Dräger, Lübeck, Germany) by the applied driving pressure. During an expiration hold, transpulmonary pressures were negative at 0 cmH 2 O PEEP and became positive during the stepwise increase of PEEP at 5 cmH 2 O before, and 10 cmH 2 O PEEP after the induction of ALI. Optimum regional compliance was different between the ventral (non-dependent) and dorsal (dependent) regions of interest. In the healthy lung, optimum PEEP was 10 in the dorsal and 5 in the ventral lungs, whereas after ALI optimum PEEP was 15 in the dorsal ROI and 5 in the ventral ROI. CONCLUSION. Optimum PEEP guided by EIT is different for dependent and non-dependent lung regions in experimental ALI. As it becomes clear that mechanical ventilation can exaggerate lung injury, individual titration of ventilator settings is of special interest. Electrical impedance tomography (EIT) has been proposed as a bedside, regional monitoring tool to guide the ventilator. In the present study we evaluate the use EIT on ventilation distribution at a caudal and cranial lung level during a PEEP trial in mechanically ventilated patients. METHODS. EIT (EIT evaluation kit 2, Dräger, Lübeck, Germany) was measured at cranial (just under the armpits, at the 3rd or 4th intercostal space) and caudal lung levels (just below the nipples at the 6th or 7th intercostal space) in 12 patients after cardio-thoracic surgery. Patients were fully sedated and mechanically ventilated and a PEEP trial was performed at 4 PEEP levels (15, 10, 5 and 0 cmH 2 O). RESULTS. The center of gravity index decreased after lowering the PEEP level at both the caudal and cranial lung levels. Whereas the tidal volume impedance variation divided by tidal volume increased at the cranial lung level and decreased at the caudal lung level during the decremental PEEP trial. CONCLUSION. Ventilation distribution shifts from dorsal to ventral direction, and from caudal to cranial during a decremental PEEP trial in mechanically ventilated patients due to lung collapse. INTRODUCTION. Theoretically, the positive end-expiratory pressure (PEEP) that minimizes the elastance of the respiratory system (Ers) is equivalent to the mathematical inflection point (MIP) of the pressure-volume (PV) curve. However, Ers is highly dependent on the tidal volume (V T ) adjusted during PEEP titration. OBJECTIVES. We aimed to propose a method to set the PEEP close to the MIP during PEEP titration using a volume-independent elastance (E 1 ) component. Initially, numerical simulations of PEEP titrations were performed using eight PV curves of patients with Acute Lung Injury (ALI). For each simulation, two models were used for the identification of the respiratory system mechanical properties: (1) the linear single compartment model (LSCM, Paw = Rrs . F + Ers . V + PEEP, where Rrs is the resistance of the respiratory system) and (2) the volume-dependent single compartment model (VDSCM, Paw = Rrs . F + [E 1 + E 2 . V] . V + PEEP, where E 2 is the volume-dependent elastance). From each model, the PEEP of minimal Ers (PEEP minErs ) and of minimal E 1 (PEEP minE1 ) were identified and compared to each respective MIP. Disturbances in estimated E 1 and Ers caused by changes in V T and by endotracheal tube (ETT) mechanical properties were evaluated. Additionally, PV curves and identical PEEP titrations were performed (with a V T of 6 and 12 ml/kg) in 16 male Wistar rats (250-320 g) with ALI induced by Escherichia coli lipopolysaccharide injected intraperitoneally (LPS ip , n = 8) and instilled intratracheally (LPS it , n = 8). Data are presented as median and range values and variables were compared with the Kruskal-Wallis one-way ANOVA. Multiple comparisons were adjusted by the Bonferroni method considering a P \ 0.05. In both simulated and experimental PEEP titration results were comparable even with different pulmonary primary insults. The PEEP minErs was always significantly lower than the MIP (3 cmH 2 O [2-6] vs. 7 cmH 2 O [6] [7] [8] [9] , respectively; P = 0.0004). The PEEP minE1 was always similar to the MIP (7 cmH 2 O [5] [6] [7] [8] vs. 7 cmH 2 O [6] [7] [8] [9] at low V T and 7 cmH 2 O [7] [8] vs. 7 cmH 2 O [6] [7] [8] at high V T ), and was always significantly higher than the PEEP minErs (8 cmH 2 O [7] [8] vs. 3 cmH 2 O [1] [2] [3] [4] ). The addition of ETT mechanical properties in both simulated and experimental PEEP titration had no effects on the estimation of the PEEP minE1 . CONCLUSIONS. The volume-independent elastance seems to be a robust parameter to determine the PEEP close to the MIP independently of the adjusted V T and may be a practical, more feasible approach for PEEP titration. INTRODUCTION. The use of a low tidal volume (V T ) seems to influence mortality in patients with acute lung Injury/acute respiratory distress syndrome patients (ALI/ARDS). However, the optimal positive end-expiratory pressure is still uncertain. OBJECTIVES. This study aims to compare two criteria for positive end-expiratory pressure (PEEP) adjustment in patients with ALI/ARDS in a decremental PEEP trial. METHODS. The Institutional Review Board of the participating institution approved the study protocol. Six patients fulfilled ALI/ARDS criteria (2 with ALI and 4 with ARDS) and were included in the protocol. A recruitment maneuver (RM) was performed in Pressure Controlled Ventilation mode (PCV), driving pressure of 15 cmH 2 O; inspiratory time of 3 s; respiratory rate (RR) of 10 bpm; FIO 2 of 1.0 and PEEP sequentially set at 25 (30 s), 30 (30 s) and 35 cmH 2 O (120 s time duration). Thereafter, in Volume Controlled mode with V T ranging 4-6 ml/kg, RR was adjusted to keep pH above 7.2, and PEEP was reduced from 25 to 9 cmH 2 O, in steps of 2 cmH 2 O with 3 min per step. At the end of each step, arterial blood was collected for gas analysis. The airway pressure (Paw) and flow (F) were continuously acquired and recorded (sampling frequency of 200 Hz). The volume (V) was calculated by the numerical integration of flow. Two models were used for the identification of the respiratory system mechanical properties: (1) the linear single-compartment model (Paw = Rrs . F + Ers . V + PEEP, where Rrs is the resistance of the respiratory system) and (2) the volume-dependent single compartment model (Paw = Rrs . F + [E 1 + E 2 . V] . V + PEEP, where E 1 and E 2 are the volume-independent and dependent elastance, respectively). From each model, the PEEP of minimal Ers (PEEPminErs) and of minimal E 1 (PEEPminE1) were identified and compared to the PEEP of maximal arterial partial pressure of oxygen (PEEPmaxPaO 2 ). Additionally, the %E 2 (%E 2 = 100 [E 2 V T / (E 1 + E 2 V T )) was calculated in order to evaluate the presence of cyclical recruitment/derecruitment (%E 2 \ 0) as well as overdistension (%E 2 INTRODUCTION. Evidence suggests that blood glucose (BG) variability, rather than absolute values, may be a predictor of intensive care unit (ICU) and in-hospital mortality [1, 2] . OBJECTIVES. To investigate whether BG variability within the first 48 h of admission (when patients may be at their most unstable) acts as a predictor of outcome in the ICU of a large district general hospital. We conducted a retrospective observational study in our ICU at the Royal Cornwall Hospital. We collected the first 10 BG values (correlating to the first 48 h) for all adult patients admitted between September 2008 and March 2009. The modified Bath protocol [3] was used for glycaemic control. We calculated the median BG value and the inter-quartile (IQ) range (as a measure of variability) for each patient. Spearman's correlation co-efficient was calculated to compare IQ range to secondary outcomes. The patient group was then split into 'high variability' and 'low variability' cohorts, and the ICU mortality of each cohort compared. We identified 130 patients. 63% of patients were male, and the median age was 64. The Spearman's correlation coefficients when comparing IQ range with a secondary outcome were as follows: APACHE II 0.176, APACHE II risk of death 0.152, Length of stay (h) -0.113, Maximum number of organs supported 0.014, Respiratory support days -0.104, Cardiovascular support days -0.019, Renal support days 0.163 and Neurological support days 0.122. ICU mortality for this cohort was 18.5% (n = 24/130). There was no statistical difference in ICU mortality between the 'high variability' (IQ C 2.56) and 'low variability' (IQ B 0.7125) groups (18.2%, n = 6/33 for each, Fisher's exact p test = 1.0). There was also no statistical difference between the mortalities of the 'high variability' group and the entire group (Fisher's exact p = 1.0). In this retrospective observational study, we were unable to demonstrate that BG variability within the first 48 h of admission is predictive of outcome. There was a weak positive correlation between BG variability and APACHE II scores, APACHE II risk of death and both renal and neurological support days. There was no effect upon mortality. This may be explained by insufficient sample size and the use of robust non-parametric analysis, both of which may have under-powered this study. These findings are in contrast to recent evidence [1, 2] . [1] there was a move to tight glucose control in critically ill patients with anticipation of a reduction in mortality. Many centres were unable to replicate the results leading to the international, multi-centre randomized control trial, NICE-SUGAR, comparing intensive versus conventional glucose control in critically ill patients [2] . This showed a statistically significant increase in mortality in patients managed with intensive glucose control. A meta-anlysis has shown an increased risk of hypoglycaemia with intensive insulin control and no overall mortality benefit [3] . Consequently many have returned to more conventional glucose control. Evidence supports standardisation of intravenous insulin therapy to improve efficiency and safety of blood glucose control in critically ill patients [4] . To establish wether the re-introduction of conventional glucose control is safer and how well we adhere to protocols in our ICU. We performed two audits of blood glucose control during intensive insulin therapy [target glucose (TG) 4.4-6.5 mmol/l] and again after the introduction of a conventional glucose control regimen (TG 6-10 mmol/l). We compared the incidence of hypoglycaemic episodes, the number of episodes blood sugar was outside the target range and the number of protocol violations that occurred. RESULTS. The percentage of blood glucose readings within the TG range for both intensive and conventional glucose control were 25.7 and 75.9%, respectively. There was a reduction in hypoglycaemic episodes (\ 4.4 mmol/l) with conventional glucose control from 5.4 to 1.7% and no incidences of severe hypoglycaemia with the conventional regimen. There was a reduction in the incidence of hyperglycaemia, ([ 10 mmol/l) from 16.6 to 9.2%. Both audits show that despite standard protocols there were a high number of violations/errors 60.2 and 54.5%. CONCLUSIONS. The audit supports the evidence that a more liberal approach to glycaemic control on the ICU reduces the incidence of severe and mild hypoglycaemia and as a consequence may confer a mortality benefit. However protocol compliance was very poor and the high incidence of hyperglycaemia and its detrimental effects can not be overlooked in the critical care environment. The education of healthcare staff is a vitally important issue. INTRODUCTION. Hyperglycaemia is a common phenomenon in critically ill patients. Many studies have demonstrated improved prognosis in patients with better glycemic control. Continuous monitoring of glucose levels may improve glycemic control of these patients. There are no previous studies that assess the accuracy of continuous glucose monitors (CGMs) data in realtime (RT) in medical and surgical critically ill patients. OBJECTIVES. To assess the accuracy of CGMs data in medical and surgical critically ill patients. METHODS. Thirty-three patients were included (21 surgical/12 medical), mean age 66 ± 10 years (21 male), 18 of them were previously known diabetics (mean Hb1Ac 7.3 ± 4%), mean Body Mass Index 32 ± 7, mean APACHE II 18.5 ± 5.2, mean SOFA 8.4 ± 3.3. Patients were monitored for 72 h using the Guardian RT Ò (RT-CGM) (Medtronic). For these patients, arterial whole blood glucose samples were obtained and glucose concentration (BG) measured using HemoCue 201DM Ò , following the standard glycemic control protocol established by the Intensive Care Unit (4-24 BG determinations per patient/day were obtained, depending on the patient's glycemic control). Insulin therapy was administered according to the same protocol, using the BG values. Results were evaluated using paired values (BG/RT-CGM). Assessment tools include mean and median absolute relative difference (RAD; RAD = [(BG -RT-CGM)/BG]*100) and ISO criteria [1] , defined as CGM values within ± 15 mg/dL for BG values \ 75 mg/dL, and CGM values within ± 20% for BG values [ 75 mg/dL. A total of 729 paired BG/RT-CGM data points were analyzed. Results Table shows the overall assessment and the results for the two types of ICU patients, medical and surgical, studied. CONCLUSIONS. They have not been observed significant differences in accuracy of CGM between medical and surgical patients. The mean and median RAD obtained in our study were similar to values reported in others studies [2] ; these results suggest that RT-CGMs can be of clinical use in the ICU, however a larger number of paired data must be assessed.  HOW SWEET CAN WE GET? A CASE REPORT OF EXTREME HYPERGLYCEMIA P. Remeta 1 , I. Zykova 2 , R. Pistorova 2 , D. Morman 1 1 Regional Hospital Liberec, Department of Anesthesiology and Intensive Care Medicine, Liberec, Czech Republic, 2 Regional Hospital Liberec, Medical ICU, Liberec, Czech Republic INTRODUCTION. Hyperosmolar hyperglycemic state (HHS) is one of the most serious acute complications of diabetes mellitus (DM). The prevalence of HHS is smaller than diabetic ketoacidosis (DKA), mostly it affects elderly people and it might be the first manifestation of undiagnosed DM. Unlike DKA (mortality rate \ 5%), mortality rate in HHS is reported higher (5-20%), mostly due to comorbidities [2] . The treatment of HHS can cause cerebral oedema, slow correction of metabolic disturbance is crucial to avoid a possibly fatal complication. The highest so far reported plasma glucose level in a diabetic patient is 106 mmol/l (1,909 mg/dl) in a diabetic patient with HHS [3] . The absolutely highest reported plasma glucose level is 311.3 mmol/l (5,600 mg/dl), it was published in 1990-a case of a young man presenting after drinking 12 l of coca cola, six cans of pineapple juice, several liters of orange juice and sugared water in a hot weather [1] . METHODS. Case report. We report a 53 years old female brought to emergency department with an acute transient loss of consciousness and dysarthria. After detecting plasma glucose level of 146.6 mmol/l (2641 mg/dl), measured osmolarity of 406 mOsm/l and pH of 7.21 the patient was admitted to ICU. This HHS was the first manifestation of type II DM. Later detected personal history revealed a week lasting weakness and polypsia without polyuria before admission. Careful correction of glycemia was started. The following course was uneventful and uncomplicated, the patient was discharged home after 2 weeks. The compensation of diabetes was satisfactory by use of combination of peroral and intensified insulin regimen. CONCLUSIONS. We report a case of glycemia of 146.6 mmol/l in a diabetic. Through the search of literature and MEDLINE we have found the highest glycemia of 106 mmol/l. Our case report after a search of literature and MEDLINE appears to be the highest glycemia so far reported in a diabetic. OBJECTIVES. We sought to assess the national response to new evidence by change in clinical practice in ICUs in the UK. We contacted all UK adult ICUs in the Directory of Critical Care (2007) by telephone between October 2007 and February 2008 [3] , then conducted a follow-up survey between March and April 2010. The nurse in charge of the unit was surveyed using a predefined questionnaire. The questions assessed current practice with regards to IIT for Intensive Care patients. Unpaired t tests were used for statistical analysis. Very few have abandoned a policy for IIT. However, overall there has been a significant relaxation of target ranges and higher target limits for blood glucose, suggesting that whilst there is continued confidence in the merits of IIT, practice is changing in response to recent research. INTRODUCTION. The prevalence of diabetes mellitus in patients requiring cardiac surgery is rapidly increasing. These patients have higher perioperative morbidity and mortality, significantly reduced long-term survival, and less freedom from recurrent episodes of angina. The postoperative care is complicated by the glucose control regimes maintaining optimal levels of blood glucose and avoiding the harmful effects of hypoglycaemia. Trials examining the effects of tighter glucose control have had conflicting results. Systematic reviews and meta-analyses have also led to differing conclusions and there is currently no clearly defined optimal blood glucose level peri operatively. OBJECTIVES. Our survey aimed to assess whether the blood glucose level at which sliding scale insulin was started had any relation to increased episodes of hypoglycaemia in cardiac surgical patients. We conducted prospective survey on patients having cardiac surgery, operated during a period of 2 months. A total of 59 patients were operated on and included 58 on pump and 1 off pump surgeries. Out of these 11(18.64%) were known diabetics. None of the patients who were put on the sliding scale with the blood glucose level greater than 8 mmol/l as per protocol in our hospital, developed hypoglycaemia. CONCLUSION. The results of our survey suggested that the optimal blood glucose level for starting sliding scale insulin is between 8 and 10 mmol/l as opposed to the previously used level of 4-6 mmol/l in our unit.Our previous survey conducted a year ago, using 4-6 mmol/l as the optimal range for blood glucose level showed a higher incidence of hypoglycaemic episodes during the peri operative period.  N.D.A. Scawn 1 , T. Ridgway 1 , E. Damm 1 , V. Seppi 1 1 The Liverpool Heart and Chest Hospital, Liverpool, UK Glucose Monitoring System with a GlucoClear sensor. The System provides automatic, realtime monitoring and trending of blood glucose (BG) values for critically ill adults. The MPE data provided insight into the relatively poor control of blood glucose in post-operative cardiac surgical patients, which was subsequently confirmed by a comprehensive prospective audit of glucose control. Having identified the need to improve glucose control, the hospital prioritized the implementation of a new glucose control policy. This was then trialed using real-time BG measurements to see if it improved the quality of glycemic control when compared to the current method of intermittent BG measuring. OBJECTIVES. To demonstrate that real-time BG monitoring has the potential to improve both the quality and safety of glycaemic control. METHODS. Phase 1: MPE, a non-blinded, single center study evaluating 17 adult patients undergoing cardiac surgery in which BG was continuously monitored in the OR, ICU and the general ward. Patients were monitored with the System for up to 72 h. Data was graphed to illustrate BG fluctuations. Phase 2: Audit, a prospective audit was completed for all patients undergoing elective cardiac surgery at the centre during the month of February. The audit recorded and analysed every BS measurement that was made for every patient in the 72 h immediately following the induction of anaesthesia. Phase 3: Implementation of Glucose Control: an Investigator Initiated, randomized, controlled, single center study will compare BS control using automated continuous BS monitoring compared with a control group using the hospital's current protocol of intermittent BS measurement at a variable frequency. RESULTS. Phase 1: Data collected illustrated poor glucose control of cardiac patients. Patient glycemic variability increased as patients moved from the OR through ICU and to general ward. Significant episodes of hyper-and hypoglycemia were revealed during the automated real-time monitoring. Phase 2: The audit of 152 sequential elective cardiac patients showed that although only 24% were known diabetics, 94% received insulin at some stage in the 72 following surgery. 3728 BS measurements were made with a mean of 25 per patient. 89% of BS measurements were less than 10 mmol/l, however, 42% of patients had BS over 10 mmol/l at some time and 9% of patients spent more than 30% of time with BS above 10 mmol/l. Phase 3: Study is ongoing. Hypothesis is that continuous real-time BG measurements improve the quality of glycemic control when compared to the current practice. CONCLUSIONS. Patients undergoing real-time BG measurements may have better glucose control and lower incidence of hypo/hyper-glycaemic episodes. Also, real-time BG measurements enable nurses to better adhere to an insulin protocol. INTRODUCTION. The major reasons to implement a bundle of care, such as tight glucose control protocol, are to promote compliance with guidelines for best practice and to facilitate sustainability. All the patients admitted to our ICU benefit from a glucose control protocol prescription. However in a random sample of ICU patients, we observed that our protocol was not fully respected in terms of inclusion criteria or modifications of the speed of insulin drip. OBJECTIVES. Before starting a multifaceted educational intervention as part of a quality improvement initiative in our ICU, we sought to identify barriers to nurses' compliance with our tight glucose control protocol. We hypothesized that nurses were not complying because majority of them did not benefit from the last educational intervention on glucose control. We performed a survey associated with semi-structured interviews of critical care nurses in a surgical ICU with 24 beds located in an academic hospital in Paris. We followed the knowledge-attitudes-behaviors model developed by Cabana et al. [1] . RESULTS. Sixty-five nurses (80%) answered our questionnaire. The majority of respondents were women (78%), younger than 35 years old (81%) and worked in the unit for less than 5 years (86%).Only 20% of nurses assisted to the last educational program on glucose control. All respondents were aware of the existence of the protocol and the majority familiar (71%) with it. Three quarter of the respondents agreed that there was a culture of tight glucose control in the unit and that the application of the protocol improved patient-centered outcomes. Two-thirds of respondents agreed with the efficacy of the protocol. 57% of nurses considered compliance with the protocol to be a priority. However, 80% of nurses acknowledged not complying with the protocol ''often'' or ''very often''. The more common answers were that ''one size protocol does not fit all, particularly for diabetic patients'' and the ''fear of hypoglycemia''. We did not identify any external barrier to the compliance of our protocol. The majority of respondents requested adaptation of the current tight glucose control protocol. Despite our hypothesis about lack of knowledge driving non-compliance, we found that attitudes were the root cause of the low compliance by our nurses. Our educational intervention will therefore focus on the fear of causing hypoglycemia among our critical care nurses. We also plan to add to our protocol specific mentions for diabetic patients. BACKGROUND. Critically ill patients' outcome could be better if their glucose levels remains in the normal range. A strict control of glucose levels in real time is needed for treating these patients in a proper way. POC technology allows to reduce the times for analysis, and permit readjusting of treatments in a more easily way. OBJECTIVES. To compare accuracy of POC glucose levels with those processed by the conventional central laboratory. PATIENTS AND METHODS. Prospective study of paired of samples obtained from 248 consecutively admitted to our ICU for determining glucose levels. Capillary blood samples were analyzed by bedside glucometers, and blood drawn from catheters was analyzed both in the central Lab and in the ICU through a blood gases analyzer ABL 850. Clinical and biological data that could interfere with measures were quoted. Results were analyzed by SPSS/PC 12.0 programs. Obtained glycaemia levels were 144.4 for glucometers, 148.1 for central lab and 153.5 for blood analyzer. Concordances between methods were studied by Bland-Altman test, being all results in the range of 95% CI. In patients with peripheral oedema concordance between glucometers and central Lab results were good, but they were not when compared to blood gases analyzer. Haematocrit less than 25% or mean BP lower than 70 mm Hg did not influence the concordance between the considered methods. CONCLUSIONS. Bedside glucometers seem to perform enough well for controlling glucose levels in critically ill patients. Found differences seem not to be related with the clinical condition of patients. INTRODUCTION. Glycemic control is a common practice in critically ill patients, but there is insufficient information from randomized controlled trials to determine the optimal target range of blood glucose in the severely ill patient. What it is clear is that attempts to normalize blood glucose with IV insulin during critical illness results in higher rates of hypoglycemia. OBJECTIVES. The aim of the present study was to assess the incidence of hypoglycemia in patients staying more than 10 days in different Intensive Care Units (UCIs). METHODS. Multicenter, prospective, observational and cohort study, during a 4 month period (January-April 2010). All patients staying more than 10 days in 5 ICUs of 3 different hospitals were enrolled. At base line, demographic and clinical information was obtained, including information necessary to determine the severity of illness. The blood glucose level was collected every day. RESULTS. 39 patients were enrolled. Mean age-57.07 ± 17.36 (55), mean SOFA score-8.02 ± 3.12 (8) . Mortality rate of 20.51%. Blood glucose level had a mean daily value of 158.3 ± 41.2 (149.7) mg per deciliter. Mean daily insulin dose-24.57 ± 28.38 (15). Hypoglycemia (defined as a blood glucose level of 50 mg per deciliter) occurred in 7 patients (18%) but only in 0.6% of all blood glucose determinations. CONCLUSIONS. The risk of hypoglycemia is higher than we think in patients staying longer time in ICU. As the incidence of hypoglycemia is very low when we take in account all measurements, most of the times the ICUs doctors do not realize the real incidence of this problem. INTRODUCTION. Intensive glucose control was advocated to be an important part of critical care management until recently when it has been shown and to be associated with an increased frequency of hypoglycaemia [1] and mortality among adults in the ICU [2] . With this in mind we audited our own glucose control practice and examined why hypoglycaemic and hyperglycaemic episodes occurred. 1. Quantify the number of hyper/hypoglycaemic episodes. 2. Investigate if there was an association between blood glucose monitoring and changes to the rate of insulin infusion and episodes of hyper/hypoglycaemia. 3. Examine how hypoglycaemic episodes were managed. We conducted a retrospective audit of glucose management over a 2 week period in the General ICU. We recorded patient demographics, APACHE and SOFA scores, the individual glucose measurements, the number of hypoglycaemic and hyperglycaemic episodes per day, the number of changes to the rate of insulin infusion per day and the number of blood glucose checks per day. The target blood glucose for all patients was between 4.4 and 6.6 mmol/ l. Additionally we analysed how hypoglycaemic episodes were managed. Hypoglycaemia was defined as a blood glucose measurement of less than 4.4 mmol/l and hyperglycaemia as a blood glucose measurement of greater than 6.6 mmol/l. . 16 patients were included, 75% were male with a mean age of 62.9 years. Their APACHE II scores ranged from 8 to 22. During the 2 week period 703 individual glucose measurements were taken, with 90 episodes of hypoglycaemia and 309 episodes of hyperglycaemia. When the data was analysed further, it was shown that on days when there was frequent blood glucose monitoring there were more hyperglycaemic (R = 0.25, P \ 0.05) and hypoglycaemic (R = 0.094) episodes. On average 4.6 glucose measurements were taken before each episode of hypoglycaemia compared to 2.6 after, suggesting that frequent checks preceded hypoglycaemia rather than an episode of hypoglycaemia prompting regular monitoring. A similar trend was also seen with changes to the with insulin infusion rate; frequent changes were associated with a greater number of hyperglycaemic (R = 0.29, P \ 0.05) and hypoglycaemic (R = 0.089) episodes per day. Episodes of hypoglycaemia were managed inconsistently with patients receiving a variety of correction fluids. CONCLUSIONS. The audit found that intensively controlled blood glucose in ICU patient's resulted in a large number of hypoglycaemic incidents. In addition we observed that frequent blood glucose monitoring and adjustments to the rate of insulin infusions was associated with more frequent episodes of hypoglycaemia or hyperglycaemia. Following this audit we have advocated permissive hyperglycaemia in our unit and introduced new guidance for the management of hypoglycaemia. In 2009, the NICESUGAR study [1] did not confirm the beneficial effects of tight glycemic control in intensive care unit (ICU). The same year, french Expert's Formalized Recommendations (EFR) for blood glucose (BG) management have been published [2] . Several hypothesis have been proposed to explain the conflicting results of litterature: impact of the blood glucose (BG) variability, differences in glycemic target with the kind of diseases or type of ICU, differences according to the diabetic status or to the proportion of calories provided parenterally. OBJECTIVES. To characterize the practice of glycemic control by french intensivists in the light of major recent publications. METHODS. Phone survey during March 2010 with a standardized questionnaire of medical team members. Thirty-one surgical ICU (SICU), 28 medical ICU (MICU) and 11 polyvalent ICU (PICU)-which represent 70 ICU distributed on the 29 French university hospitals-were contacted. In addition 10 French non university hospitals ICU (NUICU) were questionned. All results are in percentage except BG in mmol/L. All the contacted ICU accepted to participate. NICESUGAR study was known by the responder in 65/71/50 and 50% of SICU/MICU/PICU and NUICU. respectively. EFR were known by the responder in 48/50/58 and 50% of SICU/MICU/PICU and NUICU, respectively. ICU with intensivists who changed their practice since 2009 were 16/16/38 and 50% of SICU/MICU/PICU and NUICU, respectively. All of them declared to be more tolerant with the upper glycemic level. Among intensivists who did not change their practice recently, 10-20% said that their point of view prior to 2009 was confirmed by NICESUGAR results. The potential prognostic value of BG variability was known by 58/42/42 and 20% of the interlocutors in SICU/MICU/PICU and NUICU, respectively. The BG algorithms were all based on capillary glycemia with a period of measurement when stability is achieved of 3/4/3 and 3 h in SICU/MICU/PICU and NUICU, respectively. Only intravenous insulinotherapy was protocolized in 69/89/67 and 67%, respectively. 23rd ESICM Annual Congress -Barcelona, Spain -9-13 October 2010 S219 INTRODUCTION. Oxygen saturation gradients among different territories (as central to mixed venous circulations) are widely known and, recently, lactate gradients between central to mixed venous circulation were also described. Little is known about the pathophysiological meaning of these gradients, but their role may be a key understanding factor in how progression of organic dysfunctions develops in intensive care patients. Glucose, besides a central energetic source to live organisms, may not be a preferential ATP substrate to all tissues or organs as occurs with cardiomyocytes. Therefore, regional differences in glycemic concentrations may exist and their behavior may contribute to our understanding about cell death and organ disfunction in shock and hypoxia states. OBJECTIVES. Detailed describe glucose gradient patterns in different vascular compartments and different models of tissue hypoxia. Observational experimental data, 37 large white pigs, male sex, 35 kg. Animals studied under general anesthesia, mechanically ventilated and fully monitorized. Fluoroscopyguided coronary sinus, superior and inferior vena cavas, right atria/ventricle, PA and femoral artery catheterizations were performed. Sepsis = fecal peritonitis; anemia = progressive 5% reduction of hemotocrit from 30 to 7% (colloidal hydroxiethylstarch dilution); hypoxia = progressive 5% reduction in FiO 2 from 30 to 7% (air dilution with nitrogen gas); tamponade = progressive 20% reduction of initial CO each half hour. Complete blood gas analysis were performed hourly. Pigs were sacrificed with sedative overdose and 20 ml KCl 19.1% injection. Glucose among different compartments and models RESULTS. Higher differences among curves and along time were detected in anemia group. SVC consistently account for the lowest values in glucose concentrations (higher consumption by CNS?), except for anemia group (CS lower). In sepsis and hypoxia-hypoxic animals, glucose reaches peak values and acutely decreases in a different pattern (exhaustion?). Anemia, hypoxia and tamponade gradients among curves tend to enlarge along time, differently from control and sepsis. CONCLUSIONS. Glucose patterns substantially vary along time, depending on tissue hypoxia model analyzed. Further tests in our sample and further investigations will be necessary to test the clinical significance of these findings and explain the pathophysiological reasons behind them. GRANT ACKNOWLEDGMENT. FAPESP (Fundação de Amparo à Pesquisa do Estado de São Paulo). OBJECTIVES. To compare both time to wake following discontinuation of midazolam, and sedation control, between haemofiltered (HF) and non haemofiltered (NHF) patients. In this retrospective observational study, 72 consecutive HF and NHF patients were studied over 18 months. Inclusion criteria included a minimum of 7 day stay on ICU and receiving continuous midazolam infusion. Exclusion criteria included patients who were intentionally oversedated or had impaired CNS function on admission. Sedation levels were calculated hourly using the UCLH Sedation Scale, and adjusted as per Unit protocol to achieve target sedation. A score between -1 and +1 represents optimal sedation, and -2 to -3 is 'oversedation', and +2 to +3 represents 'undersedation'. RESULTS. There were 34 patients in the HF group and 38 in the NHF group. Baseline characteristics were similar for both. Approximately 40,000 h of sedation were analysed. At least one episode of 'oversedation' was recorded in 91.2% of the HF group and 89.5% of the NHF group. HF patients spent 16% of their ICU stay over-sedated, compared to 8% of the NHF patients (p = 0.001), see Table 1 . Median time from midazolam discontinuation until sedation score of +1, was 20 h in the HF group, and 5 h in the NHF group (p = 0.008). There was no significant difference between the two groups for time from midazolam discontinuation to extubation. The HF group had more 'oversedation' episodes lasting 6-12 h (p = 0.014), 13-24 h (p = 0.010) and 25-48 h (p = 0.002). INTRODUCTION. Pain, inflammatory and sympathetic response associated with anesthetic emergence have been identified as important factors mediating the increased incidence of cardiac ischemia postoperatively [1] . OBJECTIVES. To analyze the differences in terms of hemodynamic and stress response and cardioprotective effect after the implementation of two different analgo-sedation protocols aimed at mantaining a RASS score between -3 and -2. METHODS. Design analysis of a prospective and randomized collected database. Setting Intensive Care Unit (ICU) in an University Hospital. Patients A total of 50 patients aged 30-80 (31 M and 29 F; ASA II-III) with an EUROSCORE between 6 and 10, submitted to elective onpump cardiac surgery from July 2009 to February 2010. Randomization on ICU admission the patients were randomly assigned to Group 1 (Remifentanil 0.02-0.15 c/kg/min + Midazolam rescue intravenous bolus of 1-2 mg if needed) or Group 2 (Propofol 0.5-4 mg/kg/h + Fentanyl rescue as an intravenous bolus of 50-100 c if needed). Glucose control and weaning were carried out with the same protocols in the two groups. Data collection: Preoperative and each hour (during the first 10 h in ICU) assessment of Bispectral Index (BIS) and of Glucose and Lactate blood levels; hemodynamic parameters, preoperative and postoperative assessment of TNFa and IL6, C-Reactive Protein (CRP), Troponin I (TnI) and B-type Natriuretic Peptide (BNP) blood levels. Weaning parameters were assessed 30 min after the start of weaning protocol. Moreover data about Admission SOFA score, weaning duration and ICU length of stay (LOS) were collected. Statistics: Within-between groups analysis, one-way ANOVA and unpaired t test were used when appropriate. RESULTS. The preoperative and operative variables were comparable between the two groups (p = NS for all measurements). BIS values were lower in group 1 (p = 0.001). Glucose and Lactate blood levels were lower in Group 1 (p = 0.002 and p = 0.005, respectively). Heart rate and mean arterial pressure were lower in Group 1 (p = 0.008 and p = 0.004, respectively). Cardiac index, indexed systemic vascular resistances, stroke volume index, cardiac cycle efficiency and dp/dt were higher in group 1 (p = 0.002, p = 0.008, p = 0.02, p = 0.001, p = 0.008 and p = 0.004, respectively). TNFa, IL6 and CRP blood levels were lower in Group 1 (p = 0.006, p = 0.01 and p = 0.005, respectively). TnI and BNP blood levels were lower in group 1 (p = 0.008 and p = 0.004, respectively). Rapid Shallow Breathing Index (RSBI), and RR (Respiratory Rate) x PS (Pressure Support) were lower in Group 1 (p \ 0.001). Admission SOFA score were lower in Group 1 (p \ 0.005). Weaning duration were lower in group 1 (p = 0.02). No difference in ICU LOS. CONCLUSIONS. The analgo-sedation protocol remifentanil-based was associated with a better postoperative protective profile in this specific clinical context. GRANT ACKNOWLEDGMENT. Chiara Longo. INTRODUCTION. Suxamethonium [1] , historically, has been the preferred drug for providing rapid onset neuromuscular blockade in patients requiring intubation on critical care. There are numerous problems associated with Suxamethonium. Hyperkalaemia resulting in cardiac arrest is of great concern in critical care patients. Other complications include anaphylaxis, malignant hyperthermia, prolonged paralysis, bradycardia, raised intracranial pressure, raised intraocular pressure and myalgia. Critical care patients are much more vulnerable to an unpredictable hyperkalaemic response and it is not confined to patients with burns, neuromuscular disorders, renal failure and/or severe muscle trauma but septic patients as well. Rocuronium is an alternative agent that may be more suited to the critical care population. OBJECTIVES. To assess attitude within Mersey region (UK) towards the use of suxamethonium within critical care given that alternative agents are available.In particular rocuronium which has its own reversal agent-sugammadex. METHODS. We conducted a paper based survey of the 84 critical care consultants working in Mersey region. A response rate of 44% was achieved. RESULTS. When performing emergency intubations in ICU 21 respondents (71%) used Suxamethonium in a varying degree. Of these 14 respondents (40%) used Suxamethonium more than 50% during emergency intubation, while 10 (29%) did not use Suxamethonium at all. Rocuronium was used by 26 (75%) of intensivists. Of these 17 (49%) used Rocuronium more than 50% during RSI whilst 8 (23%) did not use Rocuronium at all. Suxamethonium was viewed as having a place in ICU by 29 (82%) of respondents. Witnessed complications to suxamethonium included cardiac arrest 13(37%), hyperkalaemia 14(40%), bradycardia 23 (66%), anaphylaxis 10 (28%), malignant hyperpyrexia 2 (6%) and prolonged paralysis 16 (46%). 24 (69%) believed rocuronium to be preferable to suxamethonium. 13 (37%) administered rocuronium in the dose recommended for RSI (1.2 mg/kg).The availability of Sugammadex would persuade 16 (45%) to use rocuronium in the future.19 (73%) have not experienced any problems with Rocuronium. A large number of intensivists are using suxamethonium more frequently than rocuronium despite indicating that rocuronium is more preferable. Many use suxamethonium for its ability to provde quick, reliable intubating conditions (Fig. 2 ) yet many are not using rocuronium at the dose intended therefore questionning the ability to make a comparison. Rapid offset was considered desirable but many believed this not to be applicable (Fig. 2) to their patients on critical care. In conclusion suxamethonium appears to still have a place within critical care but perhaps rocuronium is an agent more suited to many of the patients requiring intubation within critical care. OBJECTIVES. The aim of this survey was to ascertain the level of acquaintance and opinions prevalent among physicians, nurses and paramedical personnel in UK. The survey encompassed modifiable and mitigating risk factors; consequences and recommended pharmacologic approaches providing resolution of delirium in critical care patients. METHODS. Contacted Intensive Care Society UK in June 2009 Published Online Survey for 6 months (July2009-Dec 2009)). Responses collected through Intensive Care Society UK and personal E mails.Participants included clinicians, nurses and paramedical personnel. Total of 101 Responses obtained (More than 2 answers obtained from most respondents). Data analysed and results presented as percentage of correct answers. RESULTS. Delirium was stated as organ dysfunction by 55.6% respondents; clinical manifestations were correctly elucidated by 85%, 66% people recognized its relevance as terminal illness; validation tools were known to 50%; less than 20% were cognizant with modifiable risk factors while treatment with Haloperidol was known to 100% participants. CONCLUSIONS. The preponderance of delirium and its adverse impact on Critical care LOS, morbidity and mortality incur substantial financial outcome of national Health resources. Educational workshops, posters and flowcharts to facilitate understanding the presentation and management of delirium form compelling commitment for the present day intensivist. INTRODUCTION. Delirium occurs frequently in critically ill patients, and especially in severely ill and in infectious patients. Although several causal pathways for delirium have been described, the role of biomarkers in ICU patients is unknown. We investigated potential differences in various serum biomarkers between delirious and non-delirious ICU patients with and without an infection. METHODS. Delirium in adult ICU patients was diagnosed using the confusion assessment method-ICU (CAM-ICU). Delirious and non-delirious patients were matched for age, APACHE-II score, the presence of absence infection or SIRS criteria, and length of ICU stay at the moment of blood withdrawal. Neurology and trauma patients were excluded. Within 24 h after the development of delirium blood was drawn for determination of biomarkers. RESULTS. 50 delirious ICU patients were matched with 50 non-delirious patients. Delirious patients with infection or SIRS had significantly higher levels of IL-8, IL-18, IL-1ra, MCP-1, and procalcitonine compared with the non-delirious patients with an infection (Table 1) . Noninflamed delirious patients had significantly higher levels of IL-6, IL-8, IL-1ra, IL-10 and procalcitonine compared with non-delirious, non-inflamed patients. When corrected for infection or positive SIRS, levels of IL-8 (p = 0.04), IL-10 (p = 0.03), MCP-1 (p = 0.004), cortisol (p = 0.009) and procalcitonine (p = 0.04) were significantly higher in the delirious group compared with the non-delirious patients. CONCLUSIONS. In ICU patients, delirium is associated with increased concentrations of several cytokines, even after adjusting for the presence of infection. We conclude that IL-8, IL-10, MCP-1, cortisol and procalcitonine are associated with delirium in ICU patients, and could serve as possible biomarkers. METHODS. Prospective blinded randomized controlled trial involving 34 patients undergoing primary elective coronary artery bypass graft (CABG) or valve surgery. Exclusion criteria were: BMI [ 35, diabetes, age [ 75 years, ejection fraction (EF) \ 30%, ASA [ III, reduced pulmonary function (FEV1 and FVC \ 50%), combination operations (e.g. CABG + valve surgery), pre-operative alcohol or drug abuse, severe neurological or psychiatric disease, inability to give informed consent. In both groups anaesthesia was induced in a standard manner with etomidate, sufentanil, midazolam and rocuronium. In the EAA group 3 acupuncture points were routinely used bilaterally: Ssu-Tu (Tb-9; extensor side of forearm between ulna and radius), Shuei-Tu (St-10; medial border of sternocleidomastoid muscle) and the Heart (100) to Trachea (103) ear point. The acupuncture needles were stimulated with asymetrical biphasic impulses at a rate of 15-20 Hz generated by the Chinese Acupuncture Analgesia Set Type 71-3 until closure of the thorax. Anaesthesia was maintained with propofol and isoflurane under BIS monitoring. The OA group additionally received a continuous sufentanil infusion intra-operatively. Sedation with propofol was discontinued after 1 h on the ICU provided that the patient was hemodynamically stable. Following extubation numerical analog pain scale (NAS) scores [ 3 were treated with i.v. piritramid. After discharge from the ICU, patients interviewed regarding their level of satisfaction with their anaesthesia and postoperative analgesia. RESULTS. Three patients were removed from the EAA group due to postoperative sedation of greater than 24 h duration (due to hemodynamic instability, bleeding, and requirement for rethoracotomy METHODS. This observational study was carried out with approval from our institution's ethics committee. Every patient admitted to our 31-beds ICU during a 2-months period was rated (A) by his/her nurse as having or not having delirium by subjective delirium criteria, and (B) with the CAM-ICU as the reference method by two 4th year medical students unaware of the other raters' judgment. Patients on their day of admission were excluded, as well as those with severe neurological impairments (e.g., history of stroke, dementia) and non-German speakers. Patients' demographics, including TISS-28, SOFA, and SAPS II were calculated from patients' day charts, nurses' notes each day of assessment. RESULTS. Out of 170 screened patients, one withdrew consent, 4 were excluded due to incomplete data, 5 constantly comatose patients died in ICU and were also excluded. Patients were not assessed if deeply sedated or in coma. 434 paired observations in 160 patients were completed. Delirium was diagnosed in 29% (n = 126) and excluded in 71% (n = 280) with the CAM-ICU. Without CAM-ICU, subjective assessment found delirium in 19.8% of observations (n = 86) during delirium, but also in 9.2% (n = 40) in patients without delirium. Delirium was not found in 6.5% (28 cases) though delirium was diagnosed with the CAM-ICU. Four patients who had delirium left the ICU without ever been recognized by subjective assessment. CONCLUSIONS. Subjective assessment omits a considerable amount of patients with delirium, but overestimates the total number of patients with delirium. Routinely delirium monitoring will identify patients who require special treatment and exclude those who do not. We investigated the relation between the implementation of analgosedation and UE on our 14bed mixed ICU. METHODS. The incidence of UE in a 40-month period was retrospectively examined (January 2007-April 2010). In January 2009 our sedation protocol (midazolam and/or propofol combined with fentanyl) was changed.We started with analgosedation (remifentanil/propofol) in selected patients with impaired renal and hepatic function. Data regarding sedative use, level of sedation (RASS score) and time of the day of the UE were collected from our patient data management system (Metavision). CONCLUSIONS. Allthough the implementation of analgosedation seems to be associated with a shorter mean duration of ventilation this is complicated by an increased number of UE. Interestingly, a substantial part of the patients did not require re-intubation indicating the need to better distinguish these patients from the ones that needed re-intubation. INTRODUCTION. Mitochondrial dysfunction has been implicated in various diseases of critically ill patients. Since many of these patients receive analgesic drugs, effects of these compounds on mitochondrial functions are of interest. Remifentanil is a specific l-opioid receptor agonist and a potent short-acting synthetic analgesic drug. OBJECTIVES. This study addressed the hypothesis that remifentanil might regulate oxygen consumption of cultured human hepatocytes and their isolated mitochondria. The human hepatoma cell line HepG2 were exposed to remifentanil at 50 or 500 ng/ml for 1 h or 50 ng/ml for 2, 4, 8 and 16 h, and cellular respiration rates were measured using a high-resolution oxygraph (Oxygraph-2 k, Oroboros Instruments, Innsbruck, Austria). Glutamate/malate, succinate or ascorbate/TMPD were used as substrates to test the function of complex I, II and IV, respectively. Isolated HepG2 cells' mitochondria (isolated by differential centrifugations) were incubated with remifentanil at 50 or 500 ng/ml for 1 h and respiration rates were also measured. Detection and analysis of inhibitory kBa (IkBa) phosphorylation of cell extract of remifentanil (50 and 500 ng/ml, for 30 min)-induced HepG2 were done with a FunctionELISA TM IkBa assay kit (Active Motif, Carlsbad, CA, USA). Remifentanil-treated HepG2 cells were fixed and embedded in Epon and ultrathin sections were analyzed with an EM12 transmission electron microscope (Philips, Eindhoven, Netherlands). We observed early (within the first hour of incubation) remifentanil-induced (at 50 and 500 ng/ml) increases in maximal cellular respiration (Fig. 1a , b) (C: control, R: remifentanil). This effect was not present at 2, 4, 8 or 16 h of incubation. Preincubation with naloxone (1,000 ng/ml) for 1 h (Fig. 2a, b ; black bars) prevented the remifentanil-induced increase in cellular respiration. Remifentanil did not interfere with isolated mitochondrial respiration of HepG2 cells. Remifentanil also induced phosphorylation of IkBa, denoting the stimulation of nuclear factor kB. There were no major alterations in cellular or mitochondrial ultrastructure. Mitochondrial respiration data are presented as mean ± SD. Statistical significance between samples using the paired sample t test is indicated. CONCLUSIONS. The data suggest that remifentanil at 50 and 500 ng/ml interferes with cellular respiration of human hepatocytes. INTRODUCTION. Quoted rates of complications following tracheostomy insertion vary greatly [1] [2] [3] [4] with much of this data collected retrospectively. Due to large numbers of patients being lost to follow up there is little information available on complications occurring in patients with tracheostomies in situ or following their removal. To prospectively review all tracheostomies inserted into 200 consecutive critical care patients and record complications at the time of insertion, in patients whilst cannulated, and following decannulation. A questionnaire was completed at the time of insertion by the operator. All patients then received regular follow up visits whilst cannulated and post decannulation looking for complications directly related to tracheostomy insertion. Patients were followed up until hospital discharge, death or transfer to another institution. Rates of major complications on insertion were: major bleeding 5%, tracheal wall injury 0.5%, pneumothorax 0.5%. There were no deaths attributable to tracheostomy insertion and 68.5% of patients had no insertion complications. Minor bleeding was seen in 12% and tracheal cartilage fracture in 6% of patients. Ninety-three percent of patients received at least one follow up visit. Complications in patients whilst cannulated were: prolonged bleeding 5%, pneumothorax 2%, surgical revision 3%, accidental decannulation 4% and tube blockage 6%. Of the blockages/displacements 40% resulted in a severe hypoxic event including 2 cardiac arrests. Sixty-two percent of patients received follow up post decannulation. One patient developed immediate respiratory problems and required recannulation. A high number of patients initially reported problems related to swallowing (liquids 12%, solids 5%) and phonation (hoarseness 4%, voice change 9%) however these symptoms settled in all patients other than one patient with a severe brain injury and one patient with a vocal cord palsy caused by lung cancer. Rates of insertion complications were comparable to those previously described. Percutaneous tracheostomy can be safely performed in critical care patients. Our detailed follow up has highlighted an area of serious concern-blockage of tracheostomy resulting in hypoxia. All tracheostomies that blocked were single lumen tubes. No serious enduring problems were reported post decannulation in patients whilst still in hospital. However longer term follow up of patients following hospital discharge would be required to accurately assess frequency of late complications. OBJECTIVES. We evaluated the possibility to ventilate the patient during tracheostomy execution using an endotracheal tube with a camera embedded tip for continuous visualization of patient airways on a dedicated monitor (ET-view, Unimedical Bio.Tech., Italy). METHODS. Ten adult patients underwent PercuTwist PDT using ET-view instead of video fiberoptic bronchoscopy. Each PDT was performed under total intravenous anaesthesia, myoresolution and volume controlled ventilation. Heart rate, pulsoxymetric oxygen saturation and arterial blood pressure were monitored. ET-view was placed using an airway exchange catheter under continuous visualization. Mechanical ventilation (Tv 8-10 ml/kg, PEEP 5 cmH 2 O, RR 12 bpm, FiO 2 1.0) was maintained by using the ET-view tube throughout the whole duration of the procedure. Duration of each procedure was recorded. (Table 1) . Survey was developed using dichotomous questions. It was first piloted among our own ICU physicians. In September 2009, 300 surveys were mailed to both surgical and medical intensive care unit directors with more than 5 years experience in academic institutions in the USA. ICU with less than 12 beds were excluded. This survey inquired the physicians regarding training in the use of emergency airway cart and the specific devices they had used for intubations. The number and percentage of availability of these equipments in ICU settings were determined separately in the responding surveys. The trends of presence or absence of these equipments and their possible effects in DAM situations were studied. OBJECTIVES. We investigated the incidence and type of TTD in patients receiving PDT versus ST. METHODS. Data were collected prospectively from the 13-bedded unit with a mixed medical and surgical adult population over a 14-month period. All patients who underwent a tracheostomy were included. The decision on tracheostomy and technique was taken by the ITU consultant based on clinical assessment. PDT was performed using a dilatation technique [3] . ST was performed by a surgical colleague at the bedsite (standard tracheal window technique). Subgroup comparisons were carried out between the ST and the PDT group with emphasis on the incidence of TTD, defined as accidental decannulation by the patient or displacement with leak requiring repositioning. The Chi-square test was used to compare differences between groups. Values are presented as mean ± SD or median (IQR). . Tracheostomy was carried out in 127 pts (78 male, mean age 62 ± 15 years, mean BMI 26 ± 6 kg/m 2 ). Mean length of stay was 21 ± 13 days, mean day of procedure following admission was 7 ± 4 days and median APACHE IV score was 55 (IQR 25). ST was carried out in 97 pts (76%) and PDT in 30 pts. There were 33 post-procedural complications in total, significantly more in the ST group (p \ 0.001). TTD was the most common post-procedural complication (p \ 0.001). Other complications were bleeding (n = 2) and pneumomediastinum (n = 1). 4  14  18  Leak and replacement  0  12  12  Other  0  3  3  Total  4  29  33 STUDY LIMITATIONS: This is a non-randomised prospective study. The lower incidence of complications in the PDT group is therefore likely attributable to selection bias. CONCLUSIONS. These preliminary data support previous findings of more frequent complications in surgical tracheostomies. We have identified a high incidence of tracheostomy tube dislodgements in both types of tracheostomies which warrants further investigation. [1] . In several cases this has been associated with the early insertion of a fenestrated tracheostomy tube [2] [3] [4] . In the presence of positive pressure ventilation, air may leak from a fenestrated tube into the tissues even when a non-fenestrated inner cannula is inserted [5] . The UK Intensive Care Society guidelines for temporary tracheostomy 2008 recommend that fenestrated tracheostomy tubes should be used with caution in mechanically ventilated patients and only in patients who are weaning from ventilation [6] . The guidelines also state if a fenestrated tube is used, it is vital that the position and on-going patency of the fenestration(s) are checked regularly, but do not specifically recommend how this should be done. OBJECTIVES. Primary-Prospective questionnaire study of adult intensive care units in the UK to establish the current practice with respect to use of fenestrated tracheostomy tubes and also to ascertain the incidence of surgical emphysema related to tracheostomy. Secondary-Establish current UK practice regarding the requesting of chest radiographs after tracheostomy and find out if units have changed their practice since publication of the TracMan study [7] . CONCLUSIONS. In accordance with UK ICS guidelines [6] we would like to re-iterate that fenestrated tubes should not be inserted at the time of initial percutaneous tracheostomy. We would recommend that if a fenestrated tube is being used in a mechanically ventilated patient the position of the fenestration(s) in the tracheal lumen should be checked using flexible endoscopy. If however the patient is spontaneously ventilating the position of the fenestration(s) need only be checked if there is clinical suspicion of a problem. INTRODUCTION. Patients exposed to prolonged endotracheal intubation are at increased risks for significant swallowing disorders (SD) which may complicate the post-extubation period. OBJECTIVES. Data in the literature about incidence and clinical impact of thus disorders are heterogeneous [1] . The primary aim of this pilot study was to evaluate incidence of SD occurring in patients with more than 7 days of invasive mechanical ventilation. A prospective pilot study realized in a 20 beds adults medical ICU of an University hospital. During 9 months (July 2009 and March 2010), we screened all patients with more than 7 successive days with intubation at the time of extubation. Only those without pre-existing comorbidities possibly associated with SD and able to cooperate were enrolled in the final analysis. A clinical standardized test specifically designed to detect SD was performed by a dedicated physiotherapist 24-48 h after extubation. This test combines clinical evaluation of cranial nerves and a swallowing test using water [2] . Preliminary data of patients without SD and with SD were compared using non parametric statistical test. Only three patients with SD were evaluated by an oto-rhino-laryngologist because of clinical persistence of SD, several days after extubation. The fiberoptic endoscopic evaluation revealed incomplete glottal closing ability because of decreased mobility of one vocal cord in these three patients. Among the 40 patients, 3 required al least one reintubation. Two of them had swallowing disorders after the first extubation. CONCLUSIONS. Based on these preliminary results, 43% of patients with prolonged mechanical ventilation exhibit SD. SD is associated with a prolonged MV duration and ICU stay. A prospective multicenter study is planned to identify in a larger cohort the risk factors and impact on clinical outcome of SD in patients intubated for more than 7 days. [1] . While laryngeal-pharyngeal oedema is often the only aetiology suspected, the failure of any organ used in the swallow process and specially the tongue could also be involved. To report a cohort of difficult to wean patients who develop a tongue paralysis during their stay in order to discuss causes and consequences of this unfamiliar SD aetiology. A retrospective study realized in a six beds weaning units (WU) of an university hospital. Between Nov 2003 and Nov 2008, all patients admitted in the WU for management of prolonged mechanical ventilation (MV) were systematically submitted to a clinical test of cranial nerves and to a deglutition test. All patients with a clinical diagnostic of unilateral or bilateral hypoglossus nerve paralysis were enrolled. SAPS 2, duration of MV, type of paralysis and association with others cranial nerves abnormalities were checked. We also looked for the causes of this paralysis and notified the intensity of the SD recovery 1 year after ICU discharged. RESULTS. During the study period, 229 patients were admitted in the WU and hypoglossus paralysis was found in 10 of them (4%). Among the 10 patients, 5 were tracheotomised after at least 1 re-intubation and 2 were tracheotomised without any extubation attempt. Two patients required one re-intubation before a successful extubation. The last patient was successfully extubated after 10 days of MV. The median age of the population was 44 years (IQR: 36-59). The median SAPS2 score was 46 (43-76) and their median duration of mechanical ventilation was 31 days (25-72). All patients had a peripheric paralysis confirmed in electromyography. In five cases the tongue paralysis was associated with others cranial nerves block whose three with an homolateral recurrent laryngeal nerve paralysis (Tapia's syndrome). The aetiology of the paralysis was obvious in three cases: two Tapia's syndrome due to an homolateral jugular thrombosis after a central venous jugular catheter and one post infectious Guillain-Barre syndrome. In the sevenother cases, we found three ICU acquired neuromyopathy and two HSV seroconversion without any clinical sign of infection. For two patients, we were not able to find any abnormality that could be related to the isolated tongue paralysis. One year after discharged, seven patients had a complete recovery. Hypoglossus nerve paralysis is a unusual cause of SD, easy to detect by a simple clinical exam. Because of the unexpected significant incidence reported in this study, we suggest that a systematic clinical evaluation of cranial nerves (specially hypoglossus) should be associated with the currently performed swallowing test for further SD studies. [1] . OBJECTIVE. To determine hospital mortality and associated risk factors of unselected, ventilated patients in reference to the treating institution. METHODS. In a sub-study from the 2nd International Study on Mechanical Ventilation (ISMV) [2] , ventilated patients who had been admitted to an intensive care unit (ICU) in May 2004 in Germany were included, if ventilated for more than 12 h invasively or at least 1 h non-invasively. Patients were compared for treatment in a non-university hospital (NUH) or university hospital (UH), and analysed separately for having developed ARDS (NUH: n = 111; UH: n = 87) or no ARDS (NUH: n = 357; UH: n = 473). Multivariable logistic regression was performed separately for the patient group with or without ARDS to define risk factors independently associated with increased hospital mortality. Both models included the same variables concerning the setting of care (e.g. hospital-and ICU-size, NUH, UH), baseline factors (e.g. age, SAPS II-Score, main reason for ventilation), ventilator settings and gas exchange values averaged over the first week of ventilation or after ARDS-onset and complications occurring over the course of ventilation (e.g. sepsis, shock, acidosis, organ failures). CONCLUSION. Although the mean SAPS II scores were higher in our entire patient group with ARDS, the hospital mortality was 8% lower than in the ALIVE study [3] and 13% lower compared to ARDS patients from the other countries of the second ISMV [2] . The hospital mortality of ARDS patients was remarkably higher in NUH than in UH and, treatment in a NUH was the most important risk factor for ARDS patients but less important for patients without ARDS. (GOLD III-IV) is poor, after invasive mechanical ventilation (iMV), the hospital mortality appears to be around 50% [1] . In addition weaning can be difficult and patients may end up being ventilator-dependent [2] . Patients with severe COPD are often rejected for iMV because of a presumed difficult and prolonged weaning period and poor prognosis. However there is little evidence supporting this treatment strategy and ICU treatment has improved over the last decade. OBJECTIVES. An outcome study in patients with severe COPD (FEV-1 \ 1L) requiring iMV because of acute respiratory failure. METHODS. A retrospective single center study, on a mixed ICU. In total 22 patients with 25 admissions, were included in this study, between Jan 2006 and Feb 2010. RESULTS. Primary diagnosis at admission was exacerbation COPD in 44%, exacerbation COPD plus cardiac failure in 20%, pneumonia and sepsis in 36%. A previous history of congestive heart failure was present in 37%, 23% used oxygen at home and 32% were housebound. The ICU mortality was 12% and hospital mortality 16%. Cumulative mortality after 30-days was 23%, after a 1/2 year 56% and after 1 and 2 years 73 and 78%, respectively. None of the discharged patients were mechanical ventilator depended. INTRODUCTION. Barotrauma is a feared complication of mechanical ventilation and is associated with increased morbidity and mortality 1 . Incidence of barotrauma in patients with Acute Respiratory Distress Syndrome (ARDS) has been shown to range between 0 [2] to 76% [3] . Many authors recognize that experimental pulmonary and extrapulmonary acute respiratory distress syndrome are not identical, with different response to ventilatory therapies [4] . OBJECTIVES. To analyse whether barotrauma varies between ARDS with pulmonary (ARDSp) and extrapulmonary origin (ARDSexp). We evaluate incidence, risk factors and outcomes of developing barotrauma in patients with ARDSp and ARDSexp, in a cohort of patients who met the ARDS criteria of the Consensus Conference [5] after 24 h in mechanical ventilation with low tidal volume (6-8 ml/ kg body weight), and who were part of study comparing two methods of setting the level of positive end-expiratory pressure (PEEP): according to the ARDSNetwork standard-of-care recommendations [6] or to the best compliance according to the method proposed by Suter [7] . We measured demographic data daily ventilator settings, severity of disease, organ failure, daily Acute Lung Injury scale (LIS) [8] and outcome. Variables with normal distribution were described as mean ± SD, with non-normal distribution as medians and interquartile ranges. INTRODUCTION. There is known that mechanical ventilation may contribute to the development of systemic inflamatory response and subsequent multiple organ failure and death, in patients with Acute Respiratory Distress Syndrome (ARDS) [1] . Several studies have demonstrated that this effect could be mediated by the method chosen to set the possitive end-expiratory pressure (PEEP) in these patients [2] [3] [4] . To compare the effect on multiorgan failure at 28 days of two strategies of setting PEEP in patients with ARDS ventilated with low tidal volumes. We included consecutive patients who met the ARDS criteria of the Consensus Conference [5] , after 24 h on mechanical ventilation with low tidal volume (6-8 ml/kg body weight) and limitation of pressures on airway at 35 cmH 2 O. They were randomizad into two groups: a group control, where PEEP was set according to the FiO 2 applied as in the ARDS-Network study [6] , or a interventional group, where PEEP was set according to the method proposed for Suter [1] , which consist in setting PEEP level according to static compliance. In both groups PEEP level was set daily [7] . We defined organ failure as a punctuation of 3 or 4 in the Sepsis-Related Organ Failure Assesment (SOFA) [8] , and number of organ failure-free days to day 28 as the number of days alive and free of organ failure at day 28. CONCLUSIONS. IAH is common in MV patients. APP seems to be a better outcome predictor than IAP. Maximal, mean and the trend in EVLWi values correlated well with outcome. We hypothesize that there is a strong correlation between capillary leak (CLI and PVPI), positive fluid balance, increased IAP, increased EVLWi and organ failure with poor prognosis. Future studies should look at the effect of aiming for a negative fluid balance on these parameters. CONCLUSIONS. We report the interim results of the largest multicentre study on the epidemiology of IAP and APP. IAH occurs frequently in MV patients and is associated with longer MV, ICU and hospitalization periods, but not with higher mortality. On the other hand, APP below 55 mmHg is associated with significantly higher 28-day mortality, but is often related to a low MAP rather than a high IAP. The APP increases less over time in patients with IAH during their first week in ICU. INTRODUCTION. Extubation failure is common in intensive care unit and has been associated with poor outcomes like increased morbity, higher costs, higher ICU length stay and mortality. These adverse outcomes highlight the importance of predictors of extubation failure. OBJECTIVES. The aim of this study was to evaluate whether extubation failure is related to poor outcomes of medical ICU patient in our hospital. A retrospective cohort study was performed using data gathered in a 16 bed medical clinical and surgical ICU in a tertiary hospital. All adults admitted from 01/01/2007 to 31/12/2009 who required mechanical ventilation via an endotracheal tube for more than 24 h were included. Extubation failure was defined as reintubation within 48 h after planned extubation. The control cohort included patients who had successful planned extubation. The outcomes were ICU mortality, renal failure, use of vasopressors, and average duration of intubation. Data were analyzed in SPSS computer program using Chi-square test, Student's t test and Mann-Whitney test. Statistical significance was considerable when p valor \ 0.05. Two hundred and twenty patients were included. Two hundred and six were successfully extubated and fourteen had extubation failure. Extubation failure was 6% and causes were acute respiratory failure 43% (6), respiratory muscle weakness 22% (3), upper airway obstruction 14% (2), inability to protect airway 14% (2), and acute pulmonary edema 7% (1). Among then 57% (8) were female with mean age of 79 -14 years. Seventy-nine percent (11) were clinical patients and medium APACHE II score was 22 -8. ICU mortality was 64% (9), rate of renal failure was 43% (6), rate of vasopressors was 100% (14) and rate of tracheostomy was 64% (9) . Age and rate of tracheostomy was significantly higher in patients who failed extubation (p = 0, 01 and p = 0.003, respectively), but there was no significant difference in ICU mortality, renal failure, use of vasopressors and length of intubation (all p [ 0, 05). CONCLUSIONS. Rate of extubation failure is acceptable when compared with medical literature. Extubation failure patients were older with higher rate of tracheostomy, but there was no difference in outcomes between groups. Further studies will be necessary to confirm these findings. INTRODUCTION. It has been recommended to keep low differential pressures during mechanical ventilation as to prevent ventilation lung injury [1] . Recently it has been suggested that Differential Pressures (DP), the difference between plateau pressures (PL) and positive end expiratory pressure (PEEP), higher than 16 cmH 2 O may be associate to higher mortality rate in patients receiving mechanical ventilation. OBJECTIVES. The main objective of this study is to determine the association between Mortality and DP higher than 16 cmH 2 O. INTRODUCTION. The incidence of acute lung injury and ARDS varies widely in the literature [1] . Recently, the introduction of ventilator care bundles and the lung protective ventilation strategies provided means to reduce the mortality of this condition [2] . OBJECTIVES. The most recent large-scale epidemiology study on the incidence and outcome of this important disease is more than 5 years old, with national studies undertaken more recently. Although in the UK the ICNARC database collects nearly all information necessary to identify patients with ALI/ARDS, surprisingly no attempt has been made to re-establish the baseline. Therefore we decided to retrospectively analyze our electronic database to give the incidence and outcome of ALI/ARDS in a typical district general hospital in the UK. METHODS. Retrospective analysis of the electronic database of an average 11-bedded ITU/ HDU in a district general hospital. We have analysed the admission data of all patients who required mechanical ventilation on admission. Basic demographic data (age, sex, APACHE II score) on admission Lung Injury Score, ICU mortality and length of stay were collected over a 1year period. In 2008, 207 patients were admitted to the unit with the need of mechanical ventilation. Male/female ratio was 132/75. Mean (SD) age 59 (17) years. Mean (SD) LIS of the population was 1.3 (1) . 17% of the patients had ARDS according to the LIS criteria, 26% moderate to severe ALI, 35% mild ALI and 18% no ALI. The mortality was 46, 36, 32 and 24%, respectively. We found significantly higher LIS amongst the non-survivors (p \ 0.05). The most common risk factor for ALI/ARDS was pneumonia followed by non-pulmonary sepsis. There was no significant difference in mortality according to risk factor. Significantly longer LOS was observed in the ARDS group compared to the No ALI and mild ALI group (p \ 0.05). With regards to ventilation parameters mean positive endexpiratory pressure (PEEP) was 6.1 ± 2.1 cmH 2 O. On the day of diagnosis of ALI/ARDS, patients received mechanical ventilation with a mean V t of 8.9 ± 2.0 ml/kg predicted body weight. CONCLUSIONS. The incidence of ARDS is slightly higher on our unit than it is described in recent literature. The mortality of ALI/ARDS is comparable of the mortality of large randomized controlled trials, which shows that lung protective ventilation strategies are well embedded in our daily clinical practice. Ventilator associated pneumonia (VAP) is a significant nosocomial infection. There are several devices now available that have been recommended to reduce its incidence. These include silver coated 1 and continuous sub-glottic drainage [2] endotracheal tubes. These devices incur a cost which has to be offset by the economic savings that could be made by prevention of VAP. OBJECTIVES. We undertook a retrospective audit in an Adult ICU of a London teaching hospital over a 6 month period to determine the incidence and costs of antimicrobial therapy in patients developing VAP. The cost of antibiotics used for treating patients with a positive BAL was €6,868.36, or €236.84 per episode [3] . As expected, patients who had VAP will use up more resources than those with a significant BAL only. Endotracheal tube (ETT) cuff inflation provides a mechanical barrier to the passage of oral contents into the trachea and subsequently reduces the risk of pulmonary aspiration. The integrity of this seal is related to ETT cuff pressure and therefore to the ability of the cuff to reduce aspiration. ETT cuff pressure should be maintained between 20 and 30 cmH2O to reduce the risks of aspiration and tracheal mucosal damage [1] . Aspiration has been reported at cuff pressures up to 60 cmH2O [2] . OBJECTIVES. We compared three different designs of Mallinckrodt ETTs: Hi-Lo Ò (polyvinyl chloride, barrel shaped cuff), SealGuard TM (polyurethane, tapered cuff) and Taperguard TM (polyvinyl chloride, tapered cuff). A universal container with internal diameter of 21 mm was employed to represent a trachea. The universal container was intubated with each variety of ETT in sizes 7.0 and 8.0. The cuffs were inflated using a standard hand held manometer (Portex CE0473) to 25 cmH2O, as per the manufacturer's recommendation. [1] . Subglottic secretion clearance is recommended [1] and, when undertaken at hourly intervals, has been shown to reduce the incidence of VAP [2] . The cuff seal must be maintained between subglottic secretion drainage to prevent microaspiration. To compare the quality of the seal created by three Mallinckrodt endotracheal tubes (ETTs). Hi-Lo Ò (polyvinyl chloride, barrel shaped cuff) was compared with SealGuard TM (polyurethane, tapered cuff) and Taperguard TM (polyvinyl chloride, tapered cuff). A universal specimen container (internal diameter 21 mm) was used to represent a trachea. A clean dry container, positioned at 30°, to depict the semi-recumbent patient, was intubated with sizes 7.0 and 8.0 Hi-Lo, Taperguard and Sealguard tubes. Cuffs were inflated to 25 cmH 2 O (± 1). 2mls of Methylene Blue diluted in water was introduced above the cuff. At the end of 1 h, it was observed whether any fluid had leaked below the cuff. This was repeated using a viscous solution (50% dilute methylene blue and 50% KY jelly). A limit of 1 h was set to reflect intervals suggested for subglottic secretion drainage. Each experiment was repeated 10 times. There was a significant difference between the performance of the different sizes of Taperguard ETTs (Fisher's Exact Test 0.003) with the smaller tube allowing less leak. The difference between sizes 7.0 and 8.0 in Hi-Lo was not significant as leakeage was observed in all of the size 8 tubes and 9 out of 10 in the size 7. Sealguard performed best with 1 and 2 tubes leaking in the size 7 and 8, respectively, and, again, there was no significant difference between the sizes. Analysis across all size 7.0 ETTs showed Sealguard and Taperguard performed better than Hi-Lo (p \ 0.001). There was no leakage after 1 h for any of the ETTs when tested using the viscous solution. OBJECTIVES. We assessed the microbial prediction and validated the adequacy of these guidelines for antibiotic strategy. We prospectively evaluated 276 cases of pneumonia acquired in the ICU. Patients were classified in Group 1 (early-onset without risk factors for PRM, n = 38) and Group 2 (late onset or risk factors for PRM, n = 238). We determined the accuracy of the guidelines to predict the causative organisms and the influence of adherence to the guidelines on the outcome of patients. We also compared the 2005 ATS/IDSA guidelines with the previous 1996 ATS guidelines. RESULTS. The rate of etiologic diagnosis (153, 55%), polymicrobial pneumonia, and the individual pathogens isolated, including PRM, were similar between the two groups. Microbial prediction was lower in group 1 than group 2 (12, 50 vs. 119%, 92%, p \ 0.001), mainly due to the isolation of PRM (P. aeruginosa and methicillin-resistant S. aureus) in 10 (26%) patients from group 1. Adherence to the guidelines by physicians was higher in group 2 (153, 64% vs. 7, 18% in group 1, p \ 0.001). Adherence to the guidelines resulted in more appropriate empirical antimicrobial treatment than non-adherence (69, 83% vs. 45, 64%, p = 0.013) and a trend toward better response to the empiric therapy only in Group 2 (98, 64 vs. 44%, 52%, p = 0.087), but did not affect mortality. Reclassifying patients according to the risk factors for PRM of the former 1996 ATS guidelines increased microbial prediction in Group 1 to 21 (88%, p = 0.014), and all except 1 patient with PRM were correctly identified by these guidelines.  One hundred eighty-one patients in SDD period and 228 patients in no-SDD period were included in the study. Mean age, type of admission, number of ventilated patients and length of mechanical ventilation were similar in the 2 groups, whereas SAPSII was lower (p \ 0.05) in SDD period (39 ± 20) than in no-SDD period (44 ± 21). VAP incidence was slightly lower (p [ 0.05) in SDD period (16.7 episodes/1,000 days of mechanical ventilation) than in no-SDD period (19.7 episodes/1,000 days of mechanical ventilation). Acinetobacter baumanii caused VAP in 7 (3.9%) patients of the SDD-period and in 13 (5.7%) of the no-SDD period with a global ICU mortality of 35%. CONCLUSIONS. The above preliminary data indicated that the withholding of SDD protocol did not substantially modify the global incidence of VAP and, in particular, of MDR Acinetobacter Baumanii related VAP. Therefore, the use of SDD seems to be not correlated with the outbreak of MDR Acinetobacter baumanii occurred in our ICU. INTRODUCTION. VAP is the most common and serious infection among patients in trauma ICU. Trauma has been identified as an independent predictor to VAP development in large cohort studies [1] . However, contribution of VAP to death in trauma patients is still a matter of hot debate [2] . Differences in microbiology are of the utmost importance in clinical practice since inadequate empirical therapy of a VAP is an independent predictor of mortality in heterogeneous populations of ICU patients and also in trauma subjects [3] . EU-VAP/CAP is an observational survey conducted in ICUs from 9 European countries. OBJECTIVES. The aim of this secondary analysis is to describe differences in etiology, diagnostic techniques, and outcomes in trauma and non-trauma patients with VAP in European ICUs. OBJECTIVES. To compare pneumonia in the ICU acquired or not during ventilation. We prospectively collected 315 episodes of ICU-acquired pneumonia. We compared clinical and microbiological characteristics of patients with VAP (n = 164, 52%) and non-ventilator ICU-acquired pneumonia (NV-ICUAP, n = 151, 48%). Among NV-ICUAP patients, 79 (52%) needed subsequent intubation. INTRODUCTION. Ventilator associated pneumonia (VAP) has been associated with considerable costs of hospitalization and morbidity. Several strategies have been implicated to minimize the risk of VAP and to manage effectively the disease. OBJECTIVES. To investigate whether the use of pravastatin reduces the incidence of VAT and whether this strategy is related with favourable outcomes in ICU patients.  We studied 154 patients (71PG and 83CG); mean (IQR) age of participants were 56.5 (40-70), APACHE II score 13.7 (11-17), SOFA 8.3 (7-11). There was no significant difference between PG and CG in terms of baseline characteristics. ICU stay (days) were 21.6 (8-29) and 28.1 (10-34) in PG and CG, respectively (p = 0.7). VAP incidence was 25.3% in PG and 38.2 in CG (p = 0.11). The incidence of bacteremia was 23.9 and 32% in PG and CG (p = 0.2). ICU mortality was 14 and 29.6% in PG and CG, respectively, (p = 0.03). Our results provide evidence suggesting that the use of pravastatin in ICU patients may be associated with decreased mortality. 23rd ESICM Annual Congress -Barcelona, Spain -9-13 October 2010 S233 INTRODUCTION. Nosocomial infections constitute a major complication in hospitalized patients, particularly in those who are critically ill and need intensive care. Ventilator-associated pneumonia (VAP) is the most frequent nosocomial infection in the Intensive Care Unit (ICU) and complicates the illness course by increasing mortality rate, length of hospital stay and costs for patients who acquire it. OBJECTIVES. Decrease the rate of VAP with the implementation of simple and cost effective measures in a clinical intensive care unit. METHODS. This study was performed in a 12 beds high complex clinical ICU in a private hospital in Rio de Janeiro, Brazil. Since 2005, the rates of VAP were tracked. For the diagnosis of VAP we used CDC criteria. We used the annual rates to compare the results trough the years. In January 2009, a new preventive program were instituted to try to decrease the rates of VAP in at least 30%. In order to acomplish that results we used simple and cost effective measures by strengthening in-service training and completing daily checklists involving the rightly use of barrier precautions, semi-recumbent position, adequacy of stress ulcer prophylaxis, antibiotic policy guided by the infection control department, daily interruption of sedation and minimal duration of mechanical ventilation, increasing hand washing opportunity and improvement patient's oral hygiene.  Pregnant women are at high risk of getting flu and developing severe complications; H1N1 outbreak confirmed the finding and pregnant women were over represented in the group of patients requiring intensive care management for respiratory impairment [1, 2] . OBJECTIVES. Aim of our paper was to confirm the effectiveness of extracorporeal membrane oxygenation as bridge to recover in patients suffering of fulminant respiratory failure due to H1N1 infection. METHODS. From October 2009 through January 2010, 16 patients were referred to our ICU because of severe ARDS secondary to virus A/H1N1 infection; in 12 cases ECMO was required as rescue therapy [3] . Among patients requiring extracorporeal oxygenation, three were pregnant or recently post partum women; one patient was bearing twins siblings. In one case our ECMO team had to place the extracorporeal support in the referring Institute [4, 5] . RESULTS. All three patients after a mean of 16 days were weaned from ECMO and required percutaneous tracheostomy to be weaned from mechanical ventilation. The pregnant woman had the cesarean delivery done while still on ECMO. The mean LOS was 37 days; all patients were discharged home in good general conditions and not requiring oxygen supply. None of the four newborns got flu infection; all infants required NICU admission; invasive mechanical ventilation was necessary for the infant born while the mother was on ECMO support. CONCLUSIONS. ECMO treatment is still a debatable therapeutic option for refractory respiratory failure in adults because of results and costs [6] . Our very small case series demonstrates ECMO to be an efficacious bridge to recover, despite an underlying clinical condition burdened by mortality of 80% or greater. ECMO treatment should be considered in high specialized centers to reach such good results. The next future will rely on so advanced and biocompatible extracorporeal oxygenation technology that this therapeutic option might be validated for increasing numbers of ICUs and might become so popular such as CRRT is now. OBJECTIVES. To characterize clinical and management features associated with successful outcome. We reviewed patient records of all h1n1 admissions. Data were analysed with non-parametric tests, i.e. descriptive statistics and univariate comparisons of survivors versus non-survivors. All values are medians unless otherwise stated. The study was approved by the ethics committee. A requirement for informed consent was waived. RESULTS. Twenty-one patients were admitted following h1n1-associated ARDS (6 female, 15 male; median age 27 years). Only two patients had received antiviral treatment before hospital admission. Following transfer, all patients were initially managed with nitric oxide (median duration 5 days) to facilitate protective ventilation. Six patients were managed with ECMO. Eight patients died; two on ECMO. Patients who survived had shorter length-of-stay at the referring hospital before transfer than patients who died (3 vs. 4.5 days). Survivors had fewer risk factors; i.e. lower body mass index (25 vs. 31) and less co-morbidity, as well as lower SAPS II score on admission (29 vs. 38) and lower median daily SOFA-score (6 vs. 7). Survivors also had less severe respiratory failure on admission (median PaO2/FiO2 ratio 9.9 vs. 6.3 kPa). Survivors were successfully managed with protective ventilation (tidal volume of 6.7 vs. 7.5 ml/kg ideal body weight) and forced diuresis or haemofiltration to maintain negative fluid balance (median daily fluid balance -181 vs. +629 mL). CONCLUSIONS. Survival was associated with rapid transfer, fewer risk factors and co-morbidities, less severe disease and strict adherence to a management protocol with protective ventilation and fluid restriction.  We have examined by light microscopy lung tissue from six patients with pandemic influenza A (H1N1) virus infection. Immunofluorescence for oxidized dihydroethydium, 3-nitrotyrosine, inducible NO synthase (NOS-2) and human influenza A nucleoprotein (NP) (for analysis under confocal microscopy) was studied in lung tissue specimens. Age ranged from 15 to 50 years. Three patients were women, and five had preexisting medical conditions. Diffuse alveolar damage (DAD) was present in five cases (as evidenced by membrane hyaline formation, alveolo-capillary wall thickening and PMN infiltrates), and interstitial fibrosis was apparent in one case. DAD was associated with intense hemorrhage in one patient. In the immunofluorescence studies there were signs of oxygen radical generation and increased NOS-2 protein and protein nitration in all tissue samples, regardless of the duration of ICU admission. Viral NP was found in the lungs of three patients. Type I pneumocytes and macrophages harbored viral NP, as evidenced by confocal immunofluorescence microscopy. CONCLUSIONS. Lung tissue from patients with pandemic influenza A (H1N1) viral pneumonia shows histological findings consistent with DAD. Prolonged nitro-oxidative stress is present despite antiviral treatment. Viral proteins may remain in lung tissue for prolonged periods of time, lodged in macrophages and type I pneumocytes. GRANT ACKNOWLEDGMENT. Mean length of ventilator treatment before ECMO was 3 days (0-10). 12 patients were cannulated for veno-venous ECMO at the referring hospital and transported on ECMO to Stockholm, one patient was cannulated in our hospital for veno-arterial support due to combined respiratory and circulatory failure. Four patients were converted from veno-venous to veno-arteriell ECMO because of right heart failure (three) or life threatening cardiac arrhythmias (one). In case of no oxygen delivery via the lungs all patients could be supported with flow rates high enough to meet their oxygen needs, mean flow 4.6 l/min (2-6). All patients survived ECMO. One patient died 4 days after discharge because of intracranial bleeding. CONCLUSIONS. Patients who were treated at the ECMO Centre Karolinska showed a rapid deterioration after start of ventilator treatment. It is an area of chronic social deprivation, with a very high incidence of chronic lung disease from Industrial exposure and cigarette smoking, and includes 7 of the top 10 obesity ares for the UK. H1N1 infection was therefore expected to have a higher than average impact. There is no provision in Wales for ECMO but the tertiary hospital (UHW) does provide a HFOV and NO service. HFOV was planned as primary rescue for refractory hypoxaemia rather than ECMO but at the discretion of the on-site clinician. A proforma for referral for HFOV was used and was very similar to the ECMO referral proforma for Leicester. H1N1 infection came in two waves with the first wave predominantly affecting two hospitals and the second wave affecting all. Despite a vaccination programme, with a good uptake, between the first and second wave the requirement for critical care services was high. This likely reflects a population at higher than average risk of severe complications of infection. Despite this, mortality was low with a comparatively lower use of ECMO and the use of HFOV and NO as primary rescue therapy for refractory hypoxaemia. CONCLUSIONS. The SEWCCN, covering a population of 1.4 million with a high incidence of morbid obesity and chronic lung disease, managed despite high critical care requirements to keep the mortality at least in line with comparative data available. Proforma for referral and agreement between centres was essential for this. HFOV with NO appears to be a viable alternative to ECMO with this particular influenza infection and in this setting. OBJECTIVES. To evaluate the potential benefit associated with corticosteroid therapy in influenza A (H1N1) ARDS. Patients with ARDS secondary to Influenza (A/H1N1) 2009 infection and having no comorbidity, to the exception of possible obesity, were selected from the REVA-SRLF registry, in which data from patients admitted with viral pneumonia were prospectively collected. Severity at presentation, length of stay, and mortality were compared in patients receiving or not steroid therapy either for ARDS or for associated sepsis syndrome. There were 120 patients without any other comorbidity than obesity in the REVA registry; 11 patients were excluded because they were included in a randomised trial (n = 7) or received steroids for ''other reason'' (n = 4  In the context of pandemic influenza A (H1N1), Chile achieved one of the highest rates of cases per habitant worldwide. Our Hospital, a national reference center, received 34 severe patients. Considering the preliminary data that alerted about the high incidence of severe hypoxemia and frequent necessity of rescue therapies in these patients, we wanted to evaluate the impact of extended prone-position ventilation (PPV) on respiratory function in patients with severe acute respiratory distress syndrome (ARDS) secondary to pneumonia due to the novel influenza A (H1N1), and compare it with the results obtained in patients with other ARDS causes. METHODS. Prospective interventional study in a mixed medical-surgical ICU in a tertiary care university Hospital. Consecutive patients with severe ARDS, previously unresponsive to positive end-expiratory pressure (PEEP) adjustment, were treated with extended PPV for 48 h or until the oxygenation index (OI) was \ 10. If this therapy was insufficient, extracorporeal membrane oxygenation (ECMO) was early implemented according our ARDS protocol. We measured changes in oxygenation parameters before PPV, every 6 h during PPV, and 2 and 12 h after. The effects of PPV in this population were compared with the obtained in other ARDS causes. RESULTS. 10 patients with severe ARDS (age 42 ± 12 years, 3 females, APACHE II 16 ± 6, SOFA 8 ± 3) receiving volume-controlled ventilation (tidal volumes of 6 ml/kg of predicted body weight) required PPV. The time between onset of mechanical ventilation and PPV was 26 ± 27 h. The first time on PPV was 82 ± 49 straight hours (three patients required two periods on PPV). None of the patients experienced life-threatening complications or hemodynamic instability during the procedure, four patients developed grade II pressure ulcers and one patient grade III. The patients showed a statistically significant improvement in PaO 2 /FiO 2 (79 ± 23 vs. 249 ± 67, p \ 0.0001) and OI (28 ± 12 vs. 8 ± 2, p \ 0.0001) and reduction of PaCO 2 (45 ± 16 vs. 39 ± 6, p \ 0.0001) with PPV, and did not worse upon returning to the supine position. Two patients were subjected to ECMO, one of them did not recieive PPV and the other only did for 2 h. In-hospital mortality was 30%, and remained without changes at 6 months followup. This behavior did not differ with the obtained for our team in other ARDS populations. The results obtained suggest that extended PPV as rescue therapy might be useful in refractory hypoxemic patients with severe ARDS secondary to the novel A (H1N1) influenza. This approach improved oxygenation parameters. Moreover, it is feasible and relatively safe, when it is carried out by a trained staff and within an established protocol. Although the limited number of patients does not allow major conclusions to be drawn, we believe that this strategy could be used to face severe cases of A (H1N1) influenza. INTRODUCTION. Functional hemodynamic variables (pulse pressure variation-PPV; stroke volume variation-SVV; systolic pressure variation-SPV) have been constantly used to evaluate hemodynamic status and fluid responsiveness in the ICU. However, during conditions into which respiratory system compliance may vary, such as Acute Lung Injury (ALI), the role of these parameters to evidence fluid responsiveness is less understood. In addition, the use of a protective ventilation strategy which includes increased PEEP levels and low tidal volume (VT) during ALI may theoretically influence the measurement of these variables. OBJECTIVES. In this study, our purpose was to evaluate the effects of different ventilatory strategies on static and functional hemodynamic parameters in pigs with ALI during normovolemia and hypovolemia. INTRODUCTION. Levosimendan provides a new axis for inotropy and lusitropy through calcium sensitisation without increasing myocardial oxygen demand. It provides an alternative to other inotropic agents that have been associated with adverse outcomes. Despite evidence of sustained improvement in cardiac index and decreased filling pressures, concern remains with regard to mortality benefit [1] , excess hypotension, vasopressor requirements and tachycardia with levosimendan administered as an infusion following a loading dose [2] . To review the effect of using levosimendan given with no bolus dose in patients with acute heart failure. We reviewed the electronic notes of patients who had received levosimendan for acute heart failure over an 18 month period (July 2008-December 2009) in our tertiary referral ICU seeing 1,200 patients per year. Demographics and mortality data were collected for each patient. Doses of inotropes and vasopressors and haemodynamic parameters were all recorded for the duration of the infusion as well as the 24 h before and after. Data analysis was carried out using Excel 2007 (Microsoft Corp). RESULTS. 86 patients who received levosimendan for acute heart failure (acutely decompensated chronic heart failure (n = 16), post cardiac surgery (n = 35) or following acute myocardial infarction (n = 36)). All patients received a continuous infusion for 24 h at a rate of 0.10 lg/kg/min and none received a loading dose. Mean age was 70, mean ICU length of stay was 22 days, ICU mortality was 43% and in-hospital mortality was 51%. Haemodynamic data is recorded in Table 1 .  Patients receiving levosimendan had a lower mortality (51%) than the over 60% expected for patients with severe acute heart failure and an unchanging SOFA score. Omitting a loading dose has avoided the significant problems of hypotension and tachycardia which have been reported previously [2] . Infusion of levosimendan over 24 h produced a sustained improvement in cardiac index as well as surrogate markers of tissue perfusion. We were able to rapidly wean the doses of other inotropes, especially dobutamine whose dose reduction was significant and sustained. Thus levosimendan may allow for the earlier introduction of cardiovascular therapies such as beta-blockade in this group of patients. INTRODUCTION. Due to hypovolaemia and anaemia ScvO 2 \ 70% may reflect imbalance of oxygen delivery (DO 2 ) and consumption (VO 2 ) [1] . In current guidelines the transfusion trigger is haemoglobin (Hb) less than 70 g/l, but there is no recommendation for ScvO 2 [2] . OBJECTIVES. The aim of this study was to investigate the value of ScvO 2 in indicating oxygen debt in normovolaemic anaemia. After splenectomy mini-pigs (n = 10, weight range: 18-30 kg) were bled (* 10% of estimated blood volume/5 min, T 0 -T 5 ) and blood loss was replaced by the same volume of colloid, after which haemodynamic measurements and blood gas analysis were performed. Data are presented as median [interquartile range], and analysed by Friedman test and Pearson correlation.  There is presently an expanding literature and research interest in outcomerelated desirable cardiovascular waypoints/endpoints for high-risk peri-and postoperative patients. Attainment of optimal pressure, blood and oxygen flow goals requires therapeutic manipulation of intravascular volume, resistance and heart performance. Consideration of the Guytonian determinants of venous return enables the creation of simple mathematical transforms of standard dynamic variables(MAP, CO, RAP) into volume (Pms), resistance (SVR) and heart performance (Eh = (Pms -RAP)/Pms) ''states'' where Pms is the mean systemic filling pressure. Graphical depiction of the patient's position in relation to clinician-determined pressure and flow targets within a ''state'' diagram allows continuous appreciation of the next therapeutic course to target. OBJECTIVE. To evaluate the graphical volume, resistance and heart performance guidance of the Navigator TM cardiovascular decision support system in high risk perioperative patients undergoing major surgery. METHODS. Continuous sampling from patients undergoing high-risk surgical procedures of cardiac output (CO), mean arterial pressure (MAP) and central venous pressure (CVP) were processed by the Navigator TM and displayed as result of heart efficiency, vasomotor tone and volume state. These three parameters are amenable to intervention to reach physician set targets of CO (or DO 2 I) and MAP. A clinical example of pharmacological intervention is demonstrated in terms of the cardiovascular parameters. Heart rate (HR) and blood pressure (BP) variability is lowered by sedation and is almost absent in brain death patient. Respiratory frequency (RF) may also impact on HR and BP variability in spontaneously breathing subjects [1] . OBJECTIVES. We hypothesised that different respiratory frequencies and level of sedation influence HR and BP variability during mandatory mechanical ventilation (MV). Seven severely ill ICU patients and 8 brain death patients on mechanical ventilation were studied. Invasive arterial BP, ECG, airway pressure (Pao), flow and oesophageal pressure (Pes) were continuously recorded and evaluated by acquisition system (ISI Brno, CR). During study RF was changed in 5 min intervals and inspiratory pressure was adjusted to maintain end tidal CO 2 stable. Protocol was done on two predefined sedation levels controlled by bispectral index (BIS). BP and HR variability are given as standard deviations (SD) of systolic arterial pressure (BPSD) and RR intervals on ECG (RRSD) at each RF. Variability parameters were further adjusted to tidal volume (TV), Pes and Pao changes (e.g. BPSD/TV, BPSD/Pes and BPSD/Pao, respectively).Analysis was done by software Scopewin (ISI Brno, CR) and data are presented as median (IQR). Nonparametric statistics was used as appropriate. After adjustment on respiratory parameters only BP variability remained higher at lower RF-i.e. BPSD/TV 6.0 (4. CONCLUSIONS. Blood pressure and heart rate variability in ICU patients on mechanical ventilation are low and depend on level of sedation. Blood pressure variability is higher at lower respiratory rate frequencies.  Post cardiac surgical patients (n = 10) who had undergone a variety of procedures (4 CABG, 3 valve replacements, 3 combined operations), were ventilated for more than 7 days after their procedure and met the criteria for Levosimendan were included. Nine (90%) were successfully weaned from invasive ventilation and discharged from critical care. Eight (80%) survived until hospital discharge and for at least 6 months thereafter. Levosimendan has an established role in patients with acute decompensated systolic cardiac failure [1] and its use as an adjunct for weaning from invasive ventilation has been described in non-surgical patients with cardiac dysfunction [2] . Our experience suggests that patients failing to wean from invasive ventilation after cardiac surgery due to cardiac dysfunction may benefit from the adjunctive use of Levosimendan. Additionally most studies to date have no longer term outcome data, in this series we have demonstrated survival at 6 months in a patient population whose predicted survival is poor [3] .  Levosimendan is a calcium sensitizing agent developed for the treatment of congestive heart failure. It increases myocardial contractility, reduces the filling pressure and dilates both the peripheral and coronary vessels. OBJECTIVES. To investigate the haemodynamic influence of levosimendan in cardiac surgery patients. METHODS. Retrospective analysis. Levosimendan was administered to patients with suspected postcardiac surgery myocardial failure (left ventricular ejection fraction of \ 40% before start of infusion). Levosimendan was administered as a single-dose infusion of 0.05 or 0.1 lg/kg/min for 24 h starting peroperative or immediate after arrival at the intensive care. MAP was measured at baseline (t = 0), t = 1, 2, 6, 12, 24 and 48 h. RESULTS. 14 male, 10 female; mean age was 68 years, median apache 4 score at admission was 80; mean BMI was 26. Three patients died within 48 h postoperatively. Extracorporal circulation: median 143 min; aortic cross clamp: median 105 min. Surgical procedures : 9 CABG, 3 AVR, 12 combined procedures (AVR, MAZE, TVP, MVP/R, ASD, Bentall). Mean MAP is shown in Fig. 1 . MAP increased after infusion and reached significance after 24 h of administration. Infusion of other inotropics remained stable. CONCLUSIONS. Levosimendan seems to be an effective inotropic in post cardiac surgery patients with suspected myocardial failure. It's effect on MAP is significant at 24 and 48 h after administration. Further prospective analysis in this particular patient group is needed. OBJECTIVES. The aim of this ongoing prospective study is to investigate whether the dynamics of ScvO 2 and lactate as well as the ratio of lactate to ScvO 2 in the first 48 h of patient admission give more insight regarding mortality in the ICU population. Patients admitted to a medical ICU of a university hospital, in whom a central venous catheter is considered necessary and placed within the first 4 h of admission, were included. Exclusion criteria were age under 18 years, pregnancy and referral from another ICU. Mean arterial pressure (MAP), central venous pressure (CVP), central venous blood gas analysis and plasma lactate were recorded on study admission, as well as after 6, 12, 24 and 48 h. APACHE-II and SOFA scores as well as volume and vasopressor treatment were also recorded. Lactate clearance was calculated for the whole group as well as only for those patients with a plasma lactate of [ 4 mmol/l on study admission. Patients are managed according the standard procedure of the ICU based on international guidelines. The data are analysed regarding their influence on ICU mortality. The data from the first 89 patients with a mean age of 65.8 ± 15.7 years are presented here, of whom 63 patients survived and 26 patients died in the ICU. APACHE-II score was 21.3 ± 5.6 in survivors and 26.8 ± 6.5 in non-survivors (p = 0.001). Plasma lactate on study admission and after 6 h correlated with ICU mortality (p = 0.002). ScvO 2 on admission was lower in survivors than in non-survivors (64.6 ± 13.9 vs. 72.7 ± 18.4%, p = 0.025). There was no correlation between ScvO 2 and survival at any time point. Lactate clearance calculated for the whole study population did not reveal any correlation with ICU mortality. However, lactate clearance at 6 and 12 h in patients with an initial lactate of [ 4 mmol/l did correlate with survival. The ratio between plasma lactate and ScvO 2 on admission and after 6 and 12 h showed a significant correlation with ICU mortality. CONCLUSIONS. Plasma lactate has a prognostic significance in the management of critically ill patients. However, the role of ScvO 2 seems doubtful. The ratio between plasma lactate and ScvO 2 may be a useful marker of systemic perfusion and prognosis. Further investigation in a large patient population is yet necessary. INTRODUCTION. The concept of goal-directed hemodynamic therapy should be the basis of hemodynamic intervention in intensive care medicine. In the last decade parameters such as stroke volume variation (SVV), centralvenous oxygenation (ScvO 2 ), cardiac index (CI) and mean arterial pressure (MAP) have been used increasingly to monitor adequate hemodynamic treatment. However, it still remains challenging to identify patients with assumed adequate circulatory status quantified by the parameters above that suffer from microcirculatory hypoperfusion. The centralvenous-arterial pCO 2 -difference (dCO 2 ) could serve as a new parameter to evaluate the adequacy of microcirculatory perfusion [1, 2] . OBJECTIVES. The aim of the study was to evaluate the impact of dCO 2 on outcome in cardiac surgery patients based on clinical parameters and ICU scores. After approval by the local ethics committee 60 patients were included in this study. The dCO 2 was measured after cardiac surgery on arrival to intensive care unit (ICU), and at the time points 1 h ICU, 6 h ICU and 18 h ICU. dCO 2 was compared with ICU-related outcome parameters. According to the first measurement on the ICU patients were divided into two groups, the high-dCO 2 -group (C 10 mmHg) and the low-dCO 2 -group (\ 10 mmHg) 3 . Data are represented as median (25th percentile-75th percentile). Statistical analysis was performed by the Mann-Whitney-U Test and receiver operating characteristics analysis. RESULTS. Based on the postoperative measurement, 11 patients were assigned to the high-dCO 2 -group. There were no differences between the basic characteristics (Age, BMI, duration of surgery, clamping time) in the two groups. The SOFA-and the SAPS-score showed comparable values at the admission to the ICU whereas on the first postoperative day there was a significant increase of the SOFA-(8; 7-9 vs. 5; 3-7; p = 0.04) and the SAPS-score (42; 36-44 vs. 24; 18-31; p = 0.03) in the high-dCO 2 -group compared to the low-dCO 2 -group. There was no difference in hemodynamic parameters (MAP, CI, SVV, ScvO 2 ) between the two groups. ScvO 2 was significantly higher in the high-dCO 2 -group 18 h after ICU-admission (74.6%; 71.5-76.7 vs. 67.0%; 62.7-70.5; p \ 0.01). In the high-dCO 2 group a significantly prolonged need for mechanical ventilation was observed (12 h; 10-29; vs. 10 h; 8-12; p = 0.03). The dCO 2 on admission to ICU was predictive for prolonged mechanical ventilation (AUC ROC 0.72; p = 0.03). CONCLUSIONS. This is the first study describing dCO 2 as a measure of compromised microcirculation in cardiac surgical patients. Patients with a high gradient despite having higher ScvO 2 values were significantly longer on mechanical ventilation and had significantly higher SOFA-and SAPS-scores on the first postoperative day. This might be a hint to a reduced oxygen extraction rate in these patients due to microcirculatory shunting. [1, 2] . Conversely, studies have shown a protective preconditioning effect of TLR-ligands when applied before myocardial ischemia [3] . OBJECTIVES. We hypothesized that the TLR9 ligand CpG-ODN has a postconditioning effect in a murine model of myocardial ischemia and reperfusion mediated by a differential expression of myocardial cytokines. METHODS. C57BL/6 mice (12 weeks, male) underwent thoracotomy for chronic instrumentation of the LAD. Following a 5 day interval, mice were reanesthetized for a 30 min ischemia followed by 120 min of reperfusion. PBS-Group received 250 ll PBS, CpG-Group received 5 nmol CpG-ODN (Thioat 1668), each 5 min before onset of reperfusion. Ischemic postconditioning (IPC)-Group received three repetitive cycles of each 20 s reperfusion and occlusion with beginning of reperfusion. Treatment was blinded. Infarct size was determined with triphenyltetrazolium (TTC) staining. Planimetry was performed blinded. Myocardial RNA expression of TNF, IL-1b, IL-6 and IL-10 was assessed. RESULTS. Infarct size was significantly higher in PBS-group (n = 15; 17.15 ± 3.47% of area at risk) compared with CpG-ODN-group (n = 7; 1.921 ± 1.12%) and IPC-group (n = 6; 1.98 ± 1.03%, p \ 0.05), respectively. There was a robust increase of TNF and IL-10 RNAexpression in the CpG-Group compared to all other groups (TNF .47 RQ, n = 6-9, p \ 0.05). However, a differential expression pattern for IL-1b and IL-6 in PBS and IPC-groups was observed. IL-1b RNA-expression was significantly higher in CpG-group (13.85 ± 2.11 RQ) compared to IPC-group (6.48 ± 2.41 RQ) but not when compared to PBS-group (9.9 ± 2.9 RQ, n = 6-9, p \ 0.05). IL-6 RNA expression was significantly higher in IPC-group (568.0 ± 98.91 RQ) and CpG-group (606.8 ± 49.49 RQ) when compared to PBS-group (335.4 ± 50.0 RQ, n = 6-9, p \ 0.05). CONCLUSIONS. Our data support the hypothesis that the TLR9 ligand CpG-ODN mediates a cardioprotective postconditioning effect after myocardial infarction and reperfusion. Expression of proinflammatory TNF and antiinflammatory IL-10 may initiate mechanisms of protection which needs further investigation. IL-6 expression seems to play a role in ischemic postconditioning. The OBJECTIVES. To evaluate LV hemodynamics during MIP-study by using echocardiographic monitoring. We prospectively studied 10 consecutive ICU patients, hemodynamically stable, who fulfilled previously accepted criteria for a 30-min-SBT through T-tube. MIP was measured as previously suggested [1] . Echocardiography (TTE) was performed before, during and after the MIP trial. Transmitral early diastolic velocity (E)/Tissue Doppler Imaging-derived early diastolic velocity (E 0 ) at the lateral border of the mitral annulus (E/E 0 ratio) was used as a surrogate of LV filling pressures during the procedure [2] . OBJECTIVES. To evaluate the ability of a new fluid responsiveness index (FRI) to dynamically predict the response to volume expansion during assisted and spontaenous modes of ventilation. METHODS. The FRI is based on the fast Fourier transformation and spectral analysis of CVP and AP waveforms to independently determine the influence of respiration and cardiac activity on the changes in the arterial blood pressure waveform. In 17 pigs (weight 22-57 kg) we compared three different volemic conditions: hypovolemia (blood withdrawal), normovolemia (blood reinfusion) and hypervolemia (6% hydroxyl-ethyl starch-HES infusion). At each condition fluid resposiveness was assessed during three randomly applied ventilatory modes: 1)controlled ventilation (CMV) using volume controlled ventilation Vt 6 mL kg, PEEP 5 cmH 2 O, RR adjusted to a normal EtCO 2 , 2)assisted ventilation (AMV) in assisted/controlled pressure controlled ventilation with similar settings but maintaining the animal respiratory drive and 3)spontaneous breathing(SB) CPAP of 5 cmH 2 O. At each condition we evaluated the ability of FRI to predict changes in stroke volume in response to fluid administration and compared it with PPV and SVV. At baseline all animals were in a stable hemodynamic condition with normal preload values. To induce hV blood an average (± 2 SD) of 17 ± 24 mL/kg of blood was withdrawn, whereas to induce hypervolemia a mean of 45 ± 24 ml/kg 6% HES was infused. FRI showed a high correlation and good correspondence with the measured changes in stroke volume at the different preload conditions and all ventilatory modes (r 2 = 0.851, bias = -0.49%, 2 SD = 24.47% in CMV; r 2 = 0.872, bias = 3.22, 2SD = 21.57% in AMV; and r 2 = 0.854, bias = -1.96%, 2 SD = 21.29 in SB). FRI \ 80% predicted an increase more than 10% in cardiac output after fluid administration in CMV (ROC 0.92), AMB (ROC 0.84) and SB (ROC 0.85). PPV and SVV performed as good as FRI during CMV but showed a poor correlation during AMV and SB. CONCLUSIONS. The fluid responsiveness index performed as good as pulse pressure and stroke volume variations during controlled mechanical ventilation. During assisted and spontaneous modes of ventilation FRI levels below 80% could reliable predict clinical significant increases in stroke volume in response to volume administration. GRANT ACKNOWLEDGMENT. Pulsion Medical System. INTRODUCTION. Septic shock is a life-threatening illness. The commonest presentation is cardiovascular instability because the underlying illness has advanced to shock.Among all natriuretic peptides, currently Brain Natriuretic Peptide (BNP) is the most promising candidate for predicting myocardial dysfunction in septic patients, as it is of ventricular origin and its release is related to ventricular wall stretch and volume overload. OBJECTIVES. This study was to assess myocardial dysfunction in sepsis and analyze the elevations of BNP and cardiac Troponin I (cTn-I) in patients with sepsis, severe sepsis and septic shock and evaluate their relationships with echocardiographic data and the impact on outcome . METHODS. 43 patients (pts) having various degrees of sepsis admitted to Critical Care Department at Cairo University from October 2007 to February 2009 were recruited in the study, in addition to ten healthy volunteers served as a control group for BNP, cTn-I levels and echocardiographic parameters. All pts were subjected to APACHE II, SOFA score O/A and day 2, echocardiography O/A, as well as BNP and cTn-I sampling O/A, and day 2. The studied pts were divided into group I with sepsis (23pts, 12 males; mean age 46.7 ± 21 year) and group II with severe sepsis and septic shock (20 pts, 11 males; mean age 54.6 ± 17 year). RESULTS. BNP level O/A was significantly higher in group I and group II than control (p = 0.048); BNP level on day 2 was significantly higher in group II than group I (p = 0.004). cTn-I in day 2 was higher in group II than control (p \ 0.001). BNP and cTn-I were correlated positively with APACHE-II, MODS, SOFA (O/A and day2). cTnI O/A was found negatively correlated to LVEF (r = -0.348; p = 0.022 and r = -0.334; p = 0.029, respectively), whereas Neither BNP O/A nor at day 2 in the study group was correlated to LV diameters, volumes, LVEF,CO& CI. BNP was highly correlated to cTnI at day 2 (p = 0.044). BNP O/A and day 2 as well as cTnI were higher in non-survivors than survivors but with no statistical significant differences (p [ 0.05). BNP measurements should be interpreted with great caution in the critically ill. We can conclude that BNP and cTn-I cannot be used as a diagnostic marker of myocardial dysfunction nor a prognostic marker in patients with severe sepsis or septic shock. CONCLUSIONS. BNP measurements should be interpreted with great caution in the critically ill. We can conclude that BNP and cTn-I cannot be used as a diagnostic marker of myocardial dysfunction nor a prognostic marker in patients with severe sepsis or septic shock. REFERENCE(S OBJECTIVES. Two techniques were used to explore myocardial function: the conductance catheter (the reference method for intraventricular measurement), and PET (Positron Emission Tomography), a new technology for cardiac exploration. The aims of the study were: • To describe the cardiovascular effects of vasopressors • To compare information provided by both methods on vascular and cardiac functions In the present study, we used a rat model of septic shock with caecal ligation and puncture (CLP). Eighteen hours after surgery, male Wistar rats were randomized in 5 groups. Animals from Group 1, 2, 3 received 5 mL of 0.9% NaCl for 10 min, followed by a continuous infusion of catecholamines (norepinephrine, epinephrine or phenylephrine) in order to increase mean arterial pressure by 20% compared to baseline value. Sham animals (laparotomy without CLP) and CLP animals were included in group 4 and 5, respectively. Rats in group 4 and 5 received no treatment. Results revealed an impairment of cardiac function in septic rats, irrespective of the explorative method used, with alterations in both systolic and diastolic functions. Emax and PRSW, two load independent measures of systolic function, were markedly lower in septic animals than in sham animals (-35%). Cardiac output and left ventricular ejection fraction were reduced in CLP rats by 29 and 36%, respectively. End diastolic ventricular pressure was increased by 42% in septic rats. End diastolic volume and heart rate were comparable in the five groups. No morphological abnormalities or ischemic lesions were observed in PET imaging. Both norepinephrine and epinephrine showed beneficial effects on systolic and vascular functions whereas phenylephrine infusion was deleterious. All measures of systolic function reached baseline values of sham rats with norepinephrine and epinephrine. This improvement in cardiovascular function was accompanied by a significant rise in myocardial oxygen consumption, especially under epinephrine treatment. Both explorative techniques were complementary: PET imaging allowed the examination of cardiac morphology which complemented functional measurements derived from the conductance catheter study. CONCLUSIONS. In our hypodynamic septic shock model in rats norepinephrine and epinephrine display comparable effects with regard to cardiovascular function, albeit at the expense of an increase in myocardial oxygen consumption which was more pronounced with epinephrine. INTRODUCTION. Microcirculatory abnormalities may not be predicted by hemodynamic or perfusion parameters during septic shock. Recent research has evaluated potential therapies but has not addressed a fundamental problem: in whom is it worth to perform a microcirculatory assessment? In fact, the place of microcirculatory monitoring has not been established, nor a specific subpopulation with higher probability of presenting severe derangements has been identified. Our aim was to evaluate potential risk factors associated with the finding of severe microcirculatory flow abnormalities. We performed a retrospective analysis of a prospective database including 56 microcirculatory assessments in 35 septic shock patients. Under our current septic shock management protocol ( On the other hand, peripheral perfusion can be severely compromised in this setting, which has been correlated with hyperlactatemia and organ dysfunctions. However, no study has addressed the temporal profile of changes in peripheral perfusion during severe sepsis. Our aim was to evaluate the dynamics of recovery of metabolic and peripheral perfusion parameters during severe sepsis resuscitation. We included hypotensive septic patients undergoing fluid resuscitation or requiring vasopressors after ICU admission. Several perfusion parameters including lactate, ScvO 2 , venous-arterial pCO 2 gradient (D v-a pCO 2 ), capillary refill time (CRT) and central versus toe temp gradient (D t°C-T), were assessed at baseline and then at 2, 6 and 24 h of resuscitation. All patients were managed with a common protocol including additional fluid challenges, norepinephrine (NE), mechanical ventilation (MV) or dobutamine according to specific indications. The percentage of patients with normal values for every parameter at each time-point was assessed. Changes along time were analyzed by Fisher exact test. We enrolled 25 patients (mean age 61.4; SOFA 9, APACHE 18, NE 68%, MV 52%, ICU mortality 20%), of whom 24 survived the study period. More than 50% of patients exhibited abnormal values for each parameter at baseline. Although all parameters tended to normalize at 24 h, only CRT exhibited significant changes at 6 h ( Fig. 1 ). CONCLUSIONS. Both peripheral and metabolic perfusion parameters exhibited a similar recovery trend in successfully resuscitated septic patients, but CRT normalized earlier than the other parameters. Future studies should address the role of dynamic peripheral perfusion assessment in severe sepsis. INTRODUCTION. Although microcirculatory alterations are frequently being described in patients admitted to the ICU with severe sepsis and septic, the severity of these alterations seems to vary between several studies. The main purpose of our study was to establish the severity and time course of microcirculatory alterations in patients with severe sepsis and septic shock in our ICU and investigate whether the severity could differentiate between survivors and non survivors. Patients admitted with severe sepsis and septic shock were eligible for enrollment. Within 24 h of admittance and every other day clinical and hemodynamic measurements were made, until discharge or death. Additionally sublingual and skin microcirculatory perfusion was measured using sidestream dark field imaging, peripheral flow index and forearm-to-fingertip skin-temperature difference. Data of 30 patients admitted with severe sepsis or septic shock were collected. Of these patients 19 survived and 11 died. The non survivors had a significantly higher APACHE II and SOFA score than the survivors. Additionally at baseline mean arterial pressure was lower in the non survivors group and lactate concentrations were higher compared to survivors. At baseline both groups had a high microcirculatory flow index, proportion of perfused vessels and vessel density, which did not differ between the survivors and non survivors ( Fig. 1 shows the parameters of sublingual microcirculatory perfusion over time). Over time the microcirculatory parameters did not change in the survivors nor in the non survivors. CONCLUSIONS. In our study microcirculatory parameters exhibited a hyperdynamic profile after the initial resuscitation phase but within 24 h of admittance. This was less clear for the parameters of skin microcirculatory perfusion. It was not possible to differentiate between survivors and non survivors based on parameters of sublingual or skin microcirculatory perfusion. RESULTS. Three groups of patients were identified when decreasing MAP: Group 1 (N = 17, 53%) showed patients who decreased their recovery slope by more than 20%, in Group 2 (N = 10, 31%) the recovery slopes were not modified (± 20%), and in Group 3 (N = 5, 16%) the recovery slopes increased by more than 20%. Intra-group comparison for StO 2 at baseline was equivalent at the different levels of MAP. In group 1, CI decreased with the recovery slope. In group 2 and group 3 there was no significant change of CI. The oxygenation parameters were not statistically different in each group. Results are presented in the following table. Groupe 1 (n = 17) Groupe 2 (n = 10) Groupe 3 (n = 5) OBJECTIVES. We hypothesized that the persistence of microvascular dysfunction as assessed by sublingual capnometry and NIRS would be associated with a worse outcome in patients with severe sepsis. All patients admitted to the ICU with early severe sepsis were included in the study. Central venous oxygen saturation (ScvO 2 ), sublingual PCO 2 (PslCO 2 ) and NIRS-derived variables were simultaneously measured at admission and after 6 h of resuscitation. PslCO 2 was measured using a microelectrode CO 2 sensor (PslCO 2 monitor sensor; Exostat Medical Inc, USA). PslCO 2 gap was calculated as the difference between PslCO 2 and arterial PCO 2 . Thenar muscle oxygen saturation (StO 2 ) was measured using a tissue spectrometer (InSpectra TM Model 650, Hutchinson Technology Inc, USA) during a vaso-occlusive test (upper limb ischemia induced by rapid pneumatic cuff inflation around the upper arm). The following NIRS-derived variables were recorded: ''steady-state'' StO 2 (StO 2 ) and the StO 2 reperfusion rate following the ischemic period (reperf rate; %/s). The predictive values for outcome (ICU death) of the variables measured at 6 h were calculated from ROC curves, and the areas under the curve (AUC) were computed. We studied 50 patients (APACHE score: 23 ± 7), with a 36% mortality rate. The changes in ScvO 2 and StO 2 over the 6 h period were similar in survivors (S) and non-survivors (NS), but the changes in reperf rate and PslCO 2 gap were significantly different: the reperf rate increased in S but not in NS and the PslCO 2 gap decreased in S but not in NS ( OBJECTIVES. To evaluate the microcirculatory effects of enalaprilat in an experimental model of severe sepsis. METHODS. Prospective, randomized, double-blind, placebo controlled study including 16 adult female anesthetized, mechanically ventilated sheep. One hour after injection of 1.5 g/kg body weight of feces into the abdominal cavity, animals were randomized to receive either enalaprilat 2.5 mg or saline. A combination of Ringer's lactate (RL) and hydroxyethyl starch solutions was titrated to prevent hypovolemia. When fluid-resistant hypotension (MAP \ 65 mmHg) developed, the animals were given norepinephrine up to a maximal dose of 3 lg/kg/min. The sublingual microcirculation was evaluated using sidestream dark-field videomicroscopy (Microscan, MicroVision Medical) at baseline (just before feces injection), before drug administration, before norepinephrine infusion (shock), and after the 1st and 2nd hour of norepinephrine infusion. Capillary density, proportion of perfused vessels, and microvascular flow index (MFI) were calculated. A cut-off of 20 lm was used to differentiate small and large vessels. Experiments were pursued until the sheep's spontaneous death or a maximum of 30 h. Results are presented as mean ± SE. RESULTS. There were progressive and significant reductions in the proportion of small perfused vessels (p = 0.006 for trend) and in the MFI (p = 0.003 for trend) during shock and the first 2 h of norepinephrine infusion in the placebo group, which were prevented by the administration of enalaprilat (p = 0.83 and p = 0.85 for trend in the proportion of small perfused vessels and MFI, respectively) ( Fig. 1 ). There were no differences between treated and placebo groups in global hemodynamic variables, time to shock (18.1 ± 2.4 h vs. 17.6 ± 2.1 h, p = 1.0) or median survival time (23 ± 1.7 vs. 24 ± 1.9 h, p = 0.49). However creatinine concentrations increased more in the treated group (from 0.60 ± 0.09 to 1.15 ± 0.19, p = 0.04) than in the control group (from 0.62 ± 0.10 to 1.01 ± 0.23, p = 0.12). CONCLUSIONS. Enalaprilat prevented the worsening of microcirculatory variables in this fluid-resuscitated, hyperdynamic model of septic shock without significant effect on arterial pressure, but possibly associated with an earlier impairment of renal function. OBJECTIVES. In this prospective study we evaluated serial echocardiography-based indices of myocardial function and markers of vascular inflammation and endothelial dysfunction in the early phases of severe sepsis. Adult patients admitted to the Intensive Care Unit with up to 24 h after fulfilling criteria for severe sepsis or septic shock were studied. Patients with history of heart failure were excluded. Clinical, laboratory (endothelin-1[ET1], vascular cellular adhesion molecule 1 [sVCAM-1] by ELISA) and echocardiographic data were collected at 24 h, 72 h and 7 days after admission. Flow-mediated vasodilation (FMD) of the brachial artery was measured using a highfrequency linear transducer (7.5-10 MHz) according to internationally accepted protocols. We studied 45 patients (67% females; age = 51 ± 18 years) with an APACHE score of 23 ± 7 and intra-hospital mortality of 35% (16 deaths). Left ventricular dysfunction (LVD: LF ejection fraction less than 55%) was identified in 15(33%) patients while right ventricular dysfunction (RVD: peak systolic velocity of RV tissue Doppler imaging \ 12 cm/ seg) was present in 14(30%) patients. LogET1 was significantly increased in patients with LVD (2.3 ± 0.6 vs. 1.8 ± 0.4; p = 0.01) and RVD (2.5 ± 0.5 vs. 1.8 ± 0.4; p \ 0.001). FMD and sVCAM-1 values were similar in patients with or without LVD and RVD. We observed a significant negative correlation between LogET1 and LV ejection fraction (r = -0.50; p = 0.002), peak systolic RV tissue Doppler imaging (r = -0.67;p \ 0.001) and FMD (r = -0.40; p = 0.02). CONCLUSIONS. Myocardial dystunction is a prevalent and early phenomenon in sepsis, being directly associated to markers of endothelial dysfunction. INTRODUCTION. Septic shock is characterized by macro and microcirculatory derangements. The latter can be approached by the use of Near Infrared Spectroscopy (NIRS), which allows measuring the tissular oxygen saturation (StO 2 ). During a vascular occlusion test (VOT), the evolution of the StO 2 would reflect the reactive hyperemia. Recently, it has been shown that the StO 2 recovery slope may have a prognostic value in septic patients. However, this value may depend on the model of NIRS probe and the way to perform the VOT. The goal of our study was to confirm the prognostic value of the StO 2 recovery slope with the currently commercialised NIRS probe. We enrolled patients who have been admitted for septic shock since less than 24 h and once that they have been resuscitated (fluid, norepinephrine) with the goal to correct hypovolemia and to achieve a mean arterial pressure (MAP) [ 65 mmHg. In each subject, we performed a VOT using the InSpectra StO 2 650 monitor (Hutchinson, MN). A brachial pneumatic cuff was inflated to 220 mmHg once the StO 2 was stabilised. it. Brachial occlusion was maintained until StO 2 reached 40%; then the pneumatic cuff was rapidly deflated. NIRS data were calculated off-line by InSpectra Analysis Program V4.00. We included 94 patients (63 ± 13 years). The SAPS 2 was 55 ± 17; MAP was 77 ± 8 mmHg and mortality was 40%. The tables present the data in the subgroup of patients who will survive compared to patients who will die.  Systemic haemodynamic variables after resuscitation did not differ between survivors and nonsurvivors. Among NIRS data, only the StO 2 recovery slope was different between these 2 populations. CONCLUSIONS. Our study confirms that StO 2 recovery slope is the only NIRS parameter that has a prognostic value in patients with septic shock studied after the initial resuscitation. INTRODUCTION. Septic shock is characterized by an impaired tissue perfusion associated with microcirculatory alterations. The evaluation of systemic hemodynamic variables can be insufficient to appreciate this, and the optimal level of arterial pressure is hard to define. Sidestream dark field (SDF-Microscan, Microvision Medical, Amsterdam, The Netherlands) can be used to evaluate the microcirculation state. OBJECTIVES. The aim of this trial was to evaluate the effect of increasing mean arterial pressure by norepinephrine on the sub-lingual microcirculation using SDF. After Local Ethical Committee approval and informed consent, we studied 6 patients with septic shock for less than 48 h. All patients required a NE infusion for arterial hypotension resistant to fluid therapy, and were monitored with a pulmonary artery catheter. We measured hemodynamic variables, cardiac output, mixed venous oxygen saturation (SvO 2 ), and blood lactate concentration, together with the evaluation of the sub-lingual microcirculation with SDF (Microscan, Microvision Medical, Amsterdam, The Netherlands). Five sets of data were obtained: two at baseline with a MAP of 65 mmHg, once after increasing MAP to 75 and 85 mmHg by increasing the NE dose, and finally with MAP back to baseline. We obtained 20 s video clips of 5 different sites by a device with a 9 5 objective lens. The data were analyzed blindly and randomly. We based our data analysis on previously established criteria of microcirculatory perfusion [1] . We separated the vessels in small and large with a cut-off for the diameter of 20 lm. We determined two perfusion indexes, the microvascular flow index (MFI) and the vessel density. We reported the data corresponding to the mean and SD of the first two baseline measures versus MAP 85 mmHg analyzed by repeated measures analysis of variance (at 5% level) with Bonferroni adjustment to account for multiple comparisons. RESULTS. Cardiac output increased from 6.1 (5.4-6.8) to 6.7 (5.9-7.6) l/min (p \ 0.05), without significant changes in heart rate. Systemic vascular resistance also increased. INTRODUCTION. Invasive infections are common in intensive care units and mortality from severe sepsis in the critical care setting ranges from 28-50%. Inappropriate use of antibiotics can result in the development of antibiotic resistance among bactaraemic pathogens. It is also well known that resistance among pathogens is increasing internationally. Our objective was to establish if there was a difference between the bacteria cultured and the resistance patterns of these bacteria in a South African (SA) (700 admissions per year) and a British (UK) (650 admissions per year) ICU. We explored whether any differences could be explained in terms of antibiotic prescribing practices. A 6 month retrospective study was carried out in the SA unit from February to August 2008 and then in the UK ICU from February to August 2009. A record was made of all positive bacterial cultures in these periods including screening samples. The specturm of antibiotic resistance that existed for these positive cultures was recorded. The SA ICU did not have regular clinical microbiology input, with no definitive screening programme, but the UK had both of these. RESULTS. There were 288 and 198 positive cultures in the SA and UK samples, respectively. The most prevelant organisms seen in the South African ICU were Klebsiella pneumonia (n = 34), Escherichia coli (n = 28), Acinetobacter baumannii (n = 22) and Klebsiella spp (n = 18). In the UK Coliforms (n = 39), mixed coagulase negative Staphylococcus (n = 32), coagulase negative Staphylococcus (n = 30) and Staphylococcus aureus (n = 17) were the most prevalent. The highest resistance was with ampicillin (85%) in both units and the lowest was with amikacin (8%) and colistin (12%). Ampicillin, amikacin, co-amoxiclav, cefuroxime, colistin and gentamicin showed the same level of resistance in both units. The resistance to the other antibiotics tested in both units was higher in the SA ICU. In the SA unit trimethoprim (77%), followed by cefpodoxime (62%) had the highest levels of resistance. Vancomycin resistance was 10 times higher in the SA ICU. CONCLUSIONS. The vast majority of microorganisms cultured in the SA ICU were gramnegative, whilst the majority in the UK unit were gram-positive. In addition, it was noted that there was a higher amount of antibiotic resistance in SA. These differences might be explained by several factors including the amount of clinical microbiology input, the presence of screening, the duration of antibiotics given and the infection control methods used. Population demographics will influence these results too with a high prevalence of trauma and HIV patients in SA. The high rates of gram positive cultures in the UK ICU may be a consequence of the screening program that is in place. Areas of future research would be to look at the effect of the introduction of infection control measures and the input of a Microbiologist. These would be relatively cost neutral. [1] : that antimicrobial diversity prevents from resistance. Four differentiated antimicrobial strategies were consecutively implemented in an ICU for the empirical treatment of ventilator-associated pneumonia (VAP) (Patient-specific: 10 months; Priorization: 12 months; Restriction: 12 months and Mixing 10 months). Periods were grouped into heterogeneous or homogeneous according to the degree of antimicrobial diversity attained with each antibiotic strategy as measured by the antimicrobial heterogeneity index (AHI) [2] . In the group of patients with infection due to TB and NP (31 patients, 57.4%), microbiological eradication was achieved in 5 patients (100%) treated with nebulized CL and in 6 of the 9 patients (42.9%) treated with IV CL, the difference being significant (p \ 0.05). Clinical recovery in this group was 100% (6 patients) treated with nebulized CL and 75% (9 of the 12 patients) in the IV CL group. This difference was not significant. The study suggests that treatment with colistin in patients with pulmonary infection with multi-resistant acinetobacter baumannii could be more efficient if it were to be administrated solely nebulized or in combination with IV colistin rather than administered solely intravenously. RESULTS. Following the introduction of the policy in quarter 3 of 2008, there was a reduction in cephalosporin and quinolone prescription. There was an expected increase in penicillin prescription. There was an overall reduction in antibiotic use. According to the sensitivities of the common pathogens, these changes would appear to be appropriate. INTRODUCTION. Classical antiviral therapy inhibits viral proteins and are subject to resistance. An alternative strategy which target cellular factors has been developed to counteract this resistance emergence. We hypothesized that such approach may identify broad spectrum antivirals. Influenza A virus was used as a model for viral diversity and need for therapy against unpredictable viruses as recently underlined by the H1N1 pandemic. OBJECTIVES. We proposed to identify a gene-expression signature associated with infection with different influenza A virus subtypes which could help to identify potential antiviral drugs with broad spectrum. METHODS. This experimental study was divided into three parts. First, cellular gene expression response to infection with five different human and avian influenza virus strains was analyzed using a cDNA nylon microarray (HuSG9 k-TAGC Marseille, France). Lung epithelial cell line A549 were infected with avian (H5N1, H5N2 and H7N1) or human (H3N2 and H1N1) strains. Thirty independent samples were analyzed (5 replicates for each condition). Supervised analysis was performed using Significance Analysis of Microarray (SAM) algorithm. In the second part, the identified transcriptional signature (TS) was compared to the Connectivity Map (CMAP) database, in order to identified potential antivirals drugs. Then, the antiviral activity of the identified drugs was tested on A549 infected cells using a neuraminidase assay. RESULTS. Using SAM algorithm, 300 genes were determined as differentially expressed between infected and non-infected samples (FDR = 10%). Strikingly, only a few genes (n = 16) were induced by infection and related to immune response. Most of them (95%) were down-regulated. A concise list was used to screen CMAP, a database of drug-associated gene expression profiles, for molecules with inverse profiles than the signature of infection. We hypothesized that such compounds would induce an unfavorable cellular environment for influenza virus replication. Eight potential antivirals including a known antiviral were identified, and five inhibited influenza viral growth in vitro. The new pandemic H1N1 virus (SOI-V), which was not used to define the gene expression signature of infection, was inhibited by five of the eight identified molecules. CONCLUSIONS. This is the first study showing that a gene expression based-screening can be used to identify antivirals. This original in-silico approach has a very high hit-rate (5/8) compared to classical high-throughput drug screenings. The efficacy of the selected drugs on the new H1N1 (SOI-V) strain highlight the ability of the approach to identify broad spectrum drugs. Such approaches could accelerate the drug discovery progress and could be extended to other pathogens. METHODS. Retrospective analysis of empiric antibiotic therapy, antibiotic sensitivity of subsequently isolated organism and the final outcome (mortality adjusted for illness severity score-SOFA and age) among 70 bacteremic patients admitted in our multi-disciplinary ICU during 1 year (2009).  Timing of antibiotic therapy is crucial to treatment success. However duration of antibiotic therapy is also important with shorter treatment regimens increasing the likelihood of treatment failure and longer regimens increasing drug costs in the intensive care unit. Therefore it is important to investigate the length of antibiotic prescriptions in everyday practice in a busy intensive care unit outside strict study protocols. OBJECTIVES. To assess antibiotic prescription in everyday medical practice in a mixed general intensive care unit in the UK. . Of note, just over half (52.5%) of all antibiotic prescriptions were for a duration of less than 3 days, 73% for 5 days and 86.4% for up to 7 days. The most commonly prescribed antibiotics were beta-lactam antibiotics (25%), cephalosporins (19.2%), nitroimidazoles (17.8%-metronidazole), aminoglycosides (7.3%), macrolides (5.9%-clarithromycin). Second line antibiotics were more rarely prescribed : antistaphylococcal agents (5.8%-mainly teicoplanin and vancomycin) and carbapenems (4.7%-mainly meropenem). Antifungal agents (5.4%) and antiviral agents (1.9%) were not commonly prescribed. Antibiotic prescribing policy was changed in our unit in 2007 to restrict the use of cephalosporins and quinolone antibiotics in an attempt to reduce the incidence of Clostridium difficile. This can be seen in our study in that cephalosporins were commonly prescribed prior to 2007 with 20-30% of prescriptions being cephalosporins. After 2007, incidence of cephalosporin prescription dropped below 10% being only 3% of prescriptions in 2009. Administration of antibiotics for the correct duration of prescription is vital for both therapeutic success and cost effectiveness. In this study,73-86% of antibiotics were prescribing for 5-7 days which is the commonly believed duration of antibiotic therapy required for effective treatment. Unit. Failure to administer an appropriate therapy for the pathogen responsible of the infection is associated with increased morbidity and mortality. Initial empirical broad spectrum approach can be modified after assessment of antibiotic susceptibility or identification of the causative agent. Early assessment of antibiotic susceptibility, leading to administration of the correct antimicrobial agents, can reduce morbidity and mortality and can also lower toxicity, costs and microbial resistance related to inappropriate maintenance of broad spectrum therapy. To assess antibiotic susceptibility, positive blood cultures (BC) are currently treated in solid medium for 16-24 h. The HB&L Ò system, an automated instrument formerly used for urine screening, allows antibiotic susceptibility identification in 6 h, giving results 1 day in advance compared to standard disk-diffusion methods. OBJECTIVES. The aim of this study is to compare the results on antibiotic susceptibilities of BC in septic patients admitted in high dependency and intensive care units using the HB&L system, the standard method used in the clinical microbiology laboratory of the institution (VITEK-2 Ò ) and a gold standard technique (Etest Ò ). RESULTS. For Gram-positive bacteria the concordance between HB&L and Etest was 87.9% and between VITEK-2 and Etest was 80.2%. For Gram-negative bacteria the concordance between HB&L and Etest was 83.3% and between VITEK-2 and Etest was 80.4%. CONCLUSIONS. The HB&L system demonstrates a very good concordance with standard laboratory methods in the assessment of antimicrobial susceptibility in positive BC, giving results 1 day in advance as opposed to standard methods. Clinical studies suggested that high dose and concentrations of vancomycin are associated with nephrotoxicity in hospitalized patients. However, patients with high severity and septic shock were excluded from these analyses. Also, in these patients, vancomycin is often given as continuous infusion (CI). OBJECTIVES. The aim of this study was to evaluate the incidence of nephrotoxicity among ICU septic patients requiring CI of vancomycin and to identify the risk factors of development of renal dysfunction in this population. Retrospective analysis of all patients admitted in the ICU from January 2008 to December 2009 in whom a vancomycin was given as a CI. Patients were included if they (a) were [ 18 years old, (b) had sepsis according to standard criteria, (c) were treated for more than 48 h, (d) were not on continuous renal replacement therapy (CRRT). Demographics, comorbid conditions and treatment data were collected. Vancomycin loading dose, mean daily and total dose, as well as vancomycin concentrations at day 1, mean concentrations of the first 3 days of therapy and the highest concentration observed during the therapy were also recorded. Nephrotoxicity was defined as an increase in serum creatinine of C 0.3 mg/dL compared to baseline levels during therapy and within 72 h from vancomycin discontinuation. Concomitant renal toxics were also recorded. Creatinine clearance (CrCl) was calculated from 24-h urine collection and normalized to body surface area (BSA) for day 1 of therapy. Multivariate logistic regression analysis was performed using all variables showing a significant association (p \ 0.2) with nephrotoxicity during therapy in univariate analysis. During the study period, 207 patients met the inclusion criteria. 49 (24%) patients developed nephrotoxicity during vancomycin therapy. Patients developing nephrotoxicity were more frequently exposed to other concomitant nephrotoxics (p = 0.001), had higher APACHE II and SOFA score at admission (p = 0.02 and p = 0.03, respectively), longer duration of therapy (p = 0.09), higher concentrations of vancomycin at day 1 and during the first 3 days of therapy (p = 0.007 and p \ 0.001, respectively) and lower CrCl at admission (p = 0.002). However, the mean vancomycin concentration during the first 3 days of therapy (p \ 0.001, 95% CI = 1.045-1.153) and the duration of therapy (p = 0.043, 95% CI = 1.003-1.233) were the only variables associated with nephrotoxicity in the multivariate logistic regression analysis. In ICU septic patients treated with a CI of vancomycin, nephrotoxicity was found in almost 25% of cases. Vancomycin concentrations and duration of therapy were the strongest variables to predict nephrotoxicity during therapy. We selected the cases due to anastomotic leakage (14 patients) 0.14 of the 15 medical notes were reviewed.The variables were:age,APACHEII,Candida Score,lactate,procalcitonine,gener,number of surgeries,haemodynamic,respiratory or renal failure,leukocytosis/leukopenia,lenght of staying and clinical outcome.We divided the patients in two groups:those who were treated with a relaparotomy to treat the cause of the intra-abdominal infection and in the other group we included the patients treated by laparostomy and VAC devices. RESULTS. The cause of peritonitis was anastomotic dehiscense in 41.67% of the patients.All of them underwent relaparotomy,and in 5 cases (35.71%),VAC devices were applied following relaparotomy during an average of 5 days.The results are observed in Tables 1, 2 , and 3. CONCLUSIONS. Bacterial peritonitis due to anastomotic leackage has been the most frequent cause of peritonitis in our critical care unit during this period.The use of VAC devices to treat such infections is a good alternative treatment although we cannot prove, in the present study,that those devices are a better option due to the small sample of our study. OBJECTIVES. Among the development risk factors of infectious complications the most significant are duration of operation, extensiveness of surgical trauma and perioperative hemorrhage. Introduction of microsurgical techniques in the operations on intracranial tumors and brain vessels on the one hand reduced surgical trauma and intraoperative hemorrhage, but at the same time increased the duration of neurosurgical operation. The study of publications about the efficiency of perioperative preventive antibiotics showed, that there were different opinions about its benefits. We have analyzed the case histories of 3805 neurosurgical patients, who had undergone the operation in our hospital in 1998-2004 years. In 3,038 cases there were preventive intraoperative antibiotics by using of cephalosporins of the third generation, and in 767 cases there were no preventive treatment. In our research we estimated the quantity of local (meningitis, ventriculitis, wound suppuration) and systemic (postoperative pneumonia, sepsis) infectious complications. In the group of patients with preventive antibacterial treatment we observed infectious complications in 1.77% cases which was less then in group without preventive antibiotics where infectious complications occurred in 4.69% cases. The difference was statistically authentic (p \ 0.05). Thus, it is a certain fact, that preventive antibiotics decrease the number of suppurative and inflammatory complications in patients, undergoing neurosurgical operations for about 2, 92%. The most effective antibiotics are cephalosporins of the third and the fourth generations and fthorhynolones. CONCLUSIONS. In our hospital preventive antibacterial treatment resulted in decreasing of the quantity of infectious complications, lethality and reduced the duration of hospitalization. CONCLUSIONS. This population had a higher survival probability than the predicted by the SAPS III score. The rate of infection associated with devices in ICU is better than the published standards (ENVIN-ICU), emphasizing a 0 incidence density of pneumonia associated with mechanical ventilation. We have not seen an increased risk of hospital infection after SDD employment. (1). Clinical picture may include leukocytosis, fever and increased serum procalcitonin. Although clinical severity varies depending on host immunologic status and pathogen virulence, data are lacking about clinical differences between Gram positive (G +) and Gram negative sepsis (G -). OBJECTIVES. to assess for differences in terms of SAPS II score, white blood cell count (WBCC), body temperature (BT), serum procalcitonin (PCT) and ICU-mortality between microbiologically confirmed G + and G -sepsis. METHODS. Data were retrospectively collected from charts of critically ill patients admitted to a surgical ICU from the 1/1/09 to 31/12/09. Inclusion criteria were clinical evidence of sepsis (2) and microbiologically proven infection from G + or G -bacteria. Incomplete charts and fungal co-infections were considered as exclusion criteria. Microbiological diagnosis and infections sites were noted. Patients were divided in two groups, G + and G -sepsis and differences in SAPS II score, WBCC, BD and serum PCT at the time of the first positive culture and ICU mortality were sorted and tested for statistical significance (p \ 0.05). RESULTS. On a total of 39 septic patients, 28 had a G + infection and 11 a G -infection. Table A shows microbiological diagnosis and infections sites. SAPS II scores were higher in G -than G + infected patients (p \ 0.05). WBCCs were significantly higher in patients with G -sepsis than in those with G + sepsis (p \ 0.05, Table B ). Patients with G -sepsis shows, also, higher ICU-mortality rate than those with G + sepsis (p \ 0.05, Table B ). , were more prevalent than Gram-positive organisms (n = 9), anaerobes (n = 1), and fungi (n = 4). Pseudomonas was isolated most frequently (n = 7). Prophylactic antibiotics were administered to 38 of the 159 patients (23.9%), most often in patients who were admitted for 1 week or less; in this latter patient subgroup of 72 patients, 22 (30.6%) were treated with prophylactic antibiotics (most frequently beta-lactams). Twelve patients (7.5%) received prophylactic antifungals. CONCLUSION. Despite being uncommon, SAP is still associated with a high ICU mortality (22.7%). Infections continue to be a major problem in this population, with a significant proportion presenting with non-abdominal sites of infection. Most patients are treated with antibiotics (1/3 prophylaxis and 2/3 for treatment). Gram-negative organisms were isolated most frequently, whereas yeasts were less common. Hospital protocol for antibiotic surgical prophylaxis was already in place, which recommended, in a majority of specialities and cases, for administration of antibiotics at least 30 min before start of surgical procedure. With this background, we wanted to examine to what extent hospital policy guidelines were being implemented and whether best practice was being followed. To determine if patients were receiving their antibiotic prophylaxis. To determine if patients receiving their prophylactic antibiotics, were within 30 min of the commencement of procedure. To determine compliance with protocol and establish best practice. A form was filled in by the Operating Theatre Practitioner, to log the name of the operation, time of administration and name of antibiotic given by the anaesthetist and the time of start of operation i.e. knife to skin time. These forms were filled in, without the anaesthetist being aware, to exclude any form of performance or operating bias. All data was collected prospectively. A total of 100 patients were selected. It was equally divided between all the specialities in the Main Operating Theatres. They were Orthopaedics-20 cases, General Surgery-20 cases, Laparoscopic Surgery-20 cases, Urology-20 cases, and Gyneacology-20 cases. Overall: Percentage of patients receiving antibiotics after start of surgery-25%. Percentage of patients receiving antibiotics less than 30 min before start of operation-70%. Percentage of patients receiving antibiotics more than 30 min before start of operation-5%. Percentage of patients receiving antibiotics-100%. CONCLUSION. The Surgical prophylaxis policy formulated by the Microbiology department states that antibiotics be administered between 30 min and 2 h before start of surgery. The objective of this audit has been realised. The compliance rate, as per the hospital protocol is a mere 5%, with 95% of patients receiving antibiotics less than 30 min before the start of surgery or after the start of surgery. Numerous studies have clearly shown a reduction in surgical site infection rates with antibiotic prophylaxis and better outcomes. OBJECTIVES. We conducted this study to report outcomes in neutropenic patients admitted to the intensive care unit (ICU) with severe sepsis and septic shock. METHODS. Observational longitudinal cohort study over a 10-year study period in a 12-bed medical ICU.  Methaemoglobinaemia is a rare problem that can significantly impact on oxygen carriage and may require ICU management. Dapsone is the recommended second-line agent used for Pneumocystis jiroveci pneumonia prophylaxis in immunocompromised patients and has been used with increased frequency. Three leukaemic patients on dapsone developed symptomatic acquired methaemoglobinaemia (methaemoglobin level [ 1.5%) [1] . This prompted a retrospective review of all patients admitted to our institution with haematological malignancies who received dapsone over a 12-month period. OBJECTIVES. To determine the true incidence of dapsone-associated methaemoglobinaemia and other contributing factors. Retrospective study over a 12-month period. Co-oximetry data was employed to identify patients with methaemoglobinaemia. Thirty-four patients with haematologic malignancies received dapsone between January and December 2008, of whom 53% (N = 18) had co-oximetry studies done. Raised methaemoglobin levels was seen in thirteen patients, 4 of them symptomatic; with mean peak levels of 7.84% (range 1.9-26.8%). 61.5% (N = 8) of these patients required intensive care support. Mean onset of methaemoglobinaemia was 11.8 days (range 4-18 days) following dapsone commencement. All patients were anaemic with an average Hb of 85.5 g/L (range 59-111 g/L). All 13 were prescribed either fluconazole or voriconazole and 5 patients were also on high-dose steroids, both agents known to induce cytochrome P450 enzymes and hence potentiating dapsone toxicity. Our experience suggests that dapsone should be used with caution in patients with haematological malignancies as they are particularly at risk of developing symptomatic methaemoglobinaemia due to underlying anaemia, immunosuppression and potential drug interactions. The current recommendation for dapsone for PJP prophylaxis in this group of patients needs to be reviewed. When methaemoglobinaemia does occur, early recognition is possible with routine co-oximetry testing and correct treatment may lessen the need for or duration of ICU supports. REFERENCE(S). OBJECTIVES. We assess SeptiFast in the diagnosis of aspergillosis in severe sepsis. We prospectively studied patients admitted to ICU between March 2008 and April 2010 who met criteria for severe sepsis or septic shock according to consensus definitions through conventional microbiological culture (CMC) of bronchial aspirate and occasionally other specimens. During sepsis, patient blood was processed for SeptiFast one or more times using the previously described technique. DISCUSSION. IA is extremely serious in CIP and requires early specific therapy, but accurate diagnosis is difficult and slow. SeptiFast was processed in our laboratory in 5 h helping the early detection of AF among all septic CIP, and differentiation between noninvasive and invasive aspergillosis. It allows the identification of 24 other microorganisms that cause sepsis, then is not an additional burden. A multiplex PCR which includes among its target Aspergillus Fumigatus has helped the rapid diagnosis and identification of the most severe forms of Aspergillosis in critically ill patients. OBJECTIVES. To describe the epidemiological conditions of our ward and clinical characteristics of patients who suffer these infections. A retrospective study of cases admitted to ICU with this type of infection. Patients were included due to their positive result to alveolar broncoaspiration, given by the department of microbiology. Environmental controls were taken by the department of preventive medicine. We had 4 cases, 2 male and 2 female, with a range age of 46-69 years. 3 of them died because of this invasive aspergillosis [one of them with A. niger (AN) also], 2 have been confirmed by necropsia and we are still waiting one result. The female patient alive suffered, besides the pulmonary aspergillosis, neuroaspergillosis. One case was attended in our ward due to cardiovascular problems, the reason for the rest was the H1N1v flu. None had surgery, transplanted or had any severe immunosuppression due to any cause prior admission. All of them were treated with corticosteroids (2 of them with 60 mg/day, and the other two with 160 mg/day and 240 mg/day. All dosis have been pondered to metilprednisolon). All of them suffered other inside-ICU infections: one was co-infected with meticilin-resistant Staphylococcus aureus, other one with klebsiella and non albicans Candida (na C.), pseudomona aeruginosa co-infected other patient, and finally, the only patient no overinfected with bacteria, who was also infected with na C. Environmental controls carried out with Merck Ò Microbiological Air Sampler MAS-100 demonstrated the presence of AF and AN in every area of our ward. CONCLUSIONS. Our patients do not match the typical profile of patients with aspergillosis (patients who develop profound or prolonged neutropenia, AIDS, leukemia or lymphoma…), despite immunosuppression provoked the H1N1v flu in two of them, so we needed to find a common source of contamination. This was the environmental pollution caused by a remodeling of the hospital, bordering our area, and discovered by the department of preventive medicine. INTRODUCTION. Tuberculosis remains a major concern worldwide in the XXI century. OBJECTIVES. We aimed to know the circumstances of admission and outcome of patients for whom a diagnosis of tuberculosis was assessed in the intensive care unit (ICU). CONCLUSIONS. All our isolates were MDR Acinetobactor baumanii that was similar to earlier Indian reports [1] . Mortality was 63.4% in our infected patients despite early initiation of appropriate antibiotics and this was more than the predicted mortality based on APACHE IV scores [2] . MDR forms of Acinetobactor are a known independent risk factor for mortality [3] . Newer early diagnostic techniques and treatments are needed. To reduce CDI, a reduction in the use of ceftriaxone was advocated. However, this has been the first line antimicrobial for many patients with severe sepsis admitted to our ICU. Hence, there is pressure to change our antimicrobial policy despite conflicting studies regarding the risk of CDI in relation to specific antimicrobials 1 . The ICU is a nine-bedded, adult, mixed surgical/medical unit in a district general hospital. Our practice is to use broad spectrum drugs, then de-escalate after microbiological results and avoid prolonged courses of antimicrobials. OBJECTIVES. To investigate whether recent antimicrobial prescribing in ICU was associated with C. difficile infection. Patients admitted to ICU for 48 h or more, between September 2005 and March 2009, were identified from the HELICS (Hospitals in Europe Links for Infection Control through Surveillance) database. All antimicrobials administered to these patients were recorded. The local infection control department's surveillance programme provided information on patients who subsequently had a stool sample positive for C. difficile toxin. Categorical data was analysed using Chi-squared or Fisher exact test. We identified 913 patients, of which 18 (2%) subsequently had a C. difficile toxin positive stool sample (180 days post-ICU discharge in one case). Many patients received multiple antimicrobials, whilst 131 had none during their ICU stay (see Table 1 ). . Concern exists about the impact of high rates of bed occupancy on the incidence of MRSA acquisition [1] . To determine whether MRSA acquisition was related to high bed occupancy in a 9 bedded, adult, mixed medical/surgical ICU in a district general hospital in Scotland. We reviewed all patients admitted to our ICU from September 2005 to October 2008 inclusive. Information was retrieved on bed occupancy and MRSA acquistion. Patients with known MRSA prior to ICU admission and those with a positive test within the first 48 h were excluded. Patients who became MRSA-positive 48 h after admission were included as new acquisitions. Bed occupancy was based upon the number of hours patients were nursed on ICU each day, and was summed and expressed as a percentage of the maximum available (i.e. 24 9 9 = hours per day 9 maximum number of beds). Bed availability changed during the study period and is accounted for in the analysis. High occupancy was defined as greater than 87.5% as used in a previous study [1] . When occupancy exceeded 100%, patients were nursed elsewhere in the hospital until an ICU bed was available. The ICU layout remained the same throughout the study period, with no reduction in bed spacing when occupancy was high. ACKNOWLEDGMENT. We would also like to thank Suzanne Lloyd for her statistical input. METHODS. At a given day ICU surfaces were screened and included ventilator tube surfaces, bedrails, bedside monitors, cardiograms, dressing trolleys, sinks, telephones, wall oxygen humidifiers etc. Environmental sites were cultured by using sterile cotton swabs inoculated into thioglucolate broth and were incubated aerobically at 37°C for 48 h. At the same day, hand impressions were taken from all ICU staff and also blood, bronchial secretions and urine were cultured from all patients. Microorganism identification was performed by the VITEK-II method and susceptibility testing by the disk diffusion testing according CLSI. Some were further evaluated by E-test. Production of extended spectrum beta-lactamases was determined by the double disk synergy test and metallo-beta-lactamase production by the EDTA-synergy test. A colistin-resistant, MBL positive Klebsiella pneumoniae strain with an identical resistant phenotype was isolated lated from blood and ventilator tube surface of the same patient. A multiresistant K. pneumoniae strain with the same phenotype and also production of ESBLs and MBLs was isolated from bedrails and bedside monitor of another patient. A multiresistant, carbapenem resistant Pseudomonas aeruginosa of an identical phenotype was cultured from the bronchial secretions and ventilator tube of a patient, the ventilator tube of another and the bronchial secretions of a third patient. Environmental sampling also revealed the presence of 11 Enterococcus strains 3 of which were vancomycin resistant, a multiresistant Pseudomonas putida and also Candida parapsilosis from a dressing trolley shelf. A multiresistant Acinetobacter baumanii was also cultured from the hands of a healthcare worker. CONCLUSIONS. The bacteriological profile of the ICU revealed the presence of highly resistant microorganisms exhibiting multiple and complicated resistance mechanisms. The fact that identical phenotypes were observed, is an indication of a possible genetic relation among some of these strains. These isolates will further be analysed by PCR and PFGE methodology. After survey, hand antisepsis and infection control measures were encouraged. OBJECTIVES. The characteristics of an outbreak caused by a K. pneumoniae strain, resistant to carbapenem (imipenem and meropenem) in a university hospital ICU are described. METHODS. Bacterial identification and initial antimicrobial susceptibility testing were performed by the VITEK 2-automated system (bioMérieux, France). All isolates were initially screened for the presence of metallo-b-lactamases (MBLs) and K. pneumoniae cabapenemases (KPCs) using phenotypic tests. MBL production was tested with the combined synergy test between imipenem and EDTA and the presence of KPC was performed with the double disc synergy test between boronic acid and meropenem. The presence of KPC strains was selectively performed using PCR. Unpaired t test was used for statistical analysis. Table 1 .  A retrospective study of cases admitted to ICU with this type of infection and/or colonization. We included all patients admitted in our ward during the outbreak. All colonization samples were taken by the department of preventive medicine and the results analysed by the department of microbiology. We evaluated the risk factors found in the systematic revision for this topic made by the Agency for Health Technology Assessment (AETSA) of Andalucía. is an emerging pathogen and with high mortality. The limited therapies options is a concern in ICU. OBJECTIVES. We describe the clinical features of a nosocomial outbreak of MBL-producing KP in a ICU in Madrid, Spain. METHODS. From July 2009 to April 2010, 21 patients were infected and/or colonized with MBL-producing KP. The clinical and epidemiological features, and outcome were prospectively analysed. RESULTS. Among the 21 pts, 8 were infected and 13 were colonized with MBL-producing KP. The Metallo-B-LactamasE (MBL) VIM-1 (integron 1) were isolated in all cases. It showed resistance to cefotaxime (100%), ciprofloxacin (100%), imipenem (100%), meropenem 100%) and amikacin (95%); most isolates were susceptible to colistin (95%) and tigecycline (100%). Among the 21 pts, 13 were men and the mean age was 56.9 years. All of them were hospitalised in a medical ICU. Mean APACHE II score was 19.6. The mean length of stay to the first isolation of MBL-producing KP was 26.5 days (4-90). All patients have been previously treated with broad-spectrum antibiotics such as carbapenems (66%), third generation cephalosporin (66%), quinolones (62%), piperacillin/tazobactam (43%) or aminoglycosides (14%).There were 10 infections in 8 patients: pneumonia (4), UTI (3), catheter-related bacteremia (2), and ventriculitis (1). 7 patients received antibiotic directed therapy with tigecycline and colistin (6) or tygecicline (1). One patient with UTI received no treatment. Among infected patients the overall mortality was 25% (2/8), and was due to the MBL-producing KP in 2 patients with pneumonia. Among the 13 colonizated patients the most frequent sites of isolement were rectal swab (7), urine (6) and tracheal aspirate (5). The mortality among colonizated patients was 30.7% (4/13). CONCLUSIONS. MLB-producing KP are emerging in Spain. This bacteria can produce severe nosocomial infections associated with a high mortality. We have also observed a higher proportion of colonizated asymptomatic patients. Antibiotic multiresistance is of concern because of the limited therapeutic options for treatment of these infections. OBJECTIVES. The present study was to look for the time dependant relationship between hepatic dysfunction or failure as assessed by the hepatic SOFA score (score 1-2 for dysfunction; score 3-4 for failure) and the severity of ICU-acquired infection. Table 1 shows the number of patients with or without failure or dysfunction, the rate of ICU-acquired infection, the rate of septic shock, the hospital mortality and the number of infected patients with an increase in their hepatic SOFA score.  In their desire to match energy expenditure many intensivists and nutritionists employ expedient nomograms to predict energy requirement and many add stress and/or activity factors. Patients with sepsis exhibit a wide spectrum-some patients are more severe than others. Septic patients were both hypo-and hyper-metabolic [1] . As a result, predictive equations can over-or under-estimate the energy requirements in these patients. While direct calorimetry is beyond many ICUs, Weir equation (Energy expenditure = [(VO 2 9 3.941) + (VCO 2 9 1.11)] 9 1,440 cal/day) is a useful alternative. We compared various predictive equations, including Schofield Ireton-Jones, Penn state and Harris-Benedict nomograms with the Weir calculation in a cohort of patients with severe sepsis and septic shock. OBJECTIVES. Weir equation is a useful alternative to energy prediction nomograms in critically ill septic patients. METHODS. Prospective single centre study to compare the Weir equation in predicting REE with other equations in patients with varying severity of sepsis. Critically ill ventilated septic patients had their energy requirement predicted by the different nomograms, which is an agebased, weight-determined, gender-specific equation that incorporates stress and/or activity factor. These were compared with their energy expenditure calculated from (a) end-tidal CO 2 derived Carbon dioxide (CO 2 ) production (VCO 2 ) (Evita, Drager) and (b) VO 2 deduced assuming a respiratory quotient of 0.8381. OBJECTIVES. To describe a novel technique combining metoclopramide and erythromycin to facilitate insertion of the NJ tube into the correct position. A single centre pilot observational study over 2 years in 31 consecutive unselected critical care patients with acute pancreatitis requiring nasojejunal tube insertion. Twenty minutes prior to insertion of the NJ tube, intravenous erythromycin 500 mg and metoclopramide 10 mg were administered. A Fine Bore Feeding Tube (Non-Weighted with stylet; Size 8 FR; Length 140 cm) was placed blindly at the bedside, advancing it slowly 1 cm at a time to a length of 120 cm. Two hours later the position was confirmed with a chest radiograph. Of the 31 patients, 29 (93.5%) had a nasojejunal tube inserted into the correct position at the first attempt. Two patients (6.5%) did not pass the tube beyond the pylorus, deemed failed insertions, one of whom had a severely dilated stomach requiring endoscopy assisted insertion. No complications were noted in any of the patients. We contend our method combining two prokinetics, acting as facilitators, is as effective (93.2% success), safer, less time and labour intensive and more cost effective compared to other methods. Further research is needed to evaluate efficacy for non-critically ill patients, however it should be considered in this setting given its demonstrated efficacy and minimal side effects.  Nutritional support is an essential part of care in critical patients. It is well characterized the need for adequate assessment and energetic need and nutrition in these patients. OBJECTIVES. Characterizing the relationship between energetic needs in critical care and nutrition prescribed and supplied. We also propose to identify the most common complications and causes of interruption and nutritional support. We enrolled a hundred and thirty patients admitted to an Intensive Care Unit. Those patients where monitorized, from a nutritional view point, for 14 days. Their energetic needs were calculated according the Harris-Benedict formula adjusted for a stress factor. The nutritional support prescribed and administrated, as well as the most common causes for interruption and complications were registered by consultation of clinical records. We used Acute Physiology and Chronic Health Evaluation II (APACHE II) to access clinical severity. INTRODUCTION. The optimal nutrition of the critically ill is yet a matter of discussion. Although the negative consequences of malnutrition are obvious, the advantage of normocaloric nutrition regarding clinical outcome is not clearly documented. Published observational studies showed that hypocaloric feeding at least in the initial phase of the acute disease may be beneficial regarding nosocomial infections and clinical outcome. However, adequate prospective randomised trials are not yet available. OBJECTIVES. The aim of this ongoing prospective randomised controlled trial is to compare hypocaloric and normocaloric feeding in critically ill medical patients in the first 7 days of the acute illness regarding their influence on metabolic and clinical parameters. METHODS. Critically ill non-surgical patients of a university medical ICU, who would need artificial nutrition for at least 3 days, were included after informed consent of the patient or guardian. Exclusion criteria were age\18 or[80 years, pregnancy, immunosuppressive therapy, active malignant disease and pre-existing malnutrition. Patients were randomised using an electronic randomisation list into group 1 (normocaloric feeding) and group 2 (feeding 50% of measured or calculated energy requirement) within 24 h of ICU admission. Energy expenditure was measured with indirect calorimetry or, if this was not possible, calculated using the Ireton-Jones formula. Enteral feeding was preferred, with daily rate increment to achieve target volume on day 3. If the enteral route was considered not possible by the treating physician, parenteral nutrition was administered. Blood glucose control was done every 3 h and insulin dose adjusted with a target blood glucose level of 6 to 8 mmol/l. C-reactive protein and procalcitonin were also daily measured. APACHE-II and SOFA scores and relevant clinical data were documented. Patients were otherwise managed according the standard procedures of the ICU based on international guidelines. Eighty-four patients (45 in group 1 and 39 in group 2) were included until now. Mean age of patients was 66.6 ± 12.0 years with a mean body mass index of 27.2 ± 4.9 and APACHE-II-Score of 29.3 ± 8.7. Administered caloric amount was significantly different between the groups at any time during the study period. The insulin demand was significantly higher in group 1 than in group 2. There was no significant difference between the two groups regarding SOFA score as well as C-reactive protein and procalcitonin. Diarrhea was observed more frequently in group 1 than in group 2. The mortality rate was 20.5% in group 1 and 27.0% in group 2 (n.s.). CONCLUSIONS. Our data show that glycemic control was better with hypocaloric than normocaloric feeding. Hypocaloric feeding was associated with lesser episodes of diarrhea than normocaloric feeding. There was no significant difference regarding clinical outcome; however, it is too early to make a definite conclusion. OBJECTIVES. To investigate the nutritional route ratio in delivered versus planned nutritional support used in mechanically ventilated versus non ventilated patients and the association between nutritional support route and observed mortality. We recorded the type and amount, ratio kcal delivered over planned, of nutritional support given to the patients. Time until achieving caloric goals and the associations between type of nutritional support and ICU mortality were also investigated. For all study groups, categorical variables are expressed as frequencies and percentages and continuous variables as mean and standard deviation (SD) when data followed a normal distribution, or as medians and interquartile (25th-75th percentile) range when distribution departed from normality. The evolution of energy intake, enteral and parenteral, was assessed according to the ICU stay. The adjustment was done using the k-nearest point procedure. We obtained the ratio between given and planned energy intake. A marker value close to one indicates that both inputs are similar. RESULTS. 348 patients were studied (188 ventilated vs. 160 non-ventilated). Characteristics were similar in both groups: age (60 vs. 61 years), BMI (26.5 vs. 26.7 kg/m 2 ), emergency admitted (81 vs. 76%) and medical patients (64 vs. 62%). SAPS2 and SOFA score were significantly higher in mechanically ventilated patients (p\0.001). Enteral nutrition alone was used in 34% (52 vs. 12%; p \ 0.001), oral nutrition alone in 28% (2.7 vs. 56%; p \ 0.001), parenteral nutrition alone in 17.6% (22 vs. 12%; p\0.001), and enteral plus parenteral in 4.1% (5.5 vs. 2.5%; p\0.001). Patients ventilated versus non ventilated received significantly more kcal by enteral (p \0.001) and parenteral (p\0.001) routes. Ratio delivered over planned nutritional support was 0.8 within 48 h with enteral and 1 with parenteral nutrition in mechanically ventilated patients. Observed mortality rate was 29.3% in patients receiving enteral nutrition (n = 116), 26.7% with parenteral (n = 60), 23% combined (n = 14), and 10% with oral (n = 95). CONCLUSIONS. Enteral nutrition was the most common nutritional support utilized both in total and in mechanically ventilated patients, followed by oral and parenteral nutrition. Parenteral nutrition was significantly more used in ventilated (p \ 0.001) and oral nutrition in nonventilated patients (p \ 0.001). Combined nutrition was only given to 4.1% of the patients. Delivered over planned enteral nutritional support ratio was 80% within 48 h after starting nutrition in ventilated patients. Enteral nutrition is feasible with a high delivered versus planned ratio success as shown in Spanish multidisciplinary ICUs. We also try to find a relationship between the day of admission and the start time and we found than patient admitted during weekend start EN before than those admitted during the week; 21 h ± 17 h vs. 18.5 ± 12.5 h (p = 0.085). We have studied the possible relationship between Intensivist Residents rotation in the SNU, and compared the month of rotation and the next 2 months compared to pre-rotation, finding in the first case an average of 17.2 ± 13 in the second 22.4 ± 18.6 h (p = 0.082). OBJECTIVES. The goal of this study is to evaluate the amount of calories we give to the patients who stays longer than 10 days in Intensive Care Unit (ICU). Multicenter, prospective, observational and cohort study, during a 4 month period (January to April 2010). All patients staying more than 10 days in 5 ICUs of 3 different hospitals were enrolled. At base line, demographic and clinical information was obtained, including information necessary to determine the severity of illness. We collected all the nutritional support provided to the patients during the first 15 days in ICU. INTRODUCTION. The ICU nutritionDay project is an international audit about nutrition care and outcome. Currently recommended energy intake is 20-25 kcal kg -1 day -1 . There is a controversy on the amount of energy to be given to the severely undernourished or obese patients. Several guidelines suggest that above a certain cutoff of body mass index ideal body weight should replace actual body weight as a reference. OBJECTIVES. The aim of the analysis was to determine whether ideal or actual body weight appears to be used as a reference for the calculation of energy intake. We included all patients from 2007-2009 in the analysis. Energy intake as the sum of enteral and parenteral nutrition given. Total energy intake was either normalised to actual or ideal body weight. Ideal body weight was calculated as height -100. Proportions were compared with the v 2 test. A total of 2,711 patients from 205 ICUs were included. Mortality was between 20-26% in the 3 years. Approximately half of the patients received artificial nutrition. Figure 1 shows that based on actual body weight energy intake decreases progressively with increasing BMI, whereas Fig. 2 shows that based on ideal body weight energy intake was similar for all BMI groups. The proportion of patients with under-or overnutrition within each BMI group is significantly determined by the normalisation reference. Based on ideal body weight the proportion of patients within the recommendations was less than half the patients. Overnutrition appears to be common in undernourished patients.  GRANT ACKNOWLEDGMENT. Financial support from ESPEN and support from ECCRN. RESULTS. All included in the study patients prior to surgery in the hemostasis system detected a shift towards hypercoagulation and inhibition of fibrinolysis: increase in maximum amplitude (MA) at 20.7%, reduction of F to 13.6% in both groups compared to normal rates. At 1 day after surgery in patients treated with bemiparin declines AM, r and k to 12.7, 8.4 and 9.6% respectively, and F increase by 4.6% compared with preoperative. In group 2, there was a similar picture: the reduction of AM, r and k to 10.3, 8.0 and 6.6% respectively, and F increase by 4.4% within 1 postoperative day compared with preoperative. At 5 day performance of hemostasis in both groups came almost to the same value-a modest hypocoagulation, normalized activity of fibrinolysis. Within 7 days of postoperative thrombotic complications developed in 3 patients (11.53%) 1 group. In group 2, complications developed in 5 (17.85%) patients-in 4 thrombosis and in 1 case-the bleeding. CONCLUSIONS. Using haemoviscoelastography can quickly identify disorders of hemostasis in patients with cancer of uterine body before, during and after the surgery, allowing time to begin their prevention and treatment. Bemiparin at a dosage of 3,500 1 times per day before and after surgery is effective and safe method of prevention of thromboembolic complications in patients with uterine cancer after surgical treatment. OBJECTIVES and METHODS. Blood coagulation and fibrinolisis were studied in 321 pregnant women before surgery with the term of hestosis 19-36 weeks without clinical sings of coaguiopaties. Double local ishemia tests of the upper limb were performed to reveal coagulation disturbances. Lowfrequency haemoviscography (LHVG) was performed before using double local ishemia test and immediately after. CONCLUSIONS. Double local ishemia test of the upper limb is useful in assessing the coaguiopaties that follow pregnancy with hestosis without any clinical signs and provide objective data for guiding prophylactic therapy to manage these coaguiopaties. OBJECTIVES AND METHODS. To assess the functional state of the hemostasis system we have used our devised test with local ischemia of the upper extremity. The analysis of the coagulation, vascular-thrombocytic components of hemostasis and fibrinolysis was made on the basis of parameters of blood aggregate state obtained by using a method of haemoviscoelastography (HVG). There have been examined 32 healthy pregnant women in the age range from 19 to 31 (a control group), and 32 pregnant women with revealed late toxicosis of different severity degree (nephropathy of II degree-12, nephropathy of III degree-20), While analyzing the functional state of the hemostasis system in healthy pregnant women there have been distinguished two types of response to the test: compensated type (1) in 33% and subcompensated type (2) in 67%. The pregnant women suffering from late toxicosis were registered to have subcompensated type of the hemostasis system response (3) in 26% of cases and decompensated type (4) in 74% of cases. The functional test in the group 1 resulted in decreased aggregation activity of platelets (Ar), reduced activity of I and II phases of blood coagulation (elevation of r and k) and activation of the fibrinolytic system (F). The group 2 is noted to have enhanced aggregation activity of platelets (Ar). Enhanced thrombin activity and acceleration of [the thrombin-formation and activation of II and III coagulation phases. The total fibrinolytic blood activity (F) was reduced by 44%. CONCLUSIONS. Thus, late toxicosis is accompanied by changes in the hemostasis system causing exhaustion of compensatory potentials of the regulation system of the blood aggregate state promoting high risk of thrombohemorrhagic complications during delivery and in the postpartum period.  We calculated the elastic shear modulus of standard MA (Gt) and H VG MA (GH) which reflect total clot strength and procoagulatory protein component, respectively. The difference was an estimate of the platelet component (Gp). There was a l6% perioperative increase of standard MA, corresponding to a 49% increase of Gt (P\0.05) and an 79-85% contribution of the calculated Gp to Gt. We conclude that serial standard thromboelastography and HVG viscoelastic test may reveal the independent contribution of platelets and procoagulatory proteins to clot strength. Using multiple linear regressions, all coagulation, TEG and HVG variabilities were used to model postoperative hypercoagulation. Results showed that some components of the TEG failed to identify hypercoagulation (r\0.2, P[0.75). However, three components of the routine coagulation assay, including bleeding time, prothrombin time, and platelet count could be modeled to show prolonged postoperative hypercoagulability (P\0.01). We conclude that all components of the HVG test reflect postoperative coagulopathies, these results suggests that it may be useful in determining the coagulation status of cancer patients perioperative. CONCLUSIONS. Postoperative hypercoagulability, occurring for at least 1 week after major cancer abdominal surgery, may be demonstrated HVG viscoelastotest. Hypercoagulability is not reflected completely by standard coagulation monitoring and TEG and seems to be predominantly caused by increased platelet reactivity. HVG provides a fast and easy to perform bedside test to quantify in vitro coagulation, may he useful in determining the coagulation status of cancer patients preoperatively. RESULTS. At the four sample intervals, the r time (mean ± SEM) (5.91 ± 0, 65; 7.5 ± 0.25; 9.5 ± 0.55 min) and the r time (5.8 ± 0.1; 8.2 ± 0, 27; ± 9, 14 ± 0.2 min) of the HVG were significantly correlated with the expected peak and trough levels of LMWH and serum anti-Xa levels (p\0.05). After fifth dose immediately, HVG r times exceeded the normal range in 29 of 116 patients (25%). Prolongation of r time and r time on postoperative day 5 may indicate an exaggerated response to LMWH. Low frequency haemoviscoelastography is a test that could potentially correlate with the degree of anticoagulation produced by low molecular weight heparin bemiparin. well as the plasmatic coagulation system is a test that could potentially correlate with the degree of anticoagulation produced by LMWH. The r time from the haemoviscogram correlates with serum anti-Xa concentration. HVG is a convenient test to measure the decree of anticoagulation from LMWH. OBJECTIVES AND METHODS. A complete coagulation screen, activated clotting time (ACT), thromboelasthography (TEG) and viscoelasthography (VG) were performed before surgery, at the end of operation and monitoring of LMWH anticoagulation therapy on postoperative days 1, 2, 3, and 7. We tested the hypothesis that the parallel use of standard TEG and VG can fully access postoperative state of blood coagulation. The elastic shear modulus of standard MA (GT) and VGMVA (GH), which reflect total clot strength and procoagulatory protein component, was been calculated. The difference was an estimate of platelet component (Gp). There was 14% increase of standard MA, corresponding to 48% increase of Gt (P\0.05) and 80-86% contribution of the calculated Gp to Gt. Using multiple linea regression, all coagulation, TEG and VG variabilities were used to model perioperative thrombophylia. The results showed that some components of TEG failed to identify hypercoagulation (r\0.2, P\0.75). However, 3 components of the routine coagulation assay, including bleeding time, prothrombin time and platelet count could be modeled to show prolonged postoperative hypercoagulability (P \ 0.01). We conclude that all components of viscoelasthography test reflect postoperative coagulopathies. Serial standard thromboelasthography and viscoelastic analyzer may reveal the independent contribution of platelets and of procoagulatory proteins to clot strength. CONCLUSIONS. These results suggest that viscoelastic techniques might be useful in the determining the coagulation status in cancer patients perioperative. Hypercoagulability is not reflected completely by standard coagulation monitoring and TEG and seems to be predominantly caused by increased platelet reactivity. [1] . Pharmacological anticoagulation with low molecular weight heparin (LMWH) is the mainstay of prophylaxis. However, despite evidence, it is used inconsistently. To assess use of thromboprophylaxis in our ICU, and compliance with the Intensive Care Society (ICS) consensus guidelines [2] . A retrospective audit was made of 14 patients admitted consecutively to the ICU in June 2009. Data recorded included contraindications to thromboprophylaxis and the presence of risk factors for VTE; daily PT, APTT ratios and platelet count, LMWH administration and cited reasons for omission. A valid reason was defined as a PT or APTT ratio of[1.5, platelet count \50 9 10 9 /L or documentation of a reason in accordance with the ICS guidelines. RESULTS. 14 patients' case notes were reviewed: a total of 64 ICU patient days. On 42 of 64 days LMWH was either given correctly (GC) or omitted correctly (OC). On 22 of 64 days LMWH was either omitted incorrectly (OI) or given incorrectly (GI): error rate 34%. When omitted incorrectly there was no cited reason in 17/20, and the drug was not prescribed in 3/20. When omitted correctly no reason was cited in 3/31, it was not prescribed in 6/31 and in 22/31 a valid reason was cited. The frequency of failure to prescribe LMWH was not significantly different between the OI group (15%) compared with the OC group (19.3%) p = 0.72 (Fisher's exact). When comparing the two groups: GC and OI there was no significant difference between the median PT/APPT ratios: p = 0.21(Mann-Whitney U). On all of the 20 patient days when LMWH was omitted inappropriately, there was at least one specific risk factor for VTE: 3 risk factors on 9 days (45%), 2 on 9 days (45%) and 1 on 2 days (10%). Pharmacological prophylaxis reduces rate of fatal VTE and use of LMWH has been recommended in ICS and NICE guidance [2] . This audit demonstrates LMWH is rarely given inappropriately, but commonly omitted in error. On every ICU patient day when LMWH was omitted at least one risk factor was present for the development of VTE. Our results suggest failure in interpretation of results leads to erroneous omission of LMWH, and illustrates the need for a ratio rather than actual PT and APTT. Recommendations regarding VTE prophylaxis incorporating ICS and NICE guidance are now being implemented in our ICU.  Red cell transfusion is a potentially life saving therapy. However, it is associated with a number of potentially serious adverse effects in the critically ill. The Transfusion Requirements in Critical Care (TRICC) trial highlighted that a restrictive strategy of red cell transfusion is at least as effective and possibly superior to a liberal transfusion strategy in critically ill patients [1] . Despite this, a later study of 284 Intensive Care Units (ICU) revealed that the mean pretransfusion hemoglobin was 8.6 ± 1.7 g/dL [2] . OBJECTIVES. We sought to assess perceived and actual red cell transfusion triggers for critical care doctors in the Merseyside region in the UK to establish whether a restrictive transfusion policy was being followed. METHODS. Two regional audits were undertaken involving nine adult ICUs throughout the Merseyside region. The first involved a questionnaire in which doctors were asked to identify at what level of haemoglobin (Hb) they would transfuse a patient. This was followed by a prospective audit of all transfusions taking place over a 2 week period on each unit. Data were collected as to the Hb at the time of transfusion and the indication. Exclusion criteria included patients with acute haemorrhage, acute myocardial infarction, early goal directed therapy and those under 16 years of age. The majority of responders confirmed that they would transfuse at a Hb\8.0 g/dL, however 23% still felt transfusion above 8.0 g/dL was preferable. Actual Red Cell Transfusion Triggers: A total of 204 units of red cells were transfused over the study period. The majority of patients were transfused at a Hb\8.0 g/dL. However, 27% of patients received RBCs at higher levels of Hb, as shown in the graph below. Actual transfusion triggers CONCLUSIONS. Despite evidence stating that a restrictive red cell transfusion policy is desirable, 27% of transfusions taking place across the Mersey region are occurring at a level considered to be unnecessary. As such, we are constructing a regional protocol to prevent unnecessary transfusion of such an expensive and potentially dangerous commodity. INTRODUCTION. Human plasma is used to replace moderate coagulation factor deficiency e.g. due to acute bleeding. For some years a pool plasma treated with a solvent/detergent step for virus inactivation is available on the market (Octaplas, Octapharma GmbH, Germany) that is associated with a reduced risk of transfusion related lung injury [1] . Recently, a new plasma (Octaplas LG, Octapharma GmbH, Germany) was introduced to the market, which is treated with a modified solvent/detergent step and additionally treated with a prion removal step (ligand gel) to gain even more safety in plasma therapy [2] . OBJECTIVES. The long-term stability of clotting factors in thawed and stored LG plasma has not been investigated so far. We investigated the long term stability and the bacterial contamination of Octa-plasLG compared with Octaplas stored after thawing over 6 days at 4 (±2)°C. 5 plasma bags from each blood group were thawed and the coagulation factors at the following time points 0, 1, 2, 4, 6, 24, 48, 72, 96, 120 and after144 h were measured. The change of parameters over time was analyzed by means of a nonparametric ANOVA for repeated measurements. OBJECTIVES. To establish an association between the prothrombin times of patients received in intensive care unit (ICU) and the prognosis. A retrospective study with analysis of 278 patients consecutively admitted to the ICU during the period from 01 January, 2009 to January 31, 2010. There was a slight predominance of females (51.1%) with a mean age of 56.9 ± 20.5 years. The average length of stay was 7.9 ± 7.3 days and mean APACHE II score was 21.9 ± 9.0 points. Patients with early mortality (within the first 48 h after ICU admission) had higher value of prothrombin time on ICU entrance, expressed through the International Normalized Ratio (INR) (2.5 ± 1.9) than the survivors of this period (1.4 ± 0.5), p\0.05. The multiple linear regression analysis indentified the INR as an independent predictor of progression to early death (Table 1) . On the receiver operating characteristic curve, the INR value associated with the best discrimination, between patients with early mortality and survivors, was 1.48 (95% CI: 0.67-0.83, p\0.0001).  A retrospective observational study was developed which inclusions criteria were every VKA treated patient who was admitted to our Hospital between 2007-2009 for urgent reversal due to bleeding or not bleeding reasons. All patients received 600 IU iv. of Prothromplex TIM 4, most of them also got 10-30 mg of Vit K iv and 10 mg of heparin iv. Reversal efficacy was defined as (1) achievement of INR B1.5 after PCC. INR follow up at 1, 3, 6, 12, and 24 h were recorded and compared. (2) Clinical response in terms of bleeding control or no abnormal bleeding after surgery. Safety was defined by adverse events. OBJECTIVES. The purpose of this survey is to look for the rate of delay in red cells transfusion within the surgical services. For each patient who received red cells transfusion in any of the surgical services in 2008, we included the surgical file, the anesthesia file, the transfusion record and peritransfusion full blood counts (FBC) computer data. The absence of an element infers the exclusion. Transfusion triggers are discussed by 2 physicians, in light of the AFSSAPS recommendations [2] . The FBC data are then analyzed according to transfusion and clinical events. Delay [crossing of the trigger-transfusion] over 12 h is considered delayed transfusion. We noted the transfusion episodes (TE) considered unjustified. Five patients corresponding to 5 transfusion episodes were excluded. In visceral surgery, 85 TE were studied, corresponding to 61 patients transfused (age 73 ± 8) and 204 red cells units. Eleven TE were delayed, and 4 TE unjustified. In urology, 65 TE were studied, corresponding to 34 patients transfused (age 77 ± 10) and 164 red cells units. 6 TE were delayed, and 2 TE unjustified. Concerning delayed transfusion, the delay [crossing of the thresholdtransfusion] was 34.6 ± 20.5 h in visceral surgery, 29.5 ± 9.1 in urology. In neurosurgery, 6 TE were evaluated, corresponding to 5 patients. No transfusion was delayed or unjustified. CONCLUSIONS. Delayed transfusion is generally found in 11% of transfusion episodes (13% in visceral surgery, 9% in urology). The rate of unjustified transfusion episodes is low: 4% (5% in visceral surgery, 3% in urology). The emphasis is from now placed on the daily reading in the late morning of the results of FBC by the anesthesiologist responsible for a surgical specialty who alerts at the need a member of the surgical team, before checking in late afternoon that required transfusions have been performed. OBJECTIVES. The aim of this study was to evaluate laboratory data and clinical outcome of fibrinogen administration in patients suffering from major hemorrhage. A retrospective study over a 3-year observation period of consecutive patients who received a single dose of fibrinogen concentrate but not recombinant factor VIIa as part of their treatment of major hemorrhage ([2.0 L). Thirty-seven patients (mean age 74 years, range 23-87, 51% males) were included, most of them suffering from major hemorrhage following open heart (68%) or abdominal surgery (13%). After a median fibrinogen dose of 2 g (range 1-6 g) an absolute increase in plasma fibrinogen concentration of 0.6 g/L was observed (P \ 0.001). Activated partial thromboplastin time (APTT) and prothrombin time (PT) were also significantly improved (P\ 0.001), however, platelet counts and D-dimer values remained unchanged. Transfusion requirements for packed red blood cells (PRBC) were significantly reduced (P\0.01) in the 24 h after fibrinogen administration, but fresh frozen plasma (FFP) and platelet concentrate (PC) transfusions were not significantly changed. No adverse effects were documented. Eight patients (22%) died in ICU, most within 28 days, but 27 (73%) were discharged from the hospital and were still alive 6 months later. CONCLUSIONS. Administration of fibrinogen for major hemorrhage improved coagulation parameters and seemed to significantly reduce transfusions of PRBC but not FFP or PC when used as a supplement to conventional treatment. OBJECTIVES. Therefore, we conducted a retrospective analysis of the use of levosimendan in our cardiac surgical ICU. All patients admitted to our ICU within 1 year being treated with levosimendan were evaluated regarding personal data, use of levosimendan (bolus or not, start of the infusion, amount given), the combination of levosimendan with other drugs (dobutamine, norepinephrine, milrinon, vasopressin, epinephrine and beta-blocker) as well as patients ICU survival. RESULTS. 102 out of 988 patients were treated with levosimendan (10.3%). Mean age was 65 years (5-83), the majority was male (n = 68) with a mean ejection fraction of 37% (12-74%). Mean Euro Score for predicting outcome in cardiac surgery was 12 (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) . 43 patients (42%) underwent emergency surgery. In nearly half of our patients levosimendan was started during the operation (n = 48, 47%) and in a high proportion after the operation (n = 38, 37%), in 97% of the patients levosimendan was started continuously without a bolus. Virtually all patients (n = 99; 97%) were treated with additional norepinephrine, 41 patients (40%) with dobutamine while other catecholamines or vasopressin were used infrequently. Interestingly, 25 patients (25%) were on betablockers. Overall ICU survival of levosimendan treated patients was 81% (n = 83) with 79% (n = 34) of emergency patients surviving ICU. Patients treated with additional dobutamine or milrinone had higher survival rates (75.6 and 64.7%) compared to those patients requiring epinephrine or vasopressin plus levosimendan (45 and 31%). CONCLUSIONS. Levosimendan is safe in patients undergoing cardiac surgery. Even in those highest risk patients with a mean Euro Score of 12 ICU survival rates were surprisingly high. INTRODUCTION. Diaphragmatic paralysis is a non common complication of cardiac surgery that may cause further deterioration of pulmonary function, and may lead to secondary hypoxemia, prolonged ventilator use, pneumonia and atelectasis leading to increased ICU and hospital stay, as well as increased morbidity and mortality. The causes of the diaphragmatic paralysis during cardiac surgery are not clearly understood. Direct injury during harvesting of the internal mammary artery, cold injury owing to pericardial ice slush and inadvertent stretch injuries during intra-pericardial manipulation of the heart are some documented causes, but the injury may occur without an apparent reason. To assess the incidence of diaphragmatic paralysis in patients undergoing cardiac surgery and it's impact on morbidity and mortality. METHODS. Retrospective, descriptive study of a population of 6,000 patients undergoing cardiac surgery during the years 1996-2010. The diagnosis of diaphragmatic paralysis was made based on the association of clinical criteria (ventilatory failure, paradoxical breathing), radiological criteria (diaphragmatic elevation) and the relationship between intra-abdominal and intra-thoracic pressure recorded simultaneously. There is an uncertain number of patients that could present milder forms of diaphragmatic paralysis with little impact on the postoperative care. Twenty-five patients (0.40%) were including according to the criteria previously disscused. 68% male, with a mean age of 61 years. Aortic surgery 24%, valve surgery 40%, pericardiectomy 20%, heart transplant 12%, coronary artery bypass grafting 4%. The diaphragmatic paralysis was bilateral in 36%, Left in 48% and right in 16%. The median duration of mechanical ventilation was 168 h (8-3,600), with a following need of non-invasive mechanical ventilation in a 36% of cases. Reintubation occurred in 36% of patients, while 44% underwent tracheostomy. The median ICU stay in this patients was 14 days (2-151), much higher than global (2 days). Mortality of 12%. CONCLUSIONS. Diaphragmatic paralysis in patients undergoing cardiac surgery is a non frequent complication, but with a great impact on morbidity and resource consumption. It should be considered in cases of difficult weaning. The difficulty in initial diagnosis prevents to know it's real incidence, delaying appropriate treatment. The early onset of non-invasive mechanical ventilation could be useful in milder forms. INTRODUCTION. Development of acute renal failure (ARF) after cardiac surgery is related with increased mortality, morbidity and length of hospital stay [1] . It was proposed that free iron emerged after haemolysis could be one of the responsible factors of ARF devolopment after cardiopulmonary bypass and high levels of ferritin which is known to bind free iron could prevent ARF [2] . In this study, risk factors (including serum free haemoglobin level) of acute renal failure development after cardiac surgery were investigated. It was also investigated that whether or not high serum level of ferritin is protective for ARF. MATERIAL AND METHOD. 50 consecutive patients who had normal preoperative renal functions and undergone open heart surgery at our hospital were included in the study after getting Ethic Commitee approval. Preoperative, operative and postoperative clinical and laboratory findings of patients were recorded. ARF was described as a 25% or more increases of preoperative creatinin level during 48 h of surgery. The relationship between recorded variables and ARF development were investigated. RESULTS. ARF was developed in 26 of 50 (52%) patients studied. Age, diabetes mellitus (DM), high preoperative levels of blood urea and creatinin, body mass index (BMI) were found to be risk factors for ARF development after cardiopulmonary bypass. Precence of preoperative hypertension (HT), and/or low left ventricular ejection fraction (EF \40%) were found to be unrelated with ARF development. Serum ferritin level was lower than 130 lg/L in 63.9 and 54.2% of ARF developed and nondeveloped cases, respectively, although it was not reach statistical significance. Intraoperative variables that were found to be related with ARF development were valvular surgery, cross clamp time, cardiopulmonary bypass time, operation time and low urinary output. Entubation time, intensive care unit and hospital stay were longer in ARF developed patients. Preoperative, operative and postoperative serum free haemoglobin level's of ARF developed and nondeveloped patients were not different. CONCLUSIONS. Since ARF after cardiac surgery is related with high morbidity and mortality, it is very important to define the patients at high risk of ARF preoperatively. After defining high risk patients, ARF could be perevented by improved care, detailed monitorization and optimization of renal perfusion. OBJECTIVES. We review the use of both internal thoracic arteries and the subsequent sternal complications considering preoperative risk factors and highlighting the triad obesity, EPOC, DM. METHODS. Data were collected retrospectively from 662 patients who underwent isolated CABG over the last 6 years. Patients were allocated to none or one internal thoracic artery grafting (group A) or two internal thoracic arteries (group B) and then, evaluated on classic risk factors (RF)of dehiscence: gender, age, obesity, DM, COPD, smoking condition, renal impairment, peripheral vascular disease (PVD), cardiac low output. We define two high risk groups: first one with C 3 risk factor and second one with the triad obesity-COPD-DM. Of 662 CABG, both arteries were used in 190 patients (28%).Data showed higher sternal dehiscence in group A than in group B (1 to 0.06%). More prevalence of C 3 risk factors in group A p \ 0.01 and the same for the triad. Once the data has been corrected by age, no differences were found in the distribution of RF between groups apart from shock or low EF. No differences were found in sternal dehiscence. INTRODUCTION. TAVI is an emerging procedure for patients who are considered at very high or prohibitive risk for standard surgery. Moreover, these patients are prone to the contrast induced nephropathy (CIN), due to the angiographic procedure needed. OBJECTIVES. We decided therefore to study the incidence of AKI following TAVI procedures and to analyze if any of the preexisting co-morbidities, of the patients characteristics and of perioperative factors could influence its developement. After Ethical Committee approval and written personal informed consent, 148 patients undergoing TAVI were enrolled in this prospective observational study. AKI was defined according to the AKINetwork definitions [1] . We analysed 17 peri-operative variables with univariate statistical analysis. Then, the factors statistically significant underwent a multivariate logistic regression analysis to verify the relative risk for AKI. A p value \ 0.05 was considered significant. (Table 1) . RESULTS. Nineteen patients (70%) presented with early tamponade (B6 days before diagnosis. Seven patients died during their hospital stay (25%). On ICU admission, factors predictive of hospital mortality were ASAT and ALAT levels (P = 0.02). In contrast, SAPSII (P = 0.3) and SOFA scores (P = 0.9) were not related to patient outcome. At the time of tamponade diagnosis, lactate (P = 0.02), SOFA score (P = 0.02), ASAT and ALAT levels (P = 0.01) were the only predictive factors of death. In contrast, mean blood pressure (P = 0.13), central venous pressure (P = 0.9), hemoglobin level (P = 0. OBJECTIVES. We describe the demographic characteristics, treatment option, complications and evolution of a series of 18 cases with LCOS in the postoperative mitral valve. We conducted a retrospective study analyzing the use of levosimendan in adult patients with mitral valve replacement who develop LCOS (cardiac index \ 2.2 l/min/m 2 and SvO 2 \65%) and not respond to treatment with inotropic agents, from January 2009 to April 2010. We collect demographic, hemodynamic and respiratory variables, response to amines, complications and outcome. The results are expressed as mean and standard deviation or percentage. RESULTS. There were 121 mitral valve replacements. 18 patients (14.9%) had LCOS, 11 women (61%) and 7 men (39%), with a mean age of 63 years and a mean euroescore of 6.88. The indication of valve replacement was for: 7 patients rheumatic heart disease (39%), 5 with annular calcification (28%), mitral valve prolapse in 2, annular dilatation (secondary to dilated cardiomyopathy) in 2, one with ischemic mitral regurgitation, and one prosthetic dysfunction.In the postoperative hemodynamic management we use dobutamine for LCOS after optimizing preload and heart rate; in these 18 cases we report, is also given levosimendan. Only 2 patients used a loading dose (6 lg/kg); continuous infusion was starting at doses of 0.1 lg/kg/min and reaching maximum levels (0.2 lg/kg/min) in 10 patients (55%). Favorable response was achieved in 17 patients (94%), which was considered complete (stopping dobutamine within 24 h of treatment) in 9 patients, and partial (decrease of at least 75% of dobutamine in 24 h) in 7 patients. Only one patient was a non-responder who required amines restart. Side effects potentially attributable to levosimendan were an episode of hypotension that responded to fluid intake and a self-limited FA. Mean ICU stay was 4.6 days, with mean time of mechanical ventilation of 13 h. One patient died after surgery. CONCLUSIONS. In our series, levosimendan was helpful in the management of LCOS during postoperative mitral valve replacement, allowing removal of the amines. It has been shown to be a safe drug with few adverse effects attributable. OBJECTIVES. We used a flexible bronchoscope to entry a wound which was less than 1 cm.The whole procedures were done in the ICU bedside. A 16 Fr pig pig-tailed catheter inserted after the procedures. We used chest sonography to locate the entry in patients with exudative pleural effusion. Then the endoscopy went through a tocar 5.5 mm under local anesthesia; A 16 Fr pig pig-tailed catheter inserted after the procedure. Then the clinical data retrospectively studied. RESULTS. The Bedside 's Thoracoscopy was done on 8 patients. There were 5 patients (63%) proved to be malignant, 2 (25%) were parapneumonic effusion and 1 (13%) was empyema; and 1 patients (13%) reported as tuberculosis. All of the patients were received adhesiolysis due to the septated formation. There were no major complications noted after the procedure. CONCLUSIONS. This modified thoracoscopy is considered to be used in the bedside of ICU due to it's simple and safe technique, which daily using in medical pulmonologist. The opinion on administration of oxygen has been repeatedly rewieved over the past few years. Though hyperoxia might be benefitial in certain conditions, it is as well harmful due to oxygen toxicity. Since pathophysiology of AAA rupture is a combination of haemorrhagic shock and ischaemia/reperfusion trauma it can be assumed that many involved mechanisms might be affected by hyperoxia. To evaluate the effect of hyperoxia (100% inhaled oxygen) in a porcine model of ruptured abdominal aortic aneurysm (AAA) repair. Twenty-four male pigs weighting 38 (37-39) kg were separated to normoxemia (FiO 2 = 0.25) and hyperoxia group (FiO 2 = 1.0); 8 pigs in each group underwent the simulation of AAA rupture under general anaesthesia. Data of 4 sham-operated pigs in each group are not presented. Multiple transit time flow probes and catheters were used to determine regional blood flows, blood sampling and measurement of systemic hemodynamics. Baseline values (T1) were obtained after 2 h following the initial instrumentation. Subsequently, AAA rupture was simulated by bleeding the pigs to MAP 45 mmHg and abdominal cavity infused with warmed saline to reach intra-abdominal pressure of 25 mmHg. Hyperoxia started within this period. Data were collected after 4 h (T2) of shock. During repair surgery phase, infrarenal aortic clamping was performed (T3) and hemodynamics was resuscitated with shed blood. Intensive care then followed for 11 h (T4). Only systemic hemodynamics, oxygen transport and lactate data are presented in this abstract as median (IQR). Data were processed with appropriate non-parametrical tests. Tables 1 and 2 . Oxygen consumption (VO 2 ) and extraction (OER) were significantly lower in hyperoxia group during clamping. Also lactate levels were clearly higher in hyperoxia pigs but did not reach statistical significance. (# p \ 0.05 vs. Normoxemia, ## p\0.01 vs. Normoxemia). AIM. To evaluate and compare postoperative management between patients undergoing onpump and off-pump coronary revascularization surgery. A study was conducted that included patients undergoing surgery without ECC in the last 5 years on our premises. For every patient stated, another patient receiving conventional surgery was included. Preoperative data regarding gender, age, cardiovascular risk factors, previously diagnosed acute myocardial infarction, number of affected vessels and ventricular function was collected. Following surgery, time until extubation was recorded together with indicators of postoperative bleeding, highest troponin levels, necessity for blood transfusion, vasoactive drugs or intra aortic balloon pump (IABP) insertion, renal failure development, auricular fibrillation, neurological complications and surgical reintervention. Mean age was 61.01 ± 14.05 years old. Table 2 expresses some of the surgical details. Around 61% of the patients had no postoperative complications. We can see major complications in Table 3 . The length of stay was 3(2-6) days. The mortality rate was 10.5%. The area under the ROC curve was: Euroscore 0.690 (p = 0.002); Parsonnet 0.705 (p = 0.001) y SAPS 3 0.823 (p = 0.000). CONCLUSIONS. The clinical profile of the patient undergoing TAS in our setting is a 61 years old man, smoker, with high blood pressure. It is an off-pump scheduled surgery with aortic valve replacement. There usually aren't postoperative complications and the most important ones are renal failure, bleeding and shock. In this kind of patients, the observed mortality was 10.5%, and it seems that model SAPS 3 discriminates better than Euroscore or Parsonnet. OBJECTIVES. The aim of this study is to Gastrointestinal complications is rare in describe patients with mesenteric infarction in post-operative cardiac surgery and to evaluate a means of early diagnosis. From January 2006 to March 2010, 26 patients who underwent cardiac surgery and presented with symptoms of acute mesenteric ischemia were included. Demographic factors, pre operative risk factors, intra operative information, post operative and outcome data were noted. We analyzed the diagnosis methods of mesenteric ischemia. Quantitative variables were expressed as mean and range. . Twenty-six patients had mesenteric ischemia in a total of 2,208 patients (incidence 1.18%) undergoing cardiac surgery during the same period. The mortality rate was 84.6% (n = 22). The risk factors found in pre-operative period were: coronary artery disease (84.6%), hypertension (80%), dyslipidemia (50%). Arrhytmia, smoking, arteriopathy, diabetes were present in less than 38% of patients. Abdominal pain symptoms is the most constant at 61%, sometimes associated with SIRS in 15.4%. The biological balance sheets suffer a major disruption with cytolysis, the rise of myoglobin and CK in conjunction with a decrease of troponin, and hyperkalemia in the hours preceding the diagnosis. Diagnosis and treatment applied to the patients are summarized in the following The scanner has proved to have a poor sensitivity. The colonoscopy was contributive in 90.9% (when realized). CONCLUSIONS. The diagnosis of acute mesenteric ischemia (with very low incidence) is very difficult in post-operative cardiac surgery. The prognosis is initiated upon confirmation of diagnosis. Patients with coronary heart disease are at higher risk of intestinal ischemia. A more specific management perioperatively is necessary to try to anticipate before the onset of multiorgan failure. INTRODUCTION. High quality performance in emergency situations is dependent upon technical and nontechnical skills. A number of national bodies recommend team training to promote good teamwork and improve the quality and safety of healthcare [1] . Simulation training offers an authentic, low-risk environment for teaching technical and teamwork skills [2] . Simulations can be delivered in many different ways from low fidelity ''part task'' simulators, to integrated fully immersive simulation environments. Immersive simulator environments are, however, extremely expensive to develop, relatively inaccessible to clinicians and trainees, and struggle to achieve realism. In recent years a new phenomenon of ''in situ'' simulation has been described, in which simulation activity takes place in a clinical setting [3] . Given that a degree of ''buy in'' is required by those undertaking simulation training, in situ simulation has great potential as the environment, equipment and team are all genuine, at a fraction of the cost. To assess attitudes towards unannounced in situ simulation for resuscitation training. METHODS. An appropriate clinical location is selected in which simulation can be delivered. Equipment is set-up accordingly, using the ''SimMan 3G'' Mannequin, and a portable audiovisual recording system to facilitate structured feedback. A pertinent scenario is chosen and one member of staff from the clinical area is brought to the simulation location and asked to respond to the situation as they would to actual events. The oncall cardiac arrest team for the day attend, without prior warning, when a ''crash'' call is made by the local staff. The progress of the simulation then continues without further interaction by the faculty with the exception that as members of the cardiac arrest team arrive they are informed that they are to manage the simulation as though it were a real cardiac arrest. The simulations run for approximately 30 min, divided equally between simulation and structured feedback related to technical and non-technical performance. Finally, we ask participants to complete a questionnaire. Of team members attending simulations, 47 completed questionnaires. Results demonstrated that all participants strongly agreed that the simulation was realistic, that the clinical environment improves realism and that unannounced in situ simulation is useful for resuscitation training. CONCLUSIONS. Unannounced in situ simulation should be considered as a routine part of multidisciplinary resuscitation team training. 3. If such a brief and economical intervention could lead to a sustained change in knowledge. We used a standardised questionnaire on 26 FY1 doctors. Questions included what the parameters for SIRS were, which organ dysfunctions may indicate severe sepsis, what initial investigations they would organise and management steps including specifying a time frame they felt appropriate for antibiotic administration. We then gave them a laminated data card that could be attached to their lanyard, and repeated the questionnaire immediately after they had the chance to look at these and then again 2 months later to assess whether a lasting educational impact could be made. RESULTS. An immediate improvement was seen after initiating the cards. Those able to state the parameters required for SIRS improved from 12% to 100% and state six organs whose dysfunction indicated severe sepsis increased from 0 to 93%. Investigation improvements included a rise from 33% of doctors to 93% requesting a lactate and antibiotics administered within the hour went from 69 to 85%. We repeated the questionnaire 2 months after initiating the card and 24 FY1 s responded. 16 of the 24 had attended the initial session and received a laminated card. Of those who had received the card 12 still carried it with them. Of the FY1 s who continued to carry the card 83% knew the parameters for SIRS compared to 0% in the other groups. In a similar pattern 83% carrying the card would request a lactate compared to 50% of FY1 s no longer carrying the card. 92% of those still carrying the card were able to identify 5 or 6 organs affected by sepsis, compared to 75% of those not carrying the card and 50% of those who did not attend the initial session. The number giving antibiotics within the hour showed a sustained improvement at 92% of card carriers compared to 75% who did not carry the card. CONCLUSIONS. Junior doctors are poor at recognising sepsis and there are significant gaps in their investigation and management of such patients. We demonstrated the use of a brief, cost-effective intervention increases their theoretical ability to recognise, investigate and initiate suitable management of the septic patient. The laminated card is designed to clip onto the doctors' name badge so it remains with them at all times. A sustained improvement was only seen in those doctors who continued to carry the card with them. GRANT ACKNOWLEDGMENT. N/A. OBJECTIVE. Patient safety training program assessment. We designed a 7-h (80% practical) seminar. Airway management, ventilation and BCPR workshops were organized in small groups. We developed usual scenarios with human patient simulator (HPS) and actors, that represented common critical events: anaphylaxis, seizures, altered consciousness, respiratory failure, etc. After simulation and with video-assisted sessions, discussion of the proceedings were carried out.Finally, participants completed a survey that assessed various aspects in a score from 1 to 5. Results indicated the most and least interesting and included suggestions for improvement. (14), HPS high fidelity scenarios (12), teamwork (11), encourages reflection on common problems (5) .Least interesting: oral presentations (8) .Suggestions: repeat annually (20), add defibrillation (5), too short seminar (5). Overall assessment was very positive, and most valued aspects were adaptive capacity and competence of teachers. Oral presentations were the least valued aspect.The utility, small groups of practices and use of HPS high fidelity scenarios were the most appreciated aspects.40% suggested repeating it annually and 10% thinks it was too short. FINAL COMMENT. Important factor in the excellent course assessment was that the training was requested by the RD, and so we think this education program can be included as a usual activity of our Critical Care Department. intensivists of the ICU of a regional referral center for respiratory failure (Careggi Teaching Hospital, Florence, Italy) started to use bedside LUS on a daily basis in order to make diagnosis and monitor chest pathologies. A procedure ad hoc has been conceived in order to make every bedside LUS comparable. OBJECTIVES. The aim was to introduce a standard and comparable method for thorax ultrasound exams reporting, and to test the operator's improvements. Since the introduction of LUS, a close control of the exam reporting was performed. At first, LUS report consisted in an empty sheet only. Then, to uniform the way of reporting, an electronic sheet was added in our database. This sheet was divided into fields, regarding pleural line, diaphragm mobility, parenchyma, pleural effusion and pneumothorax evaluation. For each of them, several data were requested such as anatomical directions, quantification and nature of the ultrasonographic finding. Imagines of each LUS were stored in order to be re-examined. From April 2008, two senior intensivists not involved in LUS performance and expert in chest US, started to control the quality of reports by a comparison to the imagines provided. A mark for each field has been given, obtaining a score for each report ranging from 0 to 24. A mark[14 was designed as limit for a sufficient report. We supposed that and high report mark could be related with an high LUS performance quality. The study took 1 years, during which a total of 637 LUS have been performed and mean marks per month has been considered ( Fig. 1) . Seven months were needed to achieve a sufficient score into LUS report. From there, and high mark per month has been maintained, confirming high performance level of LUS with a gradual increase trend. Main missing in LUS reporting regarded diaphragm motility, clear anatomical direction for findings in lung parenchyma field, comparisons between supine and lateral position in pleural effusion quantification. A standardized method and unique electronic report sheet for LUS seemed useful for a more precise and efficient report system and for physicians' learning curve trend, confirmed by the high score achieved in the reporting during the study period ([14 in the last 5 months of study). There are currently no specific guidelines or protocols on this subject either nationally or locally. Some of the chest X-ray scans performed were avoidable, especially by combining the indications, thus limiting the cost for hospitals and radiation exposure to patients. The documentation of the Xray scans performed showing evidence that it was read and reported was frequently missed by doctors. The Ionising Radiation (Medical Exposure) Regulations 2000 (IR(ME)R 2000) implement for Great Britain the majority of the provisions of EC Directive 97/43/Euratom which concerns the protection of persons undergoing medical exposures. The Regulations require that all medical exposures to ionising radiation must go through a referral and justification process prior to the exposure, and a clinical evaluation of the results must be made and recorded after the exposure i.e. the images must be reported or ''read''. If it is known prior to the examination that no clinical evaluation will take place, then the exposure cannot be justified. 1. To determine the indications of chest X-rays. 2. To determine the number of indications with each chest X-rays. 3. To determine whether chest X-rays were read and documented. METHODS. Details of chest X-rays performed on 39 Level 3 care patients admitted to our ICU between January-March 2009 were collected and analysed. The indications for the Chest X-rays were found from the HISS system (computerised ordering system) and the documentation after the X-ray was looked up in the patient's notes. A total of 137 chest X-ray scans were performed in a 3 month period. Major indications were lung pathology, central venous line, tracheostomy, endotracheal intubation, chest drain insertion and naso-gastric tube insertion. Only 25% of the X-ray scans were performed for lung pathology. Eighty-nine percent of X-ray scans were performed looking for only one indication where as 18% of X-ray scans were performed looking for two indications. And 4% of X-ray scans were performed looking for three or more indications. Only 57% of the X-ray scans performed were read and documented in the notes. Unless the results will impact patient management, a chest X-ray is not indicated. We probably need specific protocols for ordering chest X-ray scans which may reduce the total number of chest X-ray scans performed and also reduce the cost and radiation exposure. We are not complying to IR(ME)R in 43% of chest X-ray documentation during the audit period. INTRODUCTION. Anatomy and physiology are major components of any nursing education. After graduation, nurses need to integrate this theoretical knowledge into daily practice in order to provide high-quality patient care. In ICU nurses caring for mechanically ventilated and critically ill patients, a thorough knowledge of the anatomy and physiology of the respiratory tract is pivotal. To evaluate knowledge of the anatomy and physiology of the respiratory tract among ICU nurses. METHODS. Survey using a 10-item multiple-choice questionnaire concerning anatomy and physiology of the respiratory tract. Following expert validation, the questionnaire was distributed and collected during the Flemish Society for Critical Care Nurses' annual congress (Ghent 2009). Demographics included gender, ICU experience, number of ICU beds and acquisition of a specialized ICU qualification. We collected 534 questionnaires (response rate: 71.2%). 73% of respondents knew that the venae pulmonales transport oxygenated blood to the heart's left atrium; 56% correctly identified the lung volumes after a normal expiration as the expiratory reserve volume and the residual volume; and 80% knew that breathing results in an intake of oxygen, elimination of CO 2 , and loss of H 2 O and body heat. It was known by 73% that an increase in the expiratory minute volume decreases the pCO 2 and increases the pH. In hyperventilating patients, pCO 2 levels are decreased and PO 2 levels are increased, which was known by 68% of our respondents; 95% knew that Fowler is the preferred position in patients breathing difficultly, and 93% that laryngeal edema can cause stridor. It was known by 79% that in anemic patients tissue oxygenation may be inadequate despite an SpO 2 = 95%. Only 30% knew that metabolic acidosis may be compensated by breathing faster and deeper; 71%, finally, recognized an increase in pH and a decrease in pCO 2 as potential signs of respiratory alkalosis. The mean test score was 71.8% (standard deviation: 1.81); the median score was 7 (interquartile range: 6-9). Nurses holding a specialized ICU qualification scored better than those not holding this qualification (p = 0.008) and male nurses scored better than their female colleagues (p = 0.005). There were no significant differences between scores of junior nurses and nurses working in the ICU for more than 5 or 10 years. CONCLUSIONS. Flemish ICU nurses have a good knowledge of the anatomy and physiology of the respiratory tract. Nursing education in Flanders seems to succeed in providing a good theoretical background for integrating the related knowledge in subsequent daily practice.  In recent years the high fidelity simulation has been used to train and upgrade the students [1] , medical and paramedical staff. An extension of the already large potential of the Laerdal SimMan (Laerdal, Norway) is to faithfully reproduce the monitoring of respiratory function in different diseases by using a modified lung simulator (QuickLung Ò -IngMarMedical). OBJECTIVES. The purpose of this study is the creation of a more realistic respiratory system than that currently available in the SimMan aimed to realise simulation scenarios in which patients with acute respiratory failure are assisted by mechanical ventilators. 1. To measure the respiratory mechanics of the SimMan, it was intubated with a Rüsh endotracheal tube (8.5 mm) and connected to a mechanical ventilator (Servo-i Ò , Maquet). Special care was taken to prevent air leakage and to obtain a closed system. The latter was obtained by a blocking pressure valves at the end of the bronchial tube. 2. To vary the respiratory mechanics of the SimMan, we excluded its respiratory system by connecting a lung simulator to the ventilator. The lung simulator allowed to vary the flow resistance from 5 to 50 cmH 2 O/l/s and the compliance from 10 to 20 ml/cmH 2 O. Lastly we inserted a starling resistor between the lung simulator and the mechanical ventilator to simulate the presence of expiratory flow limitation (EFL). RESULTS. Static compliance of the SimMan was about 40 ± 3.1 ml/cmH 2 O while the resistance to flow and additional resistances are respectively 9.3 ± 1.1 and 7.13 ± 0.9 cmH 2 O/ l/s.By using this new pulmonary setup, we were able to obtain flow and volume curves that faithfully reproduce the presence of EFL. CONCLUSIONS. The resistance and the compliance of SimMan can be compatible to ARDS, COPD and Pumonary Cardiogenic Edema [2] . However, the possibility to change those parameters together with the ability of reproducing the graphic characteristics of EFL increases the potentiality for high fidelity simulation in lung disease. The speed keys are used to send drug transactions and orders to the task list. The validation of the orders must be done after resuscitation, a final confirmation is needed that the medication has been given or that the orders actually took place. After pressing the stop button an evaluation form is instantly displayed on the screen. and increases the quality of the data. It also provides an evaluation moment from which acquired data can be used for training and education. Using this modus makes it possible to record a complete and reliable report of the resuscitation, containing all actions and orders in time. Targeted querying the database can now rapidly generate complete and reliable data. These data can contribute to research. Spanish, Italian and US models place empasis for donation on Co-ordiantors who are embedded within the local hospital, and these countries have signifiantly higher organ donation rates. A number of key changes were introduced in our hospital following the publication of the report ''Organs for Transplants'' by the UK Organ Donation Task Force. These included the appointment of an organ donation co-ordiantor based within our critical care unit and the introduction of a system of required referral. To examine the impact on organ donation of the introduction of a system of required referral, and the embedding on the critical care unit of an organ donation co-ordinator. METHODS. Records of referral rates and donation rates were examined restrospectively both before and after the introduction of these changes. A substantial increase in referral rates was seen from 31% in September 2009 to 80% in March 2010. An increase in organ donation rates was seen, with a particular increase in eye donation. However, in a significant proportion of patients who might have been candidates for non-heartbeating donation, organ donation was not considered. Taskforce has brought about a substantial increase in referral rates for organ donation, and appears to be having a positive impact on organ donation rates on our critical care unit. Much work remains to be done to increase donation rates, particularly in potential non-heartbeating donors. OBJECTIVES. In this study, we aim to consider whether our best option is the use of mechanical devices (VAD and/or ECMO) where this is the only possibility of reaching transplantation, given its high cost and poor medium term survival rates. METHODS. Prospective and descriptive study of all patients on mechanical device as a BTT between 2007-2009. We have performed 5 PHT, using VAD in 3 patients: One died because of stroke, due to coagulation disturbances and became an organ donor. Two are still alive after cardiac transplant (one of them with an adult graft). Average on WL time: 1-78 days.; on DVA: 8-78 day and 2-12 day on ECMO. We transplanted 15 paediatric lungs (PLT) and used ECMO as a BTT in two patients, one is alive (with an adult graft) and the other died during transplant surgery. Average on WL time: 38-75 days, 16-32 days on ECMO. DISCUSSION. The use of DVA and ECMO has proved to be effective in extending WL time until transplantation. Nevertheless, the use of this technique must be restricted to those cases where successful transplantation is the expected outcome, but never as a compassionate treatment. It is imperative that we make humane decisions based on ethical, as well as clinical, criteria. As paediatric patients are legally unable to make decisions and their parents and physicians are emotionally involved, limits need to be set and Advanced Care Planning discussed before arriving at Theatre. We might consider three aspects related to the use of these devices: ranging from Autonomy, the promotion of the patients' best interests, including decisionmaking from their standpoint as terminal disease sufferers. Physicians must seek Justice in terms which assure Equity and Utility in the limited and costly resource distribution. Stricter indications on life-sustaining techniques (DVA-ECMO) must be applied in the field of paediatric transplant. OBJECTIVES. We performed transcranial Doppler sonography (TCD) with a transorbital approach and compared findings to standard angiography in brain dead patients. Additionally, we evaluated whether reporting the angiographic and sonographic confirmation of cerebral circulatory arrest (CCA) to the families of patients improves their comprehension of brain death and their satisfaction from the medical information provided. METHODS. Twenty clinically brain dead patients underwent four-vessel angiography, TCD of the basilar and middle cerebral arteries, and TOD of the ICAs. Relatives were randomly allocated to 10 in whom brain death was presented as a clinical diagnosis (group A) and to 10 in whom brain death was presented as a clinical diagnosis confirmed by TCD and angiography examinations (group B). Comprehension and satisfaction of the relatives were assessed by an interview and a completion of a questionnaire. RESULTS. Both angiography and TCD verified CCA in all cases. In 3 subjects with absent bone windows CCA was confirmed by the transforaminal and transorbital TCD recordings only.The addition of TOD enabled 9.5% more cases of CCA to be diagnosed by TCD. Group B exhibited improved comprehension and higher satisfaction rates (p \ 0.05) but not significantly higher transplantation rate as compared to group A. CONCLUSIONS. The addition of TOD increases the efficacy of TCD in confirming CCA in brain death. Reporting angiographic and sonographic confirmation of CCA to families of brain dead patients may improve their comprehension of brain death and their satisfaction from the medical information provided. RESULTS. 3 units were removed from the analysis due to closure. From the remaining 236 ICUs we received replies from 151 (64%). In the event that their ICU was full the surveyed consultants indicated several different facilities were available to ventilate an extra patient. OBJECTIVES. To analyse whether our organizational changes and expanded criteria affected organ procurement and hence transplant activity. Hospital is a University Hospital, with 1150 beds (60 intensive care beds). Follow-up protocol of all patients with neurological damage admitted in the hospital with GCS \8 is carried out by transplant coordinators.Data about specific organ function (phisiological, X-ray, sputum cul-ture…) were collected. We analysed specifically the ''suboptimal group'',related with lung retrieval,with a cut-off age[55. RESULTS. In this period we have followed up 813 patients (GCS\8), 218 brain death (BD), 132 BD-donors, 47% (n = 62) aged between 55-87 years. A recent important change at our hospital has been the substitution of a pneumologist for a thoracic surgeon as head of our LT program. This has led to improved acceptance criteria and facilitated transplant coordinator discussion of potential donors with the thoracic team.Our efficiency in lung retrieval is 25% (33 patients), and 33% (11patients) OBJECTIVES. The goal of this study is to find out the grade of knowledge and attitude of the staff of our hospital towards organ donation and transplantation. AIM. To evaluate the ICU staff perception, knowledge and attitudes regarding living wills. METHOD. Cross-sectional descriptive study using an anonymous questionnaire where respondents were asked to give a written answer using dichotomous variables and a five-point Likert-like scale (LS). The healthcare professionals of a multidisciplinary Intensive Care Unit of a reference academic hospital completed the questionnaire, where therapeutic effort limitation is over 50% of dying patients. The data were analyzed using SPSS 12.0 for Windows. . Forty-five people answered the test. The mean age was 37.86 ± 8.98 years and 38% of the respondents were males. Regarding the working category, 50% were qualified physician specialists, 23% in training doctors and 27% were nurses, with no differences between genders. People rated their knowledge with a 4.57 on a LS. Most of them (92%) think that health professional must have some kind of knowledge about vital wills, but only a third of them had read the legal documents about the subject, in spite that 50% of surveyed professionals plan to write a living will in the coming year. We found no statistically significant differences between the different staff categories. When comparing results according to gender, women were found to be more aware of the necessity of knowing about living wills. They also support their implementation, both personally and professionally, and these differences are statistically significant (p\0.05). According to the respondents, the sources of information for patients should rely on general practitioners and this should be focused on the entire population. CONCLUSIONS. We found some contradiction between theory and practice There is a positive attitude from ICU professionals about living wills, but they do not feel personally involved enough and the knowledge should on legal conditions have to improve. Women are more aware of the importance of living wills and they are more likely to implement them. Knowledge and attitudes are not related to professional categories. METHODS. 297 person took part in the study, out of that the number of the health care professinals was 153 (8 from the intensive care unit), and 144 from the training-school college at Baja. The data obtained from questionnaire were analyzed with Chi-square test and frequency reliability range were counted. Among the health care professionals significantly higher rate of doctors would offer his relative's organs (p = 0.0197), and nearly sigificant degree out of them believe (p = 0.0593), that offering the organs may help abide the mourning. This latter opinion was carried in nearly significant degree by more lecturers and students, than employee helping in education (p = 0.0565). Significantly higher rate of doctors would offer any of their organs (p = 0.0436), than nurses with secondary qualification. The number of those doctors, who knew the concept of the cerebral death were significantly higher among health care professionals (P\ 0.001), and the rate of the relegious one's among them were also significantly higher than among nurses without higher edutational degree (p = 0.0471). The health care professionals avow themselves in significantly higher degree practising believers in totally (p = 0.0369), among them significantly more know the concept of the cerebral death (P \ 0.001) and the legal background of the inhibitory declaration (P\0.001). CONCLUSIONS. The organ deficiency is reducible with the correction of the organization, with the expansion of the layman's and health care professional's knowledge, without conciderable expenses. OBJECTIVES. Evaluate medical and nursing staff knowledge in monitoring neuromuscular blockade and improve practice within our ICU. We surveyed medical and nursing staff on our ICU to gauge the level of knowledge on placing electrodes in order to test neuromuscular blockade. Staff were asked to identify a primary and a secondary site for placing electrodes. They could do this either by description or by placing electrode stickers on the questioner. They were then asked to describe or demonstrate the appropriate muscular response at each site. Acceptable sites were ulnar and common peroneal nerves at wrist and fibular head respectively. In all cases, both the electrode position and expected motor response had to be correct. After the initial survey, we undertook a programme of education involving seminars, posters and instruction sheets included with nerve stimulation equipment. A laminated referenced sheet attached to all nerve stimulator equipment was designed. We then repeated our survey to evaluate the impact of this intervention. The results of our initial survey showed a poor level of knowledge of electrode placement. Of 20 staff surveyed only two correctly demonstrated primary and secondary sites for positioning electrodes and described the correct motor responses in each case. The most common error was placing electrodes over the radial aspect of the wrist. Eight correctly identified one site (either ulnar or common peroneal nerve) but were unable to suggest a secondary site and motor response. Following the programme of education there was a significant increase in the number of staff who could accurately place nerve stimulation electrodes and anticipate the correct muscle twitch response. There was a similar increase in the number of staff able to correctly place an electrode at a secondary site. Our survey showed that the placement of nerve stimulator electrodes and the interpretation of muscle twitches was inconsistent amongst ICU staff but can be significantly improved with targeted education and memory prompts.  Agency suggested that airway incidents in intensive care are associated with significant harm to patients [1] . Capnography use was not described in any of these reports. OBJECTIVES. We aimed to establish how commonly capnography was used in UK ICUs and why it has not been more widely adopted. RESULTS. 163 replies were received from total of 268 ICUs (61% response rate). Not all respondents answered every question. A total of 884 patients were connected to mechanical ventilators of which 308 (35%) were continuously monitored by capnography. Capnography utilisation for 3 common indications is shown in Fig. 1 . 74% of responders strongly agreed (Likert score[7 out of 10) that capnography improved patient safety. Respondents gave reasons for non-adoption of routine capnography as free text, these included concern over inappropriate replacement of arterial blood gas analysis, problems with staff training and expense ( Table 2 ). Our results show that capnography has not been universally adopted as a standard for monitoring in critical care, despite evidence that clinicians believe it increases patient safety. Since the adoption of capnography as an anaesthetic monitoring standard there has been a significant reduction in an anaesthetic mortality and morbidity although cause and effect is impossible to prove. Capnography is not 100% sensitive or specific for diagnosing correct airway placement, but it is still superior to reliance on clinical signs alone hence it's potential to improve airway safety. In a recent UK Intensive Care Society standards document we have strongly recommended the use of capnography during all airway placements in ICUs. Capnography is not a substitute for arterial CO2 monitoring and this may have lead to disillusionment about other potential benefits. Capnography was frequently not used, even when available. This may reflect problems with staff training. Capnography is not 100% sensitive and specific in the diagnosis of airway misplacement. There has been no system in place to share information about harm associated with airway misadventure in critical care. The risks may therefore go unrecognised. The adoption of capnography into critical care may be more expensive than in anaesthetics. This is in part because of the requirement for humidification of inspired gases. It would be very hard to train all the staff who work in ICU to reliably use capnography. CONCLUSIONS. Considering the increasing number of liver transplantations performed in our unity, we noticed a high prevalence of hepatic and kidney abnormalities as well as ascitis and bowell wall edema, allowing us to perform a more accurate diagnosis and management of this population. [1, 2] . These specify a list of Category One indications where there is the strongest evidence or consensus of expert opinion that TOE is likely to improve clinical outcome. OBJECTIVES. The aim of our study was to assess compliance with the guidelines and to survey our use of TOE for coronary bypass surgery. Bristol Royal Infirmary has maintained a prospective database of all adult cardiac surgery patients since 1996. The database was searched from 1997 (the first complete year of data collection) onwards. RESULTS. For Category One Indications there was a significant increase year on year for patients with (1) left ventricular ejection fraction\30% (p 0.002), (2) endocarditis (p 0.673), (3) congenital heart disease (p 0.007), and (4) thoracic aneurysm surgery (p 0.035). Overall, there was a significant increase year on year for the total percentage of patients where TOE was used (p 0.001), and for patients undergoing on-pump coronary bypass surgery. There was no significant increase in patients undergoing pericardial surgery, off-pump coronary bypass surgery or valve repair. CONCLUSIONS. The increasing use of TOE has been postulated as one of the reasons why mortality from cardiac surgery has decreased over the last decade (3), and it is an important factor in intraoperative decision making (4) . This study shows that in 60% of cases TOE is used in our institution for category one indications. Access and use of TOE will increase with training and investment in technology, however further research is required to prove a link between TOE use and improvement in clinical outcome. OBJECTIVES. The aim of the study was to explore the impact of ICIS on the nursing staff regarding overall satisfaction, training, time investment, communication and collaboration with physicians, user friendliness and other perceived advantages or drawbacks. The study took place in a tertiary university centre with 56 ICU beds. All ICU nurses (n = 197), participating in direct patient care, received a questionnaire 1 year after implementation of the ICIS in their ICU department (SICU, MICU, CSICU, PICU or Burn Unit). The questionnaire consisted of 204 questions divided into 10 domains. All statistical analyses were carried out with PASW Statistics 18 and statistical significance was defined as a P value equal or less than 0.05. There was a response rate of 79% (n = 156). The majority of the responders were female (73%), between 30 and 39 years (42%), with at least 5 years ICU experience (76%) and working full time (69%). 82% of the nursing staff was positive or very positive towards ICIS implementation and 70% did not want to return to the paper record. There is an impression of increased workload with ICIS (76%). Especially more time-consuming were ICU admission (86%) and discharge (58%) administration, recording of administered medication (55%) and recording of the patient nursing care (73%). 72% answered that use of the ICIS made it more difficult to obtain a general overview of the patient status. Benefits of working with an ICIS were a more accurate and complete registration (72%) and the automatic variable recording from monitors, ventilators and syringe pumps (98%). The nursing staff preferred the ICIS over the paper record for computing the fluid balance (75%) and writing the nurse shift report (80%). The collegial relationship was not impaired since the implementation of the ICIS (66%) and nurses found it even easier to pass information to a colleague from the next shift (75%) as there was more information available than before (76%). The nursing staff experienced a loss of communication between the medical-and the nursing staff since the implementation of the ICIS (75%). No relevant correlations were found between the above results and variables such as age, sex, full-or part-time work, ICU characteristics and years of ICU experience. Overall, nurses are very satisfied of working with the ICIS and the majority do not want to return to a paper-based record. Beside important benefits, this study identified several drawbacks of introducing an ICIS. However, the knowledge of these potential disadvantages may give opportunities to optimize an ICIS configuration and implementation. INTRODUCTION. Despite decreased overall use, pulmonary artery catheters (PAC) remain useful for specific indications. Although PAC cathethers have long been associated with thrombocytopenia, the precise quantitative and temporal nature of this effect has not been established. In particular with current continuous cardiac output (CCO) PACs, this effect is not known. In a previous pilot study we found that daily platelet counts (PC) indicated that PAC removal may be related with early improvement in PC. To better define the changes in PC with daily multiple PC determinations in patients with a PAC. To quantitatively estimate the extent of PC decreases in patients with a PAC. METHODS. All consecutive patients admitted over 1-year period who received an Edwards CCO PAC were evaluated. PC (reference range 150-300 9 10 9 /L) was determined trice daily, until 1 day after PAC-removal. PAC-removal time was accurately recorded and individual changes PC were determined for interpolated and compared with PAC-removal time, before 2 days before to 2 days after PAC removal. Weighed median and mean PC were calculated for at 2-h intervals for this period. RESULTS. 44 patients could be included. Both the nadir (lowest) mean PC of 91 ± 41 9 10 9 /L and the nadir median PC of 79 9 10 9 /L coincided within 2 h with PAC removal. The rate of change in PC rose by 18 ± 45 9 10 9 /L/d after PAC removal (p\0.001). CONCLUSIONS. The narrow coincidence of the lowest platelet counts and PAC-removal provides vvery strong evidence of a causal role of PAC in platelet count decreases. This direct temporal relationship points to increased consumption as the prime mechanism by which PACs affect platelet counts. The extent of PC consumption related with an in situ CCO-PAC appears considerable and will be clinically relevant when evaluating thrombocytopenia in such patients. INTRODUCTION. Percutaneous dilatational tracheostomy (PDT) is nowadays an established procedure in the management of the critically ill patient. The ease of performance and the availability of bronchoscopic control contributed to its safety in the hands of experienced operators and to its widespread acceptance. Routine post-procedural chest X-ray (CXR) has been used as a standard means of quality control for a long time. However, retrospective chart reviews and prospective observational studies have concluded that routine radiologic control is unnecessary. However, prospective randomised studies have not yet been published. OBJECTIVES. This ongoing prospective randomised controlled study addresses the issue whether routine CXR is necessary after a PDT. Critically ill patients on mechanical ventilation, in whom a tracheostomy was considered necessary based on the pre-existing standard procedure of the ICU, were included. Immediately before the PDT, patients were randomised into group 1 (routine post-procedural CXR) and group 2 (CXR only when there is an assumed or sure procedure-related complication) using an electronic randomisation list. Indications for CXR in group 2 were subcutaneous emphysema, major bleeding, false placement of the tracheal canula, marked damage to the tracheal wall, post-procedural hypoxia of unknown cause, or decision of the operating physician. PDT was carried out using the Ciaglia Blue Rhino set under bronchoscopic visualisation. RESULTS. Sixty-one patients are included until now. Mean age of the study population is 62.0 ± 14.0 years (24 females, 37 males). Indications for tracheostomy were long-term mechanical ventilation and respirator weaning. There was no major complication observed in both groups. Minor bleeding at the tracheostomy site was observed in 9 patients in group 1 and 6 patients in group 2. Tracheal ring fracture was observed in one patient per group. There was no need for CXR in group 2. Routine CXR in group 1 did not reveal any unexpected radiologic abnormality. Routine chest X-ray is unnecessary after a percutaneous dilatational tracheostomy carried out under bronchoscopic visualisation. Limiting radiologic control to those cases with presumed or observed procedural complications will contribute to reduction of costs and radiation exposure of patients and staff. INTRODUCTION. An intensive care information system (ICIS) was implemented in the 56-bed intensive care unit (ICU) of our tertiary university hospital between 2003 and 2008. The 6-bed PICU was computerized in 2008. A total of 470 PICU patients are admitted annually, median age 3 year (IQR 0.7-9) and median LOS 1.9 day (IQR 0.9-4). The exact impact of an ICIS on time allocation for different nursing activities remains unclear and has till now never been investigated in a PICU. OBJECTIVES. The objective of the study was to determine how nurses spend their time during their shift regarding the different nursing activities before and after the ICIS implementation. We were especially interested in the impact of an ICIS on time allocation for direct patient care and documentation. METHODS. Data were collected through the methodology of work sampling. Nursing activities were allocated in 7 categories: direct patient care, indirect patient care, unit-related activities, documentation, guarding and personal time, patient transport and others. Work sampling occurred before and 1 year after the implementation of the ICIS. On randomised moments data were collected 3 times per hour, throughout in total 16 shifts. Age, length of stay (LOS) and ''Nine Equivalents of nursing Manpower use Score'' (NEMS) at time of registration were registered to assure comparability between the patient groups pre-and post ICIS implementation. Kruskal-Wallis statistics (PASW Statistics 18) was used for statistical analysis and a P value of\0.05 was considered as significant. RESULTS. During the study, 41 different patients were admitted to the PICU. There was always a 1:2 nurse/patient ratio at all times of registration. A total of 561 data points before and 624 data points after ICIS implementation were recorded. INTRODUCTION. An increasing gap between the number of patients requiring mechanical ventilation and the number of skilled clinicians available is anticipated. Automated ventilation systems provide a potential solution to these problems. IntelliVent has been developed to provide fully closed-loop mechanical ventilation for passive and active breathing patients using a ventilation controler to keep EtCO 2 within expert-based ranges and an oxygenation controler to keep SpO 2 within predefined ranges. OBJECTIVES. This prospective randomized controlled study was designed to assess safety and potential benefits with IntelliVent as compared to conventional ventilation in post cardiac surgery ICU patients. In post surgery and after 15 min of stabilization the patients were connected for 4 h to a G5 ventilator (Hamilton Medical) and randomized to receive a conventional ventilation (V T , RR, FiO 2 and PEEP set according to the physician in charge and to the local protocol) or IntelliVent with automatic adjustments. V T , peak pressure, SpO 2 and EtCO 2 were continuously recorded, arterial blood gas analyzed every hour and periods of optimal, acceptable and not acceptable for V T , PPeak, EtCO 2 and SpO 2 were a priori defined. RESULTS. 60 patients have been included in the study, 30 were assigned to conventional ventilation and 30 to IntelliVent. Demographic, pre-operative and per-operative data were comparable. All the patients completed the study in both groups. 30/30(100%) versus 4/30 (13%) of the patients required manual changes of the ventilator settings during the 4 h study (P\ 0.001), corresponding to a total of 148 interventions during conventional ventilation compared to 5 interventions with IntelliVent (P\0.001). The V T /PBW at inclusion was comparable in both groups 10.3 ± 2.6 and 10.6 ± 2.7 ml/kg and was automatically reduced in the Intellivent group (8.1 ± 1.9 vs. 10.2 ± 1.5 ml/kg, P \ 0.001). 17/30 (57%) and 19/30 (63%) of the patients were ventilated with V T above 10 ml/kg of PBW at inclusion, in the control group and in the IntelliVent group respectively. After 1 h, the proportion did not change in the control group while all the patients were ventilated with V T below 10 ml/kg of PBW in the Intellivent group. Percentage of time within optimal, acceptable and not acceptable range for physiologic parameters were 85-12-3% with IntelliVent and 6-73-21% with conventional ventilation. Other outcome data did not differ. CONCLUSION. We conclude that it is possible to safely use this fully automated closed-loop system in the specific population of patients after cardiac surgery. In spite of a reduced number of interventions, the system maintained the patient within predefined target of optimal ventilation. The potential advantages of such system are the reduction of the workload associated with mechanical ventilation management and patient's safety improvement.  It is well demonstrated that the use of low tidal volumes, reduces mortality in patients with ARDS [1] and that high tidal volumes is a risk factor for ''acquired ARDS'' [2] . Also we recently have shown that the use of high tidal volumes after cardiac surgery was associated with organ dysfunction [3] . Some authors propose to provide ''protective'' ventilation with low tidal volumes for every patient on invasive mechanical ventilation [4[. It is often tedious to calculate dead space fraction (VD/Vt) and the resulting change in alveolar ventilation when lowering tidal volumes (Vt). OBJECTIVES. The aim of this study is to evaluate the accuracy of an algorithm that reduces Vt, while maintaining the alveolar ventilation based on dead space estimation. Any mechanically ventilated post-cardiac surgery patient was included if Vt was above 10.5 ml/kg of ideal body weight (IBW). Vt was then reduced to 10 ml/kg IBW while increasing the respiratory rate to target the same alveolar ventilation based on a calculation that accounts for total dead space (physiological and instrumental). Vt, respiratory rate, FiO 2 , temperature, EtCO 2 and arterial blood gases were collected at baseline and 30 min after reduction of Vt. No other respiratory parameters were modified. The primary endpoint was to maintain a stable PaCO 2 in comparison with baseline value (DPaCO 2 B 2 mmHg). We present here the preliminary results for 20 patients. Mean age was 63 ± 12 years. Mean Vt at baseline was 11.6 mL/kg IBW (8.6 mL/kg current body weight) and 8 patients had Vt above 12 mL/kg IBW. With reduction of Vt to 10 mL/kg, there was no significant change in PaCO 2 (DPaCO 2 = 0.2 mmHg, p = 0.8). Interestingly, there was a trend towards a reduction in PaO 2 (DPaO 2 = 24 mmHg, p = 0.06) and among those patients for whom Vt reduction exceeded 2 ml/kg (n = 8), there was a significant reduction in PaO 2 (DPaO 2 = 53 mmHg, p = 0.02). The dead space fraction (VD/Vt) estimated by the algorithm was 19% ± 2 compared to 22% ± 13 (p = 0.6) when calculated using Bohr equation. CONCLUSION. The use of a simple physiological algorithm seems to accurately estimate dead space in mechanically ventilated patients and could be used to automatically reduce the tidal volumes while maintaining alveolar ventilation. However, a larger population is required to confirm these preliminary results. Moreover, the use of higher PEEP may be required to counterbalance the drop in PaO 2 if low tidal volumes are used. INTRODUCTION. Improved peri-operative care of children with complex congenital heart disease has led to decreased mortality. Increasing attention is now being given to long-term outcomes including health related quality of life (HRQL). To determine the HRQL at 4 years of age in children who had cardiac surgery for congenital heart disease in the neonatal period, and compare with normative data. (2) To compare the HRQL between children with biventricular and single ventricle repairs. (3) To identify peri-operative factors associated with the HRQL. We designed a prospective cohort study including all neonates having complex surgery for congenital heart disease between July 2000 and December 2005, excluding patients with chromosomal abnormalities, extracorporeal life support and/or heart transplant. HRQL was assessed using the PedsQL TM 4.0 Generic Core Scales completed by the children's parents at the time of 4-year follow-up. Data from patients with single ventricle and biventricular repairs were compared with published normative values at the same age using t test for independent samples. To identify peri-operative factors associated with HRQL we used multiple linear regression analysis. RESULTS. Two hundred and sixty-five neonates underwent heart surgery during the study period; 48 died, 28 were excluded, 26 parents did not receive the forms, 2 refused to complete the forms, 1 was too ill to be seen, 7 were lost to follow-up, and 23 have not yet been seen, leaving 130 survivors for analysis. There was no significant difference between the Total PedsQL (P = 0.057) in children with single ventricle repairs versus biventricular repairs. The only summary score that was significantly different was physical functioning (P = 0.003), where the single ventricle patients had a lower score. When compared to normative data, children with biventricular repair had significantly lower Total PedsQL (P\0.001) and Psychosocial Health Summary (P\0.001) scores. When compared to normative data, children with single ventricle repair had significantly lower Total PedsQL (P \ 0.001), Psychosocial Health Summary (P = 0.001) and Physical Health Summary (P = 0.002) scores. In the multiple linear regression analysis we found a negative association between both age (in days) at surgery (P\0.01), and the highest lactate level between days 6 to 10 post-operative (P = 0.017) and Total PedsQL scores. CONCLUSIONS. At 4 years of age Total PedsQL and Psychosocial Health Summary scores were significantly lower in children who had surgery for congenital heart disease in the neonatal period when compared to normative data. Children with single ventricle repair also had lower Physical Health Summary scores. Older age at surgery and the highest lactate level between days 6 and 10 post-operative are risk factors associated with lower HRQL. These findings invite greater consideration of potential resources fostering HRQL. INTRODUCTION. Milrinone is a potent and potentially toxic vasoactive drug commonly administered to improve cardio-circulatory function in critically ill children. Dosing is intended to achieve therapeutic levels 100-300 ng/ml based on assumptions about drug elimination. To determine the proportion of milrinone blood levels outside the therapeutic range (100-300 ng/mL) during intravenous infusion therapy administered to critically ill children. (2) To determine if drug level variability can be predicted with current pharmacologic knowledge. A prospective cohort study was performed. Eligible children were less than 24 months of age, and received milrinone infusion after cardiac surgery with cardiopulmonary bypass. We excluded premature infants and patients receiving extracorporeal life support. Descriptive methods and binomial exact method was used to test the hypothesis that 25% of the milrinone levels are outside of the therapeutic range. The comparison between measured and predicted milrinone levels was performed with Spearman's rank correlation. RESULTS. Two-hundred and twenty milrinone levels were obtained from 63 patients with a mean age of 4.0 months. Overall 114 (51.8%, 95% CI 45-58%) milrinone blood levels were outside the therapeutic range; 78 (35.5%, 95% CI 29-42%) of the levels were sub-therapeutic, and 36 (16.4%, 95% CI 11-21%) were supra-therapeutic. At each time point the proportion of milrinone levels outside the therapeutic range was statistically significantly higher than 25% (all p values\0.02). The correlation between measured and predicted milrinone levels was weak: time 1 rho = 0.41, time 2 rho = 0.54, time 3 rho = 0.22, and time 4 rho = 0.39. CONCLUSIONS. Non-therapeutic milrinone blood levels are common in children receiving milrinone infusions after cardiac surgery for congenital heart disease, and levels cannot be predicted with published formulae. Information on the clinical impact of milrinone levels outside the therapeutic range and variables that could improve the prediction of these levels require further study. Therapeutic drug monitoring may be required to optimize milrinone therapy. INTRODUCTION. Ultrasound dilution (COud) technique determines cardiac output by measuring changes in ultrasound velocity through blood following injection of 0.9% saline warmed to body termperature [1] . This technology has been recently validated in animal and adult models [2] [3] [4] , however paediatric data remains lacking. The current gold standard for measuring cardiac output in children uses the Fick technique with measured oxygen consumption (VO 2 ). Indirect Fick measurements using dye or thermodilution is available and requires invasive central catheters. OBJECTIVES. To validate a novel method of ultrasound dilution (COstatusÓ, Transonic Systems Inc., Ithaca, NY, USA) to measure cardiac output in paediatric patients following repair of congenital heart disease. METHODS. Children undergoing biventricular repair of congenital heart disease were prospectively identified. A trans-esophageal echocardiogram was routinely used and all children with significant intracardiac shunts were excluded. Cardiac output was measured by ultrasound dilution and concurrently by Fick method using respiratory mass spectrometer (AMIS2000, Innovision A/S, Denmark) arterial and venous gases. RESULTS. Fifteen patients were recruited for study. Eleven individuals had data sets available for analysis; three patients had incomplete data sets and one patient had a significant residual shunt. Five patients had multiple studies accounting for 16 points comparison. The median age studied was 7 months (range: 6 days-14.5 years) with five neonates. Median weight was 6.7 kg (range: 2.7-80 kg). The median inotropic score was 6.6; all patients were on milrinone, three on epinephrine and two on vasopressin. No complications werde recorded. Pearson correlation between the two methods of cardiac output measurement r = 0.92 with tighter correlation at lower cardiac output. Ultrasound dilution method appears to be a safe, straightforward and reliable method for measurement of cardiac output in the postoperative neonatal and paediatric congenital heart disease group. INTRODUCTION. Controversy has surrounded outcomes from paediatric patients admitted to a general/adult intensive care unit (1). In the UK paediatric intensive care became centralised over 10 years ago. In South West England geographical distances have meant that many children are initially managed in general/adult intensive care units (ICUs). These children are then transferred to a central specialist paediatric intensive care (PICU) or remain in the general/adult ICU if stable, and if likely to be discharged within 24 h. Transfer is usually by a centralised specialist service. OBJECTIVES. To assess case mix and outcomes of all children admitted to a general/adult ICU over a 12 year period. METHODS. All children (16 years and under) admitted to ICU from January 1997 to December 2008 were obtained from the Intensive Care National Audit and Research Centre (ICNARC) database. Data was obtained for diagnosis, monitoring, discharge location and mortality. Predicted mortality were obtained using the Paediatric Risk of Mortality (PIM) criteria [2] which has been previously validated for use in a general/adult ICU [3] . INTRODUCTION. General anesthesia can cause some side-effects due to direct action of anesthetics on central nervous system (CNS), for example, postoperative cognitive dysfunction (POCD). Pathogenic influence of narcosis to CNS is proven and obvious, therefore prevention of POCD is very relevant, especially in children. OBJECTIVES. The aim of study is to research the possibility of using Mexidol (Pharmasoft, Russia) as mean of perioperative cerebral protection for prevention of POCD in children. METHODS. Design of study: prospective, randomized, clinical. Randomization: envelope method. We examined 40 children (all males) aged from 6 to 16 years old (10.8 ± 2.8 years), which were under non-urgent surgical treatment with cryptorchidism, varicocele, inguinal hernia. All children received standard total intravenous anesthesia (TIVA): propofol 2-3.5 mg/ kg per hour and phentanyl 3.5-5 mg/kg per hour. TIVA lasted from 40 to 180 min (132.7 ± 7.5 min). Patients were randomized on 2 groups: A (n = 20, for preventive cerebral protection Mexidol 100 mg was given i.m. before and 24 h after surgery); B (n = 20, without protection). Methods of examination: transcranial ultrasonography, electroencephalography (EEG) and neuropsychological study, included modifyed Bourdon test with calculating of accuracy coefficient and ''10 words'' test. Free-radical process markers were detected perioperatively. Examination took place day before and 3rd to 5th day after surgery. Quantitative data are expressed with median and standard deviation, and qualitative data with percentage. Statistical significance was determined using nonparametric Wilcockson-Mann-Whitney's criterion (u). Before the operation all data were within normal limits in both groups. Postoperative study showed obvious decrease of line flow velocity, growth of pulsation index in both groups. Growth of low-frequency activity registered in occipital, temporal and central zones during EEG were registered in all patients, and also acute waves in 10% of group B (p\0.05). In group A stabilization of amplitude and frequency parameters of EEG was detected (did not differ significantly from preoperative). In group B obvious decrease of cognitive functions was found in 60% of patients, while in group A-in 20% (p \0.05). Laboratory tests revealed a postoperative increase in free radical processes in group B compared with group A (p \ 0.05). Postoperative changes of cerebral flow and free-radical process and state of anti-oxidative system in all patients reminded experimental model of ischaemic stroke-''ischemia-reperfusion'' syndrome. Thus, oxidative stress and acceleration of apoptosis are probably important for the pathogenesis of POCD. CONCLUSIONS. Results of this study shows some efficiency of perioperative cerebral protection by use of neuroprotective medications with antioxidant action. OBJECTIVES. Does the age of transfused erythrocytes influence functional vessel density (FVD) in the skin in premature infants? METHODS. 17 preterm infants with birth weight \ 1500 g received RBC transfusion, 11 infants repeatedly from the same donor. The age of RBCs at repeated transfusions was significant higher than at the first transfusion. Using Sidestream Dark Field Imaging at the upper right arm, all preterm infants were examined before and 2, 24 and 48 h after transfusion. Images were blinded and analyzed with Microvision Analysis Software. RESULTS. FVD before first and repeated transfusion did not differ. In the 2nd, 24th and 48th hour after the treatment the Functional Vessel Density (FVD) CONCLUSIONS. Similar to the animal model longer storage of the red blood cells reduces functional vessel density in the skin of premature infants and more vessels display sluggish blood flow. If reduced donor exposition is worth the negative effects on the microcirculation is unknown.  A prospective, observational cohort study of infants (age B 6 months) after IHS was conducted from March to September 2009. Flexible bronchoscopy (FB) evaluations were obtained using a standardized protocol. The primary endpoint was development of EF (defined as need for invasive or noninvasive mechanical ventilation B48 h after primary extubation), incidence of significant FB findings and predictive value of FB (presence of compression as well as global assessment) for EF; secondary endpoints included duration of postoperative ventilatory support and readmission rates. Descriptive statistics were generated; FB findings were evaluated for test performance characteristics. Data were analyzed for univariate and multivariable predictors of EF; parameter estimates and 95% confidence intervals were reported. RESULTS. Over the study period 53 patients were enrolled, 30 patients had FB completed. The median (range) age was 78 (0-174) days and weight was 4.2 (2.3-7.9) kg; 9 (17%) were ventilated preoperatively; 13 (25%) patients had single ventricle physiology, 2 were listed for heart transplantation and 11 (21%) had defined genetic syndromes. The patients in whom FB images were obtained were not significantly different than the remaining cohort. CONCLUSIONS. Airway compression as characterized by FB is noted frequently after IHS. Overall FB assessment and presence of compression has poor sensitivity, specificity and predictive value for EF in our cohort of infants. Rather than being a causative factor for EF, it is more likely that baseline airway compression represents an additional physiologic burden in the face of comorbidities such as important residual lesions or neuromuscular weakness. INTRODUCTION. In acute respiratory distress syndrome (ARDS), lung recruitment manoeuvres (LMRs) are often required to improve oxygenation [1] . Recently, lung ultrasonography (LUS) have been applied successfully in critical care to obtain reliable and fast information at bedside [2] . OBJECTIVES. The aim of this study was to assess if LUS may be useful in correlating lung recruitment and clinical response during a LRM. METHODS. This is a retrospective series of children with ARDS, with a pO 2 /FiO 2 \200 and a LUS pattern of bilateral consolidation/atelectasis in the dependent zones. A LRM consisting in an incremental PEEP manoeuvre was performed concomitantly with LUS, in order to show the shift to a LUS pattern of lung aeration (i.e. B-and A-lines). Ventilation parameters such as PEEP and FiO 2 were registered before and after LRM. RESULTS. Nine children, with a median age of 7 months (range 2.3-18.6), were observed with LUS during a LRM. Overall, PEEP was increased from a median of 6 (range 4-8) to 15 (7-22) cmH 2 O and FiO 2 from 0.60 (0.40-1) to 0.45 (0.25-0.55). According recruitability, two groups were identified, with a comparable PEEP increase. In the highly recruitable group (6 patients), the shift to a prevalent LUS aeration pattern was associated with a better clinical response (FiO 2 reduction 25-55%). In the poorly recruitable group (3 children), a persistent LUS pattern of consolidation/atelectasis was associated with a worse clinical response (FiO 2 reduction 5-15%). There were no complications during LRMs. METHODS. One center observational study enrolling all children and infants older than 4 weeks, hospitalized in a tertiary PICU for a period longer than 28 days between 01/01/2002 and 31/12/2009. Data were extracted from patients charts and analyzed by 2 seniors reviewers. A total of 74 patients were enrolled in the study because a length of PICU stay (LOS) [28 days, male were 57%.The median age was 7 months (IQR25-75: 2-18).Close to 65% were younger than 6 months. The median LOS was 46 days (IQR25-75: 35-61). 20% of patients remained in our PICU more than 3 months. The median for length of mechanical ventilation was 37 days (IQR25-75: 27-41) and 6% of patients required more than 3 months of mechanical ventilation.Tracheostomy was performed in 21% of patients close to 39 ± 25 days of PICU stay. The majors causes of Prolonged PICU stay were upper respiratory problem, neuromuscular and central nervous disease. mortality was 40% and was higher than that registered at the same period in all PICU admissions (18%). CONCLUSIONS. In our PICU, prolonged PICU stay is associated with high morbidity and mortality. The great reasons of this problem are in the respiratory and neurological disease and represent a great challenge for our intensivists. RESULTS. Sixteen patients (9 male, 7 female), aged from 24 days to 5 years, were found to be infected (15 cases) or highly presumed to be (1 case) with the nH1N1. A severe anterior disease was noted only in 3 cases and 81% of patients were healthy before nH1N1 infection. Direct fluorescent antibody testing had a false negative rate of 43%. The respiratory illness presented were: ARDS: 31.25% of patients, Pneumonia or ALI: 50% patients, atelectasia: 12.5% and bronchoconstriction in 1 case (6.25%). Extra-respiratory illness were especially shock observed in 31.25%. One patient developed a mild rhabdomyolysis and 2 others a moderate elevation of hepatic enzymes. Leucopenia was noted in 43%. 87.5% of patients required mechanical ventilation and 31.25% required inotropic support. Two patients (12.5%) died from multi-organ failure that happened fewer days after an initial ARDS. Median PICU length of stay was 13 days (IQR 25-75: 6-17 days). Comparison of groups of patients with early Oseltamivir treatment (within 48 h of symptoms onset) or late treatment ([48 h) did not show any differences in mortality or duration of PICU stay. CONCLUSIONS. the critical novel H1N1 infection in children seems not to be associated with underlying chronic illness. Alveolar disease are the common respiratory manifestation and is associated with hypoxemic respiratory failure and prolonged mechanical ventilation. Hemodynamic disturbance is frequent. However, the higher rate and severity of the respiratory disease did not result in an increased mortality when compared with seasonal influenza and common bronchiolitis. OBJECTIVES. We aim to describe epidemiological and therapeutic caracteristics of children admitted in a pediatric intensive care unit for upper airway obstruction. We conducted a 9 year (1998-2007) retrospective study of the medical records of all children admitted to our pediatric intensive care unit for severe upper respiratory airway obstruction. This diagnosis was retained in every child presenting a respiratory distress caused by the obstruction of the upper airways from nostrils to tracheal bifurcation. Children presenting with airway obstruction complicating intubation were excluded. Demographic and clinical characteristics, cause of airway obstuction, treatment and clinical course were precised. RESULTS. Forty-five children were included (mean age 16.7 ± 19 months). Forty-eight percent of them were aged less than 1 year. The majority of them (93.3%) developed respiratory failure requiring intubation and mechanical ventilation (mean duration = 17 ± 12 days). The obstruction was congenital in 16 patients (35.5%) and acquired in 29 children (64.5%). Acquired causes were dominated by infections (14 patients). Tracheotomy was performed in 6 cases. Surgical treatment was performed in 11 patients. Three patients died (refractory hypoxemia: 2 cases, nosocomial infection: 1 case). CONCLUSIONS. The causes of severe upper respiratory airway obstruction in children are often acquired and dominated by infections. Its management require in the majority of cases admission to the pediatric intensive care unit with intubation and mechanical ventilation. A. Vijayan 1 , S. INTRODUCTION. Anomalous Left coronary artery arising from the Pulmonary artery is a very rare, but serious congenital anomaly. The unilateral homogenous opacity of the hemithorax in the chest X-ray of young infants are commonly of respiratory causes, but rarely could be of cardiac origin. OBJECTIVES. We describe a case series of rare congenital cardiac pathology mimicking severe pneumonia with potential for delayed diagnosis and thus high cardiac morbidity and mortality. A retrospective case series from two University centres in Ireland over a 7 year period. Detailed chart review clinical, laboratory and radiological variables. CASE. 1 A 5 month old female infant admitted with extensive pneumonia like picture (X-ray chest-white out on the left side), had cardiac arrest later on and never returned to spontaneous cardiac output. Post-mortem revealed a congenital coronary artery anomaly-ALCAPA. CASE. 2 5 month old male infant with extensive pneumonia like picture (X-ray chest-white on left side) and investigations revealed congenital coronary artery anomaly (ALCAPA), which was operated on with good outcome. CASE. 3 A 3 month old full term male infant who was treated for repeated bronchiolitis with Xray chest showing white out of left side had rapid respiratory worsening. Subsequently he was proved to have underlying coronary artery anomaly (ALCAPA), which was operated on and did well. All three cases mimicked extensive lower respiratory tract infections. In case 1 and 2 there were extensive homogenous opacity of the entire hemithorax creating diagnostic difficulties. The case 1 died on reaching cardiac centre, where as case 2 and 3 were operated on with favourable outcome. CONCLUSIONS. ALCAPA is a rare congenital coronary artery anomaly. The incidence of ALCAPA highly variable based on published reports. ALCAPA presenting as opacification of hemithorax on chest X-ray of critically ill infants has not been reported before. INTRODUCTION. Respiratory syncitial virus (RSV) bronchiolitis is usually associated with favorable outcome as regard to mortality and morbidity. Only few studies reported severe RSV bronchiolitis requiring mechanical ventilation, and respiratory outcome is not well described. OBJECTIVES. The aim of this study was to determine the outcome and the prognosis factors in infants hospitalized in a pediatric intensive care unit for severe RSV bronchiolitis. METHODS. We conducted a 9 year period (2001-2009) retrospective study in a series of 169 children managed in a single Pediatric Intensive Care Unit (PICU) for severe RSV bronchiolitis requiring mechanical ventilation. Outcome was analysed in terms of length of stay and mortality. RESULTS. At admission, 76.9% of the 169 infants were less than 3 months old. Prematurity at birth, congenital heart disease and antecedents of mechanical ventilation were present in 29.5, 10 and 5% of cases, respectively. Complications were dominated by pulmonary air leak (77.5%) followed by hospital acquired pneumonia (21.3%). Mortality was observed in 12 cases (7.1%). A prolonged length of stay superior to 10 days was observed in 40.2% of cases. In univariate analysis, main factors associated to prolonged length of stay were: congenital heart disease (p = 0.01), hypotrophy (p = 0.02), antecedents of mechanical ventilation (p = 0.04), occurrence of nosocomial infection (p = 0.000) and occurrence of pulmonary air leak (p = 0.015). Main factors associated to mortality were: occurrence of pulmonary air leak (p = 0.007), occurrence of nosocomial infection (p = 0.001) and prolonged mechanical ventilation (p = 0.000). CONCLUSIONS. RSV bronchiolitis associated with mechanical ventilation is particularly observed in young babies aged less than 3 months. The main factor associated to prolonged length of stay and mortality seems to be the occurrence of complications (nosocomial infection and pulmonary air leak). OBJECTIVES. We conducted a prospective observational study in order to examinate the relationship between Body Mass Index (BMI) with or without Metabolic Syndrome (MetS), ICU lenght of stay (ICU-LOS), duration of mechanical ventilation and mortality among these patients. DESIGN: Prospective observational study. SETTING: A 10-bed polyvalent ICU. PATIENTS: All patients hospitalized in the ICU over a period of 1 year and 7 months were included in the study. We divided the studied population into 4 groups by BMI values: group A: BMI between 18.5 and 24.9 (n = 369); group B1: BMI between 25 and 39.9 without MetS (n = 86); B2 group: BMI between 25 and 39.9 with MetS (n = 72); group C: BMI [ 40 (n = 42). Major exclusion criteria were: age \ 18 years, death or diagnosis of cerebral death within 24 h from ICU admission. Other data collected were demographic and ICU-related data. The Chi square test and the variance analysis were used to compare numeric data between groups. Variables that were significantly associated with ICU mortality by univariate analysis were entered in a multiple regression model, allowing the determination of independent predictors. . 620 patients were included in the study. These patients had a SOFA score included in an interquartile interval between 8 and 15. Significant differences in ICU-LOS between B1 and B2 subgroups were observed in ICU-LOS (p\0.01), duration of mechanical ventilation (p\ 0.01) and ICU mortality (p\0.01). Moreover, we found no statistically significant differences in terms of mortality between B2 and C groups, as well as between A and B1 groups (42.34%/ 45.15% vs. 16.27%/19.07%, respectively). After a multivariate analysis, a BMI[25 associated whit MetS was an independent predictive factor of a lower ICU-LOS and duration of mechanical ventilation and of an higher mortality rate. CONCLUSIONS. In our study a BMI [ 25 with MetS was significantly associated with an increase in morbidity and mortality in ICU patients. OBJECTIVES. We conducted this study to determine and compare functional status of elderly patients before and 6 months after ICU admission. After approval from the ethical committee, we performed this prospective observational study. Over a 1-year period, we included all the patients aged 80 or over admitted in our ICU and expected to stay more than 24 h. The functional status was evaluated using the Katz activities of daily living scale (ADLs) [1] and the Lawton-Brody instrumental ADL scale (iADLs) [2] . ADLs consist in 6 self-care tasks: bathing (bath), dressing (dress), toileting (toil), transferring (transf), continence (cont), feeding (feed); 1 point is granted per task executed without help. Interviews of the patients or their relatives took place at ICU admission and 6 months later (phone call). Data are presented as median [interquartile range] and were analysed using Wilcoxon test. Over a 1-year period, 95 elderly patients were recruited. Their ICU length of stay was 3 days [2] [3] [4] . Six months after ICU admission, 66 patients were still alive and only 27 patients (41%) had recovered their pre-admission ADLs and iADLs. OBJECTIVE. The objective of our study was to identify predictors of mortality in patients suffering from cancer admitted to critical care. Single-center, observational study performed between 1 January 2003 and 31 December 2007 in the critical care department of the University Hospital Dijon, France. All patients admitted to critical care and suffering from cancer were eligible for admission. Sociodemographic data, Simplified Acute Physiological Score (SAPS)-II, major organ deficiency, mortality in critical care and in-hospital were collected retrospectively. In total, 137 patients were included. Average age of patients was 64 ± 12 years, median SAPS-II at admission was 32.5. The median length of stay was 8 days. The main types of cancer were: broncho-pulmonary (82.5%), oesophageal (9.2%), ear/nose/throat (5.9%) and prostate (2.4%). The two main histologies were epidermoid carcinoma (40.1%) and adenocarcinoma (23.7%). Among patients with cancer, 83 (54.6%) had metastases. The principal reasons for admission were: acute respiratory insufficiency (n = 52, 34.2%), to undergo rigid bronchoscopy (n = 45, 29.6%), weaning off mechanical ventilation and post-operative care (n = 11, 7.2%), acute cardiac failure (n = 9, 5.9%), hemoptysis (n = 7, 4.6%), acute renal failure (n = 7, 4.6%), sepsis and septic shock (n = 6, 3.9%) and others (n = 15, 10%  To determine the factors influencing the home return probability of critically ill elderly patients 6 months after an intensive care unit (ICU) admission. We analyzed a cohort of patients aged 65 years or older admitted to an ICU. Demographic and social parameters as well as admission diagnosis, underlying diseases, severity scores, ICU stay parameters and complications were recorded. The final outcome was the place of stay (or death) 180 days after ICU admission. We tried to create a model including only directly and easely avalaible indicators during the hospital and ICU stay. During the inclusion period, among the 1,534 patients admitted in the unit we included 526 patients that were older than 65 years. Among the included patients, 72% were able to return to their home. Among the different variables used to perform a multivariate logistic regression, advanced age (in a non linear way), the length of hospital stay before the ICU admission, the acute illness severity (without age points), the diagnosis category and the complications (especially hemorragic complications and surgical complications) during the ICU stay as well as certain comorbidities, such as the presence of a cardiac pathology or a neoplasias, were independently negatively associated with a home return. CONCLUSIONS. Some interesting factors were identified in this monocenter study. Those factors are easely avalaible and could be considered for a multicenter study to build a universal prediction model for home return. Home return could be used for elderly patients as a surrogate for outcomes that are very important to the elderly but also to health politics. GRANT ACKNOWLEDGMENT. Only departemental sources. INTRODUCTION. There is a great uncertainty regarding the impact ofgender as an independent risk factor for morbidityand mortality following cardiac surgery. Most studies show that women have a higher risk for morbidity and mortality following coronary artery bypass grafting (CABG) procedures than do their male counterparts. OBJECTIVES. To measure the gender impact about morbidity and mortality in ICU from a cohort of patients subjected to cardiac surgery in Andalusian community. METHODS. Multicentre retrospective cohort study from patients subjected to cardiac surgery (CABG or valvular replacement) included in the database ARIAM registry that includes the majority of hospitals with cardiac surgery in Andalusia, from March 2008 until November 2009. We have analyzed according to sex, previous clinical and demographic data, as well as the programmed or urgent character of the surgery, complications during stay in ICU and mortality at discharge from ICU. Quantitative variables are expressed like mean ± standard deviation and qualitative ones as percentages. It has been used the Chi-square test or t-student according to necessity. Multivariate test were performed to identify independent predictor of morbidity and mortality. RESULTS. 2,453 patients (56% men) were analyzed. Surgery was programmed in 88.46%. Some data is shown on Table 1 : Mean age was higher in women than in men (65.23 ± 12 vs. 61.54 ± 12.9, p = 0.0001). Rate of mortality was of 8.2 and 58% suffered some complication, being most frequent: renal failure 29.1%, pleural effusion 19.5%, [1 l bleeding 18.7% and shock 11.8%. In univariate analysis, we found more global complications in women OR 1.38 IC95%, (1.14-1.67) p = 0.001, as well as higher mortality, OR 1.5 IC95% p = 0 (1.12-2),006. After adjusting for age, type of surgery and comorbidities, gender was not shown as an independent predictor of mortality p = 0.28 OR 1.23 IC95%, (0.84-1.8) neither of morbidity p = 0.66 OR 1,056 IC95% (0.82-1.35). CONCLUSIONS. In our serie, gender was not shown as an independent predictor of mortality or morbidity when other risk factors are adjusted. GRANT ACKNOWLEDGMENT. To health counseling of Andalusian Board for the financial support for the maintenance of the registry.  For the 299 patients included (mean age, 84 ± 4 year), hospital mortality was 55%. In the 133 hospital survivors, median survival time was 710 days (IC 95%, 499-921). Two-year mortality in hospital survivors was 53%, whereas for the same age-group in the general population it was 18%. Mortality at the hospital and within 2 years of discharge was influenced by the severity of illness at admission, but not by functional status prior to admission. SF-36 questionnaires were completed by 24 long-term survivors and by proxy respondents for 55 nonsurvivors at the time of evaluation. Physical function scores in both categories were poor when compared with reference populations; but scores for pain, emotional well-being and social function were similar. CONCLUSIONS. The severity of acute disease at admission influences mortality at the hospital and following discharge in patients aged 80 or over. Although up to 50% of patients discharged from the hospital were still alive at 2 years, their physical function was greatly altered. L. Garcia 1 , D. Monkhouse 1 1 The James Cook University Hospital, Critical Care Directorate, Middlesbrough, UK Mortality rates after discharge from intensive care have been reported to range from 6.1 to 27% (1). In The James Cook University Hospital, Middlesbrough, UK, there has been a progressive improvement in ICU mortality for the last 10 years. However, there has been little improvement in post-ICU mortality. There are many recognised determinants of death post ICU discharge, notably advanced age, poor chronic health status, prolonged severity of illness, premature and out of hours discharges (2). OBJECTIVES. The objectives were to investigate the factors contributing to death post-ICU discharge and modify our discharge strategies to minimise patient risk. A systematic review of all patients who died in hospital after ICU discharge over a 6 month period was performed. 33 discharge episodes were identified from the Ward Watcher database. Reviewers performed a detailed examination of the patients' case notes. Data collected included demographic details, ICU length of stay, maximum number of organs supported, APACHE II scores, timing of discharge, presence of Do Not Attempt Resuscitation orders, end of life care pathways and follow-up arrangements. RESULTS. 33 ICU discharge episodes culminated in death in hospital. However, 4 patients had multiple admissions to ICU. 26 deaths were identified and 20 sets of notes were retrieved.The average age of patients dying in hospital post-ICU was 70 years. The average length of stay in ICU prior to discharge was 6.7 days with an average of 2.5 organs supported. 30% patients were discharged out-of hours and only 40% of patients were discharged to a high dependency facility. 20% had an end of life care plan in place. 55% of patients had a DNAR order instituted prior to discharge.Follow up visits were performed in only 35% of patients discharged. When clinical deterioration occurred, prompt senior medical review occurred in all cases. Reasons for high post-ICU mortality appear multi-factorial. The number of unplanned discharges remains unacceptably high. This reflects pressure on critical care beds in our institution where ICU occupancy rates are in excess of 90%. The availability of HDU beds is likely to be a key determinant of discharge location. Daily follow-up may help reduce complications in patients who survive ICU. Readmission rates also remain unacceptably high. There were no major causes for concern regarding ward management post-ICU discharge in this cohort of patients. However, we acknowledge that this small sample may not reflect problems with failure to recognise clinical deterioration on the general wards. INTRODUCTION. Elderly intensive care unit (ICU) patient admissions were substantially increased in last years. Advanced age is associated with higher mortality and adverse outcomes in ICU. However, some studies, showed that is not age per se, that determinates prognosis, but other factors such as comorbilities and previous functional status before hospitalizations could be more important. OBJECTIVES. The aim of our study is to avaliate if elderly ICU patients admission is correlated with adverse outcomes in ICU. In this retrospective study, we analyzed 618 patients admitted to the ICU in the years 2008-2009, and establish 2 groups for comparison: one with the patients under 65 years, and other with C65. Data collected included gender, age, type of admission, SAPS II, APACHE II, length of hospitalization, tracheostomy and outcome at discharge from the ICU. The number of patients admitted with C65 years accounted for 50% of total admissions, with male predominance on both groups. The cause of hospitalization in the group of patients C65 years was medical (62.6%) while in the other group this cause accounts with 50.3% of patients (p value = 0.002). The average length of hospitalization was similar in the two groups (8.8 and 9.6 days for patients with \65 and C65 years, respectively), but the elderly group presents higher severity scores, with a mean APACHE II score of 15.5, SAPS II average of 37. 5 (population\65 years had respectively 11.6 and 27.0) and a higher mortality rate (24.8 vs. 14%, p value = 0.001). In the group C65 years tracheostomies were performed in 9.4% of patient (comparative in population\65 years is 5.2%), and were mainly caused by the difficulty in weaning (76%). CONCLUSIONS. The elderly population accounts for 50% of admissions and presents scores of higher severity but hospitalization with overlapping times. It was found that the ''outcome'' of the elderly population with regard to mortality and morbidity imposed by the necessity of tracheostomy is higher than the younger population. CONCLUSIONS. ICU admissions for Octogenarian patients are becoming more common. Even though a higher severity during the second period was found, mortality rates were significantly lower. Access restrictions to ICU care should not be based on advanced age. INTRODUCTION. In general population, obesity is related with increased morbidity and mortality. Nearly one-third of intensive care patients are obese, thus, understanding the consequences of obesity on critical illness has great public health importance. OBJECTIVES. The aim of the study was to assess the impact of overweight and obesity in the outcome of a critically ill patient. Our study included 130 patients admitted in the intensive care unit of a Portuguese hospital. In order to make the assessment it was used demographic data, Acute Physiology and Chronic Health Evaluation II (APACHE II), weight, height, body mass index (BMI), days of mechanical ventilation, nosocomial infections incidence and ICU mortality. The data was collected for each patient during their stay in the ICU. BMI was used to characterize nutritional state, allowing the classification in normal weight, overweight and obesity. We enrolled 84 (64.4%) male patients and 46 (35.6%) female patients with a mean age of 61.6 ± 18.7 years. Thirty-nine percent (n = 51) were normal weight, 38% (n = 49) were overweight and 17% (n = 22) were obese. As for the patients with normal weight, the mean APACHE II was 19.9 ± 8.2, the length of stay was of 14.5 days, the mean number of mechanical ventilation was of 11.0 days, the incidence of nosocomial infection was of 31.4% and mortality in the ICU was of 17.6%. In the overweight patients the mean APACHE II was 21.1 ± 7.8, the mean length of stay was of 14.6 days, the mean mechanical ventilation days was of 8.8 days, the incidence of nosocomial infection was of 22.4% and the ICU mortality was of 18.4%. As for the obese patients, their mean APACHE II was 21.6 ± 7.3, the mean length of stay was of 6.8 days, the mean mechanical ventilation days was of 12.7 days, the incidence of nosocomial infection was of 27.3% and ICU mortality was of 27.3%. In our study we did not verify statistic significance in the different groups when comparing APACHE II score, mechanical ventilation days, length of stay, and incidence of nosocomial infections or ICU mortality. Obesity is not related with the number of days of mechanical ventilation, prolonged length of stay or ICU mortality. On the present study we did not verify a relationship between obesity and the outcome in critical care patients. OBJECTIVES. To define over 80 year patients' surviving rate 1 year after oncologic postsurgical ICU admission, and to identify factors associated to mortality. We performed a retrospective study of 59 patients, aged 80 years or older, admitted to the post oncologic surgical ICU between January and December 2008. Median Age 83.5. Males/Females 35/24. ASA2/ASA3: 31/28.Urologicalcancer 6.Abdominal 28.Lung 13.Head and neck 5.Gynecological 3.Other 4.We evaluated the mortality rate after 1 year. We have also investigated the association with age, ASA status, type of malignancy and concomitant patologies. . We contacted 59 patients or their relatives (35 males-24 females) admitted in our oncologic postsurgical ICU. Median age was 83.5 year. Mortality rate founded after 1 year was16%.We did not find significant association between age and mortality (survivors' median age 83.12 vs. non survivors' median age83.88) P = 0.62. There was also no significant association between ASA status and mortality: mortality for ASA 2 status was 6% versus ASA 3 mortality of 15%: (P = 0.29). Mortality rate for pulmonary cancer was 31% whereas mortality rate for urological cancer was 34%. A borderline significant association was found comparing lung cancer versus other cancer sites (P = 0.09). Life expectancy continues to increase in western countries and this is associated with a growing request of ICU admission after oncological surgery. Few studies have been conducted to investigate mortality rates in octogenarians after 1 year from their discharging from ICU. As reported in a well conducted review [1] we found that age seems to be not an independent predictor of mortality. Comorbidity is commonly present in elderly patients but no studies reported correlations on outcome [2] , in our study we did not find any significant correspondence between pre-existing ASA status and mortality.On the other hand we have seen in our population a weak association between lung cancer and mortality. Nowadays there are still not validated scores to predict outcomes for the octogenarians and older oncological patients. More studies are needed to find tools able to improve outcome of frail patients.  There is universal concern about the growth of the elderly population and the demands that it may make of health care provision including Intensive Care. Recent work [1] suggested that admission rates of very old patients (80 years or older) increased by 5.6% per year,translating into a 72.4% increase in demand by 2015. OBJECTIVES. We were interested to discover whether retrospective analysis of our own database replicated these findings and their implications. METHODS. We extracted anonymised information from our clinical database for deciles of age for the 10 calendar years from 2000 to 2009 concerning topics of interest. Our Intensive Care unit provides high dependency and intensive care for medical and surgical patients including neurosurgery.There were 13,200 admissions,from 0 to 103 years, over 10 years,54% of which were surgical. 56 patients of 91 years or above were admitted in 10 years.They were excluded from further analysis as a group since they were considered an insignificant proportion.The overall crude ICU mortality was 16.9% and the hospital mortality 25.4%. OBJECTIVES. Our objective was to evaluate quality of life 6 months after ICU discharge of patients aged 75 years or over. Retrospective analysis of all patients aged 75 or over, alive after ICU discharge in the period of April 2004 to June 2009. Patients elected to follow-up consult have more than 48 h of ICU stay, and belong to hospital geographic area. At 6 months after discharge, EQ-5D instrument was applied. EQ-5D includes the report problems in five dimensions (mobility, self care, usual activities, pain/disconfort and anxiety/depression) a visual analogue scale (EQ VAS) and enables the calculation of an index. RESULTS. Patients older than 75 years were 23.8% of the total admitted in this period. Mean age was 80 ± 4 years (range 75-101); at admission, the mean SAPS II score was 48.8 ± 16.31; 65 patients were admitted less than 48 h in the ICU; 29% was the ICU mortality and 211 consecutive patients aged 75 or over were alive at ICU discharge. Total hospital mortality was 45.4%. 38 patients were transferred to residency hospital and 28 were lost to follow-up. At 6 weeks consult two patients have died and six patients at 6 months. The response rate to EQ-5D was 50%. Quality of life evaluations after 6 month showed significantly more problems on mobility; self care, usual activities and pain/disconfort. 39% answered that their quality of life was worse after ICU admission. CONCLUSIONS. Analysis of this subgroup of ICU patients is important because they have increasingly importance in the number of the ICU admissions. It is more difficult to see these patients in the follow-up because they have a higher morbid-mortality rate. This is a retrospective study of a single ICU. Among patients aged 75 or over who were selected to ICU admission, survivors reported significantly more problems only on the physical dimensions. These findings should encourage the admission of elderly patients in the ICU, however the results must be interpreted cautiously due to the small sample of survivors. Some of the conclusions should also be considered after adjustment to a sample of the general population matched on age. There were no differences in the presence of hyperlipidemia, previous coronary heart disease and renal disease. Women were less likely to have ST segment elevation (39 vs. 54% for men; p= 0.010). Women had a higher incidence of cardiogenic shock (Killip IV) on admission after STEMI. There were no differences in the thrombolysis in patients with STEMI. Women, after adjustment for baseline differences, did not have a different pattern of access to coronary angiography (in both ST elevation and non-ST elevation ACS), but men had greater frequency of percutaneous coronary revascularization (50.87 vs. 34.65%; p \ 0.010). Normal coronary arteries were much more common in women (20 vs. 5.6% in men; p = 0.001). Women were more likely to develop a higher in-hospital HF (32, 67 vs. 25, 94%; p \ 0.05) and in-hospital mortality (17.64 vs. 4.78%; p \ 0.001). Mortality at 1 year were similar for women and men (40.48 vs. 33.21%; p = 0.221). In the multivariate analyses, female sex and older age continued to be predictors of in-hospital mortality (odds ratios 3.04 and 1.05). CONCLUSIONS. In our study, female gender was an independent predictor of in-hospital mortality in patients with acute coronary syndrome. OBJECTIVES. The aim of this study is to document the actions taken for the reorganization of intensive care in the last 2 years by the Health Department in the state of Rio de Janeiro. A retrospective assessment of actions taken by the Health Department of Rio de Janeiro, in the last 2 years, related to intensive care, in 6 major emergency hospitals (level III) and 4 district hospitals (level II). The historical data of productivity before interventions were reviewed, and compared with actual results. Interventions: (1) resizing and rebuilding ICUs settings following the technical standards of the Brazilian's Health Ministry recommendation; (2) acquisition of new equipments; (3) staff recruitment and training conducted in partnership with the society of intensive care medicine of Rio de Janeiro; (4) establishment of a regulatory policy for allocation of ICU patients based on guidelines (5) organization of a leadership board of intensive care physicians to ensure policies implementation(6) review and standardization of supplies and medications (both quantitative and qualitative) to meet the need of the entire network of ICUs. CONCLUSIONS. The set of interventions promoted improvement in critical ill patients' care in the State of Rio de Janeiro. It was observed not only the expanding capacities, but, rather, a better use of the resources. It is important to focus on these high-cost areas and reassess the best approach to improving patient care outcomes in the most cost-effective way. INTRODUCTION. Experience of the intensive care unit team in our hospital suggested an increase in the number of referrals to the unit. The increase in workload for the unit doctors due to the high percentage of inappropriate referrals compromises the quality of patient care for patients in the unit. We would like to report the result of an audit conducted over a 6 week period to assess the referrals made to the unit. OBJECTIVES. The audit was aimed to assess the referrals made to intensive care unit and analyses the data to refine the referral system to the unit to ensure a more efficient working of the unit. Prospective audit on unplanned referrals to the unit over 6 weeks. The following data was collected the date/time of referrals/speciality referring/the medical personal referring/ whether the referring consultant was informed about the referral/the time when the patient was last reviewed by a consultant/Approprateness of refferral. Inappropriateness was decided on the criteria's of futility of treatment/associated co-morbidities/poor physiological reserves. A total of 54 cases were audited in this time period 28(51.85%) were appropriate while 26 (48.14%)were inappropraiate.The speciality referring were 28 by medicine, 12 by general surgery, 2 by orthopaedics,3 by outreach and 5 others. Our analyses of data showed that of the 26 cases that was deemed inappropriate because in seven (26.9%) patients it was thought treatment would be to futile, seven(26.9%) patients due to their associated co morbidities, and 12 (46.15%) was because of other reasons. The other reasons were mainly in nine cases because maximal ward therapy was not reached, two Coronary Care Unit was the more appropriate one because surgical treatment was more appropriate. (1).This would mean that will be out of the unit for about 11.55 h in a period of 6 weeks dealing with inappropriate workload. The proportion of inappropriate referrals made to the unit which was not discussed with the consultant washigher than average. Therfore a consultant to consultant referral system would reduce the number of inappropriate referrals. This would provide more efficient and safe care to the intensive care unit patients.  There is an accepted relationship between hospital volume and survival in some conditions, related to the ''practice makes perfect'' concept. This concept logically applies to technically demanding cases and is especially relevant in the context of a shortage of specialists; however, healthcare systems like the Spanish one based on wide coverage of intensivists may perform differently. OBJECTIVES. To determine whether ICU volume and survival correlate in the Spanish healthcare system. METHODS. Prospective survey of all patients admitted to 31 ICUs during the 3-month period in which data were collected for the validation of the Sabadell Score. At ICU discharge, we recorded demographic variables, severity score, and specific ICU treatments. Follow-up variables included ICU readmission and hospital survival. Statistics: Univariate and multivariate analyses for hospital mortality. Simple linear correlation between observed/predicted mortality and volume of cases. RESULTS. We admitted 4001 patients (mean age, 61 ± 17 year; mean risk of death, 23% (range: 14-46%). Observed hospital mortality was 19% (range: 11-35%), resulting in a ratio observed/predicted (SMR) mortality of 0.81 (range: 0.5-1.35). Among patients needing mechanical ventilation (n = 1923, 48% of the total), the predicted risk of death was 32% (range: 14-60%) and observed hospital mortality was 30% (range: 12-61%), resulting in an SMR of 0.96 (range: 0.5-1.7). We found no correlation between SMR and ICU volume in the whole population or in the group of patients under mechanical ventilation. CONCLUSIONS. We confirm the wide variability in outcome among hospitals even after adjusting for severity, but found no relationship between ICU volume and outcome. The universal intensivist coverage in our healthcare system may explain these results. Welch reported data from a UK national database (ICNARC) suggesting increased mortality with increasing deprivation in general ICU [1] and elective surgery [2] . Latour [3] explained his findings of excess mortality in the socially disadvantaged because they were sicker. Triggers for ICU admission are beyond the control of the intensivist. In order to assess social prejudice within the ICU itself, we examined SOFA scores on discharge or death as unlike APACHE scoring, SOFA provides 'sickness' data throughout a patients ICU stay. OBJECTIVES. To examine whether prejudice exists in our ICU by testing whether patients from poorer backgrounds have different SOFA scores upon discharge or death. METHODS. We examined 9,740 admissions ([3 days) between April 2000 and August 2009. In addition to admission and discharge SOFA, we examined age, sex, LOS, admission type (elective, emergency or transfer). The Carstairs index is a measure of social deprivation divided by postcode. For ease of analysis, Carstairs data were grouped into quintiles (1 = patients from poorest background). Data were analysed using Generalised Estimated Equations as there is interdependency between factors. RESULTS. Factors associated with changes in SOFA were admission type (p\0.001), LOS (p\0.001), age (p = 0.017) and admission SOFA (p\0.001). Sex and Carstairs quintile were not significant. There was no difference between the group of patients who died and the patients who survived. Although raw mortality rates were lowest in Carstairs Quintile 1 and 2, these were not statistically significant once other factors had been considered (OR 0.95, CI = 0.85 to 1.1, p = 0.87) CONCLUSIONS. Our data suggest that social status does not influence withdrawal of therapy or discharge. Patients were more likely to have a higher SOFA score on discharge if they had had elective surgery and were younger. INTRODUCTION. The recording of date and accurate time for entries in patient case notes is an essential part of documentation with implications for ongoing medical interventions, case note reviews, audits and not least for medico-legal proceedings. Time accuracy is even more important in acutely ill patients where a great number of medical interventions are carried out in a short space of time with effective treatment dependent on delivery at exact points. The timing of critical procedures is often subject to intense scrutiny to assure delivery of the highest standard of care. The recognition of the role of hand hygiene in the reduction of hospital acquired infections resulted in a ban of wristwatches for medical staff in England. Teams delivering medical care for critically ill patients therefore rely on the accurate time being displayed by wall mounted clocks and monitors. OBJECTIVES. Three audit cycles were undertaken to assess the efficacy of intervention to improve the accuracy of clocks present along the pathway traced by critically ill patients through an acute hospital. METHODS. An audit of 84 clocks displayed in acute and critical care areas was undertaken to assess baseline accuracy. A gold standard of an accuracy of ±30 s from Greenwich Mean Time was defined. A second audit was undertaken 36 h after the transition from British Summer to Greenwich Mean Time when all hospital clocks should have been reset to 1 h earlier. Written communication to key members of staff within the relevant clinical areas regarding time accuracy and the requirement to ensure clocks displayed the correct time was followed by a third audit and then installation of radio controlled clocks. Baseline results showed that 18% of the audited clocks were accurate within ±30 s and 7% had a time deviation of more than 20 min. Following the 'time change' 8% were within the gold standard and 50% showed an absolute time discrepancy of more than 20 min. After the written instruction to staff to set all clocks 15% of the time pieces reached the gold standard with 15% showing inaccuracies of more than 20 min. The installation of radio controlled clocks improved accuracy with 100% of the wall mounted clocks showed the exact time. CONCLUSIONS. Conservative passive and active interventions such as clock setting at the end of summer time or staff reminders failed to improve the accuracy of the time displayed in acute and critical care areas. The installation of radio controlled wall mounted clocks led to an improvement of accuracy of the time displayed. (1) To determine the effect of a nurse-led care pathway on hospital and critical care length of stay. (2) To identify quality of care markers such as, length of time to first enteral feeding and duration of epidural catheter placement. A goal-directed and nurse-led proforma was formulated for critical care provision in patients undergoing elective infra-renal open AAA repair, following mutlidisciplinary consultation. Data was collected during a 28-week period using a prospective proforma and by review of the patients' notes. Patients were excluded if the consultant intraoperative team did not agree that the patient was suitable for the pathway. Comparison was made with 13 patients who had undergone the same procedure, prior to introduction of the proforma. RESULTS. 16 patients entered into the pathway, 1 patient was excluded. The mean age was 70 (range 54-81), 13 were male (81%). 5 patients (31%) were smokers. All 16 patients survived to hospital discharge. The median length of hospital stay post-pathway was 10.5 days (range 6-20), pre-pathway it was 13 (range 5-19). Critical care stay was a median of 5 days both pre and post introduction of the pathway. Comparison with historic LOS data in our unit showed median LOS 15 days compared to 10.5 days post-pathway, (NS) p = 0.12 (Mann-Whitney U). 57% of patients post pathway had the epidural catheter in situ for greater than 3 days, pre-pathway it was 7 out of 13 (54%). Graph showing time to commencement of oral feeding . Mean time of admittance in ICU was 5 ± 3 days (1-13) since the appearance of symptoms. 4 patients required non-invasive ventilation (NIV) and 9 invasive mechanical ventilation (IMV). Six patients presented refractory hypoxemia and/or severe respiratory acidosis during optimal invasive ventilatory support and thus required veno-venous membrane oxygenation (ECMO). In three cases ECMO was started in other hospitals and then the patients were transferred to our center. Between October and December, H1N1-patients occupied 12% of total available ICU beds in our center corresponding to 14% of actually occupied beds; in November the same values were 21 and 24% respectively, with peak values of 35 and 41%, respectively. Overall these patients required 67 days of ECMO, 142 days of IMV and 64 days of NIV. All 13 patients survived; discharge from ICU occurred after 6 ± 2 days (4-13) in patients that did not require ECMO and 28 ± 9 days (17-40) in the other ones; they were discharged from hospital after 23 ± 3 days (12-50) and 50 ± 10 days (29-62), respectively. CONCLUSIONS. The burden of Influenza A on our center was substantial: H1N1-patients required a high-intensity level of care; their admissions occurred in a short length of time; at the peak, they occupied more than 1/3 of our ICU resources. INTRODUCTION. Admission to an intensive care unit(ICU) is expensive, costing upwards of £1800 per day. (http://www.isdscotland.org/isd/files/0708ScotTariffs.xls). After ICU discharge there are still increased costs incurred in 'step down' care and many factors will affect the duration of hospital stay post ICU [1, 2] . As the West of Scotland tertiary referral centre for pancreatic and burns surgery, we were particularly interested in determining whether length of hospital stay (LOS) post ICU discharge was correlated with admission diagnosis, age, severity of illness or a combination of these factors. To determine the LOS post ICU discharge and elicit any factors that predict prolonged hospital admission METHODS. All patients admitted to the ICU of GRI from the 1st August 08 to the 1st August 09, were identified from Wardwatcher(Critical Care Audit Ltd). Patients who did not survive or those without a hospital discharge date were excluded. Only the initial event was included in those patients with readmissions during the same hospital stay. Statistical analysis was performed using SPSS version 15.0 for Windows(SPSS Inc, Chicago, IL, USA). A total of 418 patients were admitted during the study period. After excluding deaths during ICU, readmissions and those with missing data, 293 patients were included in the data analysis. The patients' characteristics are shown in Table 1 . OBJECTIVES. The aims of this study were to evaluate the performance of ICNARC model for predicting 1-month mortality in patients of an emergency intensive care unit (ICU) in South Korea and to compare it with those of Acute Physiology and Chronic Health Evaluation (APACHE) II, adjusted APACHE (adj-APACHE) II, and Simplified Acute Physiology Score (SAPS) II. We retrospectively reviewed all admissions during 1-year period and analyzed 661 patients after excluding patients younger than 16 years (n = 7) and with inadequate data (n = 10). Performance of models for predicting 1-month mortality was assessed in terms of discrimination (area under receiver operating characteristics curve (AUC)) and calibration (Hosmer-Lemeshow goodness-of-fit test). Customization was performed in patients (n = 324) randomly selected. Then, corresponding probability of mortality was calculated for customized models (C-ICNARC, C-APACHE II, C-adj-APACHE II, and C-SAPS II). Performance of customized models was evaluated in patients (n = 337) not included in customization process. RESULTS. The observed 1-month mortality was 25.6% (169/661). The AUCs of ICNARC, APACHE II, adj-APACHE II, and SAPS II were 0.849, 0.845, 0.822, and 0.859, respectively. The AUC of adj-APACHE II was significantly smaller than those of others (p \ 0.05). All original models had poor calibrations (p\0.05). After customization, the AUCs of C-ICNARC, C-APACHE II, C-adjusted APACHE II, and C-SAPS II were 0.852, 0.849, 0.821, and 0.878, respectively. C-ICNARC and C-adj-APACHE II had perfect calibrations (p = 0.251 and p = 0.074), but C-APACHE II and C-SAPS II had poor calibrations (p\0.05). CONCLUSIONS. Considering discrimination and calibration, ICNARC model showed good performance for the prediction of 1-month mortality in patients of an emergency ICU in South Korea. OBJECTIVES. In our study we aim to assess the ability to identify the severity of ARF in the surgical intensive care unit in a tertiary care teaching hospital, using a criteria called the RIFLE score (Risk, Injury, Failure, Loss and End stage renal disease), and the effects of early identification of the vulnerable population on the outcome and mortality. INTRODUCTION. There are currently many scoring systems which use surgical outcomes and parameters to study patients with hollow viscus perforation. OBJECTIVES. The purpose of this study was to develop a scoring system to predict the morbidity and mortality of patients presenting with a hollow viscus perforation and to evaluate the accuracy of this scoring system when compared to The APACHE II in predicting mortality. We carried out a retrospective study of patients admitted in the Surgical intensive care unit undergoing emergency surgery for hollow viscus perforation between September 2008 and September 2009 in a tertiary care hospital in South India. Clinical presentations and surgical outcomes were analyzed. They were scored with the HVP score (0 to 8) which included the duration of abdominal pain, history of NSAID intake and presence of features of sepsis and dehydration. Adjusted odds ratio (OR) of each score on mortality rate and reoperation was compared with zero risk score. Receiver-operating characteristic curve analysis was used to compare the predictive ability between this score and APACHE II. The study included 59 patients with average age of 48 years (range: 17 to 73 years), and 77% (n = 44) were male. The commonest type of perforation was duodenal ulcer 68%(n = 40) Primary closure and omental graft was the most common procedure performed. Overall mortality rate was 30.5% and the reoperation rate was 22%.Among those who had a reoperation the case fatality rate was 77%.The mortality rate and reoperation rate increased progressively with increasing numbers of the score. Elevated levels of arterial lactate at admission is significantly (p \ 0.05) associated with higher reoperation and mortality. The higher the score at admission the greater the duration of mechanical ventilation and the stay in ICU. The ability of the APACHE II score and HVP score in predicting mortality in this group were compared using ROC curves. The APACHE II (AUC 0.781 ± 0.064, p = 0.001, at a value of 12 there was 68% specificity and 70% sensitivity) was found to predict mortality accurately while the HVP score (AUC 0.515 ± 0.078 p = 0.84) did not, in this group of patients. In recent studies, acute kidney injury (AKI) scoring has been shown to correlate well with mortality in the intensive care unit (ICU) 1. Although both Sequential Organ Failure Assessment(SOFA) and the Physiological and Operative Severity Score for the enUmeration of Mortality and morbidity(POSSUM) scores are known to predict mortality in patients undergoing emergency surgery for colorectal perforation (CP), their renal evaluation was not based on AKI classification. Modified SOFA and POSSUM scores based on AKI classification were expected to increase the sensitivity for predicting mortality. OBJECTIVES. To evaluate the accuracy of these scores based on AKI scoring for the prediction of hospital mortality in elderly patients requiring emergency surgery for CP. METHODS. This retrospective analysis included 43 patients aged 75 years and older who underwent emergency operation for CP and were admitted to our ICU from 2004 to 2009. We correlated AKI points to these scoring systems as shown in Table 1 below. After SOFA and POSSUM scores were obtained on admission to the ICU, AKI points were added instead of the original renal criteria in the SOFA and POSSUM scores. Accuracy was assessed by area under the receiver operating characteristic curve (AUC), and the follow-up period was 1 year. RESULTS. The median patient age was 82 (77-92) years, and 48.8% were female. Duration of mechanical ventilation, length of ICU and length of hospital stay were 4 (2-7) days, 6 (3-8) days and 33 (25-47.5) days, respectively. The 28-day mortality and overall hospital mortality were 9.3% (4 patients) and 20.9% (9 patients). The SOFA and POSSUM scores were 6 points (4-7) and 51 ± 9 points. As shown in Table 2 below, modified SOFA increase the sensitivity for predicting mortality than SOFA score. The modified POSSUM, however, did not. Data were shown as mean ± SD or median (interquartile range). CONCLUSION. Compared with the modified POSSUM score, the modified SOFA score was more simple and useful for predicting hospital mortality in elderly patients requiring emergency surgery for CP. CONCLUSIONS. The evidence of huge discrepancy between Dr Foster's spell and actual hospital ICU admission rate suggest a lack of validation of data used by Dr Foster for ICU patients. This lack of accuracy renders HSMR for ICU using Dr Foster's tool meaningless for majority of London hospital. We believe that the lack of completeness (coding of procedure and diagnosis, co-morbilities) and the quality of the data acquired by Dr Foster could cause unexpected departmental stigma and unnecessary concern to patients. INTRODUCTION. Acute coronary syndromes (ACS) are common causes of intensive care unit (ICU) admission. However, patient profile and ICU resources utilization vary worldwide. This makes crude morbidity and mortality comparisons between patients or different ICUs difficult. Prognostic models are necessary to accurately predict patients' outcomes, as benchmark for ICUs performance and for comparisons between units. Nowadays there are two kinds of prognostic models: ''non-specific'' models, like APACHE and SAPS, which were developed in a wide variety of patients, including those with ACS, and ''specific'' models, like GRACE, which was developed exclusively in a large cohort of ACS patients. To evaluate the performance of two non-specific models (SAPS 3 and APACHE IV) and of GRACE risk model to predict in-hospital mortality in a population with ACS in three private general ICUs in Brazil. OBJECTIVES. To identify predisposition conditions associated with hospital mortality in ICU patients admitted with community-acquired sepsis. METHODS. Severe sepsis and septic shock patients were systematically selected from the Portuguese ICU-admitted community-acquired sepsis prospective cohort study (SACiUCI). Predisposition variables potentially affecting the interest outcome (hospital mortality) were described and included in hypothesis tests (Chi-square tests for categorical and Mann-Whitney tests for continuous variables). A multiple logistic regression was used to obtain the best prediction of hospital mortality. Variables with p\0.2 in the univariate analysis were candidates for the final model and were kept in the model if p\0.1. Interactions were tested with the final group of variables but none was found to contribute significantly. PASW (SPSS) Ò software 18.0 was used for the statistical analysis. RESULTS. 808 patients were included (severe sepsis/septic shock = 358/450) in the study. Hospital mortality rate was 40% (321). Univariate analysis found a statistical association between mortality and gender (43% in men vs. 35% in women; p = 0. CONCLUSIONS. This study, based on a large prospective cohort, showed a group of easily identifiable pre-existing conditions associated with hospital mortality, in a clinically homogeneous sample that included exclusively patients with community-acquired sepsis. It also explored hospital mortality instead of 28-day mortality, which may further enhance our understanding on sepsis-related mortality. Finally, these findings may add to our knowledge concerning predisposing conditions for severe sepsis and septic shock related-mortality, according to PIRO concept.  The long term quality of life (QoL) and its measure has became and important endpoint on severe politrauma patients, besides the mortality, but it remains unclear on the available data. We wonder if an anatomical scoring system like the A.I.S. could be a good predictor of the quality of life on these patients [1, 2] . To compare the scores of the A.I.S on the different anatomical regions with the postinjury QoL to establish a predictor of the long term QoL on these patients. We selected from our hospital traumatic database all the patients who suffered injury on the years 2006, 2007 and 2008 with an Injury Severity Score C 15 who were alive at discharge. We calculated the scoring of the A.I.S. on the different body regions and got demographic data from all the patients; after we performed the SF-12 questionnaire as well as the HAQ-DI, obtaining their scores using the established norms. After we categorized the mental and physical components of the SF-12 and the HAQ-DI results according to disability. We analyzed the correlation of the scorings using the Spearman coefficient with the SPSS-WIN 15.0 software. From the 274 patients initially selected for the study we got 74 replied questionnaires. We found no significance on the differences between the patients who replied the questionnaires compared with those who did not reply. OBJECTIVES. We analyzed if the organ failure severity at the admission and/or the organ failure severity worsening during ICU stay are associated with in-Hospital mortality. METHODS. 116 patients were retrieved from prospective database from 2003 to 2009. The Sequential Organ Failure Assessment (SOFA) score was used. A multivariate analysis based on a backward-LR binary logistic regression model was used with in-Hospital mortality as a dependent variable and age, APACHE II, emergency room admission, sepsis, disease activity, needing for mechanical ventilation (MV), needing for renal replacement therapy (RRT), use vasoactive drugs and total SOFA at admission or maximum SOFA were used as independent variables. Two different models were built: (a) using total SOFA (evaluating the impact of organ failure at admission on the in-Hospital mortality); (b) using the maximum SOFA (evaluating the impact of organ failure evolution on the in-Hospital mortality). CONCLUSIONS. : In critically ill rheumatologic patients, the organ failure severity at admission measured through the total SOFA score and the severity of disease, measured through the APACHEII score, were not associated with in-Hospital mortality. However the organ failure worsing during the ICU stay was associated independently with in-Hospital mortality. OBJECTIVES. To study how the attenuation of the cytokine response develops during a continuous 24 h-endotoxin infusion and to investigate whether the level of ET correlates to outcome in terms of organ dysfunction. METHODS. Eighteen pigs were subjected to an endotoxin infusion for 24 h. Blood samples for cytokine analyses were taken and physiological variables registered every third hour. Endotoxin was also added to blood samples to a concentration of 10 ng mL -1 and incubated at 39°C for 2 h. TNF-a was later analysed in plasma. DTNF-a was then calculated for all time points, where lower DTNF-a value were interpreted as a higher degree of ET. Repeated measures ANOVA and Wilcoxon matched pairs test were used to analyze the temporal development of ET. Spearman correlations were calculated between DTNF-a levels at 6 h and physiological variables at 24 h. RESULTS. TNF-a values before and after ex vivo LPS stimulation had different temporal dynamics during 0-24 h, Fig. 1 . DTNF-a was lowest at 6 h, followed by a gradual increase. DTNFa was higher at 0 h than at all other time points except for 15-21 h. DTNF-a levels at 6 h correlated positively to MAP and SVRI, and negatively to cardiac index and SvO 2 at 24 h. DTNF-a did not correlate to PaO 2 /FiO 2 ratio, pulmonary compliance, base excess or creatinine clearance at 24 h. In contrast to the hypothesis that the continuous endotoxin load would have suppressed DTNF-a uniformly during the experiment, there was a biphasic course where the level of endotoxin tolerance decreased continuously from the peak at 6 h. At the time point of the peak of endotoxin tolerance, the individual level of endotoxin tolerance seems to be associated to a more hyperdynamic circulatory state with lower blood pressure and higher cardiac index at the end of the experiment. [1] . These patients have higher mortality than non-IAH patients, especially when IAH evolves into abdominal compartment syndrome (ACS) [2] . To further investigate the pathophysiologic mechanisms that accompany IAH and ACS, development of an in vivo model is necessary. OBJECTIVES. The aim of this study was to develop and compare 2 different modes of inducing IAH and ACS in pigs. METHODS. 24 pigs were allocated to 3 groups; two IAH-intervention groups and one sham group. In one IAH-intervention group IAH was induced by laparoscopic carbon dioxide (CO 2 ) insufflations causing pneumoperitoneum (n=8). In the second IAH-intervention group IAH was developed by placing 7 one-liter saline plastic bags intra-abdominally to elevate intra-abdominal pressure (IAP) (n=8). A sham group (n=8) was operated without introducing IAH; four with insertion of Veress cannula without insufflations, and 4 with empty saline bags placed intraabdominally. IAH was maintained for 12 h in the intervention groups. Invasive blood pressures, diuresis, and metabolic blood samples were monitored throughout the experiment. Organ tissue biopsies were obtained post mortem from lungs, liver, small intestine, rectus muscle and kidneys for histological examination. In both IAH groups, the pigs fulfilled the ACS criteria with bladder pressure above 20 mmHg and new injury in several organs. Organ injury in the IAH pigs was demonstrated by anuria together with an elevation of central venous pressure and the parameters: S-potassium and S-creatinine. Organ injury could not be seen by histological examination. In the CO 2 group, arterial PCO 2 was significantly increased due to absorption of CO 2 from pneumoperitoneum, causing a systemic acidosis. CONCLUSIONS. Both IAH-intervention models effectively imitate IAH and ACS. The only significant difference between the two modes of generating IAH was systemic acidosis found in the CO 2 pneumoperitoneum group. RESULT. Temperature,leukocyte values measured at the end of 2 h were found significantly higher in Group III and IV compared to Group I and II (p\0.01).Intraabdominal related sepsis was demonstrated in groups III and IV because the reproduction rate of E. coli strain injected was determined as 0% in Group I and Group II and as 100% in Group III and IV.Bacterial translocation was not determined in any of the groups.While intestinal ischemia was not determined in any of the rats in Group I and II,it was detected in 2 rats in both Group III and IV. However a significant difference wasn't detected statistically in the comparison made between intestinal ischemia rates of groups. MCS of all the rats in Group III and IV with intestinal ischemia was determined to be 1. In case of intraabdominal sepsis, no difference was determined in terms of intestinal ischemia and bacterial translocation when pneumoperitoneum was developed at 8 mmHg for 1 h, in our study.Therefore we consider that laparoscopic operations with low pressure can be used securely for both diagnosis and treatment in the event of intraabdominal related sepsis requiring emergency action but this study must be supported with clinical trials. INTRODUCTION AND OBJECTIVES. Platelet dysfunction and thrombocytopenia are common phenomenon in early sepsis, but the contribution of platelet to the pathophysiology of early sepsis remains poorly understood. The aim of the present study was to investigate the potential response of the platelet proteome to early sepsis, in order to obtain a better understanding of the role of platelets in the pathophysiology underlying early sepsis. We applied proteomic technology to analyze platelet samples of rats with early sepsis. Rats were divided into sham group and cecal ligation and puncture (CLP) group. Platelet samples were collected from Surviving rats 12 h after surgery in each group, and platelet proteins were separated with two-dimensional electrophoresis . Differentially expressed proteins were identified by mass spectrometry (MS). Using proteome analysis, a differential platelet protein expression was discovered between sham group and CLP group. 20 spots showed statistically significant differences, and a total of 12 spots were successfully identified. The significant changes in the differential proteins were confirmed by Western blotting analysis. CONCLUSIONS. By applying proteomics to a clinically relevant rat model of early sepsis we identified several platelet proteins that changed in abundance associated with platelet activation, acute phase proteins, cytoskeleton structure and energy production. Our results showed that proteomic analysis may bring us closer to achieve a comprehensive platelet bioinformation profiling in early sepsis. INTRODUCTION. Endothelial cell is a front-rank target during ischemia-reperfusion (I/R) phenomenons that occur during shock states. Ischemic phase leads to energetic failure whereas reperfusion phase involves burst of reactive oxygen species (ROS) that may be deleterious for cellular integrity. Epinephrine is frequently administered during shock state and could worsen I/ R injuries due to its capacity to enhance metabolism while oxygen is lacking. We aimed at exploring in vitro effect of epinephrine on energy balance and intracellular ROS production in a model of endothelial cells submitted to I/R. What are the effects of epinephrine on energy balance and ROS production in a model of endothelial cells submitted to ischemia-reperfusion? METHODS. Pulmonary microvascular endothelial cells were grown to confluence on glass coverslips that were placed in a perfusion chamber mounted on an inverted confocal microscope. Cells were submitted to a 40 min equilibrium period during which they were perfused with Krebs containing glucose and oxygen (mesured PO 2 =140 ± 5 mmHg). Cells were then submitted to one hour ischemia in hypoxic Krebs (measured PO 2 = 4.8 ± 2 mmHg) without glucose (and containing glycolysis inhibitor : 2-deoxyglucose). Reperfusion takes place during one hour in Krebs medium similar to equilibrium phase. Epinephrine was added at a concentraiton of 100 microM. 4 cells group were constituted: control group without I/R (CL), a group with I/R (I/R), a control goup with epinephrine (CL epi ) and a group I/R with epinephrine (I/R epi ). Cellular energy balance was explored with NAD(P)H autofluorescence (Wavelength exc /Wavelength em =364/ 400-550 nm). Intracellular ROS production during reperfusion was explored thanks to fluorescent probe MitoSOX (Wavelength exc /Wavelength em = 514/570-630 nm). In I/R group, ischemia led to a significant decrease in NAD(P)H autofluorescence intensity (expressed in % of autofluorescence value at the end of equilibrium period) : 60 ± 2 versus 97 ± 4% in CL. During reperfusion, a partial increase of NAD(P)H autofluorescence signal was observed (80 ± 2 vs. 98 ± 8% in CL) (p \ 0.0001 ANOVA). Epinephrine didn't modify NAD(P)H fluorescence variation in CL epi and I/R epi in comparison with CL and I/R respectively. During reperfusion, ROS production as judged by MitoSOX fluorescence was significantly increased in I/R group (145 ± 18 faU vs. 64 ± 9 faU in CL). Epinephrine significantly decreased ROS production as judged by MitoSOX fluorescence during reperfusion (71 ± 13 afU in I/R epi ) (p\0.05 ANOVA). INTRODUCTION. Nosocomial infection commonly occurs amongst patients in ICU [1] , and has a significant impact on morbidity and mortality. It is thought to reflect underlying immune dysfunction. Our group had previously demonstrated that neutrophil dysfunction in ICU patients was mediated by the anaphylotoxin C5a [2] . To test the hypothesis that C5a mediated neutrophil dysfunction would predict those patients at increased risk of nosocomial infection. Critically ill patients (patients requiring support of 1 or more organ systems for at least 48 h) admitted to ICU were recruited within 48 h of admission. Serial blood samples were analysed for neutrophil CD88, a cell surface marker reflecting C5a exposure which correlates strongly with neutrophil dysfunction [2] . Infection was determined by pre-defined criteria. Patient data were censored from 48 h before nosocomial infection occurred to reduce the risk of infection itself causing the effect seen. Patients were stratified into neutrophil dysfunction (low CD88, high C5a exposure) and no neutrophil dysfunction (high CD88, low C5a exposure) subgroups and the effects on acquisition of infection determined. INTRODUCTION. Animal models of renal failure are often only single hit models. In order to try to mimic the circumstances during renal i/r in sepsis, we made a study with a 2-hit model. In our study one hit was i/r, or other surgery of relevance and the second hit was the administration of LPS. OBJECTIVES. Our hypothesis was that renal i/r creates a larger inflammatory response in distant organ and a higher cytokine levels in the blood, than for example i/r of the hind legs. INTRODUCTION. Previous studies suggest that obesity is associated with inferior outcome in septic patients [1] , and that the microvascular endothelial responses play a key role in mediating sepsis morbidity and mortality [2, 3] . Furthermore, crosstalk between adipoyctes and endothelial cells is an important determinant of endothelial behavior in metabolic studies in mice. OBJECTIVES. Study the role of obesity and adipocyte-endothelial cell interactions in sepsis using a murine model. week-old C57Bl/6 male diet-induced obese (DIO) mice (60% fat diet) and agematched lean littermates (10% fat diet) were injected intraperitoneally with E. coli lipopolysaccharide (LPS) (8 mg/kg). Sixteen hours after LPS injection, mice were anesthetized, blood was withdrawn via cardiac puncture, and animals were perfused with PBS. All major organs, including inguinal fat were harvested and snap frozen. In a subset of mice survival experiments after LPS injection were performed. In vitro experiments were carried out using human endothelial cells (HUVEC) and conditioned media (CM) from an adipocyte cell line (3T3-L1) incubated with or without LPS. Compared with lean mice, endotoxemia in obese mice resulted in significantly higher circulating levels of leptin (1.9-fold, p\0.01), sVEGFR1 (1.5-fold, p\0.05) and IL-6 (3.8-fold, p\0.05) at 24 h. Endotoxemia in obese mice increased the induction of vascular bedspecific endothelial inflammatory gene expression. For instance, in obese mice P-selectin levels were significantly higher in the liver (1.7-fold), kidney (1.4-fold) and lung (1.2-fold) (p\0.05), but not in fat tissue, compared to their lean littermates. Endotoxemia resulted in increased mortality in DIO mice (p\0.02). Incubation of HUVEC with CM from LPS-treated adipocytes significantly up-regulated ICAM-1 (5.1-fold), VCAM-1 (6.1-fold), and E-selectin (5.8-fold) (p \0.0001) compared with CM from control treated adipocytes. Pre-conditioning of endothelial cells with 10 microM Bay11-7082, a pharmacological NF-kB inhibitor, completely abolished adipocyte-mediated endothelial activation. CONCLUSIONS. These data suggest that obesity increases sepsis morbidity and mortality in a mouse model. This increase is associated with endothelial activation, which is mediated at least in part, via adipocyte induced endothelial NF-kB activation. INTRODUCTION. Innate immune responses to bacteria are altered during sepsis. Little is known however as to which aspects of this response are impaired. In particular, the capacity of septic plasma to support phagocytosis remained to be determined in comparison to other groups of patients. OBJECTIVES. We sought to investigate the opsonic activity of plasma from different groups of ICU patients, in an assay using neutrophil-like target phagocytes, DMSO-differentiated HL-60 cells. The assay was carried out with plasma from (1) Septic patients; (2) Patients with non-infectious SIRS; and (3) Patients without SIRS. Heparinized blood was obtained in adult ICU patients at the time of admission. Opsonophagocytosis tests were performed by adding decomplemented plasma to neutrophillike HL-60 cells together with fluorescent E. coli bacteria. The phagocytic index was measured by flow cytometry after 20 and 50 min of incubation. RESULTS. 65 patients were included (mean age 50 ± 19 years, 64% males), sepsis (n=30), non-infectious SIRS (n=24), and non-SIRS (n=11). The phagocytic activity of neutrophils at 20 and 50 min was significantly higher with plasma obtained from septic patients as compared to that observed when plasma from non-infectious SIRS and non-SIRS patients were used (p=0.009 and p=0.03, respectively).This difference remained significant at 20 min in the analysis restricted to patients with SIRS (n=54; p=0.016). Considering the entire set of patients, the 28day mortality was higher in patients with plasma supporting higher opsonic activity at 20 and 50 min (p=0.025 and p=0.015, respectively) and at 50 min in the analysis including only patients with SIRS (p=0.048). Using an in vitro model, the phagocytic activity of human neutrophil-like cells was increased by plasma from septic patients as compared with plasma from SIRS and non-SIRS controls. Moreover, in a population of critically ill patients with SIRS, a higher plasma opsonic activity was associated with higher mortality. [1] . Mitochondrial biogenesis maintains mitochondrial function and is mediated in part by transcription factors and the transcriptional co-activator PGC-1a, a marker of mitochondrial biogenesis. Muscle PGC-1a levels were significantly higher in survivors of critical illness [2] . In a rodent model of sepsis we thus investigated the relationship between severity of outcome and transcript levels of PGC-1a. OBJECTIVES. To determine PGC-1a mRNA levels in different organs and timepoints in a rodent model of sepsis. METHODS. Liver, kidney and skeletal muscle were taken from a fluid-resuscitated rat model of sepsis; animals were divided into predicted survivors and non-survivors at 72 h based on echocardiography-derived stroke volumes [submitted for publication]. mRNA levels for PGC-1a were determined by qPCR and standardised to ActB mRNA. Data were analysed for significance using two-way ANOVA and tested for normality (Kolmogorov-Smirnov). Independent t tests were used to compare samples between groups. ARBITRARY METHODS. 24 anesthetized pigs [40.1 ± 4.1 kg] were randomly assigned (n=6 per group) to a non-septic control group (CG) or one of three groups in which resuscitation was initiated 6 (DT-6 h), 12 (DT-12 h) or 24 (DT-24 h) hours after induction of fecal peritonitis (instillation of 2 g/kg autologous feces). In the treatment groups resuscitation was performed for 48 h according to the Surviving Sepsis Campaign. During the study, all animals received a basal infusion (3 mL/kg/h) of Ringer's Lactate (RL) and glucose 50%. Additionally, bolus of 150 mL RL and 6% hydroxyethyl starch (130/0.4), norepinephrine and dobutamine were administered when necessary to reach a mean arterial pressure (MAP) C60 mmHg, mixed venous oxygen saturation C50%, urine output C0.5 mL/kg/h and arterial lactate level\2.0 mmol/L. Cardiovascular dysfunction was defined as MAP\60 mmHg or norepinephrine or dobutamine used in any dose. Pulmonary (paO 2 /FiO 2 ), renal (creatinine), hepatic (bilirubin), and haematological (platelets) dysfunctions were defined as [25% deviation from the highest or lowest baseline value of the current study population. Two of six animals in both the DT-12 h and the DT-24 h group died during the study. Allocation to groups DT-12 h and DT-24 h was associated with a higher incidence of new organ dysfunction during the study period and higher arterial lactate concentrations (Table 1) . Pigs in the DT-12 h and DT-24 h group tended to received more fluids, norepinephrine and dobutamine than those in the CG and DT-6 h group (Table 2) . CONCLUSIONS. These preliminary data suggest that 6 h from onset of sepsis to start of resuscitation may be the critical limit for prevention of organ dysfunction and mortality during the following 48 h. OBJECTIVES. To analyze the involvement of the NLRP3 inflammasome in ventilator-induced lung injury (VILI). Wild-type (WT) C57BL/6, NLRP3 knockout (KO) and apoptosis-associated speck-like protein (ASC) KO mice were tracheotomized and ventilated for 5 h with a high tidal volume (V T *15 ml/kg), known to cause VILI. Spontaneously breathing mice served as controls. In addition, mice were treated with the NLRP3 inflammasome blocker glibenclamide (500 mg/kg i.p.) or vehicle (10% DMSO) 1 h before MV. NLRP3 inflammasome gene expression in lung tissue and the presence of NLRP3 inflammasome ligands in bronchoalveolar lavage fluid (BALF) were analyzed. Endpoints of VILI were relative lung weights, neutrophil influx, total protein in BALF and pulmonary and plasma cyto-and chemokine levels. Uric acid, an important ligand for the NLRP3 inflammasome was released in BALF of mechanically ventilated mice. mRNA of NLRP3 and ASC, both proteins of the NLRP3 inflammasome complex, were upregulated due to MV. After 5 h of MV, NLRP3 and ASC KO mice displayed significantly lower relative lung weights, neutrophil influx and pulmonary and plasma IL-6 levels when compared to WT mice. In line, NLRP3 inflammasome blockage with glibenclamide resulted in reduced relative lung weights, neutrophil influx, total protein and IL-6 levels in BALF when compared to the vehicle treated group. CONCLUSIONS. Ventilator-induced lung injury is mediated by the NLRP3 inflammasome and blockage of NLRP3 inflammasome activation attenuates lung inflammation induced by MV. GRANT ACKNOWLEDGMENT. C.W.Wieland was sponsored by The Netherlands Organization for Scientific Research (NWO).  We have detected a wide variability in practice regarding diagnostic criteria and prevention of AKI in Spanish ICUs. The application of consensus recommendations and stratification scores for AKI (ADQI or AKIN) is still low in our Units. The use of RRT is more standardized and seems to raise more concern to our intensivists than AKI. GRANT ACKNOWLEDGMENT. The observed changes in CI, EVLWi and GEDVi were more pronounced when catheters were in wrong position. PiCCO calibration via a CVL in the femoral vein (94 measurements in 9 pts) resulted in a significant increase (or overestimation) of all three parameters, regardless of whether the CVVH was running or stopped (Table) . The overall IAP was 11.2 ± 4.1 mmHg and higher in pts with wrong catheter position: 12.9 ± 2.8. In critically ill patients treated with CVVH, hemodynamic parameters obtained by transpulmonary TD with PiCCO can be influenced. This prospective study shows a significant decrease in CI and GEDVi during CVVH, regardless of catheter position, while EVLWi increased. We hypothesize that this may be due (amongst other causes) to the relative position of CVL and dialysis catheters. Patient management should be based on parameters obtained without CVVH (ideally before start or after restitution). Moreover, irrespective of CVVH, PiCCO calibration via a femoral CVL increases CI, EVLWi and GEDVi significantly and thus cannot be recommended. We hypothesize that this may be influenced by IAP and venous return hence altering mean transit times. CONCLUSIONS. We confirm ARF as an independent factor for mortality. We found no differences in mortality related to fluid therapy, use of diuretics, or continuous versus intermittent RRT. We found no benefits for high flow RRT, but higher mortality for early RRT compared to standard timing. Earlier studies have demonstrated that that the requirement for renal replacement is in itself a risk factor for poor outcome in Intensive care.Primary pathology, severity of critical illness, requirement for respiratory support and vassopressors are independent risk factors for poor outcome in patients requiring renal support. OBJECTIVES. • To review the demography of patients who required renal replacement therapy and their outcome. • To identify the primary pathology and severity of illness in these patients. • To correlate the presence of co morbid factors and outcome. • To identify the risk factors for poor outcomes in these patients. • To study special cases and their outcome. and duration of organ support were higher in non survivors. A higher rate of mortality was observed with some co-morbidities and certain groups of medical and surgical patients. CONCLUSIONS. A wide spectrum of demographic, pathophysiological factors and need for medical or surgical interventions influence outcome in patients requiring renal replacement therapy.Renal replacement therapyby itself is also an independent risk factor for poor outcome in intensive care. OBJECTIVES. We presume that long time treatment with CRRT produces high serum concentration of ionized calcium, as concentration of calcium in the dialysis bags is 1.75 mmol/l (Hemosol Ò and Prismasol Ò ), causing a positive balance of calcium during CRRT. In some cases substitution of those bags to 0 mmol/L calcium concentration (Prismocal Ò) is needed to normalize ionized calcium. METHODS. We conducted a retrospective study with patients admitted in the ICU of a tertiary care academic hospital who were treated with CRRT using commercial dialysis bags between December 2008 and November 2009, during at least 24 consecutive hours. The CRRT techniques used were veno-venous hemofiltration and hemodialysis, using a Prismaflex Ò system. Bags substitution was performed when serum calcium concentration reached 1.21 mMol/L to prevent from hypercalcemia. RESULTS. 30 consecutive patients were included in the study. 60% were male, median age 66.73 (±9.6), APACHE 26.57 (±8.74) and SAP 52.76 (±18.03), maximum ionized calcium 1.26 (±0.13) and maximum total calcium 8.08 (±2.14). Range of duration of CRRT was between 1 and 35 days. 50% of patients required change to dialysis bags without calcium, 80% before 6 days of CRRT. 73% of these patients presented ionized calcium over 1.25 mMol/L, 47% over 1.30 mMol/L and 27% over 1.35 mMol/L. Mortality rate was 66%, no significant differences between patients who needed bag susbstitution and patients who did not. OBJECTIVES. The aim of this study is to evaluate the usefulness of ultrafiltration coefficient in this setting. Intensive Care Unit of a terciary hospital. The operating data and alarms were collected directly from monitor dialysis register (Prismaflex Ò ). Filters with the AN69 Ò membrane were used (ultrafiltration coefficient of unused filter described by manufacturer is 22 ml/h/ mmHg). We calculated the TMP and ultrafiltration coefficient 60 and 120 min before removing the filter (T 1 and T 2 respectively). [5, 6] . Although the use of GCS is a crude marker compared with Cerebral Performance Category (CPC) Score used within the Utstein definition [7] , we have nevertheless seen an improvement in the neurological outcome of the TH survivors at ICU discharge since the introduction of the local guideline and IVCD. Current numbers are small therefore future audits are required to assess a real trend in the neurological outcome including CPC score to compare our data with the published evidence. OBJECTIVES. This study aims to determine if anticoagulation status affects the occurrence of cerebrovascular events in patients with VAD. We performed an observational study in 123 consecutive patients with VAD implantation to determine the relation between coagulation status and the occurrence of thromboembolic stroke. The occurrence of thromboembolic stroke was assessed by means of screening patient correspondence, patient charts and reviewing radiological investigations. Coagulation status was retrieved from patients at the moment of the first ischemic stroke and 2 weeks preceding the event and compared with controls that were censored at the time of heart transplantation, VAD explantation, or death. [1] . As certain post-resuscitation interventions have been shown to influence outcome, the Intensive Care Society has published guidelines on post resuscitation care [2] . OBJECTIVES. This audit was conducted to assess our compliance with these guidelines. Cardiac arrest admissions were identified from ICNARC data over an 18 month period. Patient demographics, as well as information concerning pre-morbid health, cause and type of arrest and pre admission Glasgow Coma Scores (GCS) were recorded. Patient observations and management were obtained from ICU charts. INTRODUCTION. Therapeutic mild hypothermia has been advocated to reduce ischemia/ reperfusion injury in order to minimize cerebral and myocardial damage [1] . However, anecdotal reports of increased lactate levels during hypothermia might indicate ongoing anaerobic tissue metabolism [2] . OBJECTIVES. Aim of this study is to describe the evolution of arterial lactate levels during steady-state hypothermia after resuscitation and to correlate arterial lactate levels with global hemodynamic variables. We performed a single centre retrospective study in a 22-bed mixed ICU. 62 Patients after cardiac arrest with return of spontaneous circulation were included, in case invasive hemodynamic monitoring was started immediately after ICU admission. Monitoring was performed with a pulmonary artery catheter (Vigilance Ò ) or with arterial pulse contour analysis (PiCCO Ò ). Therapeutic endpoints were a mean arterial pressure C75 mmHg and central/mixed venous oxygen saturation (S(c)v02) C70%. In case these endpoints were not fulfilled, a fluid bolus of 250 ml was administered up to a point were left ventricular stroke volume rose\10%. Administration of dopamine was titrated on cardiac index in combination with central venous oxygen saturation and norepinephrine was administered in case of a persistent hypotension despite the first 2 steps. Primary outcome was the change in arterial lactate levels at the beginning and end of a 24 h steady state at 33°C. Secondary outcome were correlations between the change in arterial lactate and indices of global perfusion. Statistical comparison for paired data was performed with applicable tests; data are expressed as median (IQR). Correlation coefficients for non-parametric data are expressed as spearman's rho (r s ).  Retrospective study of all unconscious OHCA survivors from 2002 to 2008 treated with therapeutic hypothermia in our ICU, age C 15 years with no upper age limit and who fulfilled the HACA study (2) inclusion criteria: bystander-witnessed arrest, presumed cardiac cause of arrest, ventricular fibrillation as initial rhythm, interval from collapse to return of spontaneous circulation (ROSC) no more than 60 min, maximum intervals of 5-15 min from collapse to arrival of the ambulance and start of resuscitation. Good cerebral outcome was defined as a Glasgow-Pittsburgh Cerebral Performance Category 1-2 (3) and the relationship to various factors (Table 1) presented as odds ratio (OR) from a multivariate logistic regression analysis.  Outcome studies in patients with anoxic-ischemic encephalopathy focus on the early and reliable prediction of a persistent vegetative state or severe disability. The currently used outcome predictors are based on studies that were performed before the use of mild therapeutic hypothermia. A recent web-based survey among in the ICUs in the Netherlands demonstrated that the vast majority of physicians use clinical neurological examination (92%) and the median nerve SSEP (94%) for the prediction of neurological outcome [1] . OBJECTIVES. Aim of the present study was to determine the effect of mild therapeutic hypothermia on clinical and electrophysiological outcome parameters. We conducted a retrospective single centre cohort study in comatose patients after cardiac arrest who were admitted to the ICU and treated with mild therapeutic hypothermia for 24 h. A favourable outcome was defined as a Glasgow Outcome Score (GOS) of 4 and 5.  Discharge ratio of patients after cardiac arrest is low and some of these patients have permanent brain injury. There are several prediction scales and parameters for prognosis after cardiac arrest. One of these scales is BrANOS which consists of duration of cardiac arrest, Glasgow coma scale score and Hounsfield unit measured on cranial CT scan. BrANOS is a reliable predictor of neurological outcome following cardiac arrest. OBJECTIVES. The objective of this study is to investigate the effectiveness of BrANOS on predicting mortality and disability after cardiac arrest. METHODS. We investigated the cardiac arrest patients who were hospitalized in our ICU within 2 year period. Inclusion criteria were age over 18 years old, survival of more than 24 h after cardiac arrest and availability of cranial CT. We recorded age, sex, diagnosis, duration of cardiac arrest and hospital stay, mortality, Glasgow outcome score (GOS) and BrANOS score. CONCLUSIONS. Our data suggest that survival at ICU discharge and at 6 months may be similar for patients who underwent early therapeutic hypothermia and for those who underwent late therapeutic hypothermia. Furthermore, the early initiation of TH was not associated with improved long-term neurologic outcomes. CONCLUSIONS. The survivors whit mild-moderate and severe traumatic brain injury showed better GOS level and physiologic and functional capacity, being more independent in their way of life after 1 year follow-up from discharge of ICU. METHODS. 20 patients with ICH with GCS B 9 were randomized into 2 groups at the 1st day of postoperative (p/o) period. 10 patients were feed with standard enteral formula (enteral admixtures (60-75 g of protein, 1,500 ccal in 1 l) (Control group). 10 patients received enteral nutrition with high-protein admixture (Fresubin-HP-energy-75 g of protein, 1,500 ccal in 1 l) with enteral glutamine supplementation (Intestamin-30 g of glutamine in 500 ml) (Glutamine group). Energy expendure was estimated by Harris-Benedict formula, hypercatabolism severity-by nitrogen balance calculation and determination of blood transthyretin level. In case of high energy requirements and severe hypermetabolism parenteral nutrition was used according to intrahospital protocol. We recorded and compared between groups infection complications incidence, gastrointestinal function and hypercatabolism severity dynamics. OBJECTIVES. We investigated whether lung echography (LE) could detect pneumothorax in trauma victims. One hundred trauma patients (65 males, 35 ± 15 years old, body mass index = 23.9 ± 6.1 kg/m 2 , APACHE II score = 18 ± 4) who were admitted in the intensive care unit (ICU) were studied. Mean period of hospitalization was 42 ± 17 days. All patients were intubated and mechanically ventilated. Prior to admission, pneumothorax, hemothorax and hemo-pneumothorax were identified clinically and by means of radiography in 12, 15 and 25% of cases, respectively. In the ICU, LE was applied on a daily basis to test the progress of preexisting pneumothorax and identify possible new cases. LE recordings were compared to standard radiography and chest CT scan findings. We utilized a Philips XD11 XE ultrasound device (Philips, Bothell, USA) equipped with a convex 5-7 MHz and a linear 10-12 MHz transducer to perform LE. Using anterior and posterior-axillary lines as anatomical landmarks, each chest wall was divided into six lung regions for scanning: upper and lower parts of the anterior, upper and lower parts of the lateral, and upper and lower parts of the posterior chest wall. Pneumothorax was diagnosed by LE if any of the following lung patterns could be observed: absent lung sliding and horizontal A-lines (barcode sign) ( Figure 1 ) and the lung point sign ( Figure 2 ). . New cases of pneumothorax were identified by LE in 65% of patients in the ICU. These were attributed to complications of mechanical ventilation (30%) and to surgical complications (70%), such as misplaced thoracostomy tubes, and severe chest trauma. Associated pleural effusions were recorded in 75% of cases. The incidence of LE signs in cases with pneumothorax was: absent lung sliding (80%), barcode sign (85%), and lung point sign (15%). The latter was mainly associated of with smaller sized pneumothorax (r=0.8) and/or pleural effusion (r=0.7). LE was strongly correlated to standard radiography and computed tomography findings (r=0.8, r=0.9, respectively). LE exhibited 99% sensitivity and 100% specificity in detecting pneumothorax. CONCLUSIONS. LE is a powerful by the bed tool in detecting pneumothorax.  Dexmedetomidine is a selective alpha-2 adrenergic receptor against that exhibits sedative, anxiolytic, and sympatholytic effects without respiratory-drive depression,and reduces heart rate and blood pressure dose-dependently. OBJECTIVES. We investigated whether it also has ability to attenuate airway and circulatory reflexes in critical patients with blind nasotrachea intubation. METHODS. Fifty-eight ASA III-IV patients in ICU received a blind nasotrachea intubation. Five minutes before adequate preparation of blind nasotrachea intubation, they were randomly allocated to receive either dexmedetomidine 0.5 lg/kg (Group D)(n=29) or saline placebo (Group P) (n=29)intravenously over 60 s in a double-blind design.The blinded anaesthetist completed all procedures in all the patients, and the number of coughs per patient was continuously monitored for 15 min after intubation; coughing was evaluated on a 4-point scale. Any laryngospasm, bronchospasm or desaturation was recorded. Heart rate (HR) and systolic and diastolic blood pressure (SAP, DAP) were measured before, during and after tracheal intubation. The time of tracheal intubation and the successful rate of the intubations were recorded. RESULTS. Median coughing scores were 1 (1-3) in Group D and 2 (1-4) in Group P (P\0.05), but there were no differences between the groups in the incidence of breath holding or desaturation. HR, SAP and DAP increased at extubation in both groups (P\0.05), but the increase was less significant with dexmedetomidine. The time of tracheal intubation in Group D was less than in Group P, and the successful rate of tracheal intubation in Group D was higher than in Group P (P\0.05). CONCLUSIONS. These findings suggest that a single-dose bolus injection of dexmedetomidine before blind nasotrachea intubation attenuates airway-circulatory reflexes during intubation. OBJECTIVES. Valuable lessons can be learned from the evacuation of a hospital. Retrospective data analysis of patients' evacuation, treatment, and transport, as well as resources and logistics used. At 11:26 p.m. on May 24, 2004, local firefighters, EMS paramedics, ambulance officers, physicians, and a ''rapid response unit'' of the German Red Cross were sent on scene. The initial assessment was that one of three buildings of the hospital was fully engaged in flames. The hospital staff had already started a horizontal evacuation of approximately 70 patients from the burning building to one adjacent. When the chief emergency physician arrived on scene, he began patient triage by determining victim's conditions, and organized the scene by separation into 3 sections, (1) inhouse, (2) outside, and (3) transport section, each section lead by a physician. Additional medical personnel were requested, and a second triage was performed to update the situation. The total duration of the evacuation was 7 h 46 min. One hundred nineteen patients were triaged into internationally used categories (I = 0, II = 7, III = 112, IV/V = 0 patients). The seven patients in category II suffered smoke inhalation injury, without burns. Of the 119 patients, 29 were transferred to a different building of the hospital (horizontal evacuation), 90 were transported to other hospitals within a 30 km radius. The number of personnel used was 154 (14 emergency physicians, 19 paramedics, and 121 EMTs), using 2 mobile intensive care units, one rescue helicopter staffed with a physician, as well as 15 ambulances and 31 other vehicles from the Red Cross fleet. CONCLUSIONS. Difficulties faced on scene were (1) a lack of patients' paper records, aggravating the situation by a lack of knowledge of patients history, diagnosis, and medication, and (2) the initial horizontal evacuation was confused and uncoordinated, resulting in a lack of knowledge on the amount of patients that had been evacuated by nursing staff. However, with arrival of the chief emergency physician, an established disaster plan and logistics were initiated, which proved crucial for the final success of the evacuation. The critical lessons learned from this experience, included the following: 1. appointment of a chief emergency physician; 2. appointment of section commanders; 3. adequate communication systems on-scene as well as with the dispatch center, organizing hospital beds in surrounding counties; 4. patient assignment to ambulances and helicopters; 5. identification and assignment of transport personnel responsible for patient care, and 6. triage, including patient registration. The authors encourage physicians, as essential members of the health care team, to become prepared to respond to disasters. Patients admitted in Intensive Care Unit (ICU) from general wards are more severe and have a higher mortality than those admitted from emergency department as reported [1] . The majority of them develop signs of instability (e.g. tachypnea, tachycardia, hypotension, decreased oxygen saturation and change in conscious state) several hours before ICU admission. Considering this fact and that in-hospital cardiac arrests and unexpected deaths are usually preceded by warning signs, immediate on site intervention by specialists may be effective. This gave an impulse to medical emergency team (MET) implementation, which has been shown to decrease cardiac arrest, morbidity and mortality in several hospitals. OBJECTIVES AND METHODS. In order to verify if the same was true in our hospital and to determine if there was a need for MET, we prospectively collected all non elective ICU admissions of already hospitalized patients (general wards) and of patients remaining more than 3 h in emergency department (considered hospitalized). Instability criteria leading to MET call correspond to those described in the literature. The delay between the development of one criterion and ICU admission was registered. RESULTS. During an observation period of 12 months, 321 patients with our MET criteria were admitted to ICU. 88 patients came from the emergency department, 115 from the surgical and 113 from the medical ward. 65% were male. The median age was 65 years (range 17-89). The delay from MET criteria development to ICU admission was higher than 8 h in 155 patients, with a median delay of 32 h and a range of 8.4 h to 10 days. For the remaining 166 patients, an early MET criterion was present up to 8 h (median delay 3 h) before ICU admission. These results are quite concordant with the data reported in the literature (ref [1] [2] [3] [4] [5] [6] [7] [8] . 122 patients presented signs of sepsis or septic shock, 70 patients a respiratory failure, 58 patients a cardiac emergency. Cardiac arrest represent 5% of our collective of patients. CONCLUSIONS. Similar to others observations, the majority of hospitalized patients admitted on emergency basis in our ICU have warning signs lasting for several hours. More than half of them were unstable for more than 8 h. This shows there is plenty of time for early acute management by dedicated and specialized team such as MET. However, further studies are required to determine if MET implementation can reduce in-hospital cardiac arrests and influence the morbidity, the length of stay and the mortality. Trans venous pacing in the critically ill patient is commonly done for life threatening bradyarrythmias. This procedure is ideally done under fluoroscopic guidance in the cardiac catheter lab, or by the bedside with the ecg leads as a guide for placement of the transvenous pacing wire. Ultrasound guidance remains a very underused tool for emergency purposes and can be used quite effectively for the above procedure. There are also many safety issues and medicolegal issues with blind procedures in the intensive care unit. The use of ultrasound has now found mention in acls protocols(pea differential diagnosis) and also the fast/e-fast survey for a trauma patient. OBJECTIVES. To confirm that ultrasound placement of trans venous pacing wire is a safer and more definite method than previously used methods METHODS. Ultrasound machine, sonosite was used for the above linear high frequency probe was used. the pacing wire was introduced via the femoral route, jugular and subclavian route in patients views utilised-subcostal 4 chamber view, view for the inferior vena cava, apical 4 chamber view, parasternal long axis views were all used to get a better visualisation of the anatomy during the insertion process. The tip of the pacing wire in the right ventricle when visualised was taken as a successful placement. A total 14 patients were included, who presented to the ICU requiring tvp (transvenous pacing) age of patients varied from 27 to 80 years. 4 patients had complete heart block with shock, the others included all types of bradycardic rhythms and pea's 10 of the ''pacing sheaths were inserted via jugular and 4 via femoral route. Pacing was successful in all patients. 1 patient required repositioning of wire. RESULTS. Trans venous pacing under sonographic guidance was successfully performed in more than 90% of patients. Pacing wire CONCLUSIONS. Ultrasound guided transvenous pacing is a safer, easier and equally effective way to perform pacing in the critically ill patient. The most important advantage is it can be easily done at the bedside of the patient. The possible drawback is some level of proficiency and familiarity with echo is required. The obese patient, or the patient with copd could sometimes pose problems for visualisation of the anatomy REFERENCE(S). Emergency transvenous cardiac pacing placement using ultrasound guidance. Aguilera PA, Durham BA. INTRODUCTION. Major trauma is associated with complex hemodynamic and microcirculatory changes. Volume depletion resulting from blood loss and inflammation triggered by tissue trauma, besides the systemic tissue ischemia, are the main factors leading to these changes. Hypertonic saline hyperoncotic (HHS) and pentoxifylline has been proposed as options in the resuscitation of hemorrhagic shock, showing the effect of modulation of the inflammatory response and efficacy in the restoration of hemodynamic parameters OBJECTIVES. To evaluate the progression of inflammatory mediators and oxidative burst during 4 h after initial resuscitation in the treatment of hemorrhagic shock, with three different solutions: Ringer lactate, hypertonic hyperoncotic solution (HHS) and hypertonic hyperoncotic solution associated with pentoxifylline (PTX) METHODS. anesthetized and instrumented 20 Landrace pigs of 28-32 kg were randomized to Sham group (5 animals-only anesthetized and monitored) and 15 submitted to hemorrhagic shock. The mean arterial pressure (MAP) was maintained at 40 mmHg by 30 min. After shock 5 animals were treated with 32 ml/kg Ringer's lactate (RL group), 5 animals with 4 ml/kg HHS (HHS group) and 5 animals with 4 ml/kg of HHS ? 25 mg/kg pentoxifylline. In addition to systemic and regional hemodynamic parameters, we determine the oxidative burst of circulating neutrophils and inflammatory mediators (TNF-alpha, interleukin 1b, interleukin 6 and interleukin 10). RESULTS. The animals in the HHS and PTX groups showed a significant decrease in oxidative burst after resuscitation, unlike the RL group, which showed an opposite (p\0.001 for HHS vs. RL and PTX vs. RL after treatment). TNF alpha and interleukins also showed stable values in the groups treated with HHS and PTX, whereas in animals treated with RL was significant increase of these mediators. The HHS was ineffective in normalizing some regional and systemic hemodynamic variables (p \ 0.05 after treatment at T0 for HHS vs. RL for Portal vein flow index), which improved when combined with pentoxifylline CONCLUSIONS. In an experimental model of hemorrhagic shock during the observation of 4 h, hypertonic saline hyperoncotic used as a solution for volume replacement in volume 4 ml/ kg weight, shown to cause less activation of neutrophils and decreased production of inflammatory mediators when compared to Ringer's lactate. When coupled with pentoxifylline 25 mg/ kg effects on modulation of inflammatory response were similar. INTRODUCTION. Preeclampsia is a serious medical disorder (hypertension, proteinuria and oedema) of a pregnant with significant maternal and fetal morbidity and mortality. Posterior Reversible Encephalopathy Syndrome (PRES) is a neuroclinical pathology expressed by cortical and subcortical changes localised in posterior regions of cerebral hemispheres and cerebellum. A rapidly increased blood pressure altering autoregulation of cerebral blood flow produces cerebral oedema and ischaemia of brain tissue. Controversial issue is the use of subarachnoid block for Caesarean anaesthesia in this patients. The major concern is the low cerebral perfusion with exaggerated hypotension with onset of the block. OBJECTIVES. In this report we present three cases of preeclampsia followed with cortical blindness after cesarean sectio. METHODS. Severe preeclampsia with cortical blindness patients admitted to ICU were assessed including demographic characteristics, hemodynamic parameters, anesthesia techniques, blindness time and outcomes. RESULTS. Three women's files were investigated with severe preeclampsia and blindness in ICU. The common demographics of all women were young ages (19, 21, 22, respectively), high blood pressures (systolic blood pressures [180 mmHg), delivery of first gestation and anesthesia techniques (spinal anesthesia with bupivacaine, 0.05%). Only one of them was admitted from another hospital who presented with blindness in the first hour of C/S. Blindness of the other two women were diagnosed in 24 h of the delivery. PRES was confirmed with MRI. After the early therapy the patients' vision were improved in 48 h and were normal in 72 h in all the patients. CONCLUSIONS. Sudden total blindness of a healthy person after the delivery is a depressing experience for both physicians and patients. All preeclampsia cases should be followed seriously for neourologic manifestations including PRES and blindness after delivery. Regional especially spinal anesthesia may be controversial though it is known to be safe in preeclampsia. Subarachnoidal intervention may cause intracranial hypotension which was hypertensive due to increased pressure of the brain and also may cause decreased perfusion of the brain due to sympatholytic effects causing sudden hypotension especially after the delivery. Patients with overwhelming injuries initially were afforded all of the complex care the healthcare providers and supporting agencies could muster. As the numbers of patients presenting soon overwhelmed the evacuation possibilities, tough decisions regarding the intensity of care that could be provided had to be made by providers at all echelons of care. This discussion presents information from the authors' experiences at University Hospital in Port au Prince to the USNS Comfort, the US Navy's hospital ship that provided tertiary level care. OBJECTIVES. To describe the practical challenges facing critical care providers in providing emergency and critical care. Additionally, describe how resources and follow-up care also challenged tertiary care facilities in providing ideal critical care. METHODS. The abstract is descriptive, based on observations of the authors and contributors. (1) Initial attempts at providing emergency and critical care in post-earthquake Haiti were provided on first-come, first-served basis by those governmental and NGOs first arriving in country. The overwhelming number of injuries included crush injuries. Many were treated with local wound care, debridement, and as tolerated, amputation. (2) Even with the addition of minimal pharmaceuticals, including antibiotics, very limited oxygen, red blood cell transfusions, and pain medications, staff shortages and lack of evacuation capability resulted in only stable patients being afforded care. Excellence in care was determined by detailed and periodic wound care provided by a single nursing team in a designated intensive care unit. (3) Tertiary level care on board a floating ICU did not prevent the requirement for triaging care, whether that be due to lack of staff or equipment. Often the limiting factor in deciding the intensity of care provided was determined by the available resources for long-term care and support within Haiti's healthcare system of those of NGOs. CONCLUSIONS. Emergency and critical care in a disaster setting forces providers to make triage decisions on the intensity of care they provide. Evacuation to a more robust care setting such as a hospital ship helps support those with limited capability, but also forces triage decisions to be made by those critical care providers. Disaster critical care requires a change in mind set of the provider and resource investment in order to optimize the care to the greatest number of critically ill patients. OBJECTIVES. The goal of this study was to retrospective analyze the prehospital care of the pediatric trauma victims (road accidents, falls, burns etc.) under 16 years of age transported to the Speranskiy Children's Hospital #9 of the City of Moscow (it is approximately equal to level 1 pediatric trauma center) by physician-staffed medical helicopters. In this study we compared 78 pediatric trauma patients transported by helicopter from the injury scene (S group) to our pediatric hospital and 98 trauma victims transported by air after stabilization in local hospitals of the Moscow Region (H group) between January 1, 2001 and March 15, 2010. The patients were evaluated by the pediatric anesthesiologist-reanimatologist (intensivist) at the time of admission and categorized due to clinical judgment by illness severity (mildly ill, moderately ill, severely ill, very severely ill or critically ill)-see Table 1 . We compared the groups depending on requirement for therapy onboard the helicopter and mortality in the hospital. CONCLUSIONS. Triage of victims in regional hospitals allows using medical helicopter for patients in severe conditions, who more often require immediate interventions and intensive therapy. Considering cost of the medical helicopter usage, it is expedient to use it primarily for interfacility transfers. INTRODUCTION. Thirst is one of the most intense and distressing symptoms reported by intensive care patients. A randomized prospective pilot study was conducted to test the feasibility of an innovative family-administered thirst intervention to provide symptomatic relief for patient thirst. OBJECTIVES. The study hypothesis was that patient thirst intensity and distress scores will significantly decrease after a non-pharmacological thirst intervention performed by their family member as compared to patient thirst scores in the usual care/control group. In this randomized single-blinded interventional pilot study, ICU patients who reported thirst intensity or distress scores C3 [as measured by a 0 to 10 numeric rating scale (NRS)] with a visiting family member were eligible for the study. The 26 enrolled patients and their family members were randomly assigned to the thirst intervention or usual care/control group. Institutional review board approval was obtained for all procedures. Patients were comparable in age, 61.38 ± 14.49 (control), 57.46 ± 19.38 (intervention) and predominantly male (61.5%). Intervention group family members were coached by a research nurse to perform the thirst intervention; a series of moistened oral swabs, moisturizing sprays, and a lip moisturizer repeated every 10-15 min for 30 min. The unrestricted activities of family participants in the usual care/control group were observed for a similar time interval. A second research nurse, blinded to the thirst reports and group assignment, conducted all post-thirst assessments. Table 1 for the patient-reported pre and post thirst score ratings. Per a 2-way repeated measures Analysis of Variance, there was a significant main effect for the thirst intensity scores, F (1, 24) =18.41, p\0.001, with a significant interaction, F (1, 24) = 8.51, p = 0.008; partial eta squared 0.26. The main effect for the thirst distress scores was also significant, F (1, 24) = 9.99, p = 0.004, however, the interaction was only marginally significant, F (1, 24) = 3.91, p = 0.06, partial eta squared 0.14. CONCLUSIONS. This initial promising response suggests that a simple bedside intervention may potentially ameliorate one of the most pervasive symptoms reported by ICU patients but requires further study in a larger sample.  To present an original discharge plan for patients with end stage CHF. Ventricular assist devices (VAD) are used as a bridge to cardiac transplantation by providing mechanical circulation when the natural heart cannot maintain adequate cardiac output. With proper training, VAD patients can leave the hospital and wait for their transplant at home restoring their quality of life. Prior discharge a training process of self care and life supporting equipment management is needed. A multiple case studies of applying an original discharge plan for five patients with end stage CHF (and one of them also with PHTN). All patients went under LVAD HeartMateII transplantation as a bridge to cardiac transplantation. Nurse management team developed an evidence-based education program. Nursing staff was instructed by management team, the surgeon and Gamida company presenter regarding the postoperative surgical care and basic concepts related to device Three weeks prior the discharge patient's primary caregiver was trained to treat exit site using sterile technique under nurse monitoring and guided to identify signs of infection. In this time frame patient was trained how to operate the device. A week prior the discharge family was instructed on daily basis regarding the equipment that must be carried on at all times, follow-up care, device maintenance and troubleshooting. Community services which are not experienced with VAD's were instructed by the management team and Gamida presenter. SHL Telemedicine provided monitoring, call center and emergency services. RESULTS. All patients were discharged with LVAD HeartMateII and maintained their routine management at home. Four out of five patients went under donor cardiac transplantation. CONCLUSION. The current plan-involving the patient, his caregivers, nursing staff and community services-ensured a safe discharge for all five VAD patients. This plan maintains quality care with reduced costs and assures patient's Quality of Life. OBJECTIVES. This prospective observational study aims to identify any adverse complications associated with ultrasound guided PICC insertion in a ward based environment. METHODS. An observational audit was employed to review the activities of the PICC Outreach Service within the hospital. Over a period of 11 months, 57 PICC lines were sited. Of these, 89% were performed in the ward environment. For all of the PICC placements a stringent aseptic technique was employed and the team's bespoke PICC line insertion pack used, including the standard Vygon Lifecath PICC Line. The majority of the patients who received PICC lines had difficult venous access in the antecubital fossa due to multiple previous attempts at cannulation, or a low serum albumin concentration (as low as 15 g/L) leading to gross peripheral oedema. For these reasons ultrasound guidance with Sonosite Micromaxx was used in 82% of cases. Data was captured following the insertion of each line with alternate daily followup consisting of a visual site inspection and a check of haematological infection markers including white cell count and CRP. Of the 57 lines inserted, 12 yielded complications: 2 lines migrated out of the vein; 1 had to be removed due to thrombophlebitis; 3 were malpositioned on radiological assessment (including 2 in the right internal jugular vein); 3 lines failed to feed to the desired depth and 3 became occluded during use (of which all 3 were successfully made patent using Urokinase). There were no reported cases of bacteraemia. The duration of use of PICC lines ranged from 5 to 52 days with three patients leaving hospital with their line in situ to receive antibiotics in the community. Follow-up of these patients continued until removal of their lines with no complications reported. CONCLUSIONS. The insertion of PICC lines in a ward based environment using a standard equipment bundle and a robust aseptic technique has not been detrimental to this patient group. The use of ultrasound guidance has enabled PICC lines to be inserted into patients where neither peripheral cannulation nor landmark approach PICC insertion would have been possible.  Wound care is an essential part of surgical patients' nursing. Documentation reveals the quality of given care. Consistent documenting of wound healing process is a prerequisite for evaluating the efficiency, cost-effectiveness and outcomes of wound care. Several factors prevent successful wound care such as nurses' different level of knowledge in evaluating and implementing wound care, fragmented wound documentation which makes expedient access to specific information difficult, unspecific descriptions of wounds, and multiple wounds of one patient. This complexity of wound assessment can lead to inconsistent documentation. Unreliable documentation can cause inadequate and inaccurate wound treatment. The consequences will be suffering, prolonged hospital stay, multiple medication, and higher costs for patients. OBJECTIVES. The purpose of this study is to describe the wound care documentation of ICU nurses. The study material consisted of 61 patient records of heart operated patients with surgical wounds from which we randomly chose 24. The inclusion criteria were an operation in 2006, age 16 years or older and length of stay more than 5 days in one University Hospital ICU. These chosen records were nursing documents written during the actual inpatient period from the patient admission to the discharge. We performed a retrospective quantitative content analysis. The categories to which information of wounds were designed, were formed inductively from the data. We counted how often the same expressions were mentioned and measured the headings which were used in surgical wound care context. We found 133 notes of surgical wounds written during 191 inpatient days in the ICU. They described the manner and frequency of bandage changes, the names of bandages, the amount and quality of leakage and the appearance and place of wounds. The descriptions of nurses and doctors actions in wound care were also present.The language was unstructured and many words of colloquial language or out of focus were used. There were documents without any mention of a surgical wound (n=5) or it was only mentioned in the discharge note (n=1). Brand names were used instead of generic names for the bandages.The nurses wrote about surgical wounds generally without a heading (n=42) or under heading ''Other'' (n=22). Also 22 respective 8 different other headings were used in daily and discharge notes. CONCLUSIONS. The nursing documentation in the ICU does not complete the quality requirements for good wound care and patient safety. It is probably adequate and specific enough in the process of giving information from one caregiver to another when face to face communication can fill the gap. However, much further and precise facts are needed in hand-overs to the other wards or to the patient and patient's family. Improvements could be achieved by supporting the electronic documenting with obligatory templates for standardised documentation.  After the literature review realized in order to collect data, a developed data collection form has been used. Besides the questions intended to the patients sociodemographic characteristics and the proprieties of the disease a scala (1-10) has been used for the sleep quality and the affecting factors. RESULTS. The research has been performed in the CCU of a training and research hospital over a total of 100 patients hospitalized and that not have any problem of communication. The average age of the patients was 55.5 ± 16.59 (21-93) years old, the 65% was composed by men. It has been realized that 95% of the patients had a health insurance and they were not feeling anxious for the hospital expenses. 35% of the patients were hospitalized for AMI, 29% of them for CHF and 13% of them for arrhythmia and they were hospitalized with an average of 4.7 ± 1.16 days. I has been detected that 45% of the patients were hospitalized in CCU for the first time that 8% of them were getting antidepressants. While the patient sleep quality score in their home is in average 7.39 ± 1.87 (median 8) it has been determined that the first night after the hospitalization the score reaching the lowest level was 5.42 ± 2.39 (median 6) and that the average of the CCU was 6.83 ± 2.15 (median 8) and that after the transfer to the clinic the score was reaching (7.39 ± 2.18) the same score as the sleep quality at home. While the change in sleep quality related to the diagnostic of the patients was not considered as statistically meaningful (p\0.05), surprisingly the sleep quality was detected to be more higher in the first night in patients having AMI diagnostics than in patients having CHF diagnostic but this has not been evaluated as important statistically (p=0.59).It has been determined that while sleeping situation of patients was more longer within the first day of hospitalization in CCU, the awake and alert situations were increasing towards the end of the hospitalization. The factors affecting and disturbing the sleep were defined to be the cardiac monitor alarm, the light, the ventilator alarm, the nursing activities and the ring of telephone. CONCLUSIONS. While the sleep quality of patients hospitalized in CCU was showing a slight decrease during the first night of hospitalization in CCU, after the transfer to the clinic it was reaching the same sleep quality existing at home. It has been in the opinion that this situation was generated by important factors which affect the sleep quality of patients such as light, noise existing in the CCU and as well as by the nursing activities. This is important to manage CCU environment and nursing activities in order to provide patients with resting opportunity during night time. OBJECTIVE. To verify association between early pressure ulcer development and severity of illness, nursing workload, risk for pressure ulcer, lenght of stay and therapies in critical patients in the ICU. In this cross-sectional study, data from 160 patients were collected prospectively in three ICUs of a University Hospital located in São Paulo city, Brazil, from November 2007 to April 2008. Inclusion criteria were: being in the ICU at least 24 h and not present pressure ulcer on admission. Severity of illness was measured using Simplified Acute Physiology II (SAPSII) applied at admission. Risk factors for PU were determined using Braden Scale applied daily in the ICU, until the appearance of the PU. Nursing workload was measured daily using Nursing Activities Score (NAS).Sedation, mechanical ventilation and inotropic support during ICU stay were considered as therapies. Skin lesion developed until 7 days was considerated early PU. SAPSII, NAS and Braden average scores were compared using Student t test. Chi-square test was used to compare groups considering sedation, mechanical ventilation and inotropic support. RESULTS. SAPSII average was 39.9 (SD=15.1), NAS average was 62.9 (SD =12) and Braden average was12 (SD =2.4). 47.5% patients had Braden scores between 10 and 12 which represent high risk for PU and 20.6% had Braden scores\9, indicating the highest risk. Average length of stay in the group of patients without PU (9.7 days), with early UP (19.5 days) and late PU (29.01 days) was statistically different (p \ 0.05). The average length of stay was higher in patients with early UP compared with patients without UP. Braden scores average indicated high risk in patients without PU (12.3), with early UP (11.0) and late UP (10.4). The mean Braden scores of the group without PU was statistically superior to other groups (p\0.05). However the difference was not clinically significant. SAPSII scores average of patients with early PU was not different from patients without PU (p=0.076) and with PU late (p=0.173). NAS scores average of patients with early PU was not different from patients without PU (p=0.355) and with PU late (p=0.112). In this sample, more patients with PU were sedated and mechanically ventilated than patients without PU, and more patients with PU late had inotropic support. CONCLUSIONS. In this study sample, development of early PU was not associated with severity of illness, nursing workload, risk for PU and inotropic support. OBJECTIVES. The aim of this study is to evaluate the adherence to the recommendations of international guidelines for the management of intravascular devices. We observed the behaviours of healthcare workers regarding the care of central and peripheral venous catheters in four wards (three intensive care units and a semi intensive care unit), concerning the following aspects: handwashing; use of gloves; asepsis keeping during catheter manipulation; hub decontamination; catheter dressing according to the conditions of the inserction siteand of the dressing. We only observed the adherence to the guidelines of the nurses belonging to the ward. We calculated the percentage of adherence to the single behaviour. Globally, 247 observations were collected in the 4 units. Use of gloves: gloves were not used in 26% of observations; there is a low adherence to the use of gloves during the start or the change of a continuous infusion, or the administration of drugs through the catheter. Handwashing has not been performed in 55% of cases before and in 43% of cases after the device was manipulated (globally in 49% of the observed procedures). The highest adherence to handwashing has been observed before the administration of blod components (100%) and before the dressing of the cathether(70%). The lowest adherence to handwashing has been observed before drug administration (32%). Alcoholic solution has been used in 95% of observations. Handwashing and use of gloves: in 19% of observations hands were not washed nor gloves were used. Asepsis was mantained in 98% of observations. The highest adherence to the asepsis keeping has been observed during the collection of blood samples (100%) and the management of transfusions (100%). The lowest adherence to asepsis keeping has been observed during the deconnection (89%) of an infusion. Hub decontamination has been observed only in 2% of cases, before the substitution of the infusion. Catheters were dressed with semipermeable film in 94% of observations. Dressing-type was appropriate in 49% of observations. Dressing time substitution was not appropriate in 71% of observations. CONCLUSIONS. Globally, we observed many points susceptible of improvement regarding the care of the vascular catheters. Some of the behaviour may be corrected through the introduction of an hospital protocol for the management of intravascular devices an the improvement of the documentation. INTRODUCTION. Early goal-directed therapy (EGDT) has been reported to reduce mortality when it was applied in the emergency department before admission to the intensive care unit (ICU). However, the management of severe sepsis and septic shock in the general ward (GW) is not well defined. OBJECTIVES. The purpose of this study was to evaluate the outcome and prognostic factors in the patients with severe sepsis and septic shock managed in the GW with the transfer to the ICU withheld. METHODS. We retrospectively identified total 305 patients with severe sepsis and septic shock contacted to the medical emergency team (MET) from a single tertiary referral center with 28bed medical intensive care unit between March 2008 and February 2010. INTRODUCTION. Recent, prospective, epidemiological studies on severe sepsis and septic shock have been based on sub-populations rather than nationwide populations, which carries the possibility of error. Furthermore, they have been conducted during a small part of a year and thus allowing bias due to seasonal variations of sepsis. OBJECTIVES. The aim of our study was to describe epidemiology of sepsis in a whole country population during a whole year. METHODS. This was a prospective, observational study of all adult patients admitted to Icelandic ICUs, who were screened for the ACCP/SCCM criteria for severe sepsis or septic shock at admission. Data were collected from April 1st 2008 to March 31st 2009. A total of 1,425 patients were admitted to the ICUs, 115 of them were admitted because of severe sepsis or septic shock. The incidence in Iceland is 0.48/1000 inhabitants. The mean age was 65.4 years and males were 53%. The mean APACHE II score was 20.7, SAPS II: 44.1 and SOFA: 8.7. 28-day mortality was 25%, 90-day: 29% and 1-year mortality was 40%. The main sources of sepsis were: pulmonary (37%), abdomen (28%) and urinary tract (8%). Infections were microbiologically documented in 70% of cases and 39% of patients had positive blood cultures. Pathogens were gram-positive (39%), gram-negative (30%) and mixed (28%). Multi-resistant pathogens were found in 9%. No patient had sepsis caused by MRSA or fungi. Empirical initial antibiotic therapy was deemed inadequate in 21% of cases. CONCLUSIONS. The incidence of severe sepsis and septic shock in Icelandic ICUs is approximately 0.5 per 1000 inhabitants, which is similar to other recent epidemiological studies. Mortality rates are in the lower range of reported. The types of pathogens are consistent with current trends, with the exception of sepsis caused by MRSA and fungi, which are rare in Iceland.  Laparostomy is an effective method to manage initially patients with severe abdominal sepsis. The age and the primary cause of sepsis have been evaluated as prognostic factors for these patients outcome. OBJECTIVES. The aim of this study is to evaluate the primary microbial factor and the superinfection of peritoneal cavity in order to assess the correlation with morbidity and mortality in patients with severe peritonitis. METHODS. From January 2007 until Mars 2010, 35 patients (21 male, 14 female with mean age 59.45 years, range from 22 to 87 years) managed initially with laparostomy for severe peritonitis. In all patients have been used the Vacuum Assisted Closure technique (VAC) for cover the open abdomen. Sepsis evaluation made preoperatively with Manheim peritonitis score and SOFA score. Exclusion criteria from the study was the use of other temporary technique to close laparostomy, Manheim peritonitis score preoperatively \ 29 and death before the first dressing change of VAC. VAC dressing changes and transvaluation of abdominal sepsis was made every 2-4 days in operation theater. In every change we evaluated SOFA score and took peritoneal fluid and blood samples for culture. We evaluated the influence of the positive primary culture and the transfection of peritoneal cavity of patients with severe sepsis in mortality, in intensive care unit hospitalization, in complications and in the definitive closure of abdomen. INTRODUCTION. Since mortality of sepsis increases with the progression of the disease and early detection improves clinical course and outcome, early recognition of sepsis is of major importance [1] . Hence, there is a need for sensitive and specific diagnostic markers to identify sepsis quickly and accurately. In the recent years various new inflammatory markers have emerged, including lipopolysaccharide-binding protein (LBP), the long pentraxin (PTX3) and procalcitonin (PCT). Although early reports of the use of these biomarkers seem promising, relatively little is known about the kinetics of these hormones, especially with regard to possible differences between sexes. Females have been reported to show a more pronounced proinflammatory innate immune response. Although the gender differences in the inflammatory response are clearly recognized, there are no data on the possible differences in kinetics of the previously mentioned later markers of inflammation LBP, PTX3 and PCT. OBJECTIVES. To determine the kinetics and possible gender differences in LBP, PTX3 and PCT during human endotoxemia. METHODS. Thirteen male and 13 female subjects were admitted for 24 h to the intensive care unit of the Radboud University Medical Centre, the Netherlands. At t=0 h a single dose of 2 ng/ kg U.S. standard reference E. coli O:113 lipopolysaccharide (LPS) was infused intravenously. Besides several cytokines LBP, PCT, PTX3 were measured at regular time intervals. RESULTS. The administration of LPS resulted in a marked immune response as represented by clinical signs, hemodynamic changes and cytokine response. There was a large gender difference in all investigated biomarkers. LBP rose to 21.4 ± 1.8 and 32.9 ± 4.2 at t=24 h for males and females respectively. PCT levels were 8.4 ± 1.0 and 6.8 ± 1.0 respectively at t=24, and PTX levels were 5.1 ± 0.6 and 18.2 ± 10.1 at t=24 in males and females respectively. CONCLUSIONS. There is a clear gender difference in the response of biomarkers LBP, PCT and PTX3 during inflammation. This is relavant to the implementation of these markers in the diagnostic proces of systemically inflamed patients. INTRODUCTION. The balance between inflammation and anti-inflammation is essential for survival during severe infections. There is renew interest in adrenal function during sepsis. Most of serum cortisol is bound to cortisol binding globulin and albumin. However, only the free serum cortisol is active. The method to measure free serum cortisol is technically demanding and poorly reproducible. OBJECTIVES. Correlation between salivary cortisol and free serum cortisol in patients with septic shock. Correlation between free serum cortisol and total serum cortisol in patients with septic shock. METHODS. Simple correlation were use to calculate the sample size. First, between free serum cortisol to total serum cortisol of 0.55 and second, between free serum cortisol and salivary cortisol of 0.80 using two-sided Z test with a significance level of 0.05 and achieving 0.81 power. A sample size of 37 was determined. Only adult patients with septic shock as per ATS/ESICM criteria were included. Saliva and blood were collected simultaneously from 8 to 10 AM as per protocol. Patients with nasal or oral bleeding were excluded. The samples were storage and sent in batches to the reference laboratory. Salivary cortisol was measure by enzyme immunoassay. Cortisol binding globulin by radio-immunoassay. Total serum cortisol by LC-MS liquid chromatography. Free serum cortisol by equilibrium analysis. . 38 patients were included in the first correlation, salivary cortisol to free serum cortisol and 57 patients in the second correlation, free serum cortisol to total serum cortisol. There were less patients in the salivary group due to factors such as contamination with blood or not enough saliva to analyzed. The correlation for salivary cortisol to free serum cortisol was 0.79, 95% CI 0.63-0.089, p\0.0001 with a regression equation for free serum cortisol = 0.8889 ? 0.4481 * salivary cortisol.The correlation for free serum cortisol to total serum cortisol was 0.86, 95% CI 0.78-0.92, p \ 0.0001. The regression equation for free serum cortisol was = (-1.2346) ? (0.1628) * total serum cortisol. CONCLUSIONS. Salivary cortisol may replace serum cortisol for the determination of free serum cortisol in the majority of patients with septic shock. Salivary cortisol is less labor intensive and can be performed daily in septic shock patients. Salivary cortisol correlates better with free serum cortisol when the level of serum cortisol is lower, which may have therapeutic relevance. According to the data of several randomized trials (EPISEPSIS, SOAP, Finnsepsis, EPIC II) there is a significant increase in the frequency of sepsis, as well as of hospital mortality (up to 70%). A crucial role in the pathogenesis of sepsis is playing by the lipopolysaccharide of gramnegative bacteria (endotoxin). In 2008-2009, 29 patients with assumed infective and septic complications after cardiac surgery were evaluated during the randomized HAEMOSEPSIS trial led in Bakoulev Scientific Center for Cardiovascular Surgery.All patients had SIRS, bacteriologically proven gram-negative infection, unstable hemodynamics requiring inotropic support (epinephrine 0.1-0.15 mcg/kg/min, norepinephrine 0.05-0.07 mcg/kg/min), SOFA score corresponded to 12-18 and APACHE II score was from 21 to 38. Complex intensive care was carried out in accordance with Surviving Sepsis Campaign Guideline. Selective Polymyxin-B hemoperfusion using Toraymyxin-PMX-F (Toray, Japan) cartridges was used in 62% of patients.A new technique for the determination of endotoxin activity (Endotoxin Activity Assay-EAA Spectral Diagnostics, Canada) was introduced for the diagnostics of endotoxemia and the evaluation of hemoperfusion effectiveness. RESULTS. Low EAA level (\0.4; 0.31 ± 0.04) was revealed in 2 out of 29 patients (6.9%); moderate EAA level (0.4 to 0.59; 0.52 ± 0.07)-in 8 patients (27.6%), while 19 patients (65.5%) had EAA over 0.6 (0.73 ± 0.09). No lethal outcomes were seen among patients with low EAA level, in the group of patients with moderate EAA 28-days mortality was 50%, and in the group with high EAA-73.7%. Besides, this index allowed for the determination of the effectiveness of selective hemoperfusion using Polymyxin B cartridges. CONCLUSIONS. the values of EAA can be used as a marker for the evaluation of the severity of state of patients, as an index for the prediction of the outcome of infective and septic process, as well as for the evaluation of the effectiveness of complex intensive care. OBJECTIVES. We hypothesize that gene expression of IL-6 is protective and could be correlated with an improved survival outcome in patients with septic shock. Peripheral blood mononuclear cells (PBMC) from adult patients in the intensive care unit (ICU) who are in septic shock were isolated in order to measure IL-6 gene expression. We aimed to determine the association of IL-6 gene expression with hospital mortality, days of vasopressor support, and ventilator days in the ICU. METHODS. DESIGN. Prospective cohort study. SETTING. Adult patients with septic shock in the medical and surgical ICU at a tertiary care center. Sample: Subjects were screened into the cohort study within 24 h of diagnosis. Forty-eight patients with septic shock were enrolled between January and June 2008. Adults greater than 18 years of age were eligible. Exposure Measure: Patients were divided into low IL-6 level (n=27) and high IL-6 level (n=21) groups based on the median IL-6 gene expression level. IL-6 was measured in PBMC by reverse transcription polymerase chain reaction (RT-PCR). Outcome Measures: The primary outcome measure was hospital mortality. Secondary outcome measures included ventilator days and days of vasopressor support. Statistics: To assess the prospective association of IL-6 expression levels with mortality, we used Kaplan-Meier survival curves and Cox proportional hazard models. RESULTS. 29.6% (8/27) deaths in the low IL-6 level group and 61.9% (13/21) deaths in the high IL-6 level group were identified. Survival curves comparing subjects with low versus high IL-6 gene expression levels were statistically significant different (Wilcoxon rank sum test P=0.01). The unadjusted hazard ratio for IL-6 level above versus below the median was statistically significant different (HR = 3.6; 95% C.I. 1.4, 9.7) . After adjustment for body mass index (BMI), smoking and severity of illness (Apache 2 score) the HR for mortality in patients in the higher IL-6 mRNA group was 1.9 (95% CI 0.6, 5.9) and it was not statistically significant. For every increase in one unit of either BMI or Apache score there was a 7% increased risk of dying keeping all other variables the same. Ventilator days and days of vasopressor support were not statistically different between the low and high IL-6 mRNA groups. CONCLUSIONS. The survival analysis of the preliminary findings shows that higher IL-6 mRNA expression at enrollment is associated with higher hospital mortality in unadjusted analysis. In analysis adjusted for BMI and Apache score the results are uncertain. Additional analysis with larger statistical power and including stratification by BMI and Apache are needed once more patients have been enrolled. GRANT ACKNOWLEDGMENT. International Anesthesia Research Society. INTRODUCTION. More than 100 biomarkers have been claimed useful in sepsis, however results from trials are varied and inconclusive. Whether any of them will prove a valid surrogate outcome measure is not known 1 To assess the usefulness of routinely measured biomarkers namely CRP, NT pro BNP, serum lactate, albumin and total cholesterol in outcome prediction in severe sepsis and septic shock METHODS. This was a prospective observational study on 100 consecutive adult patients admitted with a diagnosis of severe sepsis/septic shock (ACCP/SCCM definition) to the medical ICU of a tertiary Indian teaching hospital between September 2009 and March 2010. On admission, data pertaining to baseline characteristics including admitting APACHE II & SOFA scores were documented and serum levels of CRP, NT pro BNP, lactate, albumin and total cholesterol were measured using standard assays. Serial SOFA scores were calculated during ICU stay. Patients were followed up to evaluate the primary and secondary outcomes, namely mortality and 1. new organ failure 2. ICU length of stay (LOS), 3. ICU free days, 4. MV days and 5. MV free days respectively. All patients were treated along lines of the ICU's SOP The mean age of the study group was 57.5 ± 17.2 years with 67% men and 33% women. The admitting APACHE II & SOFA scores were 28.1 ± 11.1 and 10 ± 3.7 respectively. Respiratory infections (30%), Leptospirosis (23%) and UTI (18%) were the major admitting diagnosis followed by others. Overall mortality was 62% (SMR 1.1). Values of biomarkers and their correlation with primary outcome is summarized in Table 1 . High admitting values of NT pro BNP, serum lactate and low serum albumin were associated with a statistically significant increase in the risk of death (p\0.05). The secondary outcomes analysed were ICU LOS (8.2 ± 9.3 days), ICU free days (8.6 ± 7.1), MV days (6.9 ± 7.7), MV free days (9.1 ± 9.2) and serial SOFA scores. With respect to the secondary outcomes, only elevated serum lactate levels showed a significant correlation with prolonged ICU and hospital LOS and MV days. New organ failure was identified in 37% of patients while in 30% there was only one value for SOFA score (day 0). In 29% of patients there was an improvement in SOFA score and no change in 4%. High levels of NT pro BNP and serum lactate, and low admitting serum cholesterol were significant risk factors for additional/new organ failures (p\0.05). CONCLUSIONS. While some biomarkers do have a prognostic role, the significance of one isolated value is dubious. Their incorporation into a formal scoring system might prove more meaningful. INTRODUCTION. Many biomarkers were identified as elevated in patients with septic shock, and their performance vary depending on risk stratification of sepsis severity and/or prognosis. Kinetics of many biomarkers beyond the first day of severe sepsis diagnosis can be heterogeneous and there is a lack of identification of key biomarkers for risk stratification and prognosis of septic shock patients. To analyze the kinetics of several biomarkers on the first week of septic shock and to identify the best accuracy of these biomarkers for prediction of early and 28th day mortality. METHODS. Sixty-seven septic shock patients were included from 3 ICUs. Clinical and laboratory data were collected on the 1st, 3rd, 5th and 7th days after septic shock diagnosis. Daily SOFA score was calculated. We performed a multiplex cytokine analysis, including a panel of 17 cytokines during the first week of septic shock: interleukin . We also measured the plasma cortisol and C reactive protein and Macrophage migration inhibitory factor (MIF) levels. The kinectics of all biomarkers were compared between survivors ans nonsurvivors groups. The accuracy of 1st day, maximum and median levels of cytokines, cortisol and SOFA score was plotted on ROC curves for prediction of early (3 days) and 28th day mortality. RESULTS. Highly significant levels of cytokines persisted beyond the first day of septic shock. Four patterns of kinetics were established during the first 7 days of septic shock: exponential decay (ex. IL-6), Gaussian curve (ex. IL-10), increasing levels (ex. IL-8) and stable levels (ex. MIF). There was good correlation of organ dysfunction severity and MIF (r=0.41; p=0.002), IL-8 (r=0.38; p=0.004), and cortisol (r=0.37; p=0.005) levels. IL-8, IL-10, and MCP-1 showed good accuracy for prediction of early mortality (AUROC 0.84, 0.79 and 0.78, respectively). Maximal cortisol levels and day 1 MIF levels had the best accuracy for prediction of 28th day mortality (AUROC 0.81 and 0.73, respectively). Across all clinical scores and biomarkers, day 1 MIF levels[3201 pg/ml, mean IL-6[206 pg/ml, and maximal cortisol level[59 mcg/ml in the first week of septic shock were predictors of 28th day mortality in a multivariate analysis. CONCLUSIONS. The kinetics of biomarkers during the 1st week of septic shock revealed different accuracy for prediction of early and 28th day mortality. Day 1 MIF, maximal cortisol and mean IL-6 levels showed the best performance for 28th survival. GRANT ACKNOWLEDGMENT. CNPq, Faperj INTRODUCTION. Procalcitonin (PCT) has been reported as a specific biomarker of bacterial infectious processes. Normal levels of PCT are considered between 0.1 and 0.5 ng/ml. While in colonization or local infection PCT levels are lower than 2 ng/ml, concentrations above 3 ng/ml are associated with severe bacterial infections with sepsis. In septic shock and multiple organ dysfunction PCT levels are even higher. OBJECTIVES. To analyse the prognostic value of PCT and PCT clearance (delta-PCT) in the course of severe sepsis with organ dysfunction. Prospective study of adults patients with severe sepsis and organ dysfunction admitted to a University Hospital Intensive Care Unit (ICU). The study was authorized by the Ethical and Clinical Investigation Committee of our hospital. Serial PCT determinations were made at ICU admission and subsequently at 12, 24, 48 and 72 h and 7 days. In order to value the PCT clearance we defined delta-PCT as the difference between the levels of PCT at admission and at 24, 48 and 72 h (delta-PCT 24 h, 48 h and 72 h respectively). Lumitest Ò PCT (Brahms Diagnostica GMBH, Berlin, Germany) was used as biochemical method. Continuous variables with normal distribution (age, APACHE II) were expressed as mean (±standard deviation) while these with not normal distribution (PCT) were expressed as median (interquartil rank, 25/ 75). U de Mann-Whitney was used for mean comparations. SPSS v18 was used for statistic analysis. A p value\0.05 was considered statistically significant. RESULTS. 27 consecutive adults patients with severe sepsis as ICU admission diagnostic were enrolled (age 65 ± 14 years old, 19 men/8 women). The APACHE-II score was 25.9 (± 8.3) points, the SOFA score was 11.5 (± 3.3) points and the ICU mortality was 66%. No significant differences were found in the levels of PCT in terms of patient outcome. However, the delta- CONCLUSIONS. In severe sepsis with multiorgan dysfunction although a significant increase in PCT levels occurs this have not prognostic value. However, in surviving patients PCT levels decreased more than non-survivors. This PCT clearance can be evaluated as delta-PCT at 48 and 72 h. Delta PCT at 48 and 72 h have prognostic value because they were significantly higher in survivors compared to non-survivors. Therefore, the persistence of high levels of PCT was associated with poor prognosis. INTRODUCTION. Early detection of sepsis is essential for implementation of diagnostis and treatment of sepsis. Clinical picture of sepsis sometimes is not evident and organ failure symptoms might be interpreted variably. Newly aviable bed site diagnostic Kits for IL-6 IL-8 and protein S-100B were used in diagnostic process of sepsis. OBJECTIVES. Clinical biomarkers of sepsis can be easily detected by bed site diagnostic tools. This proces can add useful message to decision making process. The study was performed to determin if additional bed site tests can accelerate impelementation of septic bundles and influence duration of treatemnt in the ICU Study was performed on the group of 92 adult patients (45 male and 47 female aged 18-93 years) with symptoms of infamatory reaction and multiple organ failure, admitted to general ICU. Milenia Quick bed site diagnostic kits for IL-6 IL8 and S100B were used. Standard inflamatory clinical markers assesed include determination of concentration of: White Blood Count, C Reactive Protein, Procalcytonin Fibrynogen. Patients were divided in two group: (1) group I-diagnosed with sepsis, (2) group II-suspected to have sepsis. IL-6 IL-8 and S100B tests were performed in both groups. The analysis was performed to determin if results of bed site tests have influence on decision of prescribed antibiotics, start of renal replacement therapy and length of stay in the ICU. RESULTS. There were 33 patients diagnosed with sepsis-GROUPI and 59 patients suspected to have sepsis. IL6 level was increased in 63 patients (Group I=25 Group II= 38) IL8 level was increased in 58 patients (group I 29 Group II=29) Protein S100B was elevaed in 55patients. There were only 20 patients were all 3 biomarkers were elevated and in 12 immunocompromised patients S100B was the only marker which was elevated. Bed site tests influenced decision of antibiotic treatment in 27 patients from Group II. Renal replacement therapy was started because of additional informaton from bed site tests in 6 cases. Mean length of ICU stay was 13 days and did not differ between groups. CONCLUSIONS. Bed site diagnostic tests can provide additional confirmation of inflamatory reaction and may help in making tratment decision in the ICU. Due to pathophysiology of sepsis and variations individual responce single determination of those biomarkers must be very cautiously interpreted.  We have retrospectively shown that filtering packed red blood cells (PRBCs) of donor white cells before banking (prestorage leukoreduction or PS-LR) not only blunts the known detrimental effect of aging of banked PRBCs on transfused trauma patients, but that the receipt of older PS-LR blood was associated with a protective effect on survival as well 1 . We sought to duplicate these results with a prospective cohort study. OBJECTIVE. To evaluate PS-LR's impact on the detrimental effects of aged PRBCs on outcomes in transfused trauma patients. For 19 months, all trauma patients admitted to our urban Level I trauma center who were transfused C4 units PRBCs, survived 24 h post-injury, and were C18 years old were enrolled. Data on demographics, amount of PRBCs transfused in the first 24 h, age in days of each unit, and outcomes were collected. Logistic regression was performed with patient age, injury severity score (ISS), head abbreviated injury score (AIS), and total units of PRBCs transfused as covariates. In model 1, mean age of blood for each patient was entered as a continuous independent variable. In model 2, mean age was dichotomized as C or\14 days as an independent variable. In model 3, the absolute number of PRBC units \14 days old were counted for each patient and entered as an independent variable as a percent of total PRBC transfusion. Models 2 and 3 were repeated using blood age of 21 days as a break point. Dependent variables were death, multiple organ dysfunction syndrome (MODS), and infection. In the 153 patient cohort (age=40 ± 16 years, ISS=26 ± 15, total PRBC= 10 ± 9 units, head AIS=1.3 ± 1.9, 78% male, 70% blunt), mortality was 11% (n=17), 18% had MODS (n=28), and 37% had C1 infection (n=56  Patients with severe sepsis, including septic shock, often lead to multiple organ failure. Especially, acute kidney injury (AKI) is associated with high morbidity and mortality in severe sepsis. Human atrial natriuretic peptide (hANP) is a potent endogenous natriuretic, diuretic, and vasorelaxant peptide and thought to be effective for protection against kidney injury. Therefore we think that hANP has the possibility of improving prognosis in severe sepsis by preserving renal function. OBJECTIVES. This study examined the effectiveness of hANP for severe sepsis with multiple organ failure, especially AKI or acute respiratory failure. A historical cohort study was conducted in the patients with severe sepsis. From 2006 onward we treated the patients with severe sepsis following Surviving Sepsis Campaign guidelines (SSCG) and from 2008 onward we additionally administered hANP after the recovery from septic shock. The patients who received hANP (hANP group) were compared with those treated before without hANP infusion as historical control (control group). Trends for serum concentration of creatinine and estimated glomerular filtration rate (e-GFR) were recorded during hospital days (on ICU admission, just before hANP infusion, on ICU discharge and hospital discharge). We have investigated mortality at 30 days, renal function, the percentage of introduction for maintenance hemodialysis and ventilator free days (VFD). Forty-eight patients were enrolled. hANP group included 16 patients and control group did 32 patients. The mean age was 74.9 ± 11.3 in hANP group and 71.2 ± 11.1 in control group. Except the percentage of ventilator use (higher rate in hANP group), there was no significant difference in patient characteristics between two groups. The mean serum concentration of creatinine in both groups exceeded 2 mg/dl and was not significantly different at ICU admission. Trends for mean serum concentration of creatinine and e-GFR improved day by day, but there were no significant differences between hANP group and control group (p=0.86 and 0.30, respectively). Furthermore there were no patients who were introduced maintenance hemodialysis in both groups. On the contrary, VFD tended to be longer in hANP group than control group (p=0.069). Univariate analysis did not identified predictors of survival, but multivariate analysis showed that hANP infusion, APACHE II and mean serum concentration of creatinine at the last time tended to be associated with 30 days mortality (odds ratio: 0.20, 1.10 and 5.45, respectively; p=0.125, 0.056 and 0.002, respectively). CONCLUSIONS. The effectiveness of hANP for renal function was still unclear, but hANP may have the possibility of decreasing ventilator days and improving the prognosis. Further studies are needed to assess the effectiveness of hANP for severe sepsis.  
