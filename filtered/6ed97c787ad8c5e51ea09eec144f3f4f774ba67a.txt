6ed97c787ad8c5e51ea09eec144f3f4f774ba67a
THE PREDICTIVE PERFORMANCE OF PLASMA NEUTROPHIL GELATINASE- ASSOCIATED LIPOCALIN (NGAL) INCREASES WITH GRADE OF ACUTE KIDNEY INJURY
A  Haase-Fielitz R  Bellomo P  Devarajan M  Haase 

Universitätsmedizin Berlin Austin Hospital Universitätsmedizin Berlin 
62.9 ± 11.5 31.8 ± 6.8 0.039 * Values in X ± SEM, Student's t test CysC on admission was significantly higher in group1 (p \ 0.05). Changes in CysC values during the 3 days of follow-up were also significantly higher in group 1 (p \ 0.05) CONCLUSIONS. Our preliminary results suggest that CysC could be a useful early marker for AKI detection, superior to serum creatinine. It could be an important tool to recognize early renal dysfunction; however, we are in need of more studies. OBJECTIVES. The aim of this study was to evaluate if there is a better correlation between serum Cystatin C levels and the glomerular filtration rate (GFR)-calculated with creatinine clearance and estimate by the MDRD and Cockcroft-Gault formulas-and the serum creatinine levels. A prospective and observational study was designed including all adults patients admitted in the Intensive Care Unit of the Gregorio Marañón Hospital during a period of 30 days. The serum Cystatin C levels, serum creatinine and creatinine clearance in 24 h urine were determinate at the admission day and every seven days until the unit discharge. We considered acute renal failure (ARF) a creatinine level 1.5 times the basal level, a 50% reduction of GFR or oliguria at least during 6 h. The Cockcroft-Gault (CG) and modification of diet in renal disease (MDRD) formulas were used to calculated creatinine clearance. The serum Cystatin C was determined using Hoek's formula. RESULTS. In our study, 37.6% of all patients had ARF. There was a statistically significant correlation between the serum levels of Cystatin C and creatinine clearance measure (r = -0.749; p = 0.000), and this correlation was better than serum creatinine and creatinine clearance measure (r = -0.639; p = 0.000). Serum Cystatin C levels were related with a higher risk to develop renal failure (OR 39.7 IC 95%, 3.1-497.1; p = 0.004). Patients with elevated level of Cystatin C had a risk 38 times higher to develop ARF compared with those patients with normal levels (RR 38.2, . When GFR is less than 60 ml/min, Cystatin C has a greater positive predictive value than creatinine. This also occurs when GFR is 80 ml/min (AuROC 0.89, IC 0.77-1.01, p = 0.000 for Cystatin C, and 0.782 IC 0.606-0.959 p = 0.011 for creatinine). Nevertheless, there is not statistically significant correlation between serum Cystatin C levels at the admission day with the risk to develop infectious complications (90.0% in patients with high Cystatin C and 63.2% in patients with normal levels) and non infectious complications (54.5% in patients with high Cystatin C levels and 31% in patients with normal levels). In the other hand, patients with high levels of Cystatin C had a greater rate of mortality in our intensive care unit (27 and 15%) and later during the hospital admission period (30.3 and 15%), but this difference were not statistically significant. CONCLUSIONS. Serum Cystatin C is a good marker of renal function in critically ill patients. In our study Cystatin C was better than serum creatinine in the detection of ARF. Hoek's formula is a good test for glomerular filtrated rate, similar to other formulas already validated. We didn't find neither statistically significant correlation between Cystatin C levels and other complications nor Cystatin C levels and the mortality. INTRODUCTION. Elevation of intra abdominal pressure (IAP) is a recognized risk factor for visceral dysfunction apparition. The incidence of intra abdominal hypertension (IAH) is estimated between 18 and 81% depending on the studied population's characteristics. No data concerning exclusively medical patients are available. We report the preliminary results of IAP monitoring in an exclusively medical intensive care unit population. To assess the incidence of IAH in medical ICU patients, the link between IAP elevation and organ dysfunction. METHODS. Measurement of IAP among medical, ventilated, and sedated patients with a predicted length of ventilation superior to 48 h at the time of admission. First measurement within the first 24 h of ventilation and then once or twice daily during seven days or till the end of mechanical ventilation if inferior to 7 days. Calculation of abdominal perfusion pressure and filtration gradient. RESULTS. 25% of the patients have at least one IAP measurement [12 mmHg during their ICU stay. IAP elevation mostly occurs after a fluid challenge (FC) in the previous 24 h. 70% of SOFA scores are higher at the time of IAP elevation compared to the time of admission. Among the 127 collected values 5.5% are C12 mmHg. A single value of IAP is not predictive of renal function, however some episodes of renal function worsening are contemporary of increased IAP leading to decreased APP et FG even without impaired systemic mean arterial pressure. CONCLUSION. Elevation of IAP is not uncommon among medical ICU patients. Net fluid balance contributes to IAP increase. The threshold value of IAP for ARF is low, particularly as compared with surgical patients, although the contribution of impaired systemic haemodynamics should also be considered. The usefulness of IAP as a guiding fluid ressuscitation therapy tool and as a minimally invasive renal blood flow monitoring one should be investigated. INTRODUCTION. Lung strain is indicated as a major determinant of ventilator induced lung injury. It has been defined as the ratio between end-inspiratory lung volume above functional residual capacity (DV) and functional residual capacity (FRC) (STRAIN DV = DV/ FRC). DV includes a static component due to PEEP (STRAIN PEEP ) and a dynamic component due to tidal volume (STRAIN TV ). To assess lung strain at different PEEP levels a single FRC measure, commonly at the lower PEEP level, it has been used, assuming that FRC is not influenced by PEEP. This may lead to overestimation of STRAIN at higher PEEP. We evaluated, in ARDS patients, the effect of neglecting PEEP induced FRC changes on STRAIN DV and its components. METHODS. Three levels of PEEP (5, 10, 15 cmH 2 O), were randomly applied, for 1 h each, in 10 ARDS patients. At each PEEP we obtained the FRC by helium dilution method and the volume expired from PEEP to ZEEP. . FRC increased at increasing PEEP (507 ± 292, 607 ± 311, 681 ± 312 ml (p \ 0.05) respectively at PEEP 5, 10, 15 cmH 2 O). STRAIN DV and STRAIN PEEP increased while STRAIN TV decreased at increasing PEEP ( Fig. 1 ). Using the FRC at PEEP 5 for all PEEP levels lead to overestimation (24 ± 15% and 45 ± 36% respectively at PEEP 10 and 15) of STRAIN DV , STRAIN PEEP and STRAIN TV (Fig. 1) . The overestimation is proportional to the difference between the measured FRC and the one used for the computation. INTRODUCTION. In mechanically ventilated patients higher intra-abdominal pressure (IAP) change the respiratory system mechanics. However, different abdomino-thoracic pressure transmission has been reported. OBJECTIVES. To study the mechanical relationship between intrathoracic and abdominal compartment in patients suspected of abdominal hypertension (IAH) with different abdominal compliance. METHODS. 22 patients on controlled mechanical ventilation admitted in medico-surgical ICU with different diagnosis. Mechanical properties of abdomen and chest wall were studied by measurements of static and dynamic bladder (IAP), esophageal (Pes) and central venous pressure (CVP) . At the bedside without additional devices for this study. End expiratory pressures were considered as static values and the difference between endinspiratory and end-expiratory as dynamic values. Data are showed as mean ± SD and range. RESULTS. Diagnosis were: 4 cardiac arrest, 2 thoracic trauma, 1 acute pancreatitis, 15 abdominal sepsis. IAPst [IAPst 10 ± 4 (3-21) mmHg], was related with static intrathoracic pressure (Pes,st, r = 0.6, CVP,st. r = 0.7). Pes,st 8 ± 4 (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) (20) , Pes, dyn 5 ± 4(1-18) mmHg. CVPst 13 ± 5 , CVPdyn 3 ± 2 (1-9) mmHg. Poor relationship was found between IAPst, and IAPdyn [IAPdyn 2 ± 1(1-7) mmHg], (r = 0.3). Whereas in patients (n = 9, 40%) with intra-abdominal hypertension IAp = 14 ± 2 (12-21) mmHg, the relationship between these variables were significant (r = 0.8), compared with patients with lower IAP (7 ± 2 mmHg; r = 0.4). Compliance of the respiratory system (31 ± 9 ml/cmH 2 O) was lower than lung compliance (56 ± 28 ml/ cmH 2 O) due to highest chest wall pressures. Chest wall compliance (119 ± 92 ml/cmH 2 O) was related with static and dynamic abdominal pressure (r = -0.5, r = -0.6). Respiratory oscillations of CVP and Pes were related (r = 0.6). CONCLUSIONS. The degree of respiratory system impairment caused by an increase in the intra-abdominal pressure is unpredictable in ventilated patients. In the clinical setting the estimation of chest wall compliance it is needed in order to manage the ventilator. INTRODUCTION. The effects of the transmission of increased intra-abdominal pressure to the lungs are relatively known, but there is uncertainty regarding the pulmonary effects of intra-abdominal hypertension (IAH) during acute lung injury (ALI), since there are few studies evaluating these conditions concomitantly. Another controversial issue on this topic is the setting of ventilatory parameters for patients with concomitant IAH and ALI. It has been suggested that application of external positive end-expiratory pressure (PEEP) matching abdominal pressure could improve ventilatory performance during ALI and IAH [1] . OBJECTIVES. Our purposes were to provide physiological data on the cardiopulmonary effects of IAH during ALI and to evaluate the cardiopulmonary effects of PEEP matching abdominal pressure in an experimental model of IAH and ALI. METHODS. Eight anesthetized pigs (35-42 kg) were instrumented with pulmonary artery and arterial catheters and then submitted to IAH of 20 mmHg for 30 min through pneumoperitoneum with a CO 2 insufflator. ALI was induced by lung lavage with saline (3 ml/kg) and tween (2.5%). Pressure 9 volume curves of the respiratory system were performed by a quasi static low flow method during IAH, ALI and both conditions concomitantly. The lower inflection points (LIPs) of the inspiratory and expiratory limbs of the PV curves were also identified. PEEP was subsequently adjusted to 27 cmH 2 O for 30 min. RESULTS. IAH significantly decreased pulmonary and respiratory system static compliances and increased alveolar-arterial oxygen gradient. Concomitant IAH and ALI increased airway resistance and exacerbated the alterations in respiratory mechanics. IAH increased inspiratory and expiratory LIPs more pronouncedly than isolated ALI and the concomitance of both diseases did not induce a more significant increase in the value of LIPs, as compared to IAH alone. Thirty minutes of mechanical ventilation with PEEP identical to abdominal pressure moderately improved oxygenation and respiratory mechanics. Cardiac output was maintained during high PEEP through significantly increased heart rate. However, this short period of increased PEEP caused a statistically significant decline in stroke index, left ventricle stroke work index and right ventricle ejection fraction. CONCLUSIONS. Concomitant IAH and ALI produce important impairments in the respiratory physiology. The adjustment of PEEP to match abdominal pressure may improve the respiratory performance, nevertheless with a secondary hemodynamic derangement. INTRODUCTION AND OBJECTIVE. Lung hyperinflation associated with mechanical ventilation has traditionally been inferred from functional parameters such as dead space or compliance, but it may also be assessed by quantitative computed tomography (CT) . Because information about the relationship of these surrogates of lung hyperinflation is scanty, we analyzed these parameters simultaneously in an animal model. We hypothesized that an increase in hyperinflation detected by CT should be paralleled by a decrease in compliance and an increase in alveolar dead space. METHODS. Airway pressure, flow, and expiratory CO 2 were recorded continuously in 10 anesthetized, paralyzed and mechanically ventilated sheep with normal lungs. Expiratory CT scans of the entire lung were acquired and arterial blood gases measured at two different conditions. Before CTs and blood gas measurements, equilibration (10 min) was achieved during pressure controlled ventilation (PCV) with driving pressures of 15 cmH 2 O and the respective PEEP. The first CT (CT-1) was acquired at positive end-expiratory pressure (PEEP) of 10 cmH 2 O. After performing a recruitment maneuver (PCV with PEEP 40 and driving pressure of 20 cmH 2 O for 2 min), a second CT (CT-2) was acquired at 20 cmH 2 O PEEP. For each condition, the hyperinflated lung volume was quantified from the segmented CT images of the entire lung as the volume of regions with CT numbers \ -900 HU, and the nonaerated volume was calculated as the volume of regions with CT numbers between -100 and 100 HU. Both volumes were expressed as percentage of the total lung volume. The dynamic compliance (tidal volume divided by pressure difference (peak inspiratory pressure minus PEEP)) and the alveolar dead space-to-alveolar tidal volume ratio (VD alv /VT alv ) were computed. Data are given as median (extreme values) or mean ± SD. Paired t tests or Wilcoxon tests were used for comparison. Correlation was assessed by linear regression. RESULTS. The hyperinflated volume increased significantly (p = 0.02) from CT-1 (0.5 (0.0-2.1)%) to CT-2 (1.3 (0.1-6.5)%). Although negligible at both conditions (1.4 ± 1.0% vs. 0.5 ± 0.2%), the nonaerated volume was significantly lower during CT-2 (p = 0.02). The increase in hyperinflation detected by CT was neither associated with a decrease in compliance nor with an increase in alveolar dead space. Instead, compliance was significantly higher during CT-2 than during CT-1 (50 ± 7 vs. 43 ± 7 ml/cmH 2 O, p = 0.04), whereas VD alv /VT alv did not differ (0.36 ± 0.12 vs. 0.35 ± 0.10, p = 0.67). Changes in hyperinflation and compliance were not correlated (p = 0.05). CONCLUSION. In the present study of normal lungs, lung hyperinflation detected by CT was not accompanied by the expected changes in compliance and dead space. The relationship of the appearance of lung regions with gas contents [90% (corresponding to CT numbers \ -900 HU) and physiological indicators of lung hyperinflation must be further investigated. INTRODUCTION. Understanding the hemodynamic profile of patients admitted to the Intensive care unit (ICU) with shock can be clinically challenging. Invasive methods have been developed in order to evaluate and manage those patients. The role of impedance cardiography (ICG), a noninvasive method that provides accurate hemodynamic measurements, was not fully addressed in this clinical setting. To assess the role of ICG compared to pulse contour cardiac output analysis (PicCo Ò ) in hemodynamic profiling of patients admitted to the ICU with shock. We prospectively enrolled 37 patients admitted to a polyvalent ICU with shock. Patients (n = 15) with recent cardiac surgery, major pulmonary embolism, moderate to severe aortic disease, tachyarrhythmia or aortic aneurism were excluded. Data on hemodynamic parameters simultaneously obtained by ICG (BioZ ICG Monitor, Cardiodynamics, San Diego, California) and PicCo Ò within 6 h of admission were available for 14 patients. For each method, patients were divided in 4 groups according to hemodynamic profile: group 1cardiac output (CO) below and systemic vascular resistance (SVR) above the sample's median; group 2-CO and SVR above the median; group 3-CO and SVR below the median; group 4-CO above and SVR below the median. We calculated Cohen's kappa to assess the agreement between the two methods for hemodynamic profiling of patients. RESULTS. The sample's mean (SD) age was 58.8 (±15.8) years. Seventy-one percent were men and 36.4% had systolic dysfunction by echocardiography. The distribution of patients in terms of different hemodynamic profiles assessed by PicCo Ò was: 6 (42.9%) patients in group 1, 6 (42.9%) patients in group 4, 1 (7.1%) patient in group 2 and 1 (7.1%) patient in group 3. For ICG, the number of patients in each group was the same. The agreement between the two methods in hemodynamic profiling of patients was moderately strong and statistically significant (k = 0.66, 95% CI 0.33-0.99, p = 0.001). CONCLUSIONS. In our sample, we found a clinically acceptable agreement between PicCo Ò and ICG for the classification of patients in terms of different hemodynamic profiles. Our results support the use of ICG in hemodynamic monitoring of patients admitted to the ICU with shock. METHODS. Eight patients (mean age 67 ± 8; 6 male, 2 female) undergoing thoracic surgery for malignant pleural mesothelioma were studied. CO monitoring was simultaneously performed by MostCare-PRAM and Vigileo, two different PCMs that allow beat to beat analysis of arterial pressure waveform by means of a radial line. Intrathoracic chemotherapy (pleural perfusion) was applied at the end of surgery with 3 litres of 0.9% saline solution warmed at 42.5°C, containing cisplatin (100-200 mg/m 2 ), and infused over a period of 60 min. During the study, hemodynamic parameters estimated by the two PCMs were blinded to the anaesthesiologist who based his intraoperative management on standard monitoring and variables. The comparison of CO values by the two techniques was carried out during all the duration of the surgical procedure and collected at six times: T1: Pre-induction; T2: skin-incision; T3: one lung ventilation; T4: 15 min before HIC; T5: During HIC, T6: end of surgery. Pearson's correlation and Bland-Altman analysis were applied. RESULTS. Patients were hemodynamically stable throughout the study interval; a total of 48 MostCare-PRAM and Vigileo CO measurements were evaluated and compared. MostCare-PRAM CO values ranged from 3.4 to 6.2 l/min; Vigileo CO values ranged from 3.5 to 5.5 l/ min. Mean MostCare-PRAM CO values vs mean Vigileo CO values were: 4.10 ± 0.54 l/min vs 4.28 ± 0.41 l/min; the overall correlation was R = 0.76 with a mean bias ± 2 SD of 0.03 ± 0.74. Table 1 shows mean MostCare-PRAM CO and Vigileo CO values, standard deviations (SD), mean bias, 95% limits of agreement, Pearson's coefficient (R) and percentage of error (PE%) at each time. INTRODUCTION. The pulse oximetry plethysmographic variation (Pleth Variability Index = PVI) has recently been proposed as a surrogate for arterial pulse pressure variation (PPV) to guide fluid therapy non-invasively in stable patients undergoing surgery. To compare PVI and PPV in patients with sepsis and to investigate the influence of the PVI site of measurement (finger, ear, forehead), peripheral perfusion, and the use of vasoactive drugs on the agreement between PVI and PPV. METHODS. 249 PVI measurements (Radical 7, Masimo, Irvine, CA) performed using a finger probe (PVIfi), a ear probe (PVIea) and a forehead probe (PVIfo) were simultaneously recorded on a computer and compared to PPV in 28 patients with sepsis (all but four patients were receiving norepinephrine). The pulse oxymeter-derived marker of peripheral perfusion (perfusion index = PI) and SaO 2 were also recorded. RESULTS. PPV ranged from 1 to 32% (mean 9 ± 5%) while PVIfi ranged from 2 to 41% (mean 13 ± 7%), PVIea from 2 to 44% (mean 12 ± 6%) and PVIfo from 2 to 46% (mean 12 ± 7%). PVIfi, PVIea, PVIfo were significantly (p \ 0.001) but weakly correlated with PPV. Correlation coefficients (linear regression), bias, SD, and percentage errors between PPV and PVI, as well as PI and SaO 2 values are reported in the Table 1 . The difference between PPV and PVIfi (bias) was significantly (p \ 0.0001) correlated with PI (r = 0.38) and the dosage of norepinephrine (r = 0.30). Comparable findings were observed at the other sites (ear and forehead). CONCLUSIONS. We conclude that 1. PVI and PPV are not interchangeable in patients with sepsis, whatever the site of measurement. 2. The difference between PPV and PVI is significantly influenced by peripheral perfusion and the dosage of vasoactive drugs. DECREASED CENTRAL BLOOD VOLUME OF CIRRHOTIC ICU PATIENTS A. Umgelter 1 , W. Reindl 1 , B. C. Saugel 1 , W. Huber 1 , R. M. Schmid 1 1 Technical University Munich, 2nd Medical Department, Munich, Germany Patients with advanced cirrhosis display a characteristic hemodynamic disturbance. According to the arterial vasodilation hypothesis, arterial vasodilation leads to sequestration of blood in the abdomen, reduced effective arterial blood volume and a compensatory increase in vasopressor tone jeopardizing renal blood flow. Cirrhotic cardiomyopathy may in addition limit increases in cardiac output necessary to compensate for the reduced peripheral resistance. Studies have questioned the possibility to raise cardiac output by plasma expansion in patients with advanced cirrhosis. OBJECTIVE. To assess whether the hypothetical reduction in effective arterial blood volume is reflected by decreased measurements of global end-diastolic volume index (GEDVI) in cirrhotic patients and whether these patients are in a volume responsive state. METHODS. Hemodynamic data obtained by transpulmonary thermodilution (PiCCO, Pulsion Medical Systems, Munich, Germany) of all invasively monitored cirrhotic patients treated in a gastroenterological ICU during one year (2007) were analyzed. Initial measurements were compared to measurements after 48 h. Results were compared to normal values published for the measuring device and to those of a random sample of non-cirrhotic medical non-cardiologic patients of the same ICU. RESULTS. 25 cirrhotic patients (13 male, 12 female, mean age 55 (±10) years; Child Pugh score 12 ± 2, MELD score 28 ± 9) were monitored for 48 h or more and included in the study. Global end-diastolic volume index (GEDVI; normal value 680-800 mL/m 2 ) of cirrhotic patients was lower than that of non-cirrhotic patients (604 ± 131 mL/m 2 vs 766 ± 136 mL/ m 2 ; p \ 0.001), systemic vascular resistance index (SVRI; normal values 1,200-2,000 dyn/ cm 5 /m 2 ) was also lower in cirrhotic patients (1, 384 ± 575 dyn/cm 5 /m 2 vs 1,719 ± 605 dyn/ cm 5 /m 2 ; p = 0.005), whereas cardiac index (CI; normal values 3.0-5.0 L/min/m 2 ) was increased (3.9 ± 1.2 L/min/m 2 vs 3.4 ± 1.4 L/min/m 2 ; p = 0.021). In cirrhotic patients there were increases in GEDVI (to 689 ± 116 mL/m 2 ; p \ 0.001) and CI (to 4.65 ± 1.15 L/min) during the first 48 h of ICU treatment. Relative changes of GEDVI and CI, however, were not correlated. SVRI was decreased (to 1195 ± 419 dyn/cm 5 /m 2 ; p = 0.021) and the relative change was inversely correlated with the relative increase in CI (r = 0.462; p = 0.02). In non-cirrhotic patients, there was a close correlation between increases in GEDVI and CI (r = 0.808; p \ 0.001). CONCLUSION. Compared to published normal values and to non-cirrhotic ICU-patients, cirrhotic-ICU patients had a significantly reduced GEDVI at the beginning of invasive hemodynamic monitoring. After 48 h of intensive care treatment, GEDVI and CI were significantly increased. The lack of a correlation between these changes suggests that changes in afterload or in myocardial function may have contributed to the hemodynamic improvement. SUMMARY. Hemodynamic instability during haemodialysis (HD) is related to decrease in blood volume and cardiac output which result from the imbalance between ultrafiltration rate (UFR) and the plasma refilling rate. Compensatory mechanisms for hemodynamic stabilisation involve increase in heart rate, cardiac output and peripheral vascular resistance. Increased oxygen extraction in peripheral tissue (i.e. arterio-venous oxygen difference) is an additional compensatory mechanism. In patient at rest, mixed venous oxygen saturation (ScvO 2 ) reflects cardiac output and oxygen extraction (ERO 2 ; with ScvO 2 = 1 -ERO 2 ). The aim of the study was to evaluate the effect of UF volume on global tissue oxygen, as reflected by ScvO 2 , compared to clinical and biological parameters PATIENTS AND METHOD. After local ethical committee approval, 12 patients with central venous catheter and/or double lumen catheter HD in 34 consecutive sessions were studied. The amount of UF was prescribed at the discretion of the same physician, who determined the amount of fluid to be removed based on individual clinical parameters including fluid balance, previous haemodialysis sessions, estimated dry weight and chest Xray. Non invasive cardiac index (CI) was evaluated via transthoracic bioelectrical impedance (Physioflow Ò ). Central venous blood sample for ScvO 2 was drawn hourly. Pulse oxymetric oxygen saturation (SpO 2 ), heart rate, non invasive blood pressure and UF volume were recorded each hour. Arterial blood gas, haemoglobin (Hb) and Brain Natriuretic Peptide (BNP) were determined performed before (H0) and 15 min after completion the haemodialysis session (H4). Data are expressed as mean ± maximal and minimal values. Data analyses were analyzed using SPSS for Windows Software. Analyses were carried out by Student's t test, Wilcoxon signed rank test and correlation tests (Pearson and Spearman) when appropriate. p \ 0.05 was considered significant. RESULTS. ScvO 2 decreased between H0 and H4 (75 vs. 66% p \ 0.0001). The decrease in ScvO 2 was noticed from H0 and the whole HD period. Although significant, a non relevant correlation (r = -0.381) was found between ScvO 2 and UF volume or cardiac index (r = 0.281). The correlation (r = -0.381) between weight loss and ScvO 2 variation was not significant (p = 0.09) due to lack of power of the study sample. CONCLUSION. UF volume affects tissue oxygenation as reflected by ScvO 2 , and might decrease at a critical level of O 2 supply-dependency. ScvO 2 , if available, seems an interesting tool to determine UF rate and volume. OBJECTIVES. Central venous oxygen saturation variation (DScvO 2 ), which is measured via a central venous catheter, could be an alternative method to define responders (R) and non responders (NR) to VE in absence of CI measurements. We included prospectively 30 critically ill patients, equipped with radial arterial and pulmonary artery catheters. Patients with severe sepsis or septic shock were excluded. CI, mixed venous oxygen saturation (SvO 2 ) and ScvO 2 were measured both before and after VE in hypotensive patients. CI, SvO 2 , and ScvO 2 changes (D) in % following VE were correlated using linear regression analysis. Thereafter, areas under the receiver operating characteristic (ROC) curves (AUC) to define R and NR were calculated for ScvO 2 , SvO 2 , MAP and CVP variations (D), varying the discriminating threshold of each parameter. RESULTS. Before volume infusion mean CI value was 2.33 ± 0.5 L min -1 m -2 and increase to 2.54 ± 0.54 L min -1 m -2 following VE. SvO 2 changes correlated with CI changes (r 2 = 0.24, p \ 0.05). ScvO 2 changes correlated with CI changes (r 2 = 0.44, p \ 0.05). On 30 fluid challenges, patients were classified 14 times as responders and 16 times as non-responders respectively. ROC curve testing the ability of DScvO 2 to discriminate R and NR following VE had an AUC of 0.90 ± 0.05 (95%CI; 0.79-1.0, p \ 0.05) for 30 fluid infusions (Fig. 1) . The threshold DScvO 2 value of 8% allowed discrimination between R and NR patients with a sensitivity of 64% (95% CI; 44-80%) and a specificity of 100% (95% CI; 88-100%). CONCLUSIONS. In hypotensive critically ill patients in absence of cardiac index measurement, DScvO 2 following VE could be a useful alternative method to classify fluid responsiveness responders from non-responders. (ScvO 2 ) in the emergency department has been shown to reduce mortality [1] , but recent studies in intensive care have found that low ScvO 2 is neither common nor a good predictor of poor outcome [2, 3] . OBJECTIVES. We looked at whether ScvO 2 taken on ICU admission was associated with patient outcome in our 17-bed mixed medical/surgical ICU. Unselected patients who had a central line placed on admission to the ICU or those who already had central venous access were included in the study. Admission ScvO 2 , arterial-sample lactate concentration and base excess (BE) were recorded, along with basic clinical information and outcome data (ICU and hospital mortality). Subsequent treatment was determined by the clinician in charge. Of 61 patients with a mean age 65 (Standard Deviation 16), 38 (62%) were male. 45 (74%) were surgical patients, and 28 (46%) were planned admissions after surgery. 25 (41%) met sepsis criteria. 18 (30%) died in hospital, 12 (20%) of them in the ICU. For all patients median ScvO 2 was 74.2% (interquartile range 67. 6, 81.2) , median lactate was 1.3 mmol/L (0.9, 2.1) and median BE was -1.8 mmol/L (-4.2, 0.5) . ICU survival was associated with a less negative BE (p = 0.005) and being a surgical patient (p = 0.005). Hospital survival was associated with a less negative BE (p \ 0.014). Neither ScvO 2 nor lactate concentration were associated with either outcome. OBJECTIVE. In hemodynamically unstable patients with spontaneous breathing activity, volume responsiveness cannot be predicted by the respiratory variation in arterial pressure. Bioreactance (Reliant Ò , Cheetah) is a non invasive technique which can measure stroke volume and be used for hemodynamic monitoring. Our objective was to test whether volume responsiveness can be predicted by the response of stroke volume measured by biorecatance to passive leg raising (PLR) in patients with spontaneous breathing activity. DESIGN AND SETTING. Prospective study in the respiratory critical care of a university hospital. PATIENTS. 10 patients with spontaneously breathing activity considered for volume expansion. An increase in stroke volume index (SVi) of 15% or more after volume expansion defined a responder patient. We measured the response of the bioreactance stroke volume to passive leg raising and to saline infusion (500 ml over 15 min). RESULTS. The proportional changes in (SVi) induced by PLR were correlated with the proportional changes in SVi induced by volume expansion (r = 0.64, p \ 0.05). The proportional changes in cardiac index (CI) induced by PLR were also correlated with the proportional changes in CI induced by volume expansion (r = 0.64, p \ 0.05). A passive leg raising induced increase in stroke volume of 9% or more predicted an increase in stroke volume of 15% or more after volume expansion with a sensitivity of 100% and a specificity of 75%. CONCLUSIONS. In our hemodynamically unstable patients with spontaneous breathing activity the response of bioreactance (Reliant Ò , Cheetah) stroke volume to passive leg raising was a good predictor of volume responsiveness. In spontaneous breathing patients, fluid responsiveness can be assessed totally non invasively using a bioreactance device. INTRODUCTION. As a direct indicator of the global cardiac pumping efficiency, the cardiac stroke volume (SV) has major diagnostic value in numerous conditions, including cardiovascular diseases or congestive heart failure. Electrical impedance tomography (EIT) has been reported to be capable of dynamically and noninvasively measuring changes of blood volume in the thorax. Most studies, however, have only dealt with healthy volunteers or animals and there has been limited data on EIT-derived SV measurements in respiratory failure. OBJECTIVE. We designed a study to examine if EIT can also be used to noninvasively and continuously determine SV in severe cases of ARDS without further calibration methods and without holding the breath. In 8 anesthesized and mechanically ventilated pigs, lung injury was induced by central venous oleic acid injection and abdominal hypertension. PEEP and FiO 2 were set guided by the ARDSnet protocol (RR = 35 min -1 ). After maximal recruitment of the lungs, two different PEEP levels for each pig were randomly set. One for an open lung (no decrease in PaO 2 ), one after detection of derecruitment. Reference cardiac output was measured by thermodilution and divided by the heart rate (HR) to obtain reference SV. Impedance changes related to perfusion were monitored by EIT and calculated as described in [1] . Ventricular ROI was extracted using principal component analysis (PCA). EIT stroke parameter was calculated as B 9 SQRT(A), see Fig. 1 . CONCLUSION. We found a good, but not a high correlation between non-calibrated EITderived SV parameter and reference SV. It seems necessary to use calibration methods as known, e.g., from pulse contour analysis. INTRODUCTION. Invasive arterial pressure monitoring is the method of choice for arterial pressure monitoring in most ICUs. The technique combines feasibility, continuous monitoring, the potential to derive some important hemodynamic parameters and constant access to arterial blood gases measurements. OBJECTIVE. The purpose of this study was to evaluate whether the invasive and noninvasive blood pressure measurement correlate in critically ill patients in a general ICU. Furthermore, we tried to isolate parameters that influence the accuracy of invasive blood pressure monitoring. METHODS. All consecutive patients admitted in our ICU for a 3 months time were included in the study. All patients underwent standard radial artery catheterization for invasive blood pressure monitoring and at the same time a cuff was placed in the arm for non-invasive monitoring. For each patient non-invasive measurements were performed three times a day and at the same time the invasive blood pressure was recorded for future comparisons. Once a day we were also measuring the frequency of the arterial circuit and the transducer and we compared the difference between the actual and the proposed frequency to the difference between the invasive and the non invasive monitoring. RESULTS. Thirty six consecutive critically ill patients were included in the study. Mean age was 61.2 years, mean APACHE II score was 18 and mean ICU stay was 28.7 days. Median systolic, diastolic and mean arterial pressure for invasive and non-invasive monitoring is shown in Table 1 . Median frequency of the circuit was 13.37 Hz whilst the proposed frequency from the manufacturer of the transducer is 15-20 Hz. CONCLUSION. Invasive monitoring of arterial blood pressure is the method of choice for arterial pressure monitoring in the ICU setting. There is though a substantial difference between the invasive and the non-invasive technique. If there is an increased difference between the proposed frequency of the circuit and the actual one, the invasive measurement is inaccurate. There should be meticulous preparation of the circuits from the nursing staff to avoid such situations. PICCO- 2-DERIVED  PULSE  CONTOUR  CARDIAC  INDEX  VS.  THERMODILUTION-DERIVED CARDIAC INDEX: A PROSPECTIVE STUDY  WITH RECALIBRATION AFTER FIXED INTERVALS OF 1, 2, 4, 6 AND 8 H W. Huber 1 , J. Koenig 2 , B. Saugel 2 , V. Phillip 2 , H. Einwaechter 2 , M. Treiber 2 , V. Becker 2 , C. Schlag 2 , R. Vogelmann 2 , F. Eyer 2 , R. Schmid 2 1 Technical University of Munich, Klinikum Rechts der Isar; 2nd Medical Department, Munich, Germany, 2 Technical University of Munich, Munich, Germany INTRODUCTION. Thermodilution using the PAC or PiCCO-based transpulmonary thermodilution (TD) are the gold standards for cardiac index (CI) determination. Additionally, continuous monitoring of CI based on pulse contour (PC) analysis is increasingly used. After calibration by TD, the PiCCO device is able to assess CI based on PC analysis. Despite an overall good short-term-correlation of CIpc and CItd in several studies, the manufacturer suggests recalibration by TD within B8 h. One retrospective study suggests decreasing accuracy after 1-2 h. By contrast, recent prospective data suggest acceptable long-termaccuracy (Critical Care 2009; 13S1: P217). However, these data were collected from routine measurements without fixed intervals between two TDs. OBJECTIVES. Therefore, it was the aim of our study to prospectively investigate the accuracy of CIpc exactly 1, 2, 4, 6 and 8 h after the last calibration. In 15 consecutive patients 29 data-sets each including 6 TDs after intervals of 1, 2, 4, 6 and 8 h were recorded. In each TD measurement (triplicate TD) CIpc was recorded immediately before re-calibration by TD and compared to CItd. Statistics: Spearman correlation, Bland-Altman and multiple regression analysis. RESULTS. 174 measurements with a mean time-lag between two TDs of 4.2 h were recorded. Patients characteristics: 9 male, 6 female, age 56.4 ± 13 years; APACHE-II 23.4 ± 6.2. The 174 pairs of CIpc and CItd showed a highly significant correlation (p \ 0.001; r = 0.898). There was no significant difference between CIpc vs. CItd (4.37 ± 1.53 vs. 4 .27 ± 1.48 l/min m 2 ). Analysis according to Bland-Altman demonstrated a mean bias of -0.101 ± 0.68 l/min m 2 (lower and upper levels of agreement -1.43 and 1.23 l/min m 2 ; percentage error of 31%). The percentage errors after 1, 2, 4, 6 and 8 h were 29, 27, 26, 36 and 36%, respectively. In univariate analyses, the difference of CItd and CIpc was not correlated to the interval to the last TD (p = 0.563; r = -0.044), but it was correlated to CIpc immediately before recalibration (r = -0.243; p \ 0.001) and the changes in SVRI derived from TD as well as PC compared to the previous SVRI (p \ 0.001). Similarly, multiple regression analysis demonstrated that the difference of CItd and CIpc was not associated to the interval to the last TD (p = 0.563). By contrast, the bias (CItd-CIpc) was highly significantly associated with CIpc (p \ 0.001) and changes in SVRI (p \ 0.001). Sensitivity, specificity, positive and negative predictive value of CIpc were high regarding elevated (CItd [ 5 L/min m 2 ; 91, 92, 85 and 96%) and decreased CItd (CItd \ 2.5 L/min m 2 ; 63, 95, 67 and 95%). CONCLUSION. CIpc and CItd are highly significantly correlated. Despite a non-significant trend to slightly increasing percentage errors after 6 and 8 h, the interval to the last calibration has, if at all, little impact on the accuracy of CIpc. By contrast, re-calibration should be considered in case of substantial changes of SVRI. INTRODUCTION. Thermodilution using the PAC and transpulmonary thermodilution (TD) using the PiCCO-device are the gold standards for Cardiac Index (CI) determination. In addition to CI, the PiCCO provides additional volumetric parameters derived from TD such as global enddiastolic volume index GEDVI and extravascular lung water index ELWI as well as pulse contour (PC) derived continuous CI (CIpc). According to the manufacturer's suggestion, TD usually is performed by injection of 15 ml of cold saline via a central venous catheter (cvc) . Little is known about the impact of differing volumes of these catheters, thus retaining different volumes of the indicator bolus. In certain circumstances large volume catheters such as Shaldon catheters could be used for TD, however there are no data on correction for the higher volumes of these catheters as compared to a conventional cvc. OBJECTIVES. Therefore, it was the aim of our study to prospectively compare the accuracy of TD via a Shaldon catheter using corrected TD volume (15 ml + (catheter volume of Shaldon -catheter volume of conventional cvc)). In 9 pigs (German landrace; female; 30-50 kg) a Shaldon catheter (Gambro GamCat 150, 175 or 250 mm; volume of the venous lumen 1.13, 1.35 and 1.65 ml, respectively) and a conventional cvc (Arrow multi-lumen; volume of the distal lumen 0.44 ml) were place in the left and right V. iug. int., respectively. Identical positions of the tips were verified by X-ray. A 20 cm, 5 Fr arterial PiCCO catheter was placed in the A. femoralis. A total of 93 couples (7-12 per animal) of triplicate TD measurements using an indicator bolus of 15 ml via the cvc and 15 ml + (volume Shaldon -0.44 ml) via the Shaldon catheter were recorded. Statistical analysis: Wilcoxon test; Spearman correlation. Bland-Altman analysis. Calculation of the percentage error according to Critchley. RESULTS. CItd, CIpc, stroke volume index SVI, SVRI, global ejection fraction (GEF), GEDVI, ELWI and pulmonary vascular permeability index PVPI measured by TD via the Shaldon correlated highly significantly (p \ 0.001 for all comparisons) with the values derived from TD via cvc (r = 0.962, r = 0.970, r = 0.976, r = 0.924, r = 0.879, r = 0.895, r = 0.962 and r = 0.832, respectively) with percentage errors below the critical threshold of 30%: 7.8, 9.4, 9.0, 24.8, 18.2, 14.3, 15.2 and 25 .9%, respectively. The measurements using cvc and Shaldon were not significantly different regarding CIpc, SVI and SVRI. Measurement via Shaldon significantly underestimated CItd (mean difference 0.22 ± 0.18 L/min m 2 ; p \ 0.001), GEDVI (38 ± 42 ml m -2 ; p \ 0.001), ELWI (0.24 ± 0.75 ml/kg; p = 0.003). By contrast, TD via Shaldon overestimated GEF (-2.7 ± 3.3; p \ 0.001) and PVPI (-0.12 ± 0.32; p \ 0.001). CONCLUSIONS. Using a corrected indicator bolus, TD via Shaldon catheters provides data with appropriate accuracy. Regarding low percentage errors and low bias, statistically significant differences in 5 of 8 parameters are of limited clinical relevance. METHODS. US cannulation of the BCV was performed in 26 paediatric patients admitted to our PICU. All patients required a short term central venous catheter, single or double lumen, for i.v. infusion and/or hemodynamic monitoring. Though calibre and length of the catheters were different, all were inserted by using a modified Seldinger technique (21G needle + 0.018 00 non-J guidewire + 4 Fr micro-introducer and dilator). Smaller catheters (\4 Fr) were inserted directly inside the micro-introducer; catheters [4 Fr were inserted over their own 0.025 00 guidewire, after introducing the 0.025 00 guidewire through the 4 Fr microintroducer. In all patients, a MicroMaxx Sonosite Ó with a 10-14 Mhz probe was utilized. The BCF was visualized longitudinally by scanning the upper anterior mediastinum, and needle was threaded 'in plane' towards the vein, under direct US guidance. Patients' age ranged from 20 days to 10 years (weight 2-30 kg). The BCV was easily visualized by US in all patients. In most cases (24/26), the right BCV was chosen. In all patients, US was also useful to monitor the trajectory of the guidewire inside the BCV: in 4 neonates, the guidewire was visualized by US up to its entrance in the superior vena cava. The success rate was 100%, with no accidental arterial puncture and no pneumothorax or hemothorax or local hematoma. In most cases (20/26) the BCV was punctured at first attempt. CONCLUSIONS. BCV cannulation guided by ultrasonography can be performed safely and easily in acutely ill pediatric patients. The US venipuncture of the BCV appears to be easier if compared to IJV, since the BCV (a) has a diameter constantly larger, (b) it is more stable, (c) it does not collapse with breathing. When puncturing the vein 'in plane' (i.e. threading the needle within the plane of the probe), the risk of failure or complications is minimized. BACKGROUND. Recent studies on critically ill patients demonstrate the overwhelming benefits of tight glycemic control in the Intensive Care Unit (ICU). However, there is a paucity of data in the pediatric trauma population. Our objectives were to determine the significance of blood glucose levels on length of stay, clinical outcomes and mortality in traumatically injured pediatric patients. After approval from the Institutional Review Board (IRB), we retrospectively reviewed all injured pediatric patients (age 17 or less) with an Injury Severity Score (ISS) of 9 or greater admitted to the trauma service and the Pediatric Intensive Care Unit (PICU) between January 1, 2005 and December 31, 2006 . Ninety four patients were identified. We excluded eight patients who did not have documented blood glucose levels at the time of admission. We evaluated data for ICU length of stay, ventilator dependent days, total hospital length of stay, infectious complications, Glascow Coma Scale, and outcome. Patients who died had significantly higher admission serum glucose values than those who survived (201 vs. 153 mg/dl (p \ 0.048)). Of the 4 pts who died, 3 had admission glucose greater than 200 mg/dl. The average admission glucose for patients discharged to home was 142.2 mg/dl. Patients discharged to rehab had an average glucose level of 193 mg/ dl (p \ 0.00). Eleven patients out of the included 86 (13%) developed an infection. The average admission glucose for this group was 186 vs. 150 mg/dl (p \ 0.020) for the group of patients who did not acquire any infections. Out of the patients who survived, 22 patients (27%) had a serum admission glucose [180 mg/dl. This subgroup of patients had significantly longer ICU length of stays (9.0 vs. 4.0 days, p \ 0.017), longer ventilator dependent days (6.3 vs. 1.4 days, p \ 0.008) as well as longer total hospital length of stay (13.4 vs. 7.5 days, p \ 0.008) when compared to patients with initial glucose \180 mg/dl. With regard to insulin therapy, there were no statistically significant differences in ICU length of stay and ventilator dependent days when comparing patients with admission glucose [180 mg/dl treated with insulin vs. those not receiving insulin. However, a decrease in the total length of stay was demonstrated in the insulin treated group (10.3 vs. 15 days in the non-insulin group) CONCLUSION. This study demonstrates poor overall outcome with elevated admission serum blood glucose. Patients with elevated admission serum glucose levels ([180 mg/dl) were more likely to suffer from infections, had significantly prolonged ICU length of stay, ventilator dependent days and total hospital length of stay compared with patients with lower blood glucose. Furthermore, patients with admission glucose [200 mg/dl were more likely to die during their hospitalization. Tight glucose control and admission glucose is predictive of good outcomes in the pediatric trauma population. R. Samransamruajkit 1 , U. Termsansarp 2 , J. Taweeworakiet 2 , J. Taweeworakiet 3 , N. Prapphal 1 , P. Towiwat 3 1 Chulalongkorn, Pediatrics, Bangkok, Thailand, 2 Chulalongkorn U, Pharmacology, Bangkok, Thailand, 3 Chulalongkorn, Pharmacology, Bangkok, Thailand BACKGROUND. Ventilator associated pneumonia (VAP) is a leading cause of morbidity and mortality in PICU. Early and appropriate antibiotics prescribed are critical for survival of VAP patients. Knowledge of local resistance rate trends is invaluable when considering empirical antibiotics. Our study was to determine the prevalence, microbiological data, antibiotics therapy and clinical outcomes in Pediatric VAP. MATERIAL AND METHODS. We retrospectively reviewed Infants and children admitted to the PICU who had diagnosis of VAP during [2004] [2005] [2006] [2007] . Clinical data, microbiology, treatment and outcomes were analysed. RESULTS. There were 101 patients diagnosed with VAP by CDC criteria. 64 (63.4%) were male and 37 (36.6%) were female. Their average age was at 2.72 ± 4.51 years. They were on mechanical ventilator for 14.72 ± 16.28 days before VAP was diagnosed. The most common causative organisms were A Baumanii (32%), P aeruginosa (17%), K pneumonia (8%) and S aureus (5%). Co-infection(6%) was commonly found with A baumanii and P aeruginosa. There were 71% of MDR and 8% of PDR. A. baumanii was mostly sensitive to cefoperazone (36%) and aminoglycoside (21%). P aeruginosa was mostly sensitive to aminoglycoside (76%) and S aureus was mostly sensitive (83%) to glycopeptides group. Carbapenem (25%) was mostly prescribed as initial antibiotics followed with cefoperazone (17%). The duration of mechanical ventilation and PICU length of stay were at 28.54 ± 27.25, 31.1 ± 26.2 days, respectively. The mortality of VAP was at 42%. Previous antibiotics used was associated with VAP mortality (OR = 8.75, 95%CI = 1.07-71.23, p = 0.016) CONCLUSIONS. VAP was associated with high mortality. MDR and PDR gram negative organisms were commonly found as causative agents. Appropriate empirical antibiotics coverage could be guided by local microbiological data (data represent Mean ± SD). PERFORMANCE OF SEVERITY SCORING SYSTEMS IN THE VENTILATED CHILDREN IN RUSSIA I. N. Popova 1 , N. Sitaeva 2 , Y. V. Kryukov 1 1 Regional Children's Teaching Hospital §1, ICU, Voronezh, Russian Federation, 2 State Medical Academy, Neonatology, Voronezh, Russian Federation BACKGROUND. There are exist a lot of different scoring systems to estimate the illness severity of pediatric patients and to predicting morbidity and mortality. They have been infrequently compared, especially out of the countries where they have been designed. OBJECTIVES. To compare mortality prediction models Pediatric Risk of Mortality score (PRISM), Pediatric Index of Mortality (PIM) in the ventilated children and Clinical Risk Index for Babies (CRIB) and Score for Neonatal Acute Physiology (SNAP-II)-in the newborn in ICU of a referral Regional Children's Hospital, Russia. METHODS. Data were collected on 938 ventilated children, 777 of them were the newborn, 419 of which were premature, admitted in sequence to the multidiscipline intensive care unit of the referral regional 600-bed children's hospital from January 1, 2005 to December 31, 2007 In the newborn the mean birth weight was 2,196 (770-4,500) g; gestational age 32 (27-41) weeks; male 479 (61.6%), female 298 (38.4%); 1 min Apgar score less than 4 was in 119 (15.3%) and 5 min Apgar score less than 6 was in 196 (25.2%) babies. In children older than 1 month the mean age was 9.6 months (1.5-23 months) . The total mortality rate was 10.8%. Discrimination was quantified as the area under the curve (AUC) for the receiver operating characteristic curves (ROC). The calibration of the model with the best discrimination was assessed using the standardized mortality ratio. RESULTS. Discrimination of all the scales was good: AUC for PRISM 0.811 ± 0.024; PIM 0.813 ± 0.032; CRIB 0.821 ± 0.03; SNAP-II -0.783 ± 0.03. CRIB and SNAP-II admission score both were correlated with sepsis in the newborn. The standardized mortality ratios for the CRIB and SNAP-II was 1.35 and 1.23 respectively. Using logistic regression method a model for mortality prediction in the newborn with the independent variables birth weight and CRIB (AUC = 0.869) was constructed. CONCLUSION. Discrimination for these illness severity scores is good. Published models for severity of illness under predict hospital mortality in the ventilated children in Russia and need recalibration. OBJECTIVE. The aim of our study was to estimate the function of neutrophils in newborn with severe bacterial infections after cardiosurgery. METHODS. Blood plasma samples from 25 ICU newborns with congenital heart disease (mean age 7 (4-21)) days, median weight 3.23 (1.98-4.24 ) kg) with systemic bacterial inflammation (procalcitonin level [ 2 ng/ml) were taken on 3 day after cardiosurgery. Phagocytic activity were measured as the percentage of cells to ingestions latex particles (d = 1.5 m km) in vitro. Also measured the potential phagocytic cell to induced in vitro by zimozan and lipopolysaccharide of Klebsiella pneumoniae (SIGMA, Germany, concentration -0.1 mkg/ml). Procalcitonin level was measured by immunoluminometric method (PCT sensitive LIA, BRAHMS, Germany). The data were compared by Mann-Whitney U test, p value of \0.05 was considered statistically significant. The data are expressed as median and 25th-75th percentiles. RESULTS. In both group of newborn with systemic bacterial infectious the level of procalcitonin were extremely high, repaired phagocytic activity after surgery were a good prognostic sign: the percentage of phagocytic activity and the count of cells with high ingestions activity were statistically significant higher from survived in comparison with lethal outcome patients (Table 1 ) . Meanwhile the neutrophils with extremely low phagocytic activity have shown the capacity to induce in vitro at 58% (11/19) patients with lethal outcome. Detected the correlation dependence (r = 0.79, p = 0.000000) between the ratios of induction with two type of inducing substances (zimosan vs lipopolysaccharide) in vitro experiment, that may be give evidence about TLR-independent pathways of neutrophil dysfunction. CONCLUSION. Neutrophil dysfunction plays a key role in adverse prognosis in critically ill newborn with severe infection after cardiosurgery. However, neutrophils with decreased phagocytic function have showed the potential to enhance in vitro that may useful as target for therapy. RESULTS. during the study period, 23 patients with ARF secondary to FB inhalation (0.6% of total admissions) were admitted, their age ranged from 7 months to 7 years with a mean of 28 months, 16 (69.5%) of whom were male. ARF was associated to a neurological distress in three cases (13%). A cardiorespiratory arrest was reported in two patients. Radiological abnormalities were seen in 82.6% of the cases. Bronchoscopy confirmed the diagnosis in all cases and allows the extraction of the FB with a delay of 15 ± 12.8 days after inhalation. Aspirations were primarily into the right lung (60.8%) and 82.6% of the foreign bodies were of vegetal origin. Seventeen patients (73.9%) required MV during a mean period of 4.8 ± 9.3 days. Complications were dominated by pneumonia in 12 cases (52.2%) and pulmonary air leak in five patients (21.7%). Pneumonia was associated with longer aspiration time (p = 0.045). One patient died. Death was caused by a prolonged cardiorespiratory arrest with an important cerebral damage. The mean length of stay in survival patients was 5.8 ± 10.3 days. CONCLUSIONS. FB inhalation is an uncommon life threatening event (0.6% of total admissions) in pediatric patients that can manifest with ARF requiring MV. Diagnosis should be evoked rapidly and confirmed by bronchoscpopy allowing a prompt removal of the FB. A longer aspiration time seems to be correlated to pneumonia.  A 6-week old baby presented with cyanosis, severe metabolic acidosis and hyponatraemia due to near drowning. She was paralysed for intubation and on-going ventilation, and cared for on our neonatal intensive care unit (NICU) pending transfer to a paediatric intensive care unit (PICU). Attachment of a cerebral function monitor showed status epilepticus. Prompt treatment with phenobarbital abolished the seizing, but she was transferred out to a regional PICU that did not offer cerebral function monitoring (CFM) or out-of-hours EEG assessment. Cerebral function monitoring was introduced in 1969 for use in resuscitated adults following cardiac arrest, and has been increasingly used in neonatal intensive care in the last decade. OBJECTIVE. Our aim was to survey all PICUs in the United Kingdom (UK) to determine availability and use of CFM and out-of-hours EEG monitoring. Telephone survey of all 33 PICUs in the UK conducted in March-April 2009. All 33 (100%) UK PICUs provided data regarding available round-the-clock neuromonitoring (Table 1) : CASE REPORT. We report three cases of Merrf syndrome, all from a family. First child, ten years old, had the first presentation with a refractory status epilepticus, not responding to benzodiazepines, phenytoine, thiopental and propofol. With the presentation of his brother 2 years after the girl, we made the diagnosis of Merrf syndrome, but we could not help him for the refractory status in wich he presented. In the same family is and another girl, wich has been too diagnosed for Merrf syndrome, and presents epilepsy. In refractory status in such cases, given the difficulty to treat SE, we think for a supplemental administration of continuous ketamine infusion with midazolam. CONCLUSION. In refractory status epilepticus even to phenytoin, thiopental and propofol, after failure of GABA-ergic anesthetics, we suggest to incorporate ketamine into the therapeutic protocol for the strong anticonvulsant properties of ketamine due to increased NMDA receptor expression with ongoing seizure activity. Craniosynostosis is a congenital anomaly in which one ore more cranial sutures close prematurely. It occurs in approximately one of every 2,000-3,000 births, with males affected more frequently than females. The craniosynostosis may be simple, involving one suture, or it may be very complex. Though performed as extradural procedure, craniofacial reconstruction can lead to significant blood loss from scalp and cranium and challenge the pediatric anesthetist, especially because the correction of the cranium coincides in a period of physiologic anaemia. Central venous access to monitor cardiac filling pressure is used as 'gold standard'. Blood loss, fluid shifts can lead to major problems estimating fluid maintenance and can result in low haemodynamic performance although invasive monitoring is used. The use of the non-invasive monitoring by oesophageal Doppler can improve the haemodynamic management by detecting early hypovolaemia. A 6 months old child presented to extensive remodeling without comorbidities. The induction of anaesthesia and the placement of an arterial and central venous line, intravenous lines and a gastric tube were routinely performed. After induction the patient was hemodynamically stable. The oesophageal Doppler probe could easily be fixed to the tracheal tube to assure monitoring throughout the whole procedure with only minimal access to the head under the drapes. Initial volume administration (25 cc of colloid solution over 5 min) under Doppler monitoring improved the stroke volume index (SVI in ml/m 2 ) from 19.2 to 26.0 whereas the arterial blood pressure (ABP in mmHg) dropped from 64 to 54 and the central venous pressure (CVP in mmHg) from 10 to 7. A following decrease of SVI from 26.0 to 19.3 during hemorrage was not displayed by the CVP which increased from 7 to 10 but the ABP decreased to 46. Following volume administration and transfusion of red packed blood (RPB) units could improve SVI to 33.6. During the administration the CVP decreased to 7 and the ABP did not change. Therefore, continuous administration of norepinephrine was started with 0.1 lg/kg/min up to the end of the procedure to maintain a systolic pressure of 80 mmHg. Overall the child received 340 cc of crystalloid and 160 cc of colloid solution and 150 cc of RPB's. During the postoperative course the child was extubated directly after the operation and was hemodynamically stable without catecholamines and did not need any further organ support or blood transfusions. The use of an oesophageal Doppler for the surgical correction of craniosynostosis is feasible nevertheless the difficult access to the head by fixing the probe to the endotracheal tube. Doppler monitoring was able to show deterioration of hemodynamics not seen by the ABP and the CVP. Early intervention due to this monitoring was able to improve hemodynamics. We report about a term newborn with urea-cycle disorder with severe cerebral edema in which the pharmacological treatment was combined with venovenous hemodiafiltration (VVHDF) and therapeutic hypothermia. A 50 h old boy was admitted at a NICU in an external hospital because of convulsions and respiratory failure. Initial metabolic workup showed ammonia 2,320 lmol/l and the boy was transferred to our hospital. Initial examination showed a ventilated newborn with hepatomegalia and severe hypotension and ammonia concentrations of 2,391 lmol/l under treatment with Arginin-HCL and Na-Benzoat. Cranial ultrasound (CUS) showed a cerebral edema with systolic peaks and a pulsatility index (PI) of 3.0. After placing of a dual lumen catheter in the right jugularian vein VVHDF was started. In addition neuroprotection was performed by cooling the boy to a rectal temperature of 33°C for the first 24 h using CritiCool cooling therapy system. Then the boy was rewarmed stepwise to 36°C over the next 48 h. Ammonia concentration was decreased during the first 3 h to 830.4 lmol/l by VVHDF and CUS showed a significant improvement of the cerebral blood flow. VVHDF was stopped 3 h later at ammonia 224.3 lmol/l. There was no rebound of hyperammonemia and CUS showed regular findings. The metabolic investigation revealed an Argininosuccinate lyase deficiency. After Extubation at day 10, the boy was discharged at day 38. The 2 months follow up showed an adequate neurological development despite the classic signs of metabolic stroke in MRI. CONCLUSION. Life-threatening cerebral edema in newborns with inborn urea-cycle defects can be treated effectively by the combination of VVHDF with therapeutic hypothermia. Recently, the important progression in therapeutic management of ALI/ARDS in infants and children has been established that has beneficial effect on decreasing the mortality. Except standardized guidelines the off-label therapeutic management accentuate. In recent clinical studies the important therapeutic effect of administration of exogenous surfactant was proved. Despite these results, there are still many questions and problems with optimal technique of surfactant administration, determining the ideal time for surfactant administration during the course of injury, and the development of optimal exogenous surfactant preparations that will be used to treat these patients. Authors present and discuss the different methods of exogenous surfactant delivery techniques in infants and children with ALI/ARDS: aerosol nebulization, endotracheal instillation, bronchoscopic instillation, and bronchoscopic BAL. We used exogenous surfactant in 13 patients (average age was 7.4 years) with ALI/ARDS during last 2 years. The exogenous surfactant doses vary from 20 to 100 mg/kg as BAL or endotracheal instillation. We manage two doses of exogenous surfactant in 24-h period. In 60% the selective bronchoscopic application was used. In all patients oxidative index improved after application. The effect of selective bronchoscopic application was faster. According to literature evidence and also according to own experiences authors suggest advantages of bronchoscopic selective instillation and bronchoscopic BAL as optimal delivery techniques for exogenous surfactant administration for treatment of infants and children with ALI/ARDS. INTRODUCTION. Information technology (IT) has the potential of improving the quality, safety and efficiency of medicine. Intensive care medicine is one of the most data-rich specialism, making it especially favorable for extensive use of IT. Data regarding the implementation rates of IT in ICUs are scarce, and restricted to non-European countries. OBJECTIVES. We wanted to evaluate (i) the use of ''general hospital IT systems'' such as laboratory systems, Pictures Archiving and Communication systems (PACSs), electronic medical record (EMR) and hospital EMR-linked Computerized Physician Order Entry (CPOE) in the ICUs and (ii) the adoption rate and its evolution over the last 3 years of a dedicated Intensive Care Information system (ICIS). Furthermore, we explored in detail the main obstacles for taking the decision to implement an ICIS, using a standardized questionnaire. A telephonic survey was conducted in October 2008, interviewing the head of the ICU department of each ICU situated in Flanders, Belgium. A total of 63 ICUs (860 ICU beds) were surveyed, with a 100% response rate. Currently, every ICU consults laboratory results in an electronic way and PACS is used in 93.5% of them. Electronic ordering of laboratory and radiology investigations however, is only possible in 6.3 and 7.4% respectively. The use of CPOE for medication prescriptions is available in 41.3% of the ICUs, although only 27% also register the administered medication electronically, mostly by using the features of their ICIS. The availability of an EMR is more widespread, being 65%. The adoption rate of a dedicated ICIS nearly doubled over the last 3 years from 7.9 to 17.5%, but another 31.6% of the ICUs are planning an implementation within the next 3 years. All ICISs are commercially bought. Half of the tertiary non-academic hospitals and all university hospitals have implemented an ICIS, but only 7.7% of general hospitals have shifted to a paperless ICU. Main reasons for postponing an ICIS implementation are the substantial initial investment cost, linking problems with the Hospital Information System, concerns regarding the user-friendly interface, the need for dedicated personnel, and the unclear cost-benefit. The extraction of data for management of scientific purposes is used by only 4 out of the 12 ICIS hospitals. CONCLUSIONS. Most ICUs in Flanders use hospital IT systems such as electronic laboratory results and PACS. However, electronic lab and radiology ordering is still the exception. The adoption rate of dedicated Intensive Care Information Systems doubled over the last 3 years but is still surprisingly low, especially in the general hospitals. To cross the implementation chasm, more investigation regarding the potential benefits of ICISs is urgently warranted. Furthermore, in order to overcome the high initial investment cost, the question of governmental financial incentives needs to be addressed as well. INTRODUCTION. Computerized decision support systems (CDSS) are often said to reduce medication errors and Adverse Drug Events (ADEs). However, these systems themselves may be associated with new errors. This study describes four steps for improving quality of aminoglycosides prescription in intensive care unit (ICU). Gentamycin and Tobramycin prescriptions from the computerized physician order entry (CPOE) records of a tertiary adult ICU were compared to doses recommended by a locally developed guideline. The CPOE system displayed an initial fixed default value of dosage. We showed that using this default value is associated with new errors (Eslami et al., Drug Safety 2006) . As a first step for improvement and in order to observe the changes in the physicians' prescription behaviour, we removed the fixed default dosage from the CPOE system. To visualize and make inferences on the longitudinal development of outcome measures we resort to the powerful instrument of control charts from the field of statistical process control (SPC). SPC has rarely been reported in the analysis of quality of care in IC. RESULTS AND STEP ONE. Prescription data 15 weeks before and 30 weeks after removing the fixed default value were analysed prospectively. Statistical Process Control charts showed that the proportion of prescriptions with the system default dose reduced and became out of control (that is, changed) after removing the default dose. However the error rate and ADEs among patients with renal insufficiency remained high and stable. CONCLUSION AND FUTURE WORK. First, the prescribing behaviour prior to removing the default dosage can largely be explained by a high adherence to computerized suggestions, even when the ''suggestions'' are wrong. It seems that the physicians are overly trustful to the system's suggestions perhaps because of the widely reported advantages of CDSS. Second, we learned that physicians, when unsupported, deviate from the drug prescription guidelines and do not seem to consult the paper-based guideline. Therefore we conclude that there is a need for adequate CDSS. Currently we are performing an evaluation study to evaluate three incrementally increasing levels of complexity in decision support (from patient non-specific to patient specific): LEVEL1. ICU management makes physicians aware of the lack of guideline adherence based on our preliminary results. LEVEL2. The computer provides relevant patient-related information (such as Creatinine Clearance and patient ideal weight) as well as the text of the guideline on the screen whenever physicians attempt to prescribe antibiotics, but the system does not provide any proactive advice. LEVEL3. After a drug dose has been selected, the system calculates the correct dosage according to the guideline. In addition, each time a clinician logs in the system, the CDSS checks the patient's folder and based on therapeutic drug monitoring results, alerts the physician for any necessary change. INTRODUCTION. Data collection is time consuming and expensive. In a prospective observational study, we compared the on-line electronically collected cardiac output values against data registered in the CRF during patient visits. We used continuous cardiac output by FloTrac-Vigileo system (FCO) and continuous cardiac output with pulmonary artery catheter (CCO). For Electronic Data Capture (EDC) we used a multi data logger (Edwards Lifesciences, Irvine, CA, USA). Simultaneously registered cardiac output data on CRF forms, marked as ''CRF''. Aim of this abstract is to compare quality of the data acquisition and costs. METHODS. Data collected during standard post-operative care in 28 cardiac surgery patients. The Cardiac output data was collected at 1 h (T0), 2 h (T1), 4 h (T2), 8 h (T3), 12 h (T4), 24 h (T5), 36 h (T6), and 48 h (T7) after ICU admission. For data labeled ''EDC'', the values were taken as an average of 5 min at the time points described above (2.5 min before the time point and 2.5 min after the time point). 179 paired data points could be evaluated. EDC and CRF data was evaluated using a modified Bland-Altman technique (a random effects model to compute within subject variance [1] ). RESULTS. Measured with ICO mean cardiac output was 5.1 (0.98) [range 2.9-8.2] l/min. Bias and precision between EDC data and CRF data for CCO was 0.15 (0.32) l/min, coefficient of variation 0.06, for FCO -0.05 (0.32) l/min, coefficient of variation 0.06, (Figs. 1, 2) . During a half hour visit the study nurse can examine the used equipment and register CRF data; cost were calculated as 179 9 15 Euro = 2,685 Euro. If overtime and travelling costs over 97 time points was calculated, these costs increased to 5,110 Euro. CONCLUSIONS. EDC data collection is interchangeable with cardiac output values in CRF registration. Both methods of data collection can be used and therefore cost aspects could be decisive in trial design and data collection. A. Roman 1 , M. Claus 1 , C. Hanicq 1 , V. Piersoel 2 , P. Flament 2 , E. Stevens 1 , P. Dechamps 1 , T. El Mahi 2 1 CHU Saint-Pierre, ICU, Brussels, Belgium, 2 CHU Saint-Pierre, Clinical Chemistry, Brussels, Belgium INTRODUCTION. Obtaining accurate blood glucose levels at the bedside is mandatory to titrate intravenous insulin infusions in ICU patients. Glucose monitoring in this setting appears more complicated than in ambulatory monitoring in diabetic patients [1] . The use of glucose meters included in blood gas analyzers has been advocated [2] . We evaluated comparatively the performance of two new point-of-care devices and a blood gas analyzer. METHODS. Simultaneously, arterial blood glucose was measured with a blood gas analyzer RapidLab 1265 (Siemens), the Accu-Chek Performa strip on the Accu-Chek Inform II (Roche), the Nova StatStrip (NovaBiomedical) and in the central laboratory using the hexokinase method. All the measures were duplicated and the average value of each method was computed. Bland-Altman, Passing-Bablok, Kanji and modified Kanji approaches were used. RESULTS. A total 432 matched analysis were randomly performed in 343 adult patients. The mean SOFA score was 5.0 (minimum 0 and maximum 23). The range of reference method glucose was 20-585 mg/dL. No patient had paracetamol overdose. Biases are defined as point-of care minus reference glucose values. These biases were -0.5 mg/dL for the Accu-Chek Performa strip with the Accu-Chek Inform II, -1.0 mg/dL for the Nova StatStrip and -4.9 mg/dL for the RapidLab1265. The Passing-Bablok regression show that the confidence interval (CI) of the slope contains the 1.000 for the handheld glucose meters but not for the blood gas analyzer. Rates of discrepancies for the different levels (10, 15 and 20%) were not significantly different between the methods. See Table 1 . July 1, 2007 and February 28, 2009 were included. An active computerized decision support system in the first phase (date from January till August 2008) providing patient non-specific advice and in the second phase (date from September 2008 till February 2009.) providing patient-specific advice was developed, implemented and evaluated. Effectiveness/efficiency-related indicators (mean blood glucose levels (BGL), BGL within pre-defined targets and time to capture target), safety-related indicators (hypoglycemia and hyperglycemia events, and hyperglycemia index), and protocol-related indicators (BGL sampling interval) were measured. To visualize and make inferences on the longitudinal development of outcome measures we resort to the powerful instrument of control charts from the field of statistical process control (SPC). We advocate the use of SPC for monitoring the quality of glucose regulation through the two phases as it provides insight of outcome change over time. RESULTS. Data of 3,208 patient admissions were evaluated, with 132,010 available BGL measurements. Of all measured indicators only the BGL sampling interval decreased and became out of control (indicating change) after introducing patient specific decision support. Mean BGL, time to capture target, hyperglycemia index, percentage of hyperglycemia events and ''in range'' measurements remained unchanged and stable after introducing both patient non-specific and patient specific decision support. The percentage of hypoglycemia events also did not change. CONCLUSION. Adherence to protocol sampling rules slightly increased by using patient specific CDSS. But surprisingly and in contrast to other published studies, the use of a CDSS at both levels did not improve the quality of glucose control as measured by our indicators. Internal factors such as a low agreement with the guideline and external factors such as a recently published negative meta-analysis could be possible explanation for this unexpected result.  In 11 open-chest pigs an accelerometer (11 9 14 9 5 mm) was sutured on the left ventricle (LV) in the perfusion region of the left anterior descending coronary artery (LAD). Epicardial acceleration in the circumferential direction was measured. From this signal velocity was calculated by time-integration and peak systolic velocities were determined. Stroke volume (SV) was obtained by an aortic flow probe, and mean aortic pressure (MAoP) was measured by a fluid-filled catheter. LV end-diastolic pressure (LVEDP) was measured by micromanometer catheter (Millar). LVSW was calculated by the following equation: LVSW = SV 9 (MAoP -LVEDP) 9 0.0136. Global LV function was changed by epinephrine, esmolol, colloid fluid loading and by temporary LAD occlusion. The correlation between LVSW and peak systolic velocity by accelerometer was calculated using the Spearman correlation coefficient. RESULTS. LVSW decreased during esmolol infusion (p \ 0.01) and LAD occlusion (p = 0.020), while LVSW increased during epinephrine infusion (p = 0.024). Fluid loading induced no significant changes in LVSW. Concurrent and significant changes in peak systolic velocity by the accelerometer were observed during all interventions (p \ 0.01). Changes in circumferential peak systolic velocity by the accelerometer correlated strongly to changes in LVSW (r = 0.81, p \ 0.001) (Fig. 1) . CONCLUSION. Alterations in circumferential peak systolic velocities measured by an epicardial accelerometer were closely correlated to changes in LVSW during interventions affecting global cardiac function. Peak systolic velocity generated from an epicardial accelerometer sensor could therefore be used to quantify LV performance continuously and in real time. This technique may be a powerful tool for continuous monitoring of myocardial contraction during and after cardiac surgery. OBJECTIVES. We sought to determine how often thresholds were within BPEG guidelines [1] and if the two readings correlated. METHODS. We measured thresholds from 50 patients of coronary artery bypass graft or valve replacement. The pacing threshold was measured as soon as possible after surgery. The rate was set to 10 beats above the patient's intrinsic rate then output was slowly lowered till there was a loss of capture. It was raised again till there was consistent capture and this was the pacing threshold. The sensing threshold was measured soon after the patient developed an intrinsic heart rate. The rate was set to 10 beats below the patient's intrinsic rate and the voltage output was minimised. The voltage sensitivity was lowered till the pacing box could no longer sense the patient's rhythm, then it was raised again until it would consistently sense. This was the sensing threshold. . From the 50 patients studied, 30% had a sensing threshold of less than or equal to the BPEG guideline of 4 mV. 4% had sensing thresholds beneath the pacemaker default of 2 mV. 12% of patients had pacing thresholds above or equal to half the default setting of 10 mV. Sensing and pacing thresholds do not correlate; if one is adequate, the other may not be. During this 3 weeks audit, we encountered one patient who suffered from 'R-on-T' induced VT requiring CPR with a successful outcome. It became apparent that few doctors were aware of this problem, so a brief national survey of hospitals across Britain was conducted. It showed that of 17 responding hospitals, 3 did not measure pacing threshold; however 13 did not measure sensing threshold. CONCLUSIONS. An unacceptably large proportion of the patients tested did not meet guideline threshold limits putting them at risk of iatrogenic complications. On a micro and macroscopic level, it is apparent that doctors are not aware of the risks associated with poor thresholds so this should be addressed. Giant cerebral aneurysm surgery carries a high risk for intra-operative ischemic insults, especially if long periods of temporary artery clipping are necessary to achieve final aneurysm clipping. The most robust neuroprotection is provided by the application of moderate hypothermia (32°core temperature). However, all methods of surface cooling have shown major limitations, especially in the peri-operative setting. Therefore, we decided on the intraoperative use of the Coolgard System (AlsiusR) to induce systemic hypothermia during combined surgical and endovascular management of a giant aneurysm. A 57-year-old female pt was scheduled for elective surgical clipping of a medial cerebral artery giant aneurysm (3.4 vs 9 cm diameter). After induction of anesthesia, left femoral vein was accessed inserting an ICY catheter (3-lumen coolgard catheter). Durign procedure, SSEP and EEG monitoring were applied to detect any cerebral ischemic event. Coolgard was installed at 32°''end'' temperature with ''maximal cooling'' setting. Body core temperature at start of hypothermic procedure was 34.6°for esophageal location, 35.6°for rectal, and 35.7°for bladder temperature (guide to coolgard catheter management). At 1 h 6 min after start of hypothermia induction, aimed core temperature of 32°was obtained. We did not observe any deleterious systemic effect during hypothermia induction. Mean arterial blood pressure did not change from baseline values, and remained stable (with minimal inotropic/vasopressor support). During surgical procedure (3 h 4 min), stable body core temperature (rectal-esophageal and bladder between a narrow range of 31.9°-32.1°) was maintained. In total, 4 periods of endovascular balloon occlusion were applied (34 min total duration), without any ischemic changes on SSEP/EEG monitoring. After surgical procedure, Coolgard was installed at 35°''end'' temperature with maximal rewarming set at 0.65°per hour. After 3 h and 48 min, body core temperature reached 35°, coolgard system was stopped and external surface rewarming (Bair Hugger) was installed and pt was transferred to ICU. Body core temperature slowly increased to 36°-36.5°at which pt was extubated and awakened without any deficit (11.30 hours after ICU admission). We did not observe any significant postoperative systemic disturbances necessitating any intervention. Total duration of induced cooling procedure was 7 h 58 min, without any major systemic side effect. This report describes intra-and post-operative management of induced systemic hypothermia using an endovascular cooling catheter. We were able to induce hypothermia (32°) over a very short time period (appr 1 h), while maintaining stable core temperature during procedure, without any risk of deeper hypothermia (lowest body core temperature: 31.7°). Most importantly, rewarming occurred at the desired slow rate, without any postoperative complication. INTRODUCTION. Differences in sound energy between affected and non-affected lungs in asymmetric lung disease were previously reported. In the present study, we compare total sound energy in patients diagnosed with different lung conditions. OBJECTIVES. To assess differences in absolute sound energy according to lung condition in ICU patients. Lung sound measurements, recorded with VRI, were obtained from 72 ICU patients classified in four groups according to primary finding in chest radiograph (CXR): consolidation (n = 35), congestion (n = 10), pleural effusion (n = 15) and normal appearing CXR (n = 12). Means sound energy at peak inspiration collected from 34 sensors positioned on the back of the patient were compared between the groups. p-values (Wilcoxon Two Sample Test) are reported. Significantly increased mean (±SD) sound energy was registered in patients with congestion and consolidation when compared to patients with normal appearing CXR or pleural effusion (p \ 0.003). CONCLUSION. Several lung conditions may generate increased absolute sound energy, possibly due to secretions or bronchial breathing. BACKGROUND. Automation of PEEP and FiO 2 settings based on the SpO 2 signal has the potential to reduce the clinician workload in patients on mechanical ventilation. We developed an algorithm reproducing the medical reasoning to achieve this goal and conducted the clinical evaluation of this automated system (AS). The study was conducted in patients mechanically ventilated immediately after cardiac surgery. The algorithm was embedded in a computer connected to a pulse oxymeter and recommendations were provided every minute for PEEP and FiO 2 settings. Patients were randomized for PEEP and FiO 2 management based on AS recommendations (open-loop evaluation) or based on the usual protocol (written protocol relying on the SpO 2 value) during 2 h. Continuous SpO 2 values were recorded, as well as PEEP and FiO 2 settings, and haemodynamic values. Time to set the ventilator was recorded in the control group. RESULTS. 28 patients were prospectively included. Mean initial PEEP and FiO 2 were 6 cmH 2 O and 70% respectively. The mean time to wean the PEEP at 5 and FiO 2 to 40 was 33.5 min in the control group and 18.1 min in the AS group (p = 0.01) (Fig. 1 ). Mean PaO 2 at H1 was 147 ± 67 mmHg in the control group and 117 ± 38 mmHg in the AS group (p = 0.16). CONCLUSION. An automated algorithm reproducing medical reasoning could safely wean PEEP and FiO 2 after cardiac surgery with the similar duration to wean these parameters in comparison with a protocol driven by clinicians. During PSV and CPAP testing, at all ambient pressure levels, tidal volume (V T ) of the lung simulator was set in order to achieve 500 ml with a respiratory rate (f) = 20/min. Airway pressure (P aw ) was measured inside of the bellows of the simulator, the displayed Tidel/ Minutevolumes were captured from the different display panels RESULTS. The following Tables 1 and 2 shows the deviation from the default Tidel/Minutevolume [percent]. NIV mode using optimal expiratory trigger (automatic or 40%) was compared to invasive mode. Three conditions were simulated: without leaks, with inspiratory leaks and continuous leaks. We evaluated pressurization capacity (pressure time product or PTP, measuring inspiratory area) and prolongation of insufflation during inspiratory leaks and we quantified auto-triggering during continuous leaks. No auto-triggering were detected using NIV ventilators and one transport ventilator using the NIV mode, but it was very frequent for the other 2 ventilators during continuous leaks. Pressurization capacity at 0.5 s was significantly poorer with two transport ventilators during inspiratory leaks, and prolonged insufflation time occurred with the same 2 transport ventilators. CONCLUSION. This bench test designed to test the impact of leaks, show that two transport ventilators are not efficient in presence of leaks despite a specific NIV mode. Others ventilators are better adapted to leaks. INTRODUCTION. The use of echography has been recommended to guide the insertion of central venous catheters (CVC) because ''blind'' punctures-relying on anatomical landmarks (LM)-may be associated with serious complications. However, limited access to echography and to appropriate training holds back so far the widespread use of such a technique. OBJECTIVES. The aim of the present study was to assess the potential value of a novel pocket sized Doppler ultrasound (U/S) device dedicated to vascular access. The needle advances right in the middle of the U/S beam, allowing blood vessel cannulation under realtime U/S guidance (Fig. 1 ). METHODS. This was an observational and prospective study conducted in patients requiring a CVC in a surgical ICU. We recorded the number of needle passes for each CVC insertion, as well as potential complications (arterial puncture, hematoma, pneumothorax, hemothorax, abnormal position of the catheter). The transducer was applied on the skin at the usual puncturing site, and the strongest Doppler signal (characteristic acoustic signal) determined the puncture direction, indicating that the axis of the U/S beam hit the middle of the blood vessel. The needle was then introduced in the needle guide, was advanced co-axially to the U/ S beam, and the procedure continued in the traditional way ( Fig. 1) . . 30 CVC insertions (10 jugular and 20 subclavian) have been attempted in 30 surgical ICU patients with a success rate of 100%. The rate of successful cannulation on the first needle pass was 84% and on the second pass 16% (mean number of needle passes per insertion = 1.2). No clinical complication related to vascular puncture was reported during the maneuver or after radiography control. Only one malpositioning of a sub-clavian catheter in the jugular vein was detected by radiography, but this was unrelated to the puncturing technique. The high success rates, especially that on the first needle pass, compared favorably to those reported in several echo-guided studies. For vascular access, the advantages of this device over echographs could therefore be its ease of use (no training in echography), its pocket size, and a much lower price. The present preliminary results are very encouraging and deserve confirmation in a larger patient population, ideally in comparison with a control group (LM or echo-guided). Number of attempts made, seniority of practitioner, technique used and any complications were recorded. Time taken to prepare equipment, as well as time taken from first touch of skin with needle or US to catheter insertion and guidewire removal was also recorded. 67 lines were inserted using US, 60 without. One practitioner used both techniques. RESULTS. • Consultant line placement was achieved more quickly than junior attempts regardless of technique(3 min 27 s vs 6 min 45 s) • Line insertion using the landmark technique was markedly quicker (2 min 46 s vs 6 min 4 s) • Repeated attempts were needed more often in the US group • Only significant complication (pneumothorax) occurred using US technique.  A study assessing the implementation of NICE guidelines in a London tertiary referral centre found no significant difference between complications of consultants using either technique but reported improved safety in registrars using US as compared to landmark [1] . Keenan assessed 18 trials and suggested that US offered the most significant benefit to more junior team members [2] . Concerns have been raised as to the cost effectiveness of ultrasound use; initial outlay is projected to be £15 million with an additional cost of £10 per line inserted [2, 3] . CONCLUSIONS. Ultrasound technique is not without complications and has significant cost implications. Landmark technique may be quicker to achieve central access. Complications may relate more to skill and seniority of practitioner than technique used. REFERENCES. 1. Wigmore TJ, Smythe JF (2007) Effect of the implementation of NICE guidelines for ultrasound guidance on the complication rates associated with central venous catheter placement in patients presenting for routine surgery in a tertiary referral centre. BJA 99 (5) Recently, immunotherapy was regarded as a new strategy for sepsis. In this study, the efficacy of immunotherapy with ulinastatin plus thymosin-a 1 was investigated in the septic patients. METHODS. Seventy post-operative septic patients from Gastrointestinal surgery department were randomized into immunotherapy group (n = 36), and conventional therapy group (n = 34). Immunotherapy group received intravenous ulinastatin, 200,000 U, 3 times per day for 3 days, then 100,000 U, 3 times per day for 4 days, and subcutaneous thymosin-a 1 , 1.6 mg, 2 times per day for 3 days, then once per day for 4 days. Other conventional therapies such as antibiotics and fluid resuscitation were given in both groups. Blood TNF-a, blood IL-10, blood lymphocyte subsets, blood monocytes HLA-DR CD 14 + and 28 days survival rate were compared in the two groups. RESULTS. The survival rate in the immunotherapy group was 63.9% (23/36), compared to the conventional therapy group was 41.2% (14/34), P \ 0.05. In immunotherapy group, the blood TNF-a level (1.33 ± 0.50 ng/ml vs. 1.88 ± 0.53 ng/ml, P \ 0.05) and in blood IL-10 level (217.52 ± 15.71 ng/ml vs. 101.53 ± 16.57 ng/ml, P \ 0.05) were significant difference than that in the conventional therapy group. There were also significant difference in blood CD 4 + T lymphocyte (35 ± 13% vs.21 ± 7%, P \ 0.05) and blood monocytes HLA-DR CD 14 + (50 ± 5% vs.35 ± 4%, P \ 0.05) between the two groups. CONCLUSIONS. Immunotherapy with ulinastatin plus thymosin-a 1 improves inflammatory response and immunological function and prolongs survival in the septic patients. KEYWORDS. Sepsis, Ulinastatin, Thymosin-a 1 , Immunotherapy. MATERIAL AND METHODS. We conducted a prospective study, with the local ethic committee approval that enrolled 11 patients with severe sepsis/septic shock and submitted to CRRT. We measured the cytokines TNF, IL-1B, IL-6 and IL-10 levels using an immunoassay method. The cytokines measurement was done every morning and while the technique lasted. We analyzed the following variables: age, severity scores (SAPSII, SOFA), cytokines (TNF, IL-1B, IL-6 and IL-10) levels on prefilter, posfilter and ultrafiltrate. We correlated these data with filter duration, considering 24 h the maximum theoretical limit for effective cytokine removal. . From the eleven patients enrolled, we collected 420 valid samples to measure the cytokines levels. The mean age and SAPS II score were respectively 66 ± 10.7 years and 46 ± 27.1. The mean total SOFA score at admission and at day 3 were 11.2 ± 4 and 12.7 ± 4 respectively, with a DSOFA = + 1.3 points (p [ 0.05). The mean ICU hospitalization time was 25.9 ± 33.5 days. We have done 876 h of continuous dialytic therapy; 33 AN69 membranes were used, during a mean time of 26.5 ± 25.6 h. The mean total levels found for cytokines are presented in Table 1 and the levels depending on the filter duration are in Table 2 . The ICU mortality rate was 54.6%. Similarly, at end of IgGAM therapy reperfusion data and nirVO 2 were still larger (p [ 0.05) than data collected before IgGAM. In the control group we did not observed any NIRS data variation in the 2 time points of analysis. CONCLUSIONS. The above preliminary data indicates that the early use of IgGAM in septic shock patients seems to affect muscular microcirculation with a rapid improvement in the parameters related to endothelial reactivity. We compared the outcome of septic shock patients who received APC in our institution from 2003 to 2008 to that of a series of patients who were case-matched in terms of characteristics and of severity but who did not receive APC while they fulfilled our criteria of treatment without presenting any contraindication. Sixty-five patients received APC. Before APC infusion, all of them had a circulatory failure with a mean dose of norepinephrine of 6.5 ± 4.5 mg/h and at least one other organ failure. All but one were mechanically ventilated (P/F: 168 ± 58). Blood lactate concentration was 4.9 ± 3.1 mmol/L before starting APC. To find 65 casematched patients, a regional database (CUB-Rea) with patients from 33 medical intensive care units (ICU) was used. We searched in this database case-matched patients with similar characteristics in terms of age, gender, SAPS2, presence of circulatory failure, respiratory failure (need of mechanical ventilation), renal failure (need of renal replacement therapy). Were excluded patients admitted in ICUs where APC is used on a regular basis and those potentially presenting a contraindication to APC treatment: patent haemorrhage, bleeding risk or potential anticoagulant therapies. Among 1,748 eligible patients, 61 (from 21 ICUs) could be matched one-to-one with 61 patients from our ICU. The impact of APC on survival was evaluated by marginal models (logistic regression and Cox model). . CONCLUSIONS. PMX-HP seems to induce a fast and significant ''shock reversal'' in 46% of intractable RSS. This response was associated with a better chance of survival since 76% of responders survived (higher than the predicted one, p \ 0.01). No single variable at baseline proved useful in identifying Pts who could benefit from PMX-HP (responders and non responders were comparable). PMX-HP is a safe and easy to use device: sequential use PMX-HP and CRRT, no other therapeutic limitation (steroids, DrotAA). These data suggest that PMX-HP seems to be an effective support as rescue therapy in severe RSS with hemodynamic instability. METHODS. Observational data were collected retrospectively from patients admitted in our medical intensive care unit with septic shock, between January 2005 to December 2008. We compared a group of patients treated with rhAPC versus a non treated group. All of them were managed following International Guidelines for severe sepsis and septic shock, including corticosteroids therapy. Baseline demographics, previous chronic diseases, severity scores, primary location of infection, vasopressors requirements, serum lactate level and hospital mortality were reported. We made an analysis of evolution of shock and organ dysfunction at the end of the infusion of rhAPC. Univariable analysis was made using Chi-square and Student's t test. Independent prognostic factors were studied by means of multivariable logistic regression analysis. Sixty-nine patients were studied, 38 received rhAPC. There were no differences between both groups except a higher hepatic disease in no rhAPC group (41% vs. 8%, p \ 0.00) ( Table 1) .  We found an FpC serious deficiency at admission in cases and control patients. Age, SAPS II and 28 days mortality has no statistical significance in both the groups. The FpC value after 24 h of DaA treatment go up with a significant reduction in the organ failure score. Although we haven't found a significant reduction in the mortality, the survival curve after the second day was similar for both groups and the deceased patients has an evident failure in ascent the FpC values even treated with DaA. CONCLUSIONS. Serious FpC deficiency persisting since the admission day appears to be associated with a worse prognostic and higher mortality in adults with sepsis. Although the limitation of the study, DaA treatment was more effective in ascent the FpC values, with a mortality almost despicable after the second day of treatment in the response patients. OVERVIEW. n-3 fatty acids present in fish oils have been shown to obtund systemic inflammation, prevent intra vascular thrombosis and protect endothelium mediated tissue blood flow. This meta-analysis evaluates the effects of enteral and parenteral fish oil supplements on mortality and length of stay in intensive care units. A systematic review and meta-analysis of randomised controlled trials involving fish oil supplements. Studies combining fish oils with arginine were excluded. , Tokyo) administration has been approved to use for adults with disseminated intravascular coagulation (DIC) in Japan [1] . Thrombomodulin is one of components of the protein C anticoagulant pathway. And it is also known thrombomodulin has direct anti-inflammatory activities to inhibit activated kinases and NFjB responses in endothelium [2] . OBJECTIVES. Our hypothesis is rhs-TM may have an anti-inflammatory effect for sepsis. METHODS. We investigated 6 severe septic patients (4 women, 2 men; age range 45-82 years) who were treated with rhs-TM for DIC in our ICU. In effect, rhs-TM therapy consists of 380 U/kg intravenously every 24 h for 6 days. Before the start of rhs-TM therapy and on the day after finished the therapy, WBC, CRP, IL-6, C3 (Complement 3), SOFA score, PT, APTT, Protein C (PC), Protein S (PS), thrombin-antithrombin III complex (TAT), DIC score were evaluated. IL-6 and PS were measured by enzyme-linked immunosorbent assay, C3 was by turbidimetric immunoassay, PC was by latex photometric immunoassay, and TAT was by enzyme immunoassay. Values are expressed as median. Data were analyzed by Wilcoxon signed-ranks test. A p \ 0.05 was considered as statistically significant. RESULTS. There were 4 survivors and 2 non-survivors. No side effects of rhs-TM occurred. CRP values were statistically significantly decreased after rhs-TM therapy. WBC count and IL-6 levels also decreased after the therapy, but were not significant. SOFA score and DIC score were improved but did not reach to statistical significances. There were no differences in PT, APTT, PC and TAT. CONCLUSIONS. The present study has a limitation of small number of patients. However, there is possibility rhs-TM may also have an efficacy for immflamation not only for DIC. INTRODUCTION. The report incidence of Critical illness-related corticosteroid insufficiency (CIRCI) varies widely, depending on the patient population studied and diagnostic criteria used. Surviving Sepsis Campaign guidelines suggest that corticosteroid therapy should be considered for adult septic shock when hypotension responds poorly to adequate fluid resuscitation and vasopressors, regardless any results of diagnostic test. However, steroid treatment may be associated with an increase risk of infection. To identify the best diagnostic tool for predicting responsiveness to corticosteroid therapy in Thai septic shock patients with poorly responsive to fluid resuscitation and vasopressors. METHODS. 29 patients with septic shock that poorly responsive to fluid therapy and vasopressor. A baseline serum total cortisol was measured in all patients and then 250 mcg corticotropin was injected to patients. Cortisol level was obtained 30 and 60 min after injection. All patients were administered hydrocortisone (100 mg IV then 200 mg IV in 24 h at least 5 days). Patients were considered steroid responsive if vasopressor agent could be discontinued within 48 h of the first dose of hydrocortisone. Hospital death was 62%. Forty-five percent of patients were steroid responsive. Baseline serum cortisol was 27.6 ± 11.4 lg/dl in the steroid-responsive patients compared with 40 ± 16.9 lg/dl in the steroid-nonresponsive patients (p = 0.03). The area under the ROC curves for predicting steroid responsiveness was 0.72 for baseline cortisol level, which better than that derived from delta cortisol after ACTH stimulation test (D cortisol). Serum cortisol level of 35 lg/dl was the most accurate diagnostic threshold for determination of the hemodynamic response to hydrocortisone treatment (p = 0.04). Using baseline cortisol level of B35 lg/dl as the criteria of adrenal insufficiency, sensitivity was 85%, specificity was 62% and accuracy was 72%(p = 0.03), while use of (D cortisol) showed sensitivity of 50%, specificity of 30% and accuracy of 41%(p = 0.41). RESULTS. Changes of serum CL was time dependent. In the control group we established the reduction of the CL from the day of the surgery (5.38 ± 0.19 mmol/l) till the tenth day. In the groups of patients with AS the dynamic of the CL changes was presented as a waveform curve. We established the elevation of the CL after the operation on the first day after surgery in all groups, with the next decrease till the third day in the first group (from 4.68 ± 0.19 to 4.23 ± 0.25 mmol/l), fifth day in the second group (from 6.27 ± 0.29 to 5.64 ± 0.18 mmol/ l), and the seventh day in the third group (from 6.79 ± 0.27 to 5.27 ± 0.32 mmol/l). After that we noticed the elevation of the CL in first group to 5.08 ± 0.22 mmol/l, in second group to 6.19 ± 0.73 mmol/l on the seventh day, and to 5.41 ± 0.41 mmol/l in third group on the tenth day. Correlative analysis showed the following: Correlation coefficients -0.189, 0.355, 0.859 characterized interrelations between different research groups and control. CONCLUSIONS. CL significance as AS severity marker in operated patients is determined by its role in cyclopenthan-perhydrophenantren associated metabolism of hormones and regulatory messengers characterizing regulatory disorders and hepatic dysfunction. Dynamically increased CL may be observed as an independent negative prognostic marker in ICU patients. . In various studies microalbuminuria has been correlated with rapid changes in vascular integrity. The evolution of an early, sensitive marker of inflammation might prove useful in clinical practice. To determine the incidence of microalbuminuria in ICU pts and to evaluate whether clinically significant microalbuminuria (defined as Urinary Albumin to Urinary Creatinine Ratio [ACR] [ 100 mg/g) is an early marker of the capillary dysfunction that accompanies SIRS. We prospectively evaluated 35 patients (males 27-trauma 19, postsurgical 6, medical 10) admitted to the ICU. Samples were collected on admission and at 24 and 48 h thereafter. We calculated Acute Physiology and Chronic Health Evaluation (APACHE) II Score and Sequential Organ Failure Assessment (SOFA) score on the first ICU day, we recorded demographics, cause of admission, comorbidities, outcome, Length of ICU Stay (LOS) and the presence of SIRS. Urinary albumin, urinary creatinine, serum creatinine and CRP were measured on an automated biochemistry analyser (Architect, Abbott). Twenty-three patients (69.56%) exhibited microalbuminuria on admission (ACR [ 30 mg/g). Patients were divided in 2 groups: group 1 included 20 pts with admission ACR \ 100 mg/g and group 2 included 15 pts with admission ACR C 100 mg/g. Table 1 summarises our results. In both groups ACR levels were increasing during the 3 days of follow-up, with group 2 showing a more intense rise. No significant differences were recorded in comorbidities. 5 deaths occurred in group 2 vs 0 in group 1. OBJECTIVES. to investigate the utility of plasma levels of the damage-associated molecular pattern protein, S100A8/A9 complex, and the gene expression of S100A8 and A9 in circulating immune cells. METHODS. patients with septic shock were enrolled within 24 h of onset of their second organ failure. Systemic inflammation was characterized by clinical scores, plasma levels of IL-10, IL-12p40 and MIF, and monocyte HLA-DR expression. Plasma S100A8/A9 complex levels in a training cohort then in a testing cohort and peripheral blood monocyte gene expression of S100A8 and A9 were measured on day 0 and day 1 after inclusion only in training cohort. . 49 septic shock patients (training cohort) were enrolled. Median [IQR] S100A8/ A9 complex levels were significantly higher (p \ 0.0001) in non-survivors (13.3 [5.4] lg/ml) compared to survivors (3.7 [0.9] lg/ml). Specificity and sensitivity for intensive care outcome were 100% on both day 0 and day 1 levels. The S100A8/A9 complex plasma level did not correlate with gene expression in circulating immune cells. The training threshold (8.1 lg/ml) for outcome prediction was tested in 62 consecutive septic shock patients with the same entry criteria (testing cohort) and validated the outcome prediction. CONCLUSIONS. Plasma levels of S100A8/A9 complex fulfil the criteria for an early and accurate prognosticator of outcome in septic shock.  Monocyte HLA-DR level (mHLA-DR) has been proposed for evaluation of innate immunity, especially in sepsis where low mHLA-DR could be associated with poor outcome and high risk of secondary infections, but never demonstrated in a large septic population. To evaluate mHLA-DR as a predicator for outcome and risk of secondary infections in severe sepsis ans septic shock. Prospective multicentric study (4 ICU units) AIMS. Delay in diagnosis and treatment in critically ill patients often results in rapid progression to organ failure and eventually death. Minimizing delay in diagnosis is the primary reason that diagnostic tests are performed. The aim of this study was to investigate the accuracy of serum ProCT and SOFA score as reliable diagnostic tests for sepsis, severe sepsis or septic shock. METHODS. Forty-five critically ill patients were included in this study: 15 patients with sepsis, severe sepsis and septic shock respectively. The Simplified Acute Physiology Score (SAPS) II was calculated 24 h after admission to ICU. The measurement of serum ProCT was performed when the diagnostic criteria for sepsis, severe sepsis or septic shock were present in the same day SOFA score was calculated. The serum ProCT was assayed by an enzymelinked fluorescent immunoassay (ELFA) performed in automated VIDAS strument (VIDAS BRAHMS PCT Assay). Statistical analysis was performed using the Mann-Whitney test and the Receiver Operating Characteristic (ROC) curve analysis, also positive and negative likelihood ratios (LR) was calculated. We did not observe correlation between serum ProCT and severity of illness scores (SAPS II and SOFA). Patients with septic shock had a SAPS II, SOFA score and serum ProCT significantly higher than those of patients with simple sepsis (Table 1 ). According to ROC analysis, ProCT [ 0.79 ng/ml and SOFA score [ 10 were the cut-off values that best discriminated sepsis from septic shock (AUC ± SE 0.86 ± 0.07 and AUC ± SE 0.92 ± 0.05 respectively). The values of positive and negative LR were reported in Table 2 . Animal and human studies have shown increased levels of plasma Vascular Endothelial Growth Factor-A (VEGF-A), a known potent vascular permeability inducing agent, in LPS induced endotoxemia, severe sepsis and septic shock. The pathogenic mechanism of the glomerular leakage of albumin in acute inflammatory conditions remains to be clarified. We wished to investigate the causative role of VEGF-A, in this regard which might have therapeutic implications. To study the association of albumin excretion in the urine with concomitant serum levels of Vascular Endothelial Growth Factor-A in critically ill patients. Prospective non-interventional study in 43 bedded neurological, trauma and general Intensive Care Units (ICUs) of a tertiary care hospital. Of the consecutive patients admitted to the ICUs between Sept 2008 and Jan 2009, 597 patients were included, after excluding patients with ICU stay of less than 24 h, pregnancy, menstruation, anuria, hematuria and proteinuria due to renal and post-renal diseases. Of these, 30 consecutive patients with sepsis, severe sepsis and septic shock (sepsis group) and 30 randomly chosen patients without sepsis were recruited for the VEGF-A study. Spot urine samples for urinary albumincreatinine ratio (ACR, mg/g) estimation (Immunoturbidimetry, Dade Dimension RxL, Siemens) and serum samples for VEGF-A estimation (ELISA Quantikine kit, R&D systems) were collected on ICU admission. Since ACR and VEGF-A data showed a skewed distribution, correlation was analyzed using Spearman's correlation coefficient. . 60 critically ill patients, with a median age (IQR) of 60 years (48-72), 39:21 male-female ratio, median APACHE II score (IQR) of 16 (7-23), and 3 median days of ICU stay, had a median ACR (IQR) of 125 mg/g (51.6-239.1) and a median VEGF-A (IQR) of 111 pg/ml (54.3-286.9) on ICU admission. The median ACR on admission in the sepsis group (n = 30) 161.8 mg/g was significantly higher the median ACR (78.3 mg/g) of the group without sepsis (n = 30) (p value = 0.011). On statistical analysis, no significant correlation was obtained between levels of urinary ACR and serum VEGF-A (p value = 0.327) in the entire grouo. Analysis for correlation between ACR and VEGF-A in the sepsis patients (p value = 0.396) and in the group without sepsis (p value = 0.518), yielded similar results. CONCLUSIONS. Despite a strong physiologic rationale, our pilot study did not show an association between microalbuminuria and VEGF-A in critically ill patients. Larger studies are needed to come to a definitive conclusion.  Fifty-seven patients with severe sepsis or septic shock admitted to our medical intensive care unit were included into the study and followed for at least 30 days after recruitment or until death. At the end of the follow-up period, patients were classified as ''survivors'' or ''nonsurvivors''. Blood samples were drawn within the first day of severe sepsis or septic shock. APACHE II and SOFA scores were determined on the days of admission. RESULTS. Serum lipoprotein levels, except HDL, were not statistically different in survivor and nonsurvivor groups. Serum HDL and PON1 levels were significantly higher in survivors (p \ 0.005 for both). PON1 levels were directly correlated with HDL (r = 0.74, p \ 0.001), and inversely correlated with TNF-a (r = -0.77, p \ 0.001) and IL-6 (r = -0.78, p \ 0.001). The power of admission day measurements of PON1 levels to predict the 30-day mortality in ROC curve analysis was good but not better than HDL, cytokines, and severity scores. CONCLUSION. Our results revealed that serum PON1 activity was significantly higher in survivors. PON1 activity showed positive correlation with HDL, and inverse correlations with proinflammatory cytokines (TNF-a, IL-6). PON1 levels can be used to estimate the prognosis in patients with severe sepsis or septic shock. INTRODUCTION. Sepsis induces lethal effects primarily through uncontrolled activation of pro-and anti-inflammatory response, resulting in a deregulation of physiologic homeostasis, and ultimately leading to organ dysfunction, shock, and death. Rapid identification and initiation of treatment is of crucial importance for patients with sepsis. Although novel sepsis biomarkers have been proposed for clinical use, no single clinical or biological indicator has so far obtained unanimous acceptance. We recently showed that osteopontin (OPN) is strongly up-regulated during sepsis and induces secretion of interleukin 6. OBJECTIVES. Aim of our study is to assess and compare the rate of variation of OPN with respect to well known sepsis-related inflammatory mediators, i.e. C reactive protein (CRP), procalcitonin (PCT), and soluble urokinase-type plasminogen activator receptor (SuPAR). OBJECTIVE. To evaluate the predictive and follow-up value of procalcitonin (PCT), C reactive protein (CRP) and interleukin (IL) 6, 8 and 10 at the onset of the septic episode and throughout the initial follow-up of patients with urosepsis. METHOD. The prospective study included 60 patients with suspected urosepsis. Blood samples were collected for PCT, CRP and IL 6, 8, 10 determinations for 14 consecutive days after sepsis onset. Biologic state and prognosis was evaluated using the Acute Physiology, Age and Chronic Health Evaluation (APACHE) II score and the adjusted (y) mortality index on days 1, 3, 5, 7 and 14. Patients were grouped in sepsis, severe sepsis and septic shock categories according to the American College of Chest Physicians/Society of Critical Care Medicine (ACCP/SCCM) guidelines. Outcome measurements were the development of organ dysfunctions and mortality. Predictive accuracy was evaluated by Receiver Operating Curve (ROC) statistics and marker correlations using the Pearson coefficient (R 2 ). Overall mortality rate within the group was 23.3% and was highest for patients with septic shock (57.1%). Organ dysfunctions were present in 23 patients (38.3%) and lead to death in14 of them (60.1%). At mortality analysis, the predictive power of IL 10 (AUC 0.927 for a cut-off value of 232 pg/ml with 91% sensitivity and 93% specificity) was unexpectedly superior to that of PCT and APACHE II (Sn/Sp of 87/86% and 89/82% respectively) while CRP, IL 6 and 8 provided poorer results. Regarding the prediction of organ dysfunction development and severity, better results were provided by PCT (Sn/Sp of 90/95% for a 63 ng/ml cut-off value with AUC of 0.903) and IL 6 (Sn/Sp of 86/89% for a 378 ng/ml cut-off value with AUC of 0.886). PCT values showed the best correlation with the clinical evolution assessed by the APACHE II score (R 2 = 0.955) and was followed by IL 6 (R 2 = 0.724). No other significant correlations were found for the other markers. Our results suggest that assessment of certain inflammatory markers and cytokines in patients with urosepsis might improve the risk prediction of both mortality (IL 10) and organ dysfunction development (PCT) as well as the clinical follow-up accuracy (PCT) together with the APACHE II score. Immunomodulation through elevated production of intracellular mediators and myocardial ischemia resulted from inadequate microcirculatory blood flow are considered as the main causes of myocardial dysfunction in patients with sepsis. Ischemic Modified Albumin (IMA), is a new and highly sensitive marker of early myocardial ischemia. Oxidative process associated with ischemia reperfusion and tissue injury may lead to N-terminus modification of circulating albumin resulting in the formation of IMA. AIM. Correlation of IMA levels with the severity of sepsis in elderly patients. PATIENTS AND METHODS. Twenty nine patients (13 males, 16 females), aged 79 ± 11 years, hospitalized in the Internal Medicine department were diagnosed as having had sepsis of various origin (mainly urinary tract and low respiratory infections). E. coli and Klebsiella pn. were the most frequently isolated pathogens. Upon admission, APACHE II score was calculated and correlated with the serum IMA levels (COBAS INTEGRA 400, Roche Diagnostics) in all patients. Patients with acute myocardial infarction, liver failure and severe hypoalbuminemia were excluded from the study. . A significant positive correlation between IMA values and APACHE II score levels was detected (linear regression analysis, r 2 = 0.161, p = 0.031). IMA levels (IU/L) were significantly higher in patients (n = 15) with APACHE II score [ 18 in comparison to patients (n = 14) with score \ 18 (145 ± 17 vs 127 ± 25, p = 0.024, Student's t test). IMA levels were also found higher in patients who succumbed than in patients who survived (156 ± 20 vs 132 ± 21, p = 0.033, Student's t test). CONCLUSION. In our study, Ischemia Modified Albumin seemed to be correlated with the severity of sepsis in elderly patients. Furthermore, a cut off prognostic value could be determined and used as a means for risk stratification of these patients. INTRODUCTION. Lipocalin-2 (LCN2) is a 25 kDa secretory glycoprotein, which is predominantly expressed in adipose tissue and the liver. LCN2 is upregulated in cells under stress from infection, inflammation. A rise in serum levels of LCN2 has been reported under inflammatory and infective conditions. Artificial liver assist devices like the molecular adsorbent recirculating system (MARS) have been successfully used support organ function until recovery of the native liver, or to bridge the patient to liver transplantation. The pathophysiology of multi-organ dysfunction in acute hepatic failure is incompletely understood but increased systemic inflammatory response is believed to play a pivotal role. OBJECTIVES. The relevance of LCN2 in the setting of acute liver failure (ALF) as well as acute-on-chronic-liver-failure (ACLF) is not known. Further we studied the effect of the MARS on this inflammation marker, since activation of an inflammatory cascade by the extracorporeal blood circuit of MARS could have deleterious effects in ALF and ACLF, and mitigate beneficial effects of the MARS treatment. METHODS. Serum LCN2 levels were determined by a commercially available ELISA kit in eight ALF and eight ACLF patients undergoing MARS immediately before and after the first treatment cycle. Indications for MARS therapy were ammonia levels of 100 lmol/l or higher with hepatic encephalopathy grade 3, eligibility for liver transplantation. 14 patients with chronic hepatic failure (CHF) with Child-Pugh-Score C, who were clinically stable served as controls. Data are given as median with range. INTRODUCTION. Type 2 diabetes (T2D) is associated with an increased risk of thrombosis and disturbances in the antifibrinolytic system as evaluated by elevated plasma levels of plasminogen activator inhibitor (PAI)-1 [1] . Although T2D is characterised by aberrations in innate immunity and PAI-1 is markedly induced by proinflammatory stimuli, the effect of inflammation on the antifibrinolytic system has not previously been investigated in a standardised setup in these patients. We hypothesised that patients with T2D exhibit an exacerbated PAI-1 response after lipopolysaccharide (LPS) injection, a human experimental model of systemic inflammation. After ethical approval, a thorough physical examination and informed consent, 23 healthy men and 19 men with T2D were given an intravenous LPS injection (0.3 ng kg -1 ). Measurements of PAI-1 in plasma were done hourly from baseline until 8 h after LPS. Twosample t tests were used to compare diabetics with healthy subjects at baseline. Interactions between time and T2D were analysed by two-way ANOVA for longitudinal measurements. RESULTS. At baseline, PAI-1 levels were higher in T2D than in controls vs. 37. 5 [34.8-40 .1] ng L -1 , P \ 0.01). Although LPS increased PAI-1 in both groups, the relative PAI-1 response was blunted in T2D (P \ 0.0001) with an increase of only 40% (95% CI 18-62%) above baseline in patients compared to maximum levels at 108% (95% CI 71-144%) above baseline in healthy subjects. CONCLUSION. We found higher baseline plasma levels of PAI-1, but an attenuated PAI-1 response after LPS injection, in patients with T2D. Although several studies have demonstrated that brain natriuretic peptide (BNP) has prognostic value in septic patients, there is not evidence that NT pro-BNP provide prognostic information. Our aim is to analyze the behaviour of this biomarker in septic patients and its utility as a prognostic marker. METHOD. Prospective study of septic patients admitted to Intensive Care Unit (ICU). Analyzed variables were demographic characteristics, severity scales (APACHE II and SOFA), adequacy of empiric antibiotic treatment, determination of NT-pro-BNP at admission and during the ICU stay, ICU mortality and hospital mortality. A univariate and multivariate analysis following a logistic regression model using SPSS 12.0 was conducted. For all test, p \ 0.05 was considered significant. The values of NT-proBNP at admission were higher in patients in septic shock (p \ 0.001) and with acute renal failure (creatinine [ 2.00 mg/dl) (p \ 0.001) and in patients who died in the ICU and hospital (p \ 0.001). In multivariate analysis of patients with serial determinations of NT-proBNP (n = 150) statistically significant variables that are related as an independent marker of hospital and ICU mortality were the AP II and inadequate empirical antibiotic treatment. The increase of NT-proBNP during the stay in intensive care was independently associated with ICU mortality: OR 3.55 (CI 1.29-9.8; p = 0.014). CONCLUSION. The values of NT-proBNP are higher at admission in patients with sepsis, although is not an independent prognostic factor of mortality in ICU or hospital. The increase in NT-proBNP values during the stay in ICU is a predictor of ICU mortality in septic patients. We report a single-centre series of 316 patients with vasopressor dependent septic shock who underwent short synacthen test (SST) and received corticosteroids. METHODS. Since 2001, patients admitted to the ICU of Bradford Teaching Hospitals with vasopressor dependent septic shock underwent SST. At the discretion of the intensivist, the patient also received corticosteroids until the vasopressor (norepinephrine) was withdrawn. SST used 250 lg synacthen, with levels of cortisol measured at baseline, 30 and 60 min. Data were collected retrospectively from patients who underwent SST, who had a clinical diagnosis of severe sepsis, and who, following fluid resuscitation, required norepinephrine to achieve an adequate blood pressure (systolic [ 100 mmHg/mean [ 70 mmHg). RESULTS. 316 patients were identified. Table 1 gives patient data. Table 2 gives SST results. Table 3 gives mortality and outcome according to two definitions of adrenal insufficiency (baseline cortisol \ 15 lg/dL and increment \ 9 lg/dL). 249 patients (79%) received hydrocortisone (median dose 200 mg/day). The mortality for these patients was 68% compared with a predicted mortality of 55% (SMR 1.22, 95% CI 1.11-1.33). For non-steroid treated patients, the mortality was 54% (predicted 42%, SMR 1.27, 1.12-1.41).  We present preliminary analyses of the largest single centre cohort study to date investigating adrenal function and outcomes in patients with vaspressor dependent septic shock. SST results are broadly similar to those given in the retrospective corticus cohort study [1] . Overall mortality rates are higher than in that paper but only 53% of their patients were vasopressor dependent, and likely to be less sick. Baseline cortisol levels were higher in non-survivors; there was no difference between survivor's and non-survivor's peak and increment cortisol levels. Corticosteroid therapy did not appear to influence outcome. A large aneurysm will usually contain a large volume of thrombus and a possible cause of systemic inflammation post-graft implantation is cytokine release after manipulation of endovascular thrombus. We present our findings of an inflammatory response after endoluminal stenting of the abdominal aorta. MATERIALS AND METHOD. This is a retrospective study about 18 patients, 96% were male undergoing endoluminal abdominal stents in our institution over one year period from 2006 to 2007. The indication for AAA was degenerative aneurysm of the abdominal aorta greater [6 cm. Three measurements were done preoperatively, on the operation day and postoperatively. Pre-intra-and postoperative data were collected from a retrospective review of the cases notes. Endovascular stenting was under general anaesthesia in an operative room in all cases and performed by a vascular surgeon and an interventional radiologist. After the administration of a single dose of 5000 IU of intravenous heparin, the common femoral artery was assessed and a custom made sized Y type graft was positioned to the abdominal aorta. All patients were admitted to our intensive care unit after the procedure. All patients had a postprocedure CT scan to assess the position of the stent and detect complications. There was statistically significant difference in mean Protein C serum concentration, p = 0.02, mean fibrinogen serum concentration, p = 0.01, mean D-Dimmers serum concentration, p = 0.01, mean Platelet count concentration, p = 0.02, mean H + serum concentration, p = 0.02, mean ICAM serum concentration, p = 0.02, mean VCAM serum concentration, p \ 0.01 and mean IL-6 serum concentration, p = 0.01. There was no statistically significant difference in mean ATIII serum concentration, p = 0.07, mean Protein S serum concentration, p = 0.26, in mean INR time, p = 0.1 and mean IL-10 serum concentration, p = 0.14. CONCLUSION. With the current sample, significant changes were found in serum concentration of VCAM, ICAM, Protein C, Fibrinogen, D-Dimmers, Platelet count, IL-6 and H + concentration pre, intra and postoperative. These factors seem to have an early change in patients undergoing endovascular surgery and need to be monitored to recognize a possible early beginning of P.I. syndrome. During endovascular surgery the inflammatory reaction seems to appear lower than in open surgery repair, but not long-lasting. In the future, the suggested phenomenon by many authors of a decreased general antiinflammatory cytokine response during endovascular surgery needs to be further examined. AIMS.Long-term follow-up of patients suffering from multiorganic dysfunction syndrome (MODS) admitted to the intensive care unit (ICU), find factors associated with increased functional worsening and with mortality. METHODS. This is a prospective cohort study including all the patients suffering from MODS admitted to a 24-bed medical ICU of a terciary hospital during 9 months. A subgroup of patients was assessed telephonically using Barthel and PAEEC scales. RESULTS. 469 patients were admitted to the ICU and 191 (40%) of them suffered from MODS. In the group with MODS the mean age was 58.26 ± 16 years and 64% were males. The main causes of admission were sepsis (25%), neurologic (22%) and pulmonary (17%) disorders. The severity at the time of admission was: APACHE II 23.6 ± 7, SAPS II 54.2 ± 14; SOFA 9.9 ± 3.6. According to the Barthel Scale, 16 patients showed a moderate to severe degree of dependence before the hospital admission. At admission the number of failing organs in the group with MODS was: 1-2 in 67% of the patients, 3 in 20% and 4 or more in 7%. During hospitalization 76% of them had dysfunction of 2-3 organs and 17% of 4 or more organs. Hospital mortality was 48.9% (27.6, 53.8, 81 and 86% when 1-2, 3, 4 and 5 or more organs failed during the hospitalization). Sixty-nine patients were discharged and telephonically contacted. 53 of these 69 patients survived at 18 months and 86.8% were independent or mildly dependent (Barthel 83.9 ± 25.9; PAEEC 9 ± 6.9). In the 191 patients with MODS, the total mortality at 18 months was 67.2% and severe dependence or 18-months mortality was 69.1%. In the subgroup of patients with sepsis the mortality at 18 months was 75%, similar to patients without sepsis. Factors associated to mortality or severe dependence were: APACHE II (24.9 ± 7.1 vs 21.8 ± 6.4, p = 0.005), SOFA max ( CONCLUSION. In this study, MODS had high mortality at 18 months. Functional worsening before admission and the number of failing organs at any time since admission were associated to mortality and a severe degree of dependence. In our group of patients, the SOFA and SOFA sequential had a poor prediction power of long-term mortality. INTRODUCTION. Myocardial dysfunction, impaired microcirculation and increased vascular permeability accompanying severe sepsis contribute to lung edema, particularly in acute lung injury (ALI) and septic shock (SS). Therefore, these patients require thorough monitoring of gas exchange and pulmonary hemodynamics. However, data documenting the severity of lung edema and impairment of pulmonary vascular permeability in patients with different origins of ALI are still inconclusive. Thus, the aim of our study was to assess pulmonary hemodynamics and gas exchange in patients with SS combined with direct and indirect ALI. METHODS. Thirty adult patients with SS and ALI were enrolled into a prospective study. The SOFA and Murray scores were used daily for evaluation of severity of multiple organ failure (MOF) and ALI, respectively. After the cannulation of femoral and pulmonary arteries, the PiCCOplus and VoLEF monitors (Pulsion Medical Systems, Germany) were used for assessment of systemic and pulmonary hemodynamics, including heart rate, blood pressure, central venous pressure, cardiac index, pulmonary arterial pressure, pulmonary arterial occlusion pressure, intrathoracic blood volume index, extravascular lung water index (EV-LWI), pulmonary vascular permeability index (PVPI), right heart end-diastolic volume index and left heart end-diastolic volume index. The hemodynamics and gas exchange were registered every 4-8 h during 3 days. In addition, the survival rate was registered at Day 28. INTRODUCTION. Inflammatory response after sepsis has been regarded as an important player in the development of multiple organ failure and in sepsis-related mortality. However, the dynamics of inflammatory response in experimental septic shock following resuscitation strategies similar to those used in human disease has been subject of few studies in the literature. OBJECTIVES. This study aimed to evaluate inflammatory parameters in a model of septic shock treated with volemic resuscitation and antibiotics. METHODS. Ten anesthetized pigs (35-45 kg) were instrumented with pulmonary artery and arterial catheters and submitted to peritonitis by injection of 0.75 ml/kg of fecal contents. After developing hypotension, the animals received fluids and antibiotics and were followed for 12 h. Hemodynamic and respiratory data were collected hourly after sepsis. Plasmatic concentrations of IL-6 and IL-10 were measured by ELISA. Oxidative burst was measured by non-fluorescent dichlorofluorescein oxidation on neutrophils constitutively and after S. aureus stimulus and CD14 expression was evaluated on neutrophils and monocytes by flow citometry. These parameters were measured before sepsis, before resuscitation and after 12 h of treatment. RESULTS. The median time for occurrence of hypotension was 11 h (7-21). Sepsis induced a significant decrease in cardiac output and cardiac filling pressures, probably due to dehydration. Adequate treatment reversed these findings. Significant increases in IL-6 and IL-10 plasmatic concentrations were demonstrated after peritonitis. After treatment, there was a significant decrease in the plasmatic concentrations of IL-6. Plasmatic IL-10 concentrations remained stable. A non-significant decrease in constitutive and S. aureus-induced oxidative burst was evidenced after sepsis. After treatment, however, there was a significant increase in both oxidative burst measurements. Expression of CD14 on neutrophils was significantly reduced after sepsis, an effect that did not reverse after treatment. CONCLUSIONS. The inflammatory response after sepsis is complex and variable. Sepsis treatment is associated with an increased neutrophil oxidative activity. On the other hand, the persistently reduced expression of the endotoxin receptor component CD14 and the increased IL10 concentrations early in the course of the disease may indicate a premature immune dysfunction. GRANT ACKNOWLEDGEMENT. FAPESP, Research and Education Institute, Hospital Sírio-Libanês.  Hemodynamic management for cardio-circulatory stabilization, in patients during and after burn and surgical injury, associated with normo-or hypovolemia, could be associated to progressively decreasing of Hb oxygen saturation (SaO 2 Hb), at the level of microcirculation. We have realized a prospective study upon 60 patients from Plastic and Reparatory Surgery Department, who needed of 4 ± 3 interventions for tissular restauration (skin grafts). We observed the evolution of the local morpho-clinical aspects of granulative tissue development(in three periods of time) T1: after intervention at 72 h, (T2) at three weeks and to the outcome (T3), associated to the following values: lactate, C-reactive protein (CRP), procalcytonin (PCT), SaO 2 Hb, oxidative stress index (OSI) and to clinical manifestations of SIRS. We have correlated these values to the SOFA and APACHE scores. The results, statistically assured evidentiated that there are very individualised modifications, imprevisible sometimes, but the CRP, PCT, OSI, reflected the endothelial dysfunction produced by insufficiency of tissular oxygenation RESULTS. The seric level of antioxidant potential (TAOP), from the two groups: (a) good healing of surgical wounds and: (b) defectous one were appreciated, a: 502. AIMS. The mechanisms underlying Critical Illness-Related Corticosteroid Insufficiency (CIRCI) in critically ill patients are poorly understood. Various mechanisms might be important in the pathogenesis of CIRCI, including suppression of ACTH production and impairment of enzymes of the steroidogenical pathway. Reduced activity of adrenal steroidogenic enzymes will result in lower cortisol levels and/or increased levels of cortisol upstream precursors. The aim of our study was to analyze cortisol precursors in septic patients with signs of CIRCI in order to indirectly unravel whether disturbed steroidogenic enzyme activity could account for a diminished response of the adrenocortical cells to ACTH in critically ill patients. A prospective study was performed in a tertiary medico-surgical intensive care unit from December 2004 to March 2007, including 30 critically ill patients with sepsis and a clinical suspicion of CIRCI. Patients who received etomidate within 48 h before ACTH testing were excluded. After measurement of baseline total cortisol and corticosteroid precursors (modified tandem mass spectrometry, Applied Biosystems Q trap 3200) all patients underwent a conventional 250 lg ACTH test. Post-stimulus total cortisol concentrations were determined at 30 and 60 min after the administration of synthetic ACTH. Patients with a low response to the ACTH test (defined as \ 250 mmol/L) had markedly higher 11-deoxycortisol levels compared to patients with a higher response to ACTH (C250 mmol/L) (median 22.1 vs. 3.94 nmol/L, p \ 0.01). The median cortisol/11deoxycortisol ratios in nonresponders (n = 12) and responders (n = 18) were 28.9 and 107, respectively (p \ 0.01). No difference was found between responders and non-responders in corticosterone, 17-hydroxyprogesterone, androstenedione, testosterone and DHEAS levels. CONCLUSIONS. The mechanisms underlying CIRCI are complex and poorly understood. Our data on precursors of cortisol in patients with sepsis, revealing a low cortisol/11-deoxycortisol ratio in nonresponders to ACTH, indirectly indicate a decreased activity of 11bhydroxylase resulting in a decreased conversion of 11-deoxycortisol to cortisol. This pathway may be involved in the pathophysiology in CIRCI and thus be a potential target for future therapy. INTRODUCTION. Sepsis is the leading cause of death in the critically ill [1] . Transgenic mice enable study of pathways of potential importance, however, mice models are often not clinically representative. OBJECTIVES. To develop a reproducible fluid resuscitated model of fecal peritonitis in mice with continuous conscious blood pressure (BP) recording and intermittent echocardiography. METHODS. Mice (age 22 weeks/wt 29 g) had tethered arterial and venous lines inserted under isoflurane anesthesia. The tether enabled mice to roam cages freely and obtain continuous BP traces. 24 h after surgery echocardiogram and intraperitoneal injection of rat slurry (septic) or n/saline (sham) was administered under anesthesia. Fluid resuscitation of 0.3 ml/h voluven/5% dextrose (50:50) was given to septics and 0.1 ml/h n/s/5% dextrose to shams. At 24 h echo was recorded, blood taken and mesenteric arteries dissected for myography. Data are expressed as mean (SEM). Statistical analysis-ANOVA, Chi square or t test. RESULTS. Sham mice survived 72 h before cull and septics died at 18-28 h (p \ 0.0003) and BP fell in septics from 113 (4) BACKGROUND AND AIMS. Inflammatory cytokines are recognized as mediators of major importance during sepsis. In recent years, adipose tissue appeared as a novel source of cytokines in different clinical situations, but the role of adipose tissue during sepsis remains, to the moment, completely undercover. The aim of this study was to investigate possible interactions between clinical variables and cytokines produced in adipose tissue of patients with severe sepsis. Nine patients with severe sepsis from a medical intensive care unit were investigated over 26 h. Informed consent was provided from the closest relative. A standard open-flow microperfusion catheter inserted in the subcutaneous adipose tissue (SAT) of the abdominal wall was used for continuous sampling of interstitial fluid effluent. Arterial blood samples were obtained simultaneously at two-hour intervals. Recorded clinical variables consisted of heart rate, blood pressure, body temperature, fluid balance, APACHE score II, blood gas analysis, blood count, blood glucose, albumin and high sensitive-C-reactive protein. Cytokines (TNF-alpha, IL-1beta, IL-6 and IL-8) present in SAT effluent samples and serum were measured using a bead-based multiplexed ELISA system. An explorative analysis was performed in order to identify significant (p \ 0.01) correlations between clinical variables and measured cytokines. . Distinct time profiles were depicted for each cytokine in SAT effluent samples. Cytokine concentrations were higher in SAT than in serum for IL-1beta (10.0 [3.5; 13.9] CONCLUSIONS. Cytokines measured in SAT effluent from septic patients using OFM technique are probably locally produced, as suggested by the serum-SAT gradients. As diastolic blood pressure is the main determinant of mean blood pressure, and therefore, of perfusion at the tissue level, the present data suggest that IL-6 secreted in the adipose tissue might be implicated in the regulation of tissue perfusion in patients with severe sepsis.  Though NO modulation is a likely therapeutic candidate for septic shock, the failure of the Phase III study of the non-specific NOS inhibitor L-NMMA (1) undermined this approach. However, this study revealed outcome benefit at doses \5 mg/kg/ h but harm at higher doses (5-20 mg/kg/h). We thus wished to see whether the benefits of low-dose L-NMMA could be replicated in a long-term rat model of septic shock. Conscious instrumented male Wistar rats of approx 300 g body weight received 1.8 ml fecal slurry intraperitoneally. When blood pressure (BP) dropped 20% below baseline level (at approx 5-6 h), 1-3 9 10 ml/kg Voluven fluid challenges were given i.v. to restore pressure, followed by continuous infusion of a 1:1 mix of n-saline +5% glucose at a rate of 10 ml/kg/h. Treated animals also received 3 mg/kg/h L-NMMA added into the above resuscitation fluid. Animals were observed until 48 h or death. A Kaplan-Meier survival analysis was performed. RESULTS. Five animals were excluded due to premature deaths \3 h (n = 3) and instrumentation mishaps (n = 2). Of the remainder, L-NMMA-treated septic animals (n = 13) showed a significant improvement in survival compared to untreated animals (n = 12) ( Fig. 1 ). Median survival was 19 vs. 12 h (p = 0.019). Blood pressure was better maintained in the L-NMMA treated group.  Severe sepsis and septic shock remain a major cause of mortality. Attempts to develop novel therapies in an effort to reduce this mortality have been remarkably unsuccessful. However, there appears to be an initial window of opportunity during which conventional resuscitation strategies and treatments such as antibiotics can provide a survival benefit [1, 2] . In this study we examined the immunological correlates for this clinical observation. We analysed immune receptor expression in monocytes taken from healthy volunteers and patients with shock at early (within 6 h) and late time points using flow cytometry. Patients with cardiogenic, haemorrhagic and septic shock were included. Importantly, only patients who subsequently were proven to be bacteraemic were included in the septic shock group. We further tested the proinflammatory responsiveness of these cells to stimulation with a panel of microbial toxins/heat-killed bacteria and toll-like receptor ligands by measuring tumour necrosis factor alpha by ELISA. We also compared the same innate immune profile of patients with established critical illness to those presenting de novo from the community. RESULTS. We found that the clinical context (de novo community acquired-shock versus hospital-acquired shock) of samples and sample acquisition lead-time were crucial determinants of both receptor expression and cytokine release ( Fig. 1 ). This was in contrast to diagnosis/shock type and severity which were not correlated with patient innate immune profile. This latter observation differs from that reported by other investigators [3, 4] . [1] . A mouse model would enable study of mediators using transgenics. We sought to characterise cardiovascular function and inflammatory response in a murine model of cirrhosis. METHODS. C57black mice (12 weeks/26 g) were bile duct ligated (BDL) or sham procedure under isoflurane. Echocardiography under isoflurane was performed at intervals. At day 14-either blood pressure (BP) was measured, or 1% carrageenan injected into paw and resulting oedema compared to saline-injected paw, or mice culled for histology, blood and mesenteric arteries for myography. Data-mean(SEM), statistics-ANOVA. RESULTS. Significant liver injury was present day 14 post BDL (survive to 21 days). Peak velocity, stroke volume and heart rate fell in cirrhotics p \ 0.001 ( Fig. 1 ). Weight (28%) and temperature fell p \ 0.001 (Fig. 2 ). Although BP does not fall, mesenteric arteries were hyporeactive to norepinephrine p \ 0.001 (Fig. 2 ). Bilirubin-390(56) and ALT-350(53) rose p \ 0.001. The response to carrageenan measured by paw oedema was significantly reduced in cirrhotics p \ 0.001 (Fig. 3 ). Preliminary cytokine analysis showed no change. BACKGROUND. Pro-inflammatory cytokines and lymphocyte apoptosis are important mechanisms in the development of immunosupression and organ dysfunction in severe sepsis and septic shock. Erythropoietin (EPO), well known for its role in promoting erythrocyte survival and differentiation, has recently been shown to exert tissue protective properties. Multiple protective capabilities of EPO, such as antiapoptotic and antioxidant effects, have been demonstrated. Interestingly, the anti-inflammatory effects of EPO in endotoxin-induced renal dysfunction are still not known. The aim of the present study was to evaluate the effect of EPO on endotoxin-induced renal impairment and to investigate whether EPO could reduce endotoxemia induced lymphocyte apoptosis. METHODS. Twenty-eight pigs (31-35 kg) were anesthetized and mechanically ventilated. The pigs were randomized into one of three groups (1) LPS + EPO (5,000 IE/kg) n = 10, (2) LPS + placebo, n = 10 and (3) control group, n = 8. Escherichia coli endotoxin (LPS) was infused by a stepwise increasing dose to 20 lg/kg/h, continued for 2 h and then reduced to 2.5 lg/kg/h for the last 8 h. Renal function was assessed by glomerular filtration rate (GFR) estimated hourly. Blood samples were collected for the analysis of plasma cytokines (IL-1b, TNF-a, IL-6, IL-8 and IL-10). Peripheral blood mononuclear cells (PBMC) were isolated and analyzed by flowcytometry for changes in lymphocyte subsets and apoptosis. RESULTS. LPS significantly reduced the renal function measured as GFR (p = 0.003). Treatment with EPO had no effect on the overall renal function and we found no significant differences between the LPS groups. The flowcytometry and cytokine analyses are ongoing. CONCLUSION. EPO did not minimize the renal dysfunction induced by acute experimental LPS-endotoxemia. The possible immune modulating effects of LPS and EPO, including alterations in lymphocyte subsets and apoptosis, will be presented.  The outcome of patients hospitalized in ICU due to cerebral hemorrhage or brain trauma may be adversely affected by serious infections that often complicate the course of these diseases. To document infectious complications and to study outcome and disability indices in patients admitted in ICU due to cerebral hemorrhage or brain trauma (CHBT). We prospectively studied CHBT patients hospitalised in the general ICU of University Hospital of Thessaly, between 2006 and 2008. Patients were followed up for a median period of 290 (120-690) days. The neurological status of patients was assessed by the Glasgow Coma Scale (GCS) and the Hunt and Hess Score; patients disability was evaluated by the Rapid Disability Rating Scale (RDRS). Diagnosis of nosocomial meningitis or infections was based on previously accepted CDC criteria. Ninety-six patients (65 male) with median(IQR) age of 58(37-66) years and GCS of 8(5-10), hospitalized for 18(8-33) days, were studied. Six-month overall mortality was 31.2%. Twenty three patients (24%) presented bacteraemia, 44(45.8%) presented at least one septic episode during their hospitalization; the incidence of meningitis was 21.8%. Multiresistant bacteria (Acinetobacter baumanii, Klebsiella pn. and Enterococcus f.) were cultured in cerebrospinal fluid in 15 out of 31(48%) meningitis patients. Patients who presented meningitis or bacteriaimia with multiresistant bacteria (p = 0.002) had a significantly longer hospitalization (p \ 0.001] and worse RDRS (p \ 0.03). Twenty-five (26%) patients presented mild-moderate disability and 38(49%) severe-total disability at the final follow up. Total/severe disability was associated with advanced age (p = 0.001), low baseline GCS (p = 0.001), presence of blood/cerobrospinal fluid multiresistant bacteria (p = 0.002) and increased mortality (p = 0.001). CONCLUSIONS. The course of neurosurgical patients in ICU may be complicated by multiresistant bacteria infections that may result in long term severe disability. These findings underline the necessity of developing effective strategies against multiresistant bacteria in ICU. OBJECTIVE. To study the aetiological structure, character and antibiotic resistance level of hospital infections (HI) agents in the neurological ICU in the major leading departments of neurosurgical Intensive Care Units in Russia. Prospective multy-center study in the period of marchapril of 2007, based on the six largest neurosurgical ICU in Russia. During this period of time 50 patients with hospital infections were included in to the study. Strain identification and susceptibility level was evaluated with the help of standard bacteriological methods. Nosocomial infections (NI) diagnostic was conducted on the basis of general protocol for every ICU. For NI diagnostic the CDC criteria (1988) were used. Patients' conditions severity according to APACHE II was 13.0 points (5.5;18) , consciouseness level according to 14) , according to SOFA-3.0 (1;6). NI onset happened on the 9.3th (6;13.5) days. Among Hospital Infections the low respiratory tract infections were prevalent-66.6%. CNS infections were evaluated as 7%. VAP incidence was 13.2 per 1,000 device-days of mechanical ventilation. Urinary catheter-associated infections-4.9 per 1,000 device-days, central-line associated rate was 5.6 per 1,000 device-days. As NI agents the following ones dominated: P. aeruginosa-31.7%, A. baumannii-10.0%, K. ðneumoniae-8.3%, E. coli-8.3%,MSSA-10.0%, MRSA-8.3%. The highest level of activity towads P. aeruginosa was demonstrated by imepenem/cilastatin and meropenem 64.7 and 58.8% sensitive strains respectively. Strains of A. baumannii showed the maximum sensitivity towads cephepime-76.7%, gentomycine-50%, ciprofloxacine-50%. CONCLUSIONS. Among NI the major leading place in the neurosurgical ICU is taken by low respiratory tract infections(LRTI). The main causative agents of NI are P. aeruginosa`, S. aureus è A. baumannii. The highest level of resistance to antibiotics is achieved by nonenzymatic bacteria. They also represent the mainstay in the emergency treatment of hydrocephalus, On that basis: Drainage of CSF reduces intracranial volume and thus is one of the therapeutic tools available for the treatment of intracranial hypertension. The most common drawback of external ventricular drainage is that of CSF infection [16] . Mayhall and coworkers [20] found a strong relationship between the duration of insertion of EVD and the risk of drain-associated infection. They recommended elective revision of an EVD on Day 5 postinsertion to reduce this risk. Conversely, authors of other larger studies have shown that the duration of EVD insertion in a patient has no effect on the risk of infection [10, 34] . Furthermore, data from a randomized controlled trial [37] revealed no difference in the infection rate between one group of patients undergoing elective EVD revision every 5 days and another group with EVDs left unchanged unless clinically indicated. Despite this evidence, elective revision of EVDs with the aim of preventing CSF infection remains a common practice. To evaluate the role of the duration of insertion of EVDs as a predictor of infection together with the timing of infection relative to insertion. To discuss the practice of electively revising EVDs and wether we should adapt elective reviewing in our practice, recommending when a reinsertion revision should be performed. A prospective study of 102 patients with 138 EVDS in a tertiary intensive care unit in Abudhabi, UAE. We found 11 cases of CSF (cerebrospinal fluid infection), approximately 46% of which were: pseudomonas auregenosa and gram positive bacteria. We found the duration of drainage to be an independent predictor of infection. The longer the duration of insertion the higher the risk of infection. An EVD infection was initially identified at a mean of 7.2 ± 2 days (by standard error of the mean). CONCLUSION. Elective EVD revision would be expected to decrease the rate of infection in light of our results we recommend elective revision of EVD. INTRODUCTION. Pulmonary complications are frequent occurrence in head trauma patients with pneumonia being the most important cause in morbimortality in these patients. Therefore is important the knowledge in variables that have influenced the development of pulmonary complication to improve the management of these patients. The aim of our study was to assess the risk factors of onset pulmonary infection in head trauma patients who were admitted in Critical Care Unit (CCU) in our centre, high technology hospital. A prospective observational study from June 2006 to July 2008 in head trauma patients who were admitted in our hospital. The following variables were evaluated: age, gender, risk index, Glasgow Coma Scale (GCS), place where patients were intubated (before or after hospital admission), computer tomography (CT), polytrauma, hypotension, hypoxia, presence of intracranial hypertension, steroid and barbiturates use, aspiration before intubation, duration of mechanical ventilation, presence of pulmonary and infectious complication. Chi-square test, multiple and simple logistic regression analyses were used. The presence of intracranial hypertension (p = 0.02), hypotension (p = 0.04) and days of mechanical ventilation (p = 0.000) were significantly associated with onset pulmonary infection. The tracheal intubation in accident place was not significant. The pulmonary infection is a frequent complication in head trauma patients. About the variables that significantly have influenced in this complication, we have to early treat hypotension in an aggressive way, since microcirculatory disorders can make a great contribution to the development of this complication. We have to insist on applying recommendations to prevent pulmonary complication related mechanical ventilation. (2) to be specific and more rapid in decreasing the elevated temperature of the brain. 6 patients with episodes of intractable fever were treated with specific neck pads of ArcticSun Ò Medivance. 88 temperature values of the brain, blood and bladder, respectively, were taken every 15 min over a period of 2 h, every 30 min until hour 4 and up to hour 8 hourly, after application of the cooling neck pads. • No side effects related to the cooling technique occurred. • Brain temperature decreased from hour 0 with 38.2°C ± 0.3 to 37.5°C ± 0.4 hour 3.5. • In all but one episode, the temperature of the brain remounted to values [ 38°C after hour 5. • In one episode the rise again was prevented by additional cool washing. • During the entire study period the mean temperature measured in the brain (37.9°C ± 0.4) was significant higher compared to the blood (37.8°C ± 0.4) (p = 0.01 paired t test). CONCLUSION. Selective cooling of the neck might be efficient in decreasing intractable for several hours, but not for a sustained period. INTRODUCTION. Individuals who sustain a traumatic brain injury (TBI) frequently present acute ethanol intoxication at the time of injury. and up to 75% also have chronic alcoholism. (1) Several studies provide support for a deleterious interaction between positive blood alcohol levels (BAL) and outcome from TBI. (2) Also, the influence of pre-injury alcohol abuse on poor outcome cannot be underestimated. Our purpose is to investigate the effects of day-of-injury intoxication and chronic alcoholism on early functional status in patients (pts) with TBI. We reviewed 589 pts from DRG database admitted at S. João Hospital with ICD9-CM codes of TBI with age between 18 and 65 years old during 2007-2008. 152 pts were selected considering the following inclusion criteria at admission: BAL measurement, Glasgow Coma Score (GCS) evaluation and head CT-scan. Acute alcohol intoxication was defined as BAL C 0.5 g/l according to Portuguese law. Outcome analysis was based on the Glasgow Outcome Scale (GOS) at day of discharge. Statistical analysis was performed using chi-square tests, t test, two-way ANOVA, multivariate regression analyses using the forward stepwise model. BAL positive results were significantly higher in males (p = 0.0018). Preliminary correlational analysis indicated that BAL C 0.5 g/l was associated with lower mortality (p = 0.008). Considering the acute alcohol intoxication status (AEI) and chronic alcoholism (CA) status, we divided the pts in four groups (i.e. AEI and CA; only AEI or CA and none). There was no difference between those groups as far as concerned the following variables: GCS, head CT scan, UCI stay, hospital stay, GOS and mortality. No correlation was found between chronic alcoholism and mortality. However, multivariate regression analyses demonstrated that the only predictor of mortality was GCS (p = 0.000). CONCLUSIONS. We did not find a significant association between acute or chronic alcoholism and functional outcome at discharge as referred in previous studies. (2) In the present study we investigated the early prognostic value of the serum levels of the main pro-and anti-inflammatory cytokines and soluble cytokine inhibitors for mortality and late complications as sepsis and MOF in trauma. METHODS. 99 previously healthy immunocompetent patients with severe multiple trauma admitted to the E.R in less than 8 h from trauma were included during a period of 22 months. 64 healthy individuals served as controls. We determined a wide spectrum of pro-and antiinflammatory cytokines simultaneously (TNF-a, IL-1b, IL-6, IL-10, sTNFR type-I and-II, IL-1ra and TGF-b) on admission, 12 h, and 24 h after trauma. All patients were followed up for sepsis, MOF and death until discharge from hospital. The variables were compared between groups with and without complications and death. RESULTS. The age of patients (88 men and 11 women) was 41.98 ± 17.81 years, the ISS 23.21 ± 11.47 and the rate of mortality, MOF, ARDS and sepsis 20.20, 32.32, 10.10 and 41.41% respectively. On admission trauma patients had significantly higher levels of IL-6, IL-10, sTNFRII, IL-1ra and TGF-b than did controls. IL-6 (adm, 12 h, 24 h), IL-1ra (12 h, 24 h) and IL-10 (24 h) were more closely related to the severity of trauma as measured by the ISS score (p \ 0.001). Elevated IL-6 (12 h), TGF-b (adm) and IL-6:IL-10 ratio were detected in patients who died, whereas sTNFR I (adm, 12 h) as well as IL-1b, IL-6, IL-10, IL-1ra, sTNFR I, sTNFRII levels (24 h) were significantly higher in patients who developed sepsis. Serum levels of TGF-1b and IL-1ra (adm) as well as IL-6, IL-1ra, sTNFR I, sTNFRII (12 h) and IL-1b, IL-6, sTNFR I, sTNFRII, IL-1ra levels (24 h) were significantly higher in patients who developed MOF. A significant decline in serum IL-10 and IL-1ra levels was observed in survivors, non-septic and without MOF patients (12 and 24 h). Results of the multivariate analysis by logistic regression are shown in Tables 1, 2, 3 ROC curve for the model AUC (95% CI) 0.879 (0.809-0.953) CONCLUSIONS. Serum levels of TGF-b1, IL-6 and IL-1ra as well as the sustained overproduction of IL-10 and IL-1ra may predict death and late complications as sepsis and MOF as soon as into the first 24 h after severe trauma. INTRODUCTION. The importance of magnesium in intensive care has been white of much attention in recent years. Some publications relate the hypomagnesemia with the increase in mortality of critical sick patients; others discuss the importance of its correction. Magnesium changes in the politrauma patient have been less referenced in literature, although some studies do mention its importance, especially in traumatic brain injury. Results and contradictory opinions exist in respect to admission magnesium levels in the universe of critical trauma patients. OBJECTIVE. To find correlation between magnesium, at admission and during hospital stay, and main outcomes in trauma patients, admitted in to the trauma room of a 700 bedded teaching hospital (level 3 trauma centre), during a 5-year period. MATERIALS AND METHODS. Retrospective analysis of our trauma database from 2002 to 2007. Evaluation of admission magnesium levels and daily magnesium in the first 8 days of hospital stay; correlation with the following parameters: mechanism of injury, need for intensive care, injury scores (ISS-Injury Severity Score, RTS-Revised Score Trauma). The evaluated measures of outcome were: LOS, ICU LOS and mortality. Cut-off for hypomagnesemia applied in the study was our institution's value of reference (0.6 mmol/L). CONCLUSIONS. In this population of severe politrauma patients, low magnesium at arrival to the trauma room was a marker of severity of the traumatic injury, but without significant influence on mortality. GRANT ACKNOWLEDGEMENT. None of the authors has any grant. (1) with 47% of all murders now involving knives in Scotland (2). Unfortunately Scotland has the joint highest murder rate in Western Europe at 2.13 deaths per 100,000 (3). The majority of homicides are recorded in the West of Scotland with Glasgow having the highest murder rate in Western Europe at 5 deaths per 100,000 (3). This survey attempted to quantify the number of admissions and outcome for victims of stab injuries admitted to the Intensive Care Unit, Southern General Hospital Glasgow. This retrospective survey demonstrates that although the total numbers of patients admitted after assaults with a sharp weapon are small representing roughly 3 patients a year. They represent a group of young patients with a high mortality rate (10%). Many require massive transfusions and active resuscitation. The injuries sustained can be lethal both immediately and later despite intensive care. Whatever the outcome these assaults have the potential to have a significant impact on the individuals, their families and the local community. OBJECTIVE. To determine the prognosis factors related to a better outcome in patients with moderate and severe brain traumatic injury. Hospital Intensive Care Unit from January 2007 to March 2009. Patients older than 18 years old, with a moderate or severe head injury were included. Head injury severity was score based on initial Glasgow Coma Scale (GCS) and computerized tomography (CT) findings by the National Coma Data Bank (NCDB) scale. Epidemiology data and potential risk factors were collected. To evaluate the functional outcome a telephone interview was made, using the Glasgow Outcome Scale (GOS) and Modified Rankin Scale (mRS). INTRODUCTION. Posttraumatic acute brain swelling (ABS) is generally thought to result from a hypoxic, ischemic insult to the brain due to prolonged shock or apnea occurring immediately after the trauma. We previously reported that the incidence of posttraumatic cerebral venous sinus occlusion (CVSO) was over 20% in the patients with a skull fracture crossing a dural sinus or with a petrous bone fracture (risk-fracture of CVSO), and it is closely associated with ABS (J Trauma 66 (4): [1002] [1003] [1004] [1005] [1006] [1007] 2009 ). The purpose of this study was to investigate the risk factor of ABS occurring immediately after the trauma. METHODS. This study comprised 376 consecutive patients admitted to our Trauma Center from 2002 through 2009 with head trauma. Multivariate stepwise logistic regression (MSLR) analysis was used to identify independent risk factors for ABS. The dependant variable was ABS. ABS was defined as diffuse injury 3 or 4 according to the Traumatic Coma Data Bank classification on admission day. The explaining variables were age, gender, presence of riskfracture of CVSO, blood pressure and blood gas data on admission (Shock was defined as blood pressure less than 90 mmHg, hypoxia was defined as PaO 2 less than 60 mmHg, and hypercapnia was defined as PaCO 2 more than 45 mmHg). RESULTS. ABS was observed in 4.5% (17/376). Out of 119 patients with risk-fracture of CVSO, ABS occurred in 11.8% (14/119). ABS also was observed in 37.5% (9/24) in patient with shock. All patients of ABS were died. MSLR found as the most important prognostic indicators, risk-fracture of CVSO (OR: 13.3, p \ 0.01), and shock (OR: 35.6, p \ 0.01). There was no correlation between risk-fracture of CVSO and shock. CONCLUSION. We reasoned in the previous study that the patients with a risk-fracture of CVSO could receive direct injury to cerebral venous sinus, which caused disturbance of venous outflow and increased the risk of ABS. These results indicated that risk-fracture of CVSO may be involved in occurrence of ABS by the mechanism different from the shock, such as venous outflow block. Further clinical studies are warranted to determine the effects of shock and obstruction of cerebral venous flow on ABS. INTRODUCTION. The cerebral sinus venous thrombosis (CVT) is a rare subtype of stroke with a difficult diagnosis and an unknown incidence, in the past it was associated with an unfavourable outcome. The aim of the present study was to describe clinical characteristics and outcome of two patients with CVT admitted in ICU in the last 6 months. RESULTS. Clinical case 1:A 25-year-old woman with a personal history of a recent epidural anesthesia for vaginal delivery was attended four days later in the emergency department by persistent headache. In the physical examination there was not nuchal rigidity nor neurological abnormalities. Initially hydration, analgesic drugs and lying down were the treatment for a suspected postdural puncture headache. Due to a lack of relieve with this treatment an urgent brain computerized tomography scan was performed, it showed a CVT. Clinical case 2: A 27-year-old woman with oral contraceptives treatment history who consulted in the family medicine center several times with headache with a poor response to treatment. 24 h later was attended in the emergency department with headache and lower right extremity paresis. A brain computerized tomography scan showed CVT. The patients were admitted in the ICU and were treated with systemic anticoagulation therapy, they started to improve and after 4 days (case 1) and 6 days (case 2) were discharged to the neurology ward. CONCLUSION. • The treatment with heparin in the acute phase of the CVT is safe and is likely to improve its outcome. OBJECTIVES. We investigated the time course of interleukine-6 (IL-6), C-reactive protein (CRP) and fibrinogen serum levels, as markers of acute reaction, in ICH patients and their relation to the neurological outcome. METHODS. Twenty eight patients with spontaneous ICH admitted to a general ICU of a tertiary hospital, were enrolled in this prospective study. Serum levels of the above markers were measured on days 1 and 3. Patients were divided in two groups according to their neurological outcome estimated with Glasgow outcome scale (GOS): Group A (GOS 1-3, worse outcome) 20 patients, Group B (GOS 4-5, better outcome) 8 patients. Data distribution was not normal according to Shapiro-Wilk test of normality. Mann-Whitney U test was used for differences in biomarkers between the two groups. Wilcoxon signed ranks test was used in order to confirm differences between first and third day measurement. Spearman's bivariate correlation test was used in order to correlate the three markers. RESULTS. The only statistically significant difference between the two groups was the increase of IL-6 on day 3 in group A. A statistically significant elevation of fibrinogen was observed in Group A patients on day 3 compared to day 1. On the contrary CRP levels on day 3 increased in both groups of patients. Statistically significant correlation was observed on day 3 between fibrinogen, CRP and IL-6 only in group A patients. Mean, standard deviation and p values are shown in Table 1 . Supra-orbital incision offers a minimal invasive surgical approach for cerebral aneurysm clipping. Since 2004, we introduced this technique for all pts presenting for elective cerebral aneurysm surgery. In this paper, we want to present a retrospective analysis of this 5-years experience. Over this 5-years period, 98 pts scheduled for elective cerebral aneurysm surgery underwent craniotomy by supra-orbital incision performed by the same neurosurgeon. In 65 pts, the aneurysm was located on the medial cerebral artery, in 11 pts it was located on the internal carotid artery, whereas in the other 22 pts the communicans anterior was involved. 9 pts presented with multiple aneurysms, in 2 pts multiple aneurysms were clipped in one surgical procedure. Retrospective control group included 98 consecutive pts, undergoing aneurysm clipping by conventional surgical approach, before 2004 and performed by the same neurosurgeon. With minimal invasive approach, cerebral aneurysm was successfully clipped in 95/98 pts and post-operative course was uneventful. In 2 pts, it seemed impossible to clip the aneurysm due to anatomical characteristics. In 1 pt, intra-operative bleeding occurred during surgical manipulation of the aneurysm, with ensuing brain bulging and a large craniotomy had to be performed. In the control group, in 96 of 98 pts, cerebral aneurysm was successfully clipped without any neurologic deficit. We did observe a significantly shorter mean surgical procedure time compared to standard procedure times for cerebral aneurysm clipping before 2004 (m195 min vs m329 min). Related to this shortened mean surgical time, we observed a significantly shorter time to awakening (m135 min vs m285 min after ICU admission). 92 of 98 pts were discharged from ICU within 36 h of admission, and 32 pts were even discharged within the first 12 h of ICU admission. In the control group before 2004, mean ICU stay was 21.3 h with no pt leaving ICU within first 12 h of ICU admission. After 2004, mean hospital stay was reduced to 6.3 days, with 5 pts leaving the hospital within 3 days after surgical intervention. In conclusion, our data confirm all advantages of minimal invasive neurosurgical approach for cerebral aneurysm clipping. The less invasive approach guarantees as well optimal surgical success (at least identical to conventional approach) as significantly shortened procedure time and ICU-hospital stay.  To characterize the behaviour of serum insulin like growth factor-I (IGF-I) and growth hormone (GH) in the acute phase and to three months after acute subarachnoid haemorrhage (SAH). To evaluate if IGF-I has impact on the quality of life in patients with SAH. [ 18 years scheduled for elective aneurysm surgery (n = 16) and patients with SAH (n = 30) were included. Patients with pituitary insufficiency were excluded. First week daily IGF-I and GH concentration were measured and the measurements were repeated at three months. At three months a 15 dimension quality of life assessment was filled out. We defined low serum IGF-I concentration as \11 nmol/l and low quality of life as less than 0.8. We used a Bayesian network method for predicting factors affecting poor quality of life after SAH. RESULTS. IGF-I levels were lower in patients with SAH than in control patients at days 1-5 (p = 0.01) (Fig. 1) . No difference was found at three months. Serum GH concentrations were similar in both groups. There was no consistent correlation of SAPS II, SOFAmax or APACHE II scores with GH or IGF-I. There was no difference between IGF-I or GH in respect of aneurysm location, treatment modality, Hunt-Hess grades, Fisher grade, GCS, vasospasm or need for noradrenalin or hydrocephalus. The 15 days quality of life in patients with SAH was 0.81 ± 0.16 and in control patients 0.86 ± 0.09 (p = 0.24). The mean IGF-I concentrations from days 1-7 in patients with SAH was 11.1 ± 5.0 nmol/l. Patients with Glasgow Outcome Scale (GOS) \ 4 had lower IGF-I levels than GOS 5 patients. If mean IGF-I concentration was \ 6.22 nmol/it predicted poor quality of life with a probability of 97% in patients with SAH. IGF-I did not predict quality of life in the control group CONCLUSIONS. This is the first study to evaluate the behaviour of IGF-I and its association with quality of life in the acute phase of SAH. Serum IGF-I levels are low during acute SAH, but they normalize at three months. Severity of SAH does not influence serum IGF-levels. Quality of life at three months was equal in patients with acute SAH and after elective operational aneurysmal surgery. However, low IGF-I concentration immediately after SAH may predict poor quality of life. More studies are needed to evaluate the role of IGF-I in acute brain catastrophes like SAH. RESULTS. 168 patients were included: age 57.5 years (SD 14.9), 62.5% women, APACHE II 12 (SD 6.7), Glasgow Coma Scale (GCS) 9.9 (SD 6.5). Punctuation in clinical grading scales was: Hunt-Hess(H-H) 2.8 (SD 1.5); Fisher(F) 3.0 (SD 1.0); World Federation Neurosurgeons Scale (WFNS) 2.8 (SD 1.5). Personal antecedents: arterial hypertension (32.1%), followed by alcohol/drugs use (31.2%) and previous SAH (6.8%). Presentation was headache (61.9%), followed by low consciousness (28.6%). We perform CT angiography 9.6% and arteriography 78.6% (delay was 1 day). We found no aneurysm in 24.6%. INTRODUCTION. Advanced hemodynamic monitoring role in the estimation of infusion strategy in the critically ill patients is still an unknown question. We compared the infusion volume and structure before and after systemic hemodynamic monitoring initialization in patients with intracranial hemorrhage. METHODS. 46 patients with aneurismal subarachnoid hemorrhage and severe traumatic brain injury with GCS 4-9 enrolled in the study. Advanced monitoring of hemodynamic parameters by transpulmonal thermodilution was used in all patients. We calculated and compared infusion volume and structure in the 24-h periods before and after initialization of advanced hemodynamic monitoring. At the time of first thermodilution hypovolemia (global end-diastolic volume index below 680 ml/m 2 ) was diagnosed in 32 patients (70%). Infusion volume increased after the beginning of advanced hemodynamic monitoring (before monitoring initialization-3,764 ± 1,815 ml, after monitoring initialization-4,215 ± 1,740 ml). Amount of infused crystalloid solutions and blood products remained unchanged (crystalloids: before monitoring initialization-2,084 ± 1,993 ml, after monitoring initialization-1,975 ± 1,705 ml; blood products: before monitoring initialization-575 ± 123 ml, after monitoring initialization-767 ± 105 ml). Volume of infused colloid solutions increased significantly (before monitoring initialization-1,105 ± 801 ml, after monitoring initialization-1,474 ± 899 ml (p \ 0.05)). CONCLUSION. Initialization of advanced hemodynamic monitoring in patients with intracranial hemorrhage allows accurate hypovolemia diagnosis and is associated with significant changes in the infusion strategy. METHODS. We carry out at least one examination of CSF in patients with SAH or with unruptured aneurysm, with a control of CSF pressure and a biochemical examination. In indicated cases we perform a more detailed CSF examination focused on inflammatory changes. We evaluate the inflammatory reaction by an energy-balance examination, which describes the level of aerobic and anaerobic metabolism in the CNS compartment, based on the ratio of glucose and lactate levels in CSF and monitoring the cytology changes. The results were divided in three categories: without inflammation, with serous inflammatory response and with purulent inflammatory response. RESULTS. 167 patients with SAH or unruptured aneurysms were treated in our department between January 2006 and December 2008 with the following Hunt-Hess classification: HH0 = 51, HH1 = 19, HH2 = 26, HH3 = 29, HH4 = 26, HH5 = 16. In 112 patients a surgery was performed (clip, wrap), 50 patients were treated with coiling, and in 5 patients we decided to conduct only a conservative treatment. In 43 indicated patients we performed altogether 119 detailed examinations of CSF, based on a single lumbar punction or external lumbar/ventricular drainage. CSF samples showed no inflammatory response in 13 patients, serose inflammatory response was found in 11 patients and purulent response in 19 patients. This purulent response was more frequent in patients with higher degree of Hunt-Hess classification, however, it was recorded also in both clipped and coiled patients. Positive bacterial cultivation was found only in 9 patients. DISCUSSION. Subarachnoid haemorrhage can produce an inflammatory response itself and the brain tissue damage caused by hemorrhage can elicit inflammation too. This response is intended for restoration of the initial condition and it is evidently a non-infectious etiology. In this reaction we can usually see moderate level of anaerobic metabolism in CSF compartment caused by activation of the immune system. In SAH we can also see a non-infective purulent response caused by reperfusion of the ischemic areas of the brain due to cerebral vasospasms. The key role takes the C5a unit of the complement with its chemotactic effect on neutrophils and their production of free oxygen radicals. This response manifests itself with deep anaerobic metabolism in CSF compartment and predominantly neutrophils in cytologic picture. When the bacterial etiology is missing, we call this reaction a ''pseudopurulent'' response. A significant risk factor for the participation of bacterial etiology is the presence of external lumbar or ventricular drainage. CONCLUSION. By using these simple and widely available biochemical methods we can quickly and precisely detect the inflammatory changes in time with no systemic signs of an inflammatory response. BACKGROUND. Hypotonic hyponatremia is frequent in patients with subarachnoid hemorrhage (SAH) and is generally related to the syndrome of inappropriate antidiuretic hormone secretion (SIADH). Several treatments, including hypertonic solutions or arginine vasopressin receptor antagonists (VRA) may be considered but have potential adverse effects and VRA are expensive. The efficacy and safety of urea has been reported in patients with chronic SIADH, but not in patients with acute neurological disease and SIADH. HYPOTHESIS. Urea is an effective and safe treatment to correct sodium (Na) levels in SAH patients with SIADH. We reviewed the medical data of all patients admitted in our department for non-traumatic SAH from January 2003 to February 2009 (n = 368). All patients with hyponatremia due to SIADH (Na \ 135 mEq/L, osmolality \ 270 mosm/L, urine Na [ 20 mEq/L, urine osmolality [ 200 mosm/L, absence of dehydration or edema, and of renal, adrenal and thyroid disease) received oral urea when hyponatremia was associated with clinical deterioration or remained below 130 mEq/L despite adequate fluid management and sodium administration. Urea was given orally or by nasogastric tube, at doses of 15 to 30 g q6 h. The primary efficacy indicator was the time to Na correction ([135 mEq/L). We also evaluated the total dose of urea received as well as the potential adverse events. Data are presented as median (range). Thirty-nine patients (11%) received urea to reverse hyponatremia due to SIADH. Median age was 55 (29-80), 21 patients were female. Most aneurysms (23/39) were located in anterior vessels. Median admission Na was 139 mEq/L, with only one hyponatremic patient. Hyponatremia, with a median Na of 132 (126-134) mEq/L, was diagnosed after a median time of 4 days (1-13. Urea was started after a median time of 7 days (2-18) and given for a median of 5 days (1-23). Median daily dose was 60 g (15-150). Hyponatremia was corrected in all patients, with a median time to Na [ 135 mEq/L of 3 days (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) . The median Na increase over the first day of treatment was 3 mEq/L (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) . Urea was well tolerated and no adverse effect was reported. Oral urea is an effective and well tolerated treatment to increase serum Na in SAH patients with hyponatremia due to SIADH. The need of mechanical ventilation, intracranial hypertension and renal failure were significantly associated with higher mortality. Coiling or clipping treatment were not associated with gender and pathological history. There were significantly more percentages of worse scores of GCS, Hunt-Hess, WFNS in patients with coiled than clipped aneurisms. Rebleeding and hydrocephalus were more frequent in coiled patients, but more intracranial hypertension and ischaemia in clipped patients, without statistically significant differences. No statistically significant differences were observed in no neurological complications in ICU. CONCLUSIONS. Patients with SAH in our ICU were severe because most of them (82%) were Fisher 3-4. Characteristics associated with SAH mortality in ICU were: prognostic scores for SAH (GCS, Hunt-Hess, WNFS), intracranial hypertension, the need of mechanical ventilation and renal failure. There were more clipped aneurisms than coiled, and coiled aneurisms were more severe than the clipped ones. Complex cerebral aneurysm surgery carries a high risk for intra-operative ischemic insults, especially if multiple periods of temporary clipping seem necessary to allow final aneurysm clipping. The use of non-invasive neuromonitoring, applied during aneurysm surgery, could guide as well intra-operative neuroprotective strategy as postoperative neuro-critical care. In 12 pts, scheduled for elective complex cerebral aneurysm surgery by supra-orbital incision, non-invasive cerebral oximetry was applied over the patient's forehead, enabling bilateral brain saturation monitoring intra-operatively and for the first 12 h after ICU admission. Fore-Sight monitor is a continuous wave, spatially resolved, near-infrared spectrometer that measures absolute cerebral tissue oxygen saturation (SctO 2 %) using 4 wavelengths. Validation studies proved a stable correlation between SctO 2 and jugular bulb saturation (SjO 2 ) with SctO 2 10% higher than SjO 2 . As SjO 2 has a normal safe limit of 45%, the absolute SctO 2 threshold is estimated at 55%. In 3 of 12 pts, excessive intra-operative ambient light interfered with SctO 2 monitoring and no SctO 2 data could be obtained. In 7 of 9 remaining pts, multiple periods of temporary clipping were applied. In all pts, a small, nonsignificant decrease in ipsilateral SctO 2 was observed during temporary clipping, but in all periods, SctO 2 values remained above 55%. After release of the temporary clip, an immediate, shortlasting (3-5 min) and significant increase in ipsilateral SctO 2 was observed in 5 of 7 pts. After release of the temporary clip, ipsilateral SctO 2 immediately increased by a mean of 8.4% (range 7-11%) with return to baseline values after a mean of 4 min. This could point to a local and important hyperperfusion occurring after the release of the temporary clip. All pts remained sedated until stable postoperative conditions were obtained. During postoperative ICU course, all pts revealed slightly increased (bilateral) SctO 2 values without any values below 55%, even during awakening procedure. No pt revealed any neurologic deficit at awakening (mean 6.4 h after ICU admission). This first report reveals the feasibility of intra-and post-operative non-invasive cerebral oxygenation monitoring, using absolute SctO 2 monitoring, during complex cerebral aneurysm surgery. Brain oxygenation monitoring during critical periods of temporary clipping may guide optimal postoperative neuro-critical care. Cerebral oximetry, based on NIRS, measures regional cerebral tissue oxygen saturation (SctO 2 ) non-invasively at the microvascular level. The FORE-SIGHT absolute cerebral oximeter, a recently introduced monitoring device, uses 4 precise wavelengths to determine absolute SctO 2 . In the present study, we want to report on the changes in absolute SctO 2 occurring during craniotomy for acute intracerebral hematoma. Thirteen pts suffering from acute intracerebral bleeding and scheduled for urgent craniotomy were included. All pts presented with reduced consciousness (GCS \ 8) and with signs of increased intracranial pressure (referring to CT imaging). Pts received systemic stabilization (intubation, ventilation, hemodynamic monitoring and support) and were transferred as soon as possible from the emergency department into the operating theatre (OR) for urgent removal of the intracerebral bleeding. As soon as pt arrived in the OR, bilateral SctO 2 monitoring was started (sensors applied bilaterally over patient's forehead). Pts arrived in the OR after a mean of 1.3 h after hospital admission. Five pts suffered from acute intracerebral bleeding, while 4 pts presented with acute subdural hematoma and 4 pts presented with acute epidural hematoma. In 2 of 13 pts, excessive ambient light interfered with SctO 2 monitoring and no SctO 2 data could be obtained. In the other 11 pts, SctO 2 values ipsilateral to the intracerebral bleeding, were significantly lower than contralateral SctO 2 values. In 2 pts, ipsilateral SctO 2 values below 55% were observed. One of these pts suffered from epidural hematoma, the other pt presented with a subdural hematoma. Bone removal resulted in a significant increase in ipsilateral SctO 2 in 2 pts. Opening of the dura resulted in a significant increase in ipsilateral SctO 2 in 7 pts, while in 2 pts (with intracerebral bleeding) a significant increase in ipislateral SctO 2 occurred after effective removal of the bleeding. In no pts, any significant change in contralateral SctO 2 values was observed during the whole procedure. In all pts, ipsilateral SctO 2 values increased further during procedure and ipsilateral SctO 2 values were higher than 80% in all pts at postoperative transfer to the ICU department. Non-invasive monitoring of absolute cerebral oxygen saturation at the microvascular level might offer new opportunities for the management of pts suffering from acute intracerebral bleeding. Information obtained during urgent craniotomy might guide further neuro-critical care management. CONCLUSION. Our study showed that the most significant prognosis factors related to 6 months outcome are: APACHE II, initial GCS, discharge GOS and GCS. Complications related to SAH were associated with prognostic in the following 6 months. The patients with poor 6 months GOS had longer ICU length of stay. Six months outcome was significantly better than discharge ICU, and most of the patients present good recovery. OBJECTIVES. We aimed to investigate the diagnosis and surgical management of symptomatic SSEH. METHODS. Five cases of acute symptomatic SSEH with favourable neurological recovery after emergent microsurgery were prospectively analysed. RESULTS. The main clinical presentations were root pain and palsy. The main manifestations of MRI (Magnetic Resonance Imaging) were long-segment epidural lesions of high intensity on T1 and T2-weighted images without enhancement. With the microsurgery system, laminectomy via posterior approach and hematoma removal were undergone for all patients. Postoperative MRI confirmed the complete evacuation of hematoma, and all patients achieved full neurological recovery without complications. CONCLUSIONS. MRI manifestation assisted with the main clinical symptoms may aid the preoperative diagnosis of acute SSEH, and the delay in obtaining Digital subtraction angiography before surgery is worthwhile, especially for those patients with progressive neurological deterioration. Microsurgery is an effective method for treating acute symptomatic SSEH. OBJECTIVES. The mechanism of acute lung injury prevention with shock resuscitation under hypoxemia was investigated. METHODS. Rabbits were subjected to hemorrhagic shock; they were then resuscitated under normoxemic (NormoxRes) or hypoxemic conditions (HypoxRes). Broncho-alveolar lavage (BAL) was performed in the right lung and BAL fluid oxidative mediators and pro-inflammatory activity were estimated; the left lung was removed for measurement of wet to dry weight ratio, histopathology and estimation of cytokine gene expression. Cell peroxides were considerably reduced in BAL cells of HypoxRes compared to NormoxRes animals; the same was true for BAL malonyldialdehyde, while BAL total antioxidant capacity was increased. NormoxRes group BAL was a greater stimulator of interleukin (IL)-8 and other pro-inflammatory cytokine release than those of the HypoxRes or sham groups. In the presence of SB203580 and Syk inhibitor and of monosodium urate (MSU), release of IL-8 was decreased suggesting involvement of specific tyrosine kinases. Lung oedema, nitrotyrosine and IL-8 levels, degree of lung infiltration by neutrophils, tissue myeloperoxidase (MPO) and IL-8 gene expression were reduced in lungs from HypoxRes compared to NormoxRes animals. INTRODUCTION. The mechanisms associated with immunomodulation after red blood cell (RBC) transfusion are not completely understood, possibly due to methodological biases and presence of comorbidities such as sepsis and trauma in the clinical studies. Therefore, a controlled experimental model of blood cell transfusion in normal animals may be a more appropriate approach to minimize these issues and to study transfusion-induced adverse events. OBJECTIVES. We designed this pilot study in order to validate in vitro and in vivo the survival of swine RBC stored for 13 days. We also performed a transfusion of stored red blood cells in one hypovolemic animal to test the feasibility of this procedure and to assess possible significant clinical reactions. METHODS. Blood was collected from one swine and stored in 2 units of RBC. The following measurements (in vitro evaluation) were performed at baseline and after 13 days of storage: volume, hemoglobin and hematocrit, hemolysis index, potassium, sodium, glucose and pH. In vivo validation and hemolysis evaluation were performed by labeling the cells with Na 2 51 CrO 4 and injecting 2.5 ml/kg of labeled cells in 1 autologous and 4 homologous animals. Blood was collected at different intervals (5 min, 10 min, 1, 3, 6, 9, 12 and 24 h) in order to acquire a feasibility curve of erythrocytes up to 24 h after transfusion. Three microliters of each blood sample collected were counted for 300 s in an Automatic Gamma Counter. The animal chosen to receive the allogeneic blood transfusion underwent a controlled hemorrhage of 1,000 mL with replacement of 3000 mL of normal saline and further transfusion of 233.4 mL of RBC stored for 13 days. Hemodynamic and respiratory parameters were measured before hemorrhage and every 2 h until 24 h after transfusion. A splenectomy was performed after death in all the animals to evaluate splenic sequestration of RBC. Table 1 . BACKGROUND. Gabapentin has been reported to have protective effect against ischemic brain injury but the cellular mechanisms of action remain unknown. Heat shock proteins (Hsps) are important regulators of cellular survival and have neuroprotective effects against cerebral ischemia. The present study was undertaken to examine the protective effects of gabapentin pretreatment against cerebral ischemia and if the neuroprotective effects of gabapentin could have relation to the expression of Hsps. METHODS. Forty male Sprague-Dawley rats (260-300 g) were randomly assigned one of four groups (control group, 0.1 mg/kg gabapentin group, 0.5 mg/kg gabapentin group, 5 mg/ kg gabapentin group). In all animals, focal cerebral ischemia was induced by intraluminal middle cerebral artery occlusion for 1 h. The animals of gabapentin groups were pretreated with a single intravenous administration of gabapentin 20 min before ischemic insults. The infarct volume, brain edema and motor behavior deficits were analyzed 24 h after ischemic insult. The caspase-3 reactive cells and the cells showing Hsp70 activity were counted at the caudoputamen and fronto-parietal cortex. RESULTS. The infarction ratio was significantly decreased in the 5 mg/kg gabapentin group (P \ 0.05) and brain edema ratios were significantly reduced in the 0.1, 0.5, and 5 mg/kg gabapentin group 24 h after ischemia/reperfusion injury (P \ 0.05). The number of caspase-3 reactive cells in the gabapentin groups was not significantly different than those values of the control group in the caudoputamen and fronto-parietal cortex, but the number of cells showing Hsp70 activity was higher in the 5 mg/kg gabapentin group than those values of the control group in the caudoputamen and fronto-parietal cortex (P \ 0.05). These results indicate that the gabapentin may have neuroprotective effect and reduce early neuronal injury caused by focal cerebral ischemia/reperfusion, and this could be mediated by expression of Hsp70. However gabapentin pretreatment may not prevent the caspase dependent apoptosis. OBJECTIVES. This study designed to investigate the neuroprotective effects of lithium on hypoxic-ischemic brain injury in the neonatal rats. We analyzed the effect of lithium treatment using 1 H-magnetic resonance spectroscopy as a non-invasive tool. METHODS. 7-day-old Sprague-Dawley rats underwent hypoxic-ischemic injury (HII) induced by the ligation of the common carotid artery followed by exposure to about 2.5 h of hypoxia (oxygen concentration was maintained about 7%). After the HII, rat pups were randomly assigned into two groups; control group (n = 21) and lithium group (n = 32). Two groups of rats were treated daily subcutaneous injection with lithium chloride (1 mmol/kg) or 0.9% normal saline for 2 weeks following the HII. N-acetylaspartate/Creatinine (NAA/Cr), Choline/Creatinine (Cho/Cr) and Lipid/Creatinine (Lip/Cr) ratios of proton magnetic resonance spectroscopy ( 1 H MRS) were evaluated as apoptotic markers on the day of HII, 7 and 14 days after HII. All rats were sacrificed 2 weeks after HII for morphologic scoring. RESULTS. At 7 days after HII, the Lip/Cr ratios in the lithium group were significantly lower than in the control group (p = 0.004, p = 0.021, respectively) ( Fig. 1 ). There were no significant differences in the Cho/Cr and NAA/Cr ratio between two groups. The mean morphologic score of the lithium group (3.5 ± 0.9) was significantly lower than the control group (3.0 ± 1.0) (p = 0.026). CONCLUSIONS. Our in vivo study showed that chronic post-HII treatment with lithium had a neuroprotective effect in the immature developing brain. OBJECTIVES. Our objective was to test this hypothesis. Experimental study in Swiss mice with intraperitoneal morphine administration and comparison of both analgesic (using hot plate, N = 10/group) and respiratory effects (using plethysmography under 4%-FiCO 2 , N = 8/group); determination of a protocol inducing acute and chronic tolerance; calculation of the 50%-effective dose (ED 50 ); in vitro study of 3 H-DAMGO binding on 2 brain structures (periaqueductal grey region and brainstem); comparisons using ANOVA for repeated measurements followed by Bonferroni posttest. Morphine analgesic effects were dose-dependent. Tolerance to morphine was reached with a repeated 2.5 mg/kg/day administration during 10 days, with a 13-time increase in ED 50 . Kinetics of morphine-related respiratory effects were parallel to the analgesic effects with a significant increase in inspiratory time (TI) at 30 and 40 min after injection (p \ 0.01), without any significant modification in the total volume. Mice pre-treatment with a huge dose of morphine (100 mg/kg, subcutaneously) one day before resulted in a significant reduction of 2.5 mg/kg morphine-related effects on the expiratory time (T E ) (p \ 0.05). Using the same protocol, we observed in mice only a limited tolerance at day 10 in comparison to day 1 without a significant modification in the ED 50 of the respiratory effects. Tolerance intensity to the analgesic effects was more important than tolerance to the respiratory effects at day 10. This difference was not accompanied by any significant modification in membrane expression of mu-opioid receptors based on differences in 3 H-DAMGO binding between the periaqueductal and brainstem regions. CONCLUSIONS. Tolerance to morphine respiratory effects was more limited than to its analgesic effects at day 10 of repeated administration. Consequently, this model supports the hypothesis that attributes morphine toxicity to the development of a weaker tolerance to its respiratory effects. However, other mechanisms of toxicity should be considered to explain the variability of respiratory depression. [1] . However, data about gender differences in hypovolemic normothermic cardiac arrest is lacking. OBJECTIVES. The aim of this study was to evaluate possible beneficial effects of estradiol with vasopressin and amiodarone in hypovolemic CA and subsequent cardiopulmonary resuscitation. METHODS. Five anesthetized female piglets (25.9 ± 1.6 kg) were bled (29 ± 4% of calculated total blood volume) via right femoral artery to a mean arterial blood pressure of 35 mmHg during 13.4 ± 0.2 min. At the end of bleeding 50 lg/kg 17b-estradiol was given intravenously to all piglets. Afterwards the piglets were subject to 4 min untreated ventricular fibrillation followed by 15 min open-chest cardiopulmonary resuscitation. At 5 min of CA 0.4 U/kg vasopressin and 0.5 mg/kg amiodarone were given intravenously and an infusion of hypertonic saline and dextran (HSD, 7.5% saline, 6% dextran 70) 3 ml/kg was given in 20 min. Internal defibrillation was attempted from 8 min of CA to achieve restoration of spontaneous circulation (ROSC). Hemodynamic variables, continuous cerebral cortical blood flow and blood gas parameters were measured during CPR and up to 180 min after ROSC. Blood samples for 8-iso-PGF2a, 15-keto-dihydro-PGF2a, protein S-100b and troponin I were taken. RESULTS. ROSC was achieved in 3 out of 5 piglets. Only two of these piglets survived the whole experiment. Another piglet died 10 min after ROSC due to a new episode of ventricular fibrillation. It was difficult to achieve ROSC due to persistent ventricular fibrillation during CPR. The mean number of defibrillation attempts was 13 (range 5-30). The mean coronary perfusion pressure was 12-28 mmHg during CPR. Piglets that achieved ROSC needed a constant dobutamine infusion for hemodynamic stability. Concentrations of troponin I continuously increased after ROSC, reaching maximum levels in the end of the study. During the very early reperfusion phase (5-15 min after ROSC) cerebral cortical blood flow was 6-11% greater than baseline values. Thereafter, it decreased to baseline level during the remainder of the experiment. PBN) is a spin-trap scavenger that significantly alleviates cerebral cellular damage after global ischemia [1] . OBJECTIVES. We hypothesized that S-PBN given during cardiopulmonary resuscitation (CPR) will diminish cerebral damage and improve cerebral perfusion response in hypovolemic cardiac arrest. METHODS. Five anesthetized male piglets 24 kg were bled 30% of calculated total blood volume via femoral artery to a mean arterial blood pressure of 35 mmHg during 14 min. Afterwards the piglets were subject to 8 min untreated ventricular fibrillation followed by 15 min open-chest CPR. At 9 min of CA 0.4 U/kg vasopressin and 1.0 mg/kg amiodarone, and 60 mg/kg S-PBN were given intravenously. At the same time 3 ml/kg infusion of hypertonic saline and dextran (7.5% saline, 6% dextran 70) was started and given for 20 min. Internal defibrillation was attempted from 11 min of CA to achieve restoration of spontaneous circulation (ROSC). Hemodynamic variables, continuous cerebral cortical blood flow and blood gas parameters were measured during CPR and up to 180 min after ROSC. Blood samples for 8-iso-PGF2a, 15-keto-dihydro-PGF2a, protein S-100b and troponin I were taken. RESULTS. ROSC was achieved in 5 out of 5 piglets. All these piglets survived the whole experiment. The mean number of defibrillation attempts was 5 (range 2-9). Dobutamine was started 8.3 min after ROSC. The total dose of dobutamine was 19 mg (range 10-26). Cerebral parameters are presented in Table 1 (data is presented as mean ± SD, n = 5). AIMS. Cooperation of the members in emergency teams is very crucial to reduce the waste time and increase the chance of survival in critical care situations. The good teamwork may be achieved by continuous practicing of team members only. The structure of the Hungarian Emergency Medical Service (EMS) has changed in the last decade, new positions and staffs appeared in this altered system. Until recently there was no study available to assess the collaboration, and tasks of members in teams. Our goal is to analyze nurses' tasks and physician's attitude about advanced life support (ALS) skills of nurses according to daily routine. A representative cross sectional study design was applied with self-fill-in questionnaire about nurse's tasks and physician's attitude about nurse's duties in ALS process. The questionnaires was distributed between September and November 2007 in 24 (out of 31) emergency departments. In this survey 159 physicians' and 327 nurses' questionnaires were processed. Chi-square and Student's t test was used for comparison of variables. p-values less than 0.05 were considered statistically significant. RESULTS. According to nursing answers their participations in different steps of ALS were low (17.7-68.2%). Several important steps of resuscitation as chest compression (p = 0.029) and defibrillation (p \ 0.001) are significantly rarely were performed by nurses than the expectation of medical staff. But the achievement of mask-bag ventilation, intravenous access and drug administration did not show difference between medical and nursing staffs. Significantly larger part of male nurses were applied mask-bag ventilation (p = 0.001), and chest compression (p \ 0.001), whereas the greater proportion of female nurses have been done intravenous ways (p = 0.001) and administered drugs (p = 0.002) in nursing practice during ALS. The tendencies of active participation of nurses in ALS process were increased with age of nurses. CONCLUSIONS. The active participation of nurses during ALS was lower than required especially in cases of chest compression (49.8%) and defibrillation (17.7%) skills. If the assembling of emergency team is impaired the effectiveness of teamwork may be reduced critically. The low involvement of nurses in ALS and gender differences of duties highlight to determined the exact tasks of nurses and increased the collaboration of teamwork between the members of staff by more practicing. Factors associated with the development of delirium during ICU admission were the presence of neurological worsening (\0001), sensory deprivation (p = 0003) or sepsis (p = 0001) and treatment with benzodiazepines (\0001). Among the factors that were associated with the disparity between the two scales, only the diagnosis of delirium by CAM-ICU was associated with worse scores on Glasgow Coma Scale (p = 0002) and worse score on the SOFA scale(p = 0016), while none of the factors studied were associated with the diagnosis only by ICDSC. CONCLUSIONS. The presence of neurological disturbance, sensory deprivation or sepsis, and treatment with benzodiazepines were associated with the development of delirium in our series. The GCS score has a great influence on the diagnosis of delirium using the CAM-ICU system, since most patients with some degree of altered level of consciousness were diagnosed by that scale, but not with ICDSC. This may lead to overestimate the incidence of delirium using CAM-ICU in patients with neurologic deficits or sedation. Further studies are needed to define the ideal tool for the diagnosis of delirium in the ICU. INTRODUCTION. Delirium is a significant clinical entity that occurs in 11-80% [1] of the critically ill patients. It is an independent predictor of increased mortality at 6 months and prolongs the stay of ventilated patients in intensive care [2] . It may be associated with prolonged hospital stay and a high rate of cognitive impairment at discharge [3] . These factors contribute to amplified intensive care and hospital costs [4] . OBJECTIVES. To find out the existing practise of managing Delirium in Intensive care in UK. A nationwide telephonic survey was undertaken; data was collected by interviewing the doctors within 33 intensive care units in UK. • 67% of the Survey was answered by Registrars, 27% by Consultants and 6% by Senior House officer/foundation year doctors. • Only 39% were aware of any guidelines/recommendation in the management of ICU delirium. • 94% used subjective measures to assess and identify delirium in intensive care, while only 6% used objective findings. • Based on UK Clinical Pharmacy Association guidance 5 , only 61% got all the components right, with regard to clinical features of ICU delirium. • 70% used Haloperidol as their first line management of ICU delirium, whereas 27% used benzodiazepine, and 3% used other agents. • 58% used benzodiazepine as their second line management of the ICU Delirium, while 24% used haloperidol, and 18% used others. • 100% practise some form of non pharmacological methods in managing delirium. 97% practiced sedation hold. • 82% started pre existing psychiatric medications immediately (within 48 h)/as soon as they could in ITU patients, 13% delayed their use (after 48 h). • 73% used sedation or agitation score in ITU. CONCLUSIONS. Awareness among ITU medical staff is poor with regard to recommendations or guidance on management of delirium. Incorporation of recommended guidance based assessment and management of delirium in the ICU and awareness processes may improve long-term patient outcomes. It may also facilitate judicious utilisation of resources. (13), grade III (11) and ACS (28). Sepsis was the commonest primary diagnosis in 11 patients followed by intestinal obstruction in 6. The primary diagnosis was SAP, post laparoscopy, ascites and polytrauma in two each. There were one patient in each group of intraperitoneal bleed, dengue and post TURP. The indications for intervention were unexplained respiratory deterioration (14), decrease in urinary output (6), critical bleeding (6), source control sepsis (2) . There were 19 primary, 9 secondary and 2 recurrent cases. OBJECTIVES. To audit the incidence of adverse events when mobilising patients receiving vasoactive agents. METHODS. All physiotherapist-led mobilisations of patients receiving continuous infusions of vasoactive agents were prospectively examined over 8 weeks. Changes in haemodynamic parameters from baseline, adverse symptoms, and levels of physical activity achieved were recorded. Adverse events were defined as one or more of: 25% fall in blood pressure, 25% change in heart rate, signs and symptoms persisting more than 60 s, or early discontinuation of therapy. (4), transferring to the chair (14), standing (13), marching on the spot (27), and walking (11). 8 adverse events were recorded. 4 of these represented prolonged dizziness without significant change in cardiovascular parameters (3 necessitating discontinuation of therapy). 4 represented a 25% reduction in blood pressure: 2 were associated with symptoms and 1 with tachycardia. 2 required early discontinuation of therapy. There were no significant differences in dose of vasoactive agent or number of agents being received in patients suffering adverse events (Table 1) . 3 pts had been previously mobilised uneventfully on greater doses of vasopressor. All changes resolved when the patient returned to bed. All patients subsequently survived to hospital discharge.  Recently there has been increased interest in the early mobilisation of critically ill patients [1, 2, 3] . Proposed potential benefits include improvements in respiratory function, reduced muscle wasting and decreased intensive care unit and hospital length of stay [1, 4] . OBJECTIVES. The aims of this study were to describe the frequency of utilisation of early mobilisation techniques in critically ill patients and the reasons for inability to conduct the techniques. A 4-week prospective audit was undertaken in a mixed medical and surgical tertiary intensive care unit. Demographic data collected on all admissions included: age, gender and admission diagnosis. Outcome data included: the number of patients mobilised by a physiotherapist, the nature of mobilisation and the reasons for inability to mobilise the patient. . 106 patients were assessed over 324 patient days. 48% (155 patient days) were ventilated patient days. The patients were predominantly male (66%), mean age 60 ± 20 years with mean APACHE II score of 14.7 ± 7.8. During the patient assessment period, 76 patient days underwent active mobilisation (marching on the spot for [30 s or mobilising away from the bed space), of which 17% were ventilated and 83% were nonventilated. 110 patient days underwent active transfer out of bed to a chair (15% ventilated patient days and 85% non-ventilated patient days) and 67 patient days underwent passive transfer out of bed to a chair (63% ventilated and 37% non-ventilated). Adverse events occurred in 2 of the 324 patient care days (0.6%). Reasons for inability to mobilise a patient during the ventilated patient days included: respiratory instability (28 patient days), haemodynamic instability (17 patient days), presence of a femoral dialysis catheter (15 patient days), neurological instability (14 patient days), and timing of procedures (11 patient days). Critically ill patients can be safely mobilised during the majority of their intensive care unit stay, which can be further improved by some simple adjustments in care (siting of dialysis catheters and timing of procedures). INTRODUCTION AND OBJECTIVES. The critically ill patients on numerous occasions need to be transported from one section of the hospital to the other for diagnostic, therapeutic or operative procedures. During the intrahospital transport, a number of critical events have been reported with incidence ranging form 21 to 84%. These critical events mainly include variation in blood pressure, airway obstruction, hypoxaemia, cardiac dysrrhythmias and even frank cardiac or respiratory arrest. In addition, lack of appropriate monitors and advanced supportive care and absence of trained nurse(s) to transport a patient safely to areas within the hospital, add to the adverse untoward events during Intrahospital transport. However, the incidence of adverse outcomes from transport related complications is not well documented. So this study was designed to documents the critical events during the intrahospital transport of critically ill patients. An attempt is also made to recommend guidelines for safe transport of these patients. . 55 critically ill patients requiring movement within the hospital were prospectively studied. Cardiovascular and respiratory parameters including oxygen saturation (SpO 2 ) and end tidal CO 2 (ETCO 2 ) were recorded using a battery powered monitor (Propaq 102 EL, Protocol Inc., USA) during the transport; ventilation wherever needed, was provided using a self inflation bag by a nurse, however a critical care nurse accompanied all the patients. A note was also made of complications related to equipment, personnel and route itself. RESULTS. 85% of patients showed critical changes in pulse (p \ 0.001), 83% developed haemodynamic instability (p \ 0.001). 72% showed significant fall in SpO 2 (p \ 0.001) and 93% of ventilator dependent patients showed changes in ETCO 2 (p \ 0.00). Equipment related complications were encountered in 60% of the moves (p \ 0.001) while 31% of the moves (p \ 0.05) required a major intervention. Inexperienced Nurse resulted in lifethreatening situations during two moves. Severity of the illness and total duration of transport contributed to frequency of complications. The linear relationship was observed on regression analysis between SpO 2 and time (p \ 0.05). We recommend a portable transport system with patient monitor, ventilator and resuscitative equipments (with sufficient power backup) along with trained Nurse and prior planning of the route for safe intrahospital transport of critically ill patients.  We conducted an observational retrospective pilot study over 12 months, including all patients from the Boucle Nord palliative care networks and who called the Service d'Aide Médicale Urgente (French EMS system, SAMU) for a life-threatening emergency. A formal procedure has been set up for these situations. In case of a lifethreatening situation, the patient or his relatives call first the palliative network physician on duty who has full access to patient's file. The call to the EMS coordination centre (SAMU) is made by the palliative network physician and not directly by the patient himself. Both the palliative network physician and the SAMU physician share the decision whether an EMS team has to be sent out or not. Characteristics of patients, treatments, orientation and outcomes were recorded. Patients were allocated to one of the two groups: respect of the procedure or not. Data were compared between the 2 groups. Man criterion was the proportion of patients for whom the palliative care plan has been respected. Data were compared using a Fisher's exact test. A p \ 0.05 was considered the threshold for significance. . 30 patients were included. The procedure was point by point followed for 20 patients and not followed for 10 patients. Main distresses were respiratory failure (13 patients), prolonged seizure (5 patients), unbearable pain (4 patients). Patient's characteristics are similar in both groups. A decision of transfer to the hospital was taken for 21 patients. In 5 cases, the EMS physician made a prescription for a left on-scene patient and management was continued by the palliative network. The palliative care plan was respected for 100% patient when the procedure was followed vs 50% when the procedure was not followed (p = 0.002). CONCLUSION. Collaboration between an ambulatory palliative care network and a physician staffed EMS is promising and allows emergency responses for this particular population with a respect of the advanced care plan. INTRODUCTION. Created by multiple sources, alarms in the ICU generate noise, discomfort and stress for patients, and divert ICU staff attention. Less than 25% of alarms trigger a staff response (adjustment of sensor position, aspiration, treatment change…) and medical opinion is required in only 5.9% of cases [1] . Beside false alarms, some alarms could be generated by inappropriate settings. As there are no guidelines regarding alarms settings in the ICU, we conducted this study to assess variability in alarms settings on the monitor. We conducted a single-centre, prospective study during two 21-day periods to assess variability in alarms settings (07/08 and 09/08). After initial setting by nurses, alarms limits for various parameters (arterial blood pressure-ABP, EKG, arrhythmia, RR, SpO 2 , EtCO 2 ) were reviewed and eventually modified by the physician (MD) in charge at the beginning of day shifts. Consistency between alarms settings by nurses and physician was recorded, as well as occurrences, type and reasons for modifications of alarms settings during the monitoring period. We also recorded demographic data, motif of ICU admission, ICU length of stay, type and duration of organ support, and SOFA scores. RESULTS. 144 pts monitored for a total 484 monitoring days have been enrolled in the study. Nurses and MDs disagree on alarms settings in 26% of cases, and we identified major discrepancies in patterns of alarm setting irrespective of patients' condition. Nurses initiated 76% of modifications of alarms settings. They modified 3 ± 2.2 settings at start of day shift in 60% of cases whereas settings were altered in only 28% of cases (4 ± 1.8 changes) at start of night shift. 82% of alarms changes occurred outside of starting shifts. Figures 1 and 2 illustrate the reasons and the main changes in alarms settings. The noise peaks derived from the alarm systems often exceed 80 dB and are comparable to noise levels next to busy streets, thereby providing potential health hazards to patients and staff. Furthermore, low specificity of the alarms may lead to reduced alertness of staff which can result in missing responses to relevant alarms, eventually leading to a reduction of the clinical sensitivity of the alarm system. Previously, we established an experimental setting for generating a database of physiological data and clinical alarm annotations, and we here report the analysis of the completed database as well as possible solutions for a reduction of alarms. METHODS. The study was performed as a prospective observational clinical study in a medical ICU of a university hospital. Physiologic data, monitor alarms and monitor settings from the cardiovascular surveillance network were recorded at one-second intervals. Bedside video recordings were performed with a day and night camera and clinically annotated offline with respect to alarm relevance and technical validity. RESULTS. 5934 alarms were annotated during 982 h of observation, corresponding to 6 alarms per hour. About 40% of all alarms did not correctly describe the patient condition and were classified as technically false, 68% of those were caused by manipulation. Only 885 (15%) of all alarms were considered clinically relevant. Most of the generated alarms were related to arterial blood pressure (44%), followed by oxygen saturation (26%) and heart rate alarms (13%). Application of new alarm algorithms based on robust repeated median regression achieved an alarm reduction of 45% with acceptable sensitivity for arterial pressure, but not for heart rate. CONCLUSIONS. This study showed that even with modern monitoring systems, most alarms are not clinically relevant. Based on our results, several approaches for alarm reduction could be applied. Statistical methods are suitable to reduce the number of threshold alarms, but the high rate of technically false alarms also call for technical improvements. Since many alarms were induced by staff, recognition of certain alarm patterns, i.e. flushing of central lines, or methods for the detection of staff at bedside could also contribute to a reduction of alarms in order to improve patient care. BACKGROUND. Acute care nursing requires more stronger and intense work relations among the staff. Our aim was to find out working characteristics between nurses' teams in critical care settings (intensive, coronary care, emergency room) and in other acute units (surgery, acute internal medicine). A cross-sectional study design was used to explore teamwork features in a Hungarian hospital in 2008. A pilot tested self fill-in questionnaire was distributed to 130 bedside acute nurses working in the given setting more then 2 years. The tool measured different characteristics and impacts of teamwork on direct patient care. The data analysis was done with chi-square, t test and ANOVA method using SPSS 14.0. (5) educations (6) colleagues (nurses, doctors) and from ICU data systems. Nurses use mostly professional nursing journals (89%) and less common scientific nursing journals: international (23%) and national (19%) nursing journals. CONCLUSION. Nurses search evidence for practice studiously. More effort should put on use of scientific nursing journals and use of research of intensive care. On the other hand nurses use and read professional literature (nursing books and journals) and Internet. Therefore research results should also be contributed to professional nursing journals and books in appropriate design and further, the articles should be easy to access and available to read through via Internet.  A review was carried out to assess the impact of the implementation of the combined Outreach and Resuscitation service. Audit data was collected using the Medicus PDA system and MS Excel. A qualitative survey was also carried out using a free-text questionnaire. RESULTS. It would appear that there is an overall benefit of having competent and experienced Practitioners both teaching and providing resuscitation and critical care in the ward environment. Both the Outreach and Resuscitation Practitioners and the ward staff felt that their clinical skills were maintained and the links between the Resuscitation department and the hospital were improved. [1] recommended that the provision of care for patients in the cardiothoracic critical care unit must be reviewed to ensure that it provides continuity of care for patients and is in line with best practice in other cardiac units. We describe the multidisciplinary input of patients admitted to the Cardiothoracic Critical Care Unit (CTCC) of a large Teaching Hospital over a 6 month period and the severity of their condition on admission, examining the relationships between multidisciplinary team (MDT) input and trends in mortality. .7) but no difference was found in the total number of interventions between the groups (avg. 30). We also found this in the mortality group. CONCLUSION. All high risk cardiac surgical patients had a minimum of 8 different MDT inputs from non-core team members. There was no statistical difference in the total number of interventions between very high risk patients (EuroSCORE [ 40), the mortality group and the rest. A possible explanation for this could be because the length of stay was skewed in the very high risk and mortality groups; either very short or long, hence averaging out to the same number of total interventions between the groups. However the very high risk and mortality groups did have increased input from non-core MDT groups (mean of 9.7 vs. 8.8). This is in keeping with expectations that higher risk patients require more intensive MDT care. INTRODUCTION. Infection of a central venous catheter (CVC) occurs often in areas of critical care such as emergency department, intensive care unit and operating theatre. We investigated the role of the introduction site location in CVC sepsis, as well as puncture site in relation to catheter sepsis as defined by the Centre for Disease Control and Prevention, before and after an education-based intervention [1] . It has been shown that subclavian catheters show the least infection rates compared to femoral and jugular catheters. HYPOTHESIS: Education-based interventions can decrease rate of catheter-related bloodstream infections and change the puncture site from femoral to subclavian. In 2007 and the second half of 2008 all central venous catheters in our hospital were investigated for colonisation. CVC puncture site was registered as femoral, jugular or subclavian. Also the location of introduction: emergency department, intensive care unit or operating theatre was registered. All positive blood cultures with the same micro-organism as on the CVC were registered, according to the definition of the Dutch Working group on Infection Prevention. After an introduced intervention we investigated in the second half of 2008 all CVCs for colonisation and the location of introduction. The interventions were didactic sessions with the question: ''How can we reduce the catheterrelated bloodstream infection rate''. The educational sessions comprised of hygiene instructions, assistance of the physician, daily care of the CVC, signalling of infection. The proportion of CVCs inserted into the femoral vein decreased from 58% before the intervention to 40% after the intervention in the ICU. The catheter-related bloodstream infections rate before the intervention was 2.3 cases per 1,000 CVC-days and after the interventions 2.0 cases per 1,000 CVC-days on the ICU. The femoral route was the preferred puncture site for emergency department (45% in 2007 and 100% in 2008) and the jugular site was the preferred puncture site for the operating theatre (60% in 2007 and 90% in 2008). (CVCs), particularly in patients with severe coagulation disorders or at high risk for infection, since their insertion is easy and safe, and their use is associated with a very low incidence of catheter related blood stream infections. Though, PICCs are still considered to be relatively contraindicated in ICU, for several reasons: (a) the flow through a PICC is limited, due to the high resistance of the device (proportional to the length of the catheter and to its calibre), (b) ICU patients typically need multiple lumen central venous lines, (c) peripheral veins for PICC insertion may not be available in the ICU patient, (d) there are concerns about the possible occurrence of PICC-related venous thrombosis, and (e) measurement of central venous pressure is not considered reliable through PICCs. We report the preliminary results of our clinical experience with 2-lumen and 3-lumen power injectable PICCs in ICU. METHODS. 16 power injectable, open ended PICCs (7 Power PICC Ó Bard and 9 Pro-PICC Ó Medcomp, all made of highly resistant polyurethane, apt to tolerate very high pressures, [200 psi) were inserted in 15 patients in ICU. Ten PICCs were double lumen (5 Fr) and six were triple lumen (6 Fr). All PICCs were inserted by trained ICU nurses. US guided puncture of the basilica or brachial veins at midarm was performed in all cases: veins whose diameter was [4 mm were considered suitable for 5 Fr catheters, and veins [5 mm for 6 Fr. The tip of the catheter was positioned in the upper third of the right atrium by using the EKG method. All 16 PICCs were successfully inserted. No insertion-related complication was detected. Most catheters stayed in place for more than 2 weeks: in six cases, the patient was transferred to another ward while the PICC was still in place. While in ICU, no PICC was removed because of complications. Complications were: one accidental dislocation + one thrombosis of the axillary vein, both occurring after the patient had been transferred to a nonintensive ward. There was no catheter-related blood stream infection. Most PICCs were easily used for high flow i.v. infusions ([1,000 ml/h, by infusional pump), as well as for measurement of the central venous pressure. INTRODUCTION. Patients who do not recover despite intensive treatment or whose likelihood of survival with a good quality of life is very poor, recommendations about end-of-life care in ICU advise starting a deliberation process in order to decide whether or not to carry out Life-Sustaining-Treatment Limitation (LSTL). This procedure has been developed in our ICU with a new protocol that includes a standard order form. To analyze the LSTL procedure, which treatment was withheld or withdrawn, the differences between patients with LTSL and the remaining cases, and the clinical course of patients with LTSL. METHODS. prospective observational study including all consecutive patients who were referred to our medical-surgical ICU in 2008. Data are expressed as median ± SD, compared with a percent confidence interval of 95%. RESULTS. During the study period 679 patients were admitted to ICU, with a mortality rate of 11.48%. The decision to carry out LSTL was made in 65 patients (9.57% of patients admitted to ICU); the decision was documented by the specific form in 63 cases (97%) and the others with annotations on the medical record. During the study period 78 patients died, seven were brain stem dead and became organ donors; from the 71 remaining patients who died, LSTL was applied in 51 cases (73.91%). Ten LTSV patients were discharged from ICU: three of them died on the ward and seven were discharged alive from the Hospital. Compared to survivors, patients with LTSL were older (mean age 72 ± 13.38 vs. 62 ± 18.15 years, p \ 0.001) and had higher severity scores: APACHE II (21 ± 7.44 vs. 13 ± 8.39, p \ 0.001) and SAPSS II (51 ± 16.70 vs. 31 ± 17.85, p \ 0.001). Patients who died despite full treatment were younger than LTSV-patients (mean age 65 ± 18.02 vs. 72 ± 13.38 years, p \ 0.05) and more severe: APACHE II 29 ± 8.13 vs. 21 ± 7.44 (p \ 0.05) and SAPSS II 63 ± 16.72 vs. 51 ± 16.70 (p \ 0.05). There were not gender differences in cases of LTSV or with full treatment. Median length of stay in UCI before LTSV implementation was 6 days. LTSV was proposed by physicians in 37 cases, by patients' relatives in six cases and by doctors and families at the same time in the 21 remaining cases. All LTSV patients would not receive cardiopulmonary resuscitation. Decision to maintain but not to increase treatment was made in 25 cases. Treatment was withheld in 35 cases, most of all not to start dialysis (21 cases). In 37 patients treatments were withdrawn: mechanical ventilation in 24 cases (15 weaning and 9 terminal extubation), dialysis (21), vasoactive drugs (21), and nutrition (8). CONCLUSION. In patients admitted to ICU, withholding or withdrawing life-sustainingtreatments precedes the process of dying in most cases, after a period of intensive therapy. Patients with LTSL are older and have higher severity scores than the others. Dialysis, mechanical ventilation and vasoactive drugs are the therapies which are withheld or withdrawn the most. 22nd OBJECTIVE. Preferences of patients to discuss life sustaining treatment treated at an internal department of medicine in Austria. METHODS. 164 patients were interviewed at the end of their stay at the department of internal medicine. 44 of them had discussed life sustaining treatments with relatives or friends before hospital stay. RESULTS. 47% of patients B50 a, 59% of patients between 51 a and 70 a, and 43% of patients older than 70 a wanted to discuss and decide life sustaining treatment, when asked at the end of their hospital stay. 80% (\50 a), 89% (51-70 a) and 58% (C71 a) with a positive decision wanted life sustaining treatments like CPR, admission to the ICU and artificial ventilation. None of the patients under 50 years, 8% of the patients between 51 and 70 a, and 2% B71a were bothered by the discussion. 44, 46 and 22% answered to be bothered if the discussion would have taken place at the time of admission to the hospital. 82% of the patients B70 years and 64% of the patients C71 a wanted to discuss life sustaining treatment in future hospital admissions. CONCLUSION. More than 80% of patients wanted to discuss life sustaining treatment during there hospital stay, but many of them would prefer to discuss it not at the time of admission. More than half of them did not want to decide life sustaining treatments themselves, those of them who wanted to decide, mostly decided pro life sustaining treatment. RESULTS. During the study period, 14,720 patients were admitted to our SICU (61.8 male, mean age 62 years). The incidence of end-of-life decisions was 2.7% (n = 398); 1.1% decisions to withhold/withdraw life support and 1.6% (n = 230) only do-not-resuscitate (DNR) orders. Patients with end-of-life decisions had higher severity scores on the day of ICU admission, were mostly unplanned admissions, were older, and were more commonly referred from the emergency room or other hospitals compared to those who did not have end-of-life decisions. The incidence of end-of-life decisions increased significantly with the severity of sepsis. ICU and hospital mortality rates were 6.1 and 10.3%, respectively. An end-of-life decision was taken in 29% of the patients who died in the ICU. The ICU and hospital mortality rates in patients with an end-of-life decision were 65.1 and 82.2%, respectively. In multivariate analysis, older age, admission from another hospital, cirrhosis, sepsis syndromes, SAPS II and SOFA scores were independently associated with end-of-life decisions. CONCLUSIONS. Twenty-nine percent of patients who die on the surgical ICU have an endof-life decision. Severe sepsis/septic shock was associated with a 16-fold increased likelihood of having an end-of-life decision. AIM. To withhold or withdraw life sustaining treatment are common decisions in the intensive care unit (ICU). The objective of this study is to assess the incidence of withdrawal of treatment and the reasons for withdrawal of life sustaining therapy. A retrospective observational, single centre study in a general ICU of a university hospital. All patients admitted to the ICU between November 1, 2006, and October 31, 2007 were included. Age, sex, length of stay, APACHE II score and diagnosis, and SOFAscore were collected for all subjects. Additional data on reasons to withdraw treatment were collected for patients who died in the ICU. Data were extracted from our patient data management system, electronic patient dossier, and handwritten medical charts.  To explore the quality of the dying and death experience within a critical care service with the perception of relatives providing a surrogate assessment for the patient. To evaluate interventions instigated to facilitate the bereavement process for family members and to assess the standard of information giving and communication that operate within the service. A retrospective study, which surveyed relatives of patients who had died within a critical care service during a two-year period (2005 and 2006) . A 31-item questionnaire was utilized to obtain both qualitative and quantitative data. The items were rated on a scale of 1-5, with higher scores indicating a better experience within the area. During the study period a total of 287 patients died in the critical care area. Of this number, 232 patients were included in the study. A total of 137 completed questionnaires were returned giving a response rate of 59%. Of the respondents, 78% reported that they received good information; 65% believed they were involved in decision-making and 75% responded that they had received adequate spiritual care. For these items relatives were additionally asked to reply on behalf of the patient. Responses were overall positive; however 46% of participants felt they could not respond to these items on behalf of the patient. With regard to pain and symptom management 64% of respondents indicated that they believed the patient was comfortable and 84% reported that staff made all efforts to ensure that their loved one was pain free. Interventions to facilitate the bereavement process for relatives include the issuing of a condolence card to relatives and an annual Ecumenical Service. Although only 45% of respondents attended the service, qualitative data was overwhelmingly positive and relatives reported that this was a key factor in facilitating their bereavement process. Over 80% of relatives expressed the view that communication was adequate and expressed in an appropriate manner. An analysis was conducted using Spearman's Rank Correlation Coefficient to establish what items from the questionnaire are predictive of satisfaction on the part of the relative and the patient. Adequate information and staff support for the relative was strongly predictive of satisfaction as was pain and symptom management. An additional factor that correlated well with satisfaction was being allowed spend time after death with the patient. Aspects that did not appear to have important associations with satisfaction include adequate information and involvement in decision making. Good communication, staff support, pain and symptom management were found to be indicative of a quality service. We further found that interventions already in place facilitated the bereavement process for relatives. Findings from this study will serve to optimize our service. Further research involving the perceptions of clinical staff using a similar tool could be valuable. ) , there has been a 10% decrease in the number of lung or heart/lung transplants being undertaken. This is on a background of an 8% increase in the number of patients on the list for a lung or heart/lung transplant. 20% of those on the list died, or were removed from the list while waiting for their transplant and 57% were still waiting. Strict criteria exist for the selection of lungs suitable for transplantation. Studies have shown that targeted management of 'marginal donors' can improve oxygenation to meet transplantation standards in 18%. OBJECTIVES. We examined whether the removal of PEEP and application of FiO 2 of 1.0 during apnoea testing decreased the PaO 2 /FiO 2 ratios and increased the likelihood of patients failing to meet the oxygenation criteria. METHODS. Medical notes of organ donors from the last 5 years of a mixed medical-surgical ICU were reviewed. Data from arterial blood gases and basic ventilatory settings were collected at time of admission, at different points of the brain stem testing period, and at the time of assessment for transplantation. Results from the first 13 cases are presented here. The mean age of organ donors was 36 years. The cause of death was head injury in 31%, intracranial haemorrhage in 46% and hypoxic brain injury in 23%. The average length of ventilation was 53 h. From these 13 patients, 5 had lungs retrieved for transplantation. Prior to brain stem testing, 9/13 (69%) of patients fulfilled the criteria of PaO 2 /FiO 2 ratio grater than 40. After brain stem testing, at assessment for suitability for transplantation, 3 of those patients (23%) suffered a decrease of PaO 2 /FiO 2 ratio to below 40. In total, 7 (64%) patients had a decrease of PaO 2 /FiO 2 ratio following brain-stem death testing. The preliminary data suggest that some patients may sustain a decrease in PaO 2 /FiO 2 ratio following apnoea testing to establish brain stem death. This reduction may breach predefined thresholds and label them as unsuitable for lung donation. Studies in anaesthetic populations have established that use of high inspired oxygen concentrations predisposes to atelectasis and increased shunt fraction. Prolonged ventilation with an FiO 2 of 1.0 followed by apnoeic oxygenation may produce similar effects in potential transplant donors. Maintenance of PEEP during, and recruitment manoeuvres after brain stem testing may help to negate possible detrimental effects of current apnoea testing practice REFERENCES. BACKGROUND. We review the waiting time of the children listed for heart transplant, the mortality and complications. We focus our study in the different ages and status of the patients waiting an organ. METHODS AND RESULTS. During the last three years 87 children has been inclosed in the list of heart transplant in Spain. The median age was 10.8 years, and the median weight was 22.8 kg and 24%) were female. The primary cardiac diagnosis that led to heart transplant listing was congenital heart disease in 49%, cardiomyopathy in 27%, and myocarditis in 22%. Overall, 63% were listed as status 1A, 25% as status 1B, and 12% as status 2. The ONT published a complete annual report about the number of pediatric heart transplant and the number of children in the waiting list. Almost 50% of the children gets out of the list in 5 month. The difference about age, weight and clinical status are very important with a significant increase of waiting time and mortality in the group of patients from 1 to 3 years, less than 10 kg and status 1A patients which rise to 65% mortality. Patients from 10 to 16 years in status 1 are less than 30 days in the waiting list with an acceptable mortality of 9.8%. The status 1A patients under ventricular assist device has the poorest outcome with 30% mortality in the waiting list and nearly to 80% after 90 days in waiting list. In spite the improvements of getting appropriate organs for children, the waiting list and mortality for heart transplant remains still high. The distribution inside the list not only by clinical status but also weight and age is necessary looking better outcomes. METHODS. Therefore we conducted a retrospective analysis of clinical charts (MRR) of all patients who died between 2003 and 2006 in the five different ICU's of our institution. We recorded: the number of potential donors, overt brain death, and also family consents, effective organ donation. Then, we collected 736 anonymous questionnaires (HAS) which had been proposed to all ICU staffs, in 2004. These data were analyzed using the Donor Action database. RESULTS. The answering rate was 66% (doctors: 59%, paramedics: 67%). Professionals were much in favour of organ donation for themselves and their relatives, despite of a heterogeneous knowledge of organ donation. All highlighted a need for further training to diagnose and handle donors and relatives. (58) CONCLUSIONS. Donor Action programme made the staff aware of potential donors and brain death patients, with an earlier and more exhaustive detection. However, more efforts should be made to meet and handle families in order to reduce families' refusals. Donor Action programme is a highly efficient system to evaluate the donation process and assess staff behaviour. The sustained effect of this audit, as observed in our centre, through a 4-year follow-up showed a long lasting impact on donation rates, like in most of French centres which implemented this program. INTRODUCTION. The leading causes of brain death are traumatic brain injury (TBI), (aneurysm) subarachnoid haemorrhage (SAH) and intracerebral haemorrhage (ICH), which compromise approximately 80-90% of the cases [1] [2] [3] . There is a steady decline in the actual number of brain death patients over the past decades as a result of progress in prevention and treatment of these conditions. There is no uniform definition of a potential organ donor that can be used to determine the potential of heart-beating organ donors. Therefore we defined a potential brain death organ donor as a patient with documented severe brain damage of a known origin, a GCS-score of 3 and more than 2 absent brain stem reflexes which includes: pupil, cornea, oculovestibular, oculocephalic and the cough reflex. We applied this definition in a retrospective analysis over the last three years of our ICU. To estimate the potential of heart-beating donors and determine reasons for non-procurement. Retrospective review of medical charts over 2006-2008, concerning patients with TBI, SAH, and ICH who died during the course of ICU treatment. A 32-bed tertiary general intensive care unit with neurosurgical services. . 555 patients with a diagnosis of TBI, SAH, or ICH were admitted of which 186 died. Of these patients 107 (57%) patients could be determined as potential heart-beating donor. Twenty one (19.6%) patients became a heart-beating donor. Five patients (4.6%) were converted to controlled donation after cardiac death. In 81 of the potential heart-beating organ donors, procurement could not be completed because of; family refusal before complete brain death determination (58%), malignancy (11%), or patient refusal in Donor Register (8.6%) being the most important reasons. There is an unused potential heart-beating donors in which procurement could not be completed. Family-refusal is the most important reason for failure to procure organs. In respect to a study performed in 2006 in our hospital, an incline is observed of 26% [4] . With a strict definition of a potential organ donor (GCS-3, with 2 or more absent brain stem reflexes) more than 50% of the patients who died of SAH, ICH or TBI were eligible for organ donation. RESULTS. During a 24 months period, we have screened 15 patients. We performed 7 NHBD (mean age 31 ± 17 years; range 3-59 years). The diagnosis related to these procedures were severe neurologic damages after trauma (n = 3), anoxia (n = 3) or intra-cerebral hemorrhage (n = 1). The reasons for refusal from the transplant center were age (n = 3), medical history (n = 4) and sepsis (n = 1). Overall, 18 organs were offered and transplanted (kidney n = 14, liver n = 4). Moreover, tissues (heart valves, bones and hepatic cells) were also sent to the tissue bank. DISCUSSION. For more than 15 years, our unit has developed an expertise on organ donation. With the evolving modifications in end of life considerations in ICU's, the implantation of a NHBD program appears to be a continuation of the local procurement coordination work. During the same period, the team took care of 322 potentials donors, and more specifically of 15 NHBD. This program was implanted progressively in the unit after consultation of the medical and nursing teams and of course the accordance of the Ethic Committee. A specific psychological support was not included in the program. However, upon request of the staff, psychologist was available. This program represents a hard work for the nursing team and was only possible with the presence of a local coordination (nurse) already in place in our institution since 1994. This point is probably the most important one in the successful introduction of such a program. It is important to point out that contacts with families were especially peaceful. For some patients, the potential of organ donation was indeed suggested by the close relationship when they had to face a hopeless prognosis. Moreover, the local coordinator remains in relationship with the family in the weeks following donation CONCLUSIONS. NHBD program can be implanted successfully in a non transplant center, but the presence of local procurement coordination is probably mandatory. This program allowed an important increase of organ referred for transplantation. However, the burden of work and the psychological impact for the ICU team need to be carefully supported. In our experience, most of the time, the procedure was particularly well accepted by the donor's family and seems to bring some kind of moral support in the mourning process. Importantly, ethical as well as legal reflections are mandatory to explore the future of the NHBD. Indeed, juridical litigation and public disinformation could create a counter-productive opinion on organ donation in general. The specific role of the intensivist should also be carefully asses especially for the procedure surrounding withdrawal from mechanical ventilation. INTRODUCTION. Surgery offers cure for many patients suffering from cardiac diseases, such as vessel diseases or valve dysfunctions. The success of intensive care management has improved and more complex diseases can be adequately treated. Co-morbidity and age of patients undergoing cardiac surgery have increased during the last years, often leading to a prolonged stay at the intensive care unit (ICU). Usually, the outcome following surgery is assessed with mortality or morbidity rates. Nevertheless, quality of life plays an important role in recovery after cardiac surgery. The aim of this study was to compare the quality of life in patients with an uncomplicated (\2 days) and prolonged ([14 days) postoperative ICU stay one-year after cardiac surgery at the Hietzing Hospital in Vienna, Austria. A standardized state of health questionnaire, the Short Form Health Survey (SF36), was used to evaluate the patient's subjective impression of their health state. We compared patients after a prolonged ICU stay ([14 days) with patients having experienced an uneventful postoperative course, and performed the SF36 questionnaire 3, 6, and 12 months after surgery. Reasons for cardiac surgery were aorto-coronary bypass surgery, valve replacement, combinations of both or complex surgical interventions. Furthermore, the duration and number of medication were investigated. Patients with a short postoperative ICU stay had, in general, a good state of health and answered most of the questions with scores higher than the median. This response was consistent over the 3 consecutive surveys. In contrast, patients with a prolonged ICU stay had significant more limitations in daily short-term (p = 0.03, Mann-Whitney test), and longterm (p = 0.03) activities (according to SF36 questionnaire). They also had a significant worse subjective state of health (p = 0.01 compared with the control group). These limitations did not improve during the investigated period. No significant differences were observed in questions asking for pain, social contacts, and psychic problems, as well as the subjective estimation of the personal health state. Patients with a prolonged ICU stay still needed more medication one year after surgery. CONCLUSION. This preliminary analysis demonstrates that patients with a shorter postoperative stay at the ICU seem to have a better postoperative subjective state of health (as assessed with the standardized SF36 questionnaire) than those with a prolonged stay. The effect was even evident one year after cardiac surgery. INTRODUCTION. Extended-daily-diafiltration (EDD-f), also known as sustained-lowefficiency-dialysis (SLED), is an emerging form of renal replacement therapy (RRT) being increasingly used world-wide for critically ill patients with acute kidney injury (AKI). However, drug dosing remains a challenge to critical care physicians with little pharmacokinetic studies undertaken to date with this specific dialysis modality OBJECTIVE. To describe the variability of gentamicin plasma concentrations in critically ill patients with AKI necessitating EDD-f using a population pharmacokinetic model and to subsequently perform dosing Monte Carlo simulations to determine which dose regimen achieves pharmacodynamic targets most consistently. METHODS. This was a prospective pharmacokinetic study. Twenty-eight treatments in 14 critically ill adult patients with AKI requiring EDD-f and therapeutic gentamicin. Gentamicin dosing was undertaken at the discretion of the treating critical care physician. Serial plasma samples were collected. A population pharmacokinetic model was used to describe the pharmacokinetics of gentamicin and perform Monte-Carlo dosing simulations of 3, 5 and 7 mg/kg at various time points before commencement of EDD-f to evaluate the optimal dosing regimen for achieving pharmacodynamic targets. RESULTS. This is the first known paper to describe gentamicin pharmacokinetics during EDD-f in patients with AKI. A two-compartment pharmacokinetic model described gentamicin clearance on and off EDD-f adequately. The plasma half-life of gentamicin during EDD-f was 9.9 h compared with 24.3 h without EDD-f. Monte-Carlo simulations suggest that that a 7 mg/kg initial dose either 30 min or 1 h before the commencement of EDD-f results in ca. 65% attainment of target AUC 0-24 (70-120 mg h/L) and ca. 98% of Cmax (\10 mg/L). None of the dosing regimens achieved satisfactory Cmin targets (\0.5 mg/L) at 24 h. CONCLUSIONS. Dosing gentamicin 30-min to one-hour before EDD-f enables attainment of target peak concentrations for maximal therapeutic effect, whilst enhancing drug clearance to minimize toxicity. Re-dosing in many patients should occur using lower doses (5 mg/kg) for a course of B 4 doses (where possible) with re-dosing also guided by therapeutic drug monitoring of 'trough' gentamicin concentrations. GRANT ACKNOWLEDGEMENT. We would like thank Fresenius medical for funding the cost of the blood assays. JR is funded by an Australian National Health CONCLUSION. Despite a standardised vancomycin administration protocol consisting of a loading dose followed by a continuous infusion, a quarter of the ICU patients did not reach therapeutic serum levels in the initial treatment phase. After correction for covariates, greater body weight and younger age were associated with inadequate therapy. INTRODUCTION. Piperacillin-tazobactam (pip-tazo) is a broad spectrum antibiotic, used for treatment of ventilator-associated pneumonia (VAP) and other serious infections. The effectiveness of such betalactam antibiotics is best predicted by the duration of free drug concentrations above the minimal inhibitory concentration (t [ MIC) of infecting pathogens [1] . Continuous infusion (CI) of pip-tazo is an alternative mode of administration which may improve t [ MIC but there is little data on drug levels in plasma and corresponding levels at infections sites in critically ill patients. OBJECTIVES. The aim of our study was to determine concentrations of pip-tazo in plasma and broncho-alveolar epithelial lining fluid (ELF) at steady state during CI, which may serve as surrogate parameters for therapeutic efficacy. After approval by the Ethics Committee, 16 mechanically ventilated critically ill patients were enrolled during treatment in 3 anaesthesiological and surgical ICUs. After a loading dose of 4 g/0.5 g of pip-tazo, 12 g/1.5 g were continuously infused every 24 h. At steady state (67.8 ± 39.5 h after loading dose), a total of 30 blood samples were drawn and bronchoalveolar lavage (BAL) was simultaneously performed in 8 cases (1 sample discarded for technical reasons). Samples were stored at -80°C until analysis by liquid chromatography coupled with mass-spectrometry (LC-MS). ELF-concentrations were calculated from BALsamples using the relation of urea plasma :urea BAL as dilution factor. RESULTS. Plasma concentrations of pip and tazo (n = 30 in 16 pts) amounted to 15.38 ± 8.89 lg/ml, and 1.31 ± 0.95 lg/ml, respectively. ELF-levels (n = 7) were 56.63 ± 27.24 lg/ml, and 5.95 ± 3.74 lg/ml. ELF-levels were 368 + 236%, and 587 + 584% of corresponding plasma levels (n = 7) for pip and tazo, respectively. The ratio pip:tazo was similar in plasma (11.74:1) and in ELF (9.52:1). CONCLUSIONS. CI yielded steady state pip plasma concentrations in excess of MICs of susceptible bacteria (B8 lg/ml, according to EUCAST) in 76.6% of measurements, but ELF levels exceeded 8 lg/ml in all cases. These concentrations were higher than previously reported, which may be explained by the high severity of illness of our patients, as well as differences in sampling and analytical methods [2] . Our data provide further arguments for CI being the preferred mode of administration for pip-tazo in critically ill patients with suspected VAP. (2005) BACKGROUND. Altered pharmacokinetics (PK) in critically ill patients can result in insufficient amikacin (AMK) concentrations when standard doses are given. Distribution, metabolism, and clearance of many antimicrobials are altered by physiological changes associated with obesity. Some recommendations on dose adjustment for AMK have been proposed for patients with BMI \20 or [30, but no studies have evaluated the influence of patient body weight or body mass index (BMI) on the optimalization of AMK administration, especially in critically ill patients. The aim of this study was to evaluate the impact of body weight on serum AMK concentrations in patients with severe sepsis and septic shock. A loading dose of 25 mg/kg of amikacin (AMK), calculated on actual body weight (ABW), were given to 74 patients with severe sepsis and septic shock in combination of a broad-spectrum b-lactam. Serum concentrations were determined either by fluorescence polarization immunoassay method before and 1, 1.5, 4.5, 8 and 24 h after the injection. PK parameters were estimated by WinNonlin. The PK parameters of this population were used to generate a simulation of AMK peak concentrations for a 25 mg/kg dose calculated on the ideal body weight (IBW). We also calculated the AMK peak for patients with BMI \ 20 and [ 30, using published formulas (corrected body weight, CBW = 1.3 9 ABW for BMI \20 and CBW = ABW + 0.4 (ABW-IBW) for BMI [30). Finally, we compared AMK peaks obtained by a loading dose calculated on ABW (pABW) and IBW (pIBW). Optimal drug concentration was considered if peak AMK concentration at least [64 mg/mL [1] , corresponding to 8 times the clinical breakpoint for Enterobacteriacae and Pseudomonas aeruginosa (MIC = 8 mg/mL), determined by EUCAST. Optimal AMK peak was obtained in 52 patients (70%). Adequate AMK peak were achieved in 6/11 (54%) of patients with BMI \20, 23/36 (64%) with BMI 20-25, 15/18 (83%) with BMI 25-30 and 8/9 (89%) with BMI [30. Simulation with doses calculated on IBW showed that only 37 (50%) would have reached a peak [64 mg/mL (p \ 0.01). Using CBW, patients with BMI \20 had 7/11 (63%) optimal AMK peaks, whereas patients with BMI [30 6/9 (66%). Differences between pABW and pIBW were in a range of +10/-10% for BMI between 20.5 and 25.2, 15% for BMI between 19.4 and 26.5 and 20% for 18.4-28.0. Optimal AMK peak could be influenced by BMI if doses are calculated on ABW. Doses higher than 25 mg/kg should probably be proposed in patients with BMI \25 to optimize amikacin PKs. Using CBW will not significantly improve adequate AMK regimen. If AMK regimen is calculated on IBW, a correction factor could already be considered for BMI [25, to reduce the risk of lower target concentrations when compared to dosage given on ABW. INTRODUCTION. Surgical site infections remain a feared complication after cardiac surgery that results in significant morbidity and mortality, prolonged hospital stay and high healthcare costs [1] . Cephalosporins are the standard prophylactic antibiotics for cardiac surgery [2] . Administering an adequate dose of prophylactic antibiotics at the appropriate time has a paramount significance. Therefore, we compared two different regimens of antibiotic prophylaxis with cefuroxime in two groups of patients undergoing elective cardiac surgery. A total of twelve patients were investigated. Group A (n = 6) received 2 9 1.5 g cefuroxime as an i.v. bolus infusion before surgery and after 12 h. In group B (n = 6), after the initial i.v. bolus infusion of 1.5 g cefuroxime, continuous infusion of 1.5 g cefuroxime was started. Samples for analysis of cefuroxime plasma concentrations were collected during following 24 h. Student's t test was used for statistical analysis. Data are presented as means ± SD. RESULTS. The plasma drug decay curves after cefuroxime bolus administration for group A and for group B are shown in Fig. 1 . In group A immediately after the bolus infusion, plasma cefuroxime concentrations rose rapidly within 10-20 min and achieved peak concentrations of 78 ± 15 mg/L (first peak) and 83 ± 9 mg/L (second peak) and thereafter decreased rapidly to 2.4 ± 1.9 mg/L (first trough) and 2.8 ± 2.7 mg/L (second trough) within 8 h. In group B a peak of 82 ± 18 mg/L was reached within 20 min after the bolus infusion. Thereafter, plasma concentrations decreased to 11.6 ± 7.8 at 24 h after the bolus infusion. Total wash-out was observed 8 h after bolus infusion. In contrast, during continuous cefuroxime infusion therapeutic levels of the antibiotic were achieved throughout. (2007) The not-so-hidden costs of surgical site infections. Aorn J 86 (2) INTRODUCTION. Aminoglycosides (AG) are concentration-dependent antibacterials and exhibit prolonged post-antibiotic effect. Once-daily regimens have been proposed to treat patients (pts) with severe sepsis and septic shock (SS). Their increased volume of distribution may induce a decrease of peak serum concentrations, delayed therapeutic responses or treatment failure. Therefore, an initial high weight-based dose, independent of creatinine clearance (Cl(Cr)), is necessary to achieve optimal killing rate; the subsequent doses being based on trough level (TL) and Cl(cr). Therapeutic AG monitoring may then be warranted to minimize nephrotoxicity particularly in seriously ill pts with renal impairment, even in case of 3-4 days therapy. Tobramycin (T) [2 lg/ml, Amikacin (AMK) [8 lg/ml according to renal impairment] and to define guidelines for TL24 assessment for intensive care unit (ICU) practice. with SS were prospectively enrolled during a 5-month period; 24 had nosocomial sepsis, 2 needed renal replacement therapy at the time of AG treatment. All of them received combined empirical antimicrobial therapy. The CL(cr), estimated by the Cockcroft-Gault equation, at time of initial administration was 43.9 (26.9-78.1) ml/min; severe renal impairment [(Cl(cr) \ 60 ml/min] was present in 68% of cases. Patients were divided into five groups according to their CL(cr): [90; 60-90; 30-60; 30-15; \15 ml/min. The SAPS II was 70, (47.5-79), the ICU length of stay: 21 days (8.5-31) and hospital mortality rate 44%. RESULTS. Serum samples were systematically collected 24 h after AG injection. Initial and subsequent doses were at physician discretion. AMK, G, T were used as empirical therapy in respectively 13, 12 and 16 pts and for a limited time period (3.6 days/pt), and modified after culture availability.  Nephrotoxicity is a known side effect of vancomycin, the most widely used antimicrobial for treatment of resistant Staphylococci, most often MRSA. Raise of BUN or creatinine, according to literature, occurs in 5-17% of treated patients. Acute renal failure (ARF) occurs less frequently (\5%), but is a serious side-effect, often requiring change of treatment, dialysis (in about half of patients) and prolongation of hospitalisation. Also, since acute renal failure occurring in sepsis is associated with worse prognosis, vancomycin neptrotoxicity can also influence survival. Patients admitted to intensive care units (ICUs) are usually at increased risk of renal failure because of critical illness (i.e. sepsis, severe trauma, severe pancreatitis, major surgery, burns, etc.); they also often already have impaired renal function at ICU admission. Such patients probably suffer additional risk of vancomycin neptrotoxicity. We have conducted an observational 2-year study in a medical ICU, trying to determine incidence of vancomycin induced acute renal failure (VI-ARF) in ICU population and to identify risk factors associated with occurrence of VI-ARF. All adult patients treated with vancomycin were eligible for inclusion. Excluded were patients with ARF before vancomycin treatment, patients with chronic renal failure and creatinine clearance \20 ml/min and patients on hemodyalisis. Deterioration of renal function (renal toxicity) was defined as raise in creatinine more than 10% of basal level; ARF was defined as twofold raise in serum creatinine. Age, sex, primary admission diagnosis, diabetes, APACHE II score, organ deficiencies other than ARF and use of concomitant nephrotoxic antimicrobials were evaluated as potential risk factors for VI-ARF. A total of 625 patients were treated with vancomycin in the study period, from which 578 were included. Deterioration of renal function occurred in 249 (43%) patients. Acute renal failure occurred in 108 (18.6%) patients, from which 67 (62%) were treated with dialysis. Identified high risk factors (odds ration greater than 2.0) for occurrence of VI-ARF were: sepsis with organ failure (other than renal), hypotension requiring vaspressors, diabetes mellitus with microalbuminuria, chronic renal failure (creatinine clearance \60 ml/min/m 2 ), concomitant nephrotoxic treatment. CONCLUSIONS. The incidence of vancomycin induced ARF is much higher in ICU than in general patient population reported in the studies. When treated patients with suspected or proven resistant staphylococcal infections and one of identified high risk factors for VI-ARF, other anti-staphylococcal drugs (such as linezolid) should be considered. The prevalent antibiotic practice and antimicrobial resistance patterns in India differ from western countries. But, empiric antibiotics for ICU infections in India are chosen based on western guidelines. We undertook a pilot study to explore microbial spectrum and resistance patterns and report our interim data. METHODS. Prospective, cohort, and multicenter study. All patients admitted to the participating ICUs between 2005 and 2008 were studied. Patients were followed until discharge from the ICU or up to a maximum of 30 days. The following infections were recorded: mechanical ventilation-associated pneumonia, catheter-related urinary tract infection, and primary bacteremia. MRM were those defined by the CDC (1). Data were collected using an Access 97-based program developed for the study. Resistance rates are expressed as percentage of resistant isolates to antimicrobials selected in relation to the total number of isolates for each pathogen. OBJECTIVE. To describe antibiotic use in the ICU (between clinically indicated, culture driven and prophylactic), to define the proportion of antibiotic start decisions associated with verified infection, and to identify clinical indicators associated with correct antibiotic start decisions. Consecutive antibiotic start decisions were divided prospectively into 3 categories: (1) clinically indicated [subdivided into catastrophic deteriorations (e.g. septic shock) and suspected infections (e.g. ventilator associated pneumonia without evidence of multiorgan failure)], (2) culture driven decisions, e.g. narrowing of antibiotic spectrum based on culture results and (3) procedure related prophylaxis. Based on a retrospective examination of clinical course and culture data, the presence of infection was determined 1 week after each clinically indicated antibiotic start decision by an independent infectious diseases specialist not involved in patient care. Physiological data to determine SIRS criteria and SOFA scores were collected daily. RESULTS. Data were collected on 45 antibiotic start decisions made during 202 days of patient care. These divided into 25/45 (56%) for clinical indications [9/45 (20%) for catastrophic deterioration and 16/45 (36%) for suspected infection], 9/45 (20%) for culture results and 11/45 (24%) for prophylaxis. Infection was verified for 9/25 (36%) of the clinically indicated antibiotic start decisions, including 5/9 (56%) catastrophic deteriorations and 4/16 (25%) suspected infections. Catastrophic deteriorations included peritonitis (3 cases/2 verified), mediastinitis (2/1), pneumonia (1/1), meningitis (1/1) and 2 others. Suspected infections included pneumonia (6 cases/2 verified), other respiratory tract infections (4/0), soft tissue infections (2/1) and 4 others. The SOFA score on antibiotic start days was higher than other days (8.2 ± 4.2 vs 6.5 ± 4.0, p = 0.043), principally due to the cardiovascular element (1.8 ± 1.9 vs 0.9 ± 1.6, p = 0.006). There were no significant differences in SOFA scores or SIRS criteria for antibiotic start days with vs without verified infection. CONCLUSION. Infection was verified following only a minority of clinically indicated antibiotic start decisions. Better defining the presence of infection prior to beginning antibiotic therapy represents the potential to decrease unnecessary antibiotic administration. Additional information beyond physiological data (such as biomarkers) may be necessary to improve decision-making. CONCLUSION. Antibiotic usage is very high in Indian ICU's. As compared to the international data available (NNIS,) our use of Carbapenem is 5.5 times, anti psuedomonal penicillin [3 times, fluroquinolones one-third, cephalosporins three-fourth and vancomycin one-eigth. Thus we tend to overuse broad spectrum antibiotics, and underuse narrow spectrum antibiotics. Our use of antibiotics covering gram negative bacteria is much higher and that against MRSA is much lower.  In the UK, nosocomial infections affect 1 in 10 patients admitted to hospital, resulting in 5,000 deaths annually 1 , and are an important cause of patient morbidity and mortality on ICU. Any personnel or equipment encountered by a patient during treatment is a potential vector for infection transmission. This audit was conducted on the 16 bedded mixed general/neuroscience ICU at Salford Royal NHS Foundation Trust, between May and July 2008. It aimed to assess the adequacy of the current method of cleaning pulse oximeter probes, and to determine if alternative methods could improve the effectiveness of the cleaning process. Pulse oximeter probes on the ICU were examined to assess cleanliness and the effectiveness of current cleaning practices. Microbiology samples were taken from all probes and the specimens cultured. Initial results demonstrated ineffective cleaning techniques. Augmented cleaning techniques (where a toothbrush was used), and an alternative cleansing agent (Chloroprep) were then tested, to see if the use of such techniques reduced the potential for the probes to act as vectors for infection transmission. Initial swabbing was carried out on all the pulse oximeters on the ICU. Mixed coagulase negative staphylococcus was isolated from [ 80% of all probes after standard cleaning techniques were used, staphylococcus aureus from 3 probes and MRSA from isolated in one probe. After cleaning using augmented cleaning techniques, only 12.5% of the probes cleaned showed no growth on culture: there was still significant growth of MCNS on most swabs. This is a similar incidence of growth to that found after cleaning using established techniques. When ChlorPrep was used to clean the pulse oximeter probes, samples taken from 66% of the oximeter probes resulted in no bacterial growth; significant growth still occurred in swabs taken from 33% of pulse oximeters. OBJECTIVES. We set out to address the problem of central line related blood stream infection (CRBSI). It is one of the most frequent, lethal and costly complications of central venous catheterization. Together with the microbiology department we used an agreed definition for CRSBI, following root cause analysis. We measured the rate of CRBSI in the Intensive Care Unit. We assessed the cause as multifactorial. Using PDSA methodology we introduced a series of changes. clc A series of small step changes were introduced. These involved application of the central line care bundle, introduction of catheter packs and the use of 2% chlorhexidine. We also introduced strict policies for visiting teams and hand washing. All medical and nursing staff were involved with nomination of ''champions'' for each group. To date there have been no CRBSI's for more than 560 days. There have been no MRSA bacteraemia for more than a year. Constant attention to detail, dissemination of information and embedding a culture of ownership all proved challenging. CONCLUSIONS. A target that initially seemed improbably achievable was in fact possible. This is a multifactorial problem that is not solved by a ''quick fix''. A combination of methodologies is the best way forward. Listening to all suggestions by any member of staff prove very useful and time saving. It is imperative to involve all members of the team and to disseminate information, changes and results in a prominent and timely fashion. There must be a universal sense of ownership and responsibility for the problem. Ultimately it is necessary to change culture both within the individual unit and the wider organisation. METHODS. Prospective observational study in a multidisciplinary 8-bed ICU. During a 20month period, 176 consecutive patients with a length of stay (LOS) C72 h were enrolled in the study. Data were collected using a specially designed software and included age, gender, APACHE II score on admission, days on mechanical ventilation, number of central venous catheters, LOS and ICU outcome. Patients were stratified into two groups: Group A included patients who did not develop CRBSI (n = 152) and Group B patients in whom CRBSI diagnosis was confirmed based on currently adopted criteria (n = 24). In Group B, isolated pathogens were also recorded. Data were analyzed using Student's t test, Mann-Whitney rank sum test and Chi-square. BACKGROUND. Selective decontamination of the digestive tract (SDD) is a prophylactic antibiotic strategy, which aims to prevent secondary endogenous infections amongst critically ill patients by elimination of 15 Potential Pathogenic Microorganisms located in the digestive tract. However, it is unknown whether recolonisation with resistant aerobic gram negative bacteria (AGNB) occurs after cessation of SDD in the decontaminated intestine, which increases the incidence of antibiotic resistance on the ward. In a 20 bed mixed medical-surgical ICU in a teaching hospital a prospective observational cohort study was performed to the incidence of recolonisation of the digestive tract with resistant microorganisms (MO) after cessation of SDD. We analysed recolonisation of the throat and rectum and compared the resistance patterns before and after SDD treatment. Consecutive patients were included when they had been treated with SDD on the ICU for at least 72 h, age was older than 18 years and after written informed consent had been given. The SDD consisted of oral application and enteral administration of non-absorbable antibiotics (polymyxin E (P) 100 mg, tobramycin(T) 80 mg and amphotericin B 500 mg), 4 times daily during the entire ICU stay in combination with parenteral cefotaxim(C) for the first 3-4 days. Baseline throat and rectal swabs were taken on admission to the ICU. Colonisation pattern during SDD application was monitored twice weekly and recolonisation after cessation was monitored on the general ward through combined throat and rectal swabs taken twice weekly until discharge from the hospital. All AGNB recovered from throat or rectum cultures were screened for resistance to cefotaxime, cefpodoxime, polymyxin, ciprofloxacin and tobramycin. An attempt was made to find a matching control group on the general ward but the discrepancy in severity of illness and length of hospital stay was too large. RESULTS. In 6 months 66 patients were included. Mean APACHE II score was 21. Median follow up after cessation of SDD was 4.5 weeks. Recolonisation with AGNB with a resistance pattern similar to the admission flora occurred in 38 out of the 66 patients (57.5%). Recolonisation with newly acquired AGNB resistant to either P, T, or C were found in 3 patients (4 samples) (4.5%). Two samples showed C resistant bacteria (Aeromonas and Citrobacter), one showed Serratia (intrinsic resistance for P), and one showed a P-resistant Enterobacter. In two patients Ciprofloxacin resistant AGNB were acquired during follow-up. No other resistant MO were found. CONCLUSION. In this study, the incidence of recolonisation in the ward after cessation of SDD during treatment in the ICU with AGNB resistant to Polymyxin, Tobramycin or Cefotaxim was low (4.5%).  Design-Before-after study. A medical ICU with 7 beds. CRBSI was defined as CRBSIs for which other sources were excluded, and where a culture of the catheter tip demonstrated an organism identical to those found in the bloodstream [1] . CVC colonization was defined as a colony count of 15 CFU/ml or more by the technique of roll-plate of the distal segment of the CVC. CRBRI and CVC colonization rates were studied at two different periods: the before intervention period, between March 2006 and March 2007, and the after intervention period, between July 2007 and July 2008. The following interventions were already in use as a routine practice in the ICU: appropriate hand hygiene, use of full-barrier precautions during CVC insertion, subclavian vein placement as the preferred site. According to the guidelines and the work by Pronovost et al [1, 2] the following interventions were implemented: (1) use of chlorhexidine for skin preparation, (2) use of sterile semipermeable dressings during CVC insertion (3) use of sterile semipermeable dressings during the all period of use of the CVC to protect hubs and connecters; (4) use of alcohol impregnated dressings in every manipulation of hubs and connecters; (5) removing unnecessary CVCs and (6) educational sessions for all ICU physicians and nurses. Data were obtained from a running database, only CVCs that were inserted in the ICU were considered. Collected data included age, gender, SAPS II, length of ICU stay (LOS), reason for ICU admission, local of CVC insertion, CVC days, type of microrganisms isolated in the CVC tip and in the blood culture. Appropriate descriptive statistics are presented. Comparisons between groups were performed using Chi-square test. In the before period a total of 253 patients were admitted (60% male; mean age 61 years; mean SAPS II 45, mean LOS 7.5 days) and a total of 201 CVCs were recorded. There were 12 CRBSI-7.8 CRBSI per 1,000 catheter days. Colonization rate was 38%. In the after period, a total of 264 patients were admitted (59% male; mean age 61 years; mean SAPS II 46, mean LOS 7 days) and a total of 138 CVCs were recorded. There were 3 CRBSI-3 CRBSI per 1,000 catheter days. CVC colonization rate was 18%. A significantly statistical reduction was found in CRBSI and in the CVC colonization rate between both periods (p \ 0.001). CONCLUSION. An evidence-based intervention was able to reduce CRBSI and CVC colonization rate. A prospective study will be needed to confirm these findings. METHODS. Central venous catheter-associated bacteremia (CAB) can cause complications and result in high treatment costs. Studies suggest that the use of coated catheters is associated with lower CAB rates when compared to conventional catheters. The aim of the study was to evaluate the impact of the use of minocycline-and rifampicin-coated catheters in lowering CAB rates in a medical/surgical ICU (Intensive Care Unit) in a private hospital. Table 1 and 2. Comparison between the two types of catheters. The DNA-comets showed significantly higher oxidative-stress related DNA damage in hemorrhage group in kidney cortex, kidney medulla and liver compared to sham-operated group. CONCLUSIONS. This model induced well-marked changes in inflammatory parameters. The inflammatory response was not satisfactorily homogenous-most probably due to varying severity of intervention (haemorrhage target reached at different rate, etc.). Homogenous and less severe insult together with widening of the panel of examined inflammation markers will be applied in further experiments. The model will then be used for intervention testing.  Studies of septic patients show that significantly more male patients suffer from severe sepsis or septic shock than female patients [1, 2] . On the contrary, gender differences of the perioperative immune response have not yet been investigated. OBJECTIVE. Aim of this study was to investigate monocyte response to an operation regarding gender differences. METHODS. This study is a prospective observative study, approved by the local ethic committee. Consecutively, 218 patients classified ASA 3 and ASA 4 were included in the preoperative assessment clinic after written consent: 135 men and 83 women. Ex-vivo secretion of TNF alpha and IL-10 in LPS-stimulated monocytes were measured preoperatively, postoperatively and on day 1 after surgery. Postoperative infections were diagnosed according to CDC criteria.  Leukocyte Antigen-DR (HLA-DR) expression on blood monocytes has been proposed as a potential marker of postoperative infective complications. However, studies to date have focused on high risk surgery, and there have been few reports on this biomarker in low risk surgery. Blood monocytes consist of heterogeneous cell populations of different phenotype and maturity, which can be divided into 2 or 3 subsets based on their CD14 and CD16 expression. Since monocyte HLA-DR expression increases with maturation, the decreased HLA-DR levels following surgery may be just a reflection of surgical stress-induced monocyte trafficking, i.e. mobilisation of immature monocytes from the bone marrow, and/or disappearance of mature monocytes from the central circulation due to margination to the microvasculature or extravasation. OBJECTIVE. We investigated early postoperative changes in monocyte HLA-DR expression in patients following low and intermediate risk surgery. We also evaluated the monocyte subset trafficking and correlated them with their HLA-DR expression. METHODS. We recruited 42 elective surgical patients from four categories of procedure: laparoscopic bariatric, open lower GI, hip arthroplasty and knee arthroplasty using tourniquet, to represent varying degrees of tissue trauma and bacterial exposure. Peripheral venous samples were collected immediately prior to, at termination of, and 24 h following surgery. Samples were analyzed by flow cytometry to quantify cell surface HLA-DR expression and cell numbers for both CD14 high and CD14 low /CD16 + monocytes. CONCLUSIONS. These results demonstrated that a substantial depression of monocyte HLA-DR expression occurs 24 h following low to intermediate risk surgery with minimal complications. Thus, the levels of HLA-DR expression on blood monocytes, when measured immediately following surgery, do not seem to be a clinically useful biomarker for postoperative complications. Our results also showed, for the first time, that surgery induces significant mobilization and margination/extravasation of individual monocyte subsets. However, the subsequent HLA-DR depression was consistent across all monocyte subsets and thus cannot be explained solely by differential monocyte trafficking. INTRODUCTION. Previously we demonstrated that dobutamine protects human T-cells from apoptosis [1] . Because this effect of dobutamine may have clinical implications, our current research focuses on the molecular mechanism responsible for this cytoprotection. We already showed that this cytoprotective effect was not receptor-mediated and independent of MAPK pathways. OBJECTIVES. Because dobutamine can protect cultured endothelial cells (HUVEC's) by acting as a ROS-scavenger [2] , the goal of the current study was to investigate if antioxidative properties of the dobutamine molecule are responsible for its cytoprotective effect on human lymphocytes. Jurkat T-cells passages 1-12 were used. To measure generation of reactive oxygen species (ROS), cells were loaded with the fluorescent dye CM-H 2 DCFDA (5 lM). Experiments with a caspase-activity assay showed that pre-treatment with dobutamine decreased staurosporin-induced (2 lM for 2 h) apoptosis in Jurkat cells. In contrast, isoproterenol and epinephrine had no protective effect. To test if dobutamine can act as a ROS-scavenger in these conditions, H 2 DCFDA-loaded Tcells were exposed to staurosporin, with or without dobuatmine pre-treatment: the ROSscavenging effect was very pronounced in the 0.1 mM group (decrease in fluorescence signal (arbitrary units) from 10,733 ± 887 to 5,345 ± 342 AU, p \ 0.01), and increased further in the 0.5 mM group (5,062 ± 274 AU). Next we investigated if the protection was mediated by this anti-oxidative action: The production of ROS due to staurosporin-treatment was measured: only after prolonged (6 h) staurosporin-treatment, the ROS-signal increased significantly. Next, the anti-oxidative action of isoproterenol was investigated: with 0.1 mM, the ROSfluorescence signal decreased from 10,826 ± 2,069 to 4,408 ± 582 AU, p \ 0.01), and decreased further in the 0.5 mM group (3,069 ± 657 AU). Epinephrine had a similar effect. Finally, the protective action of N-Acetyl-Cysteïne (NAC) was investigated with a caspaseactivity assay: although NAC did act as a ROS-scavenger, it did not reduce apoptosis in lymphocytes (caspase activity pre-and post-treatment (0.5 mM) was 38,427 ± 7,531 U and 39,182 ± 5,695 U). Because (1) BACKGROUND. There is increasing evidence that the ongoing systemic inflammatory response is associated with advanced abdominal cancer. Thought to be due to infiltration of leukocytes, cytokines, and chemokines in the tumor microenvironment, such responses could predict outcomes, and studies have revealed that an inflammation-based prognostic score could be useful. OBJECTIVE. This study aims to describe perioperative systemic levels of four cytokines, comparing patients with gastric and colorectal adenocarcinomas submitted to surgical treatment. We prospectively studied 59 patients, comparing 32 submitted to gastrectomy vs. 27 to colectomy. The two groups were comparable concerning preoperative status including comorbidities and neoadjuvant oncologic approach. All patients had peripheral blood harvest before, and also 3 and 6 days after surgical procedures. Using ELISA-sandwich technique, we measured circulating levels of a proinflammatory cytokine-macrophage migratin inhibitory factor (MIF), a chemokine-macrophage chemoatractant protein 1 (MCP-1), an anti-inflammatory cytokine-interleukin 10 (IL10), and a non-specific cytokine-interleukin 6 (IL6). Data were plotted and statistically treated by SPSS 11.0 for Windows, using non-parametric statistic. RESULTS. Circulating levels of the reactants (pg/dL) were lower among gastrectomized patients compared with colectomized ones. MCP-1 started from 206 ± 74 vs. 715 ± 389 (p = 0.027), going to 198 ± 40 vs. 877 ± 479 (p = 0.005) at the third day. IL10 started from 24 ± 5 vs. 91 ± 55 (p = 0.017) going to 29 ± 9 vs. 173 ± 127 (p = 0.024) at the third day and to 11 ± 5 vs. 72 ± 29 (p = 0.000) at the fifth day. IL6 started from 10 ± 4 vs. 71 ± 28 (p = 0.000) going to 51 ± 12 vs. 198 ± 106 (p = 0.006) at the third day. The exception was MIF, whose preoperatively levels were significantly higher in the gastric adenocarcinoma population (7,760 ± 1,197 vs. 2,761 ± 532, p = 0.012) and did not significantly differed postoperatively. CONCLUSION. Gastric and colorectal adenocarcinomas have different inflammatory perioperative behavior concerning MCP1, IL-6 and IL10, whose circulating levels are significantly higher among colorectal population. These findings were not reproduced regarding MIF, possibly suggesting the involvement of alternative control mechanisms. INTRODUCTION. The trace elements selenium (Se), copper (Cu) and zinc (Sn) are essential for the maintenance of the oxidative balance and crucial for the regulation of immunological, endothelial and cardiac function [1] . Cardiac surgery using cardiopulmonary bypass (CPB) is known to trigger a systemic inflammatory response syndrome (SIRS). We hypothesized that trace element-depletion is critically involved in this response. In 60 consecutive patients (Age 65.12 ± 13.92; EuroScore: 5.35 ± 3.26) undergoing cardiac surgery with the use of CPB, whole blood concentrations of Se-Cu-Sn were measured after induction of anesthesia and 1 h after admission to the ICU (eos) using atomic absorption spectrometry. At the first postoperative day, patients where separated into 3 a priori-defined subgroups (according to the ACCP/SCCM-consensus): no SIRS, SIRS, and severe SIRS (=SIRS + organ failure). Results were statistically analysed using one-way, Kruskal-Wallis ANOVA and receiver operating characteristics analysis. . 50 patients exhibited a significant deficiency of Se-Cu-Sn already at beginning of surgery. In all patients, blood levels of Se-Cu-Sn were significantly reduced after eos when compared to preoperative values. During the first postoperative day, 6 patients presented with severe SIRS, 38 with SIRS and 6 without SIRS-criteria. In patients developing severe SIRS postoperatively, the intraoperative decrease of Se-Cu-Sn was most pronounced. Intraoperative losses of Se-Cu-Sn were predictive for the development of severe SIRS at day 1 after surgery ( Fig. 1) . INTRODUCTION. Acute renal failure requiring renal replacement therapy (RRT) is known to develop in 1-5% of patients undergoing cardiac surgery and is a strong predictor of perioperative morbidity and mortality. This retrospective study compares incidence of renal failure requiring renal replacement therapy and subsequent in-hospital mortality in subsets of patient groups defined by operation and pre-operative serum creatinine over three consecutive 4 year periods at a UK tertiary cardiac centre, the Bristol Royal Infirmary. We define a group of patients with pre-operative creatinine of \200 lmol/l and subsequent requirement for (in-hospital) renal replacement therapy as 'unexpected' renal failure and analyse cardiac intensive care unit length of stay, age and sex distribution of this group. METHOD. Data on all cardiac surgical patients treated at the Bristol Royal Infirmary is routinely stored in PATS (Patients Analysis and Tracking System, Dendrite Clinical Systems Ltd, UK). Data was ripped to Microsoft Excel (Microsoft Corporation, US) for analysis. We studied 6 groups: first-time valve replacements, re-do valve replacements, first-time CABG on-pump, first-time CABG off-pump, re-do CABG on-pump and re-do CABG off-pump. For the purposes of this study, we refer to a requirement for in-hospital post-operative renal replacement therapy (CVVHDF) in patients with a pre-operative serum creatinine of \200 lmol/l as 'unexpected' acute renal failure. Groups were studied over 3 periods: 1996-1999, 2000-2003 and 2004-2007. OUTCOMES. New renal replacement therapy and in-hospital mortality. The unexpected renal failure group was analysed by age, sex and length of cardiac intensive care unit stay (LOS). Incidence of unexpected ARF requiring renal replacement therapy was lowest in first-time CABG off-pump (0.55-0.98%) and highest in re-do valves (1.64-7.58%). Mortality of unexpected ARF was extremely high (25-100%). Small numbers made analysis by operation difficult. No mortality trend was shown over the 3 time periods. Mortality is increased after age 80. There was no difference in incidence by sex but female mortality is increased. Patients in the unexpected ARF group were much less likely than the overall patient group to have a cardiac intensive care stay of 0-5 days. Those that survived were most likely to be discharged between days 6 and 10. The overwhelming majority (97.8%) of patients in the overall group are likely to be discharged by day 11. This is not true for the unexpected ARF patients that survived (only 50% being discharged prior to day 11) or for the unexpected ARF patients that died (70.3% discharged prior to day 11). In addition 3.45% of patients that survived unexpected RRT and 6.6% of patients that didn't survive unexpected RRT were still on the cardiac intensive care ward beyond 40 days. SUMMARY. We demonstrate that unexpected ARF presents a highly significant burden of cost and human suffering to cardiac intensive care services. METHOD. This study is a retrospective observation carried out in an intensive care unit of a tertiary referral hospital in London. Data was collected from all patients admitted to the unit from 2005 to 2007 following either pylorus preserving partial pancreatectomy or Whipples procedure. According to one-year mortality patients were divided into survivors (n = 53) and non-survivors (n = 21). Mean age was 61.8 years (survivors) versus 65.6 years (non-survivors). Mean APACHE scores were 14.26 (survivors) versus 13.63 (non-survivors). Both preoperative and immediate post-operative values of CRP, WCC, Creatinine, Fibrinogen and Albumin were recorded. We compared the means of these parameters between survivors and non-survivors with unpaired t test. RESULTS. Pre-operative CRP in non-survivors (mean 30.25 mg/dl) was significantly higher than in survivors (mean 11.3 mg/dl) with a two-tailed p-value of 0.0342. No significant difference was seen with other parameters or any of the post-operative values. Pre-operative p-values: WCC 0.369, CRP 0.0342, Albumin 0.344, Creatinine 0.465, Fibrinogen 0.186. Pre-operative C-Reactive Protein has a significant association with 1-year mortality in pancreatectomy patients. C-reactive protein is an acute phase protein, reactive not only due to infection and inflammation but also linked to the presence and prognosis of cancer. INTRODUCTION. The procedure of total thyroidectomy has a very high incidence of postoperative laryngeal oedema [1] . This facilitates an increase in the risk of acute respiratory insufficiency after the extubation of the trachea postoperatively [2] . To evaluate the effect of administering 0.1% 15 ml solutio L-lysini aescinatis intravenously for the prophylaxis against acute respiratory insufficiency resulting from the post-operative laryngeal oedema. After informed consent, 140 ASA II-III physical status patients, ages 35-62 years, undergoing total thyroidectomy, were randomly divided into two groups. A group (n = 70) received 0.1% 15 ml sol. L-lysini aescinatis intravenously, 30 min before the onset of anesthesia, while B group (n = 70) received 4 mg dexamethasone intravenously, 30 min before the onset of anesthesia. The anesthesia was induced with fentanyl, propofol, and vecuronium. The duration of anesthesia was 120 ± 15 min. SAP, DAP, HR, SpO 2 , PaO 2 , PaCO 2 , sedation and pain degree were recorded before and after surgical procedure. Analysis of variance and t tests were used for statistical comparisons. RESULTS. The two groups were similar in regard to demographical variables, ASA physical status, surgical procedure, anesthesia and duration of surgery. After extubation, 1 patient in group A developed symptoms of I degree acute respiratory insufficiency which resolved in 45 min. In group B, 7 patients developed the symptoms of I degree acute respiratory insufficiency which resolved in 110 ± 20 min and 2 patients developed the symptoms of III degree acute respiratory insufficiency demanding reintubation for lung ventilation (P \ 0.05). CONCLUSIONS. Use of 0.1% 15 ml sol. L-lysini aescinatis before total thyroidectomy effectively allows for decrease in the incidence of acute respiratory insufficiency as an outcome of post-operative laryngeal oedema. Year old female, admitted with PV bleeding 2 weeks after termination of pregnancy. Underwent surgery for evacuation of retained products continued to bleed heavily post-operatively which necessitated transfusion with 6 units of packed cells and 4 bags of FFP. Coagulation tests showed significantly elevated APTT AT 3.1 while other coagulation parameters were normal. managed with further FFP and blood transfusion and referred for ITU input. PAST MEDICAL HISTORY. 3 previous normal vaginal deliveries, last being 3 months prior to current admission. ITU team identified that APTT was deranged from a previous admission 4 weeks ago when she had presented with hematuria. Apart from this she had no significant past history of any bleeding diathesis or coagulation abnormalities. Coagulation tests showed significantly elevated APTT at 3.1 while other coagulation and haematological parameters were normal. The APTT was not corrected on mixing with O-ve serum. Factor 8 levels were 0.7% which increased to 7% after treatment with FFP. FACTOR 8 inhibitor assay was positive. Autoimmune screen was negative and complement levels normal. MANAGEMENT. She was given 3 doses of recombinant factor 7 (novo 7) at a dose of 90 units/kg, which stopped the PV bleeding. Uterine tamponade was attained with a foley's catheter left inflated in-situ for 3 days. Adjuvant management with tranexamic acid, oral prednisolone 60 mg od and calcium. She had no further bleeding and foley's catheter was removed on third day. She was referred to a tertiary haematology centre for further management where she received Rituximab infusions, 3 doses at monthly intervals. DISCUSSION. Acquired coagulation disorders in which autoantibodies against factor VIII are produced are termed acquired hemophilia A. The incidence rate of acquired hemophilia A in the UK is 1.48/million/year. Only 7% of these cases occur in the postpartum period. Acquired hemophilia is associated with significant morbidity and potential death. Cases may be associated with underlying immune or malignant disease, but at least 50% are idiopathic. In young women, the most common association is with the puerperium. There is variation in the natural history of factor VIII inhibitors in pregnancy with respect to onset, site, severity of hemorrhage and inhibitor titre. factor VIII inhibitors are most commonly found in primigravid patients. Acquired hemophilia is typically diagnosed in the postpartum period, but, rarely, it can be detected antenatally or during delivery. The median time to inhibitor onset is 2 months, but onset can occur from as soon as the antepartum period to 12 months after delivery. BACKGROUND AND GOAL OF THE STUDY. Thrombin activates the fibrin stabilizing FXIII to FXIIIa, which is responsible for the polymerisation of the fibrin clot and enables clot firmness along with platelets and fibrinogen as well as protection against fibrinolysis. Furthermore, FXIII decreases capillary leakage and improves regular wound healing. According to recommendations in the literature, FXIII activities of above 10% have been judged as sufficient in the past, while several clinical studies showed an increased blood loos and blood transfusion requirements in surgical patients with FXIII activities below 60%. Until now, no clinical data are available, if administration of FXIII concentrate (Fibro-gamminHS Ò , CSL Behring, Vienna, Austria) is effective in reducing blood transfusion requirements in bleeding critical ill patients. MATERIAL AND METHODS. The data presented were obtained retrospectively between January 2006 and March 2008 from 96 surgical critically ill patients with ongoing bleeding and transfusion requirements as a consequence of microvascular bleeding. All patients, who received FXIII concentrate (FibrogamminHS Ò , CSL Behring, Vienna, Austria) showed FXIII plasma levels below 60% and received a single shot application of about 20 IU/kg bodyweight. A Wilcoxon test for paired samples was applied to assess differences in blood product usage between baseline versus 24 h measurement and baseline versus 48 h measurements, respectively. A Mann-Whitney U test was used to compare the effect of FXIII concentrate alone or in combination with other blood products. According to the procedure of Bonferroni to correct for the two multiple comparisons (baseline vs. 24 h after administration of FXIII concentrate and baseline vs. 48 h after administration of FXIII concentrate) p-values \0.025 were assumed statistically significant. . 24 h after administration of about 20 IU/kg FXIII concentrate (FibrogamminHS Ò ), blood transfusion requirements as well as further need for blood products and clotting factor concentrates decreased statistically significant. The need for transfusion of red blood cell concentrates (RBC) decreased from a median transfusion rate of 4 RBC's (0-22) within 24 h before FXIII administration to 1 RBC (1-9) within 24 h after FXIII administration and 0 RBC (0-4) within 48 h after FXIII administration (p \ 0.001). Furthermore, the transfusion of FFP and platelet concentrates as well as the administration of fibrinogen concentrate and PCC were reduced statistically significant. CONCLUSION. In surgical critically ill patients with FXIII plasma levels below 60% and the tendency to microvascular bleeding, administration of FXIII concentrate (Fibro-gamminHS Ò ) was effective to achieve normal haemostasis, to stop microvascular bleeding and to reduce transfusion requirements. AIMS. Postoperative bleeding still is a major complication associated with a high mortality and morbidity in cardiac surgery and therefore coagulation monitoring is very crucial. Routine coagulation tests are widely used to monitor coagulation in cardiac surgery but they have several limitations. To overcome these new monitoring methods have been developed as the Sonoclot Ò system [1] . It assesses rapidly the viscoelastic properties of clot formation in whole blood. The aim of this study was to find out if preoperative conventional coagulation tests and perioperative Sonoclot Ò assays could predict postoperative bleeding in patients undergoing cardiac surgery. The study included patients undergoing cardiac surgery in our teaching hospital from july 2007 to december 2008. Exclusion criteria were a known coagulopathy or anticoagulating medication. Preoperative routine coagulation tests (platelet count, INR, activated partial Thromboplastin time (aPTT) and fibrinogen level) were obtained preoperatively and Sonoclot Ò assays (Activated Clotting Time (ACT), Clot Rate, Platelet Function; celite/Clay and glass bead as activators) were performed before the operation and after the administration of protamin. The amount of chest tube drainage was recorded hourly over the first 4 h postoperative. An abnormal bleeding was defined as more than 800 ml in these first 4 h. Statistical analyse was performed and ROC curves where obtained. Means are indicated ± SD. . 300 patients were included in this study [(female:male = 94:206 (31%:69%), mean age 65 ± 11 years, range 27-87 years); cardiopulmonary bypass 183 (61%), off-pump 117 (39%))]. 50 patients showed abnormal bleeding (16%). The area under the curve (AUC) for all the preoperative coagulation tests (routine tests and all the Sonoclot Ò assays) as well as for the postprotamin Sonoclot Ò tests with the celite/clay activator were between 0.51 and 0.55. These tests were unable to predict abnormal bleeding. On the contrary the postprotamin ACT, Clot Rate and Platelet Function performed with the glass bead activator were predictive of postoperative enhanced bleeding. AUC for the ACT was 0.76 (95% confidence interval (CI) 0.70-0.82), Clot rate 0.72 (95% CI 0.63-0.81) and Platelet Function AUC 0.79 (95 CI 0.72-0.87). Sensitivity for the ACT, the Clot Rate and the Platelet Function were respectively 81, 80 and 87%, specificity 70, 68 and 73%. CONCLUSIONS. In opposition to the preoperative routine coagulation and initial Sonoclot Ò tests, the ACT, the Clot Rate and the Platelet Function determined using the glass bead activator after administration of protamin could predict an abnormal postoperative bleeding in patients undergoing cardiac surgery. Patients undergoing open prostatectomy are at risk, for venous thromboembolic complications for up to 3 weeks postoperatively. We evaluated the efficacy and safety of postoperative regiment of enoxaparin. Currently, there is no convenient test to measure the degree of anticoagulation from LMWH. OBJECTIVES. We carried out a single-centre, prospective, randomized, double-blind trial with the aim of assessing the efficacy of postoperative prophylactic treatment. This prospective study examines the relationship of haemoviscoelastography (HVG) MEDNORD (Ukraine Co analyzer), a viscoelastic test, measures clot formation and includes information on the cellular, as well as the plasmatic coagulation, system and serum anti-Xa concentration in patients treated with enoxaparin. METHODS. 188 patients scheduled for open prostatectomy using epidural anesthesia were enrolled. Epidural catheters were removed the morning after surgery before the commencement of subcutaneous enoxaparin 20 mg once daily. Venous blood samples were obtained at: (1) the induction of anesthesia (baseline), (2) immediately before the third dose of enoxaparin operatively; (3) 4 h after the third dose postoperatively, and (4) immediately before the fifth close postoperatively. Whole blood samples were obtained for haemoviscoelastography (HVG), activated clotting time, and anti-Xa level analyses at each of the four time intervals. RESULTS. At the four sample intervals, the r time (mean ± SEM) (5.91 ± 0.65; 7.5 ± 0.25; 9.5 ± 0.55 min) and the eˆtime (5.8 ± 0.1; 8.2 ± 0.27; ± 9.14 ± 0.2 min) of the HVG were significantly correlated with the expected peak and trough levels of LMWH and serum anti-Xa levels (p \ 0.05). After fifth dose immediately, HVG r times exceeded the normal range in 47 of 188 patients (25%). Prolongation of r time and eˆtime on postoperative day 5 may indicate an exaggerated response to LMWH. Low frequency haemoviscoelastography is a test that could potentially correlate with the degree of anticoagulation produced by low molecular weight heparin enoxaparin. CONCLUSION. Low frequency haemoviscoelastography MEDNORD (Ukraine Co analyzer), a viscoelastic test, measures clot formation and includes information on the cellular, as well as the plasmatic coagulation system is a test that could potentially correlate with the degree of anticoagulation produced by LMWH. The r time from the haemoviscogram correlates with serum anti-Xa concentration. HVG is a convenient test to measure the decree of anticoagulation from LMWH. O. Zuscich 1 , R. Hajek 1 , A. Drobilicova 1 , R. Zezula 1 1 University Hospital Olomouc, Department of Cardiac Surgery, Olomouc, Czech Republic OBJECTIVE. Regional citrate anticoagulation is suitable for cardiac surgical patients with hemostatic defect requiring the continuous renal replacement therapy (CRRT) in the postoperative period. This mode of anticoagulation does not affect the coagulation system in terms of further alteration hemostatic profile monitored using thrombelastography. Thrombelastography (TEG) is a suitable method for comprehensive evaluation of hemostatic profile in cardiac surgical patients. METHODS. The prospective study included 6 patients after cardiac surgery requiring continuous elimination (CRRT) for renal indications. The regional citrate anticoagulation protocol was administered with the definition of levels of calcium in the circuit 0.25-0.35 mmol/l and systemic levels of calcium within the physiological range. Sodium citrate 4% concentration, substitute calcium chloratum 10%, 10% magnesium sulfuricum were used. All patients were eliminated with the continuous venovenous hemodiafiltration using the substitution of bags according to the current state acid-base balance. Hemostatic profile during CRRT was monitored using thrombelastography (TEG Ò Haemoscope 5000, kaolin activated). Thrombelastography was carried out before connecting the patient to CRRT (native) and after 3 h of the ongoing regional anticoagulation (sample of native blood). CONCLUSIONS. Regional citrate anticoagulation is suitable for patients with high risk of bleeding. Minimally affects systemic coagulation and enables modification of blood coagulation disorders. The use of regional citrate anticoagulation provides a sufficient hemofilter life period in patients with impaired blood clotting Thrombelastography is the appropriate instrument for monitoring of hemostasis in the course of regional citrate anticoagulation. [1] . Thrombelastography (TEG) and standard coagulation tests are carried out at temperature of 37°C thus omitting the effects of hypothermia. Shimokawa was comparing Sonocloth and TEG results in animal model and find out that conventional measurement at 37°C were not able to show coagulation disorder under hypothermia [2] . To compare the results of TEG during therapeutic hypothermia when the blood was analysed at actual temperature (hypothermia) and 37°C (normothermia). METHODS. Eleven patients after CPR because of cardiac causes were included into the study where therapeutic hypothermia (32-34°C) was indicated for 24 h. Patients were observed for 48 h, TEG measurements were done in 12 h intervals. Standard coagulation tests, blood count and dose of anticoagulants/antiaggregants were also monitored. Data are shown as median (IQR). Wilcox match pair test was used for the statistical analysis, p \ 0.05 was considered significant. Pooled TEG results when therapeutic hypothermia was reached (n = 14) are presented in tables for both kaolin (K) and kaolin-heparinase (KH) samples. In hypothermic TEG, coagulation index (CI) was classified as hypocoagulation in 1 case in K samples and in 3 cases of KH samples. In all these 4 samples CI index was normal at 37°C. Also NTP, aPTT and thrombocytes were normal. CONCLUSIONS. Some relevant parameters of TEG measured during hypothermia were significantly different from the parameters measured at 37°C. Though clinical significance of these differences was often small in several cases hypocoagulation at TEG was missed when blood warmed up to 37°C. BACKGROUND. Drug monitoring of low molecular weight heparin (LMWH) is generally not recommended, but could be reasonable in critically ill patients, whose risk for bleeding or thrombosis shows a high interpatient variability. Prothrombinase induced clotting timereagent (PiCT Ò ) allows determination of factor Xa-inhibition in plasma. OBJECTIVE. Aim of our study was to evaluate the feasibility of LMWH detection at the point-of-care employing the PiCT Ò -reagent in a whole blood assay of rotational thrombelastometry (ROTEM Ò ). Citrated whole blood was incubated with enoxaparin at 16 different anti Xaconcentrations and subsequently tested with ROTEM Ò . The new PiCT Ò NATEM test modification was compared with a low tissue factor (LowTF) modification and the commercially available heparin-sensitive ROTEM Ò assays (CT delta calculated out of INTEM and HEP-TEM). Main target value was the clotting time (CT), which gives information about the initial activation of clot formation and is prolonged by anticoagulants. Baseline CT values were 168.60 s ± 6.11 s (PiCT Ò NATEM), 247.30 s ± 18.61 s (LowTF), and -6.20 s ± 7.91 s (CT delta). A linear dependency between anti Xa-concentration and CT was found for PiCT Ò NATEM (p \ 0.01), for LowTF (p \ 0.01), and for CT delta (p \ 0.01). The correlation coefficients were 0.93 for PiCT Ò NATEM, 0.94 for LowTF, and 0.81 for CT delta. CONCLUSION. This in vitro experiment demonstrates the feasibility of monitoring the anticoagulant effect of enoxaparin with PiCT Ò NATEM, a new ROTEM Ò test modification. This promising assay should be evaluated for monitoring anticoagulation in high risk patients. GRANT ACKNOWLEDGEMENT. INTRODUCTION. Dipyridamole (DP) inhibits platelet aggregation by blocking platelets' adenosine diphosphate receptors [1] . Plasma concentrations between 0.5 and 1.9 lg/mL are considered to lie in the therapeutic range. DP is used together with aspirin in the secondary prevention of stroke and transient ischaemic attack. It has recently also been employed in patients with left ventricular assist devices to prevent thromboembolic events. A previous trial investigated by light transmission aggregometry the dose-dependent anti-aggregatory effect of DP ex vivo when given as the sole agent [2] . Testing platelet function in whole blood is closer to physiologic conditions, however. The novel Multiplate Ò analyzer (Dynabyte, Munich, Germany), which is based on whole blood impedance aggregometry has been successfully utilized to continuously assess platelet function in patients supported with artificial hearts who were anticoagulated with aspirin and phenprocoumon [3] . This assay was therefore selected to estimate the ADP inhibitory activity by DP. METHODS. Hirudin-anticoagulated whole blood of seven volunteers was pretreated with DP to reach the following final plasma concentrations of 0, 0.4, 0.8, 1, 2, 4, 6, and 8 lg/mL, covering the therapeutic range. It was then incubated for 45 min at 37°C. After dilution (1:1 with 0.9% NaCl solution) and adding adenosin diphosphate that stimulates platelet activation by the ADP receptor, aggregation was continuously recorded for 5 min. Adhesion of activated platelets to the electrodes leads to an increase of impedance, which is detected for each sensor unit separately and transformed to aggregation units (AU) that are plotted against time (AU min). AU min is the Area under the impedance curve. RESULTS. Figure 1 shows the dose-dependent DP-induced changes in electrical resistance depicted as units (U; One U corresponds to 10 AU min). * P \ 0.05; 0 mg/mL vs. 2, 4, 6, and 8 mg/mL. Dipyridamol concentration Our results show a DP concentration dependant reduction in ADP-stimulated platelet activation. The bedside Multiplate assay is thus a device that allows evaluation of DP's characteristic platelet inhibiting effect. This could be particularly useful in monitoring patients with ventricular assist devices who are anticoagulated with DP, aspirin and phenprocoumon. While ultrasound guidance has minimized needle-related complications (pneumothorax, arterial puncture), primary malpositions are still quite common, particularly after infraclavicular approaches to the axillary/subclavian vein and during positioning of PICCs at the elbow or at midarm. Since fluoroscopy is logistically difficult in ICU, most operators rely on post-procedural chest X-ray, after which the device may have to be repositioned. Intracavitary EKG guidance is a simple, effective and inexpensive alternative method for controlling of the tip position directly during the insertion. The electrical transducer-either the AlphaCard Ò (BBraun) or the Vygocard Ò (Vygon) device-is connected both with the catheter and with a cable going to lead II of a standard EKG monitor: the saline column within the catheter acts as intracavitary electrode. After ultrasound guided insertion of the catheter in the selected central or peripheral vein, either with the direct (CVC) or modified (PICC) Seldinger technique, the catheter is filled with saline and connected to the transducer. Then it is slowly advanced observing the morphological changes of the P wave, till the tip reaches the desired position: as the P wave gets to its maximal height, the catheter tip is close to the seno-atrial node, i.e. in the upper part of the right atrium; 1 cm above this point (when the P is at one-half of its maximal height), the tip is close to the atrio-caval junction. RESULTS. 74 central venous access devices (47 CVC + 27 PICC) were positioned by the EKG method. All of them were successfully inserted. The ''atrial P wave'' was observed in all patients but one. In this case, the cardiac signal was disturbed by electrical artefacts. All patients underwent a post-operative chest X-ray: no primary malposition was observed and all catheter tips appeared to be at the desired location (either at the atrio-caval junction or in the upper part of the atrium). A retrospective comparison with a similar cohort of patients where no intra-procedural method had been adopted for tip positioning suggested that the EKG method allowed us to avoid at least 9 reposition procedures (which accounts for about €3,000). Also, replacing the post-procedural X-ray with the EKG method (even considering the cost of the transducer) would carry and additional saving of €5,000 every 100 insertions. Intracavitary EKG guidance is an accurate, safe and inexpensive method for real-time positioning of the tip of PICCs and CVCs in ICU: its systematic adoption allows to avoid chest X-ray and reposition procedures, thus saving time and money. The only contraindication to the EKG method is the inability to detect the P wave (atrial fibrillation or other supra-ventricular arrhythmias, presence of an active pace-maker, or major electrical artefacts). INTRODUCTION. Few data has been published reporting the use of epidural analgesia in the setting of intensive care [1] . Limited evidence suggests its benefit [1] . There are nonetheless controversies regarding its use in the critically ill patient, due to infectious and bleeding risks, difficulty in neurological assessment and technical execution [1] . OBJECTIVES. To describe the use of epidural analgesia in a surgical intensive care unit (ICU). The clinical records of the 87 patients who received epidural analgesia during the years 2007 and 2008 were retrospectively reviewed. RESULTS. Fifteen percent of the patients admitted to the ICU received epidural analgesia. Mean SAPS II score was 31 with a standard deviation of 14. Relative contraindications were found in 8% of the patients; accountability was attributed to hemostasis disorders (corrected before epidural placement) and recent bacteriemia. Major contraindication precluded the technique. Epidural placement was performed by anesthetists or intensivists with anesthetic background. Epidural puncture level was dictated by the dermatomes to be blocked (Graph 1). Perfusion of levobupivacaine 0.125% plus fentanil 1.25 lg/mL was used. The duration of epidural analgesia is shown in graph 2. There were two cases of dural puncture and one case of paravertebral abcess. Epidural analgesia has emerged as a commonly applied method of improving pain management. Recent study supports the finding that epidural analgesia can significantly reduce intraabdominal hypertension and prevent pressure-related organ dysfunction. AIM. The aim of the present study was to evaluate two analgesics regiment versus outcome in patients with severe acute pancreatitis. METHODS. Data for 62 consecutive patients, who have been diagnosed as severe acute pancreatitis, were prospectively acquired and retrospectively reviewed at our institution. After 48 h of common management including aggressive fluid resuscitation, prophylactic antibiotic(imipenem-cilastatin) use and organ function protection, all patients were randomized in two groups, as: group I (IVA; n = 29), which received intravenous analgesic and Group II (EDA; n = 33) with thoracic epidural analgesia regiment. Respiratory, renal and cardiovascular functions were monitored upon the start of the resuscitation. RESULTS. The baseline demographic and clinical characteristics of the two groups were similar. Patients administered epidural analgesia had significantly lower pain scores (successful pain relief observed in 38 patients, six in the group I; p B 0.01) and the incidence of respiratory complications (6 vs. 18, p B 0.01). Multiple organ failure was detected in 22 patients (eight in group II). At 38.2% IVA patients and 19.8% EDA patients have been necessary pharmacological support targeted at specific organ. A trend towards longer mechanical ventilation [9 (7-24) vs. 6 (1-15)] and intensive care unit hospitalization [21 (15-28) vs. 14 (9-18)] was observed among intravenous analgesia patients, who required more aggressive fluid resuscitation. Enteral nutrition support was preferred and was started earlier in second group (2 days after admission vs. 5 days in intravenous patients) which displayed better tolerance to this support(an average 3.2 complications in first and 1.8 in second group). Twelve intravenous patients and 21 with epidurally pain relief did not require decompressive laparotomy. CONCLUSION. Thoracic epidural analgesia in severe acute pancreatitis is associated with hemodynamic stability, lower morbidity and intensive care unit hospitalization. INTRODUCTION. Cardiac surgery exposes patients to an approximate 1-2% risk of experiencing heparin-induced thrombocytopenia (HIT) which is a severe immune-mediated disease associated with thromboembolic events. The implantation of a ventricular assist device increases the risk of developing HIT by at least 5 times. OBJECTIVES. To prove that the incidence of HIT is more important in patients admitted to cardiac ICU than in general population and that it is close to 10% in ventricular assisted patients. To draw the attention on the importance of this pathology in the cardiac ICU. To expose the complications associated with the anticoagulant treatment of these patients. A retrospective analysis of the data from our patients with ventricular assist devices between 2000 and 2008. RESULTS. The data from 58 consecutive patients were analyzed. There was noticed a number of 5 patients (8.6%) with positive tests for heparin-induced thrombocytopenia. CONCLUSIONS. The results of our study are correlated with those found in literature. Heparin-induced thrombocytopenia is a frequent complication in VAD patients. Early detection of HIT antibodies after VAD implantation and immediate implementation of an alternative anticoagulation regimen may be a strategy to improve outcome. BACKGROUND. Alveolar recruitment and positive end-expiratory pressure (PEEP) is helpful for treatment of atelectasis-induced hypoxemia during general anesthesia. In laparoscopic hysterectomy, however, application of PEEP is limited because of high airway pressure induced by pneumoperitoneum and Trendelenburg position. So we applied the preemptive alveolar recruitment strategy (ARS) before gas insufflation and no PEEP during pneumoperitoneum. We investigated if it had preventive effect during surgery. After intubation, 50 patients were allocated randomly to two groups. In group C, ventilator was set with usual method with 35% oxygen. Group P received ARS of 10 manual breathings with peak inspiratory pressure of 40 cmH 2 O followed by positive endexpiratory pressure of 15 cmH 2 O until CO 2 insufflations started. Arterial oxygen pressure (PaO 2 ) was measured before and during ARS in supine position and every 15 min during pneumoperitoneum in the Trendelenburg position. RESULTS. Baseline PaO 2 in group C was similar with that in group P (90 ± 15 vs 90 ± 10 mmHg). However, PaO 2 measured during peumoperitoneum in Trendelenburg position was higher in group P than in group C (166 ± 32 vs 145 ± 34 mmHg at 15 min, p = 0.028, 155 ± 30 vs 136 ± 32 mmHg at 30 min, p = 0.035). Alveolar-arterial oxygen gradient in group P increased less after gas insufflation (13 ± 9 to 60 ± 34 mmHg vs 10 ± 9 to 37 ± 31 mmHg, p = 0.013). Preemptive ARS before gas insufflation may be useful in improving arterial oxygenation without additional increase in airway pressure in gynecologic laparoscopic surgery. TRANSPULMONARY THERMODILUTION MONITORING DURING ANS AFTER PNEUMONECTOMY M. García Raimundo 1 , A. Mugarra Llopis 1 1 University Clinical Hospital Valencia, Anaesthesia and critical care, Valencia, Spain BACKGROUND AND GOAL OF STUDY. Pneumonectomy is a major surgery with a high intraoperative adverse events with and postoperative mortality rate. The goal of study is to evaluate the practical utility of the PiCCO (Pulsion Medical Systems, Munich, Germany) for monitoring cardiac index (CI) and extravascular lung water index (ELWI) and its derived variables during pneumonectomy resection surgery and critical care postsurgery. MATERIALS AND METHODS. The study protocol was approved by the hospital ethics committee. After induction of anesthesia and double-lumen intubation, a venous catheter was placed in the superior vena cava through the jugular right vein and a termistor-tipped catheter was placed in the descending aorta through the femoral artery, connected to the PiCCO monitor. Each measurement (3 thermodilution shots) was made 6 times, performed basal (before thoracotomy in supine position), posthoracotomy (decubitus lateral position), postneumonectomy, to the closed chest, at critical care unit admission and post 24 h. The cardiac output and ELWI and its derived variables was studied. Ventilation, fluids and analgesia intra and postoperative (epidural catheter) were managed according to our protocol. RESULTS AND DISCUSSION. The population was composed of 12 men and 4 women,13 left and 3 rigth pneumonectomy for lung cancer. The catheter functioned in all cases and using the PiCCO system and is a reliable technique. Baseline values of CI and ELWI [3 L/ min/m 2 and 3-7 ml/kg, respectively. Statistical analysis was performed (G-Stat 1.1 GSK), results are expressed as mean SD. During thoracotomy one patient developed low cardiac output and responded to conservative treatment (CI: 1.35). ELWI is reduced after pneumonectomy and remained relatively stable over the first 24 h. Basal Toracotomy Pneumonectomy Thorax Closed Critical Care Post 24 h CI 2.93 ± 0.78 2.91 ± 0.82 2.62 ± 0.68 2.83 ± 0.61 3.15 ± 0.52 3.28 ± 0.52 ELWI 6.25 ± 2.18 6.25 ± 1.67 5.37 ± 1.30 6.00 ± 2.56 5.62 ± 2.50 6.50 ± 2.23 CONCLUSION(S). ELWI decreased little after pneumonectomy and is underestimated. The PiCCO system during pneumonectomy is an excellent monitoring to detect adverse events.  To study the incidence of cocaine use in patients under 45 years presenting to an emergency department with adverse cardiovascular events METHODS. Prospective, observational cohort study during four months (February-May 2006) . All patients under 45 years presenting with a cardiovascular complain such as chest pain or palpitations were included. Data collected were demographic data, ECG registry, presence of acute myocardial infarction (AMI) and hospital course. To detect cocaine use, measurement was made in urine samples by AXYM test. For statistical analysis descriptive and chi-square test were used. RESULTS. 88 patients were included, 70% of whom were men, with a mean age of 31 + 8 years. The admission diagnosis was acute chest pain in 70% (n = 64) and palpitations in the remaining 30% (n = 28). The ECG showed alterations in 17% of cases. A total of 10 patients experienced an AMI (11%). Ten patients were found positive for cocaine use. There was no difference in gender (155 vs 4%, p = 0.15). The incidence of drug abuse was higher in week-ends (25.9 vs 5.1%, p = 0.005). There was no relationship between AMI and cocaine use (12.5 vs 11.4%, ns). Cocaine use in patients under 45 years presenting to an emergency department with adverse cardiovascular events is high, especially during week-ends. AMI rates in cocaine-associated chest pain was 12.5% C. Lafaras 1 , E. Mavroudi 2 , D. Platogiannis 1 , T. Bischiniotis 1 1 Theagenion Cancer Hospital, Cardiology, Thessaloniki, Greece, 2 Theagenion Cancer Hospital, Intensive Care Unit, Thessaloniki, Greece OBJECTIVES. Pericardial effusion and cardiac tamponade are known complications of many advanced malignancies. Echo-guided pericardiocentesis can be easily obtained and well-tolerated even in critically ill patients. Recurrence of malignant pericardial effusion and subsequently tamponade is extremely frequent (40-70%). AIM. Effectiveness and safety of intrapericardial cisplatin administration in non small lung cancer (NSLC) patients. Since 2000, 56 patients with NSLC and clinical signs of cardiac tamponade, 40 men and 16 women (median age of 59 years), were studied. Patients underwent subxiphoid pericardiocentesis under electrocardiographic, echocardiographic and haemodynamic monitoring. After a cytological examination and confirmation of neoplasmatic cells' presence, cisplatin (10 mg in 20 ml normal saline) was instilled into the pericardial cavity for three consecutive days. After the second and third dose of intrapericardial cisplatin administration, cytologic examination was performed and neoplastic burden was evaluated. Clinical and echocardiographic follow up examinations were made on a monthly basis. Following pericardiocentesis and fluid drainage, clinical and hemodynamic improvement was achieved in all our patients. The median volume of the pericardial fluid drained was 950 cc (range 400- 3, 200) and was hemorrhagic in 89.28% of the patients. Five patients had paroxysmal atrial fibrillation (8.9%) cardioverted by amiodarone (4 patients) or electrically (1 patient). Recurrence of pericardial effusion was observed in 1 patient (1.7%) treated by second pericardiocentesis and local cisplatin infusion. Significant neoplastic burden reduce was observed after the third dose of cisplatin instilled into the pericardial cavity. Median survival was 6.2 months (range 4-124 weeks). AIMS. Strong experimental evidence suggests that burn injury results in myocardial depression [1, 2] . However, clinical evidence of cardiac dysfunction and its impact on patient outcome is less established [3] [4] [5] . We sought to determine the relationship between cardiac function and clinical outcome in pediatric burn patients. Systolic and diastolic functions were determined using transesophageal echocardiography (TEE) in children, ages 2-18 years, within the first 72 h of admission following burns to [40% total body surface area. Systolic function (Ejection Fraction %) was assessed from volumetric tracings using the modified Simpson's equation of the left ventricle in the parasternal long axis view at the end of diastole (EDV) and systole (ESV). Ejection fraction (EF%) was calculated by (EDV -ESV)/(EDV). Diastolic function parameters were obtained using pulsed wave Doppler measurements across the mitral valve and tissue Doppler measurements of the mitral annulus during diastole. A ratio of mitral inflow velocity (E-wave) to tissue Doppler of (e 0 ) was used as an index of diastolic function. Clinical outcome variables including length of ICU stay, ventilator days and other variables were recorded and compared to TEE findings. We measured systolic and diastolic function using TEE in 53 patients. Clinical outcome variables and TEE findings were obtained in 37 patients. Fifty-eight percent of patients in this cohort had evidence of systolic dysfunction [6] . A similar percentage had evidence of diastolic dysfunction (E/e 0 [ 8) [7] . Poor systolic function (EF% \ 40%) was associated with a two-fold increase in ICU stay. Diastolic dysfunction did not alter clinical outcome. Other independent variables associated with increased length of stay were burn size and number of surgeries. CONCLUSION. This study substantiates that moderate to severe cardiac dysfunction occurs in children sustaining large burn injury. Additionally, systolic dysfunction, diagnosed early in the acute hospitalization, is an independent risk factor for increasing ICU stay. Whether optimizing systolic function in pediatric burn patients could lead to improved patient outcome remains to be determined. F. Tromp 1 , E. Hoste 1 , K. Colpaert 1 , S. Gevaert 1 , E. Vandecasteele 1 , A. Verstraete 1 , A. Dhondt 1 , S. Monstrey 1 , J. Decruyenaere 1 , J. Dewaele 1 1 Ghent University Hospital, Ghent, Belgium Povidone-iodine is a commonly used topical antimicrobial agent, especially in burn unit patients. Previous case reports describe total atrioventricular (AV) block in patients treated with povidone-iodine. The exact mechanism has not yet been elucidated. OBJECTIVES. To report the association of total AV block and iodine toxicity in burn unit patients. METHODS. Description of a case series of burn unit patients treated with povidone-iodine who developed total AV block, admitted during a 15-month period in the burn unit. A total of 6 patients developed initially unexplained sudden total AV block. Five patients were admitted for deep second and third degree burns covering a median of 53% (range 25-80%) of the total body surface area (TBSA) and one patient was admitted for necrotizing fasciitis, requiring extensive debridement (17.5% of the TBSA). None of the patients had a cardiac history or was treated with drugs interfering with cardiac conduction. All patients were topically treated with povidone-iodine 10% gel daily and underwent several surgical interventions. A nodal rhythm developed on day 39 (median; range 35-65). In 4 patients total AV block appeared peri-operatively (2 patients during surgery and 2 patients 48 h post-operatively). Epinephrine could temporarily restore sinus rhythm in 3 patients; placement of a temporary pacemaker was only possible in 3 patients due to access problems. Echocardiography showed no structural heart disease. Alarmed by the first 2 patients urinary iodine was measured in the 3rd and the 4th patient, revealing high concentrations: 72,700 and 678 mcg/g creatinine respectively (normal range \222 mcg/g creatinine). In the last 2 patients serum iodine concentration was measured: 927 mcg/L and 66,500 mcg/L respectively (normal range 50-80 mcg/L). All patients had acute renal failure (ARF) at the time of AV block. High plasma iodine level can cause acute tubular necrosis and iodine is excreted by the kidneys. Hemodialysis is an effective treatment for clearing iodine. Continuous dialysis was efficient in restoring AV conduction in 2 patients. CONCLUSIONS. This case series demonstrates the association between topical treatment with povidone-iodine, iodine toxicity and total AV block especially when given over a longer period ([30 days) and in patients with a large % TBSA burns. ARF and recent surgery may enhance iodine toxicity. We advocate regular measurements of the serum iodine concentrations in patients treated with povidone-iodine for prolonged periods of time. Discontinuation of povidone-iodine treatment is recommended in patients with signs of-or high risk foriodine toxicity. INTRODUCTION. According to the arterial vasodilation hypothesis, in cirrhotic patients, splanchnic vasodilation and a reduction in ''effective'' blood volume cause a counter-regulatory increase in endogenous vasopressors leading to renal vasoconstriction, refractory ascites and functional renal failure. TIPS has been proposed as a treatment. Renal vasoconstriction in cirrhotic patients has been shown to increase renal resistive index (RI) assessed by doppler ultrasound. To evaluate systemic and renal hemodynamic changes following TIPS insertion. METHODS. Retrospective analysis of a prospectively maintained database on hemodynamic monitoring in cirrhotic ICU patients. Cases were included in this analysis if patients were off vasopressors and did not have clinically relevant gastrointestinal hemorrhage at the time of TIPS insertion. Between 2004 and 2008 eight ICU patients (4 m; 4 f; median age 59 years (52-63)) with stable hemodynamic condition and invasive hemodynamic monitoring (PiCCO, Pulsion Medical Systems, Munich) originally introduced for other reasons, received a TIPS because of hepatorenal syndrome (n = 4), intractable ascites (n = 2), or recidivating hemorrhage from gastric varices (n = 2). Child-Pugh-score was 10 (8-12), MELD-score was 17 (15-24), ICU mortality was 0. Transpulmonary thermodilution measurements within 2 h before and after TIPS insertion were available in all patients, renal Doppler examinations immediately before and after TIPS insertion in 5 patients. After TIPS insertion, there were significant increases in global end-diastolic volume index (663 mL/m 2 (643-791) vs 646 mL/m 2 (580-738); p = 0.036), heart rate (HR) (98 BPM vs 86 BPM (67-92); p = 0.025), cardiac index (CI) (3.9 L/min/m 2 (3.6-5.3) CONCLUSION. TIPS placement resulted in an increase of central blood volume and CI. Whereas in our series of patients the latter effect seems to be predominantly due to a raised HR, there was also a trend towards an increase in SVI, suggesting improved cardiac filling conditions. Increasing cardiac power index upon increased preload suggests that cirrhotic cardiomyopathy was not an important factor in this series of patients. The associated decrease of RI, although partly explained by the increase in HR, indicates improved renal perfusion. Amiodarone is the antiarrhythmic agent of choice in treatment of haemodynamically unstable patients suffering from acute tachyarrhythmias due to impaired cardiac function. The intravenous form of amiodarone-hydrochloride (IvAm) has an interindividually different antiarrhythmic and rate controlling efficacy, and the dosage of amiodarone is empirical. Main adverse effects are severe bradyacardia, asystole, hypotension, low cardiac output, acute heart failure, bronchosapsm and impaired liver function. Acute liver failure (ALF) is a known, but very rare complication of IvAm that may be reversible by stopping the iv. administration in most of the cases. The few papers in the literature suppose ALF may be caused by polysorbate 80, the vehicle of th IvAm. Oral administration does not to have such an adverse effect, therefore IvAm can be changed to oral form in induced ALF cases. Our aim was to investigate the incidence of ALF and relation of IvAm and ALF in cardiac patients in a retrospective manner. History, treatment sheets, laboratory parameters of 11722 patients treated in the Heart Center between 2005 and 2007 were analyzed. Patients were considered severe ALF patients if transaminase levels exceeded 80xULN during stay in our CCU. Cut off point was determined for differentiation of ALF patients from heart failure and myocardial infarct patients with elevated transaminase levels. On the basis of the enzyme levels 55 patients revealed to suffer from severe ALF during the 3 years, 26 of them had IvAm treatment. On the basis of treatment sheets, start and elimination of IvAm treatment, status of acute myocardial infarct and heart heart failure and transaminase kinetics 8 patients proved to have ALF induced by IvAm. Indication for amiodarone administration was atrial fibrillation (n = 6) and ventricular tachycardia. Average multipliers of ULN were 379 ± 190 at ASAT, 191 ± 87 at ALAT, 57 ± 22 at LDH. Time range from start of IvAm to detection of ALF was 17 ± 4.6 h. 25% of these patients has died in ALF. Liver enzymes decreased to 10xULN during 2.5 ± 0.6 days. CONCLUSIONS. ALF is a rare but potentially life threatening adverse effect of IvAm. Authors suggest thorough monitoring liver enzymes from the start of IvAm treatment. Fast elevation in liver enzyme levels indicate acute hepatotoxic effect of IvAm. In these cases the immediate elimination of IvAm administration and start of intensive care is life saving. METHODS. The levels of NtBNP (electrochemiluminiscence immunoassay) were analysed in 26 mechanically ventilated patients in acute renal failure (fulfilling ,,Failure'' criteria within RIFLE scoring) and requiring continuous haemodiafiltration (CVVHDF). Samples were drawn before start of CRRT, after 24 and 48 h both from the ports proximal and distal to the polysulfone filter, arteriovenous difference was calculated (AVdiff). LVEF was measured with echocardiography using biplanar Simpson method. The results were compared between the subgroup where daily diuresis (Vu) remained low or decreased (n = 16) and the subgroup where Vu increased to the level of 1.5 ml/kg h or higher after 48 h of treatment (n = 10). The control group consisted of 44 ICU patients with serum creatinine less than 150 lmol/l. Wilcoxon non-parametric test, Kruskal-Wallis ANOVA and Spearman correlation test were applied. Data are expressed as medians and interquartile ranges. RESULTS. The levels of NtBNP (1717.5, 389.5-4138 ng/l) were significantly higher (p \ 0.001) in subgroup with low Vu (405, 100-1130 ml/24 h) than NtBNP levels (748.8, 384.2-2217 ng/l) in subgroup with increasing Vu (3950, 2795-4815 ml/24 h). Both subgroups had significantly higher levels than cardiac controls with normal renal function (350.7, 130.2-661.2 ng/l, p \ 0.001). EFLV did not differ between study group (55, 40-63%) and controls (50, 35-65%) . Correlation analysis showed a significant relationship between NtBNP and LVEF in control group (r = -0.50, p \ 0.001) which we could not demonstrate on either of study subgroups. Renal functions did not differ between betwen study subgroups before initiation of CVVHDF however, duration of therapy was shorter and NtBNP lower in subgroup with increasing diuresis (p \ 0.01). The average AVdiff (%) of NtBNP on filter was insignificant. Mortality of patients on CVVHDF was related to NtBNP (p \ 0.01). CONCLUSIONS. NtBNP cannot be used as marker of LV function in patients developing acute renal failure. Particularly high levels were observed in low Vu and oliguric patients which confirms previous data suggesting relationship between residual diuresis and natriuretic peptides [1] . The elimination of NtBNP on CVVHDF is negligible. The levels of NtBNP predict survival. REFERENCE. 1. Balik M et al (2003) OBJECTIVE. Although echocardiography (ECHOc) is used to identify left ventricular dysfunction in critically ill patients, inherent limitations suggest the need for additional tools as a screening method. The B-type natriuretic peptide (BNP) partially reflects ventricular pressure and could be used as a screening method prior to ECHOc in ICU patients. One-hundred patients admitted to a medical-surgical ICU of a university hospital were prospectively studied. During stable phase of the mean disease an ECHOc was performed with a simultaneously determination of plasma BNP levels. Echocardiographist was blinded to BNP values. Patients were classified according to the ECHOc findings in: normal function, systolic dysfunction, impaired relaxation, pseudonormal pattern and restrictive pattern. BNP values are expressed as median (interquartile range). Sixty-four patients (64%) showed ECHOc dysfunction: 14 (22%) systolic dysfunction, 35 (55%) impaired relaxation, 6 (9%) pseudonormal pattern, 9 (14%) restrictive pattern. Patients with ventricular dysfunction were older (67.2 ± 12.1 vs 56.9 ± 13.1, p \ 0.001), showed a higher APACHE II on admission (20.1 ± 8 vs 16.8 ± 7.5, p = 0.04), suffered previous history of heart failure (4.8% vs 95.2%, p \ 0.001) and arterial hypertension (75.4% vs 24.5%, p = 0.006). BNP levels were significantly higher in patients with systolic dysfunction respect to those with diastolic dysfunction [1100 (275-1240) pg/mL vs 263 (126-696) pg/mL respectively; (p = 0.004)]. BNP levels were significantly higher in patients with diastolic dysfunction compared to those with no ventricular dysfunction [263 (126-696) pg/mL vs 115 (50-197) pg/mL respectively; p = 0.038]. The area under the ROC curve of BNP detecting any degree of ventricular dysfunction was 0.78 (95% CI 0.69-0.87; p \ 0001). A value of BNP of 95 pg/mL had a sensitivity of 90%, specificity of 48% and an accuracy of 74% to detect any degree of ventricular dysfunction. A rapid test of BNP can detect easily the presence of ventricular dysfunction and may be a useful screening method to evaluate left ventricular dysfunction in critically ill patients. OBJECTIVES. The aim of this study was to assess the prognostic value of post-operative Btype natriuretic peptide (BNP) level after major gastrointestinal surgery. Between October 2007 and June 2008 99 consecutive patients undergoing elective or emergency major abdominal surgery for lower gastrointestinal or colorectal pathology were recruited. Patients were evaluated for perioperative cardiac risk according to the Lee Revised Cardiac Risk Index. ECGs and troponin I were recorded before and after surgery to identify myocardial injury and infarction. A single post-operative BNP level was measured 12-48 h following surgery and prognostic value evaluated for all-cause mortality over a 3 month follow-up period. RESULTS. Mean post-operative BNP level was 240 pg/ml. There were three non-fatal myocardial infarctions following surgery (3%), but 35 (35%) of patients had biochemical evidence of myocardial injury (post-operative troponin I C 0.03 ng/ml). Ten patients died over the three month follow-up period-nine of these following emergency surgery. Within the emergency population, post-operative BNP C 400 pg/ml identified patients with an odds ratio of death within 90 days of surgery of 15.2 (95% CI 3.06-75.5, p \ 0.01). The elective population had a low mortality, but elevated post-operative BNP at a threshold of C300 pg/ ml was associated with myocardial injury (odds ratio 5.31, 95% CI 1.24-23.0, p = 0.02). The Lee Revised Cardiac Risk Index was not predictive of BNP or troponin elevation, myocardial infarction, or death for either the elective or emergency group. A single BNP value in the early post-operative phase identifies patients at increased risk of death following major emergency gastrointestinal surgery, enabling clinicians to target resources at such patients early. OBJECTIVES. We surveyed the incidence of elevated cTnI in our 17-bed mixed medical/ surgical ICU using daily sampling. We compared our findings to patients' outcomes. METHODS. The study group included all ICU patients treated between 01/01/08 and 31/06/ 08. Clinical details were recorded on admission, and ICU and hospital mortality were recorded as outcomes. Daily serum cTnI was determined for all patients with a Siemens Advia Centaur TnI-Ultra assay, using 0.04 mcg/L as the 99th percentile cutoff above which values were considered elevated. RESULTS. Of 741 admissions in the study period, 401 (54%) were male, with a mean age of 60 (SD 18) years. 460 (62%) were surgical patients and 48 (6%) were readmissions. The median APACHE II score was 15 (IQR 12.20). 71 (10%) patients had an acute cardiac problem documented at the time of admission, including 29 (4%) who had acute myocardial ischaemia and 33 (4%) who had suffered a cardiac arrest, and these patients were excluded from further analysis. 226 (34%) patients had an elevated cTnI on admission, and 321 (49%) had at least one elevated cTnI during their ICU stay. 12 patients (2%) had an incomplete set of cTnI values, and were excluded from outcome analysis. 64 patients (10%) died in the ICU. ICU mortality was associated with higher age, higher APACHE II score, being a non-surgical patient, elevated admission cTnI and elevated cTnI at any point (all p \ 0.001). The area under a Receiver Operating Characteristic curve using peak cTnI level to predict ICU mortality was 0.78. 39 patients were discharged directly home or to other hospitals and were excluded from hospital mortality analysis. Of the 631 patients with hospital outcome data, 102 (16%) died in ICU or on the ward. Hospital mortality was associated with higher age, higher APACHE II score, being a non-surgical patient, elevated admission cTnI, elevated cTnI at any point (all p \ 0.001), longer unit stay (p = 0.004), and being a readmitted patient (p = 0.038). The area under a ROC curve using peak cTnI level to predict hospital mortality was 0.76 and the optimal cutoff (highest sum of sensitivity and specificity) was 0.075 mcg/L. Multivariate logistic regression analysis identified age, being a non-surgical patient, APACHE II score and a cTnI value above this 0.075mcg/L threshold as independent predictors of death in hospital. INTRODUCTION. Volemia is one of the independent variables determining cardiac output. Its evaluation is therefore fundamental in critically ill patients. Beyond clinical examination, many techniques have been proposed for its assessment, but none of them has received wide consensus. Normally, variations of volemia are associated to total body sodium (Na) stores, which are finely regulated by the kidney. If an extra-amount of Na is added to plasma, arriving to the kidney, and the kidney is conditioned by hypovolemia, the extra-Na will be entirely reabsorbed, therefore not reaching the urine. In contrast, in normo-/hypervolemia, Na will be almost completely excreted. The extra-amount of urinary Na will increase the urinary strong ion difference (SID U ), thereby causing a consensual elevation in urinary pH (pH U ). OBJECTIVES. To investigate the validity of a novel test, consisting in pH U monitoring after 20 min. infusion of sodium-bicarbonate (NaHCO 3 ) and to compare the effects on pH U of the infusion and a rapid bolus injection of the same dose. Thirty-seven patients without kidney disease, admitted to a post-operative ICU, were enrolled. Their urinary catheter was connected to an analyzer (K.IN.G, Kidney INstant monitorinG) allowing continuous measurement of pH U and principal urinary electrolytes. On the basis of a pre-test clinical evaluation including hemodynamics, acid-base status, SvO 2 and urinary rate, patients were assigned to either ''normo-/hypervolemia'' (group 1), or ''hypovolemia'' (group 2). NaHCO 3 (0.3 mEq/kg ideal body weight) was then infused in 20 min. and pH U was monitored for the following hour. In 19 patients the same dose of NaHCO 3 was also injected as bolus to compare the effects on pH U of the two ways of administration. Analysis was performed by t test or two-way ANOVA for repeated measurements, as appropriate. In group 1 (n = 21), NaHCO 3 infusion progressively increased pH U , which reached a plateau within 30 min., whereas in group 2 (n = 16) no such difference was observed. Similarly, the maximal pH U variation within 60 min. detected in group 1 was significantly higher than that observed in group 2 (0.54 ± 0.41 vs 0.06 ± 0.01, p \ 0.001). Variation in pH U was paralleled by an increase in SID U in group 1 (from 3 ± 21 to 12 ± 23 mEq/l, p = 0.001), while no such variation was observed in group 2 (from -1 ± 28 to 2 ± 27 mEq/l, p = 0.26). Both in group 1 (n = 12) and group 2 (n = 7) pH U variation caused by NaHCO 3 did not significantly differ between the two ways of administration. Moreover, the maximal pH U increase observed within 60 min. was similar with infusion and bolus administration (0.56 ± 0.35 vs 0.50 ± 0.24, p = 0.50, for group 1, and 0.05 ± 0.04 vs 0.08 ± 0.10, p = 0.47 for group 2). CONCLUSIONS.. These findings support the possible role of this easy and non-invasive test for studying the effective circulating volume in critically ill patient. INTRODUCTION. In clinical practice the effect of fluid challenges or postural changes on stroke volume determines whether a patient is fluid responsive. Although there is increasing evidence that the regional blood flow cannot be predicted from global hemodynamic measurements, the effect on regional perfusion has never been studied. To assess the relationship between stroke volume (SV) and peripheral perfusion we studied the effect of the head up tilt (HUT) test and passive leg raising (PLR) test on parameters of peripheral perfusion in 15 healthy volunteers. The tilt table test consisted of 5 min of supine rest followed by a HUT of 70°on a manually operated tilt table and ending with 5 min of supine rest. PLR test consisted of 5 min of rest in a semirecumbent position of 30°, followed by 5 min PLR (lower limbs elevated at 30°and trunk in supine position) and ending with 5 min of rest in semirecumbent position. SV was measured continuously and non-invasively using NICOM, based on chest bioreactance. Mean arterial pressure and heart rate was measured using Finometer. Peripheral perfusion was measured continuously with Sidestream Dark Field imaging (sublingual area) and Laser Doppler Flowmetry (finger). RESULTS. Figure 1 shows the results for the HUT and PLR. Both HUT and PLR induced significant changes in SV and cardiac output (CO). During the HUT there were significant changes in mean arterial pressure (MAP) and heart rate (HR). Total capillary density (TCD), proportion of perfused vessels (PPV) and perfused capillary density (PCD) did not change throughout the experiment. In addition, flow measured with LDF showed no changes. Out of hospital cardiac arrest (OHCA) is a major health problem whose prognosis is still very severe. This pathology represents a unique ischemia-reperfusion model. It is well known that ischemia and moreover reperfusion generates an oxidative stress. This phenomenon can lead to deleterious cellular and organs injuries. The beneficial effects of therapeutic hypothermia could be partly explained by the mitigation of oxidative stress. However oxidative stress has never been shown in clinical practice. OBJECTIVES. The aim of this study is to evaluate oxidative stress markers and lactate after OHCA treated by moderate hypothermia. METHODS. This is a prospective observational study conducted in one medical surgical ICU. After ethic committee approval and written informed consent, OHCA patients were included consecutively. They received sedation, mechanical ventilation and therapeutic hypothermia (24 h at a temperature of 34°C). Blood sampling was done at 3 time-points: arrival in ICU (T0), after hypothermia (T1) and on day 2 (T2). The different biological parameters included a lipid peroxydation marker (TBARS), antioxidant defences (glutathione, glutathione peroxidase and thiols) and lactate. The outcome was assessed by the Glasgow Outcome Scale at 6 months. GOS 4-5 were considered as good outcome whereas GOS 1-3 as poor outcome. Data are expressed as median and interquartile range. Statistical analysis was carried out using Mann-Whitney and Wilcoxon tests, p \ 0.05 was considered significant. RESULTS. Twenty seven patients were included aged 62 years (50. OBJECTIVES. Magnesium sulfate (MgSO 4 ) is a calcium-and an NMDA-antagonist. It may therefore have neuroprotective properties in global brain ischemia [1] . Internal cardioverter/ defibrillator (ICD) implantation requiring repeated inductions of ventricular fibrillation (VF) for threshold testing is an ideal model to study the effects of short-lasting cerebral ischemia on brain tissue and neurologic function. As part of a greater trial, we also evaluated cognitive function in patients undergoing elective ICD insertion in monitored anesthesia care. In a double blind fashion, 13 patients randomly received a 16 mmol bolus of MgSO 4 30 min prior to induction of VF followed by a continuous infusion of 5 mmol over 2 h. 16 control patients received placebo instead. Surgery was carried out in local anesthesia; apart from 0.1 mg/kg etomidate IV given immediately before induction of VF no further anesthetics were administered. The following psychometric tests were employed perioperatively: Mini Mental State Exam, Forward and Backward Digit Span Tests, and Trail Making Test. In addition, acoustic evoked potentials (peak P300 latencies) were determined before and, together with neurocognitive testing, two days after surgery. P300 latencies are inversely associated with attention allocation and immediate working memory. t tests and analysis of variance were employed to assess differences between and within groups. A P-value \ 0.05 was considered significant. RESULTS. There were no significant differences in the demographics of the two groups as well as in the number of applied shocks and the cumulative duration of VF. Magnesium serum levels increased during administration of MgSO 4 and remained elevated (i.e. [ 1 mmol/L) until 6 h after surgery (P \ 0.05 vs. baseline). P300 latencies increased slightly in both groups without differences between groups (P [ 0.05). There were no appreciable changes in the Mini Mental State Exam and the Digit Span Forward Test when compared with preoperative scores independent of group assignment. Patients in both groups scored marginally worse in the Digit Span Backward Test. Patients in the placebo group concluded the Trail Making Test faster after surgery whereas patients in the magnesium group required more time to connect the numbered dots in the right order as compared to preoperative evaluation. This difference, however, was not statistically significant. CONCLUSION. MgSO 4 administered pre-emptively in this setting does not seem to have a major beneficial effect on neurocognitive function after brief periods of cardiac arrest. However, either higher dosages or a prolonged administration might still be effective in mitigating the ongoing neuronal injury [2] . [1] . But there is little documentation and no echocardiographic data about haemodynamic and cardiac effects of hypothermia [2, 3] . PATIENTS AND METHODS. setting: a tertiary care 15-bed medical ICU in a university hospital. Patients included in the Icerea study (hypothermia during 24 h in patients surviving cardiac arrest) were evaluated by transoesophageal echography during normothermic and hypothermic periods. RESULTS. 10 patients (mean age: 60 ± 14; SAPS II: 62 ± 12; ICU mortality: 60%) were included. Ventilatory settings, inotropic and vasoactive drugs doses were identical during both periods.  A recently published protocol of cardiopulmonary resuscitation (CPR), which includes the use of steroids during and after CPR, may benefit patients with postresuscitation shock [1, 2] . We seek to provide additional evidence supporting this hypothesis and its generalizability by adequately increasing the size of the originally studied population [1] in the context of a three-center, randomized, controlled trial. Herein, we report the results of the second interim analysis. METHODS. According to the study protocol [1] , adult in-patients who were successfully resuscitated from refractory cardiac arrest were randomized to receive either (1) stress dose hydrocortisone (300 mg/day for 3-7 days and then gradual taper; study group), or (2) placebo (control group). Post-resuscitation shock was defined as sustained ([4 h), new post-arrest circulatory failure or post-arrest need for at least a 50% increase in any pre-arrest vasopressor/ inotropic support targeted to maintain mean arterial pressure [70 mmHg. Assessed endpoints were mean arterial pressure, central venous oxygen saturation, and the systemic inflammatory response during the first 10 days post-randomization, organ failure free days during days 1-60 post-randomization, and survival to discharge either to home or to a rehabilitation facility. Data from 85 patients were analyzed. Baseline patient clinical profiles were similar. Linear mixed-model analysis showed significant effects of group on central venous oxygen saturation (P \ 0.001), mean arterial pressure (P \ 0.001), and log-transformed plasma interleukin-6 levels (P \ 0.001). Study group patients who completed a full course of hydrocortisone according to protocol (n = 17) vs. corresponding controls (n = 12) had significantly more days free of all organ failure and circulatory, neurologic, hepatic, renal, coagulation, and respiratory failure (P \ 0.05). Lastly, study group patients vs. controls had higher rates of discharge to either home or a rehabilitation/high dependency unit (13/36 vs. 1/ 34, P = 0.006). CONCLUSION. These results suggest that the new CPR protocol, which includes corticosteroid supplementation for [ 3 days following resuscitation, may be of particular benefit in patients with post-resuscitation shock. GRANT ACKNOWLEDGEMENT. Supported in part by the Thorax Foundation. Almere is a new Dutch urban area, with a population that differs from other cities in the Netherlands; only 7.2% of the population is older than 65 years, compared to a mean of 8.8% in the Netherlands [2] . Data regarding survival after an OHCA in Almere is lacking. Therefore we performed a prospective follow-up study of all OHCA presented at the emergency department in the Flevoziekenhuis (FZ, Flevo-hospital). From January 2004 to December 2008, all OHCA presented at the emergency department were analysed. Patient characteristics, time to return of spontaneous circulation (ROSC), cause of the arrest, initial recorded rhythm and outcome were recorded. Data on OHCA that did not survive initial resuscitation come from the ambulance service records. Both hospital survival and survival after discharge were taken from the hospital information system. During this period 315 cases of OHCA were recorded, 146 patients (46%) did not survive initial out-of-hospital resuscitation and died at the scene. 168 were presented at the emergency department. 12 patients were excluded because of missing data, and 1 patient was directly transported to another hospital. Survival rate after successful initial resuscitation was 52%. After discharge only 2 patients deceased during a mean follow up period of 2.5 years. The results are shown in Table 1 below. We compared cardiac arrest cases in areas with AED access in the year following the deployment (the post-AED period) to cardiac arrest cases in these areas during the two years preceding the deployment (the pre-AED period). During both periods a Medical Emergency Team was available to assist inpatients displaying serious, but non-arrest, signs and symptoms and a Code Blue team was available to assist patients suffering cardiac arrest. RESULTS. Fifty-five (55) cardiac arrests occurred in the two-year pre-AED period and 31 in the one-year post-AED period. An AED was utilised in all cases of cardiac arrest in the post-AED period. Pre-AED period and post-AED period cardiac arrest patients were similar with respect to median age (74 years vs. 78 years), gender (male 62% vs. 55%), assignment to a medical unit (75% vs. 61%), event location on an acute inpatient ward (78% vs. 90%) and initial arrest rhythm of VT/VF (18% vs. 16%), PEA (47% vs. 55%) and asystole (31% vs. 29%). Cardiac arrest outcomes improved somewhat from the pre-AED period to the post-AED period with respect to ROSC (42% vs. 55%, p = 0.276) and survival to hospital discharge (22% vs. 29%, p = 0.457), though this did not reach statistical significance. CONCLUSIONS. This small study does not provide compelling evidence to support the use of AEDs for in-hospital cardiac arrest, but neither does it refute the use of AEDs in this setting. The potential for AEDs to improve outcomes may be limited when there is a relatively low proportion of cardiac arrests due to a shockable rhythm (less than 20% in our study) and when a cardiac arrest team is available that can respond to these emergencies in a timely fashion.  Recommendations for optimal first-shock energies with biphasic waveforms are conflicting. We evaluated prospectively the relation between type and duration of atrial tachyarrhythmias and the probability of successful cardioversion with a specific biphasic shock waveform to develop recommendations for the initial energy setting aiming at the lowest cumulative energy with 2 or less consecutive shocks. We analyzed 453 consecutive patients undergoing their first transthoracic electrical cardioversion, including 358 attempts for atrial fibrillation (AF) and 95 attempts for atrial flutter (AFL) and atrial tachycardia (AT). A step-up protocol with a truncated exponential biphasic waveform starting with 50 J was used. Total cumulative energies were estimated under the assumption of a 2-tiered escalating shock protocol with different initial energy settings and a ''rescue shock'' of 250 J for AFL/AT or 360 J for AF. The initial energy setting leading to the lowest total cumulative energy was regarded as the optimal first-shock level. RESULTS. Cardioversion was successful in 448 patients (cumulative efficacy, 99%). In patients with AFL/AT, the lowest total cumulative energy was attained with an initial energy setting of 50 J. In patients with AF, lowest values were achieved with an initial energy of 100 J for arrhythmia duration of 2 days or less and an initial energy of 150 J for arrhythmia durations of more than 2 days. We recommend an initial energy setting of 50 J in patients with AFL/AT, of 100 J in patients with AF 2 days or less, and of 150 J with AF more than 2 days. The estimation of the duration of ventricular fibrillation (VF) or ventricular tachycardia (VT) could have important implications regarding the selection of the best therapeutic intervention during cardiopulmonary resuscitation (CPR). The current guidelines of the American Heart Association (AHA) prescribe immediate defibrillation after onset of VF or VT. The whole purpose of using a defibrillator is to eliminate the chaotic electrical activity of the heart during VF or the too-rapid ventricular activity in VT which precludes a circulation. No drugs being used during CPR have been shown to improve clinical outcome. Recent evidence has suggested that a period of CPR before defibrillation may be beneficial after prolonged collapse. OBJECTIVE. The ECG tracings recorded during resuscitation using an AED contain information predictive of shock therapy. The focus is on the morphology of the VF waveforms. More specifically, the amplitude or the spectral properties of VF predicted the duration of untreated cardiac arrest and the likelihood of successful resuscitation. Such a VF morphology analysis is based on different single amplitude or spectral features of the VF waveforms [1, 2] . But at present, all the VF strategies to optimise defibrillation timing have not sufficient predictive power. The several indicators yield complementary information since a little correlation exists between them [3] . A smart strategy could be to extract the different information from the several ECG features and develop combinations [4] . METHODS. 300 patients with out-of-hospital cardiac arrest on arrival in an emergency medical service were examined. The rhythm was identified as VF and confirmed by two trained investigators. ECG data were stored in modules in digitized form over a period of 20 min and analyzed retrospectively. ECG traces containing CPR artefacts, produced during precordial compression, were removed by digital filtering. Times of collapse, dispatch, scene arrival, CPR, and initial defibrillation were determined from dispatch records, recordings of arrest events, interviews with bystanders, and hospital records. Pre-shock VF waveform morphology was studied and different parameters of VF ECG signals have been extracted (centroid frequency, peak power, etc. OBJECTIVE. The use of multiple antiplatelet and antithrombotic agents alongside the invasive catheterization procedures have lead to an increase in the risk of bleeding in patients with acute coronary syndromes (ACS). We study the incidence and risk factors associated to major bleeding in ACS patients admitted to the intensive care unit (ICU). METHODS. Prospective, observational study of ACS patients admitted to the ICU during the year 2005. The primary end point were major bleeding defined as the occurrence of hemorrhagic stroke or any bleeding that required transfusion of blood products, use of vasoactive drugs, gastrointestinal endoscopy or any kind of surgery. Variables studied as risk factors were: age, gender, type of ACS (with or without ST segment elevation), creatinine levels at admission, comorbidities, use of antiplatelets, heparin pre and post-procedure, thrombolytic therapy and cardiac catheterization. A multivariate logistic regression analysis was used for statistical analysis. BACKGROUND AND OBJECTIVES. Acute ST-elevation myocardial infarction (MI) is a medical emergency, requiring early reperfusion therapy with either primary percutaneous coronary intervention (PCI) or iv. fibrinolysis in order to decrease the magnitude of ischemic necrosis and the incidence of complications after acute MI such as heart failure, arrhythmias and mortality. Our aim was to evaluate independent predictors of in-hospital mortality in patients with acute ST-elevation MI. We retrospectively evaluated the records of all the patients admitted to our hospital between January and October 2008 due to acute MI. We included 190 patients (mean age 62.9 ± 12.8 years; 137 men, 53 women) with chest pain, ST-elevation on ECG with or without Q-wave or with presumably new bundle branch block and all with increased troponin I, estimated by immunomethod (normal levels up to 0.1 lg/l). The patients were treated by primary PCI if possible and other appropriate medical therapies according to guidelines. We registered demographic variables, clinical and laboratory data on admission and during inhospital stay. Predictors of in-hospital mortality were estimated by univariate statistical testing and multivariate logistic regression (forward Wald method). In-hospital mortality of 190 included patients was 9.5%. Between survivors and nonsurvivors there were significant differences in diabetes ( INTRODUCTION. Primary ventricular fibrillation (PVF) occurs in the absence of cardiac failure or shock. It appears shortly after the onset of acute myocardial infarction (AMI). It is the most lethal complication and is related with morbidity. We try to classify the patients' clinical features and those variables implied as risk factors for PVF. We studied 756 patients admitted to our Intensive Care Unit (ICU) suffering an AMI in the time interval from January 2006 up to December 2007. We compared those suffering PVF (cases) with those who did not (control group). Demographic, environmental and clinical variables were analyzed. Statistical data were reported as mean, median and percentage. Chi-square test was used to determine if two categorical variables were independent and a multivariate analysis detected risk factors implied in its development. Age median was similar in case and control groups (63 and 65 years old, respectively). Similar was also men percentage (70%). It was the first ischemic event in 75.9% in both groups. Anterior wall was damaged in 53.7% and inferior wall in 46.3% of them. Anterior coronary artery was the most frequently lesion site (53%), being the right coronary artery the one in a 33% and circumflex artery in up to 13%. In about 54.5% of all an extensive coronary artery disease was present. TIMI flow of the artery responsible at the moment of percutaneous coronary intervention (PCI) was TIMI 0 (38.2%), TIMI 1 (9.1%), TIMI 2 (18.2%), and TIMI 3 (34.5% All the patients were stratified and those who were stratified as high risk by: risk score TIMI [ 4, the presence of an electrocardiogram to suggest involvement of proximal coronary artery, were considered to perform catheterization hemodynamic urgent after combination therapy. To assess the effectiveness of fibrinolysis used clinical criteria, cessation of pain, electrical criteria, decrease at least 50% or 70% of the sum in millimeters of ST, depending of the affected territory, and enzymatic criteria, ratio of myoglobin after fibrinolysis [4. Other criteria of effectiveness of fibrinolysis was no reoclusión and TIMI 3 flow of the culprit infarct artery before percutaneous intervention. Qualitative variables are expressed as absolute value and percentage, whereas quantitative variables are expressed as mean ± standard deviation. Comparisons between groups were made with the t test for continuous variables and the v 2 or Fisher's exact for categorical variables when necessary. Alpha Error has been considered a maximum of 5%. A total of 1276 patients were admitted with Coronary Syndrome with ST elevation during the time period of the study, which was held to 920 of them fibrinolysis. Of these 920 met criteria and combination therapy was performed in 136 patients. Combination therapy (rt-PA half-dose + abciximab + heparin at very low doses and facilitated percutaneous intervention within 24 h). When comparing this group with that of standard therapy, do not find significant differences in demographic variables of age, sex and cardiovascular risk factors (except dyslipidemia). The efficacy data from fibrinolysis showed significant differences in the three criteria discussed in both the cessation of pain (p = 0001), as in the ratio of myoglobin (p = 0002) or the decrease of ST (p = 0001). Addition showed a lower rate of reoclusión 14.6% VS 0.73% (p = 0.0001) and a higher percentage of patients with the artery open (TIMI 3) at coronariography, 44.9% vs. 67.2% (p = 0.0001). We found no differences in mortality for cardiovascular causes within UCI 10.6% in the fibrinolysis group of standard compared to 6.6% in the combined therapy group (p = 0.15). CONCLUSION. Combination therapy exploits the benefits of mechanical reperfusion and prevents deleterious effects of the early activation of platelets caused by the use of fibrinolytic alone. Combination therapy in our environment has been proven effective with an acceptable rate of complications.  A total of 1276 patients were admitted with Coronary Syndrome with ST elevation during the time period of the study, which was held to 920 of them fibrinolysis. Of these 920 met criteria and combination therapy was performed in 136 patients. Combination therapy (rt-PA half-dose + abciximab + heparin at very low doses and facilitated percutaneous intervention within 24 h). When comparing this group with that of standard therapy, do not find significant differences in demographic variables of age, sex and cardiovascular risk factors (except dyslipidemia). Complications of both groups are sown in Table 1 : We found more thrombocytopenia in the combination therapy group as an intrinsic effect or abciximab which is used in combination therapy and no in standard therapy. We found no differences in mortality for cardiovascular causes within UCI 10.6% in the fibrinolysis group of standard compared to 6.6% in the combined therapy group (p = 0.15). Combination therapy showed as safety as standard fibrinolysis in our serie, with no major adverse outcomes. BACKGROUND. Gut epithelium responds to the absence of luminal nutriments by changing its morphology and functionality Thus, after a long-lasting period of starvation mucosal atrophy is prominent and sometimes hardly reversible. Alterations of the gut following a fasting period are successfully reversed, when enteric nutrition is re-established. Basic and clinical research underlines the importance of early enteral nutrition by preserving the functional competence of the gastrointestinal tract. The aim of the present study is to investigate the potentially promoting effect of probiotics on the morphological features of the jejunal mucosa following a short period of fasting. MATERIAL AND METHODS. Sixty adult male Wistar rats were used: (1) RESULTS. All groups having suffered starvation showed altered morphology indicating jejunal atrophy: number of villi, mucosal thickness, villi length and crypt depth were reduced in relation to control. Refeeding seems to restore intestinal atrophy, while L. acidophilus supplementation resulted in a statistically significant improvement of all morphology related parameters in the gut. On the contrary, probiotics given in starvation-parenteral treatment group exhibited no significant difference in relation to non-probiotic group. CONCLUSIONS. In the present short-term fasting/refeeding rat model L. acidophilus treatment seems to enhance restoration of jejunal mucosal atrophy. This finding would be of great importance in patients being deprived from food due to their illness. INTRODUCTION. Implementation of protocols for nutritional support is associated with less energy deficit, but the impact on clinical relevant outcomes is controversial. We recently reported a low standardized mortality ratio in patients with prolonged ICU stay despite substantial caloric deficits. OBJECTIVES. The aim of this study was to assess the effects of implementation of an evidence based nutritional management protocol in our ICU. PATIENTS AND METHODS. Energy, protein and fluid intake were prospectively measured in all patients staying [72 h in a mixed medical-surgical 30-bed adult ICU. Data collection included four months before (Pre-I) and four month after implementation (Post-I) of a nutritional management protocol. Caloric intake and outcome variables were compared between the two time periods. Data from a retrospective analysis from the year before served as a control. RESULTS. CONCLUSIONS. Implementation of an evidence based nutritional management protocol did not increase the average caloric intake when the phases directly before and after implementation were compared. However, our data suggest that engagement in nutrition aspects of ICU care and protocol preparation increased the awareness to malnutrition and led to a substantial increase in average energy delivery. Nevertheless, this did not translate to altered outcome. Specific characteristics of metabolic derangements occurring in critical illness are domination of developing catabolic state particularly in acute necrotizing pankreatitis. As a result, we faced such a problem as developing a clinically apparent protein-calorie deficiency which is resistant to standard nutritional support. The treatment of acute necrotizing pankreatitis in chronic abuse patients is difficult to handle for the clinician and should include sufficient energoplastic supply. In our research we aimed to assess the efficacy of adding of ornithineaspartate complex in carbohydrate metabolism in chronic abuse patients with acute necrotizing pankreatitis. METHODS. 16 comparable chronic abuse patients with acute necrotizing pancreatitis(control groupe N = 8, mean age 45.1 ± 8.5;Ornithine group N = 8, mean age 44.0 ± 8.1) received early parenteral nutrition from the moment of admission to hospital with universal system ''three-in-one''. Ornithine group also received ornithine-aspartate complex by parenteral administration (40 g/day). On the second day the patients were admitted parenteral nutrition and tube feeding 24 h/day. The volume of parenteral nutrition was gradually decreasing. Biochemical and metabolic endpoints were measured at baseline and on 6th day (nitrogen balance, amino acids spectrum, plasma whole protein, transferring concentrations, glucose and insulin levels) at the Clinical Laboratory In all patients metabolic disturbances with protein status and carbohydrate metabolism shifts were revealed. Dynamic of the whole protein, albumin/protein ratio and nitrous balance in both group showed similar tendency of metabolic improvement. Dynamic of essential and nonessential amino acids concentration remained normal showing adequate energoplastic supply in both groups. Glutamine concentration in Ornithine group remained stable and even increased by the 6th day of nutritional support, while in Control group glutamine concentration was decreasing, and by the 6th day of nutritional support it was below normal values. In Ornithine group higher levels of endogenous insulin at normal values of glucose and faster Fisher index improvement were detected. CONCLUSION. In Ornitine group duration of delirium tremens causes was 4 ± 1 days versus Control group (6 ± 1 days). Restoration of metabolic activities confirms adequate nutritional support in both groups but ornithine-aspartate complex adding provides faster improvement of protein and carbohydrate metabolism.  We screened 655 consecutive admissions to ICU in years 2006-2008. 242 of them had no primary pathology in abdomino-pelvic region and stayed in ICU for more than 24 h, and were therefore included in this study. Retrospective analysis of prospectively collected data was performed. The delivery of more than 50% of caloric needs enterally after maximum of two days in ICU was considered as achievement of the goal of enteral feeding.  In the past few years, the nutrition in the critically ill is getting a growing attention as it became a tool for better prognosis and increasing the survival. OBJECTIVE. evaluate the nutritional approach performed by different Portuguese ICUs. We sent a 51 multiple choice questions formulary to 39 different ICUs concerning the ICU characteristics, the existence of specialized nutrition groups, the nutritional support and the time of implementation, the used formulas for accessing the nutrition, time elapsed from ICU admission to initiation of nutrition and most common complications. RESULTS. 29 (74%) of the selected ICUs answered the questionnaire. 62% of those have an artificial nutrition responsible. The enteric nutrition is preferred and many keep enteric nutrition despite hemodinamic instability. Only 17% are able to access the patient's effective weight, in consequence, in 33% of the ICUs the nutritional needs are calculated using a protocol that doesn't consider the patient's weight. In terms of glycemic control, the majority (66.7%) uses an intensive insulin infusion protocol in all patients and 20.8% aim 120 mg/dL of glycaemia as superior limit. CONCLUSIONS. The results of this questionnaire meet our expectations and traduce the increasing importance attributed to the nutrition in the critically ill.  To improve visualization of cancer during surgical resections, 5-aminolevulinic acid (5-ALA) is increasingly administered pre-operatively to patients. This technique may improve improve survival in patients who undergo neurosurgery for resection of glioma. Due to its toxic effects on mitochondria, 5-ALA may increase lactate levels. This has been demonstrated in rats [1] . The impact of 5-ALA on circulating lactate has not been studied in man. To assess the impact of peroperative 5-ALA administration on systemic lactate levels in neurosurgical patients. In a retrospective study we compared neurosurgical patients who received 5-ALA (5-ALA group) with patients who did not receive 5-ALA (control group). All patients were operated for an intracranial process and were subsequently admitted to the neurosurgical ICU. 5-ALA patients received 20 mg/kg of 5-ALA orally 2 h before the induction of anesthesia. During the patients' ICU stay, arterial lactate levels were frequently measured with a point-of-care Radiometer ABL 800-series analyzer. For each patient we determined maximum lactate levels on the day of ICU-admission (day 0) and on the next day (day 1). Means were compared with Student's t test. RESULTS. 146 consecutive patients who underwent a craniotomy to remove a spaceoccupying lesion were analyzed. Their mean (± SD) age was 53 ± 15 years and 55% of the patients were female. 22 patients (14%) received 5-ALA. On day 0 the mean maximum lactate was 2.7 ± 1.7 versus 2.1 ± 0.9 mmol/L in 5-ALA group compared to the control group (p = 0.005). On day 1 these levels were 1.7 ± 0.8 and 1.6 ± 0.8 mmol/L respectively (p = 0.4) for the 5-ALA group and the control group. CONCLUSION. Lactate levels were significantly higher in patients who received 5-ALA compared to those who did not. This difference had disappeared on the next day. This may indicate that the applied dose of 5-ALA transiently induces considerable metabolic stress. The metabolic consequences of 5-ALA deserve further inquiry. Fig. 1 . O/E ratio decreased for PN + EN in 2008 with p \ 0.005 (Fig. 1) . Length of stay in the ICU at ND was shorter in the no nutrition and oral groups (4.5 and 6.2 days) and above 10 days for all other groups. CONCLUSION. EN and PN were similar in terms of outcome. Surprisingly O/E ratio was lowest for patients without nutrition or with oral nutrition. There is an association between outcome of nutrition care and length of stay. (440 and 537) were able to answer. Patients that were thirsty or had a dry mouth were twice frequent as those being hungry or wanting to eat p \ 0.0001. Those having nausea or abdominal pain were least frequent p \ 0.0001 (Fig. 1) . CONCLUSION. An extremely high proportion (1:  Prospective study over a period of 2 years set in a 21 bed University Hospital ICU. 510 pts were included in the study that met the ACCP/SCCM consensus criteria for septic shock. Blood samples were collected from these patients upon admission and on septic days 1, 3, 6 and on discharge from the unit or death and were analyzed for total cholesterol, HDL, LDL and triglycerides. Results are expressed as mean ± SD. Paired Student's t test and Multiple level regression analysis was used. P \ 0.05 was considered significant RESULTS. The group of pts was divided into septic and non septic. The septic pts developed sepsis in the unit and were used as the study group. The non septic did not developed sepsis in the unit and were used as controls. We had 153 patients in the non septic group and 357 patients that developed sepsis and/or septic shock. The mean age was 67.4 ± 19.8 years. The mortality rate for the study group was approximately 48.65%. Admission mean values of serum lipoproteins are shown on Table 1 . Table 2 presents mean values of serum lipoproteins of the study group on septic days 1, 3 and 6. The lowest values of cholesterol and HDL and high triglyceride values were seen in patients that died in the study group. Table 3 indicates mean serum lipid values of both groups upon discharge. LDL showed no significant difference between the two groups. INTRODUCTION. Microdialysis can be used to continuously monitor changes in the concentration of various metabolites in adipose tissues A prospective study was designed to evaluate the response of adipose tissue during the metabolic stress induced by sepsis. Glycerol is produced by adipose tissue lipolysis and lactate is also shown to be produced in significant amounts in adipose tissue. The release of glycerol and lactate from subcutaneous adipose tissue was followed using microdialysis in septic and non-septic patients. Prospective study in a 21 bed University Hospital Medical Intensive Care Unit. A subcutaneous devise (microdialysis catheter CMA 60) was placed in the subcutaneous fat of the upper thigh in 37 newly admitted ICU patients that met the ACCP/SCCM consensus criteria for sepsis. Dialysis samples were collected every 4 h for 6 days using a CMA 106 microdialysis pump and were analyzed immediately in a CMA ISCUS Microdialysis Analyzer. Lactate and glycerol were measured in the microdialysate. Arterial lactate was measured using a blood gas analyzer. Venous blood samples were collected once daily and were analyzed for total cholesterol, high density lipoprotein (HDL), low density lipoprotein (LDL) and triglycerides. RESULTS. The group of patients was divided into septic and non septic. Twenty five patients progressed into septic shock and were classified as septic. Twelve patients recovered from their sepsis within 24 h from admission, were classified as non-septic and were used as controls. Five patients died. Septic patients had higher concentrations of lactate and glycerol in their subcutaneous adipose tissue than the non septic group. In addition they exhibited low blood values of cholesterol and HDL and high triglyceride than the non-septic group. These dialysate values were significantly decreasing in the patients that exhibited sustained shock and/or died. CONCLUSION. In our study it was evident that patients with septic shock have a stimulation of subcutaneous adipose lipolysis and a higher lipid oxidation. As the shock progresses however there seems to be inability of the tissue to utilize lipids indicating major differences in lipolysis and lipid oxidation between patients with reversible shock and patients with sustained circulatory failure. INTRODUCTION. Nutritional support (NS) is a very important part in the management of the critically ill patient. Critical illness is a major factor to malnutrition that can lead to more infections and multi-organ failure. Although we know the benefits of NS to the critically ill, the amount of prescribed nutrition in intensive care units (ICU) is not always delivered to the patients due to several reasons. METHODS. Prospective analysis of consecutively admitted patients in two mixed ICUs. Exclusion criteria were: NS for \2 days, age \16 years and length-of-stay (LOS) \3 days. Besides the demographic data, timing of NS beginning, route of delivery and type of enteral nutrition formula, prescribed and delivered diet and reasons for suspension and reduction were collected for the first 7 days of NS. Chi-square, Mann-Whitney U, t test and logistic regression analysis were used in statistical analysis. METHODS. Prospective analysis of consecutively admitted patients in two mixed ICUs. Exclusion criteria were: NS for \2 days, age \16 years and length-of-stay (LOS) \3 days. Besides the demographic data, timing of NS beginning, route of delivery, route of feeding and type of enteral nutrition formula, prescribed and delivered diet and reasons for suspension and reduction were collected for the first 7 days of NS. Chi-square, Mann-Whitney U and t test were used in statistical analysis. RESULTS. Ninety seven patients were studied: 49 medical, 26 trauma and 22 surgical patients. They were mainly male (69.1%), age of 58.3 ± 17.8 years and a SAPS II score 49.5 ± 14.4. NS was started 33.7 ± 18.2 h after ICU admission and most of the times by enteral route feeding (89.7%). Twenty-four patients achieved target dose during the first 5 days of NS (ATD5). They were older (p = 0.122) with a higher SAPS II score (p = 0.1). Gender and cause of ICU admission were similar in both groups. There were no differences in the timing of the beginning of NS in both groups. However parenteral nutrition was started more frequently in ATD5 patients (33.3% vs. 2.7%; p \ 0.001). Despite gastrointestinal (GI) intolerance had no statistical significance (p = 0.139) it was less frequent in ATD5 patients (33.3% vs. 50.7%). After 5 days of NS, ATD5 patients showed a higher decrease in serum Creactive protein (p = 0.451), an increase in lymphocytes count (p = 0.197) and a significantly increase in serum albumin (p = 0.001) and proteins (p = 0.001). Although ATD5 patients had a higher ICU mortality (p = 0.017) no differences were found regarding hospital mortality, ICU and hospital LOS between the two groups. CONCLUSIONS. Early achievement of target dose (less than 5 days) was not associated with a higher GI intolerance. These results suggest an improvement in protein synthesis and immunological response. However we did not observed a positive impact concerning mortality and LOS. AIMS. We evaluated the outcome of patients submitted to OLT. Our goal was to define if there was a significant relationship between different variables analysed and in-hospital mortality. A retrospective study was conducted in a private clinic of Rio. We collected data from comorbidities, surgery, transfusions, sepsis, rejection, organ dysfunction, APACHE II, SOFA and MELD scores, ICU and hospital length of stay, and outcome. RESULTS. Fifty patients were studied. Mean (± SD) of collected scores were: MELD = 19.6 ± 7.9 points, SOFA = 5.1 ± 2.8 points, and APACHE II = 14.5 ± 6.0 points. Primary diseases were mainly: cirrhosis (76%) by hepatitis C (58%), alcohol (12%) and hepatitis B (4%). Main complications were: billiary fistulas (6%), hepatic artery thrombosis (6%), acute rejection (14%), pneumonia (26%), and acute renal failure (49%). The hospital mortality rate was 18%. ICU length of stay, APACHE II and SOFA scores were higher among those who died. However, when analyzing simultaneously these variables, only high APACHE II (p = 0.002) contributed significantly to predict mortality. After plotting data in a ROC curve, we found a APACHE II C 20 the best cutoff for mortality. CONCLUSION. This audit allowed us to define a bedside predictive model helping us to identify ''a priori'' patients that are more likely to undergo PMV. These results ushered crucial changes in our daily policy as we implemented (i) a shared preoperative (by 12 h) policy of volume management therapy in patients with renal insufficiency (ii) our strategies to control the inflammatory response following cardiac surgery (iii) the use of early (within 96 h since commencing of MV) tracheostomy in the patient likely undergoing PMV. INTRODUCTION. Simplified acute physiology score II (SAPS II) is used to assess severity of illness in intensive care unit (ICU) patients. The score is based on the worst variables during the first 24 h of ICU stay, including age, type of admission, prior diagnoses and physiological parameters. SAPS II is utilized to calculate the probability of hospital mortality in patients' groups. The standardized mortality ratio (SMR), which is the ratio between observed and predicted hospital mortality, is used to assess the clinical performance of the ICU. OBJECTIVES. The purpose of the study was to assess the whether hospital organization influenced SAPS II score in trauma patients with acute renal failure. Oslo University Hospital Ullevaal is the regional trauma referral centre for approximately 1.93 million adult ([18 years) persons. Unlike most other hospitals in Norway it is organized in a manner that all trauma patients stay in the emergency room (ER) for initial stabilization, and is often through diagnostic (laboratory and radiographic examinations) and therapeutic (surgery and radiographic interventions) procedures before they are admitted to ICU. Adult trauma patients with acute renal failure treated with continuous renal replacement therapy between January 1, 1996, and December 31, 2007 , were retrospectively reviewed. Two different SAPS II scores were calculated for each person, one starting at ER arrival (to simulate an organization that patients are brought directly to ICU) and one at ICU arrival (to simulate an organization that patients are stabilized before they are admitted to ICU). Data were compared utilizing a two-sided, paired Wilcoxon test. CONCLUSIONS. This study indicates that the organization of the hospital had a significant influence on SAPS II score, which is the basis for calculations used to predict hospital mortality and evaluate clinical performance of the ICU. Clinicians should be aware of the limitations of scoring systems in their ability to evaluate severity of illness, calculate probability of survival and monitor quality of care. GRANT ACKNOWLEDGEMENT. The author is supported by institutional grants. INTRODUCTION. In this study we compared clinical outcome and LOS (length of stay) prediction of several scoring systems with the actual outcome and LOS in our ICU (intensive care unit). We also compared the outcome and LOS prediction made by intensivists and bedside nurses to the actual outcome and LOS. The goal of this study is to estimate potential benefits of routine evaluation and calculation of scouring systems and its comparison to the power of direct clinical judgments. Our surgical ICU consists of ten beds. Majority of patients underwent elective or emergency abdominal operations. Some patients were admitted to the ICU after large abdominal blood vessel repair procedures and thoracic surgery patients. We have made a prospective study on 117 patients admitted from 1 December 2008 till 30 March 2009. At admission patient basic demographic characteristics, diagnosis and type of operative procedure were recorded. During the first hour following the ICU admission we recorded an attending intensives' (six of them) and bedside nurse's prediction of survival probability (in %) and prediction of ICU LOS (in days). After every consecutive 24 h after ICU admission the following scores were calculated: APACHE II, APACHE III, APACHE IV, SAPS II, SAPS III, POSSUM, MODS, SOFA, MPM-II at admission, MPM-II after 24, 48 and 72 h and LODS. Multiple regression analysis was used to determine the degree of correlation between a clinical scoring system predictions and actual outcome and LOS. The same method was applied to the medical personnel predictions of outcome and observed outcome. The analysis of intensivists' and nurses' predictions of LOS and observed LOS was made using Student's t test for independent variables. As expected all clinical scores were significantly positively correlated with actual outcome in our ICU. All scoring systems' results, except APACHE II and APACHE III, were significantly positively correlated with actual LOS. The outcome predictions made by both ICU-doctors and bedside nurses significantly positively correlated with the observed outcome (p \ 0.05). The analysis of medical personnel predictions concerning LOS revealed that there is no statistical difference between predictions made by intensivists and scoring systems. On the other hand, predictions made by bedside nurses were significantly higher than observed LOS. CONCLUSION. Subjective clinical prediction of outcome and LOS may be at least as good as objective scoring systems developed in the past. Clinical evaluation of patient status at the ICU-admission may have predictive power which parallels the elaborated scoring systems. Life style in the western society is changing and these changes can modify our disease's pattern. It is important to know the trend of the pattern to predict, if possible, our future requirements in health care. OBJECTIVE. To analyze trends in coronary risk factors (CRF) in acute myocardial infarction (AMI) patients admitted from 01/01/1995 to 31/12/2004 in the ICU's of the Valencian Community (Eastern Spain). METHODS. Retrospective analysis of a large dataset (19,719 cases included in the PRIM-VAC register). AMI was diagnosticated using the classic MONICA definition. We analyze changes for the main CRF during this period. Cuantitative variables were analyzed using Oneway procedure while trends in cualitative data were studied using Mantel's Chi square. SPSS statistical packet was used and an 0.05 a risk established.  To examine the outcome of ICU admission in patients with malignancy and analyze prognostic factors associated with outcome. METHODS. Data were collected retrospectively from all cancer patients admitted to the ICU of a general hospital during the period April 2002-March 2009. Demographic, patient, disease and treatment related factors were reviewed and APACHE II and SOFA scores at admission as well as mortality rate were calculated. Stepwise logistic regression was used to identify predictors associated wit increased hospital mortality. RESULTS. 63 patients with cancer were admitted with a mean APACHE II score 21.08 ± 8.91and SOFA score 7.11 ± 3.40. They were 45 males and 18 females with mean age of 70.04 ± 11.33 (16-18) years. The predominant type of cancer was gastrointestinal cancer (46.8%) and the main reason for admission was the post-operative recovery (42.2%) with a mean ICU LOS of 7.87 ± 9.53 days. 17 patients died in ICU, 23 survived more than 6 months and the hospital mortality was 50.79%. Variables with a significant difference between the two groups of survivors and non-survivors were gender (p = 0.027), mechanical ventilation (p = 0.005), tracheotomy in ICU (p = 0.001), remission of the malignancy (p = 0.05), metastasis (p = 0.027), type of respiratory failure (p = 0.025), sepsis (p = 0.027) and stage of tumor (p = 0.021). Table 1 and Fig. 1 summarize the results of the multivariate analysis. INTRODUCTION. There is a close relationship among infection, inflammation, and coagulation that provides the rationale for increased use of anticoagulant treatments in ICU patients. Drug-drug interactions are very common in ICU setting and they put critically ill patients at risk. In order to assure patient safety, ICU physicians must increase their knowledge about drug interactions that can cause hematologic effects and impact clinical outcomes. There are scarce data about the incidence of these types of drug interactions and the frequency that they cause adverse events. OBJECTIVES. The aim of this study is to determine the incidence of drug interactions with potential hematologic effects and the incidence of adverse events caused by these interactions. Between January 2008 and December 2008 we prospectively analyzed ICU prescriptions with the aim to identify potential drug-drug interactions. The screening was done by the clinical pharmacist, present on daily rounds, with the help from specific software (Epocrates Rx Ò drug reference). The interactions detected were classified in eight groups according to the affected system (neurological, cardiovascular, gastrointestinal, renal/metabolic, pharmacokinetic, hematological, musculoskeletical, others). We considered the hematologic group and identified the most common potential effects and the involved medications. We also recorded the incidence of adverse drug events and morbidity and mortality associated with these events. The ICU admitted 300 patients in study period. We analyzed 692 physician orders with 8059 prescribed items. We have identified 3716 drug interactions. The neurological and cardiovascular systems were the most potentially affected accounting for 67% of tracked interactions. The hematologic group comprised 9% (n = 339). The most common effects were increased risk of bleeding, hemolysis, cytopenias and alterations in coagulation lab tests. The involved medications comprised a wide range of ICU prescribed drugs. We were not able to identify any adverse drug event with hematologic effects but even with our active search procedure sub notification remains an issue to be taken into consideration. Our overall rate of adverse drug events was 5 per 1000 patient days and no ICU mortality rate could be attributed to these events. CONCLUSIONS. Drug interactions leading to hematological effects are common in ICU patients, involve a wide range of medications and although adverse drug events seem to be not so frequent their possibility cannot be neglected when physicians are making diagnostic thinking and therapeutic approach. The clinical pharmacist is essential in keeping the multiprofessional team updated regarding this important aspect of ICU care. OBJECTIVES. We designed this study to assess if cancer as cause of ICU admission is related to worse prognosis than non-cancer patients. METHODS. This is a retrospective cohort study including all patients admitted in a 31 beds general ICU over a period of 5 years. Data were collected from a database witch included characteristics, treatment and outcomes of patients from their admission to death or hospital discharge. INTRODUCTION. Drug misuse is a widespread problem in Scotland with 5.6 per 1000 adults injecting drugs regularly. Although a small percentage of the population, they are more likely to come into contact with the healthcare system due to the immediate and long term effects of drug use. We hypothesised that intravenous drug use would be more common among the intensive care population and that they would have a higher mortality than predicted by their APACHE score. A prospective case note review of 503 consecutive admissions to Glasgow Royal Infirmary Intensive Care Unit (ICU) was undertaken over an 18 month period. Evidence of intravenous drug use and a variety of diseases was sought from the patients' case notes by hand using details of current and previous admissions, clinical letters, results of investigations and correspondence from the patient's general practitioner, using agreed criteria. Demographic, Acute Physiology and Chronic Health Evaluation II (APACHE-II) score and outcome data were also retrieved. Complete data were available for all 503 admissions. 8.0% (n = 40) of these patients were intravenous drug abusers. See Table 1 CONCLUSION. As can be seen injecting drug users are likely to present to ICU at a younger age and with a lower APACHE score which is reflected in a lower predicted mortality. They have the same actual hospital mortality as the general population which leads to a higher SMR. They are also considerably more likely to be infected with a blood borne virus. These factors should be borne in mind when admitting these patients to intensive care. AIMS. Patients with cirrhosis requiring intensive care are generally viewed as having a poor prognosis related to their underlying immunosuppression, coagulopathy and poor nutritional status. We aimed to describe prognostic risk factors in patients admitted to a general ICU with decompensated liver disease. As sepsis and upper gastrointestinal bleeding (UGB) are amongst the most common reasons for admission, these were also analysed separately. We conducted a retrospective analysis of data collected from consecutive patients admitted with decompensated cirrhosis to our general university hospital ICU over a 3 year period (2005-2007 CONCLUSIONS. Our overall ICU mortality of 39% is similar to published literature from other centres. We demonstrate the poor prognosis when organ support is required in patients with sepsis and liver disease. Our mortality from variceal bleeding was higher than more recent published series [1] despite all receiving appropriate therapy; notably the majority of those who died had an additional diagnosis of sepsis. Unfortunately conventional markers of severity of illness failed to predict ICU outcome in cirrhotic patients with acute decompensation. METHODS. All patients treated with any form of ventilatory support (CPAP, non-invasive ventilation, or invasive mechanical ventilation) were included to the prospective, cohort study of ARF patients. All ICUs and high dependency units (HDU) in the 11 hospitals of District of Helsinki and Uusimaa with adult population of 1 190 967 participated in the study. During an 8-week period (April 16-June 10, 2007) 704 patients had an episode of ARF needing ventilatory support leading to incidence of 384/100 000/y. ICU was the primary unit in 304 patients and HDU in 400 patients. Need for respiratory support was less than 6 h in 179 of 704 (25%) patients. Seventy of 400 (17.5%) HDU patients were transferred to ICU. The overall ICU and HDU mortalities were 37 of 373 (9.9%) and 39 of 330 (11.8%), respectively. CONCLUSIONS. The overall incidence of ARF is much higher than estimated in studies based on ICU patients. GRANT ACKNOWLEDGEMENT. EVO-grant from Helsinki University Hospital. 22nd ESICM Annual Congress -Vienna, Austria -11-14 October 2009 CONCLUSION. Our results demonstrate that cigarette smokers are overrepresented in the ICU population, possibly due to their comorbidity. As a group, they are more likely to be younger and male but with similar APACHE scores on admission. They are significantly more likely than non-smokers to have COPD but, surprisingly, they are not more likely to have ischaemic heart disease in our population. Ultimately they are less likely to survive critical illness, despite having a lower predicted mortality, leading to a marked difference in SMR. This is important when assessing patients for admission to ICU. INTRODUCTION. The ability to identify who is likely to deteriorate after ICU discharge is limited. The estimate rate of readmission in our ICU is 2.5-3.0%, which is consistent with the rates presented in literature. In an effort to improve the ICU's clinical effectiveness and costefficiency, interest in readmission to ICU has grown considerably [1, 2, 3] . OBJECTIVES. The aim of our study was to investigate possible risk factors for readmission in our ICU, comparing readmitted to non-readmitted patients in our ICU. METHODS. Single centre retrospective study in a 12 bed mixed ICU of a tertiary university hospital from a pool of patients admitted during 2007 and 2008. During the study period 792 patients were admitted in the unit: the median of age was 55 (38-70), the males were 63.4% and the mean of SAPSII was 44 ± 15. In the group I were included all 25 patients that have been readmitted during the period of study. In the group II were included 282 randomly selected non-readmitted patients (deaths and patients discharged to another hospital [not at risk of readmission] were not included). All admissions and readmissions were unplanned. Statistical analysis of variables: v 2 , Mann-Whitney, unpaired and paired Student's t. . No significant differences were found concerning age and sex. We found higher rates of ventilator associated pneumonia ( In the group I the readmission and admission diagnoses were different in 64% of cases; septic shock (32%) and severe sepsis (52%) were the most frequent at readmission. The SAPSII (41.1 ± 14.4 vs 34.9 ± 11.9 [p 0.024]) and SOFA at 24 h (5.9 ± 3.7 vs 4.7 ± 2.6 [p 0.045]) at readmission was lower than at initial admission. The ventilator associated pneumonia was more frequent when the diagnosis of readmission was different from the admission diagnosis (81.25 vs 11.1% [p \ 0.01]). We did not find an increase in severity of illness at readmission comparing to initial admission. It was not possible to identify any admission diagnosis as an independent risk factor of readmission, but an unplanned post-operative initial admission could be related to an increased readmission risk. Failure of prior therapy at an hospital ward before the initial admission might increase ICU readmission [1] . We also emphasized the need of optimize measures for reduction of ventilator associated pneumonia, considering the observed impact in readmission. OBJECTIVES. Patients readmitted to the intensive care unit (ICU) during the same hospital stay have a bad prognosis. The outcome of patients readmitted to the ICU after hospital discharge is, however, not well defined. The aim of this study was to compare the outcome of patients readmitted to the ICU during the same hospitalization with patients readmitted to the ICU after discharge from the hospital. Retrospective study of all patients admitted to a University Hospital medical ICU between January 1, 2005 and May 1, 2008. Of the 1405 patients discharged alive from the ICU, 192 were readmitted: 94 during the same hospital stay and 98 after discharge from the hospital. Respiratory failure, cardiovascular diseases and sepsis were the most common reasons for readmission. Patients readmitted to the ICU during the same hospitalization were more likely to have been treated with mechanical ventilation (invasive or non-invasive) or vasopressor agents. Interestingly, these patients more frequently had a ''do not resuscitate'' order than other patients (18 vs 0%, p \ 0.05). Patients readmitted to the ICU after discharge from the hospital had a hospital mortality rate of 13%, not significantly different to the mortality rate of patients who were not readmitted in the ICU (9%). In contrast, the mortality rate was 43% for patients readmitted to the ICU during the same hospital stay. CONCLUSIONS. In our experience, patients who are readmitted to the ICU after discharge from the hospital do not have a worse prognosis than patients who are not readmitted; more than 85% are discharged alive from the hospital after ICU readmission. INTRODUCTION. Readmission to an intensive care unit (ICU) is associated with increased morbidity, mortality, length of stay (LOS) and cost [1] . However, keeping patients in an ICU when they are considered fit for discharge to a lower level of care leads to increased healthcare costs, and may prevent other patients accessing the ICU. To determine the readmission rate of patients to a cardiothoracic ICU after discharge, and assess whether early readmission to a cardiothoracic ICU is associated with increased mortality and LOS. METHODS. Data was collected prospectively from all patients admitted to an 18 bed cardiothoracic ICU over 5 years (1 April 2004 -31 March 2009 ). All data was entered into the local ICU database (Medicus Ò ). All patients who had been readmitted within 48 h of discharge were identified from the ICU database. The median length of readmission ICU stay was compared with the median ICU total LOS for all ICU patients in the study period. The mortality rate was compared between all ICU patients and those patients who were readmitted within 48 h of initial ICU discharge. RESULTS. The total number of ICU admissions in the study period was 5749 patients. 113 patients were readmitted within 48 h of discharge (1.96%). The median LOS for all patients admitted to the ICU in the study period was 1.9 days. For patients readmitted within 48 h the median LOS for the initial admission was 1.7 days (range 0. 2-52.6) , and the readmission stay was 4.2 days (range 01-73). A comparison of the readmission mortality rate against the overall mortality rate is shown in Table 1 . CONCLUSION. This study shows a low early readmission rate (\2%) in this large group of cardiothoracic ICU patients. The mortality rate for patients readmitted to ICU within 48 h of discharge was more than twice the overall mortality. The readmission median LOS was twice the overall ICU LOS. The low early readmission rate suggests that the local policy for discharging patients from the ICU is appropriate. There has been an established critical care outreach team in place throughout the duration of this study. The increased mortality rate and LOS in the readmitted patients demonstrates that this group should be identified and optimized before ICU discharge. INTRODUCTION. Unplanned readmissions to an ICU are associated with a bad prognosis. Except in the cases of therapeutic limitation (TL), readmission or death in the following days may be regarded as a failure of the decision to discharge the patient (pt). The SWIFT score was developed by Gajic (CCM 2008) to predict the readmission risk. Our goal was to test the predictive values of the SWIFT score in a French multicenter cohort, and to elaborate and validate a new score, that we called ''FAIR'' (Feasible Avoidance of ICU Readmission). Inclusion: ICU length of stay [24 h (only the 1st stay was taken into account), no TL during the ICU stay, pt discharged alive from the ICU. Cohort of consecutive pts from 4 hospitals of the Outcomeréa database. Prospective collection of the data required to assess the SWIFT score, demographics, prognosis and therapy along the ICU stay. Descriptive statistics and predictive values of the score were assessed for the event ''readmission to the ICU or death within 7 days after discharge''. Construction of the FAIR score was based on a multivariate analysis. Measurement of discrimination (ROC curve) and calibration (Hosmer-Lemeshow test) for SWIFT and FAIR scores. RESULTS. 3544 pts included. 32% surgical pts. 132/3412 (3.7%) pts readmitted or deceased within 7 days after ICU discharge. 3 main symptoms at readmission: respiratory failure (31%), cardiogenic shock (13%), coma (9%). 10% died during the 2nd ICU stay. Univariate analysis: compared to pts ''not readmitted and alive at day 7'', the following values are higher (p \ 0.05) in the pts ''readmitted or deceased within 7 days'': age; SAPS 2, LOD and McCabe; % pts with an arterial catheter; hospital LOS; % pts referred from another hospital unit; P/F and Glasgow Coma score at ICU discharge. Hosmer-Lemeshow test: SWIFT 10.7 (p = 0.09) and FAIR 9 (p = 0.34). DISCUSSION. In this series, the proportion of pts discharged alive from the ICU without TL and readmitted or deceased at days 7 is around 4%. The ability of the SWIFT score to predict these events are poor in our population. We built the FAIR score which is more discriminant and well calibrated. The benefit of the routine use of these scores to improve the decision to discharge the pts remains to be documented. BACKGROUND. There is growing interest on patient safety in healthcare, especially among critically ill patients. These patients need a quick decision making process followed by complex protocols, teamwork management and a large amount of resources. In this context, patient safety plays a critical role and assessing its perception among the frontline providers is crucial. We conducted a patient safety assessment in our 52 beds ICU in order to establish a baseline needed to implement patient safety improvements. To evaluate the perception of patient safety (culture) among ICU providers at the ''Hospital Universitario Marqués de Valdecilla'' in Santander (Spain). METHODS. During November 2008 we created, validated and administered a 20 questions survey among all providers in our ICU to assess the level of patient safety culture. The survey was administered to all physicians, resident physicians, nurses, nursing assistants and other ICU staff (including clinical leaders). Results are presented as rates among providers and differences between groups were evaluated using X 2 test. RESULTS. The rate of response was 53.3% with a total of 132 completed surveys (physician: 60.6%, nurse: 55.7% and other personnel: 50.6%). Of the responders, 82.7% considered that the origin and prevention of errors are on the hands of the providers caring for critically ill patients. 68.2% of those polled considered that the implementation of an anonymous reporting system of adverse effects could improve patient safety. 94.1% positively considered adherence to established protocols as part of a culture of patient safety. Clarity of medical orders was considered by 97.8% as a critical action to prevent errors. Adequate communication among caregivers was considered essential to minimize errors by 77.1% of the workers, and the use of a patient daily goal sheet is considered an interesting option. 87.2% thought that multidisciplinary patient daily rounds improve communication and minimize error. Lack of experience among providers was considered a source of error by more than 95% of nurses and physicians. Medical education and training in patient safety was assessed favourably by 93.3% of participants in order to improve care and prevent error. To achieve patient safety as a strategic priority, 84.9% considered essential the involvement of hospital managers, clinical directors and supervisors. CONCLUSIONS. Survey results suggest that improving communication, adherence to established protocols, education and training in patient safety, multidisciplinary patient daily rounds, experienced professionals and the involvement of hospital management and clinical leaders could minimize clinical errors. Several efforts to improve patient safety culture have been initiated in our environment based on these results. INTRODUCTION. The potential for medical errors and harm to the patients is increased in the intensive care unit (ICU) as the patients are sicker, have complicated conditions and need multi-disciplinary care. Critical incident reporting system helps identify various types of errors and risks to patient safety and their root causes thus reducing the likelihood of their recurrence. To determine the occurrence and type of incidents in the ICU using a voluntary reporting system and to investigate and take necessary action to prevent their recurrence. METHODS. ICU comprises of 9 bed critical care unit (CCU), 14 bed recovery room (RR) and 14 bed high dependency unit (HDU). A voluntary critical incident reporting system (CIRS) was started as a quality improvement initiative. Prior to implementation the ICU staff (Doctors and Nurses) were educated about the CIRS. The severity of incidents was categorized as none (no harm done), minor (minimal harm, no treatment required), moderate (harm requiring treatment), severe (long term harm, death) and catastrophic (multiple deaths). The likelihood of recurrence was classified as almost certain, likely, possible, unlikely and rare. These incidents were investigated and contributory factors identified and action was taken by the risk management team. RESULTS. 50 incidents were reported between February and December 2008. The median number of incidents/month was 3.5. Harm was reported in 38% of patients. 26% patients required treatment and 2 patients later died. 51% occurred in the CCU, 41% in RR and 8% in HDU. Severity of reported incidents was minor 12%, major 16% and severe 10%. The likelihood of recurrence was classified as almost certain (16%), likely (30%), possible (38%), unlikely (14%) and rare (2%). Incidents that harmed the patients requiring treatment were related to medication (36%), equipment (28%), line/tube/drain incidents (28%) and others (8%). 48% incidents were reported by doctors and 46% were anonymous. System factors contributing to the incidents were lack of knowledge and failure to follow protocol (82%), working conditions (66%) and teamwork issues (52%). Major incidents had C 5 contributory factors. Action was taken in 94% of the incidents and completed in 60% till date. CONCLUSIONS. Critical incident reporting system provides a mechanism to improve patient safety and the quality of care administered, however under reporting is an inherent problem in this system. INTRODUCTION. NICCIMS was a 10 months prospective regional audit study carried out in 7 Intensive Care Units (ICU) in Northern Ireland. Its aim was to collect and analyse anonymously adverse events and near misses in these ICUs. It suggested that the incidents related to drugs were the most frequent (36.4%) [1] . Although a large number of these events resulted in no adverse outcome, the same failures that lead to near misses or situations of low harm may lead, in other circumstances, to more serious harm. To determine the possible causes of these events we examined the practice in drug prescription and administration within the ICUs participating in NICCIMS. Electronic questionnaires were sent to the lead consultants, lead clinical nurses, medical educational supervisors and pharmacists. The questions related to the presence of a drug formulary, the computerised prescription system and the existence of protocols for the prescription and administration of drugs. Responses were compared between staff within units to assess agreement. 100% response rate was achieved. RESULTS. All units have a drug formulary but none of the pharmacists were aware of its existence and in 4 out of the 7 units, there is a disagreement between medical and nursing staff as for the existence of this document. Erroneous settings seem to exist in the prescription computer program but only a third of respondents are aware of it. Furthermore, when the pharmacist was aware of this, doctors in those 2 units rely on these settings to prescribe. A sedation protocol is present in 5 units but there was an agreement between staff in only 2 units. All units claim to have a protocol for the management of Insulin therapy. However, the target to be achieved was not uniform between units and within a given unit. ICUs are complex environments where the most vulnerable patients are exposed to critical incidents. NICCIMS stressed that medication errors are frequent, serious, and predictable 1 . The prescription and the administration of drugs do not seem to be uniform between and within the ICUs participating in the study and the discordance between clinicians, nursing staff and pharmacists suggest an inefficient practice. The prescription and administration of drugs in ICUs requires a solid framework, which could include a drug formulary, regular staff induction, reliable computerised prescribing systems and effective protocols [2] . INTRODUCTION. ICU patients experience situations related to daily care they receive that can harm them or even cause their death. Some of these events are avoidable and measures can be taken. We used an adverse events computer database to evaluate these events and create recommendations. OBJECTIVES. Improve the evaluation of the adverse events related to patients in the ICU setting in order to change tasks and procedures and get a safer health care environment. For the period from April 2008 to April 2009 all the staff of an 18 bed polyvalent ICU was proposed to notify voluntarily and anonymously all adverse events (AE) in a computer database. These AE were classified according to the type of event, the harm they caused, their avoidability and the status of the person who declared. Based on the PDCA problem-solving process (Plan-Do-Check-Act) and previous to this period, all the staff was explained the importance of AE, instructed in the use of the database and encouraged to notify AE. Nosocomial infections were excluded because they are declared in a specific national nosocomial infection database. During the evaluation period the AE group analyzed these events and proposed recommendations to perform tasks and procedures in a safer way based on the notifications made in the database. A total of 127 declarations were notified. Doctors made 84 declarations, nurses 35 and other auxiliary staff 8. From these notifications 35 were related to vascular and urinary catheters and drains, 26 to medication prescription or administration, 25 to airway management, 17 to equipment failures, 10 to direct patient care, 5 to diagnostic tests, 3 to procedures and 3 to transfusions. None of these AE caused death, 25 did not harmed patients and 102 harmed patients to a diverse extent. 36 were considered to be possibly avoidable, 79 certainly avoidable, 9 possibly unavoidable and 2 certainly unavoidable. 12 recommendations were made. A computer AE database encourages staff to notify these events by being voluntary and anonymous. This information is more easily managed and stored in a computer setting. We think that useful recommendations and modification of protocols can be made using this information. These interventions can be of benefit to patients by reducing the importance of AE in terms of morbidity, mortality and cost. INTRODUCTION. Parenteral medication errors are common and a serious safety problem in intensive care units [1] . The Department of Intensive Care Medicine of the University Hospital Hamburg-Eppendorf has standardized concentrations for all drugs routinely applied by continuous infusion. These solutions are manually prepared at the bedside by ICU nursing staff. OBJECTIVES. The study aimed at investigating whether an automated production in the pharmacy can improve the pharmaceutical quality of infusion solutions and also be economically efficient. Concentration conformity of solutions either manually prepared in clinical routine or produced by a centralized, machine-made process was analyzed. Economic efficiency was addressed by comparing production costs for both methods on the basis of annual prescription rates for all syringe driver solutions. METHODS. Pharmaceutical concentrations (mg/ml) of 115 manually prepared and 100 machine-made infusion solutions (50 ml) for syringe drivers with standardized prescriptions of Noradrenaline, Amiodarone and Hydrocortisone were analyzed by using High Performance Liquid Chromatography. Production costs were estimated on the basis of observed average labour times and machine related costs. A break even point of annual production numbers was calculated, beyond which a machine-made production was more economic. RESULTS. 60 (52%) of the manually prepared and 83 (83%) of the machine-made solutions showed an actual concentration variation of less than 5% from the declared concentration. The remaining 17% of the machine-made samples showed a deviation of 5 to 15% in contrast to 34% of the manually prepared. Of the remaining manually prepared solutions 13% deviated between 15 and 45% and one sample was as low as 45% of the declared concentration. The difference between the mean concentrations of the two groups was statistically significant (p = 0.007). At an annual production rate of 47,000 infusion solutions (200/day) the calculated cost savings on labour time by using the automated production method economically outweighed the additional machine-related investment and maintenance costs. CONCLUSIONS. Machine-made infusion solutions from the pharmacy achieved better concentration conformity than manually prepared solutions. Individual concentration deviations of manually prepared solutions observed in routine practice can lead to clinically relevant parenteral medication errors. Machine-made preparation of standardized infusion solutions is an effective means to reduce this type of medication error. Potential cost saving effects make this approach even more attractive. Although not measured, we propose additional benefits of an automated preparation through more reliable use of appropriate solvents and syringe labelling as well as enhanced asepsis. These effects would further increase patient safety. Several studies showed a clear benefit from two-dimensional ultrasound guidance for CVC compared with landmark method supporting the idea that it should be part of the routine care and being recommended by the Agency for Healthcare Research and Quality (USA) and by the National Institute of Clinical Excellence (UK). To determine the success rate, the number of attempts and the number of complications of real-time ultrasound-guided cannulation of the internal jugular vein, done by ICU physicians. Prospective study, single-center consecutive case series evaluating critically ill adult patients, admitted in a 31-bed general ICU requiring cannulation of internal jugular vein. Catheterization was performed using real-time ultrasound guidance with all patients. The baseline characteristics were evaluated, as well as the presence of risk factors for difficult venous cannulation such as shock, untreated coagulopathy, mechanical ventilation, prior catheterization, previous difficulties during catheterization, vessel's size and position, catheter size and kind (central venous, haemodialysis or pulmonary artery catheter), number of attempts and operator experience. RESULTS. 65 patients were included (30 male) with a median age of 71 ± 16 years, the Body Mass Index (BMI) was 27 ± 6 kg/m 2 and the median catheter in place was 7 ± 6 days. 53% were in mechanical ventilation. Internal jugular vein cannulation was successful in 89% patients. Jugular cannulation was successful at the first attempt in 49 patients (79%). Among the risk factors for failures of cannulation, previous catheter (60% vs. 40%, p = 0.007) and more than one the needle passes (86% v. 14%, p \ 0.001) were associated with failure. We found a low rate of complications (3.5%), one arterial puncture and 1 neck haematoma. CONCLUSIONS. Ultrasound guidance for jugular vein cannulation was safe and feasible in ICU patients. Our results suggest that ultrasound guidance could be used by ICU physicians with low complications, similar to the results in the literature. It is about an intensive care unit of 10 beds in a general hospital of 350 beds SITUATION. During the night from August 3rd to 4th 2008, a tornado of force 4 (on a scale of 5) fell down on the communes of Hautmont, Maubeuge and Boussières on Sambre. The hospital of Maubeuge was directly reached. Several services (Gastro-enterology, Internal medicine, Psychiatry) have being closed partially. The intensive care unit on the other hand has being entirely evacuated following extensive damage. DISCUSSION. Several problems were put forward by this event. The access to the hospital was problematic because of the obstruction of the access roads. The installation of the white plan was slowed down by it. The absence of protocol of evacuation of the various services made random the evacuation of the patients of the reanimation with initially a distribution between the rooms of déchocage of the urgencies and the department of surgery, close to the reanimation. Then only in the one second time the opening of the recovery room of the operating room suite to accommodate all the patients in only one place. Moreover damage in the other services has to limit the mobilization of other personal to lend strong hand during the evacuation. On the logistic level the main issue came from the lack of respirators of transport, delaying the evacuation of the service. CONCLUSION. The damage having been mainly material in the touched communes, the hospital did not have to face an surge of victims. The management of the crisis was limited to the evacuation of the patients towards the sure zones. Nevertheless, the question of arises what would have been the situation if there had been more human damage imposing a massive reception of the victims combined with the state of catastrophe in which the hospital was. This report imposes not only in our hospital, but in all the other health systems, a recasting of the protocols of white plan.  Adverse events related to inter-hospital transfer are well studied and are known to be relatively common [1] . However adverse events related to intra-hospital transfer are not well studied. We looked at the movement of acutely ill patients within the Countess of Chester Hospital-a 600 bed acute hospital in the UK. Analysis of critical incidents in our hospital suggested that the adverse events related to intra-hospital transfers may be both numerically and proportionately larger. The commonest reason that led to critical incidents related to intra-hospital transfer was that the escorting staff lacked the necessary knowledge and skill to match the complexity of the level of transfer. A critical care outreach team (CCOT) and the Early Warning Score-EWS [2] is well established in our hospital. The trigger score is 4 or more and this demands an immediate referral to the CCOT. The EWS is integrated into the vital signs chart and every adult in-patient is scored on a regular basis. Based on the EWS and on a number of key interventions we developed the Chester Transfer Score. This allowed staff in critical care and non-critical care areas to determine the appropriate level of expertise required for the transfer any individual patient. THE CHESTER TRANSFER SCORE. All potential transfers are categorised into four transfer score levels: 0, 1, 2 and 3 denoting increasing levels of complexity. The transfer score depends upon the EWS or the requirement for certain key interventions. For example, a patient with an EWS of less than 3 and not in need of any key interventions is given a transfer score of 0. This level of transfer can be carried out by non-trained staff. However if a patient is in need of any of the listed key interventions then the patient is scored on the basis of these regardless of the EWS. CONCLUSIONS. The Chester Transfer Score has been integrated into the transfer policy of our hospital and into a locally developed educational programme known as the Safe Transfer Of Patients (STOP) course. It has been in use for 2 years. We believe that this novel method has allowed us to classify the complexity of any transfer and in turn it helps, in particular ward based staff, to determine the appropriate level of escort. This along with the STOP course has led to an improvement in the safety of transfer of acutely ill patients within our hospital.  The study was carried out from July 01, 2008 to December 31, 2008. In this period 864 patients were admitted and 178 of them were submitted to mechanical ventilation. In this period 864 patients, 51.74% male and 48.26% female. There was a predominance of patients aged over 71 years (27.66%). Patients up to 20 years (18.63%) from 21 to 30 years (5.32%) from 31 to 40 (6.6%) from 41 to 50 (10.3%) from 51 to 60 years (14.47%) from 61 to 70 years (17.01%). The mean APACHE II index was 10 (±7.46) and mean SAPS II was 30.87 (±13.31). In this period, 178 (20.60%) patients were submitted to the mechanical ventilation. We observed 03 (1.68%) cases of accidental extubation. In none of the cases have required re-intubation. It was necessary to use noninvasive mechanical ventilation in O 2 patients only 01 situation the patient was in process of weaning. In O 2 cases there was failure to control the exchange of fixing the TOT and the other failed in containing the patient table of psychomotor agitation during the hygiene of nursing care. Only 01 case occurred in the night duty, which was found 100% occupancy of the ICU and a decrease in the number of nursing assistants by licensed health. There were no cases of death. CONCLUSION. The monitoring conducted by the team of physiotherapy and the existence of routines for exchange of fixing endotracheal tube favors low incidence of adverse events of accidental extubation. Although there has been no cases of death, the search for preventive mechanisms confirms the quality of care. OBJECTIVES. • To assess the starting of a safety tool: ''safety check list'' • To detect events related-events to medication, airway and mechanical ventilation, devices, patient transferring, hypoglycemia, medical equipment, unexpected deaths and a delay in the data collection laboratory and patient hygiene. • To promote the safety culture in our organization. A systematic study to collect the errors and adverse events by means of quality and safety tool (''check list''). Before-after study about the impact of ''check list'' on safety culture assessment with Safety Attitudes Questionnaire. We use Trauma-Injury Severity Score (ISS-TRISS) methodology to assess the severity and survival probability in our patients. We considered the results on the anonymous events reporting, focal groups, medical literature review and the risk priority number of Failure Mode and Effect Analysis to decide the check list contents. The clinical trials scale on adverse events (Sociedad Española de Medicina Intensiva, SEMICYUC) for severity assessment. We established quality criteria for our safety reporting tools for the good working of our medical team and a good activities state. Results are expressed as means (SD) and medians (interquartile ranges). Exploratory data analysis was conducted by tabulating data and conducting chi-square test to compare categorical variables. For comparison of group differences on continuous variables, t test was used. RESULTS. During 6 months, a total of 161 patients were reported. The patients characteristic were: age 39 ± 17.3 years, 76.4% man, and ISS 24.9 ± 17. We recorded 249 shift of a total of 280 (88.9%). Briefing reporting time was 6.8 ± 4.2 min. Global events rate was 45.47/100 days of staylengs; this means 12.77/100 patients, avoidable in the most cases. According to the frequency of events, in order: medication-related, place and standing of device-related, care-related, airway and mechanical ventilation-related, and equipment-related. We found a statistically significant difference in shift between more adverse events and a greater work-load. Some aspects of the safety culture were improved in a significant way. This was measured as the subjective perception for working in an active way in security, in the frequency of reported events and in the staff communication. CONCLUSION. Safety ''Check List'', to handle the harm events, is a feasible tool, to use in a way easy for the ICU personal in contact with patients, with plenty capacity to have influence on the safety culture and improve the communication. Currently, this tool is part of the routine work in our intensive unit. This study is another step to assess the application of high risk industry tools on the health area. INTRODUCTION. The autopsy has long been regarded as an important tool for clinical confrontation, education and quality assurance [1] . We investigated the correlation between the clinical diagnosis and autopsy findings in adult patients who died in our ICU during a 5-year period. We reviewed the clinical diagnosis of all patients who died in 2004-2008, in a medico-surgical 31-bed Department of Intensive Care and who underwent post-mortem examination. Comparisons between pre-and post-mortem diagnoses were classified according to the classification proposed by Goldman et al. [2] . RESULTS. Of the total of 1787 patients who died in the study period (13.2% of the total number of patients admitted), 643 (36%) had a post-mortem examination. Unexpected findings occurred in 128 (20%) patients, including class I in 7.8% (invasive aspergillosis, pulmonary embolism, myocardial or mesenteric infarctions, mediastinitis…), and class II in 12.2% (malignancy, cerebral hemorrhage, pancreatitis, cirrhosis…). The relative number of discrepancies was identical during the 5 years. There was no correlation between the discrepancies and the age of the patients, the length of ICU stay, or the decisions of withholding or withdrawing life-support. CONCLUSIONS. Despite the development of modern diagnostic techniques, the incidence of unexpected findings with clinical significance remained stable over the last years. Postmortem examination remains a valuable source of pertinent information that may improve the management of ICU patients. INTRODUCTION. Critical illness polyneuromyopathy (CIPNM) is the most common and precisely defined neuromuscular complication in ICU patients, presenting with extended skeletal muscle weakness resulting in prolonged weaning and potential increase in morbidity and mortality. The MRC (Medical Research Council) muscle strength scale has been used for the diagnosis of CIPNM, but requires patient cooperation and has significant intraobserver variability. By measuring Maximum Inspiratory Pressure (MIP), one can assess an important aspect of the respiratory component of muscle weakness, without relying on patient cooperation. The aim of our study was to explore the use of MIP as a surrogate parameter for the diagnosis of CIPNM. One hundred and forty-two consecutive patients with ICU stay C7 days (age 56 ± 20 years, 101 M/41 F) were prospectively included in the study. Apache II admission score was 16 ± 6 and duration of ICU stay was 26 ± 19 days. CIPNM was diagnosed with MRC muscle strength scale with a score of 48/60 being the cut off value for the diagnosis of CIPNM. MIP was measured with a unidirectional expiratory valve where low resistance was used to selectively permit exhalation while inspiration was blocked (Marini method). Statistical analyses employed independent t test, Spearman correlation and ROC curve analysis. RESULTS. Fifty-six (56) patients could cooperate sufficiently in order to be evaluated with the MRC scale and 21 patients were diagnosed with CIPNM. Patients with CIPNM had a significant delay in weaning from the ventilator (11 ± 14 days vs. 3 ± 3 days, p \ 0.001). MIP mean value in patients with and without CIPNM was 26 ± 14 cmH 2 0 vs 48 ± 13 cmH 2 0 (p \ 0.001) respectively. A statistical significant correlation was found between the MRC scale and the MIP value (r = 0.6, p \ 0.001). ROC curve analysis defined a value of 43 cmH 2 O as the cut-off value for MIP towards identification of CIPNM, with an area under the curve of 0.75 (0.63-0.87), sensitivity of 70% and specificity of 73% for this special diagnosis. Patients with MIP B 43 cmH 2 O thereafter had a longer weaning period (8 ± 13 days) vs. patients with MIP [ 43 cmH 2 O (3 ± 3 days, p \ 0.05). CONCLUSION. Respiratory muscle strength as assessed by MIP was significantly lower in patients with CIPNM. The assessment of respiratory muscle strength by using bedside non invasive measurements in ICU patients, before they are able to cooperate sufficiently, could possibly be a method for early detection of CIPNM. Further studies are needed in order to evaluate the role of MIP for the diagnosis of CIPNM. This research project is co-financed by E.U., European Social Fund (75%) and the Greek Ministry of Development, General Secretariat for Research and Technology (25%). Lung aeration can be quantified from computed tomography (CT) scans. Specific subvolumes of lung aeration such as nonaerated or hyperinflated lung may help to better individualize mechanical ventilation. Potential clinical applications of such quantitative information are hindered by the time-consuming analysis of the CT slices covering the entire lung. This could possibly be improved by approaches using only a few representative CT slices. Due to the fact that previous studies comparing the results obtained from a reduced number of CT slices to those read from the entire lung were found not to agree consistently, we tested a novel method. METHODS. Thoracic CTs taken from 130 patients were studied: 32 spontaneously breathing patients with normal lungs, 42 mechanically ventilated patients with normal lungs, and 56 mechanically ventilated patients with acute lung injury. The most extreme cranial and caudal CT slices were identified on the frontal topogram. Between them a further 8 evenly spaced CT slices were selected. These 10 CT slices were analyzed using standard segmentation and densitometry methods, and the results were extrapolated to the entire lung using a previously described method [1] . CT slices from the entire lung were analyzed for the purpose of comparison. Bland-Altman-Plots were used to assess the agreement between both methods. Results from the analysis of the CT slices from the entire lung are given as medians (extreme values). In contrast to previous studies, we found an excellent agreement between the values calculated from a reduced number of CT slices and those obtained from the complete CT image set. Bias (limits of agreement) were 23 (-90 to 136) ml for the total lung volume (median 3846 (1304-6768) ml) and 7 (-39 to 54) g for the lung mass (median 960 (545-3019) g). Bias (limits of agreement) were -2 (-23 to 19) ml for the nonaerated (median 25 (2-1315) ml), -4 (-38 to 30) ml for the poorly aerated (median 196 (4-2026) ml), 28 (-63 to 119) ml for the normally aerated (median 3182 (763-5390) ml), and 0 (-36 to 37) ml for the hyperinflated (median 81 (0-2964) ml) lung subvolume. When these subvolumes were calculated as percentage of the total lung volume, bias (limits of agreement) were -0.1 (-1.1 to 0.9) % for the nonaerated (median 0.8 (0.1-51.5) %), 0.1 (-0.8 to 0.9) % for the poorly aerated (median 5.1 (0.9-43.6) %), 0.2 (-0.8 to 1.3) % ml for the normally aerated (median 85.0 (33.6-97.5) %), and 0.0 (-0.6 to 0.6) % ml for the hyperinflated (median 2.3 (0.0-48.1) %) lung subvolume. CONCLUSION. The method evaluated in this work seems to be a promising approach to shorten the time required for the CT-based quantification of the aeration of the entire lung. It could thus aid the clinical application of quantitative analyses of lung aeration.  Our group has recently demonstrated that lung gas volumes measured with a modified nitrogen washout/washin technique correlate well with those obtained with quantitative analysis of lung computed tomography (CT) in adult mechanically-ventilated lung-injured patients [1] . Whether this remains valid in case of smaller lung volumes, such as those of experimental animals or paediatric patients, is not known. To compare lung gas volumes measured with a modified nitrogen washout/ washin technique with those obtained with quantitative analysis of lung CT, considered as the gold standard, in pigs. METHODS. 18 mechanically-ventilated, sedated and paralyzed pigs (20 ± 2 kg) had their functional residual capacity (FRC) measured with a newly developed ventilator employing a modified nitrogen washout/washin technique [Engström Carestation, GE Healthcare]. They then underwent a lung CT scan during an end-expiratory pause, with no positive pressure applied. Each CT scan slice was manually delineated and gas volume (FRC) calculated with a custom-made software. Individual measurements obtained with the two methods were compared by Bland-Altman analysis and linear regression. Data are presented as mean ± standard deviation. In the overall population, FRC calculated on lung CT scan was 326 ± 95 ml. Measurements obtained with the modified nitrogen washout/washin technique had an average difference of 28 ± 108 ml relative to those calculated on lung CT. Limits of agreement were -188 to 244 ml. Values obtained with the two techniques were significantly correlated (R 2 0.34, p = 0.01). CONCLUSIONS. On average, lung gas volumes measured with the modified nitrogen washout/washin technique only slightly differed from those calculated on CT scan. Values obtained with the two methods were significantly correlated, but not as well as previously reported [1] . The small number of animals and the initial learning process might explain this preliminary finding, that remains under current investigation. In patients with acute respiratory failure, positive end expiratory pressure (PEEP)-induced change in lung volumes has been demonstrated to improve oxygenation, lung mechanics and heart-lung interaction. Recently, a new technology has been developed and validated to measure the end expiratory lung volume (EELV) at the bedside. In this study, PEEP-induced changes of EELV, compliance, oxygenation and right ventricle performance have been analyzed to identify optimal cardiopulmonary interaction. METHODS. Six hemodynamically stable mechanically ventilated patients with acute respiratory failure underwent a decremental PEEP trial. Four levels of PEEP were given (15, 10, 5, and 0 cmH 2 O). Each PEEP level was maintained for 30 min. At each PEEP level the following parameters were evaluated: (1) EELV by nitrogen washout/washin technique provided with the Engström Carestation ventilator (GE Healthcare, Madison, USA), which allowed the calculation of the compliance at each PEEP decrement: (compliance EELV ) = (EELV 1 -EELV 2 )/(PEEP 1 -PEEP 2 ); in all patients EELV has been normalized for the predicted body weight; (2) Ratio between PaO 2 and the inspired fraction of oxygen (PaO 2 / FiO 2 ); (3) Echocardiographic index of the right ventricle (RV) performance, calculated as change in RV fractional area (RVFA = (RVDA -RVSA)/RVDA), where RVDA is the RV diastolic area and RVSA is the RV systolic area. RESULTS. Data are expressed as mean ± SEM In all patients the EELV decreased with the reduction of PEEP from 15 to 0 cmH 2 O. In each patient, the PEEP level resulting in the highest change of end expiratory volume (compliance EELV ) was associated with the highest value of right ventricle performance (RVFA). Moreover, a correlation between change in end expiratory lung volume (compliance EELV ) and change in the RV fractional area (RVFA) was found for each decrement of PEEP in every patient (R 2 = 0.29; p \ 0.05). There was no correlation between EELV and PaO 2 /FiO 2 , or between change in end expiratory lung volume (compliance EELV ) and PaO 2 /FiO 2 . CONCLUSIONS. Bedside measurement of end expiratory lung volume may allow to identify PEEP values resulting in optimal heart lung interaction in mechanically ventilated patients with acute respiratory failure. A. Gavrilov 1 , M. Croitoru 2 , A. Bikel 1 , S. Ivry 1 , E. Altman 1 1 Western Galilee Hospital, Nahariya, Israel, 2 Bnai Zion Medical Center, Haifa, Israel BACKGROUND. Routine employment of fiberoptic bronchoscopy (FOB) during percutaneous tracheostomy (PCT) has dramatically reduced the amount of complications and increased the safety of the procedure. At the same time, it was found that FOB employment may contribute significantly to hypoventilation and hypercarbia in the critically ill patients during the procedure. In this experimental study, we aimed to investigate the influence of FOB employment on ventilation parameters during PCT. MATERIAL AND METHODS. Simulated trachea and training/test lung (model 56 011 adult TTL Michigan Instruments Inc.) were used for bench PCT performance. In the first series (fixed mechanical ventilation through endotracheal tubes (ETT) with 7, 8, and 8.5 mm internal diameter (ID) was performed during simulation of PCT by Griggs technique. In the second series, the same experiments were repeated with adult and pediatric FOB employment. In the third series, jet ventilation through ventilation catheter inserted in the ETT 7, 8, and 8.5 mm ID was used during simulation of PCT. The following parameters were registered: peak inspiratory pressure (PIP), tidal volume (V T ) and autopositive end expiratory pressure (autoPEEP). RESULTS. Employment of adult FOB gave negative influence only in combination with ETT 7 mm ID. Measurements revealed quick and pronounce impact on PIP (rise to 80-85 cmH 2 O), decrease of V T (on 82%), and appearance of autoPEEP. At the same conditions, use of pediatric FOB resulted in acceptable changes of these parameters for ETT 7, 8, and 8.5 mm ID. Employment of jet ventilation was characterized by lower numbers of PIP and absence of autoPEEP in all sizes of ETT (7, Portable ultrasound (US) is widely available throughout ICUs in the UK In our ICU, preoperative neck US is standard practice before PDT and mandatory when using a ''closed'' technique. It aids identification of normal structures and describes aberrant anatomy or vasculature at the operation site. Abnormal anatomy and vasculature increase the risk of complications during PDT [1] . OBJECTIVES. We sought to determine: 1. the usage of preoperative neck US when performing PDT in UK ICUs 2. the relative frequencies of ''semi-open'' vs ''closed'' PDTs 3. whether ICUs employing a ''closed'' PDT technique consider US mandatory, useful or not useful. METHOD. An on-line survey was sent to 300 adult ICUs in the UK. Enquiries were made regarding the use of US and the method of insertion of PDT. RESULTS. The response rate was 51% (152 responses). The responses to our questions are depicted in Figs. 1 and 2. Fig. 1 Do you think a preoperative USS is mandatory, useful or not useful prior to PDT Fig. 2 Which of the following methods most closely describes your PDT insertion technique? 8% of respondents using a ''closed'' technique consider preoperative neck US mandatory. 70% believe it is useful and 22% consider it to be without benefit. CONCLUSION. US is a widely available, non-invasive screening tool. Evidence suggests use prior to PDT can improve patient safety, nonetheless a wide diversity of opinion and practice exist within the UK. Several centres, even if practising closed PDT choose not to use it preoperatively. OBJECTIVES. This study was aimed at evaluating ICU physicians' knowledge about drug interactions. We surveyed ICU physicians with a 50-question questionnaire that was elaborated based on the work of our clinical pharmacy department and with a true or false design (T/F). At our unit the clinical pharmacist took part in daily rounds performing a complete analysis of the items prescribed in physician orders. This analysis was done with software (Epocrates Rx Ò drug reference). The drug interactions were identified and discussed by the ICU team to define the following approach to the patient. We have constructed a database of these interactions (from January 2006 to March 2009) that served as basis for our questionnaire. We have considered the aspects of frequency and potential severity as criteria for an interaction being included. We surveyed 15 full time ICU physicians and we had no refusal to participate in the study. Of the respondents 8 had daily contact with an ICU pharmacist and were frequently exposed to clinical discussions about drug interactions. The general right answer rate was 60% (range 40-98%). When we considered only the drug interactions classified as moderate or severe by our database the right answer rate dropped to 56%. Among the most frequent interactions the rate was 57%. There was no difference when we compared true with false questions regarding the right answer rate. We identified 12 questions with very low scores; the right answer rate ranged from 20 to 46% (7T/5F) and they involved a wide variety of commonly prescribed ICU medications with potential effects over many physiologic systems. CONCLUSIONS. Based on these preliminary data we have concluded that there is room for improvement regarding ICU physicians' knowledge about drug interactions and we have to do it if we want to deliver a safe and quality care to our patients. The clinical pharmacist as a member of the multiprofessional team is essential in support to clinical activities at the bedside, acting as a source of timely information and continuing education to all ICU professionals. TARGET. To determine if there exist differences at the initial evaluation of patients' severity represented in a resuscitation's room, which revenue is decided by a resident doctor in the position of triage, at the beginning and at the end of their second year of training, which we would name a July's Phenomenon. METHOD. transverse observational study which includes all the patients who need (specific) assistance in the Resuscitation's Room of an Emergency Department from a tertiary hospital, during May (301 patients) and July (336) 2008, assessing the mortality and the final destination after evaluation. The months have been chosen for being the last and the first month of stay of second year residents in the position of classification (Triage). OUTCOME. See Table 1 . CONCLUSIONS. The ''July Phenomenon'', while an interesting concept, still has limited data to support its existence. In our field, the acute score of patients who need specific assistance in the emergency room shows that it does not exist the ''July Phenomenon'' because at this level it exists attending supervision from experienced doctors. 22nd ESICM Annual Congress -Vienna, Austria -11-14 October 2009 S305 
