16c9173e280bdf5015dd629078c9fbb53a597b8e
POSTERS P001 DONOR HEIGHT VALUE COMBINED WITH ISLET DONOR SCORE IMPROVES PANCREAS SELECTION IN CLINICAL ISLET TRANSPLANTATION CELL THERAPY WITH AUTOLOGOUS BONE MARROW STEM CELLS IN THE PREOPERATORY TREATMENT OF THE REMNANT LIVER IN PATIENTS SUBSIDIARY OF MAJOR HEPATECTOMIES. PRELIMINARY RESULTS
Lingjia  Wang Olivia  Cochet Michael J Millis Piotr  Witkowski Jos  E-Mar Ia Alamo Carmen  Bernal Luis-Miguel  Mar In   Concepci On Herrera Magdalena  Carmona Lydia  Barrera Alvaro  Iglesias Juan  Serrano Gonzalo  Su Arez Jordi  Muntan Miguel-Angel G Omez-Bravo Javier  Padillo 

   Geneva University Hospitals and University of Geneva Geneva University Hospitals and University of Geneva Shiraz University of Medical Sciences     
Background: In order to maximize the islet yield for successful islet transplantation, the key task is to select an ideal donor pancreas. By using Islet Donor Scoring (IDS) (O'Gorman et al. 2005) in the past years, we consistently obtained 50% transplant rate if the IDS reached above 80. In this study, we added donor height value as an independent variable in combination with the donor score to see if this addition can improve the pancreas selection. Methods and Materials: Donor and islet isolation information (n = 22, 2011-2012) were collected and studied. Pearson Correlation Analysis was used in statistical analysis. Results and Conclusions: Donor height value as an independent variable is significantly correlated to the pre-IEQ, post-IEQ, donor score and final pancreatic weight (all r > 0.5 and p < 0.02). When height (179 AE 3 cm) was used with IDS, islet transplant rate reached 80% in selected pancreases. extracellular matrix in the culture plates that can be detected with Alizarin Red. Adipocytes are easily identified by their morphology and staining with Oil Red. Conclusion: All these data suggest that MSCs can be isolated and expanded from most healthy donors, providing for a source of cell based transplantation. Keywords: Cell transplantation, Mesenchymal stem cells, Human bone marrow. Negar Azarpira 1 , Anahita Shaer 2 , Akbar Vahdati 2 1 Shiraz University of Medical Science; 2 Islamic Azad University, Oloom va Background: Neurogenin-3 is a protein that in humans is encoded by the NEUROG3 gene. Neurogenin-3 is expressed in endocrine progenitor cells and is required for endocrine cell development in the pancreas and intestine. It belongs to a family of basic helix-loop-helix (bHLH) transcription factors involved in the determination of neural precursor cells in the neuroectoderm during embryogenesis. Method: Total RNA was extracted from fresh human pancreatic tissue using RNX-RNA extract kit. The pancreas belongs to a 12 years old boy died during car accident and after giving consent from his parents, the pancreas and liver was dedicated for transplantation. Because the organ was not good quality for whole organ transplant, it was used for research. Result: The RT-PCR analysis showed Neurogenin-3 gene expression. Conclusion: As the donor is young, it is suggested that the progenitor cells near the ducts or the residual stem cells in islets may be the source of Neurogenin-3 expression. Negar Azarpira, Mahdokht Aghdai, Saman Nikeghbalian, Masumeh Darai, Elahe Esfandiari Shiraz University of Medical Science Introduction: Pancreatic islet transplantation has become the minimally invasive procedure for the treatment of type 1 diabetes mellitus. Method: Shiraz Organ Transplant Center is a leading center for organ transplantation especially pancreas transplant in Iran. For this reason, we intended to establish an islet transplantation program. Our experience in islet isolation on six pancreata from deceased donors is briefly presented. This required necessary equipment as well as well-trained professionals and a specially planned facility. Results: The islet viability was good. We don't have a refrigerated COBE processor (COBE 2991; Cobe) for purification, therefore our yield was low. Our experience must be improved to achieve more islets in order to develop clinical grade cell therapy. Conclusion: Overall, the isolation costs are high and accessing to a safer, more economic and persistent source of material and reagents will improve this technique. Background: It is hoped that in near future stem cells can be used in diabetes therapy through pancreatic beta cell replacement. IPS cells (Induced plurip-otent stem cells) are a kind of pluripotent stem cell which are taken from nonpluripotent cell, an adult somatic cell, through 'stimulating' certain genes. Objective: In diabetes type 1, it is beta cells that are mostly destroyed, but in diabetes type 2 the number of beta cells is reduced by a 40-60%. A way of producing immature islet-like clusters of insulin-producing cells taken from iPS cells will be introduced. Methodology: From the Iranian Royan Stem Cell Bank We got a human induced pluripotent stem cell line which had been derived from reprogramming a 42-year-old man's dermal fibroblast cells. Several steps were involved in this protocol. In the first place, embryoid bodies had to be formed and then plated in insulin-transferring-selenium medium. The medium was supplemented with N2, B27, and bFGF (basic fibroblast growth factor). In the next step, broke loose concentration in a medium was reduced, the bFGF was taken out, and nicotinic acid was added. Clusters were formed after the cells were isolated and cultured in suspension. An enhanced expression of pancreatic genes was observed through reverse transcription-polymerase chain reaction. The outgrowths were incubated in DTZ solution for 15 min. Result: Gene expression of insulin-GlucagonePDX1-NGN3-PAX4-PAX6-NKX6.1-KIR6.2-GLUT2 was documented by Real-time qPCR analysis. DTZstained cellular clusters were observed after nearly 23 days but they were more observable after 31 days. Conclusions: Since ips cells can be developed through reprogramming the patient's somatic cells, and due to the distinction between these cells and Beta cells they can produce sufficient insulin and there is no need to use suppressing drugs when applied to diabetic patients, they seem to be very promising. Thus in the present study we were able to produce clusters of cells, from IPS cells, which were quite capable of producing insulin. The present project may result in the formation of an unlimited source of cells appropriate for transplant. Background: Total pancreatectomy (TPE) is sometimes the only treatment option in severe pancreatic fistula (PF). Pancreas islet autotransplantation (PIT) performed at the time of completion pancreatectomy can rescue a part of endocrine tissue and prevent or minimize the bright diabetes. Data on long term outcomes are limited. We report our experience with patients who underwent TPE followed by PITx. Methods/Materials: From 2007 to 2013 seven patients underwent TPE for grade C PF after hemipancreatoduodenectomy (five out of them for carcinoma and two for non-malignant tumours). Pancreatic islets were isolated from pancreatic tail using digestion with collagenase (Serva). Non-purified islet suspension was infused into the portal vein intraoperatively. Results: A median number of islets transplanted was 210 000 ieq (range 70 000-365 000). One patient died postoperatively for reasons unrelated to PITx. One patient is 6 months after PITx with full islet function without insulin and without tumor recurrence (fasting C-peptide 0.45 nM). Other three patients have stable diabetes with partial graft function (fasting C-peptide levels 0.23, 0.61 and 0.22 nM). Two patients resected for ampuloma are alive. One patient with T3 pancreatic head carcinoma is alive 25 months after PITx with tumor recurrence. Another one with bile duct carcinoma died 47 months after PITx with tumor recurrence. Third patient with carcinoma of papilla of Vater with positive lymph nodes and angioinvasion died 12 months after PITx with local recurrence and solitary liver metastasis. Conclusion: PITx after complete pancreatectomy for severe pancreatic fistula is able to prevent brittle diabetes and maintain some level of C peptide. The fear is about the possibilities of malignant tumour cells spreading. In our small series we did not observe any early development of multiple liver metastases, which could be caused by islet suspension contaminated with malignant cells. The aim of the work was to study the effectiveness of the stapes allotransplantation in the course of reconstructive operations on the middle ear on the basis of experimental and clinical research. Material: According to the tasks set, the experimental part of the research of the stapes allotransplantation was conducted on cats. The operation was performed in the sterile conditions under the general anaesthesie. Electronic and microscopic examination of the stapes allotransplantation was conducted after one, three and six months after the operation, consequently. In the clinical research the effectiveness of using the stapes allotransplastics was compared with the operations, during which the columella of the autobone was used as the prosthetic material. The results of the research. In six months after the operation, the periosteous formation of the bone starts due to the osteogenous cells, which accumulate themselves along the periphery of the transplant. However, the research of the transplant at the sub-microscopic level allowed to find out that the first signs of bone-formation in it appeared considerably earlier. At three months already, on the surface of the transplant there accumulate multiple one-nuclear osteogenous cells, which contain granular endoplasmic reticulum; here also appear single osteoblasts, which have a developed endoplasmic reticulum with the homogenic secretion. It localizes itself mostly near the outer nucleus membrane. First of all, the reconstruction starts along the edges of the stapes's base. Obviously, it is caused by the fact that this is the very place where the physiologic stress during the sound transmission concentrates. Then, the intensive periosteous bone formation appears in the stapes's legs, and the bone formed here covers the inside cell-free structures of the transplant's legs as if a cuff. A year after the transplantation a nearly total reconstruction is observed in the outside layers of the stapes; the nearlyformed bone tissue begins to substitute the external side of the stapes's head. The cell elements of the bone tissue start to appear in the inside layers of the stapes, but they remain single units on the background of the cell-free fibrous structures so far. The layer of the osteoblasts on the stapes's surface modifies, becoming thinner, and the osteoblasts themselves look like thin flat formations, a little bit like the cambial layer of the periosteum. It is the stapes's head, where the process of bone-formation appears in the last turn. A characteristic feature is that here, together with the periosteous modification of the bone, there happen sections of intraosteal growth along the way of a vascular, growing into the head from the side of the stapes's leg, and it looks in it as a multi-layer tendon, which contains a great number of cell elements. A comparative analysis of D2Rm between US and Italy has not been performed. To investigate peculiarities & differences in D2Rm, UNOS and Italian D-MELD databases were merged (2002) (2003) (2004) (2005) (2006) (2007) (2008) (2009) . Pediatric cases, multiorgan Tx, SPLITs, living donor Tx, national share cases and DCDs were excluded. There were 36.795 cases (US = 31.569, ITALY = 5226). Donor age (X, IQR) was lower in US than in Italy (43, 25-55 vs. 56, 40-68) , MELD was higher in US than in Italy (20, 14-28 vs. 15, 11-21) . D-MELD was similar. Low D-MELD class (<338) was prevalent in Italy. High D-MELD class (>1628) was prevalent in US. Un-adjusted patient survival (PS) between US and Italy were similar. Long term predictors of PS at 6-year Cox regression were: Recipient age (Rage) 50-64 (HR 1.1, p = 0.038) Rage >64 (HR 1.6, p < 0.001) Ethnicity: caucasian versus afro-american (HR 0.9, p < 0.001) Acute liver failure (HR 1.8, p = 0.001), HCV (HR 1.5, p < 0.001), HBV (HR 0.8, p = 0.003), Cholestasis (HR 1.5, p < 0.001), Low D-MELD versus Intermediate D-MELD (HR 0.7, p < 0.001), High D-MELD versus Intermediate D-MELD (HR 1.8, p < 0.001), Portal thrombosis (HR 1.3, p < 0.001), Italy versus US (HR 0.9, p = 0.007); v 2 = 934. US versus Italy difference in adjusted PS was significant. D2Rm quantified by D-MELD remains a strong predictor of PS in US and Italy. The allocation of a graft from an elderly donor to an high-MELD patient, should be avoided especially if the recipient is HCV+. The Italian allocation system is more efficacious than the American one in the utilization of resources allowing better adjusted survival figures. Danick F. Gut, Franziska Beyeler, Franz F. Immer Swisstransplant Introduction: We evaluated from where our pediatric organs for liver transplant originate from. We compared the rates of split liver donation and child to child donation with deceased donor organs from Switzerland and from foreign offers, and also from living donation. We compared the waiting time for children and adults on the waiting list. Methods: We retrieved the data from the SOAS (Swiss Organ Allocation System). In the SOAS we have information concerning all donors and recipients. We evaluated the timeframe from the 1st of January 2008 to the 31st of December 2012. We considered all patients to be pediatric in the age range 0-16 years. From this data we compared the rates of split liver and child to child donations. We also compared where the organs came from. We compared the waiting time for children and adults on the waiting list. Results: In the study period 6% (n = 44) of the recipients listed were pediatric. Sixty-two percent (n = 21) of the pediatric recipients received a split liver transplantation. Thiry-eight percent (n = 13) of all pediatric transplantation were child to child donations. Thiry-eight percent (n = 13) of all pediatric transplantations were from foreign offers. The mortality for pediatric recipients remained at 0% in these five years. We did not evaluate the patients that were taken off the waiting list and then deceased. In 2012 there were no splits performed in Switzerland; but there was an increase of 54% from 2008 (n = 6) until 2011 (n = 11) in pediatric transplantations. 2012 showed a drop in pediatric transplantations, this is compatible with the low donor numbers in Switzerland in 2012. The waiting time for adults was longer (mean 254d/median 191d) than the waiting time for pediatric recipients (mean 90d/median 52.5d). Conclusions: In conclusion there is a very low mortality for children requiring a liver transplantation in Switzerland. This is in part due to an increase in split liver transplantation (n = 21/62% of all pediatric Tx) and Livers from foreign countries, mainly accepted in a critical medical situation (urgent, n = 7/53.8% of pediatric Tx from foreign offers) by the local liver transplantation program. PS04-ETHICS/LAW/PSYCHOSOCIAL/PUBLIC POLICY to which CIM is being implemented in Tx programs. We implemented the CIMI-BRIGHT in a large multi-continental study in heart Tx centers, i.e. the BRIGHT study, which will also allow to further evaluate its psychometric properties. Annemarie Nijboer, Andreas A Schnitzbauer, Frank Ulrich, Wolf Bechstein Klinikum der Johann Wolfgang Goethe-Universit € at Background: Volume-outcome relationships for transplant procedures has become one of the major topics in the discussions born from the organ transplantation scandal in Germany during the last six months. Proponents of the regulation argue, that highly specialized transplant centers may offer a higher quality but disregard the patients' wishes of a regionally available medical service. To investigate the relation between volume and outcome, in kidney, liver, and pancreas transplantation, a systematic review was performed. Methods: 27 February 2013, the MEDLINE and PubMed databases were searched for the search terms: "kidney / liver / pancreas transplantation, and "volume-outcome relationship". The bibliographies of articles meeting the eligibility criteria were examined to identify additional studies. Only articles in English and German were included. Results: Seventy-two articles were identified, of which seven articles were eligible. For renal transplantation different authors describe a significantly decreasing 3-month graft survival with decreasing center size. High-volume and medium (>100 transplants/year) transplant centers showed a significantly lower mortality rate, compared to low and very low volume (<60) centers. Furthermore, transplant surgeons' case mix was identified as a related factor; patients treated by "kidney only" transplant surgeons, were found to have an almost doubled operative mortality, compared to those treated by "multiorgan" transplant surgeons (1.7% vs. 0.9%). For liver transplantation various authors postulate a clear volume-outcome relation. Again, high-volume centers (>100) exceed low volume centers (<60-70), in the worst case with a 30% difference in mortality. Other authors report a cut-off of 20 transplants per year as the minimum acceptable standard. America's Medicare benchmark (minimum of 12 transplants/year, among other criteria), showed a significantly lower operative mortality. Pancreas transplant The largest study, analysing 6876 pancreas transplants failed to identify an outcome difference between low (<10), medium (10-20), high (21-50) and very high (>50) volume centers. Conclusion: This systematic review demonstrated a volume-outcome relationship for kidney, liver, and less extensively, pancreas transplantation. For liver transplantation a minimum of 20 transplantations was proposed more than 14 years ago. However, especially for Germany, volume-outcome relationships have to be discussed critically; taking into account quality (acceptable survival and a low rate of re-transplantation) on one hand, and regional supply factors on the other hand. We propose an extensive prospective analysis, of volume-outcome and regional distribution of transplant centers, as basis for future regulative decisions in the German transplant environment. Methods: During 1.5 quite intensive days participants were introduced to the principles of evidence-based practice through interactive lectures and small group discussions. They were taught how to critically appraise a paper on a therapeutic intervention, search common medical databases including the Transplant Library, and conduct a systematic review. Thereafter participants had to carry out a systematic review of Advagraf versus Prograf in small groups with some short cuts by going through the following steps: 1. Defining inclusion and exclusion criteria; 2. Designing search strategies for medical databases; 3. Selecting trials to include; 4. Critical appraisal and data extraction; 5. Constructing forest plots for outcomes; 6. Conclusions steps. The final step was a presentation of their findings. Results: The course was highly rated by participants, with 80% of participants rating the course as very good and 20% as good. In particular, the practical sessions including the systematic review workshop were greatly valued. Conclusions: Evidence-based practice skills essential to modern medical practice with high clinical standards can be taught in a comprehensive, Background: Last year, kidneys from a DCD donor were transplanted to two recipients, the post mortem examination undertaken after death revealed the cause of death as a rare intra-vascular high grade B -cell Lymphoma. Pre mortem, donor presented with reduced consciousness and a CT report stated a cerebral lesion. The Organ donation offer was made after a reported benign brain biopsy. Retrieval team did not report any pathology. Both recipients decided to keep the kidneys and were successfully treated with chemotherapy. The worldwide press reported this as a critical incident. Huge public response was noted for a universal disease screening prior to all offers. An urgent investigation was performed to assess the root cause with-in the Organ Donation and Transplantation Directorate. Results: Organs were offered after a documented Coroner's consent. A post mortem was done 2 days later, as a routine because of absence of a confirmed diagnosis as a cause of death. The Specialist Nurse in organ donation (SN-OD) referred the offer to Recipient Coordinator. Liverpool Centre based on the recorded contemporaneous notes accepted the kidneys. Electronic offering system (EOS) notes too made no reference to a possible lymphoma. Post mortem biopsy report 6 days post transplant showed high-grade intra-vascular B Cell lymphoma. Though liver was macroscopically normal but histology confirmed the lymphoma. On further review it was noted that the working diagnosis by the Intensivist was encephalitis and an abbreviation PCL (primary cerebral lymphoma) was used as one of the possible diagnoses. Consecutive teams possibly missed this abbreviation. It was also noted that SN-OD coordinating the donation was in training for SN-OD role. The possible errors were made at time of communication between the consecutive teams. Recommendations: Royal College of Pathologists has been contacted to expedite reporting and to immediately inform the NHSBT (NHS Blood and Transplant (NHSBT). As this case was a very rare lymphoma, it is not possible to place a separate screening recommendation for it. All offers need to be electronic and in event of verbal offers all conversation are now recorded. Full review of SN-OD Training shall be under taken. Background: Awareness of transplantation, as a treatment option, is an important part of medical training. We noted a knowledge gap amongst medical students and endeavoured to investigate and rectify this discrepancy. Methods: A questionnaire was sent to all final year medical students at our institution to establish awareness and attitudes towards transplantation. We asked specifically about exposure to transplantation, awareness of it as a treatment option and interest in the speciality. To raise awareness we ran an educational interactive session for all first year medical students focussing on the clinical, psycho-social, ethical and practical issues surrounding transplantation. Participants were an expert renal patient, renal psychologist, general practioner and transplant surgeon. In addition part of a recent documentary involving our patient's surgeon was screened. Feedback from the session was analysed and focus groups run, looking at longer term impact 9 months after the event. Results: We received 161 complete responses to the initial questionnaire and found only 30% had exposure or would get exposure to transplantation by the end of their training. After the education session 330 feedback forms were completed. They showed greatly increased awareness of the difficulties of renal failure and the positive effect of transplantation (95%). The results from the focus groups were analysed using thematic analysis and showed good understanding of the holistic impact of renal failure and the benefits of transplantation. Interestingly a theme of the importance of team working also emerged. Conclusion: An awareness of the impact of renal failure and the advantages of transplantation is important for medical practitioners. We used a novel method to instill the impact of renal disease into our first year students, and increased the knowledge, and we hope, acceptability of transplantation as an important means of managing renal failure in tomorrows doctors. Background: The internet and mass media have become increasingly popular means of providing information about transplantation. Other new trends in transplantation include paired and anonymous donation. Nephrologists' perceptions and attitudes regarding these trends in transplantation have not been well-explored. Methods/Materials: We used a web-based survey to investigate the perceptions of international nephrologists about five topics: (i) use of mass media for public education about kidney donation, (ii) use of media for promotion of kidney donation, (iii) use of the internet for solicitation of kidneys by patients, (iv) anonymous kidney donation, and (v) paired kidney donation. The relation between perceptions and demographic characteristics of 1280 nephrologists (age >50: 40%; female: 28%; rural practice: 11%; academic: 63%; transplant nephrologist: 51%) from 74 countries were examined by univariate and multivariable analyses. Results: Used of mass media to educate the public about deceased donation and living donation were favored by 98% and 94% of the respondents, respectively. Use of mass media campaigns to promote deceased organ donation and living organ donation were favored by 74% and 58% of the respondents, respectively. Practice in an academic setting was more likely to be associated with favoring media advertisements to promote deceased organ donation Background: Prior to 2009, the Northern Ireland (NI) transplantation service relied on cadaveric organs as the bedrock of activity. An inability to use organs retrieved after cardiac death combined with a reduction of numbers of organs from brain death donors impacted to create a rising waiting list. The NI population benefits from the preservation of a close extended family network and a strongly positive attitude to living donation. Methods: The need to increase transplantation numbers was identified and given logistical and financial support from the Department of Health. A "onestop" donor assessment clinic was instigated. This reduced the burden of multiple hospital attendances and made the donor pathway acceptable. The Birmingham transplant team were engaged on a peripatetic basis to provide a donor nephrectomy service on a regular basis "teaming up" with the Belfast team who provide the reimplantation service. To address succession planning for the NI unit, a surgical trainee was identified and received training in renal surgery by the Birmingham surgeons within their unit. Results: The rate of living donor transplantation has increased exponentially (2008; n = 9; 2013; n = 50) since 2009. This has resulted in the NI transplant waiting list becoming shorter. The live donor transplant rate for NI is double the national average (33.5 ppm). The trainee has performed in excess of 100 transplants and 50 nephrectomies and is well placed to sustain this output into the future. Conclusions: The Belfast-Birmingham relationship demonstrates how "twinning" of units can drive development. With appropriate logistical, political and financial support, this model may be transferable to similar units across Europe to increase transplant numbers and reduce waiting lists. Introduction: Only 0.8 per million populations donate organ for transplantation in Japan. This extreme shortage of donor organ insists the renal transplant waiting patients to expect longer than 15 years. Even after the change of transplantation act in 2010, total number of organ donor has not increased, although the percentages of brain dead donor increase. The number of end stage renal disease patients on the transplantation waiting list reached 12764 in Japan. Of these patients, 1741 (13.6%) have been waiting longer than 15 years. In our hospital, 18% of 256 waiting patients are as well. Most of these long-term waiting patients are high risk for renal transplant because of various complications due to long period of dialysis. It is mandatory to avoid the danger frequently encountered in transplant surgery and later. It is of course important to enlighten citizen to understand transplant medicine to increase the number of donation, but support these patients and their family to keep good condition. Methods: We started and continued the annual seminar of renal transplant from 1999, 14 years ago. We have expanded the object of this seminar to citizen. This seminar aims to spread better understanding about transplant medicine and to share the information to maintain health condition better in long period of dialysis life and to reduce their anxiety. In this seminar, the information about donation and transplantation by Japanese organ procurement organization and transplant doctors have been shared, also talk by transplant patients, group work and discussion.  Background: We have analyzed the efficacy of mammalian target of rapamycin inhibitor (mTORi) in patients with de novo malignancies or those trasplanted because of a primary liver cancer. Methods: A case-control study of patients with hepatocellular carcinoma (HCC; n = 119), cholangiocarcinoma (n = 1) or de novo malignancies (n = 73). Thirty-seven patients were treated with mTORi, and 167 with calcineurin inhibitors (CNI). Results: No incidence of rejection, serious adverse events, or death was observed with an overall actuarial survival of 68.5% in the mTORi group versus 45.7% among the CNI group. Tumor recurrence were 15.2% and 36.8%, respectively (p < 0.05). In HCC, survival was 100% of mTORi with and 61.5% among CNI patients, with tumor recurrence rates of 6.2% and 19.1%, respectively (p < 0.05) Conclusion: Differences in survival and tumor recurrence rates were observed. Switching from CNI to mTORi immunosuppressant therapy appeared to be safe. It's reasonable to employ this strategy in liver transplant. Basic data from 60 healthy volunteers. Follow up measurements at week 1,2,3,4 and month 3-120. Results: IMPDH activity increased with a high variability nearly 8 fold (318 vs. 2100 pmol/min/ml) in whole blood. In isolated lymphocytes the increase was up to 340% and higher in patients with rejection episodes; a decrease of IMPDH inhibition 3 to 43 months post tx. Background: The oral health of renal transplant recipients (RTR) can be affected by the oral manifestations of the chronic kidney disease as well as by oral complications related with transplantation. The aim of this study was to evaluate oral health status of RTR receiving tacrolimus (Tac) or everolimus (ERL) as immunossupressants, and living kidney donors (LKD) as healthy comparison group. Methods: Thirty-six RTR receiving Tac and 22 receiving ERL as well as 13 LKD were included in the study. Age, gender, literacy, body mass index, time since transplant and pharmacological data were recorded and oral health status was assessed through the evaluation of teeth, periodontal parameters, saliva, oral hygiene habits and oral symptoms. Results: RTR receiving Tac (39 AE 9 year) were younger than ERL (50 AE 11 year) and LKD (44 AE 9 year) groups (p = 0.001). The prevalence of female gender was higher in LKD group (p = 0.001). No differences were found among the three groups concerning oral hygiene habits, oral symptoms and smoking habits. Although DMFT index did not differ among groups (11 AE 7 vs 11 AE 6 vs 16 AE 8), visible plaque index was higher in Tac group (92 AE 21) than both ERL (82 AE 23) and LKD (83 AE 14) groups (p = 0.035). Also, bleeding on probing in Tac group (15 AE 20.7) was higher than ERL (5.5 AE 9.6) or LKD (9.9 AE 10.5) groups (p = 0.047). No differences were found in clinical attachment level (2.8 AE 0.6 vs 2.9 AE 0.7 vs 2.6 AE 0.7), unstimulated (UNS) and stimulated (SS)saliva flow rate (UNS: 0.43 AE 0.33 vs 0.41 AE 0.27 vs 0.35 AE 0.29; SS: 1.59 AE 0.9 vs 1.51 AE 0.9 vs 1.42 AE 0.81) and pH (UNS: 7.11 AE 0.46 vs 7.2 AE 0.61 vs 6.89 AE 0.46; SS: 7.72 AE 0.4 vs 7.8 AE 0.27 vs 7.65 AE 0.36) among the studied groups. Conclusions: Renal transplant recipients receiving ERL have lower periodontal inflammation than RTR receiving Tac and similar levels to LKD, suggesting that RTR receiving ERL may be better protected for the development of periodontal disease when compared to RTR receiving Tac. Stefano Vittorio Impedovo 1 , Michele Battaglia 1 , Giuseppe Grandaliano 2 , Carlo Bettocchi 1 , Loreto Gesualdo 3 , Francesco Paolo Selvaggi 1 , Antonio Schena 3 , Silvano Palazzo 1 , Floriana Giangrande 1 , Pasquale Ditonno 1 1 Department of Urology, Andrology and Kidney Transplantation Unit, University of Bari, Italy; 2 Department of Nephrology, Dialysis and Transplantation Unit, University of Foggia, Italy; 3 Department of Renal, Dialysis and Transplantation Unit, University of Bari, Italy Introduction: Non-compliance after kidney transplantation, represents a major concern, leading to a worst graft survival. Tacrolimus is an immunosuppressive drug, commonly used for rejection prophylaxis after kidney transplantation. In order to improve patient's compliance, a once daily dosing formulation of tacrolimus was developed. Herein, we compare the efficacy and safety of twice versus once daily tacrolimus formulation in de novo kidney transplant patients. Materials and Methods: we enrolled 174 patients who underwent kidney transplantations between January 2007 and December 2010. Patients were divided into two groups according to Tacrolimus formulation, once daily (QD, Group A, n = 85) and twice daily (BID, Group B, n = 89), both in combination with mycophenolate and corticosteroids and followed for 36 months. Results: We did not observe significant difference between groups in tacrolimus trough levels, graft function and blood glucose levels during the hospital stay and throughout the observational period. Acute rejection rate (5.9% in group A vs. 11.2% in group B), delayed graft function (36.9% in group A vs. 29.2% in group B), onset of post-transplant diabetes (5.8% in group A vs. 6.7% in group B) were similar in the two groups. Three patients treated with Tacrolimus BID developed graft failure, one due to recurrence of the underlying disease and two from non-compliance to therapy. We counted two exitus: one recipient of group A died because of severe acute respiratory syndrome by coronavirus, while another one of group B, died from urothelial cancer. Conclusion: in our experience tacrolimus QD was well tolerated with similar short and long term safety and efficacy profiles of tacrolimus BID. Reduction in the number of pills is the best condition to improve treatment compliance, potentially reducing graft failure. Aim: Given that Candida is a relevant opportunist microorganism, the aim of the present study was to evaluate oral Candida prevalence in renal transplant recipients (RTR) receiving cyclosporine (CsA), tacrolimus (Tac) or everolimus (ERL) as immunosuppressants and compare it with a control group, the living kidney donors (LKD). Methods: Twenty-seven RTR receiving CsA (13 men and 14 women, age 55 AE 8 years), 29 receiving Tac (15 men and 14 women, mean age 39 AE 9 years) and 22 receiving ERL (16 men and six women, mean age 50 AE 11 years) as well as 13 LKD (1 men and 12 women, mean age 44 AE 9 years years) participated voluntarily in the study. The number of decayed, missing and filled teeth (DMFT) index as well as saliva flow and pH were evaluated in all patients by a physician blind to the transplantation status and immunosuppressive treatment. Also, oral Candida prevalence was determined using stimulated saliva plated in CHROMagar TM Candida. Results: The DMFT index (p = 0.132), unstimulated saliva flow rate (p = 0.308) and pH (p = 0.200) as well as stimulated saliva flow rate (p = 0.551) and pH (p = 0.540) did not differ between RTR receiving CsA, Tac or ERL and LKD. Oral Candida prevalence did not differ between patients receiving CsA (37%), Tac (52%) or ERL (36%). Also, the mean value of oral Candida quantification was similar in patients receiving CsA (2.67 AE 0.22), Tac (2.77 AE 0.15) or ERL (2.48 AE 0.17). Additionally, oral Candida prevalence and quantification was similar between RTR (42%, 2.67 AE 0.10) and LKD (39%, 2.84 AE 0.38). Conclusions: Although is established that immunosuppressed individuals are more susceptible to opportunistic Candida infection, the oral Candida prevalence as member of normal microbiota does not seem to differ between RTR and LKD or between different immunosuppressive regimens. Background: Finding adequate tacrolimus (TAC) dosing is difficult to handle in the early post pediatric liver transplantation period due to TAC interindividual pharmacokinetic (PK) variability. This variability is largely influenced by the activity of (donor and recipient) P-glycoprotein (P-gp) and (donor) hepatic and (recipient) intestinal CYP3A4 and CYP3A5 enzymes. Single nucleotide polymorphisms (SNPs) in genes coding for CYP3A5 (6986A>G, CYP3A5*3), CYP3A4 (CYP3A4*22) and P-gp (ABCB1, 3435C>T, 2677G>T/A) could influence TAC PK. Therefore, both donor and recipient genetic background could explain a part of the TAC PK variability. We wanted to study the impact of these donor and recipient genotypes on TAC PK in a pediatric liver transplanted cohort. Methods: We retrospectively collected demographic and days 0-90 PK data from 83 children (0.5-14.3 years) who benefited from de novo living donor liver transplantation (2001) (2002) (2003) (2004) (2005) (2006) (2007) (2008) (2009) (2010) (2011) and were immunosuppressed with a Basiliximab induction and TAC monotherapy. Fifty recipients and 44 donors were genotyped for CYP3A4, CYP3A5 and ABCB1 SNPs. Results: As expected, donor CYP3A4*22 and CYP3A5*3 alleles were significantly associated with increased TAC trough level (C0) at days 3 and 10 (p = 0.008 and p = 0.024) and at day 10 (p = 0.021), respectively. At day 1 post transplantation, both C0 and dose-adjusted C0 displayed a significant reduction (p = 0.036 and p = 0.021, respectively) for recipients expressing CYP3A5*1 in their intestinal mucosa. Recipients with ABCB1 2677 TA and TT genotypes had higher C0 and dose-adjusted C0 at day 1 (p = 0.011 and p = 0.013). No effect of recipient or donor ABCB1 3435C>T SNP was observed. Conclusion: As recipient CYP3A5 and ABCB1 2677 genotypes influence the TAC PK at day 1, they should be proposed as covariates for TAC first dose prescription. Silvia Schaffellner, Doris Wagner, Estrella Jakoby, Daniela Kniepeiss, Florian Iberer Med. Uni. Graz Clinical Dep. of Transplantation Background/Aims: The optimal immunosuppression after liver transplantation (LT) is still controversially discussed. Sirolimus (SIR) as m TOR inhibitor has been proposed to provide a calcineurin inhibitor (CNI) free immunosuppression but was associated with various side effects recently. The aim of the presented analysis was to follow up a cohort of LT recipients on SIR. Methods: Patients after LT who received SIR off label over a time period of over 24 months as maintenance immunosuppression were included. Patients were worked up retrospectively. SIR was introduced originally in case of an existing renal impairment or hepatocellular carzinoma defined by the MDRD in combination to Mycophenolat Mofetil with target blood levels between 3-7 ng/ ml. Potential side effects like dyslipidemia, renal impairment, cancer development or disease recurrence and the development of infections were recorded. Results: Thirty-three patients were included into the analysis. Indications for LT were viral hepatitis (8), HCC (11) and alcoholic cirrhosis (14). The median time since LT was 8 a (2-15). Patients were on SIR based immunosuppression for 5.8 years at median (2-10). Sirolimus was administered due to HCC (10), viral hepatitis (13) and renal impairment. The median blood trough level of SIR was 4.5 ng/ml (2-7.1) with a median dose of 0.75 mg (0.5-1.5) SIR daily. None of the patients suffered an acute rejection or a recurrence of the viral disease or a HCC recurrence during the whole follow up. Five patients developed cancerous lesions (2 basaliomas, 1 prostatae cancer, 1 tongue cancer, 1 leukaemia). In total seven patients suffered from bacterial, nine from viral and two from fungal infections. None of the patients needed dialysis. Discussion: Sirolimus was safe and well tolerated as immunosuppression even in the longterm after LT. We did not observe severe side effects. This might be due to low trough levels of the administered therapy. Nevertheless the treatment was effective. Advagraf (Adv), a prolonged release formulation of tacrolimus (tac) permits a once a day administration and improves medication adherence. Patients (pts) possessing at least one CYP3A5*1 allele (also called CYP3A5 expressors) have an increased tac metabolism. This prospective study evaluates the clinical interest of a new simplified starting dose protocol of Adv right after RT according to The CYP3A5 genotype status of the KTR. Material and methods: CYP3A5 genotype (CYP3A5*1/*1, CYP3A5*1/*3, CYP3A5*3/*3) was determined at the time of HLA typing. All KTR received one Adv dose of 0.1 mg/kg prior to RT. On day 1, the Adv dose was adapted according to CYP3A5 genotype: 0.35 and 0.30 mg/kg/d in CYP3A5*1/*1 and CYP3A5*1/*3 respectively. CYP3A5 non expressors (CYP3A5*3/*3) were stratified to receive either 0.20 (control group) or 0.25 mg/kg/day. The daily dose (dd) remained unchanged during the first 3 days. The first tac trough level (TL) was determined at day 3 and the first dose adaptation performed on day 4. Associated therapy included MMF and CS. Pts needing plasma exchange because of prior sensitization were excluded. Kazunari Yoshida 1 , Daisuke Ishii 1 , Michiro Nakamura 2 , Junichi Teranishi 3 , Tatsuya Chikaraishi 4 , Hiroyasu Yamamoto 5 , Yuji Marui 6 , Yugo Shibagaki 7 , Hajime Suzuki 2 , Yoji Wakatabe 1 1 Kitasato University, Urology; 2 Tokai University, Transplantation Surgery; 3 Yokohama City University, Urology; 4 St Marianna @Medical University, Urology; 5 Atsugi Civic Hospital; 6 Toranomon Hospital, Kidney Center Surgery; 7 St Marianna Medical University, Nephrology Introduction: We expect good renal graft function and little incidence of viral infection by the regimen with everolimus (EVR). Primary de novo regimen with EVR and tacrolimus-extended release (TER) is, however reported only little. We conduct multi-central de novo regimen with EVR and TER. Method: Everolimus of 2 mg/day is initiated from 14 days after transplantation and control at the C0 of 5 ng/ml. PSL is started with 30 mg and gradually reduced to 2.5 mg by POD 30. TER is administrated with 0.15 mg/Kg and maintained with C0 level of 8 ng/ml until POD 14, then reduced to 5 ng/ml after EVR initiation. MMF is also reduced from 2000 to 1000 mg at same time. Other immunosuppressions are same as usual. We evaluated the results of the graft and patient survival, graft function, incidence of acute rejection, and adverse events such as CMV infection, proteinuria and dyslipidemia. Results: Entry cases were nine in 8 months. Mean age of the recipients were 47.2 years, M/F were 6/2, one was ABO incompatible, two were cadaver, HLA mismatch of AB/DR were 1.67/0.83. In all cases graft function result in good, the average eGFR were 34.3 ml/min. No BPAR, nor CMV infection were observed by mean follow-up of 6 months. Two cases had hyperlipidemia, and proteinuria of more than 1 g/day, stomatitis and wound trouble were occurred in one case each. The dose of EVR was unstable (1-3 mg/day) at beginning, but settled at 1-1.75 after two months. We had difficulty to control EVR and TAC dose, because C0 of EVR and TAC were certainly unstable (mean C0 of EVR: 4.78}1.76 (1.3'8.99 ) ng/ml),and C0/mg dose: 2.48}1.08. Special attention should be necessary for TER dose control when EVR is stopped because it flies high. Conclusion: EVR and TER de novo regimen for renal transplantation resulted in good graft function, little incidence of rejection and viral infection, but in some risks of dyslipidemia and proteinuria. We need attention to control dose of EVR and TER with frequent drug monitoring. Henry Whalen 1 , Julie Glen 1 , Alan Jardine 2 , Marc Clancy 1 1 NHS Greater Glasgow and Clyde; 2 Glasgow University Background: High intrapatient tacrolimus variability (ITV) has been associated with worse clinical outcomes post-renal transplantation. High tacrolimus levels cause toxicity, whilst sub-therapeutic tacrolimus levels predispose to acute rejection (AR) and graft loss. We investigated the effects of ITV 6-12 months post renal transplant on episodes of AR, eGFR at 1 year and rates of allograft failure. Methods: Data was collected for adult kidney transplants performed between 01/01/07 and 01/05/10. Patients 247 patients were included. Patients received Basiliximab at induction and triple therapy immunosuppression with prednisolone and mycophenolate. Target tacrolimus trough levels were 5-8 ng/dL. Median ITV 6-12 months post transplant was calculated according to the formula: {[(Xmean -X1) + (Xmean -X2)…..+(Xmean -Xn)] / n} / Xmean*100 = intra individual variability (%) (X mean is the mean tacrolimus level for all available samples, X1 is the first level available, X2 is the second, etc.) Patients were placed into High variability (HV) or Low Variability (LV) groups. HV was defined as variability > observed median and LV as. Background: DCD kidneys have a high incidence and suffer from a longer period of DGF compared to DBD kidneys. Avoiding early rejection in those patients might be even more important since it avoids additional injury and might also ameliorate the need for weekly biopsies during the duration of DGF. Aim of the study was to see if induction with ATG confers an advantage in terms of rejection in DCD kidneys compared to patients who received Basiliximab without increasing their morbidity. Methods: This is a non-randomised observational study in patients transplanted in two different periods who received a DCD kidney and different inductions. Group A (n = 77) received ATG induction for 5 days (1.25 mg/kg/ day). Group B (n = 36) received Basiliximab (20 mg on day 0 and day 4). Both groups received Tacrolimus to achieve levels of 4-8, Mycophenolate Sodium (up to 1 g BD) or Mycophenolate Acid (up to 720 mg BD), and 20 mg of steroids tapered down to 0, 3 months post transplant. Results: The baseline characteristics were similar apart from total mismatches that were higher in the ATG group. One patient died in the Basiliximab and two in the ATG group. There were no patients with CMV disease in the ATG group and 1 in the Simulect group. There were two cases of BK viraemia in group B, and 1 in group A and 47.4% of the ATG group still received steroids at 12 months compared to 58% in the Simulect group. DGF, graft survival and acute rejections are summarized in table. Conclusion: ATG induction in DCD kidneys is safe and results in significantly lower rejection rate, same graft survival and marginally better 1 year Creatinine Clearance. Immunosuppression is accepted as a major risk for BK virus replication. The increased incidence of BK virus infection in kidney transplant recipients (KTR), coincidental with the introduction of tacrolimus /mycophenolic acid (Tac/MPA) immunosuppression, has emerged as an important cause of graft damage and loss. However, the specific contribution of individual medications to this risk has not been well established. To evaluate that, we have analyzed with serial (1-6, 9 and 12 mos.) quantitative PCR, the incidence of BK replication in urine and blood and its correlation with: (i) the usage of induction (anti IL2 receptor antibodies versus Thymoglobulin/Rituximab (Thy/Rit)) in 271 KTR on Tac/ MMF/Pred protocol (groups A -213 KTR and B -58 KTR, respectively); and (ii) the blood levels of Tac or MPA in 53 additional KTR, receiving the same protocol as group A, in whom MPA levels were available (group C). The therapeutic and high levels of Tac and MPA were considered to be 6-12 ng/ml and >12 ng/ml and 30-40 ng/ml and > 60 ng/ml, respectively. PCR lowest, high and upper values of detection were 325, 10 000 and 3 250 000 copies/ml, respectively. The statistical significance was determined with Fisher's exact test. In urine and blood the BK prevalence <10 000 copies/ml was 14% and 24% in groups A and B (p 0.04) respectively, and 32% in group C (p 0.04 with group A and p 0.4 with group B), respectively. The prevalence of high viral load in blood was 21%, 35.7% and 0% in groups A, B and C (p 0.3 for group A vs. B (p 0.0002 for A and B vs. C), respectively. With regard to Tac and MPA levels, 10 and 12 instances of high levels were found respectively in 35 patients without BK, while 6 and 16 of such instances were detected in 18 patients with BK (p 0.7 for FK and p 0.0002 for MPA). We conclude, that Thy/Rit induction, or high MPA, but not Tac levels, were associated with a significant increase in BK viral prevalence. Background: Tacrolimus has originally been registered as a twice-daily formulation (Prograf, Tac BID). More recently, a once-daily formulation (Advagraf, Tac QD) is also available. It has been suggested to have a reduced intra-patient variability (expressed as coefficient of variation, CV) of Tac Cmin, Cmin is a surrogate marker for 24-h drug exposure (AUC0-24). Improvement of CV can be caused by better adherence or by different intrinsic pharmacokinetic properties of the formulations. The change in CV of AUC0-24 by conversion has never been studied prospectively yet. The main purpose of this study was to investigate the change in CV of Tac AUC0-24 after conversion from Tac BID to Tac QD. Methods/Materials: Forty stable renal transplant patients on Tac BID were converted on a 1:1 (mg:mg) basis to Tac QD in an investigator-driven comparative pharmacokinetic study. AUC0-24 was determined five times, both before and after conversion, where each PK-profile consists of eight samples. Samples were collected in duplo by the patients themselves using the Dried Bloodspot method. Main outcome measure is change in intra-patient CV of AUC0-24. Moreover, the influence of Cyp3a5 genotype polymorphism on change in CV was studied. Results: All patients had 10 adequate PK-profiles; in total 400 AUC0-24 were available for analyses. Conversion to Tac QD resulted in a significant improvement of intra-patient CV from 14.1% to 10.9% (p = 0.012). Patients with the Cyp3A5 *1/*3 genotype (n = 11) had a numerically larger improvement in CV (18.2% to 12.8%; p = 0.066) than patients with the CYP3A5 *3/*3 genotype (12.6% to 10.2%; p= ns). Conclusion: The intra-patient CV of Tac AUC0-24 is improved after conversion of Tac BID to Tac QD in stable renal transplant patients, especially in patient with the CYP3A5*1/3 genotype. Given the very strict protocol of this PK study, this improvement is most likely due to different intrinsic pharmacokinetic properties of Tac QD compared to Tac BID. Osama Gheith, Torki Al-Otaibi, Narayanan M.R. Nampoory, Medhat Halim, Tarek Said, Zakareya Zakareya, Prasad Nair, Waleed Hosni, Hani Adel OTC Introduction: Obesity has been associated with poor graft and patient survival after kidney transplantation, requiring functional increase of antirejection drugs. Weight loss surgery may be a good alternative in this clinical scenario. Aim of the study: To assess the outcomes of bariatric procedures performed in patients after renal transplantation compared to conventional group of patients. Patients and Methods: In this retrospective study, collected database was conducted to analyze the outcomes of obese patients after kidney transplantation (BMI>38) who underwent bariatric procedures during the last 5 years (n = 11cases) in comparison to controlled obese group without this type of surgery (n = 41 cases). Roux-en-Y gastric bypass was the most common procedure. We aimed to evaluate this type of surgery among renal transplant patients in comparison to control group. Results: The two groups of patients were matched regarding their demographic data, type of donor, cases with IHD, type of induction and maintenance of immunosuppression. Most of patients in bariatric group were females (60%) while males dominated the other group (84%, p = 0.03). The basal and last follow up BMI means were 38.3 A AE 8.9 and 33.3 A AE 7.3; while they were 44.2 AE 5.6 and 44.2 AE 6.7 in the control group. The mean percentage of excess weight loss at 6 months in bariatric group was 15.4 A AE 5.1% vs. 0.4 A AE 0.2% in the control group (p < 0.001). We found no significant difference in the two groups regarding number of cases with pre-transplant diabetes or NODAT, however the total number of diabetics in the control group was significantly higher (73.3% vs. 40%, p = 0.042). Moreover, we observed that rejection episodes, graft and patient outcomes were similar in both groups (p > 0.05). There were no postoperative complications except in two patients: one with strangulated hernia; and the second with postoperative deep venous thrombosis and pulmonary embolism. Conclusion: Bariatric surgical techniques may be used safely and effectivelywith some precautions-to control obesity among renal transplant recipients. Further improvement in metabolic parameters and long term patient and graft outcome can be observed only with longer and larger studies. Background: We conducted a randomized trial to determine whether epithelial to mesenchymal transition (EMT) markers would help to identify kidney transplant (tx) recipients at such a high risk of graft fibrogenesis that they would benefit from an early withdrawal of calcineurin inhibitor (CNI). Methods/Materials: Initial treatment consisted in CsA, mycophenolate sodium (MPS), corticosteroids and basiliximab. We measured by immunohistochemistry the de novo expression of vimentin and the translocation of betacatenin in tubular epithelial cells, on a first biopsy performed at 3 months posttx. A biopsy in which ıΥ10% of tubules expressed mesenchymal markers defined EMT+ patients (pts). We randomly assigned both EMT+ (n = 75) and EMT-(n = 119) pts to either continue CsA+full dose MPS (n = 98), or to withdraw CsA and to start on everolimus+low dose MPS (EVL/CNI-free) (n = 96). Results: Study objective was to evaluate if the progression of interstitial fibrosis (IF) between the first and a second surveillance biopsy performed at 12 months post-Tx would be attenuated in EMT+ pts converted to a CNI-free regimen, when compared to those maintained on CsA. The primary endpoint (PE) was the progression of IF and tubular atrophy (TA) Banff score from M3 to M12 (DIF/TA≥1). In the modified intent-to-treat analysis (pts with adequate structural data at M3 & M12), the PE occurred in 16 of the 31 EMT+ pts maintained on CsA and in 12 of the 26 EMT+ pts converted to EVL/CNI-free (p = 0.68). Overall biopsy proven acute rejection (BPAR) occurred more frequently in the EVL/CNI-free group (25.0 vs. 5.1%, p < 0.001). Of these, subclinical BPAR was diagnosed on M12 biopsy in 10.4% of the EVL/CNI-free pts and 2.0% of the CsA pts (p = 0.015). Independent associated factor of BPAR was a dose of MPS inferior to the recommended one (720 mg/day in the EVL/CNI-free, 1440 mg in the CsA group) during >28 consecutive days. Pts with a trough level of EVL < 5.7 ng/ml were also particularly at risk of BPAR (8/ 22, 36.4%) . Graft loss occurred in 5 pts in the EVL/CNI-free group (vs. 1 in the CsA group, p = 0.12). Conclusion: An early CNI withdrawal with a switch from CsA to EVL does not prevent IF progression in patients at high fibrogenic risk and carries out a significant risk of rejection. Aims: This study sought to investigate the role of SNP CYP3A5(rs776746) and MDR1(rs1045642) on pharmacokinetics of prolonged-release tacrolimus (TAC-OD). Methods: N = 69 stable liver transplanted patients were converted from TAC twice daily (TAC-BID) to TAC-OD. TAC doses and trough levels were determined at regular time intervals between baseline and month 6 postcon-version. Sequencing of PCR-amplified genomic DNA was used to determine the recipients' genotype. Kruskal-Wallis test was performed to compare subgroups of patients with different genotypes. T-test or Mann-Whitney-U-test was used to compare continuous data. Results: TAC-OD doses differed significantly according to CYP3A5 genotype at week 1 (p = 0.03), week 2 (p = 0.03), month 1 (p = 0.02) and month 3 (p = 0.04). Patients with G/G-SNP required significantly lower doses of TAC-OD than those with G/A-and A/A-genotypes (p < 0.05 at each time point). Moreover, there was a significant difference regarding the dose requirements of TAC-OD at month 6 for MDR1 genotypes (p = 0.02). Patients with C/Cgenotype needed to be dosed significantly higher at month 6 (4.7 AE 1.96 mg vs. 3.3 AE 1.69 mg, p = 0.01) than those with other genotypes. Conclusion: The recipients' CYP3A5 and MDR1 genotypes seem to affect the function of enzymes in TAC metabolism; this may explain differences in TAC pharmacokinetics among transplant patients. Background: Kidney transplantation is the cure for end-stage renal diseases. The availability of organs is a scarce resource and is the real limit to a wider diffusion of organ replacement. Tissue engineering holds the promise to offer a potentially inexhaustible source of transplantable organs. Material and Methods: Renal extra-cellular matrix (ECM) (n = 10) scaffolds were obtained in 4 h with decellularization of rat kidneys by sequential peristaltic perfusion of Triton X-100 and SDS-based solutions. In a second step the scaffold was implanted in a in a same-species recipient as it is, without any attempt to seed functional parenchymal cells. Results: Preliminary results show the protocol feasibility. Kidneys were successfully and consistently decellularized while ECM framework remained well preserved. At the reperfusion ECM scaffolds reperfused well and sustained blood pressure. It was not observed any bleeding and the graft was normally perfused. Histological findings demonstrated the absence of cells and the maintenance of the entire 3D extra-cellular matrix. Conclusions: Rat renal ECM scaffolds may represent an optimal platform for renal bioengineering and regeneration research. Background: The kidney is the most frequently transplanted organ, yet few studies have focused on kidney tissue engineering. We compared three decellularization protocols in rat kidneys to create extracellular matrix (ECM) scaffolds for tissue engineering applications. We have further analyzed these scaffolds using rigorous methods for: (i) retention of critical matrix structures, (ii) efficient removal of cells and (iii) presence of structural and growth factor proteins. Methods/Material: Three different protocols were used: Triton only (P1), Triton and SDS (P2) and Triton and Trypsin (P3). Hematoxylin & eosin (H&E) staining and scanning electron microscopy (SEM) was used to characterize the ECM. The presence of ECM structural proteins was analyzed by immunofluorescence and growth factors were determined by ELISA. Results: After decellularization, kidneys were transparent and cells were not present in H&E staining (P2 and P3). The structure of glomeruli and tubules remained intact and was confirmed by SEM. Immunostaining showed the presence of collagen IV. FGF was detectable in P1 and P2. Conclusions: P2 and P3 showed high efficiency of cell removal while maintaining preservation of the kidney architecture. However, P1 and P2 demonstrated retention of FGF. Taken together, the use of triton and SDS efficiently removes cells and retains FGF after decellularization in rat kidneys. This provides a basis for repopulating the parenchyma with renal progenitor and endothelial cells. Background: IL-6 is one of the key inflammatory mediators. The role of IL-6 in the rejection reaction is not fully understood. Methods/Materials: We have studied the role of IL-6 in the pathogenesis of rejection. Results: Transplantation outcomes are largely determined by the activity of rejection. Great importance is the regulatory influence CD4-cells. Now known another type of T-helper cells: Th17. These cells can secrete IL-17 and come from the naive T-cells in response to IL-6 and transforming growth factorstimulation. In the absence of TGF stimulation of naive T cells to differentiate into regulatory T cells -Tregs, expressing Foxp3, which is the opposite effect of Th17. IL-6 synergistically with TNFa prevent the development of tolerance to the transplant tissue. Conclusion: Thus, IL-6 is an important mediator in the process of rejection. This may be a new target for specific therapy. IRF3 and IRF7 proteins regulate transcription of IFNs. Both can be induced by several factors in lymphoid cells and tissues. IFN a gene family is IRF7 dependent and we reported a higher production during acute rejections (AR) in human kidney transplants (KTX). KTX were divided into group I, rejection free and AR between day 6 and 4 years, group II. Aspiration biopsy (AB) was done on day 7 in I and on rejection day in II. Cytoslides were stained by a goat polyclonal IgG anti-human IRF3 and IRF7 by ABC. For IRF3, I and II included 39 and 15 cases and for IRF7, included 21 in I and 13 cases in II. IRF3 and IRF7 expression were higher in II whether +cells, p = 0.0002 and p = 0.0009, +/kidney cells p = 0.000, p = 0.002, or +/mononuclear cells, p = 0.000 and p = 0.0002 ratio, respectively. These results indirectly confirm our previous report on the importance of IFN-alpha in acute rejection of KTX and surmises the place unspecific, inflammatory, non cognate stimuli may find in the early fate of KTX. Christoph Tschuor, Ekaterina Kachaylo, Perparim Limani, Andrea Schlegel, Jae Hwi Jang, Dimitri A. Raptis, Emmanuel Melloul, Michael Linecker, Andrea Vuck, Yinghua Tian, Rolf Graf, Bostjan Humar, Pierre-Alain Clavien Swiss Hepato-Pancreatico-Biliary (HPB) Center, Department of Visceral and Transplant Surgery, Univer Background: Living donors left with marginal liver remnants or recipients of small/poor quality liver grafts are at risk of developing the Small-for-Size-Syndrome (SFSS). SFSS is characterized by an insufficient regeneration of liver mass. Constitutive androstane receptor (CAR) agonism induces liver hyperplasia. We investigated the potential of the CAR agonist TCPOBOP (TCP) to ameliorate experimental SFSS. Methods: The effects of TCP were assessed in three murine models: 30% graft liver transplantation (0% survival), 86% Hx (75% survival) and 91% Hx (0% survival). Bilirubin, ALKP, and albumin served as measures of SFSS-like features. Proliferation-associated-molecules, including Foxm1b and miR375dependent pathways, were analyzed. Results: TCP markedly improved survival following 30% transplantation, 86% Hx and 91% Hx. Likewise, SFSS-associated features of bilirubinemia and reduced liver function were normalized by TCP. Furthermore, TCP reversed the abnormal induction of the Foxm1b/miR375 pathways, normalized upregulated p21 and restored the deficient regeneration. Conclusions: TCP can prevent experimental SFSS. When given after extended resection or 30% graft liver transplantation, TCP rescues >40% of otherwise moribund mice. The underlying molecular changes suggest a contribution of pathways promoting cell cycle progression. TCP appears to override the regenerative deficits of marginal liver remnants. Innate inflammatory response either preexistent in the recipient or released by injured allografts may influence graft outcome. We retrospectively evaluated the influence of Kynurenine, HMGB-1, C5b-9 and IL-33 on delayed graft function (DGF), acute rejection (AR) and the long term outcome (GS). Patients and Methods: A consecutive group of patients after renal transplantation (in total n = 122, mean age 42 + 11 years). Probes were taken prior tx 0, wk1, wk2, wk3, wk4 and month3. Results: HMGB-1 was predictive for DGF (donor) and correlated with duration of pop dialysis need. C5b-9, Kynurenin and HMGB-1 (p < 0.001) were significant elevated during DGF, but not IL-33. IL-33 was significant higher after 3 months in the DGF group. Predictive values for rejection were only given by Kynurenine. IL-33 was significant increased during AR. High IL-33 in the long-term (>3rd month) is correlated with a higher creatinine after 1-3 years (r 2 = 0.685). Prolonged GS was only predicted by Kynurenine and lower IL-33. Conclusion: Kynurenine showed an excellent correlation to acute rejection as well as to long term graft function. HMGB-1 showed significant the injury of the graft and IL-33 showed a correlation to the graft function in the follow up <3 months. Hani Oweira, Imad Lahdou University Hospital of Heidelberg Background: The Model for End-Stage Liver Disease (MELD) score is a wellestablished tool to assess the degree of hepatic insufficiency/ failure. Neopterin, a pteridine mainly synthesized by activated macrophages, is a marker of inflammation and immune system activation. Here we investigate whether the degree of systemic inflammation as measured by Neopterin and other parameters correlate with clinical liver dysfunction according to MELD scoring system. Method: Serum samples from 180 patients with liver cirrhosis were categorized in two groups according to baseline MELD score (group I, MELD <20) and (group II, MELD ≥20). Serum levels of CRP, sCD30, and neopterin were assessed by ELISA. Results: Serum levels of neopterin,and CRP, significantly correlated with MELD score whereas sCD30 showed no significant correlation. Rafael Simas, Isaac Azevedo Silva, Laura Menegat, Sueli Gomes Ferreira, Cristianode Jesus Correia, Paulina Sannomiya, Luiz Felipe Moreira Cardiovasc. Surg. and Circ. Pathophysiol. Lab., Heart Institute (Incor), University of Sao Paulo Background: Brain death (BD) is usually followed by autonomic changes leading to hemodynamic instability, which seems to be associated with microcirculatory dysfunction and inflammatory activation. In this study, we evaluated the effects of autonomic storm inhibition by thoracic epidural anesthesia (TEA) on mesenteric microcirculatory changes and inflammatory response due to BD induction in rats. Methods: Male Wistar rats (250-350 g) were anesthetized and mechanically ventilated. BD was induced by intracranial balloon inflation. An epidural catheter was placed to saline or bupivacaine infusion immediately before BD induction and these two groups were compared to sham operated animals. Mesenteric microcirculation was analyzed by intravital microscopy and the expression of adhesion molecules was evaluated 180 min after BD induction. Results: Autonomic storm was blockade in bupivacaine group, with a significant difference in mean arterial pressure behavior in comparison with saline and sham groups (p < 0.001). However, proportion of perfused small vessels (<30 lm) in this group (43 AE 6%) was similar to BD with saline infusion (39 AE 7%) and lower than sham animals (74 AE 6%, p = 0.002). The expression of ICAM-1 did not differ among bupivacaine and saline groups (21 AE 5 and 23 AE 8, respectively) and these values were significantly higher than sham obtained data (9 AE 2, p < 0.001). Bupivacaine and saline groups also showed similar numbers of migrated leucocytes in perivascular tissue, which were significantly higher than those observed in sham operated animals. Conclusions: TEA was effective to inhibit autonomic storm, but it did not affect mesenteric hypoperfusion and inflammatory changes after BD induction in rats. Introduction: Representing a crucial T-helper 1 cytokine, IFN-c acts as an important bridge between innate and adaptive immunity and is involved in many acute and chronic pathologic states, such as autoimmune diseases and solid organ transplant rejection. At present, debate still prevails about the ability of human monocytes to produce IFN-c. We aimed to investigate whether human monocytes possess the capacity to produce IFN-c at mRNA and protein level. Materials and Methods: Using flow cytometric analysis and real time PCR, we investigated the capacity of freshly, isolated CD14 + monocytes of kidney transplant recipients to produce IFN-c after stimulation with IFN-c and LPS or LPS alone. Results: We observed that stimulation of freshly isolated CD14 + human monocytes with LPS alone or combined stimulation with IFN-c and LPS led to a significant increase in the percentage of TNF-a-and IFN-c-producing monocytes (p < 0.05). In addition, IFN-c mRNA levels in CD14 + monocytes increased after 2 h of stimulation as compared to the unstimulated controls. Moreover, these monocytes did not show a shift towards CD68 positivity. Conclusion: We conclude that human monocytes possess the capacity to produce IFN-c. Nicolas Degauque 1 , Annie Elong Ngono 1 , Ahmed Akl 1 , Romain Crochette 1 , Julie Lepourry 1 , Magali Giral-Classe 1 , St ephanie Castagnet 1 , Emilie Dugast 1 , Anne Devys 2 , David Laplaud 1 , Arnaud Nicot 1 , Sophie Brouard 1 , Jean-Paul Soulillou 1 1 INSERM UMR1064; 2 EFS de Nantes Background: Whereas antigen-specific antibodies have been extensively characterized, estimation of frequency, isolation and analysis of B cells with a defined antigen receptor remain a challenge. Here, we describe a new approach to quantify and characterize B cells engaging interaction with an antigen following the incubation with single or multiplex single antigen beads. Methods: B cells were purified from human anti-MOG IGH transgeneic mice, healthy volunteers (n = 38) and patients with known immunization against HLA molecules (n = 34). B cells reactivity was assessed using nominal antigen coated beads Results: Using B cells purified from human anti-MOG IGH transgeneic mice, we show that interaction between B cells and rMOG coated beads can be measured and inhibited by soluble MOG. Blood B cells purified from healthy volunteers were then tested for their ability to interact with various nominal antigens, including viral, vaccine or self and alloantigens. The frequency of B cells of male individuals interacting with the panel of HLA class I molecules was similar to the frequency of B cells interacting with Albumin (mean AE SEM; 0.73 AE 0.17 vs. 0.61 AE 0.09 respectively). An increase frequency of B cell bound to self-antigen MOG (1.53 AE 0.16%), latent EBV antigen (EBNA1; 6.02 AE 0.69%) and tetanus toxin (6.44 AE 0.88%) coated beads was measured. The B cell frequency in a context of over immunization against HLA antigens was finally tested. A significantly higher anti-HLA-A*0201 BBR frequency in HLA-A*0201 sensitized recipients compared to non-sensitized stable patients and healthy volunteers was detected. An important level of polyreactivity of the circulating B cells was observed when antigens with minor differences are tested. Finally, we show that both memory and resting B cells were able to bind to antigen-coated beads. Background: Malignancy remains a serious cause of morbidity and mortality in transplant recipients, with incidence rates 3 -5 times higher than the general population. Of these, cutaneous squamous cell carcinoma (cSCC) is the most common cancer post-transplantation, with 30% of kidney transplant recipients (KTR's) developing at least one within 10 years of transplantation. In a previous study we have shown that high numbers of T-regulatory (Treg) and low numbers of Natural Killer (NK) cells in patients could predict cSCC development in KTR's (Carroll, R. P. et al. NEJM 2010) . In this follow-up study we aimed to validate these results and ensure immune biomarker stability in patients on long-term immunosuppression. Materials/Methods: We followed up previously gender, age, and duration of immunosuppression matched KTR's with (n = 65) and without (n = 51) cSCC. During the follow up period (mean time = 1535 days) 36 KTR's from previous SCC group and 28 previously were re-assessed for known risk factors of cSCC and bled for assessment using multi-parameter flow cytometry of lymphocyte subsets. Results: We found a higher proportion of Treg cells in patients with a history of SCC compared with those without (p = 0.03). No significant difference was identified between the proportion or number of NK cells between those with previous SCC and those without. Importantly we found no significant change in the proportions of T lymphocyte subsets in SCC or non-SCC group over the follow-up time. Interestingly, patients who are on Azathioprine have significantly reduced proportion and numbers of NK cells (Both p > 0.01). We found no difference in Treg numbers between immunosuppressive regimens. Conclusion: Overall we have shown that monitoring of the immune system in these patients can provide insight into patients at an increased risk of developing a post-transplant malignancy. Furthermore, these immune markers remain stable over time despite chronic immunosuppression use. Background: Tolerance induction through mixed chimerism holds promise for clinical translation but has only been investigated in young recipients so far. Therefore we investigated the consequences of recipient age on the outcome of mixed chimerism and tolerance induction. Methods: Young (2mth; 20 g) and old (12mth; 30 g) recipients (B6) were treated with 5 different BMT protocols. In each protocols recipients were transplanted with Balb/c BM cells adjusted to body weight (1 9 103/kg, i.e. young 20 9 106; old 30 9 106). 3 Gy TBI and an induction treatment of costimulation-blockade (CB: a-CD154mAb; CTLA4Ig) or T cell depletion (TCD: a-CD4; a-CD8), 1 Gy and CB or rapamycin and without irradiation and rapamycin. Lymphocyte subsets and cytokine production were compared between young and old na€ ıve mice and multi-lineage chimerism was assessed by flow cytometry. Results: Successful chimeras were achieved age-independently following non-myeloablative TBI (3 Gy) together with CB (7/8 old vs. 11/11 young). Of note, following T-cell-depletion chimerism levels were significantly higher in older recipients in all tested lineages (i.e. donor B-cell chimerism: 56.33% old vs. 18.17% young; p < 0.0001; by week 8 after BMT). Moreover, under a less vigorous conditioning regimen (1 Gy/CB), chimerism was achieved in most animals in an age-independent fashion (7/10 old vs. 6/6 young). In contrast, 1 Gy irradiation in combination with rapamycin led to chimerism in only 2/6 old recipients and none of the young recipients; neither old nor young recipients became chimeric when animals were only treated with rapamycin. Notably, frequencies of Tregs among splenocytes of old BMT recipients had significantly increased. Moreover, T cell proliferation and IFN-c production after polyclonal but not allogeneic stimulation was increased in old mice. Conclusion: BM engraftment and chimerism were successfully induced in older recipients through Treg maintenance and a reduced alloreactivity response. Introduction: Renal tubular epithelial cells (TECs) are one of the main targets of infiltrating T cells. Indoleamine 2,3-dioxygenase (IDO) has been shown to inhibit allogeneic T-cell proliferation. We hypothesise that renal TECs modulate alloactivated T-cell proliferation via IDO. Methods/Materials: Primary human TECs were prestimulated with IFN-c and TNF-a for 3 days to upregulate IDO. In the absence or presence of IDO inhibitor 1-methyl-L-tryptophan (1-MT), we tested the inhibitory effect of TECs on allogeneic and anti-CD3/CD28 induced proliferation of T cells. Results: Activated TECs inhibited the allogeneic T-cell proliferation by 56%, while antiCD3/CD28 induced T-cell proliferation was inhibited by 95%. Preactivated TECs show IDO mRNA expression while unstimulated TECs did not. This expression was inhibited by 1-MT. Addition of the IDO inhibitor resulted in the recovery of allogeneic T-cell proliferation in a dose dependent manner, while only 50% recovery was found in the antiCD3/CD28 induced T-cell proliferation. Conclusion: IFN-c/TNF-a preactivated TECs inhibit allogeneic induced T-cell proliferation. Our results indicate a crucial role for IDO as the underlying mechanism for this effect of TECs, and provide a potential immunosuppressive mechanism of TECs during renal allograft rejection. Ana Cristina Breithaupt-Faloppa 1 , Sueli Gomes Ferreira 1 , Micael Nunes da Silva 1 , Cristianode Jesus Correia 1 , Wothan Tavares-de-Lima 2 , Paulina Sannomiya 1 , Luiz Felipe Moreira 1 1 Cardiovasc. Surg. and Circ. Pathophysiol. Lab., Heart Institute (Incor), University of Sao Paulo; 2 Department of Pharmacology, Institute of Biomedical Sciences, University of Sao Paulo Rattionale: Brain death (BD) triggers the immune system which is characterized by the expression of inflammatory mediators, edema and cell infiltration to the organs. There is evidence that the immune response differs between men and women, which could influence the donor state and the results of the transplant. Here we investigated the differences between the genders regarding the evolution of the inflammatory process in different organs and mesenteric microcirculatory changes in a model of BD in rats. Methods: BD was induced by a sudden increase in intracranial pressure by rapid inflation of a ballon catheter in the extradural space. Groups of female in proestrus (time of maximal estradiol secretion) or estrus, and male rats were used throughout the experiments. Vascular permeability and myeloperoxidase (MPO) activity were assessed at 6 h as markers of organ inflammation. White blood cell counts and estradiol levels were analyzed. Mesenteric microcirculatory perfusion was observed after 3 h using intravital microscopy. Results: Lung (L) and kidney (K) vascular permeability were increased in proestrus female (L = 172€ ı¿½10, K = 274€ ı¿½17) compared to male rats (L = 105€ ı¿½8, K = 154€ ı¿½28; p < 0.05). Regarding MPO activity, liver of female proestrus presented higher activity (1.03€ ı¿½0.15 ) when compared to male (0.55€ ı¿½0.09, p < 0.05). Male rats showed pronounced leukopenia (7880€ ı¿½689 cell/mm3), while proestrus female rats maintained the circulating cell number after 6 h (11567€ ı¿½1628 cell/mm3). Despite organ inflammation, proestrus female rats maintained the proportion of perfused small vessels (78.6€ ı¿½3.5%) 3 h after BD, whereas estrus female (50.4€ ı¿½8.9%, p < 0.05) and male rats (39%€ ı¿½7, p < 0.01) presented hypoperfusion. Conclusions: Our results evidenced important differences between genders after BD, suggesting that estradiol may exert a role on the inflammatory events triggered by BD and deserve, therefore, attention as a potential factor influencing the organ status. Supported by CNPq and FAPESP. Background: Brain death (BD) is associated with increased inflammatory response in the different organs. In this study, we evaluated the recruitment of bone marrow cells to peripheral blood in rats submitted to BD compared with BD-associated trauma. Methods: Male Wistar rats (250-350 g) were anesthetized and mechanically ventilated. A balloon catheter was placed into intracranial cavity, through trepanation, and quickly inflated to induce BD. Sham operated rats (SH) were trepanned only. Bone marrow cells were obtained by flushing the femoral cavity with Iscoves medium 6 h thereafter. White blood cell (WBC) counts in the peripheral blood were determined at baseline, and after 3 and 6 h. Total bone marrow cells and WBC counts were determined using a hemocytometer. Differential counts were performed on smears stained with May-Grunwald Giemsa solution. Results: BD rats exhibited a progressive leucopenia (Baseline: 13171€ ı¿½1377; 3 h: 11086€ ı¿½1779; 6 h: 8300€ ı¿½927 cells/mm3), in contrast with SH group (Baseline: 12863€ ı¿½1283; 3 h: 17013€ ı¿½6186; 6 h: 17353€ ı¿½8286 cells/mm3, p = 0.012). The leucopenia observed in BD animals was also associated with lower values for neutrophil/lymphocyte ratio in comparison with the values observed in SH rats at 6 h (p = 0.004). BD rats showed a significant reduction in the total number of bone marrow cells (2.8€ ı¿½0.2 9 107 cells/ml) compared with SH animals (4.9€ ı¿½0.9 9 107 cells/ ml, p = 0.03), specially due to a significant reduction in the number of stabs (p = 0.03), and lymphocytes (p = 0.06). Conclusions: Despite its pro-inflammatory effects, BD itself paradoxically induced progressive leucopenia and reduction in the number of bone marrow cells in this experimental model. Background: Vitamin K (Vit K) is a fat-soluble vitamin involved in blood coagulation and bone metabolism. VK has been shown to suppress cancer growth and induce apoptosis and differentiation in various cancer cells including hepatocellular carcinoma (HCC) cells. In HCC patients, abnormal prothrombins (PIVKA-II) are detected at high frequencies in the blood as an important tumor marker. Methods: In this study, we intended to reveal the migration suppression effect of Vitamin K through blocking the HGF/c-Met pathway. HepG2 cells (HCC cell line) were cultured and then treated with hepatocyte growth factor (HGF), in which E-cadherin expression were measured by using special immunohistochemeical stains and Western Blot and cell migration was also measured by scratch tests. Results: After treatment with different concentrations of HGF, E-cadherin expression was weakened reversely according to the concentration of HGF. In contrast, concurrent treatment with HGF and Vitamin K1/2 revealed no attenuation in E-cadherin expression. Migration of HCC cells were accelerated after HGF treatment, but this effect became much weakened after concurrent treatment with HGF and Vitamin K1/2. Attenuated expression of E-cadherin implicates that cell migration for HCC metastasis is facilitated by loss of adhesion molecules. Conclusion: Treatment with Vitamin K1/2 in HCC cell lines resulted in downregulation of N-cadherin and snail, and up-regulation of E-cadherin. The mechanism may take a part on the role of Vitamin K-associated anti-tumor effect during HCC progression. Further studies are necessary to integrate this pathway to the already-established action mechanisms of Vitamin K. Herein we addressed whether genetic polymorphisms of NKC-encoded genes affect NK-cells′ potential to negatively regulate T-cell responses. Purified NKcells cultured in the presence of IL-2 of NKC-congenic rat strains LEW and LEW.TO-NKC differing exclusively in multiple genetic polymorphisms of NKCgenes were used to supplement MLC assays composed of lymph node cells of strains LEW or LEW.TO-NKC and irradiated MHC-disparate LEW.1U stimulators. NK-cells of LEW.TO-NKC inhibited autologous T-cell responses significantly stronger than LEW NK-cells respective T-cells even at low amounts. The inhibitory potential was rather mediated by NK-cells lacking expression of the inhibitory NKRP1B receptor than by NKRP1B positive NKcells. This study strengthens that genetic polymorphisms of NKC-encoded surface proteins can influence immunoregulatory functions of NK-cells. Depending on the recipient′s NKC-haplotype it is expected in vivo that survival of MHC-disparate tissues might differ. Background: Measurement of sCD30 in serum has been considered a useful parameter to estimate the rejection risk in renal transplant recipients; however, little is known about the components of the immune system involved in the modulation of CD30 expression and sCD30 release during the alloimmune response in patients with end-stage renal disease (ESRD). Materials: We evaluated whether the genes related to expression and shedding (ADAM10, ADAM17) of CD30 and transcription factors associated with Th1 and Th2 (t-bet and GATA3) T-cell subsets are differentially expressed in circulating cells of ESRD patients and age-and gender-matched healthy controls (HC). By principal component analysis (PCA) we determined the interrelationship of the same gene transcripts, with the release of sCD30 and 32 different analytes into supernatants from allo-and polyclonally-stimulated CD3+-enriched T lymphocytes. Results: ESRD patients exhibited circulating increased transcripts of both Th1 t-bet and Th2 GATA3 (p ≤ 0.005). T cells of ESRD patients displayed higher expression levels of CD30 transcripts than HC in response to allogeneic and polyclonal stimulation (both p < 0.001), and higher basal in vitro expression levels of ADAM17 transcripts (p < 0.001). PCA enabled the establishment of differential interrelationships in allostimulated cell-cultures of ESRD patients, including (i) sCD30 with MIP-1b, TNF-b, RANTES and GM-CSF, (ii) a high correlation of CD30 transcripts with t-bet transcripts and IP-10, IL-8, IL-1Ra, MCP-1 and IL-13, and (iii) a higher correlation between sCD30 and CD30L, ADAM10 and ADAM17 transcripts. Conclusion: Our findings suggest that activation of both Th1 and Th2 responses, active pathways leading to upregulation of CD30-expression and -shedding and their interrelationship with Th1 and pro-inflammatory responses, may explain the activated immune state in ESRD patients and the poor graft prognosis after transplantation in ESRD patients with higher serum levels of sCD30. Louise Onions 1 , Arun Gupta 2 , Cristina Navarrete 3 , Anthony Warrrens 1 1 Queen Mary, University of London; 2 Clinical Transplantation, The Royal London Hospital, London; 3 NHSBT, Colindale, London Background: Dysfunction in the B cell compartment may contribute to chronic allograft deterioration. B cell activating factor (BAFF), if in excess, has been associated with rejection and development of donor-specific antibody (DSA). Here we examined BAFF and regulatory B cells (Breg) to identify the relationships between differential expression and level of function of the allograft. Methods: CD19+ cells from patients with deteriorating (gp 1), stably-impaired (gp 2) and well-functioning (gp 3) grafts were examined for CD19 & BAFF-R or cultured for Breg analysis and stained for CD19, CD24, CD38, IL-10. FACSsorted-cells were stained with CD19, CD24 & CD38. Serum BAFF (sBAFF) levels were measured by ELISA. HLA antibodies were assessed using Luminex technology. Results: Gp 1 had higher sBAFF and lower CD19 + BAFF-R+ cells. DSA with elevated sBAFF or low BAFF-R were only detected in gp 1. IL-10 producing-B cells, enriched in the CD24 high CD38 high compartment were lower in gp1 and cell-sorting showed the distinct CD19 + CD24 high CD38 high subset was minimal. Conclusion: The expression of BAFF and Bregs correlates with deteriorating graft function, suggesting important roles in regulating B cell homeostasis. We are currently examining functional regulatory properties. ABSTRACT The success of transplantation is limited by allograft rejection, an unwelcome response of T-cells against the allograft. If alloreactive T-cell clones specifically could be removed from the host, allograft tolerance would result, without blanket pharmacologic therapies which suppress all immune responses. The goal of this project is to increase the longevity of transplanted organs by inhibiting T cell expression of c-FLIP, an important physiologic regulator of apoptosis, thereby promoting activation induced cell death (AICD) of alloreactive effector T-cells. As an important anti-apoptotic regulator of Tcells in normal immune responses, c-FLIP represents a novel target for manipulating the allograft immune response. Materials and Methods: BALB/c and C57/BL6 mice were purchased from Jackson Lab. T cells were purified using a Miltenyi Biotech magnetic beads kit. siRNA and lentiviral vectors containing shRNA to cFLIP were purchased from Sigma. siRNA transfer into T cells used the Amaxa nucleofector, an electroporation technique. T cell apoptosis was measured using annexin V binding in flow cytometry. Skin grafting used colloidian glue and dressings for seven days. Cre-ER/lox-cFLIP mice were a kind gift of Dr You Wen He, Duke University Results: Electroporation of BALB/c T-cells with siRNA to cFLIP resulted in knock-down of cFLIP protein expression as measured by Western Blot. This knockdown resulted in increased T cell apoptosis upon anti-CD3/CD28 stimulation, as measured by Annexin-V binding in flow cytometry. Conclusions: cFLIP knock-down in T cells can be achieved using either siRNA nucleoporation or lentiviral vector bearing shRNA. Either method of gene transfer leads to increased T cell apoptosis and susceptibility to activation induced cell death. We plan experiments shortly with cFLIP conditional knockout mice in a ER-Cre/lox system which hopefully will show prolonged allograft survival. Background: Dendritic cells (DCs) present antigen to T cells. The state of DCs maturation is crucial for induction of T cell response. It was noted that immature DCs play an important role in peripheral tolerance, whereas mature DCs induce a complete immune response. This is very important in transplantation, especially in allograft rejection. Immature DCs or DCs with tolerogenic properties may prolong allograft survival. It appears that this could be achieved using the immunosuppressive therapy with cyclosporine A and rapamycin. We have studied the effect of dendritic cells generated in the environment of immunosuppressive agents: rapamycin and cyclosporine A on the expression of T cell activation markers and the proliferative T cells activity. Methods: Human peripheral blood monocytes were induced by using cytokines: IL-4 and GM-CSF, in the direction of DCs in the presence of rapamycin (Rapa-DCs) and cyclosporine A (CsA-DCs) or without drugs. Immature DCs were then stimulated with LPS to create mature DCs. To evaluate effects of these DCs on T cells, mixed leukocyte reaction (MLR) was applied. At the end of MLR cultures the expression of T cells activation markers (CD25, CD69) was measured by flow cytometry. Additionally the proliferative T cells activity was determined by measuring the fluorescence intensity of CFSE dye using flow cytometry. Results: We have observed a decrease in the percentage of CD69 + T cells when these cells were cultured with Rapa-DCs and CsA-DCs. The lowest percentage of T cells was noted in an environment of cyclosporine A. In contrast the percentage of CD25 + T cells was slightly increased in the presence of Rapa-DCs and CsA-DCs. We have also noted that the percentage of proliferating T cells do not change significantly after culture with Rapa-DCs and CsA-DCs. Conclusions: Dendritic cells generated in the environment of immunosuppressive agents slightly change the expression of T cell activation markers. Luiz Felipe Moreira, Cristianode Jesus Correia, Daniela Janolli, Sueli Gomes Ferreira, Rafael Simas, Paulina Sannomiya Cardiovasc. Surg. and Circ. Pathophysiol. Lab., Heart Institute (Incor), University of Sao Paulo Background: Brain death (BD) induces hemodynamic instability with microcirculatory hypoperfusion leading to increased organ inflammation and dysfunction. in this study, we investigated the effects of hypertonic saline on mesenteric microcirculatory changes and systemic inflammatory markers after BD induction in rats. Methods: Male Wistar rats (250-350 g) were anesthetized and mechanically ventilated. BD was induced by intracranial balloon inflation. Hypertonic saline (7.5%) or normal saline solutions (4 ml/Kg) were infused immediately after BD induction. Mesenteric microcirculation and leucocyte-endotelial interactions were analyzed by intravital microscopy 180 min thereafter. The expression of serum concentrations of cytokines, chemokines and corticosterone were also obtained. Results: There was no difference in mean arterial pressure behavior between Hypertonic and normal saline groups. On the other hand, proportion of perfused small vessels (<30 lm) was significantly higher in Hypertonic group (69 AE 7%) in relation to normal saline animals (40 AE 6%, p = 0.002). Hypertonic rats also exhibited decreased numbers of rolling (p = 0.036), adhered (p = 0.03) and migrated leucocytes to the perivascular tissue in comparison with normal saline group (2.8 AE 0.4 vs. 0.3 AE 0.2, p = 0.02). Similar values in the cytokine, chemokine and costicosterone levels were observed in both groups. Conclusion: Despite the absence of any influence on hemodynamic behavior and on systemic markers of inflammation, infusion of hypertonic saline improves mesenteric microcirculatory perfusion and decreases inflammatory cells migration after BD induction in rats. Background: This study aimed to devise a reproducible method of prehepatic portal hypertension (PH) in a large animal model. Materials and Methods Eight pigs weighing a mean 23 AE 4 kg were treated with portal vein partial ligation (PVPL) using a cotton umbilical tape to determine a porto-systemic gradient of major of 12 mmHg (subtracting the central venous pressure from the portal venous pressure-PVP). Mean arterial pressure, heart rate and central vein pressure were monitored continuously. A venous line was surgically placed through a inferior mesenteric vein for PVP monitoring; while hepatic artery and portal vein flows were measured before and after PVPL using ultrasound transit time flow probes. Pigs were followed up for 7 days (n = 4) or 14 days (n = 4). Results: Prior to PVPL, the average PVP was 15.2 AE 9.5 mmHg. After PVPL, porto-systemic gradient was 15.1 AE 1.8 mmHg, secondary to an increase of the mean PVP, which was 23.9 AE 8.1 mmHg. PVF dropped significantly after PVPL, from 463 AE 197 to 202 AE 119 ml/min, corresponding to a percentage decrease of 46%. Conversely, HAF had a 62% increase: from 24.3 AE 20.9 to 39.3 AE 24.16 ml/min, with a percentage increasing of 61.7%. After ligation, portal vein diameters passed from 47.7 AE 6.4 to 21.4 AE 4.0 mm. In all animals, at autopsy, we showed severe portal cavernomatosis with gastro-esophageal venous collaterals and splenic stiffness. Porto-systemic gradient was unchanged after 7 days and decreased of 6.3 AE 1.6 mmHg after 14 days (p = 0.002). Mean PVP was 26.3 AE 11.7 mmHg on day 7th and 9.5 AE 3.6 mmHg on day 14th (p = 0.06). PVF reduction was of 304 AE 159 and 460 AE 171 ml/min after 7 and 14 days, respectively (p = 0.04). No significant modifications occurred to the HAF and to the LFTs. Conclusion This technique has been shown to be easily reproducible of pre-hepatic PH and well tolerated by the animals and allow easy assessment of liver function and splanchnic blood flow redistribution in the postoperative period. Background: This study demonstrated that pharmacologic induction of HO-1 along with catalytic activation significantly modulated apoptosis of Jurkat cells induced by mycophenolic acid (MPA). Methods/Materials: We observed, cell viability, measurement of H2O2 generation, intracellular accumulations of Ca2 + and NO, and western blottings of apoptotic pathway proteins, such as caspase, HO-1,Bcl-2, and Bax proteins. Mitochondrial membrane potential transition (MPT) determination by JC-1 staining was performed. Results Caspase-3 proteases expression on MPA treated-Jurkat cells in a timedependent manner. Treatment of MPA resulted in reactive oxygen species (ROS) generation in Jurkat cells. 20¥ ıM cobalt protoporphyrin (CoPPIX; HO-1 inducer) significantly increased HO-1 expression in MPA treated cells. Apoptosis rate is 3.53% in media only, 23% in MPA treated cells, 5.8% in MPA treated cells with CoPPIX. The cell viability was reduced 77% under MPA, but combination with CoPPIX, there was no increased MPA induced apoptosis. Induction of HO-1 decreased expression of Bax protein. Decreased HO-1 expression on MPA treated-Jurkat cells after 36 h. Change of mitochondrial MPT was also noted. Expression of Bax proteins was identified. CoPPIX, induced expression of HO-1 proteins in MPA treated Jurkat cells. CoPPIX inhibited generation of H2O2. CoPPIX also inhibited change of mitochondrial MPT. CoPPIX significantly inhibited the MPA induced apoptosis. Conclusion; CoPPIX, HO-1 inducer, significantly inhibited the MPA-induced apoptosis. CoPPIX attenuated ROS production and mitochondrial permeability transition in MPA-treated cells. In conclusion, the protective mechanism of HO-1 on MPA-induced apoptosis is associated with direct inhibitions of ROS generation and mitochondrial permeability transition. Background: MicroRNAs (miRNAs) are short noncoding 21-24 nucleotide sequences that inhibits protein synthesis by targeting messenger RNAs in a sequence specific manner. It has been known that gene specific translational silencing by miRNAs regulates various inflammatory responses. The present study clarified the involvment of miRNAs in the acute liver graft rejection. Methods/Materials: Orthotopic liver transplantation was performed from DA (RT1a) to Lewis (RT1 l) rats without immunosspression. We studied liver grafts by day 11, focuing on the degree of acute liver graft rejection, and alteration of miRNA profile during the development ofliver graft rejection. miRNAs in the liver grafts were examined by microRNA array, and analyzed by GeneSpring (Agilent Technologies). Results: In DA-to-Lewis rat liver transplantation, the progressive acute T cellmediated and antibody-mediated rejection occurred from day 5 and developed by day 11 with irreversible graft failure. During the development of liver graft rejection between day 5 and day 11, 193 microRNAs were up-regulated or down-regulated in rejecting grafts when compared with those in normal DA liver. These miRNAs were included miRNAs which are known as the pathways for various inflammatory responses, immune cells differentiation and signaling, development of immunity and molecular pathways for allograft rejection; upregulated miRNAs (miR-146b, miR-223, miR-181, miR-34a, miR-326, miR-21) and down-regulated miRNAs (miR-150, miR-125b, miR-20a) . Conclusion: miRNAs may be involved in various immunological processes including development of innate and acquired immunity, inflammation, T-cell and B-cell mediated immune responses in transplant liver graft rejection. miRNAs in transplant immunobiology will provide an exciting framework for developing new biomarkers as well as new therapeutic interventions in transplantation. Introduction: HCV disease is the leading cause of liver transplantation (Ltx). Since reinfection of HCV after Ltx can not be avoided, tailoring immunosuppression in the presence of biomarkers of early acute rejection (EAR) may improve outcomes after Ltx for HCV diseases. Immune system could be highly modified by chronic infection of HCV. If so, this modification must be taken into account to explore biomarkers of EAR after Ltx for HCVdisease. Method: 22 HCV (female/male = 6/16, 53.8 AE 4.5years) and 26 non-HCV (female/male = 10/16, 41.5 AE 11.8 years) living-donor liver transplantation (LDLT) recipients were enrolled. Pre-Ltx peripheral blood mononuclear cells (PBMC) were systemically phenotyped by FACS analysis. The frequency of each phenotype within the lymphocytes was presented. The frequency of each phenotype was compared between recipients who experienced early acute rejection (EAR: < 3 months post-Ltx) and recipients who did not experience EAR both in HCV cohort and non-HCV cohort. Result: The incidence of EAR was equivalent between HCV and non-HCV cohorts (8/22 in HCV vs. 11/26 in non-HCV, NS). HCV patients experienced EAR at 19 AE 14 days post-Ltx while non-HCV patients at 18 AE 14 days post-Ltx (NS). HCV patients with EAR exhibited low frequency of CD3 + CD8 + , cdT or NKT cells and high frequency of ab T cells, CD3 + CD4 + or CD4 + CD25 + cells compared to those without EAR. On the other hand, non-HCV patients with EAR exhibited high frequency of NKT cells and low frequency of CD19 + compared to those without EAR. Conclusion: Our data suggest that chronic HCV infection modifies immune systems prior to liver transplantation (Ltx), which in turn results in differential correlation between PBMC phenotypes and EAR (early acute rejection) in HCV patients versus non-HCV patients. Thus, it is tempting to state that consideration of immunological modification by HCV infection may be needed when biomarkers of EAR after Ltx are explored. Background: Acute rejection remains a major cause for long-term kidney allograft failure. Reliable immunological parameters suitable to define the pre-Tx activation state and hence the individual risk for graft rejection are highly desired to appropriately adapt the immunosuppressive regimen in advance. Methods: Donor-and 3rd-party alloreactivity were measured by mixed lymphocyte culture. Soluble forms of CD25, CD30 and CD44 were detected in patients′ serum by ELISA. Various lymphocyte subsets were determined by flow-cytometry. All patients received immunosuppression with CNI/MMF/ steroids and were grouped according to protocol and indicated biopsies within the first year post-Tx: non-rejector (NR, n = 13), borderline (BL, n = 5), acute rejector (AR, n = 7). Results: Patients suffering from AR showed significantly higher pre-Tx alloreactivities than NR (p < 0.02). Highest levels of sCD25, sCD30 and sCD44 likewise were observed in the former (p = 0.030, 0.011 and 0.002 compared to NR). BL-patients were found between both other groups. Combination of these parameters enhanced differences seen between groups. Patients with graft rejection showed markedly increased frequencies of CD4 + CD28À and CD8 + CD28À T-cells pre-Tx. Conclusions: Pre-transplant levels of alloreactivity, the overall activation state of recipient's immune system and the frequency of particular T-cell subsets seem to be associated with graft rejection after kidney-Tx and should be further evaluated for clinical applicability. Background: The third apoptotic pathway is endoplasmic reticulum (ER) mediated apoptosis. We examined the effects of FK506 on ER mediated apoptosis of Jurkat cells. Methods/Materials: We observed cell viability, measurement of H2O2 generation, intracellular accumulations of Ca2+ and NO, and western blottings of ER stress mediated apoptotic pathway proteins, such as phospho-PERK, PERK, CHOP, Grp78, Grp94, Bcl-2, and Bak proteins. Mitochondrial membrane potential determination by JC-1 staining was performed. Results: Cells were cultured with the presence or absence of FK506. Flow cytometric analysis was performed after PI stain. Viability of Jurkat cells were decreased by the addition of FK506 in a dose-dependent manner. FK506 induced cytotoxicity was characterized by sub G0/G1 phase arrest. FK506 induced cell death was confirmed as apoptosis characterized by nuclear fragmentation and caspase-3 protease activation. Intracellular accumulations of Ca2+ and NO production were identified in FK506 treated Jurkat cells after 24 h. Expression of iNOS protein was also noted. Generation of H2O2 was identified. Deceased activation of procaspase-12 protease confirmed activation of caspase-12 after 48 hours. Activation of phospho-PERK protein peaked at 36 hours after FK506 treatment. Expressions of CHOP/GADD153, Grp78 and Grp94/BiP proteins were also identified after 36 hours. Expression of Bak protein was also noted. Change of mitochondrial membrane potential transition (MPT) was also noted. Conclusion: FK506 treated Jurkat T cells increased the sub G0/G1 phase, nuclear fragmentation and activations of three and 12 caspases. FK506 also increased NO production through induction of iNOS and H2O2. Reactive oxygen species induced by FK506 resulted in the modulation of Bak protein expression and mitochondrial dysfunction through ER stress mediated pathway. FK506 induced ER mediated apoptosis in Juekat T cells were identified. Thomas BACHELET, Gwendaline Guidicelli, Jonathan Visentin, Lionel Couzi, Pierre Merville, Jean-Luc TAUPIN CHU Bordeaux Virtual crossmatch strategies and their definition of presumptive Donor Specific Antibodies (DSA) rely on single antigen flow beads (SAFB) assays. Technological limitations sometimes made its interpretation challenging (distorded HLA molecules, variable HLA density, prozone effect, inter and intra-test variation). Circumventing these limits is yet mandatory to extrapolate results to clinical practice. We here aimed to define which clues optimize the analysis by confronting acellular SAFB-DSA to cellular crossmatch (XM) DSA levels. To that end, 603 T-lymphocytes XMs combining flow cytometry (FCXM) and complement dependent cytotoxicity (CDC) assays (results expressed in Mean Channel Shift deviation (MCS) and using the CDC viability score) were performed by using 137 sera from sensitized patients, exhaustively characterized with SFAB on a Luminex platform and 90 organ donors' lymph nodes,with extensive HLA Class I typing. The correlation between SAFB-DSA and FCXM-DSA and CDC-DSA is better if (i) the sum of the Mean Fluorescence Intensity (MFI) of the different HLA DSA was taken in account rather than the MFI of the immunodominant DSA (for the whole tests: R² 0.47 vs. R² 0.46 and R² 0.29 vs. R² 0.21; for the tests with more than one mismatches-MM (N = 187): R² 0.64 vs. R² 0.57 and R² 0.46 vs. R² 0.33, respectively); (ii) MFI was doubled for homozygote sera (for the whole tests: R² 0.47 vs. R² 0.46 and R² 0.29 vs. R² 0.23; for the tests with homozygotic MM antigens (N = 71): R² 0.65 vs. R² 0.64 and R² 0.49 vs. R² 0.46, respectively). Noteworthy, information given by the different beads is not equivalent, likely in relation with the conformation of HLA Ag on the beads (each bead evaluated in more than 10 XM tests, being the unique DSA target): performant for HLA A11, B35, B38, B51, B57, B7 (R²>0.6, p < 0.001), correct for HLA A1, A2, A23, A24, A68, B44, B8 (p < 0.05) but results given by HLA A3, B18, B62 should be taken with caution (p > 0.05) Better apprehend the results from SAFB assay should enable the clinicians to better integrate this tool in their practice. Mary Gieschen-Krische 1 , Sumiyya Mahmood 2 , Josie Adams 2 , Anna Rowan 2 , Mohamed Al-Aloul 2 , Nizar Yonan 3 , James Fildes 3 1 The University of Manchester; 2 UHSM; 3 UHSM, The University of Manchester Introduction: NKT cells have the potential to contribute to inflammatory and tolerogenic immune responsiveness, yet their role following lung transplantation is unclear. In this study we aimed to characterise and determine the differences in NKT cells and their function between lung transplant recipients and non-transplant controls. Methods: Peripheral blood samples were collected from (n = 87) lung transplant recipients during routine clinical visits, and (n = 10 healthy controls). NKT cells were quantified by flow cytometry using fluorescent-labelled antibodies: CD3, CD16 and CD56. Phenotypes were characterised using activation markers (CD107a, CD161 and NKG2D) and tolerance markers (CD200 and CD200R). Differences between lung transplant recipients and controls were determined using Mann-Whitney U test, whereby p-values < 0.05 were considered statistically significant. Results: Lung transplant recipients had significantly higher numbers of NKT cells expressing CD107a+ (p < 0.01), CD161+ (p = 0.43) and NKG2D+ (p < 0.01), compared to non-transplant controls. However, higher numbers of NKT cells expressing tolerogenic markers CD200+ (p < 0.01), CD200R+ (p < 0.01) and CD200+ CD200R+ (p < 0.01) were found in the control group. Differences in relative mean expression of markers of activation or tolerance were found to be non-significant between groups. Conclusions: A higher frequency of activated NKT cells following lung transplantation suggests the existence of a signal inducing cellular maturation to an inflammatory phenotype. This is likely to be in response to alloantigen, and also indicates NKT cells are not sufficiently suppressed by immunosuppression. Clearly further work on this important cell is warranted in the transplant setting. Mary Gieschen-Krische 1 , Louise Archer 2 , Timothy Entwistle 1 , Claire Cowan 2 , Mohamed Al-Aloul 2 , Nizar Yonan 3 , James Fildes 3 1 The University of Manchester; 2 UHSM; 3 UHSM, The University of Manchester Introduction: Allograft rejection is a major complication following transplantation, requiring continuous immunosuppression. The mechanisms of action of immunosuppressive drugs have been well described. However, their effect on NKT cells following lung transplantation remains is unclear. In this study, we assessed the association between NKT cells (peripheral blood and BAL) with immunosuppression doses in a lung transplant cohort. Methods: Peripheral blood samples (n = 87), BALs (n = 33) and clinical data were collected during routine clinic visits. NKT cells were quantified by flow cytometry using fluorescent-labelled antibodies: CD3, CD16 and CD56. Cell function was characterised using CD200 and CD200R (markers of tolerance) and CD107a, CD161 and NKG2D (markers of activation). The relationship between administered doses of immunosuppression and NKT cells was performed by partial correlation co-efficient analysis, controlling for time. Results: The percentage of NKG2D+ NKt cells negatively correlated with azathioprine dose (p = 0.047, R = À0.338). When assessing airway NKt cells, azathioprine dose again positively correlated with NKG2D+ NKT cell numbers (p = 0.047, R = À0.338), as well as the number of inhibitory CD200+ NKT cells (p < 0.001, R = 0.952); Conclusion: Following gut absorption, azathioprine is converted to 6mercaptopurine which inhibits purine synthesis, preventing DNA synthesis and therefore cell proliferation. Azathioprine associated NKT cell modulation and migration is therefore likely to be via another route. Further studies are required to delineate this pathway, and also to translate these phenotypic changes into clinical measures of outcome. Gamma-delta (gd) T cells are unconventional T lymphocytes combining innatelike and adaptive features. In immunocompromized patients, a subset of gd T cells markedly expands during cytomegalovirus (CMV) infection. These non-Vd2 gd T cells exhibit an in vitro dual reactivity toward tumor cells, which translate in vivo in solid organ transplant recipients: their expansion associates with resolution of CMV infection and with a reduced cancer-risk. Although their repertoire is restricted, they express diverse types of TCRs encoded by different V-genes suggesting the recognition of multiple stress-associated antigens common to CMV-infection and tumor transformation. In order to identify the antigens recognized by different non-Vd2 gd TCRs on infected and tumor cells, we immunized mice with these target cells and screened antibodies able to block their recognition by gd T cells. One such monoclonal antibody (6G8) specifically blocked the antitumor reactivity of Vg9Vd1 TCR transductants generated from a dually reactive Vg9Vd1 clone. Using immunoprecipitation and mass spectroscopy, the 6G8 ligand was identified as EphA2 (Ephrin receptor A2), a member of the largest family of tyrosine kinase receptors. EphA2 is expressed on endothelial cells infected by CMV, and is heavily upregulated during tumorigenesis, with high EphA2 expression correlating with poor cancer prognosis. Immobilized recombinant EphA2 was able to activate Vg9Vd1 transductants and directly bound to the Vg9Vd1 TCR as assessed by Alphascreen technology. Different Vd1-containing TCRs were shown to recognize EphA2, suggesting a shared reactivity toward EphA2 within the Vd1 T cell subset. We thus identified EphA2 as a new stress-regulated antigen targeting by non Vd2-gd T cells. These data suggest that in humans, a fortiori when immunosuppressed, gd T cells compose a lymphoid stresssurveillance compartment, capable of recognizing the dysregulated state of infected or transformed cells. TRIB1, a serine-threonine kinase-like molecule, which was identified as a biomarker of chronic antibody-mediated rejection, is highly expressed in CD4 + CD25 + Foxp3 + Regulatory T-cells (Tregs). We isolated Tregs and non-Tregs counterparts and analyzed TRIB1 and Foxp3 mRNA expression by quantitative PCR. Physical interaction between the TRIB1 and Foxp3 proteins was analyzed by Protein Complementation Assay (PCA) using flow cytometry, microscopy and co-immunoprecipitation. Both TRIB1 and Foxp3 were expressed at higher levels (p < 0.001) and correlated tightly in Tregs (Spearman r = 1.0; p < 0.001) but not in CD4 + CD25À T cells. The PCA revealed a direct physical interaction between TRIB1 and Foxp3, which is impaired upon deletion of the TRIB1 N-terminal but not the C-terminal domain, suggesting interaction in the nucleus. This interaction was confirmed in primary human Tregs by co-immunoprecipitation. By infecting CD4 + T cells with lentivirus expressing or not TRIB1, we showed that TRIB1 block CD4 + T cells proliferation after one cycle of cell division. Altogether, these data show a direct relationship between TRIB1 and Foxp3 in terms of expression and physical interaction and show that TRIB1 is an inhibitor of cell proliferation by blocking the cells before the G2 phase of the cell cycle. Background: It was known that declining intracellular T-lymphocyte concentration of cyclosporine A precedes acute rejection in kidney transplant recipients. The aim of this study was to elucidate the impact of various statins on intracellular cyclosporine A concentration in the PBMC (peripheral blood mononuclear cell). Method: PBMCs were isolated from 30 ml of freshly collected blood which were obtained from healthy 4 volunteers with informed consent. PBMC were incubated in the media with 0.1 ml of ND96 buffer containing 200 nm of cyclosporine A in the presence and absence of rosuvastatin (10¥ ım, 100 ¥ ı m), simvastatin (10 ¥ ım, 100 ¥ ım), atorvastatin (10 ¥ ım, 100 ¥ ım), fluvastatin (10 ¥ ım, 100 ¥ ım), pitavastatin (10 ¥ ım, 100 ¥ ım) for 30 min at 37 ιAEC. The radioactivity was measured by a MicroBeta TriLux 96-well Scintillation/ Luminescence detector (PerkinElmer). We also measured intracellular cyclosporine A concentration in the presence of the statins (100 ¥ ım) in the LLC-PK1 overexpressing P-glycoprotein cells. Result: The intracellular concentration of cyclosporine A in the control and in the presence of verapamil was 30.5î¾ 6.2 fmol/min/2*10^5 and 55.8î¾ 6.4 fmol/min/2*10^5 (p = 0.008) respectively. The intracellular cyclosporine A concentration with simvastain (10¥ ım, 100 ¥ ım) and with atorvastatin (10¥ ım, 100 ¥ ım) showed significant higher value, 67.1î¾ 6.7 fmol/min/2*10^5 (p = 0.002), 66.2î¾ 4.5 fmol/min/2*10^5 (p = 0.001), 45î¾ 4.9 fmol/min/ 2*10^5 (p = 0.03), 57.5î¾ 2 fmol/min/2*10^5 (p = 0.002),respectively. But the others were not (p > 0.05). It also revealed higher intracellular cyclosporine A concentrations in the presence of verapamil, atorvastatin and simvastatin, 398.7î¾ 1.1 fmol/min/1*10^4 (p = 0.0002), 108.3î¾0.6 fmol/min/1*10^4 (p = 0.04), 222î¾0.8 fmol/min/1*10^4 (p = 0.01), respectively, in the LLC-PK1 cells. Conclusion: The intracellular cyclosporine A concentration could be affected variously with statins by p-glycoprotein mediated inhibition. LARGE ANIMAL SOLID ORGAN ALLOGRAFT TRANSPLANTATION MODEL USING PIGLETS can be candidates for proper substitute for adult model. However, piglet allograft models have not been widely used in allotransplant model because of immunological and surgical problems. The aim of this study was to introduce our experience of kidney and heart transplantation using piglets. Methods: We performed 12 kidney and 11 heart transplantations between wild type piglets. We use heart and kidney allograft using single donor in principle and monitored perioperative and immunological parameters before and after transplantation. Average weight of donor and recipient piglet is around 5 kg. Immunosuppressive protocols consisted of FK506, MMF and steroid. Results: Average survival days of piglet recipients after transplant are 16.75 (4~89) in kidney and 17.10 (6~41) in heart without pathologic evidence of rejection. The major causes of death were not related to rejection, but other non-immunologic factors just like dehydration due to vomiting and diarrhea or stricture of ureter-bladder reconstruction. We performed second look op for evaluating and sampling the allograft of four cases among the porcines surviving the early postoperative period. Conclusion: We successfully performed 12 cases of renal and 11 cases of heart allotransplant using piglet model with successful immunosuppression without acute rejection or early postoperative complication. However, we need to optimize protocols for immune modulation and post-operative care to attain long-term survival of piglet allotransplantation models. The products of the 3rd classical MHC locus HLA-C were the last serologically discovered (Thorsby et al. 1970; Mayr et al. 1973) . Hayek-Rosenmayer and Doxiadis (1984) displayed the products by 1-D-IEF and Bunce et al. (1996) achieved molecular typing reducing the incidence of C "blank" to 0. Recently, O'Huigin reported on the binding of miRNA-148a to the 3′untranslated region of HLA-C. Two groups were defined: C2,5,6,8,12,15,16 escaping down regulation and the C3,4,7,14,17 , which are down regulated. In solid organ transplantation almost no information is available with respect to antibody formation towards HLA-C. Earlier, we showed that antibody production is closely related to the number of epitope incompatibilities (EI) expressed by the HLA antigens. We questioned whether the low immunogenicity of HLA-C is not only due to the differential expression of this locus but also to a lower degree of antigenicity, measured as EI. We selected HLA-A, B, and C molecularly typed phenotypes occurring at least twice in the normal population (N = 126). We simulated a situation in which these would occur as a single mismatch in transplantation (N = 77). Finally, we calculated the median EI per HLA locus. The mean EI for HLA-A was 5.2 vs. 4.0 for HLA-B and 2.4 for HLA-C (p < 0.001). When the HLA-B locus was divided into the Bw4/Bw6 epitopes and the HLA-C into NKC1 and NKC2 groups the results in terms of EI where Bw4 (EI = 5.3)>A (5.2)>C2 (3.6) >Bw6 (3.1) >C1 (2.0). HLA antigens, which were outliers with respect to their EI were: HLA-A2 (EI = 10), A1 (8), B44 (8), B60 (7), and HLA-C7 (8). HLA-C7 with a high number of EI belongs to the group of low expressed HLA-C, and leads to 18% specific antibodies in highly sensitized patients. Although the expression of the HLA-C in a transplanted graft certainly plays a role in antibody formation, the number and type of the EI is crucial as well. In general, the products of the HLA-C locus have a low immunogenicity on basis of their EI. Introduction: Angiotensin II is a peptide hormone involved in renin-angiotensin-system (RAS). Anti-angiotensin receptor 1 (AT1R) antibodies are implicated in stimulating RAS and suspected to have some adverse impacts on renal transplantation outcome. Methods: From Nov 2009 to Feb 2012, 42 remaining sera from renal transplantation recipients with biopsy-proven antibody mediated rejection (AMR) (n = 6), acute cellular rejection (ACR) (n = 23) and AMR+ACR (n = 8) without preformed HLA antibodies were tested with anti-AT1R antibody assay (Onelambda, USA). Forty two control patients without rejection were also analyzed. Results: The frequencies of elevated anti-AT1R antibodies was higher in patients with AMR (n = 14) compared to controls (28.6% vs. 4.9%, p = 0.03, OR = 8.0). It was also higher in patients with AMR+ACR (n = 8) (37.5% vs. 4.9%, p = 0.03, OR = 12.0). There was no difference in frequencies of elevated anti-AT1R antibody in patients with ACR. Background: Acute antibody mediated rejection (AMR) and acute T-cell mediated rejection (TCMR) activates the immune system in different ways. Granzyme A (GZA) and Granzyme B (GZB) are cytolytic molecules expressed on effector cells of the immune system. Positive costimulatory molecule of Tlymphocytes is OX40. We studied the expression of biomarkers in renal allografts with AMR, TCMR, combined rejection (AMR + TCMR) and other diagnoses. Methods/Materials: The study group included 55 kidney transplant recipients. We evaluated 79 biopsies from allografts: 28 samples (spl.) with AMR, 18 spl. with TCMR, 7 spl. with AMR + TCMR and 9 spl. with the recurrence of the disease in the graft (R). A group of 17 spl. without histologic signs of acute rejection had served as a control (K). Total RNA obtained from tissue was transcribed into cDNA, then amplified by real time PCR. Relative changes in gene expression of markers were calculated using the 2-DeltaCT. The results were evaluated by Mann Whitney U test. Results: The results are given in the table. The values in the table are medians, P for U test in comparison with the control. Differences between AMR and TCMR are not statistically significant. Linear combination of results of GZA-GZB-OX40 has differented each group except R. Conclusion: Acute rejection increases the expression of studied biomarkers. The highest levels of biomarker expression we found in TCMR group. In combined rejection the level of biomarkers (excluding GZA) is lower than the one in TCMR, which may indicate the different mechanism of activation of the immune system. The best differentiation among the groups was done by linear combination of GZA-GZB-OX40. Our results show that to obtain the better information value is advantageous to investigate more biomarkes together, which may be beneficial in the evaluation of ambiguous histologic or complicated clinical situations. Background: Part of the antigen-specific memory T-cells generated against pathogens, such as cytomegalovirus (CMV) and Epstein-Barr virus (EBV) show also reactivity to allo-antigens, so called heterologous immunity. In kidney transplant recipients, the presence of virus specific T-cells with cross-reactivity to allo-antigens of donor origin might impair allograft function and survival. We here developed a method to analyze the characteristics of cross-reactive T cells in vitro. Methods: Peripheral blood mononuclear cells (PBMCs) from five healthy individuals known to have circulating CMV-or EBV-specific T-cells, were labelled with CFSE. To expand allo-and virus-specific T-cells, PBMCs were cultured for 6 days either with allogeneic stimulator cells in a mixed lymphocyte reaction (MLR) or with viral peptide and IL-2. Cells were re-stimulated for 6 h with allogeneic cells or peptide loaded-autologous PBMCs and analyzed by flow cytometry. Cross-reactive CD8 + T-cells were identified as tetramer+ and CFSEdim in a MLR. Results: Viral peptide dose-dependently induced expression of IFNc, IL-2 and the degranulation marker CD107a in virus-specific T-cells expanded by either viral-or allo-antigen stimulation. Some cross-reactive T cells also produced cytokines in response to re-stimulation with allogenic cells, which appeared to be dependent on the cross-reactive allo-antigen involved. For example, EBV B8 FLR-specific T cells, known to cross-react to HLA B44*02, produced large amounts of IFNc and IL-2 (respectively 60% and 25% of the cells) in response to cells bearing this HLA molecule, whereas allo-stimulation evoked proliferation but no cytokine secretion in CMV B35 IPS-specific T cells. Conclusion: Together these results show that frequency and function of cross-reactive T-cells can be analyzed in vitro and differ between crossreactive epitopes. Rakesh Sindhi 1 , Bishu Ganguly 2 , Robert Townsend 2 1 Plexision Inc; 2 Bristol-Myers Squibb Background: Belatacept (NulojixTM, Bristol-Myers Squibb) blocks CD28mediated co-stimulation of T-cells. Variable dependency of T-cell subsets on CD28-mediated co-stimulation may affect the capacity of belatacept to inhibit their allo-responsiveness. The sensitivity of T-cell subsets to belataceptmediated inhibition of allo-responses was evaluated in vitro. Methods: Thirty-six CD3+ T-cell subsets were evaluated in PBMC from 20 NHV. Sensitivity of subsets to inhibition by belatacept (0-100 lg/ml) was tested in responder PBMC, stimulated with HLA-mismatched, T-cell-depleted stimulator PBMC (1:2 ratio). T-cell CD154 expression was used as a measure of Tcell activation as previously described. Allo-responses were stratified by T cell phenotypes (cytotoxic (Tc), helper (Th), memory (M) and na€ ıve (N)) and CD28 expression. Belatacept concentrations associated with half-maximal inhibition of allo-responses (EC50) were estimated for each T-cell subset. Results: CD28-neg cells were more frequent among Tc (25.3 AE 2.8%) compared with Th (2.3 AE 0.76%, p = 5.6 E-9, n = 31) subsets. The least belatacept-sensitive T-cell subsets were ThMCD28-neg > TMCD28-neg > Tc > TcCD28-pos > TcCD28-neg (median EC50 = 35.8, 30.1, 26.5, 22.7, and 20.95 lg/ml, respectively, n = 20) . The most belatacept-sensitive subsets included ThN, TcN, TcNCD28-neg, and TN and TM double-neg cells (median EC50 range = 9.4 to 3.15 lg/ml). Median EC50 values of the remaining 26 T cell-subsets ranged from 10.35 to 19.7 lg/ml. Conclusion CD28-neg TM and Tc populations are relatively insensitivity to inhibition by belatacept in vitro, suggesting less dependence on CD28-mediated co-stimulation. Reduced inhibitory effect of belatacept on these donor-specific T-cell subsets may result in suboptimal immunosuppression and potentially increased risk of acute rejection. Understanding the effect of belatacept and co-therapies on these cell subsets may inform the selection of optimized belatacept-based treatment regimens. Markus J. Barten 1 , Katja John 1 , Jens Garbade 1 , Stefan Dhein 1 , Friedrich-Wilhelm Mohr 1 , Hartmuth B. Bittner 2 1 University Leipzig Heart Center; 2 Florida Hospital Orlando Objective: Over the last decade many studies evaluated the potential of certain biomarkers to predict acute cellular rejection (ACR) without finding their way in the clinical routine. Thus, in our study we monitored dendritic cells (DCs) in heart transplant recipients (HTxR) treated either with a tacrolimus (TAC) or cyclosporine A (CsA) -based immunosuppressive regimen in the context of ACR. Methods: Both groups consisted of 14 maintenance HTxR. At different study time points (0, 3 and 6 months after study start) peripheral blood from all HTxR was drawn to analyse for (1) blood CsA or TAC concentration (trough value) and (2) to analyse myeloid and plasmocytoid (m and p) DCs with FACS. Histological rejection grading was performed of endomyocardial biopsies. Results: TAC treated HTxR had significantly higher values of pDCs (CsAgroup 53.9 AE 13.0%, TAC-group 67.5 AE 8.4%, p < 0.05) and significantly lower values of mDCs than CsA treated HTxR (CsA-group 57.9 AE 19.0%, TAC-group 45.2 AE 10.7%, p < 0.05). In general, HTxR with rejection grade of ≥2 ISHLT 1990 had significant (p < 0.05) lower values of pDCs (55. Anti-endothelial cell (EC) antibodies (AECA) have been implicated in solid organ transplant dysfunction, but routine testing for donor-specific AECA has been limited to expensive flow-cytometry crossmatches (e.g. Xm-OneTM) employing circulating EC precursors. Since most EC antigens identified to date are not polymorphic, there is no need for donor EC. We have employed a new assay consisting of human umbilical vein endothelial cells (HUVEC) fixed onto slides and combined it with indirect immunofluorescence to detect AECA (TiterplaneTM technique, Euroimmun GmbH). Sun et al reported that de novo AECA detected by TiterplaneTM were correlated to rejection after deceaseddonor kidney transplantation in a Chinese cohort (Kidney Int. 2011 Mar; 79 (6) :655-62). Among study criticisms was the lack of HLA typing for HUVEC lines used in the assays, since HUVEC also express HLA and thus the assay could have had false positives anti-HLA antibodies rather than AECA. We retrospectively replicated their study across a spectrum of 216 solid organ transplants (deceased donor and living donor kidney, pancreas transplant alone, pancreas-after-kidney, simultaneous pancreas and kidney) performed consecutively at the University of Pisa Transplant Centre in [2009] [2010] [2011] [2012] . Stored sera at posttransplant month +1, +3, +6, year +1 and +2 were available for 187 recipients. A single lot of Titerplane kits was used, and the HUVEC line was HLA typed (A/B/C/DRB1/DQB1), censoring all positive reactions occurring in the presence of donor-specific anti-HLA antibodies. Overall AECA prevalence was 7% in our cohort (vs. 25% in the Chinese study). We found a very low incidence of de novo AECA (0.1% vs. 10% in the Chinese study), likely due to the occurrence of 39% of living donor procedures (implicating shorter cold ischemia times) in our cohort. We report for the first for the first time the occurrence of negativization of preexisting AECA (6 out of 13) after transplantation, likely due to maintenance therapy. Background: Malignancy post-transplantation has incidence rates 3-5 times higher than in the general population and is the second commonest cause of death. cSCC occurs in the UK in 30% of kidney transplant recipients (KTRs) within 10 years of transplantation. Previously we have shown that high numbers of T-regulatory (Treg) and low numbers of Natural Killer (NK) cells predicts cSCC development in KTRs. In this study we aimed to validate the presence and stability of high Treg /low NK phenotype in long-term KTRs. Materials/Methods: We prospectively studied gender, age, and duration of immunosuppression matched long-term (mean = 17.1 years) KTR's with (n = 60) and without (n = 50) cSCC. Mortality during follow up (mean = 4.2 years) was 18.2% (n = 20); 9.1% (n = 10) failed grafts; 14.5% (n = 16) lost to follow up. Thirty-six KTR's from cSCC group and 28 cSCC-free KTRs were re-assessed. Flow cytometry to examine lymphocyte subsets was performed on fresh blood samples, and clinical phenotypic data collected using a questionnaire. Results: We found increased Treg cells (CD3 + CD4 + CD25hiFOXP3 + ) [p = 0.03], but no significant difference between the proportion or number of NK cells (CD3-CD19-CD16 + CD56 + ) in patients with a cSCC compared with those without. Importantly we found no significant change in the proportions of T lymphocyte subsets in SCC or non-SCC group over the follow-up period. KTRs on azathioprine have significantly reduced proportion and numbers of NK cells (p > 0.01). Conclusion: Monitoring immune phenotype in long-term KTRs can potentially identify patients at an increased risk of developing a cSCC. Immune phenotype remains stable over time in the setting of chronic immunosuppression. Immune markers could be incorporated into a useful clinical predictive index of cSCC risk in KTRs. University of Illinois; 2 Washington University Viral infections remain a major complication following transplantation and may be exacerbated by immunosuppressive treatments. For example, BK virus (BKV) develops in approximately 10% of kidney transplant patients resulting in the loss of the graft in 15-50% of affected grafts. The role of specific genotypes of BKV, other polyoma viruses including JC virus or other associated infections remains unknown. To investigate the role of urinary infections in kidney transplantation, we analyzed the metagenome of patients with a clinical diagnosis of BK infection (and control patients diagnosed BK negative) using deep sequencing by the Illumina HiSeq 2000 platform. We obtained 6-12 9106 reads per sample. After BLAST analysis to filter human sequences and assembly, we analyzed data with CLC and Megan software. Our results demonstrated: 1) detectable levels of BKV was identified in all transplant patients including the controls without a clinical diagnosis of BKV, 2) we identified 18 different genotypes of BKV, and 3) many patients had multiple different genotypes with a maximum of 9 different genotypes identified in a single patient. We also identified additional viruses including JC, torque teno and numerous less abundant viruses. We are currently correlating the BK genotypes with clinical outcomes following transplantation. Background: Advances in immunosuppressive therapy have led to better transplant outcomes, making heart transplantation (HT) a valid treatment for end stage heart disease. The purpose of this study was to identify which combination of variables potentially influences outcomes in our working area. Methods: A retrospective analysis of 102 patients who underwent HT at our Institute from October 2004 to August 2012. Results: Mean recipient age was 49.9 years. The majority was male (82.3%). Most frequent indications for HT were ischemic (46.1%) and idiopathic (29.4%) cardiomyopathy. Mean donor age was 34.4. There were 37 female donors (36.3%). Most frequent causes of death were cerebral bleeding in 37 patients (36.3%), head trauma in 54 (52.9%), and ischemic stroke in 4 (3.9%). Mean ischemic time was 173.8. Ischemic time was ≤120 min in 19 patients (18.6%), >120 and <180 in 27 (26.5%), ≥180 and 240 in 16 (15.7%). Actuarial survival was 84% at 12 months; 15 deaths occurred in the first 3 months, and 1 after 240 days. In this population, risk factors affecting outcomes were donor and recipient age (p = 0.002 and p < 0.0001), cause of death (p = 0.036), and ischemic time (p = 0.023). Donor age was correlated with cause of death (p = 0.0001). An ischemic time of >180 min was associated with higher mortality among the entire study population (p = 0.014), and we found a fourfold increase in mortality risk for the group of patients with an ischemic time of >180 min when compared with the group with an ischemic time of <180 min (p = 0.017). Conclusions: This study identified an epidemiology different from northern Italian, and European, transplant centers in terms of donor age and cause of death, which appears to be closely linked to age. Recipient and donor age, ischemic time, and donor cause of death other than head trauma were associated with poor outcome. The fact that 42.2% of organs were procured outside the Sicilian region was not significantly associated with either higher donor age or lower incidence of head trauma as cause of death. Conversely, we found significant differences in ischemic time values when organs were procured outside of Sicily. Endomyocardial biopsy (EMB) is the gold standard for diagnosis of acute cardiac allograft rejection; however surveillance EMB protocols were developed with earlier immunosuppression regimens. We retrospectively analysed the clinical and EMB findings during the 1st year following orthotopic heart transplantation in patients with a negative HLA crossmatch. Mean age at transplantation was 48 (range 18-65). Indications for transplantation included dilated cardiomyopathy (72%), ischaemic cardiomyopathy (21%) and 1 case of post partum cardiomyopathy, 1 restrictive cardiomyopathy and 1 hypertrophic cardiomyopathy. Immunosuppression was rabbit antithymocyte globulin induction followed by maintenance tacrolimus, mycophenolate and steroids Four patients were treated for clinical rejection with a biopsy showing ISHLT 1R. Four patients were treated for ISHLT 2R biopsy proven rejection in the absence of symptoms, i.e. the true yield of surveillance biopsy without clinical indication was 0.88% and the incidence of treated asymptomatic rejection 9.3%. All episodes of rejection occurred within 83 days of transplantation The scarcity of rejection episodes in patients transplanted with an HLA negative crossmatch and quadruple sequential immunosuppression has reduced the yield of routine surveillance EMBs and suggests that their frequency should be reduced or that other methods of monitoring be used. Furthermore, since all the ISHLT 2R rejections were asymptomatic, the issue of whether histologically diagnosed asymptomatic 2R rejection always requires increased immunosuppression in patients receiving quadruple therapy needs to be investigated further.  Background and Aims: Growing evidences have demonstrated a tight kidney-heart connection. However, while it is well established that compensatory and persistent hypertrophy occurs in the remaining kidney following unilateral nephrectomy (UNX), it remains unknown whether remodeling process also occurs in the heart following kidney donation. Thus, the aim of our study was to investigate long-term (≥5 years) myocardial structure and function in healthy kidney donors. Methods and Results: A total of 12 kidney donors (≥13 years of age) and 13 sex matched healthy subjects were evaluated by standard and speckle tracking echocardiography (STE). In particular, longitudinal systolic strain (sS) and strain rate (sSR) for the inferoseptal and lateral walls were assessed. On average, patients donated one kidney 8.1 years before enrollment (range: 5.2-10.3). Left ventricular (LV) wall thickness (10 AE 0.8 vs. 9.2 AE 0.09 p 0.04) as well as stroke volume, cardiac output and cardiac index were lower in controls as compared to donors, although mitral inflow parameters, sS and sSR, were similar in the two groups (À22.6 AE 1 vs. À21.2 AE 2.2 p 0.11 and À1.5 AE 0.2 vs. À1.7 AE 0.3 p 0.21, for sS and sSR, respectively) Conclusions: Kidney donors have no apparent structural or functional myocardial abnormalities by standard or speckle strain echocardiography 5 years post UNX. However, more sensitive evaluation (cardiac magnetic resonance, or cardiovascular biomarkers) are warranted for a definitive conclusion. Background: This was a single-center retrospective study to assess the surgical outcomes of liver transplant recipients undergoing cardiac surgery with the use of extracorporeal circulation. Methods: Between 2002 and 2012, 21 patients with a functioning liver allograft underwent cardiac surgery (CABG n = 6; AVR n = 10; MVR n = 1; HTx n = 1; pulmonary embolectomy n = 3). The mean interval between liver transplantation and cardiac surgery was 4.5 AE 4.6 years. The patients were divided in to two groups according to their belonging to either Child-Pugh group A = 14 patients (66.6%) or B = 7 patients. (One patient classified as Child-Pugh C was excluded from our study). Pre and postoperative data were analyzed. Results: The 30 days mortality was 9.5% (2 patients; 1 death after modified Trendelenburg's operation for pulmonary embolectomy, one after aortic root replacement and bypass surgery because of destructive endocarditis of the aortic valve and abscess formation). The survival rate was 76.1% at 1 year, 71.4% at 5 years and 66.7% at 10 years. Patients in the Child Pugh group A had a significantly better short time survival compared to group B: 92.9% compared to 42.9% at 1 year (p = 0.02). The long time survival did not differ between both groups. Cox regression analysis showed pulmonary embolectomy to be an independent risk factor predicting mortality (three patients; all passed within the first year). Conclusions: Cardiac surgery in liver allograft recipients was associated with acceptable surgical results in. Grouping the patients according to their Child-Pugh status of their liver allografts may be a predictor of early mortality. A risk stratification according to the MELD score of the patients did not reach Introduction: Muscle dystrophy (MD) has been considered a contraindication for heart transplantation. Nevertheless, the feasibility of heart transplantation in patients with inherited myopathies has been described in several recently published case reports. Here we present our clinical experience in heart transplanted recipients with MD. Methods: We searched our patient records for heart transplant recipients with MD and evaluated their clinical outcome. Grad of mobilization was defined: Grad I bedridden, Grad II: confined to a wheel chair, Grad III: Walking aid (Rollator), Grad IV: confined to a cane, Grad V: self-sufficient and was evaluated pr€ a-HTX, month 1 (t1), month 12 (t12), month 60 (t60). Results: Between January 1989 and December 2009, 11 patients with MD were transplanted at our institution. Of these patients, five had an Emery-Dreifuss-MD, four had a Becker-Kiener-MD, one had a Neuromuscular-Typ-MD and one had a Multi-Core-MD. Mean age was 33.4 years (range: 18-58 years). Mean ischemic time was 205 min (range: 142-266 min). Maintenance immunosuppressive therapy was cyclosporine A plus cortisone (n = 5) and tacrolimus plus mycophenolate mofetil (n = 6). Median survival was 80.3 months (range: 0.6-236 months). One-year and 5-year survival rates were 91.7% and 81.5%, respectively. Of the three patients who died, causes of death were rejection (n = 1); graftvasculopathy (n = 1); and technical complications (n = 1). Currently, all eight patients who are still alive are in good clinical condition. There is no evidence for an increased risk of adverse events such as neurological complications or myalgia. Referring the mobilization grading a significant improvement was seen (p < 0.05): pr€ a HTX: Grad I 54%, Grad 46%; t1: Grad II 10%, Grad III 40% and Grad IV 50%. T12: Grad II 10% and Grad V 90%. t60: six of six patients Grad V. Conclusion: To our opinion, in patients with end-stage heart failure due to MD, heart transplantation is a reliable treatment option with acceptable long term results. Background: Sinus tachycardia is common after heart transplantation due to graft denervation. Given heart rate reduction is linked to improved clinical outcomes in patients with native cardiovascular disease, the merits of lowering post transplant sinus tachycardia (PTST) warrants further investigation. Tachycardia can predispose to localised inflammation and immune activation within the transplanted heart (by increasing myocardial metabolism), yet to date the effects of heart rate on inflammatory status remain unknown. Methods: We prospectively studied immune profile in 11 heart transplant recipients with PTST (HR >90 bpm). Patients were administered Ivabradine (5 mg twice daily) and dose adjusted based on tolerance. Peripheral blood samples were taken prior to drug initiation, then at 6 and 10 weeks. A total of 8 chemokines were quantified via a multiplexed bead based luminex assay. Results: Ivabradine induced significant heart rate reduction (mean bpm [95% CI] 100. 6 [97.4-103.7] vs. 77.3 [73.0-81.6] vs. 73.8 [70.7-76.8 ] for baseline, 6 and 10 weeks respectively, p < 0.001). However, heart rate reduction does not alter the circulating chemokine environment in this cohort. No significant difference was observed in the concentration of: RANTES (p = 0.146), eotaxin (p = 0.363), MIP-1a (p = 0.159), IL-8 (p = 0.369), MIP-1b (p = 0.705), MCP-1 (p = 0.100), IP-10 (p = 0.431) or MIG (p = 0.746) and heart rate at any time point Conclusions: Ivabradine had no effect on the peripheral chemokine profile in this cohort, despite significant heart rate reduction. This suggests that while being effective in lowering heart rate, Ivabradine has no systemic effect on cellular trafficking following heart transplantation. Introduction: According to Tpe index and T wave analysis in predicting dangerous arrythmias, in this study the effects of dialysis and renal transplantation on Tpe, Tpec,Qtc,Qtd,Tpe/Qtd parameters & also the association between electrolyte change, arterial blood gas and these parameters would be assessed. Materials and Methods: In a retrospective study, 42 transplant patients in the case of not having the existing criteria were selected, under the superrision of a cardioelectrophysiologist information as well as electrolyte information, arterial blood gas (ABG) before & after dialysis, and after transplantation were analyzed. Results: The mean Pre-dialysis and post-dialysis Tpe were respectively 0.063 AE 0.002 & 0.058 AE 0.002 (p = 0.087). Two weeks after transplantation, it was 0.052 AE 0.002 which was significant before (p < 0.001) & after dialysis (p = 0.019). The mean pre-dialysis and post dialysis TpeC were 0.0672 AE 0.003 & 0.0614 AE 0.002 which was statistically significant (p = 0.030). After transplantation, it was 0.059 AE 0.002, that just comparing to pre-dialysis was significant (p = 0.005). The mean pre-dialysis and postdialysis QTD were respectively 0.073 AE 0.005 & 0.070 AE 0.004 (p = 1.000). After transplantation, it was 0.066 AE 0.004 which wasn't significant before and after dialysis. The mean pre-dialysis and post-dialysis Tpe/Qt was respectively 0. Background: Echocardiography is fundamental in managing patients with PGF after Htx supported by extra-corporeal membrane oxygenation (ECMO) from cannula placement to weaning decision. Several echocardiography parameters as well ejection fraction (EF) >35% to 40%, an left ventricular (LV) outflow tract velocity-time integral >10 cm, absence of LV dilatation, aortic valve opening (AVO) rate and eventually, mitral regurgitation (MR) degree may predict a successful weaning. The aim of our study is to analyze the role of TEE in complications detection, cardiac recovery and readiness for ECMO weaning in patients with PGF. Methods: Over 104 orthotopic HTx performed between 2006 and 2013, 10 patients developed PGF requiring ECMO and IABP support. TEE was performed daily to: 1) exclude ECMO dysfunction 2) evaluate: EF, left ventricular end diastolic diameter (LVEDD), AVO, degree of MR; 3) establish the optimal weaning time. Results: The mean age was 46 years and eight were male. Four patients had severe MR. Central/peripheral ECMO ratio was 6/4. Mean support time was 139 h. During ECMO support TEE evaluation evidenced: 1) pericardial effusion compressing heart chambers despite a properly ECMO flows ( patients); 2) no adequate AVO requiring decreasing ECMO speed in one; 3) EF improvement (mean 18% to 66%), decreasing of MR, conservated LVEDD (mean 53.5 mm) and increased AVO rate (Fig 1) . Eight patients were successfully weaned from ECMO (average length of support 6.1AE2.3 days) and 7 (70%) survived to hospital discharge and are still alive. Causes of dead were multi organ failure. Conclusion: TEE is a powerful tool to monitor the heart during ECMO support. Despite early complications detection as well strict cardiac recovery monitoring by daily TEE can favorable affect weaning successful rate, the decision to wean and its timing are still a complex issue. Jacek Malyszko 1 , Piotr Przybylowski 2 , Ewa Koc-Zorawska 1 , Michal Mysliwiec 1 , Jolanta Malyszko 1 1 Department of Nephrology and Transplantology; 2 Department of Cardiac Surgery and Transplantology VAP-1 (vascular adhesion protein-1) is a copper-containing SSAO (semicarbazide sensitive amine oxidase) secreted by vascular smooth muscle cells, adipocytes, and endothelial cells. Elevation of SSAO activity is observed in atherosclerosis, diabetes mellitus and obesity. Renalase, a novel protein believed to participate in the regulation of blood pressure, is also monoaminooxidase, present in endotheliaal cells. Considering all these data, the aim of the study was to assess VAP-1 and renalase in 128 prevalent patients after orthotopic heart transplantation [OHT] (96 males) and 130 renal allograft recipients (90 males). Methods: Complete blood count, urea, serum lipids, fasting glucose, creatinine, were studied by standard laboratory method. We assessed VAP-1 and hsCRP with commercially available assays. Background: Today transplant recipients are older, sicker and have more comorbidities than in earlier eras. The aim of this analysis was to evaluate incidence, risk factors and outcome after sternal-wound complications in a current heart transplant cohort Methods: A retrospective analysis was performed in 534 heart patients, transplanted between 1998 and 2011. Complications were defined according to tissue involvement and presence of infection. Therapy was defined as conservative or surgical. Risk factor analysis was performed to evaluate previously published variables. Survival was compared between patients with versus without wound complications by Kaplan Meier analysis. Results: Twenty-six (4.9%) patients developed sternal wound complications. 15.4% of cases were non-infectious complications, whereas 61.5% were bacterial and 23.1% were fungal infections. Tissues involved were skin/ subcutaneous (61.5%), deep soft tissue (15.4%) or sternum/retrosternal space (23.1%). Median time to bacterial and non-infectious complication infection was shorter than in fungal infections (24 vs. 110 days). Conservative therapy was used in three cases (11.5%) whereas surgical therapy was used in 23 (88.5%). In 17 patients (77%) vacuum assisted closure therapy was used; six underwent (23%) surgical debridement. We identified six significant risk factors (p < 005): transfusion requirement post transplantation ( Background: Tricuspid valve insufficiency is common after heart transplantation (HTx) but need for replacement or repair is rare. Patients with signs of advanced right-sided heart failure are considered at higher risk for surgery. Aim of this study is to evaluate if a minimally invasive approach for tricuspid valve surgery can guarantee better results. Methods: We reviewed our overall experience between 1985 and 2012 (497 HTx). Five patients (1%) developed symptomatic severe tricuspid regurgitation (TR) with right ventricular failure requiring surgical treatment after a mean interval of 81 (8-138) months after transplantation. TR mechanism was: leaflet prolapse due to chordal rupture after biopsy injury in three patients, leaflets theatering in 2, both combined with annular dilatation. Surgical approach was right minithoracotomy, peripheral vessels cannulation for extra corporeal circulation, and beating heart procedure. Results: Treatment was bioprosthetic valve replacement in three patients, ring implantation in 2. Two patients died due to refractory right ventricular failure despite temporary mechanical circulatory support. One patient developed renal failure and cerebral ischemia, one needed prolonged ventilatory support. During follow-up (27 AE 13 months), survivors improved their functional NHYA class (<2 in all), had no recurrence of right failure with minimal dose of diuretics (furosemide 25-75 mg/die), and no prosthetic or repair failures occurred. Conclusions: Treatment of patient with right failure due to tricuspid regurgitation after HTx is associated with high morbidity and mortality even if minimally invasive technique is employed. Early surgery could get better results. Background: It is proposed that circulating hematopoietic stem cells (HSC) may have some impact on pathogenesis of cardiac allograft vasculopathy (CAV). It was shown that in heart recipients high plasma levels of placenta growth factor (PlGF), soluble CD40 ligand (sCD40L) and pregnancy associated protein A (PAPP-A) are negative predictors of CAV development. The aim of the study was to determine relationship of HSC number in peripheral blood before and after HTx with plasma level of the biomarkers. Methods: We studied 42 pts. (33 men; 43 AE 15 years) with heart failure caused by ischemic (25 cases, 21 men; 51 AE 10 years) and dilated cardiomyopathy (17 cases, 12 men; 33 AE 12 years), 28 of them received HTx (22 men; 39 AE 14 years). HSC (as CD34/CD45 positive cells) were measured in peripheral blood by flow cytometry and expressed in mean number of the cells per 106 events AE SD, plasma level of the biomarkers -by ELISA. Results: The number of CD34/CD45 + cells in pts. with heart failure (196 AE 169) was similar to those in healthy individuals (208 AE 124) but there was significant difference (p = 0.03) in the cell number between pts. with ischemic (168 AE 159) and dilated cardiomyopathy (245 AE 195) . The cell number did not correlate with age, sex, body weight, blood cells counts and preoperative levels of PlGF (25.9 AE 15.0 ng/l), sCD40L (5.0 AE 3.0 ng/ml) and PAPP-A (42.0 AE 20.7mlU/L). In 2-5 days after HTx the cell number decreased to 96 AE 86, p = 0.01 and did not differ in pts. with previous ischemic (100 AE 86) or dilated (98 AE 97) cardiomyopathy. After HTx the cell number correlated with WBC (r = À0.45) and did not correlate with age, sex, body weight, ischemia and hypothermia duration, blood loss volume and preoperative level of the biomarkers. Conclusion: Circulating HSC number is lower in pts. with ischemic cardiomyopathy than in those with dilated cardiomyopathy and decreases after HTx. The cell number before and after transplantation does not correlate with plasma levels of the negative predictors. Methods/Materials: This was a 38 years female patient at the transplantation time, with a medical history of hyperlipidemia and smoking which had severe Coronary Artery Disease, with multiple myocardial infarctions, refractory angina and severe LV dysfunction. In 1991 an orthotropic cardiac transplant was performed with an ischemic graft period of 120 min. She required peritoneal dialysis during 10 days before being discharged at 21 postoperative days. Results: The first endomyocardial biopsies revealed a light rejection grade 1a, becoming negative after six months. Her immunosuppressive therapy was based on Cyclosporine, Prednisone and Azathioprine scheme, drugs that she has tolerated very well and has been the immunosuppressive treatment with slight changes to present day. The follow up angiograms have been normal. Lately, she has had an appendectomy, salpingectomy and hysterectomy. The medical condition is overall good, receiving medication for hypertension, diabetes mellitus and hyperuricemia with a mild secondary renal failure. The last echocardiogram shows a slight aortic regurgitation with a 45% ejection fraction and type 2 diastolic dysfunction. She is in a NYHA 2 functional class with some knee movement limitation due to degenerative arthropathy. At the present time, she is 61 years old, currently living in a rural community, married and fully integrated to the society. Conclussion: This case represents a landmark in the Social Security system of Costa Rica. The follow up after more than two decades reveals a prolonged survival time in a limited resources environment with an unique health system in Latin America. She is part of a group of patients (the first in Central America) admitted into a heart transplant program that started in 1990 with a one year survival of 80%. Background: Long-term survival after heart transplant (HTx) is impaired due to rejection, opportunistic infections and malignancies, and metabolic disorders. Everolimus (RAD) has been introduced more recently and could affect in a different manner the most significant clinical end points. The aim of this study was to assess resuts of de novo immunosuppression with RAD + CyAin terms of death, graft failure, rejection, kidney disease and infections. Methods/Materials: In a retrospective analysis of our single center experience, we studied 47 consecutive patients undergone heart transplant from 2006 through 2011. The clinical outcomes evaluated were death, graft dysfunction, infections, cancer, kidney disease and lipid abnormalities. Cytomegalovirus (CMV) replication was also assessed. Results: Three patients died. Causes of death were cardiac allograft vasculopathy for one patient and a malignancy for two patients. Acute cellular rejection (ACR) occurred in 11 (23%) while cardiac functional impairment was observed in 12.7% in the RAD group. Opportunistic infections were observed in only two patients, but CMV infection or disease was observed in 8/47. After HTx, median eGFR declined up to 3 years post-transplant with a better prophile in patients with GFR less than 60 (10 patients whose Renal functrion at 3 years was higher than the preoperative). Conclusions: RAD use is associated on the short term with a low rate of CMV infections/disease. Renal function showed a decline on the long run clearly more evident in patients with a better preoperative renal function. This results could be related with the higher CNI exposure achieved in patients with good renal function. An aggressive reduction of CNI is desirable when using RAD as denovo primary immunosuppressor. Background: Malignancies are a major cause of death after heart transplant (HT). While several risk factors have been suggested to promote carcinogenesis after HT, data about markers and strategies influencing outcome after cancer onset are lacking. The use of mTOR inhibitors reduces the occurrence of malignancies after transplant, and everolimus (EVE) has been registered for the treatment of several solid organ cancers in the general population, but its effect as immunosuppressant in HT recipients with a concurrent malignancy is unknown. Methods/Materials: From clinical charts of all patients followed in our Center between October 1988 and July 2012, we collected data about cancer incidence, staging (presence (M1) or not (M0) of metastasis), treatment, immunosuppression, and 5-years survival after cancer diagnosis. Results: Out of 500 patients, 71 (14.2%) developed a solid organ cancer (16.8 AE 2.2% at 10 years after HT), with a poor 5-years survival (43.4 AE 6.8%). Although cancer incidence did not differ between study eras (before-after 2002), after a standardized protocol for malignancy surveillance was established, cancer-related death (p = 0.02) and incidence of M1 status (47.9% vs. 19.0%, p = 0.02), significantly reduced. As expected, M1 predicted negative outcome (p < 0.01) while availability of surgical treatment was protective (p = 0.03). Treatment with EVE after cancer diagnosis (20 patients) was associated with a 64% reduction of relative risk for death (p = 0.01, Figure) . Benefit of EVE therapy was more evident in patients who were M0 at diagnosis. Conclusions: Despite several limitations, this study supports the concept that early diagnosis of solid organ malignancies after HTx may provide a more favorable prognosis, suggests the feasibility of an aggressive surgical treatment, and provide a strong rationale for the introduction of EVE as an effective rescue strategy in patients with malignancies, in particular in the subgroup diagnosed at early cancer stage. EXCELLENT LONG-TERM OUTCOME FOLLOWING ORTHOTOPIC HEART TRANSPLANTATION PERFORMED FOR ANTHRACYCLINE INDUCED CARDIOMYOPATHY Ramesh Kutty 1 , R.V. Venkateswaran 2 , Clive Lewis 1 , Pedro Catarino 1 , Catherine Sudarshan 1 , John Dunning 1 , David Jenkins 1 , Steven Tsui 1 , Jayan Parameshwar 1 1 Papworth Hospital; 2 Wythenshawe Hospital Objectives: Advances in the oncological management of many cancers have lead to improved cancer specific survival of patients. However, this leads to increased numbers of patients presenting with end stage heart failure caused by anthracycline induced dilated cardiomyopathy (AIDCM). Successful cases of heart transplantation for AIDCM have been reported, but their long-term outcome is unknown. This study evaluated the long-term outcome following heart transplantation for AIDCM. Methods: All heart transplants performed in a single unit between January 2000 and November 2010 were retrospectively analysed. Patients with pretransplantation diagnosis other than idiopathic DCM were excluded. The case notes of all idiopathic DCM recipients were reviewed to identify pre-transplant diagnosis of AIDCM. The pre-transplant parameters, incidence of acute rejection and infection were collected. The long-term outcome was analysed using Kaplan-Meier survival analysis. Results: A total of 347 heart transplants were performed of which 164 (47.2%) were for DCM. Nine (5.5%) were performed for AIDCM; with 6 in the last 4 years. Five were male and mean age was 38 AE 19 years. Primary cancer sites included breast (3), acute leukaemia (3), lymphoma (1), hepatoblastoma (1) and sarcoma (1) . Following treatment, the mean time to diagnosis of heart failure was 102 AE 41 months and 3 patients (33%) required urgent transplantation. Routine surveillance identified acute rejection in seven patients (77%). The 1 and 5 year survival was 100% and 71% respectively. Kaplan-Meier survival analysis showed no difference in the long-term outcome between AIDCM and DCM recipients (p = 0.64). Conclusion: Heart transplantation for AIDCM is rare, with an apparent increase in incidence in the last 4 years at our centre. Development of symptomatic heart failure often appears late after initial cancer treatment. Background: Heart transplantation (HT) can significantly improve the quality of life, but the patient will have to adapt to multiple limitations and other health problems. HT requires substantial personal, financial, and psychosocial resources. Purpose. This study investigates psychosocial vulnerability as a predictor of quality of life HT recipients. Methods: One-hundred and nineteen patients after heart transplantation were assessed. Psychological vulnerability markers were cognitive beliefs (sense of coherence, optimism and self efficacy), affect (depression and stress). All participants completed a self-report quality of life instrument. Data was statistically analyzed. Background: The number of heart transplants performed by year is declining since the 2000s because of organ shortage. Increasing the donor pool could be achieved by improving graft preservation. This would allow to prolong cold ischemic time or to use extended criteria donors. Hypothermic machine perfusion (MP) has been shown to better preserve kidney, liver or lung grafts. We investigated in a large animal model whether this would be the case in heart grafts. Methods: Sixteen pig hearts were retrieved after cardioplegia and randomized to 4 h preservation on static cold storage (CS) or MP (Modified Lifeport©System, Organ Recovery Systems©, Itasca, IL). The preservation solution was KPS-1 in both groups. After preservation, the grafts were reperfused on a Langendorff during 60 min. Myocardial biopsies were performed at baseline, post-preservation and post-reperfusion to quantify oxidative metabolism by measuring lactate, nucleotides, phosphocreatine (Pcr) and creatine (Cr). Contractility index (CI) was assessed in vivo before cardioplegia with a Millar catheter and during reperfusion with an intraventricular balloon. Results: Compared to MP, hearts preserved on CS showed significant higher lactate levels, higher AMP/ATP ratio and lower PCr/Cr ratio after preservation and during reperfusion ( Figure 1 ). Coronay flow was similar in both groups during reperfusion (CS = 107 AE 9 vs. MP=125 AE 9 ml/min/100 g heart; p = ns). Compared to baseline, CI decreased by 25 AE 10% in the CS group while it remained stable in the MP group. Conclusion: Compared to MP, hearts preserved on CS suffer more severe ischemia during preservation, as shown by a higher lactate and lower energy states. These differences remain after reperfusion despite equal coronary flow in both groups, probably due to oxidative defects in CS group. Functional recovery is better in the MP group. Background: The spectrum of kidney disease (KD) is broad ranging from mild chronic kidney disease to end-stage renal disease, which requires dialysis and kidney transplantation. Coronary heart disease (CHD) is prevalent in KD patients, and contributes substantially to the morbidity and mortality of these patients. However, the classical CHD risk equations have shown limited clinical utility in KD patients. Aims: The aims were: a) to develop and assess the predictive capacity of a CHD risk function based on clinical variables; and b) to evaluate whether the inclusion of genetic variants improve CHD risk estimation. Methods: Our cohort study included 632 KD patients with a median follow-up of 9.13 years. Mean age was 53.4 (AE10.6) years and 32.4% of the patients were male. Seventy three coronary events (fatal-or non-fatal acute myocardial infarct or acute angina) were identified in the follow-up. The clinical CHD risk score included KD status, age, sex, HDL, diabetic condition, hypertension condition, dislypemic condition, hemoglobin A1c. In a second model, we also included a weigthed genetic risk score (GRS) [Cardio inCode Score] with variants previously identified to be associated with CHD and not related with classical cardiovascular risk factors (rs10455872, rs12526453, rs1333049, rs17465637, rs501120, rs6725887, rs9818870, rs9982601, rs10507391, rs17222842, and rs9315051) . Results: The discrimination of the CHD risk function improved with the GRS (c-statistic = 72.0 vs. 68, p-value = 0.015). The calibration assessed by the Howmer Lemeshow test was 9.6, p = 0088 (i.e., calibration was good with no statistical differences between the events predicted and the observed). The reclassification of the patients also improved with the GRS (Net reclassification improvement = 22.0; 95%CI: 5.5; 38.6). Conclusion: The inclusion of a GRS improves risk prediction of CHD in patients with KD. Genetic screening could help to prevent CHD events in this group of patients.  Background: The safety of the donor after donation is still one of the main issues in living donor liver transplantation. We are going to evaluate the overall safety of living donors in our low volume center. Methods: Among the 49 liver transplants, which is total number in our institution and starting from June 2006, 29 living donors of adult living donor liver transplantations, performed from June 2006 to December 2012, were analyzed. Results: There was no operative mortality and no re-operation. The mean age of donors was 27.76. Mean remnant volume was 38.985%. The mean operation time was 5 h and 38.31 min. The mean hospital stay was 12.86 days. There was no intraoperative blood transfusion. There was one major complication which was biliary stricture and it was improved with endoscopic retrograde biliary drainage (ERBD). There were three minor complications which were one mild depression with poor diet, one wound infection, and one postoperative blood transfusion. The global shortage of organ donors has become the key factor halting the progress of organ transplantation. Research and trials have been made to expand donor banks in various countries, but problems of organ transplant tourism, organ trafficking and ethical debates follow at heel, which have aroused extensive attention and further reflection. In this article, we analyze possible strategies to narrow the donor-recipient imbalance, and explore the ethical preferences and ways of compensation to donations by cardiac death (DCD). In our opinion, the fixed compensation mode may be the most reasonable mode, given the actual situation in China at present. The total amount of compensation should be measured comprehensively according to the economic situation in different regions, the cost of transplantation there, and the interests obtained by both the donor and the recipient. Introduction: Hand Assisted Retroperitoneoscopic Donor Nephrectomy (HARDN) is an established technique for live renal graft donation that confers advantages over laparoscopic methods, potentially reducing complications. The incidence of seroma formation following kidney donation before and after the institution of localised wound treatment was observed. Methods: Retrospective review of all live donor cases (June 2011 to June 2012). A comparison of two distinct groups was made. Group 1 -HARDN cases without a drain and Group 2 nephrectomy patients with routine insertion of 10fr Redivac drain. Seromas diagnosed clinically and/or with Ultrasound in outpatient clinics. Results: In group one there were a total of six seromas (n = 24, mean BMI 26.9). Three were aspirated in clinic (mean volume 40 ml) and three underwent drainage (mean vol. 123 ml). In group two, only one seroma was diagnosed. (n = 24, mean BMI 26.6) which spontaneously discharged. Conclusion: The reduced incidence of seroma formation in Group 2 favour localised wound treatment in patients undergoing HARDN. It is now routine practice at our unit to insert a superficial operative drain in all live kidney donors. Rose Marie Liquete 1 , M.A. Zsarin Tuazon 2 1 InFORT, Inc., QMMC-AUFMC; 2 QMMC Introduction: Despite the Organ Donation Act of 1991 organ donation in the Philippines barely advanced. The Quirino Memorial Medical Center is a typical government facility lacking in logistics and manpower, but networking with a private foundation can push forward the frontiers of transplantation. Objective: To analyze organ donation activity at the QMMC and identify factors that influence family decisions and make recommendations. Method: Referred cases for donation and interview data of donor families were analyzed. Results: From 2010 to 2012, 60/209 (29%) of head trauma admissions at QMMC became brain dead but only 37 (62%) were referred for organ donation. Together with 13 other non-trauma patients, 50 potential donors were evaluated. Only 21/50 (42%) were found suitable for donation. Donor creatinine ranged from 37.9 to 187.38 mmol/l (mean -97.52). It took 10-93 h (mean -34 h) for them to deteriorate to brain death from time of injury, and 6-17 h more (mean -15 h)from brain death to retrieval. Retrieved were 41 kidneys, one liver and six corneas. There was doubling in the annual referral (11-23 cases) implying increased awareness, being a transplant center, with a surgical residency program and a neuroscience institute. However, actual retrieval declined annually from 46.6% to 19.4%. This is attributed to more fatal injuries, late referrals and comorbidities. Some families still have misconceptions. In decision-making, opinions of distant relations, common law partners and friends had always played a pivotal role. Cost of donor maintenance were shouldered by the private foundation. Background: Trustful cooperation between the organ procurement organisation (DSO), and the donor hospitals is essential. The "Region Bayern" of the DSO established a telephone survey after organ donation. Hospitals get the possibility to discuss problems and comment the donation process. Methods: The telephone surveys were conducted under the following conditions: -skilled and informed coordinator ("caller"), not involved in donation process himself -caller contacts physician who was responsible for organ donation in the hospital Due to results from our first evaluation in 2011 we Background: Organ donation in Germany is a complex process with many different stakeholders. The process is coordinated by staff (coordinators) from the german organ procurement organisation, which are not employees of the donor hospital. In 2011 the "Region Bayern" started a questionnaire to detect problems in the donation process caused by collaboration with different stakeholders. Methods: The questionnaire is filled out by the coordinators following the organ donation and evaluates the following stakeholders: hospital staff, explant surgeons, eurotransplant, and other service providers. Two hundred and fortyeight questionnaires are evaluated. Results: In 32% one or more problems were documented: The main problems (73%) were reported in collaboration with hospital staff (e.g. lack of medical knowledge, family approach, access to the operating theatre, etc.). In 14% coordinators reported about problems with surgeons and in 13% with other service providers. Conclusion: In the german transplant law organ donation is a common task of all hospitals in cooperation with the organ procurement organization. However, the separation of responsibilities and additional work load is often a problem leading to little appreciation of the organ donation. Reasons and solutions will be presented. In order to reach high quality levels in organ donation, Donor Action program (DA) started in 1998, to check whether all brain deaths are diagnosed, referred and assessed in Emilia-Romagna ICUs. Methods: The program involved 29 regional ICUs, seven belonging to hospitals with neurosurgical department, identifying deceased patient charts through the regional computer network by 22 Hospital Transplant Coordinators collaboration, to avoid missing any potential donor. Results: Total deaths in ICUs rose from 1998 to 2012, in spite of a decrease in the percentage of deaths with severe brain damages on total deaths (43.9% vs. 20.15%) and a significant increasing brain death assessments (86 vs. 198 ). In the last years is reported a decrease of family refusals too. Over the years, organ donation improved and transplant centres achieved high level activity standards. Conclusions: Despite severe brain damage death reduction, a remarkable brain death assessment gain was observed in Emilia-Romagna ICUs. These results confirm that: a) DA is an efficient quality control program in ICUs; b) it is correct to extend identification of brain injured patients in departments other than ICUs. (iii) Implementation of the "Deceased Alert System" (DAS); (iv) Application of the "Essential in Organ Donation" (EOD) and 5) Hospital Audit. Monthly monitoring meetings to make needed adjustments based on the specific characteristics of the country were done. Results: During the 4 years before of the SEUSA model implementation, two deceased organs donors were procured in Trinidad. The SEUSA Started in July of 2010, it has been implemented the phases 1-3. In 2012, 167 alerts of possible Donor Circulatory Death and 35 alerts of possible Donor Brain Death happened, 13 cases were diagnosed as Brain Death and seven family approaches were done. Seven forensic cases reported and one authorized. Finally two actual donors were obtained in one year. The main reason that explains the difficulties of the organ procurement was the lack of guidelines when a coroner case occurs. Background: Diagnosis of brain death is determined when loss of all brain stem reflexes and apnea is permanently observed. Reflex motor activities known as spinal reflexes occur frequently in brain-dead and they do not disprove the diagnosis of brain death. This study aimed to evaluate the association between different factors and rate of medullary reflexes in braindead. Methods: Brain-dead bodies transferred to the organ procurement unit of Masih Daneshvari Hospital during a one year period starting from June 2011 were evaluated for the spinal reflexes. Demographic characteristics, vital signs; serum electrolytes and arterial blood gases were compared among those with or without reflexes. Background: The most important problem in our country such as the rest of the world is the shortage of organs for transplantation. We could recognize four changeable aspects: 1-Donor detection 2-Family approach 3-Donor maintenance 4-Social awareness Methods: We handled these problems with designing some new projects: 1-Creating a team consisted of some expert nurses for inspection of ICUs "Inspector project" 2-Training the coordinators and some psychologists for family approach 3-Active donor management right after detection 4-Performing many social awareness activities such as: 5-Online registry for Donor card 6-Taking cooperation of the other organizations such as mass media 7-Annual Organ donation celebration 8-Volunteers' project (using the volunteers help in social awareness activities) Results: 1-Jumping the family consent rate from 32% to 90% 2-Increasing the PMP from 5.7 to 25 3-Improving the quantity and quality of retrieved organs Conclusion: The mentioned projects have been the most effective way for increasing the pool of potential donors in Iran. However, donor safety is a primary concern, and selection of the preoperative imaging modality is important in preserving donor's health by excluding unsuitable candidates, and tailoring the surgical procedure according to anatomic variations. In this study, we evaluate the impact of multislice spiral computed tomography on potential donor selection and surgical planning before living-related liver transplant. Materials and Methods: One-hundred seventy-five potential living-liver donors (62 women and 113 men; age range, 23-34 years; mean, 32 years) were included in our study. All subjects underwent multiphasic multislice spiral computed tomography. Postcontrast acquisitions were obtained for the arterial and venous phases. There were 139 potential donors for the right lobe and 36 potential donors for the left lateral segment. All data were analyzed to detect vascular variants, exclude focal liver lesions, and determine hepatic volume, and preoperative findings were correlated with intraoperative findings in 65 patients. Results: Of the 175 potential liver donors evaluated with multislice spiral computed tomography, 56 (32%) were excluded for the following reasons: portal vein anomalies in 11 (19.6%), hepatic venous anomalies in 9 (16.1%), fatty liver in 17 (30.3%), small liver volume in 12 (21.4%), and a focal lesion in the liver in 7 (12.5%). Of the 65 candidates, surgical planning and technique were modified in 24 donors and recipients, in 23 candidates, and the donor only in one candidate. Conclusions: Multislice spiral computed tomography provides parenchymal, vascular, and volumetric preoperative evaluation of potential donors for livingrelated liver transplant and has an effect on surgical planning: It allows the surgeon to reduce postoperative complications by modifying the surgical technique. Maria Paula Gómez 1 , Martı´Manyalich 2 , Blanca P erez 1 1 DTI Foundation; 2 Hospital Cl ınic de Barcelona Background: IRODaT is the first registry in this field, which contains statistics of deceased/living donors and transplants. Out of the 105 countries with organ donation or transplantation activity, 86 national reporters submit data to IRODaT. Methods: IRODaT is a friendly, easy to use database. Reporters introduce the figures of their countries directly to the webpage. Experts validate and update the data. IRODaT staff process the information and produce different materials to meet users' needs and requirements. Results: The registry enables the analysis of donation activity at national level. For example we are able to identify a decrease in donation activity in Austria from 24.3 dpm in 2006 to 23.5 dpm in 2011. A further analysis reveals an increase of donation activity between 2008 and 2009 when the rate reached 25 dpm. Currently Austria has higher donation rates than the European average rate of deceased organ donation. The new IRODaT work line aims at offering activity data at REGIONAL level. It will analyze regions with homogenous number of inhabitants helping to identify peer developments. Conclusions: IRODaT is able to provide basic statistics within a short timeframe, based on a worldwide network of experts involved in organ donation and transplantation. The data have proved to be of an extreme value to scientific programs, social and governmental bodies. Background and Aim: There is marked regional variation in organ donation among different region of Saudi Arabia. Mobile donor team was active in Centeral region since 2006. Our aim is to study the reasons for this variation in order to improve organ donation in areas of low donation rate. Methods: Saudi Center for organ transplantation (SCOT) data for cadaveric organ donation from 2006-2011 detailing the number of cases reported, documented, consented and harvested, as well as the distribution by region (central 29.4% of the total population Saudi Arabia, western 32%, eastern 15%, northern 8%, southern 15.6%). The number of contributing ICU stratified by size of ICU and the region was also reviewed. The overall donation rate as well as the percentage of harvested cases per region as well as the conversion rate (harvested/Documented) was reviewed. Results: Between 2006-2011, 448 cases procured form Saudi Arabia, of which 343 where procured from central region representing 76.5% coming from 30 out of 97 contributing ICU's (31%), the eastern region came second with 49 cases (11%) followed by the western region with 35 cases (7.8%) while northern and southern region had 12 and 9 cases (2.7&2%) respectively. The conversion rate followed a similar trend. This is related to the presence of active mobile donor team in Riyadh (the capital) as well as active transplant centers. Conclusion: There is marked variation with regards of contribution to organ donation in different regions in Saudi Arabia from 2% in the southern area to 76.5% in central area. This is related to the presence of active mobile donor team in the central region. A similar trend towards increasing number of cases and conversion rate was observed in the eastern region after having a new mobile donor team. We suggest that having active well trained mobile donor team in each region will increase the number of cadaveric donor at least 3 folds in the next 3-5 years. Aim: The organ shortage associated with the increased waiting list time have led to the acceptance of marginal donors. On the other hand, a "perfect liver" can expand the graft pool by using the split liver technique. The purpose of this study is to evaluate our liver transplantation experience using graft from deceased donors and alternative liver transplantation technique. Patients and methods: From January 2010 to December 2012 we performed 191 liver transplantations, 146 by using grafts from deceased donors. There were transplanted 140 patients using whole graft technique and six patients using split liver technique. Donor and recipient data were analyzed by both uniand multivariate Cox proportional hazard model analyses. The grafts from marginal donors were used in patients with hepatocellular carcinoma and liver cirrhosis (30 patients). Results: Primary graft non-function was recorded in two cases (one in case of a marginal donor). Four patients were retrasplanted (2 primary graft nonfunctions, one hepatic artery thrombosis and one ischaemic type bile lesion). Over the past 15 years organ donation criteria were extended to older or vascular BD donors in an attempt to overcome organ shortage. Among non-optimal donors, we performed a 5-years retrospective study to analyse the results of organ transplantations from donors affected by a rare disease. From January 2007 to December 2012 we found 388 donors with rare diseases in the French Agency of biomedicine registry out of 9250 donors (0.4%). Thre hundred and thirty were retrieved. We classified diseases as neurodegenerative and non-neurological. Those procurement rates increased between 2007 and 2012, mainly (40%) in neurodegenerative diseases (ALS, multiple sclerosis, chorea etc., fig 1) . The average number of organ retrieved was three per donor. The cohorts were rather young excepted for the neurodegenerative group whose average age was higher than the national one. Reasons for organ refusal was the rare disease status, either by following recommendations that the disease was a procurement contraindication (von Hippel, lymphoma) or by precautionary principle. The pathway of organs retrieved and accepted and the success of transplantation were studied 1 year, 3 years, and 5 years. Some of these diseases appear to have a significant transplant failure rate. For most of them (cohort 2007/2009) the 3-years survival looks identical to standard donors. This study showed that potential donors carrying rare disorders can be eligible and utilized donors and that organs pathway can be extrapolated in accordance to the type of pathology. Collaboration between Agency of biomedicine and "Orphanet" will develop eligibility sheets for these potential donors based on the literature and experience drawn from this study. survival. Mostly, organ damage is caused during brain death (BD), cold ischemic time (CIT) or after reperfusion due to oxidative stress or the induction of apoptosis. The aim of this study was to study a panel of genes involved in oxidative stress and apoptosis and compare these findings with immunohistochemistry from a BD and living donation (LD) pig model and after cold ischemia time (CIT). Methods: BD (n = 6) was induced in pigs; after 12 h organ retrieval was performed; heart, liver and kidney tissue specimens were collected in the BD and in a LD model. PCR analysis for NFKB1, GSS, SOD2, PPAR-alpha, OSXR1, BAX, BCL2L1, and HSP70.2 was performed and immunohistochemistry was used to show apoptosis and nitrosative stress induced cell damage. Results: In heart tissue NFKB, GSS, SOD2, PPAR-alpha and HSP70.2 gene expression was higher in BD after 4 h of CIT; in liver tissue, BCL-2L1, GSS, OXSR1, NFKB1, SOD2 and BAX gene expression was significantly higher in BD after 6 h of CIT. No differences could be observed in kidney tissue. In all organs, activated capsase-3 and nitrotyrosine positivity was significantly higher in BD after CIT. Conclusion: Our results showed an up-regulation in most of the genes encoding for enzymes protecting the organs from oxidative stress in BD; however after CIT apoptosis was more likely to occur in BD organs as compared to LD. Background: Outcome data of live donors with axially malrotated (AM) kidneys in the context of normal function is unknown. Unilateral AM is not an absolute contraindication for live donor nephrectomy. The decision to proceed is made on an individual basis at the multidisciplinary level, with anecdotal evidence. The estimated incidence of AM in a donor population is <1%, although may be larger in the general population. As such, a dilemma is faced as to whether it is appropriate to leave a healthy donor with a known anatomical abnormality in which long term outcome is unknown. This unknown can lead to the rejection of a suitable donor. In this report the outcomes of donors with a contralateral AM kidney are presented from the experience of a single UK centre. Methods: Four potential donors presented over a 6 month period during 2012. CT angiogram of these patients demonstrated a unilateral right malrotated kidney. Split function was performed on all patients alongside routine screening protocols. In all cases, the left kidney was favored for donation due to vessel anatomy or function. Follow up after donation was undertaken and is currently on going. Results: Three patients (all female, mean age 58 years) were selected for left donor nephrectomy, with the 4th declined due to a potential tumour on CT imaging. To date two patients have successfully donated the anatomically correct left kidney, with a 3rd awaiting paired exchange. Follow up serum creatinine at 1 week and 6 months for the first patient was 92 lmol/l with no associated hypertension. The 2nd patients' renal function at 2 weeks was stable at 102 lmol/l. Her procedure was uneventful, and she was discharged without compromise to her renal function or blood pressure. Objective: Brain death (BD) organ donation is an option for patients with end stage organ disease ESOD. The objective of this study is to evaluate the demographic criteria and challenges of organ donation among potential brain dead (BD) organ donor patients and plan a strategy to improve organ donation in Qatar. Materials and methods: This retrospective review was carried out from January 2011 to April 2012. Various criteria of BD patients in the intensive care units (ICUs) of HMC, and possible reflection on organ retrieval were studied. The time intervals analyzed to determine the possible causes of organ retrieval delay were: time of diagnosing fixed dilated pupils in the ICU, to performing the first BD test, then second BD test, to family approach, to organ retrieval and/or circulatory death (CD) without organ retrieval. The mean DD organ recovery in our country reached 16 pmp last year, and is similar to that observed in Germany, the Netherlands and a number of other European countries. However the number of people dying in ICUs and neurological and neurosurgical utilities is much higher. Donation rate in various regions of our country differs greatly (from 5 to 28 pmp). In our previous studies we showed that there is a great difference in attitude of physicians toward the recognition (and acceptance) of brain death and organ recovery. Seven hundred and forty-four anesthesiologists, neurologists and neurosurgeons (i.e. physicians involved in brain death diagnosis) were interviewed. Physicians from regions with low donation rates (LDR) were twice more reluctant than their colleagues from high donation rate regions (HDR) to start the diagnostic procedure when clinical signs suggesting brain death were present (14% vs. 7% would not diagnose death, respectively). In 2012 we monitored the death rate among patients treated in the ICUs, and neurological and neurosurgical utilities of three regions of the country and calculated theoretical potential of deceased organ donors according to DOPKI donation index. Results are shown below: In conclusion, low donation activity seems to be mostly due to the medical staff attitude. Moreover, the tendency to diagnose brain death exclusively for purpose of organ recovery was observed. Does this mean that two concepts of death are in use? Tomasz Jakimowicz, Slawomir Nazarewski, Tomasz Ciacka, Lukasz Romanowski, Amro Alsharabi, Jacek Szmidt Medical Univerity of Warsaw, Department of General, Vascular and Transplant Surgery Objective: The advantages of minimally invasive nephrectomy are: faster recovery, shorter hospital stay and better quality of life for the donors. It helps potential donors to make the decision to donate and therefore expands the donor pool. The aim of the study was to present the biggest polish single center experience in hand assisted laparoscopic donor nephrectomy (HALDN). Material and Methods: First HALDN in Poland has been done in our department on 18.06.2003 and was performed retroperitoneally as well as next two cases. Those three were left kidneys. From 06.06.2011 we changed the method to transperitoneal approach and started to harvest also right kidneys with hand assisted laparoscopic method. From this time we used it in all consecutive donors except one who refused laparoscopy and three with multiple renal arteries which we considered contraindication for laparoscopy on the beginning. Our total experience is 32 operations -18 left (3 retro-and 15 transperitoneal) and 14 right kidneys (transperitoneal). All but one had single renal artery. In all cases we used hand-port (Gelport in last 29 cases) and renal vessels were closed with endo-staplers. WIT was 80-420 s (mean 217, 8 s). Results: All surgeries were uncomplicated and all donors were discharged home after 2-7 days with the creatinine level in normal range. The follow-up was uneventful in all cases. None of the kidneys had nephrectomy dependent complications however there were two cases of transient DGF and one kidney was lost in third postoperative week due to the urether necrosis and infection. Background: As a result of the actual amendment of the German transplantation law, every citizen will be regularly asked by health insurance companies Abstracts of the 16th Congress of the European Society for Organ Transplantation Posters about his attitude towards postmortem organ donationwithout the obligation to decide. The aim is to increase the willingness of donations as well as the availability of organs. Therefore, we investigated the level of information of students at the University of Regensburg and their agreement to organ transplantation regarding an informed consent. Methods: Using an interdisciplinary developed questionnaire (Medicine, Theology, Educational Science) the level of information concerning process and possibilities of organ donation, the possession of an organ donor card, as well as the active or passive consent to donate organs was investigated. Results: Out of 1225 respondents 31.5% had an organ donor card, 49.1% wanted to donate organs, 32.1% were unsure. Ninty-eight percent generally favoured organ donation. However, serious information deficits about brain death were identified: 37.4% did not know that brain death is a prerequisite for a post-mortem organ donation, 18% thought brain death is reversible, 52.7% were not aware of the necessity of intensive medical care. Furthermore, providing information about other potential donor organs including lungs, pancreas, small intestine, and tissue is required. Conclusion: Health insurance companies and responsible authorities need to close the identified gaps in knowledge in order to achieve "informed" consent with organ donation, which might increase the availability and number of donor organs. Background: This is a report of 100 consecutive hand assisted retroperitoneoscopic live donor nephrectomies (HARS). The main benefit of this approach is increased safety for the donor. Risk of bleeding and intraabdominal injury is low thanks to hand assistance and extraperitoneal approach. This method has been introduced at our unit in January 2003, since June 2011 is being used for all the donors including right sided and complex anatomy cases. Methods: This study reviews last 100 consecutive cases of living-donor nephrectomies performed since the HARS has been introduced for all the cases with no exclusions. Data were collected prospectively. The operation is performed in the manner described by Wadstr€ om et al 2002, with minor modifications. Results: There was no conversion to open nephrectomy, one donor was reoperated on the first postoperative day for bleeding from paraaortic lymphatics, this donor was also given two units of blood. The median blood loss was zero otherwise, meaning no use of suction or no blood in container. The median post-operative hospital stay was 2 days. Minor complications include one wound infection and three wound haematomas. Major complications included bleeding from paraaortic lyphatics mentioned above required retroperitoneoscopic exploration and one incisional hernia. All donors have life-long follow up. All transplanted kidneys had immediate function, we did not observe any delayed graft function. Conclusions: HARS is a safe way of performing living-donor nephrectomy with minimal morbidity and fast recovery. It is safe and quick alternative to the intraperitoneal approach, or other nephrectomy techniques. It can be used safely for all the anatomical variations as well as right sided cases. Introduction: Urinary tract infections (UTIs) are the most common infections in renal transplant recipients. Acute graft pyelonephritis (AGPN) is considered a potential risk factor for poorer graft outcomes, however its clinical impact still remains controversial. Methods: We performed a retrospective cohort study reviewing medical records of patients who received a renal transplant at Gdañsk Transplantation Centre between January 2007 and December 2009. We analyzed urine cultures performed within first 12 months after RTx with reference to clinical data. Renal function assessed by creatinine concentration and eGFR was recorded 24 months after RTx. Results: We studied urine cultures and clinical data from 209 renal transplant recipients, including 59.3% of male gender, with mean age of 46 AE 14 years. We observed 70 AGPN episodes defined as the presence of significant bacteriuria, fever >38⁰ and/or graft pain and/or acute graft function impairment, including 13 cases of bacteraemia in 46 patients. This accounted for 22% of all diagnosed UTIs. Over 80% of all AGPN episodes were diagnosed beginning from the second month post-transplant and the most frequently isolated uropathogen was Escherichia coli (65.7%, n = 46). Female gender, vesico-ureteral reflux or strictures at the uretero-vesical junction and history of CMV infection emerged as independent predictors of AGPN. The evolution of renal graft function over the period of 24 months measured by serum creatinine concentration and MDRD eGFR did not differ significantly between patients with and without AGPN. Conclusions: AGPN may be a marker of underlying impairment of urine flow e.g. due to vesico-ureteral reflux or strictures at the uretero-vesical junction, while it does not affect graft function in renal transplant recipients. Results: Steroids did not significantly affect HEV replication. However, calcineurin inhibitor (CNI) FK506 significantly enhanced HEV infection in both subgenomic and infectious models. Another CNI, cyclosporin A (CsA), which potently inhibit hepatitis C virus (HCV) infection, also resulted in enhancement of HEV infection. Forty-eight hour treatment of 5 lg/ml of CsA increased luciferase activity up to 2.5-fold (p < 0.01) in the subgenomic model and increased HEV genomic RNA by 9.6-fold (p < 0.01) in the infectious model. Using an RNAi gene silencing approach, the CsA-induced enhancement of HEV infection was found to be mediated by its cellular targets cyclophilin A and B. In contrast to CNIs, mycophenolic acid (MPA), an inhibitor of the IMPDH enzyme, inhibited HEV replication. Treatment with 10 lg/ml of MPA for 24 h resulted in 52¡ A3% (p < 0.01) inhibition of HEV luciferase activity. Ribavirin is another IMPDH inhibitor without immunosuppressive property that is often considered as an off-label drug for treating chronic HEV. Similarly, 100 lmol\l of ribavirin resulted in 51¡ A8% (p < 0.01) inhibition of HEV luciferase activity. Supplementation with exogenous guanosine partially restored their antiviral activity, suggesting depletion of cellular nucleotide pool contributing to the antiviral action. Conclusion: Both CsA and FK506 enhance HEV infection. Similar to HCV, MPA was found to suppress HEV replication. These findings may help to choose the right immunosuppressive medication for post-transplant patients who are infected with HEV. Results: The incidence of positive PF was 34.8%, mainly staphylococci, 9.9% C. albicans. Urine culture was positive for the same bacteria of PF in four recipients. In 30/101 positive PF, the bacteria isolated were sensitive to AP. The infection rate between recipients changing AP according to PF (51/101) and recipients maintaining AP regardless PF (21/101) was not different. Conclusion: Although PF contamination is frequent, the incidence of PFrelated infections is low and changing of AP does not cause a reduction of recipient bacterial infections. Nevertheless, culture of PF should be routinely performed to identify fungal contamination. Kidney transplantation outcome is affected by liver disease in patients with HCV infection. Factors associated with progression of liver disease were not studied before with sequential liver biopsy. The aim of this research is to study the natural history of liver disease post kidney transplantation in patients infected with HCV supported by sequential liver biopsy. Methods: This is a prospective longitudinal study of all kidney transplantation patients infected with HCV in a tertiary care centre in Saudi Arabia, study started January 2007 and is still ongoing. Patients were planned for liver biopsy at year 1, 5 10 and 15 post kidney transplantation. All patients had liver biopsy before kidney transplantation. Results: About 1951 kidney recipients were screened, 285 had HCV, 136 patients underwent liver biopsy. Mean age was 43 + 15 years. Males were 55%. Tacrolimus was used in 70% of patients. Majority (> 90%) of patients were also on prdnisone and MPA. Viral genotype 1, 4 and 2 were found in 82 (60%), 44 (32%) and 10 (7%) patients. Twenty percent of patients had persistent elevation of liver enzymes and 50% had transient elevation. Metavir scoring system was used to grade inflammation and stage fibrosis. Patients who crossed one grade of inflammation or one stage of fibrosis in comparison to baseline biopsy were classified as progressors. Safety data showed two patients had in adequate tissue, 13 had mild pain responding to oral pain killer. No patients had bleeding, required admission or blood transfusion. Table 1 Necro-inflammation and fibrosis based on metavir scoring system 0 Kidney transplantation is the best modality treatment for any chronic renal failure patient, but sometimes it associates with horrible complications that one of them is allograft nephrectomy and post allograft nephrectomy bleeding. The vascular complications of post transplant allograft kidney is rare but they sometimes result in very bad outcomes (1) . In our kidney transplant department with more than 20 years of experience, there were two cases of post allograft transplantation nephrectomy bleeding due to weakness of carell patch caused by it's infection after nephrectomy. For controlling the bleeding, the external iliac artery was ligated without any consequent ischemic finding at corresponding foot with subsequent reperfusion of it with collateral artery especially superficial femoral artery. Results: The most common symptoms were dry cough (80%), fever (73%), dyspnea (60%), hypoxemia (SpO2 less than 85%; 47%) and weight loss (40%). Chest x-ray was interpreted as normal in all cases, but 'ground-glass' infiltrate was found on chest CT in 67%. Graft function was not deteriorated during PJP, except of 3 cases when chronic hemodialysis was restarted. Treatment with trimethoprimsulfametaxozole (TMP-SMX) was successful in 80%, but none of patients was able to tolerate the recommended dose of the American Society of Transplantation guidelines (Am J Transplant 2004; 4 (suppl. 10): 135-141) due to side effects. The mean tolerated dose was 960 mg bid. The mortality rate was 20% and was associated with graft loss (p = 0.01) and development of pneumothorax (p = 0.03) . The growing incidence of PJP led to necessity of implementation of universal TMP-SMX prophylaxis in middle of 2011, what resulted in relative decrease of the number of PJP ( Figure) and absence of PJP from June 2012. Brain infections in patients undergoing haemopoietic stem cell transplants or solid organ transplants, thus seriously immunosuppressed, are very complex to deal with and lead to higher mortality rates. It would very important for diagnostic images to be interpreted in a more accurate and consistent way so that treatments could be applied more rapidly. The Brain Supporters Project aims at creating an international database capable of gathering an extensive collection of radiologic images of brain lesions together with the relevant clinical, laboratory and microbiological data. Starting from this database the possibility is envisaged to develop an "intelligent" software that through the use of multi-dimensional analysis techniques, variational methods and classification procedures taking advantage also of neural networks and Bayesian forecasting models, can detect, highlight and differentiate the minimal and yet peculiar differences in the "radiologic footprint" connected with the local alterations of brain tissue produced by each individual pathogen, thus becoming an objective diagnostic aid not influenced by the individual interpretation given by the operator. An internet site will be created, www.brainsupporters.eu, freely accessible to transplant centres world-wide. The radiologic images with confirmed diagnosis collected in the database will then be subject to a blind evaluation (without knowing the microbiologic diagnosis) by a team of specialists belonging to at least two of the Centres taking part in the project, so as to obtain an independent confirmation of the diagnosis. The images will then be classified by aetiologic agent and subsequently by age group and by clinical characteristics of the patients. It will thus be possible to evaluate if and how the "radiologic footprint" of lesions due to the same pathogen is modified depending on the different characteristics of the host. Background: To prevent cytomegalovirus (CMV) disease, most transplant centers use antiviral prophylaxis to the CMV (D+/R-) risk patients. However, late primary infections after cessation of prophylaxis may occur. In this study, we investigated the long-term efficiency of valganciclovir prophylaxis in preventing primary CMV infections in adult liver transplant petients. Methods: Of 154 consecutive adult liver transplant recipients transplanted 2006-2009, 20 (13%) CMV D+/R-recipients received valganciclovir prophylaxis up to 3 months after transplantation. The patients were frequently monitored for CMV by quantitative real-time PCR for one year after transplantation. After excluding the recipients with incomplete prophylaxis or monitoring, 13 (D+/R-) patients with follow-up of >4 years were included in the study. Results: During valganciclovir prophylaxis no break-through CMV infections occurred. After cessation of prophylaxis 12/13 (90%) patients developed CMV infection mean 165 days (range 95-320 days) post transplantation. Two lowlevel CMV infections were ansymptomatic and were not treated with antivirals, 6 infections were successfully treated with valganciclovir, and four severe cases of CMV disease with intravenous ganciclovir and secondary valganciclovir prophylaxis. No intragraft infection was seen, but one patient developed gastrointestinal CMV. Recurrent asymptomatic low-level CMV replication was recorded in three patients, 6 months, 3 years and 3.5 years after transplantation. One patient died of bacterial sepsis, but no patient or graft was lost due to CMV. Conclusions: During valganciclovir prophylaxis no break-through CMV infections were recorded. Primary CMV infections after cessation of prophylaxis were common, but were successfully treated with valganciclovir (or ganciclovir). Methods: Two CE marked screening immunoassays and an immunoblot (confirmatory assay) were used for detection of HLTV-1 antibodies. Proviral DNA was quantified in blood and biopsies of organ recipients by HTLV-1 realtime polymerase chain reaction (RT-PCR). Results: Proviral HTLV-1-DNA was detected in all blood samples of organ recipients (1 9 10 4 -1 9 10 6 copies/ml) but seroconversion was delayed for up to 2 years in screening assays and more than 6 years in the confirmatory assay. In two of three organ recipients a cutaneous T-cell lymphoma was diagnosed 2 and 3 years after infection, respectively. Proviral HTLV-1 DNA concentration was almost 1 copy/cell in cutaneous lymphoma biopsies whereas in biopsies of other tissues ≤0.03 copies/cell were found. The organ recipient did not suffer from lymphoma but detailed clinical data on this patient were not available to us. Conclusions: Biopsy results support an etiological role for HTLV-1 in these cases of primary cutaneous T cell lymphoma after solid organ transplantation. Diagnosis of potentially HTLV-1 associated disease in organ recipients may require PCR because of delayed seroconversion and rapid onset of disease. Background: Hepatitis C virus (HCV) infection is an independent risk factor for renal transplant recipients. The aim of the study was to present the long term clinical outcome of HCV positive renal transplant recipients. Methods: A retrospective study was performed in order to analyze the long term clinical outcome of 54 HCV positive living donor kidney transplant recipients, transplanted in the period from 1992 to 2008. The 1, 5 and 10 years patients and graft survival rate, GFR-MDRD, the renal and extra renal morbidity and mortality were analyzed. Anti-HCV status was determined before transplantation. The results were compared with outcome of 69 HCV negative patients who were recruited during the same period. The usual triple drug immunosuppression was used in both groups of recipients. There was no difference regarding donor and recipient's age, HLA mismatch, delayed draft function and rejection episodes between the groups. Results: The 1, 5, and 10 years HCV positive patients survival rate was 96%, 94.4 and 79.4% compared with 98%, 96.9% and 84.3% in HCV negative recipients, which is statistically significant (p < 0.05) . The cardiovascular morbidity and mortality was predominant in HCV positive patients compared with infection and sepsis in HCV negative recipients. Calculated GFR-MDRD was significantly lower in HCV positive than in HCV negative patients (43.4 + 9.5 vs. 55.9 + 13.2 ml/min/1.73 m 2 , p < 0.000). There was no significant difference in graft survival rate among the groups (98.1%, 92.6% and 83% vs. 98.6%, 94.2% and 90.7%, respectively, p < 0.87). None of the recipients developed cirrhosis and diabetes mellitus during the follow up. Background: IFIs occur in 4% to 15% of LTx patients. Candida and Aspergillus account for nearly all IFIs with high attributable mortality (30-70%). While targeted antifungal prophylaxis (TAP) seems justified in high risk (HR) pts, more controversial, in spite being used, is AP in low risk (LR) pts. Material and Methods: Retrospective review of 192 consecutive LTx recipients who received universal AP (UAP) to determine 1) the incidence of early IFIs and the associated risk factors (RF); 2) the proportion of pts at high (HR) and low risk (LR) for IFI; 3) how appropriate was UAP in this series. Immunosuppression included antithymocyte serum, steroids and IL2 inhibitors. UAP included oral nystatin, and Fluconazole. Amphotericin B lipid formulations (ABL) were used as TAP (3-5 mg/kg/day, 7-10 days) in case of fulminant hepatic failure (FHF), post-transplant abdominal reexploration, retransplantation, renal failure, CRRT, acute rejection, documented mould colonization and/ or positive galactomannan assay. Results: Median age was 54 years, MELD score 15 AE 7. LTx indications were viral cirrhosis (70%), ETOH cirrhosis (25%), miscellaneous (5%) Mortality rate at 3 months was 5%. Infections episodes were present in 40 pts (21%). 45 pts were at HR for IFI (24%), 147 (76%) at LR. 4 IFIs were recorded in 4 pts (2%, CI 95% 0.02-3.98%), more represented in HR pts (6.6%, vs. 0.7%, p = 0.04): 2 had C Glabrata candidemia and recovered; two had invasive Aspergillosis (1 proven, 1 probable) and recovered. Independent RFs for IFI were HR, CRRT, FHF, fungal colonization, peritonitis, blood stream infection. Conclusions: TAP approach with broad spectrum antifungals (ABL) in the HR group might have played a role in achieving these good results. Our study confirms the futility of UAP with FLU in LR pts. Due to the different risk factors for Candida and Aspergillus, broad spectrum antifungals (ABL vs. echinocandins) are to be considered for TAP. Background: Recurrence of focal segmental glomerulosclerosis (FSGS) is an important cause of graft loss following kidney transplantation. The management of patients with recurrent FSGS is not well established because there are no prospective randomized studies with a view to the impact of FSGS on graft survival. Recent studies suggest that rituximaban anti-B-CD20 monoclonal antibody may be therapeutic alternative in selected cases resistant to conventional therapy. Opportunistic infections with rituximab have not been studied extensively, but recent studies suggest an increased risk for Pneumocystis jirovecii pneumonia (PJP) following rituximab therapy. Methods: We report the case of a kidney transplant recipient with the recurrence of FSGS in the graft, who developed fatal Pneumocystis jiroveci pneumonia subsequent to treatment with rituximab. Our patient was treated with plasmapheresis and a complex immunosuppressive drug scheme for the recurrence of FSGS in transplanted kidney. However this treatment had no effect on the amount of proteinuria which increased to maximal 15 g per day after 18 session of plasmapheresis. Thereafter 500 mg i.v. of rituximab was administrated at a four week interval. Results: The number of CD19 positive B lymphocytes decreased from 9% to 0.57%. 2 months after the second dose of rituximab proteinuria decreased to 2.1 g per day. 10 months after transplantation and five months after first dose of rituximab was administrated the patient developed severe PJP pneumonia and died despite all efforts with antibiotic therapy. Conclusions: It seems to be essential that all renal transplant recipients treated with rituximab should currently be considered at an increased risk for PJP. This case suggest that prolonged or restarted prophylaxis for PJP should be recommended following not only conventional treatment for acute rejection episodes but after use of rituximab in combination with other immunosuppressive therapy as well. Clinical samples were taken from these recipients before transplantation, intraoperatively and during the first month after the operation. Cultured bacterial and fungal strains were identified and characterised at the Chair and Department of Medical Microbiology at the Medical University of Warsaw using standard microbiological methods. The differences between isolated strains in these four periods have been evaluated by statistical analysis using SAS 9.1 program: chi-square test, Fisher test. Differences between the incidence rate in two periods (2001-2004 vs. 2005-2007) was performed using bootstrap method. The significance level was considered to be alfa = 0.05. In the analysed clinical materials a high prevalence of multidrug resistant strains was  Abstracts of the Background: To develop a practical score -based on readily available immunological parameters-to predict the risk of infection in kidney transplant (KT) recipients. Methods: We included 245 patients who undergo a KT between November 2008 and July 2011. Total lymphocyte count and peripheral blood lymphocyte subpopulations (PBLSs), serum immunoglobulin levels (IgG, IgA and IgM), and serum complement levels (C3 and C4) were investigated at months 1 and 6. Predictors for overall and opportunistic infection in different post-transplant periods (intermediate [months [1] [2] [3] [4] [5] [6] and late [>6 months]) were assessed by Cox regression models. One point was assigned to each of the following: IgG hypogammaglobulinemia (<700 mg/dL), C3 hypocomplementemia (<83 mg/dL), and low counts in some PBLSs (CD8 + T-cell <0.200 9 103/ll at month 1 and CD3 + T-cell <0.500 9 103/ll at month 6) . The index was collapsed into three groups: low-(score of 0), intermediate-(score of 1-2), and high-risk (score of 3). Results: According to the score value at month 1, cumulative incidences of overall infection at the end of the intermediate period were 19.3%, 41.8% and 77.8% in low-, intermediate-and high risk-groups, respectively (p < 0.001). Cumulative incidences of opportunistic infection were 8.8%, 25.9% and 55.6%, respectively (P = 0.001). In the multivariate analysis, compared to the low-risk group, the hazard ratios for overall infection in the intermediate-and high-risk groups were 1.96 (95% confidence interval [CI]: 1.01-3.79) and 4.14 (95% CI: 1.82-9.41), respectively. The area under receiver operating characteristics (auROC) curve of the model at month 1 for predicting infection in the intermediate period was 0.68 (95% CI: 0.61-0.75). In the late period, cumulative incidences of overall infection were 8.6%, 23.2% and 50.0% in low-, intermediate-and high risk-groups, respectively (p = 0.011) . The auROC of the model at month 6 for predicting late infection was 0.65 (95% CI: 0.55-0.75). Conclusions: A simple score, on the basis of scheduled monitoring of PBLSs and serum IgG and C3 levels, is useful for evaluating the risk of infection after KT. Since 2001 hygiene management in Germany is regulated by law according to the Infection Protection Act (IPA; Infektionsschutzgestz, IfSG). After revision in 2011, the act highlights the legal character of guidelines published by the Robert Koch Institute (Division of Applied General and Hospital Hygiene and Commission for Hospital (healthcare associated). Mentioned amendment had become necessary inter alia after reality stroke expectations regarding presupposed control of MRSA in Germany: In 1997 MRSA-prevalence (KISS-data from 200 ICU) rose from an average of 8% to 30% until year 2003. Moreover at least 400 000-600 000 nosocomial infections are presupposed in Germany annually, whereof 14 000 MRSA-infections. As this situation has impacts on organ transplantation programs, too, consequently case reports regarding the spread of MRSA via organ donation have been published. Moreover, there is evidence suggesting that the outcome of S. aureus donor-torecipient-transmitted infection might be poor in cases of solid organ transplantation. Today, regarding hygiene management, organ donation programs in Germany usually refer to respective hospital hygiene guidelines which are not specially adapted to the needs of multi-organ donations involving multiple teams arriving from different places bringing along their own equipment for organ recovery, preservation and transportation. Regarding the above, it is of major importance to apply and adapt standardized guidelines for hygiene management of MRSA in organ donation and transplantation programs, too. The present recommendations on hygiene management of MRSA in organ donation and procurement refer to mentioned regulations and guidelines but as well take into account other actual published literature. As it is generally agreed upon that the course of nosocomial infection is mostly due to transmission via contaminated hands, hygienic hand disinfection remains the most important measure in organ transplantation setting, too. This study aims to evaluate the impact of positive transport fluid cultures following deceased-donor kidney transplantation. Materials and Methods: A retrospective analysis over an 8-month period assessed 41 consecutive transport fluid cultures. Recipient demographics: median age 56.9 AE 12.9, inpatient-stay 5.7 AE 2.1 days, 31 DBD, 11 DCD. All patients received prophylactic antibiotics as per institution protocol. Patients were followed-up for 90 days. Results: Ten recipients had culture-positive perfusion fluid (CP) and 31 were negative (CN). There was no difference in white cell count, serum creatinine and eGFR at Day 7, 30 and 90. Patients in the CP group had a numerically higher rate of culture-proven infective episodes (urinary, wound, bacteraemia) compared to the CN group (8/10 vs. 14/31, P 0.0578). Of these eight episodes, 50% had similar organisms cultured to that of the transport fluid. One patient in this group required graft nephrectomy for ongoing sepsis. Conclusions: This study suggests that positive transport fluid cultures are associated with increased incidence of infections. This should prompt clinicians to be pro-active in ascertaining culture results and establishing appropriate treatment early in the post-transplant period. Background: Amphotericin B (AmB) and fluconazole are recommended for antifungal prophylaxis after liver transplant (LTx) . In this open-label, randomised, multicentre trial, the efficacy and safety of micafungin was compared with site-approved standard care prophylaxis (SC) in LTx pts at high risk of invasive fungal disease (IFD). Methods: After LTx, pts were randomised 1:1 to iv micafungin 100 mg once daily (od) or iv SC (fluconazole 200-400 mg od; liposomal AmB 1-3 mg/kg/ day; or caspofungin 70 mg loading, 50 mg maintenance od) . The primary endpoint was clinical success (absence of a proven/probable IFD and no additional antifungals) at end of prophylaxis (EOP). Non-inferiority (10% margin) of micafungin versus SC was assessed in the per protocol set (PPS) and confirmed in the full analysis set (FAS). Safety assessments were adverse events (AE) and liver and kidney function. Results: The FAS comprised 172 micafungin and 172 SC pts. Mean age was 51.2 years, 48.0% had a MELD score ≥20. Most common risk factors for IFD were post-operative renal impairment (31.4%), abdominal re-operation within 5 days of LTx (21.5%) and pre-operative renal impairment (20.3%). 60 (17.4%) pts had intra-operative transfusion of ≥20 units of cellular blood product. 13.4% of pts had a previous liver transplant. 22.7% of donors were >65 years old. At EOP (mean drug duration 17 days), clinical success was 98.6% for micafungin (n = 140) and 99.3% for SC (n = 137; D[95% CI]: 0.7 [À2.7, 4.4]) in the PPS and 96.5% and 93.6% (À2.9 [À8.0, 1.9]) in the FAS. There were four Aspergillus and eight Candida infections at EOP. 70% of pts completed prophylaxis. Incidences of drug-related AEs for micafungin and SC were 11.6% and 16.3%, leading to discontinuation in 6.4% and 11.6% of cases, respectively. Liver and kidney function were similar between groups. Conclusions: Micafungin was shown to be safe and non-inferior to SC as antifungal prophylaxis in high-risk LTx patients. Rationale, Goals and Aims: Invasive fungal infections severely affect lung transplant morbidity and mortality. However, a safe and effective antifungal prophylaxis has not been established yet. The aim of this study is to determine safety and efficacy of antifungal prophylaxis with short-course intravenous ABLC followed by Aerosolized ABLC. Patients and Methods: In this longitudinal retrospective study from Jan 2008 to Jan 2012, we evaluated lung transplant patients of Padova General Hospital, Italy. We analyzed, in two follow-up periods (within 2 and 6 months), the following variables: presence/absence of invasive aspergillosis, concomitant other antifungal prophylaxis, culture-oriented or empiric antifungal therapies, severe bacterial infections, and other risk factors for invasive fungal infections such as adjunctive immunosuppressive drugs, high-dose steroids for rejection, diabetes, dialysis and ECMO. Results: Eighty-four patients were enrolled in the study. Eleven patients could not receive aerosolized ABLC because of clinical incompatibility or intolerance (1/11) and received only intravenous ABLC. The other 73 patients were treated with intravenous ABLC (median 5 days) followed by a median of 4 weeks aerosolized ABLC (50 mg/weekly). Forty-five patients received antifungal therapy within 8 weeks after transplant: in five cases invasive aspergillosis was diagnosed, in 14 patients invasive candida infection was present, and finally in 26 cases antifungal therapy was administered empirically. Between 2 and 6 months we observed two other cases of invasive aspergillosis. Conclusions: Unlike safety, efficacy of ABLC prescribed as prophylaxis in lung transplant patients has not been completely proved. Our study suggests that this strategy could be appropriate. More effort is needed to establish the correct dosage and the adequate length of therapy. Aims: High interindividual variability of anti-HBs consumption may be of multifactorial etiology. We therefore aimed to identify predictive parameters for sc HBIG consumption in a prospective study. Methods: Transplanted HBV patients were switched from iv HBIG to weekly sc HBIG. According to SPC, sc doses of 500 IU/week and 1000 IU/week were initiated in 24 (55.8%) and 19 patients (44.2%) respectively. At baseline, relevant parameters were determined and repeated at day 8, 15, monthly between month 1-6, at month 9 and 12, and comprehensive body composition was assessed using a bioelectrical-impedance-analyzer. Results: Mean body weight, BMI and waist circumference (74.9 AE 14 kg, 26.2 AE 4.9 kg/m 2 and 96.9 AE 13.2 cm) measured at baseline did not significantly change during follow-up. The same was true for renal function and total protein. Pearson correlation analysis showed that anti-HBs titers were negatively associated with MDRD (p = 0.04), total protein (p = 0.04), total body water (p = 0.007), fat-free mass (p = 0.005) and muscle mass (p = 0.01) and positively associated with creatinine (p = 0.03), body weight (p = 0.02), BMI (p = 0.003), body waist (p = 0.03) and fat mass (p = 0.005 Background: CMV infections have been among the most fatal post-OLTx complications. However, post-OLTx CMV prophylaxis has been a controversial issue during the last two decades. Our aim is to present the results of our unit, of long-term post-OLTx CMV prophylaxis. Materials and Methods: Thirty-two adults (7 female) underwent OLTx, within 3 years. Twenty-four recipients were CMV (IgG) positive (R+) and 8 CMV negative (R-). Donors CMV status: 21 were CMV (IgM) positive (D+) and 11 negative (DÀ). Liver-grafts distribution: 18 R+ received 18 D+ grafts and 6 R+ received 6 D(À). Eight R (À) received 8 D(À) grafts. IV Ganciclovir 5 mg/kg/ day, was administered for as long as recipients stayed in ITU. Valganciclovir 900 mg bd given then orally for three months, followed by dose once daily for further three months. Their dose reduced further to one tabl, every other day for six more months. Background: By inhibiting creatinine secretion, it has been well known that high dose trimethoprim (TMP) increases serum creatinine (S-Cr) level without changes in real glomerular filtration rate. But there has been no report regarding the effect of low dose TMP on S-Cr level after renal transplantation (RTx). Materials and Methods: Retrospectively, we investigated fifty-one outpatients who required re-administration of TMP-sulfamethoxazole (TMP-SMX) to prevent the possible outbreak of pneumocystis pneumonia (PCP). Thirteen patients who were not available during the same period were set as a control. Dosage was 80/400 mg (single strength) three tablets per week and administrated about 30.6 AE 13.5 days until the diagnosis of the patient to be PCP was denied. Results: S-Cr was raised significantly in the case group (from 1.40 AE 0.64 mg/dl to 1.48 AE 0.70 mg/dl, p < 0.01) while not in the control group (from 1.39 AE 0.50 mg/dl to 1.38 AE 0.45 mg/dl, not significant). DS-Cr (before and after the administration) was significantly higher in the case group (p < 0.05). S-Cr returned to baseline level after cessation. No adverse events were observed and all patients completed re-administration without failure. Other laboratory data such as serum total bilirubin, serum blood urea nitrogen, serum potassium and urine protein (UP) were not changed significantly. The higher the initial S-Cr levels, the greater the increase of DS-Cr (R = 0.59, p < 0.001). Gender, baseline UP levels, angiotensin-converting enzyme inhibitor/angiotensin receptor blocker use, donor type and time after renal transplantation did not affect DS-Cr. S-Cr returned to baseline levels after cessation. Background: The aim of the study was to evaluate the relationship between inflammation markers [(interleukin-6 (IL-6), high-sensitivity C-reactive protein (hsCRP)], malnutrition and health-related quality of life (HRQoL) with volume parameters [echocardiography (ECO), blood pressure measurements] taken before and 6 months after renal transplantation. Material and Methods: Forty-one patients received deceased donor kidney transplantation were included in this trial. The short form (SF-36) HRQoL scale adapted to Turkish society was used for the HRQoL assessments. Systolic and diastolic blood pressure (BP), echocardiography measurements were used for the evaluation of the volumetric status of patients. Routine biochemistry parameters and demographic data were recorded. Malnutrition scores (Subjective Global Assessment, SGA) and anthropometric measurements were obtained, and inflammation markers (IL-6, hsCRP) were measured. Results: All of the subscales of HRQoL except vitality (energy) were improved after transplantation. Malnutrition and HRQoL were assessed in the preoperative period; SGA, arm circumference, MAMC (mid-arm muscle circumference) and in the post-operative period; albumin, SGA were statistically significant. When we evaluated the inflammation markers and HRQoL, we found relationships between hsCRP and the pain subscale and between IL-6 and the vitality (energy) subscale. For the postoperative period, we found a relationship between hsCRP and the physical function subscale and between IL-6 and the general and mental health subscales. Conclusion: Hypervolaemia and uraemia may cause inflammation, decreased HRQoL and malnutrition. Therefore, the establishment of a normovolaemic status and the decrease in uraemia that occur after renal transplantation can contribute to the decline of uremic inflammation, the improvement of the HRQoL and recovery from malnutrition. Ji Yoon Choi Department of Surgery, College of Medicine, Hanyang University Background: Low functional renal mass and mismatch of donor kidneyrecipient body size can lead to progressive renal injury and poor graft function. So, we evaluated the association between living donor renal volumes and graft function after Tx. Methods: We analyzed 51 consecutive living donor renal Txs carried out between January 2005 and December 2011. The patients were divided into two groups by donor-recipient BSA ratio:group I (n = 31, ı A1) and group ¥AE(n = 20, >1). Results: Serum creatinine after renal Tx was correlated with transplanted renal volume at 1 and 12 months (r = À0.319, p = 0.048; r = À0.472, p = 0.002). Serum eGFR was also correlated with transplanted renal volume at 3 and 12 months (r = 0.318, p = 0.049; r = 0.388, p = 0.015).Serum creatinine levels at 6 and 12 months was higher in group I (p = 0.022, p = 0.007) and serum eGFR at 6 and 12 months after renal Tx was significantly lower in group I (p = 0.042, p = 0.049). Conclusions: Donor's renal volume may reflect allograft function and have a significant impact on graft outcomes. Background: PTDM is associated with poor graft outcomes and increased infections and cardiovascular disease following renal Tx. We assessed the incidence and association between PTDM and graft function. Methods: We investigated 565 renal Txs and divided into two groups:group 1 (n = 228, January 1990 to December1995) and group 2 (n = 377, January 1996 to December 2011). All patients in group 1 received CsA and patients in group 2 received CsA or tacrolimus. We analyzed the clinical characteristics of recipients and long-term graft outcomes. Results: The incidence of PTDM was 11.7% (n = 66). There was a higher incidence of PTDM in the recipients who received tacrolimus than in those who received CsA (25.0% vs. 9.5%, p = 0.000) and the delay before the appearance of PTDM was shorter (38.5 ı¾6.9 vs. 75.8 ı¾7.6, p = 0.017). Serum creatinine levels at 10 years after renal Tx (p = 0.756 in group 1 and p = 0.559 in group 2) and long-term graft survival in those groups were not significantly different (p = 0.067 in group 1 and p = 0.125 in group 2). Conclusion: Allograft function and outcomes are more impaired in patients with PTDM than in either non-DM or pre-DM. However, if early diagnosis and appropriate treatment of PTDM are carried out, the risk of complications can be minimized and the long-term outcomes improved. Background: This retrospective study was undertaken to analyze the possible etiological factors that caused renal graft thromboses after deceased donor renal transplant. Material and Methods: Ten patients who had graft thrombosis following deceased donor renal transplant between 1st April, 2006 and 1st April, 2012 were included. Result: 2.75% of the recipients had renal graft thromboses within the given time period. Mean deceased donor age was 44 years (range 10-68 years). Mean warm ischemia time was 47 min (range 30-54 min). Mean cold ischemia time was 19 h (range 11-28 h). Renal Doppler ultrasound was performed to assess the status of the graft in post transplant period. Mean time interval between transplant and graft thromboses was 3 days (range 2-10 days). Conclusion: Renal vein thromboses appeared to be the most frequent cause of early graft failure. More effort is required to look for possible etiological factors which could help reduce this problem. Background: Ureteral duplication in a renal graft might result in an increased complication rate after transplantation. We analyzed our data of double ureter renal transplantations using a case-control study design and we performed a review of the literature. Methods: From January 1995 to April 2012, twelve patients received a donor kidney with a double ureter (0.8%). We created a control group of 24 patients that matched in age, sex, donor type and ureteral stenting. Patient charts were reviewed retrospectively. Results: In seven patients both ureters were separately anastomosed to the bladder. In four patients a common ostium was created. In one patient one of the two ureters was ligated. No postoperative urological complications occured. In the single ureter group, the urological complication rate was 17% (p = 0.71). Mean creatinine levels after transplantation were comparable between the groups. Conclusion: We conclude that transplantation of a kidney with a duplicated ureter is safe. TRANSPLANT NEPHRECTOMY: WHAT ARE THE SURGICAL RISKS? Victor Alberts, Robert Minnee, Frederike J. Bemelman, Mirza Idu Academic Medical Center Background: Whether or not to remove a failed renal graft has been subject of much debate. We analyzed the morbidity, mortality and risk factors of transplant nephrectomy at our center. Methods: We included 157 cases of transplant nephrectomy in 143 patients, performed between January 2000 and May 2012 at our study center. Patient data were collected retrospectively. Results: A total of 32 surgical complications occurred after transplant nephrectomy (20%) and 16 patients needed surgical re-intervention (10%). Haemorrhage and infection are the most frequent causes of surgical complications (14%). The mortality rate was 3.2%. There were no significant differences in characteristics and timing of transplant nephrectomy between the group with surgical complications and the group without. A total of 59 retransplantations were performed in 57 patients (38%). Conclusion: We found no significant risk factors for surgical complications following transplant nephrectomy. Anti-thymocyte Globulin (ATG) is used to treat acute cellular transplant rejection unresponsive to intravenous steroids. ATG contains antibodies against human T-cells but has numerous adverse drug reactions. There is one case report of hearing loss linked to ATG whereby transient sudden unilateral deafness occurred post-treatment. We describe a patient who experienced sudden deafness 90 min post-infusion. An audiogram demonstrated 93 dB loss in the right and 17 dB loss in the left compared with a baseline audiogram. MRI brain revealed a 3.7 mm right-sided vestibular schwannoma. The post-insult audiogram shows bilateral hearing loss. The schwannoma could not account for this. Timing of onset correlates closely with ATG use, favouring a link. Hearing loss can have a profoundly debilitating impact upon a patient's life. It might be prudent to advise patients' of the risk when consenting and patients with predisposing ear pathology may be recommended to get an audiogram pre-treatment. Brachial-ankle pulse wave velocity and plasma FABP4 was measured using an automatic pulse wave analyzer and commercial ELISA kit. Results: Age, KT duration, triglyceride, systolic blood pressure,, and FABP4 were positively correlated with arterial stiffness, while serum HDL-cholesterol level was negatively correlated with arterial stiffness. Multivariate forward stepwise linear regression analysis showed that systolic blood pressure ( Background: The number of pregnancies in renal transplant recipients has been increased. Many studies show that it increased the risk of graft, fetal, and maternal complication and doesn't affect on long-term graft outcomes, however, there are limited. Therefore, we assessed the incidence of pregnancy after renal transplantation and examined their graft, fetal, and maternal outcomes. We included 145 women recipients who were in child-bearing age (15-45) in our center from January 1990 to December 2011. All recipients were divided into two groups: pregnancy (n = 17) and control (n = 128). Twenty-six pregnancies in 17 recipients were also classified into live births (n = 10) and no-live births (n = 16) and analyzed to evaluate pregnancy outcomes, graft function and long-term graft survivals. Results: Pregnancy outcomes included 10 live births, eight therapeutic abortion, seven spontaneous abortion, and 1 stillbirth. Objective: Adult polycystic kidney disease (APKD) is as a risk factor for the lymphocele (LY) formation. The objective of this work was to describe APKD metabolic role. Method: We have analyzed data of 40 patients who were treated for LY. The Lymphocele Formation Risk Index (LFRI) was calculated. LFRI = albumin/(a1 globulin + c globulin) the total protein and albumin pre-transplant levels were analyzed. The data of APKD and non-APKD patients were compared. Results: Eight APKD patients (25%) were found in cohort. The protein levels in APKD resp. in non-APKD were 57.1, resp. 58.2 g/l (ns), albumin levels were 31.4, resp. 36.2 g/l (p 0.06). Median LFRI in APKD, resp. non-APKD patients were 2.29, resp. 3.44 (p 0.02). Conclusion: The APKD is metabolic factor of high incidence LY in APKD. Not absolute protein and albumin levels, but protein subgroups spectrum are fundamental circumstances. Supported by the project for conceptual development of research organization 00179906. Papillary thyroid carcinoma (PTC) is the most common endocrine malignancy with the increasing incidence in general population. From 1973 to December 2012, 1458 patients received kidney allograft at our institution. We retrospectively reviewed medical files to identify cases of PTC. In five female and three male patients aged 46-59 years, PTC were discovered incidentally based on ultrasonographic screening for evaluation of parathyroid glands pathology 1-19 years after transplantation. Patients underwent total thyroidectomy. The mean size of the largest tumor nodule was 0.72 cm. Postsurgical radioiodine administration was applied. Immunosuppressive protocol was modified, with sirolimus introduced instead of the calcineurin inhibitor in all patients. During the mean follow-up period of 24 months all patients remained disease-free with the stable graft function. Increased rate of PTC may be a consequence of increased diagnostic work-up for evaluation of the parathyroid pathology. The concept of high-urgency (HU) renal transplantation was introduced in order to offer to patients, who are not able to undergo long-term dialysis treatment, a suitable renal graft in a short period of time. The goal of this study was to evaluate the patient and graft survival after HU renal transplantation and compare them to the outcomes of the non HU renal transplant recipients. The course of 33 HU renal transplant recipients operated on at our center between 1995 and 2010 was retrospectively analyzed. The patient survival of the study population was 67%, 56% and 56% whereas the graft survival was 47%, 35% and 35% at 5-, 10-and 15-years respectively. In the comparison between our study population and the non HU transplant recipients, our study population presented statistically significant lower patient survival rates. The HU transplant recipients also presented lower graft survival rates, but statistical significance was reached only in the 5-year graft survival rate. Siren Sezer 1 , Emre Tutal 1 , Mehtap Erkmen Uyar 1 , Zeynep Bal 1 , Bahar Gurlek Demirci 1 , Orhan guliyev 1 , Turan Colak 1 , Mehmet Haberal 1 Baskent University Medical School Background: Previous literature showed strong associations between vascular calcifications and adynamic bone disease. The aim of this study is to evaluate the relationship between pre-transplant bone activity and posttransplant osteoporosis and arterial stiffness in kidney transplant recipients. Methods: Eighty-three patients' clinical and biochemical parameters, pretransplant PTH levels, post-transplant lumbar t-scores and pulse wave velocity (PWv) levels were cross sectionally analyzed. Results: In patients with adynamic bone disease (PTH<100 pg/ml, n = 24) post-transplant serum PTH levels were significantly lower than in patients with those pretrans PTH levels>100 (118.5 AE 14.5 vs. 178.9 AE 17.6 pg/ml, p = 0.029). In linear regression analysis of factors influencing lumbar t-score; pre-transplant and post-transplant PTH levels were associated with posttransplant osteoporosis (p = 0.0049, p = 0.004). Pre-transplant PTH levels were negatively correlated with lumbar t-scores (r = À0.345, p = 0.005). PWv levels were significantly higher in adynamic bone disease group than in normal or hyperdynamic bone disease (7.6 AE 2.5 vs. 6.4 AE 2.0 respectively, p = 0.08). In regression analysis for factors influencing PWv pretransplant PTH levels (p = 0.07) and age (p = 0.046) were the major determinants of PWv. Results: Ten years patient and graft survival was 88.3% and 78.2%, respectively. Malignancy was diagnosed in 5.4%.no differences were found between is regimens with respect to the studied endpoints, excluding nodat. combination of TAC and AZA resulted in higher nodat incidence than other is combinations (p < 0.05). Conclusion: Is did not influence patient and graft survival. this suggests a need for economic evaluation of is. The patients at risk for diabetes mellitus probably do not benefit from TAC and AZA. The use of mTOR inhibitors is limited because of high incidence of adverse reactions (Sanchez-Fructuoso, A.I. et al.Transplantation Proc 2010; 42: 3050-3052) . We report a patient with proteinuria and painful crural ulcerations which appeared after a few years of mTOR inhibitors' therapy and necessitated their withdrawal. A cadaveric kidney recipient, was converted to sirolimus after being diagnosed with carcinoma of his own removed cystic kidney. After 5.5 years of fairly good tolerance of the treatment, the proteinuria and painful crural ulcerations appeared. Because of the progressive character of the adverse reactions and no results of the applied treatment, the mTOR therapy was discontinued, which reduced proteinuria, relieved pain and favoured healing of the ulcerations. Presented case indicates that adverse reactions may develop as a result of mTOR inhibitor use even after many years of good tolerance of the drug and they may necessitate its withdrawal. Background: We evaluated the association of two single nucleotide polymorphisms (SNPs) located in cytokine-inducible SH-2 containing protein (CISH), a negative regulator of IL-2 signaling, with kidney allograft outcomes. SNPs in CISH (rs414171 and rs2239751) were genotyped in 339 donorrecipient pairs of living-donor kidney transplantion (KT). Results: There was no association with acute rejection (AR). eGFR tended to be lower in the group with donor rs2239751 AA genotypes for more than 10 years, after correcting for AR, year after transplantation, donor age, gender of donor and recipient, and immunosuppressant regimen (beta = À3.3, p = 0.057). Graft survival rate was significantly lower in subjects with donor rs414171 TT than TA+AA genotypes (HR 2.7, 95% CI 1.1-6.9, p = 0.033), and it was higher in subjects with donor rs2239751 AC+CC than AA genotype (HR 0.33, 95% CI 0.13-0.84, p = 0.02). Conclusion: Donor CISH polymorphism was associated with long-term graft survival in living donor KT. Retrospective analysis of acute rejection (AR) during the first 6-months posttransplant, and its influence on graft function and survival in 255 adult renal graft recipients treated with a quadruple IS regimen (TAC, MMF, Pred, IL2RAntibody), between 2004 and 2010 in our centre. Thirty (11.8%) patients were treated for AR in the first 6 months posttransplant. Population characteristics and group comparison are shown below. In a multivariate (recipient gender, panel reactive antibody >15%, second graft, number of HLA mismatches by each locus) logistic regression analysis, only increasing number of HLA-DR mismatches was an independent predictor of AR (OR 1.98 per each HLA-DR mismatch, p = 0.014); no association was found between HLA-A (p = 0.52) or -B (p = 0.16) mismatches and AR. Deathcensured graft survival according with AR status is shown below. Only HLA-DR matching was a significant predictor of AR and, therefore, remains an important tool in improving kidney graft outcomes. Background: We aimed to assess the clinical outcomes of kidney transplant recipients (KTR) with human leukocyte antigen (HLA) identical living donor (HLAILD) receiving different immunosuppressive treatments (IT). Methods: Data of 25 HLAILD KTR between 1994 and 2010 years were collected. Patients were divided into 3 groups based on IT: Cyclosporine A (CsA); Tacrolimus (TAC) and Sirolimus (SRL). All groups received also mycophenolate mofetil (MMF) 1000 mg/day. If there was no acute rejection (AR) until 90th posttransplant day (PTD) and until 180th PTD, CsA and TAC doses were reduced 50% and 75%, respectively, with prednisone 2.5 mg/day maintenance. Abstracts of the 16th Congress of the European Society for Organ Transplantation Results: Seventeen patients (11.6%) developed NODAT within 1 year after transplantation. All of the postload plasma glucose concentrations were higher in patients who developed NODAT, while fasting plasma glucose showed no significant difference. Univariate and multivariate analyses indicated each of the postload plasma glucose as an independent risk factor for NODAT. Furthermore, patients with normal glucose tolerance (NGT) and with impaired glucose tolerance (IGT), who were classified using the American Diabetes Association criteria, could be stratified with a 1 h-PG cut point of 152 mg/dl; the rates of the incidence of NODAT were 23.5%, 16.7%, 9.1%, and 0% for patients Forty-two years old female with end stage renal disease on hemodiaylsis underwent living related kidney transplant from her son. On post op day four patient had right lower quadrant pain with hypotension and tachycardia. Bed side ultrasound showed large perinephric hematoma extending retroperitoneal for 20 cm above the upper pole of the kidney. Patient was taken to the operation room for exploration which showed a large crack on the lateral side of the graft extending from the upper pole to the lower pole around 10-12 cm length. Bleeding was controlled using argon and tachoseel was put in the crack and Bioglue injected over it and pressure applied by wet gauze for 10-15 min. The bleeding stopped and biopsy was taken from upper pole using 18 gauge needle gun biopsy. Biopsy showed antibody mediated rejection. kidney function improved and patient discharged in a good condition with serum creatinin 54 lmol/l. Graft nephrectomy is not a must in acute rupture of kidney transplant. Bone mineral density (BMD) changes were estimated in kidney recipients. In 62 patients creatinine clearance was> 50 ml/min over the study period, BMD was estimated in the lumbar spine, femoral neck and the distal third of the radius using dual energy absorptiometry 0. The aim of the study was to evaluate the relation between epicardial adipose tissue with volume markers and inflammation markers within chronic heamodialysis, peritoneal dialysis, renal transplant patients and control group. Total number of 160 patients, 40 people in each group, chronic hemodialysis (CHD), peritoneal dialysis (PD), renal transplant (RT) patients and the control group were evaluated. To evaluate volume status of patients, left atrium (LA), LA index (LAI), left ventricular mass (LVM), LVM index (LVMI), collapse of the inferior vena cava index (IVCCI), ejection fraction (EF), and the EAT were evaluated by echocardiography (ECHO) and additionally, systolic-diastolic blood pressures (BP) of the patients were recorded. Inflammation markers (IL-6, hsCRP) were measured. Biochemistry markers were tested. IL-6, hsCRP, systolic-diastolic BP, LA, LAI, LVM, LVMI for CHD patients were significantly higher than the other three groups. On the other hand, IVCCI and EF values were lower than the others. EAT values for CHD patients were higher than the other groups. Correlation analyses were done for CHD patients to evaluate the relation between anthropometric markers, laboratory data and ECHO parameters with EAT. Significant data for these analyses were BMI, hsCRP, IL-6, LAI, LVMI, IVCCI. BMI, LAI and IVCCI were found independent predictors for high EAT values. Significant relation was found between volume markers and EAT in CHD patients with the highest volume overload in present study. It is considered that EFT follow-up could give some information regarding volume condition and EAT might be accepted as a new marker for volume evaluation. The Toll-like receptors (TLRs) are related to innate immunity. We investigated the association between TLR9 polymorphisms and kidney allograft outcomes. To investigate whether TLR9 polymorphisms are associated with acute rejection after renal transplantation, two SNPs of TLR9 gene (rs187084, -1486; rs352140, G2848A) were selected and genotyped by direct sequencing in 342 renal transplant recipients. Both SNPs, TLR9 rs187084 -1486 and rs352140 G2848A, of recipients were associated with the risk of acute rejection in renal transplantation. C allele of rs187084 -1486 and A allele of rs352140 G2848A were protective genotype for acute rejection (OR 0.6, 95% CI 0.40-0.92; p = 0.018, OR 0.64, 95% CI 0.42-0.98; p = 0.04, respectively). rs187084 CT and rs352140 GA genotype were associated with a lower eGFR after a year of renal transplantation. TLR9 polymorphisms of recipients were associated with the risk of acute rejection and a lower eGFR after a year of renal transplantation. Takuzo Fujiwara 1 , Shinichiro Tanaka 1 , Kouichiro Okada 1 , Kei Namba 1 , Haruchika Yamamoto 1 , Hiroaki Matsuda 2 1 Okayama Medical Center/National Hospital Organization; 2 Saiwaicho Background: Cytomegalovirus (CMV) Infection and acute rejection (AR) are major complications of organ transplantation. Patients and Methods: We analyzed outcomes in 145 kidney transplant recipients at our center. Patients were categorized according to the occurrence of AR and/or CMV infection within the first 12 months after transplantation. Group 1 (n = 79) without AR or CMV; Group 2 (n = 21) with AR; Group 3 (n = 22) with CMV infection; and Group 4 (n = 23) with both AR and CMV. Results: Death-uncensored graft survival rates in the four groups were 94.9%, 90.5%, 83.8%, and 65.2% (p = 0.007), whereas mean eGFR 1 year after transplantation in these 4 groups was 54. 1, 14.4, 42.9, 11.2, 44.8, 10.6, and 37.4, 13 .9 ml/min/1.73 m 2 , respectively (p < 0.001). When patients in Group four were subdivided into those with AR and CMV occurring with intervals of <40 days (n = 9) and >40 days (n = 13), graft survival rate was worse in the former (35.3% vs. 85.7%, p = 0.019). Conclusion: The combination of CMV and AR after kidney transplantation was associated with poor outcomes, especially when the interval between complication was shorter. Jadranka Buturovic´-Ponikvar, Ales Christian Mihelac, Jakob Gubensek, Miha Arnol, Aljo sa Kandus, Rafael Ponikvar Department of Nephrology, University Medical Center Ljubljana Objective: To assess drug and pill burden in kidney graft recipients. Methods: All Slovenian adult patients with functioning kidney graft at the end of 2012 were included in the retrospective cross sectional study. Number of drugs and pills reported in medical chart from the last outpatient visit in 2012 were counted. Estimated glomerular filtration rate (eGFR/1.73 m 2 , MDRD), duration of renal replacement therapy (RRT) and time after transplantation were evaluated in multivariate model. Results: About 634 kidney graft recipients, 55% males, aged 54 A AE 14 years (median 55) participated in the study. Average time after transplantation was 100 A AE 75 months (median 94 months, range 1-438), duration of RRT was 179 A AE 125 months. Mean eGFR was 58 A AE 21 ml/ min/1.73 m 2 (median 58). The mean number of drugs prescribed per day was 10.5 A AE 3.5 (median 10, range 2-26). The mean number of pills prescribed per day was 19.9 AAE9.1 (median 19, range 3-46). In multiple linear regression analysis age (B = 0.05, p < 0.001), male gender (B = 0.81, p = 0.001), diabetes (B = 1.19, p < 0.01), eGFR (B = À0.05, p < 0.001) and time after transplantation (B = À0.01, p < 0.001) were identified as independent predictors of number of drugs, while time on RRT was not. Independent predictors of number of pills per day were male gender (B = 2.15, p < 0.001), eGFR (B = À0.05, p < 0.001) and time after transplantation (B = À0.04, p < 0.001). Conclusions: Drug and pill burden in kidney graft recipients is high. Male gender, lower eGFR and shorter time after transplantation were independent predictors of number of drugs and pills prescribed. Strategies to reduce drug and pill burden should be explored in future, to avoid drug interactions and improve patients' adherence. Results: Among 14 patients of BKVAN, nine patients had BKVAN alone. There were two graft losses and one patient death. Five patients were found to have both BKVAN and AR. BKVAN in BKVAN/AR group was detected earlier than in the BKVAN alone group (6.39 vs. 21.77 months, p = 0.03). Histological grade was more advanced (p = 0.034). Steroid pulse and ATG were administered to four and one patient, respectively. After anti-rejection therapy, all patients reduced immunosuppression, and two patients received IVIG. Graft loss occurred in one patient. BKV load, dose of immunosuppressants, and tacrolimus level showed a lower tendency in the BKVAN/AR group. Renal functional deterioration over 1 year after BKVAN diagnosis was similar. Conclusion: The prognosis of BKVAN/AR might be similar as that of BKVAN alone. Chan-Duck Kim, Jeong-Hoon Lim, Hee-Yeon Jung, Seung-Chan Park, Kyung-Hoon Kim, Owen Kwon, Ji-Young Choi, Jang-Hee Cho, Sun-Hee Park, Yong-Lim Kim Department of Internal Medicine, Kyungpook National University Hospital Background: We proposed criteria for withdrawal of antiviral agents and reported long-term outcomes after withdrawal in kidney transplant recipients (KTR) with chronic hepatitis B virus (HBV) infection. Methods: HBsAg (+) KTR treated with antiviral agents were enrolled. Antiviral agents were withdrawn in KTR who met the following criteria: (i) normal liver biochemistry, (ii) HBV DNA (À) and HBeAg (À), (iii) at least 9 months antiviral treatment. Results: Among a total of 424 KTR, 14 HBsAg (+) KTR were included. Antiviral therapy suppressed viral replication in 11 KTR (78.6%). Long-term graft and patient survival of HBsAg (+) KTR were comparable to those of HBsAg (À) KTR. Discontinuation of antiviral agent was attempted in 6 (42.9%) of 14 patients who satisfied the criteria. Four (66.7%) of six KTR were successfully withdrawn and remained negative for HBV DNA for 62.5 ι¾ 14.7 months. Conclusion: Antiviral therapy can be successfully discontinued in selected KTR with chronic HBV infection. Allocation of kidneys from old donors to old recipients was launched in Israel in 2001. We reviewed our experience with old-for-old (OFO) transplantation. Patients and Methods: We analyzed graft and patient survival, ATN and primary non-function rates in a cohort of 87 transplants performed between 2001 and 2011. All patients had 0% PRA and allocation was based on time on dialysis only. CDC cross-match results were reported at transplant. Survival analysis was done using Kaplan-Meier method on SPSS program. Results: The mean age of the donor and recipient was 65.4 and 65.3 y, respectively. Mean cold ischemia was 8.1 h (4.3-12.4 h.). ATN rate was 54%. Three grafts never functioned, one probably due to antibody-mediated rejection. Overall 33 grafts were lost with 15 (45.5%) of which for death with a functioning graft. Graft survival rates at 1, 5 and 10 years, were 81.7%, 62.6% and 23.8%. Patient survivals at 1, 5 and 10 years were 87.2%, 75.7% and 25.2%. Conclusions: The use of kidneys from elderly donors in age matched recipients yields a relatively good graft survival for the short term. Omitting cross-match test before transplant in these low-risk group allows to keep a short cold ischemia. Introduction: The aim of the study was to investigate the diagnostic value of the enzymemia and enzymuria as markers of CKAGD. Methods: Alkaline phosphatase (AP), c-glutamiltransferase (c-GGT), alanine-aminotransferase (ALT), aspartate-aminotransferase (AST) were measured in the serum and urine by standard laboratory methods using the spectrophotometry. N-acetyl-b-D-hexosaminidase (NAG) activity was measured in the urine by a colorimetric assay. Abstracts of the 16th Congress of the European Society for Organ Transplantation Results: Analysis of the results showed no significant differences in the activity of the enzymes in the blood, while it found significant increase in the urinary excretion of c-GGT, AP, NAG and AST in patients with CKAGD (serum creatinine above 150 lmol/l). Univariant logistic regression revealed that only the activities of AP (OR=1.13, p = 0.04) and NAG (OR=1.26, p = 0.01) were significantly associated with the CKAGD. Multivariate analysis showed that only the activity of NAG in urine had an independent predictive value (OR=1.38, p = 0.01). Conclusion: Our findings demonstrate the inutility of enzymes studies in the serum in the monitoring of CKAGD. They confirmed the diagnostics value of urinary enzymes, especially, NAG, that indicates the ongoing damage of the tubules epithelium and requires prescribing of relevant therapy. Marco Quaglia 1 , Roberta Fenoglio 2 , Elisa Lazzarich 2 , Andrea Airoldi 2 , Cristina Izzo 2 , Mara Giordano 1 , Piero Stratta 1 1 Amedeo Avogadro University, Novara; 2 Maggiore della Carit a Hospital, Novara Background: Several undiagnosed rare disorders could be recognized after renal transplant (Tx) through genetic analysis. Material and Methods: We analysed a ten-year experience (2003-2012) of a genetic diagnosis of rare nephropathies after Tx. This was performed for: uromodulin or HNF1ß-associated nephropathy (chronic interstitial nephropathy and renal cysts, extrarenal involvement); Fabry disease; "Dense deposits disease" (DDD); adenine phosforibosil-transferase (APRT) deficiency (intratubular 2,8 dihydroxyadenine crystals in acute renal failure); mutation of formin 2 (nephrotic syndrome). Results: Six nephropathies were diagnosed in nine patients: 2 UMOD and 2 HNF1ß-associated nephropathies; one DDD; one FSGS from INF2 mutation; one Fabry and 2 APRT-deficiency nephropathies. The latter relapsed on the graft and diagnosis was crucial for management. Conclusion: Genetic analysis has the potential to disclose rare nephropathies in Tx with heavy clinical implications. Luis Leon, Demian Curcio, Olga Guardia, Maria del C Rial, Domingo H. Casadei Nephrology SA Objective: To evaluate teriparatide subcutaneous (sc) treatment in renal transplant patients with symptomatic post-surgical hypoparathyroidism. Materials and Methods: We reported the treatment of teriparatide 20 lg/day (sc) in three patients who received a renal transplantation from deceased donor with post-surgical symptomatic hypoparathyroidism since January 2012. The following biochemical parameters were determined: (Basal time, 1°,3°6°y 12°m onths post treatment), ionic calcium (normal value: 1-1.30 mmol/l), phosphatemia (NV: 2.5-4.50 mg/dl), magnesemia (NV: 1.70-2.40 mg/dl), alkaline phosphatase (NV: 120-270 mUI/l), Calciuria (NV 60-200 mg/day), uric acid (NV 3.3-7 mg/dl y 2.2-5.7 mg/dl in women), cholesterol (NV150-200 mg/dl), iPTH (NV 35-72 pg/ml), 25OHD (NV >40 ng/ml) and serum creatinine (0.8-1.2 mg/dl). All patients received in post transplantation thymoglobuline (6 mg/ kg) and subsequent maintenance immunosuppression with calcineurin inhibitors (2 pts), sirolimus (1 pts), all associated with mycophenolate and methylprednisolone. Besides, all the patients were treated with ergocalciferol, calcium and calcitriol. Results: Three pt received a renal transplantation from deceased donors (1 patient a 2°TX) 2 male, Mean age: 42, 6 AE 6.02 years, CKD Etiology: obstructive uropathy, unknown, systemic lupus erythematosis. Time on dialysis (mean): 101.3 AE 121, 7 m, Transplant follow up: 6 AE 3, 46 years, Parathyroidectomy: one patient previous transplantation; two patients after 4 years of transplantation. All cases were due to severe secondary hypoparathyroidism with subtotal parathyroidectomy indication. Two pts showed convulsion due to hypocalcemia in the immediate parathyroidectomy surgery, one of them fell down and had a clavicle and scapula fracture. Patients continued with hypoparathyroidism in their follow up (PTH <5 ng/ml) with symptomatic hipocalcemia despite of required high doses of calcium and calcitriol (oral and intravenous administration) and ergocalciferol (oral administration; keeping levels of 25 OHD in 40 ng/ml) so in January 2012, all the patients started with synthetic human parathyroid hormone. Once teriparatide was administered, calcium and calcitriol requirements substantially diminished and were afterwards suspended (in 30 days). SIDE EFFECTS att initial time: only one patient experienced nauseas, mild hypotension, numbness of the legs (due to hypomagnesemia) one patient presented chills episodes, tachycadria and dyspnea at 9°month of the treatment. Therefore, teriparatide was discontinued. She did not show any other symptoms within the subsequent days (As described in the literature have been detected antibodies with cross-reactivity with Teriparatide in 2.8% of women treated with this medication, usually after 12 months of treatment yielding the symptoms to suspend it) . Non alterations in creatinine levels and urinary calcium were observed but a slight increase in uric acid, cholesterol and alkaline phosphatase (PTH effect) were exhibited (Table) . Conclusion: The use of intermittent synthetic parathormone is a therapeutic option in those patients with hypoparathyroidism. It reduces their calcium and calcitriol requirements and remarkably improves their life standard. References: Nogueira EL, y col, Teriparatide efficacy in the treatment of severe hypocalcemia after kidney transplantation in parathyroidectomized patients: a series of five case reports, Transplantation, 2011 Aug 15: 92 (3) Background: Steroid pulse therapy has been used for patients with acute rejection after kidney transplantation. The ABCB1 gene codes for P-glycoprotein, a transporter involved in the metabolism of steroid. However, role of ABCB1 polymorphisms have not yet been delineated in patients with acute rejection after kidney transplantation. Methods: Among 763 patients performed kidney transplantation or simultaneous pancreas-kidney transplantation at Seoul National University Hospital between May 1996 and July 2009, 684 patients agreed genetic sampling for polymorphism. Results: Steroid resistant group showed higher serum creatinine than steroid sensitive group. Frequency of ABCB1 gene polymorphism (C1236T and C3435T) did not show significant difference between steroid sensitive group and steroid resistant group. Conclusions: ABCB1 gene polymorphism (C1236T and C3435T) did not associate with steroid resistance in patients with acute rejection after kidney transplantation. reviewed published studies for the role of plasma exchange (PLEX) and its variants on rFSGS in adults. Methods and Materials: Eligible manuscripts compared PLEX with supportive care for inducing proteinuria remission (PR) in rFSGS and they were identified through MEDLINE and reference lists. Data were abstracted in parallel by two reviewers. No randomized controlled trial met the defined inclusion criteria. Results: We identified four cohort trials which used historical control groups. A total of 93 patients were included in the analysis. In a random effects model, the pooled risk ratio for the composite end-point of partial or complete PR was 3.19 for patients treated with PLEX compared with controls (95% CI: 1.72-5.90, p < 0.05). No statistically significant heterogeneity was detected (p = 0.33, I 2 = 13%). Conclusion: Notwithstanding the inherent limitations of non randomized trials, PLEX appears to be efficacious for PR in rFSGS. Additional research is needed to further elucidate its impact on long-term allograft survival. Background: The activation of indoleamine 2,3-dioxygenase leads to the formation of kynurenine (Kyn) and other metabolites which counter-regulates immune activation. But in chronic immune activationas in hemodialyzed patientsthe immunosuppressive feedback mechanisms continue as indicated by elevated Kyn concentrations. However their prognostic relevance is still a matter of debate. Materials and Methods: This retrospective analysis presents the pre-transplant Kyn levels (quantified photometrically) of 307 kidney graft recipients in connection with some pre-and post-transplant variables and the type of immunosuppression (cyclosporine based triple drug therapy without/with ATG-[Fresenius]-induction). Statistics: analysis of variance, Scheff e's test for pairwise comparisons, Cox regression, extended CHAID segmentation analysis. Results: The pre-transplant Kyn levels were significantly elevated in comparison to those of 257 healthy adults (14.1 AE 5.9 vs. 2.5 AE 0.4 nmol/ml). The magnitude of the pre-transplant Kyn levels was higher in Panel-Reactive-Antibody-positive (≥5%, n = 196) than in PRA-negative (<5%, n = 111) patients (16.1 vs. 12.9 nmol/ml; p = 0.0001) but was neither related to underlying disease and time on dialysis nor to rejections and graft survival, however to a certain degree to post-transplant graft function (immediate versus non-immediate: p = 0.053). Post-transplant differences in graft outcome depended mainly on the type of immunosuppression. Conclusions: The pre-transplant elevated serum Kyn levels did not predict graft outcome. Marine Lorent 1 , Yohann Foucher 1 , Magali Giral-Classe 2 1 Department of Biostatistics EA 4275, University of Nantes; 2 ITUN, Nantes Hospital and University, Inserm U1064, Background: Identifying prognostic markers of mortality in transplantation is essential for determining patients at high-risk of death and optimizing medical management. Nevertheless, an important part of the mortality may not be due directly to end-stage renal disease and/or kidney transplantation. Moreover, it is often impossible to individually determine the death causality, for example a cancer can be related to the chronic disease and immunosuppressive drug exposure or this cancer would have an independent link. Methods: In survival analysis, one solution is to distinguish between the expected mortality of one general population (estimated on the basis of mortality tables) and the excess mortality attributable to the pathology, by using an additive relative survival model. The main objective of such models is to estimate the "net survival", survival which would be observed if the only possible death is related to the transplantation. We have adapted this concept in order to evaluate the capacity of a marker to predict the mortality attributable specifically to transplantation. Results: We illustrate this method of net time-dependent ROC curves with the analysis of kidney transplant recipients of the DIVAT (Nantes). Recurrent focal segmental glomerulosclerosis (FSGS) is a major therapeutic challenge in kidney transplant. However, the most effective dosage and regimen of rituximab have not been determined. Herein we reported the first case of successful treatment of recurrent FSGS with a low dose rituximab. The patient showed marked proteinuria (3.5 g/day) and oliguria two days after transplantation. Two courses of plasmapheresis and immunoglobulin treatment were applied for treatment of recurrent FSGS, however, nephrotic range proteinuria persisted and creatinine level increased to 3.56 mg/dl. Five months post-transplant, the patient received only one dose of rituximab 100 mg, without further plasmapheresis, which resulted in immediate reduction of serum creatinine and full remission of proteinuria during the following 10 months. This case suggested that recurrent FSGS, which relapses after plasmapheresis, could be treated successfully with a low dose rituximab even without plasmapheresis. Paola Todeschini, Dalmastri Vittorio, Giorgio Feliciangeli, Gaetano La Manna, Mara Montanari, Maria Cappuccilli, Maria Piera Scolari, Sergio Stefoni University of Bologna Introduction: Kidney transplant recipients (KTR) show an acquired hypercoagulable state determining an increased incidence of deep vein thrombosis (DVT). A possible underlying mechanisms might be hemostasis imbalance, with a multifactorial rise of procoagulant factors, both traditional (diabetes, pregnancy, obesity, preexisting thrombophilias), and transplant-related factors (surgery, immunosuppression, primary nephropathy, pre-transplant dialysis mode, erythrocytosis, infections). We investigated KTR with DVT at least 6 months post-transplant. Methods: We included 30 patients transplanted between 2008 and 2011 who experienced DVT (lower limbs, lower limbs complicated by pulmonary embolism, retinal) at least 6 months post-transplant. Primary nephropathy, immunosuppressive regimen, infections and erythrocytosis were recorded. LMWH was given as trombophylactic treatment in the first post-transplant week and thereafter aspirin. All patients underwent color duplex ultrasonography. Results: Increased DVT incidence was observed in patients receiving cyclosporine or cyclosporine+mTOR inhibitors, in PCKD, LES, nephrotic syndrome, peritoneal dialysis and in those with rapid and excessive correction of hematocrit values after transplant. DVT was unrelated to acute infection and dialysis modality. Conclusions: These study suggest that the prevention of DVT consist either in accurate pre-transplant thrombophilia screening or in identification of patients at higher DVT risk requiring long-term antiplatelet therapy. Abstracts of the 16th Congress of the European Society for Organ Transplantation Open-label, randomized, controlled, multi-center 12 months study assessing safety and efficacy of Everolimus (EVR) regimen after Calcineurin-Inhibitor (CNI) withdrawal in maintenance KTx patients (pts). 93 pts on stable CNI+Enteric-Coated MycophenolateSodium (ECMPS) regimen were randomized to either continued CNI/ECMPS (n47) or EVR/ECMPS conversion (n46). 72(77%) pts completed observational 48 months follow-up visit. Mean trough levels[ng/ml]: 84 AE 44 CsA, 5.9 AE 2.4 Tacrolimus, 6.7 AE 2.0 EVR. Mean adjustedGFR (Nankivell [ml/min/1.73 m 2 ]) +5.6 ([À0.6; +11.8]) for EVR over CNI ITTpts and +8.7([+16.0;+1.4];p = 0.02) for EVR (n20) over CNI (n31) non-switcher pts. 2 deaths, 1 graft loss in CNI, 1 death, 3 graft losses in EVR, no BPAR in either group. Infections months 12 to 48: 23(50%) EVR vs. 20(43%) CNI pts, severe 3 (7%) EVR vs. 1(2%) CNI; none leading to hospitalization. Malignancies: EVR none versus 1(2%) CNI. Late conversion to EVR/ECMPS treatment in maintenance KTx pts after CNI withdrawal is safe with by trend better RF after 4 years. Background: Interstitial fibrosis (IF) and tubular atrophy in kidney transplant recipients have been associated with calcineurin inhibitors and ischaemia. This study aimed to evaluate IF in live donor (LD) biopsies. Methods: Surveillance biopsies from recipients of LD kidneys were stained using Sirius Red and assessed using computer assisted scanning. Results: Sixty-two LD recipients (1998) (1999) (2000) (2001) (2002) (2003) (2004) (2005) were identified with both a preimplantation and 12 month biopsy. The area fraction of IF at 6 months (25 AE 8%) and 1 year (25 AE 8%) was equivalent but significantly greater than pre-implantation (18 AE 6%, t-test, p < 0.0001). Recipient serum creatinine was correlated with the degree of fibrosis at 1 year (Pearson r = À0.255, p = 0.045). A subset of patients (n = 14) changed to rapamycin at 3 months also had equivalent levels of IF (27%). Previous studies at our institution have shown similar levels of IF at 1 year in recipients of cadaveric grafts (27%). Conclusion: Interstitial fibrosis develops early after transplantation, irrespective of donor source and immunosuppression, and correlates with serum creatinine at 1 year. Jin Ho Hwang 1 , Yon Su Kim 2 , Jung Pyo Lee 1 , Chun Soo Lim 1 , Yun Kyu Oh 1 , In Mok Jung 1 1 Boramae Medical Center, Seoul National University; 2 Seoul National University Hospital Malnutrition, inflammation, and atherosclerosis (MIA) is associated with a high mortality rate in ESRD patients. However, the clinical relevance of MIA syndrome in kidney transplantation (KT) recipients remains unknown. A total of 394 adult recipients of KT were enrolled and analyzed by level of serum albumin and hs-CRP. Recipients were classified into four groups according to pretransplant albumin and hs-CRP levels. Recipients with lower pretransplant albumin showed higher occurrence of CVE, and composite of CVE with all-cause mortality. The lower albumin level was, the more CVE occur. The higher hs-CRP level tends to be associated with occurrence both of primary outcomes. In four groups analysis, cumulative CVE free survival was lower in low albumin + high hs-CRP group. The composite of CVE and all-cause mortality was high in low albumin + high hs-CRP group. In conclusion, the malnutrition and inflammation status before KT increases the risk of developing CVE and all-cause mortality. Background: Intra-patient variability (IPV) in tacrolimus exposure was associated with rejection and graft failure (e.g. Borra, L.C. P et al. Nephrol Dial Transplant 2010; 25: 2757 -2763 . The aim of this study was to investigate whether conversion from twice-daily tacrolimus formulation (Tac-TD) to a oncedaily formulation (Tac-OD) leads to a lower IPV in tacrolimus exposure. Methods: Two hundred and fifty two stable renal transplant recipients were converted from Tac-TD to Tac-OD. We analyzed tacrolimus trough blood concentrations (C0), serum creatinine, estimated glomerular filtration rate (eGFR) and proteinuria over a period of 1 year before and after conversion. Results: For the analysis we included only patients of whom three or more C0 values were available (n = 220). After conversion, the mean tacrolimus C0 fell from 6.10 AE 1.76 lg/l to 5.37 AE 1.29 lg/l, corresponding to a 12% reduction (p < 0.001). Both drugs exhibited similar IPV (Tac-TD: 18.88 AE 9.32% vs. Tac-OD: 18.85 AE 9.97%; p = 0.387). Renal function remained stable (eGFR prior conversion: 47.31 AE 15.47 ml/min versus eGFR 12 months after conversion: 47.54 AE 15.50 ml/min; p = 0.656), demonstrating the safety of switching to Tac-OD. Conclusions: Conversion from Tac-TD to Tac-OD leads to a significantly lower tacrolimus exposure, however it does not lead to lower IPV in tacrolimus exposure. Background: Secondary hyperparathyroidism (SHPT) is one of the major complications among the dialysis patients. Although parathyroid function improves dramatically immediately after renal transplantation (RTx), there have been little regarding reports parathyroid function of perioperative period. We aimed to investigate the comprehensive analyses of perioperative parathyroid function in early post-RTx period. Materials and Methods: From April 2011 to January 2013, 33 living-donor RTx were performed at our institution. Four patients were excluded (two patients received cinacalcet after RTx and two patients with parathyroidectomy before RTx), then a total of 29 patients were analysed (20 males, nine females; age, 43.3, 14.8 years; duration of dialysis, 26.1, 22.4 months). Changes of intact parathyroid hormone (i-PTH), serum calcium (sCa), serum phosphorus (sP) and sCa~sP, and alkaline phosphatase between pre-ope and about three weeks after RTx were analyzed. Results: There were significant reduction in the values of i-PTH (p < 0.01), sP (p < 0.01), and sCa~sP (p < 0.01). The excretion of urinary calcium was increased immediately after RTx and transient hypocalcemia was seen in the very early phase of post-RTx. However, one patient had been oral administration of cinacalcet before RTx was more than 10.5 mg/dl in serum calcium level at 1 year after RTx. Conclusions: Parathyroid function was improved in the phase of post-RTx. However, patients persistent HPT after RTx must be observed carefully. In SHPT patients with cinacalcet before RTx might be the candidates of pre-ope parathyroidectomy. Background: Unplanned reoperation is used as indicator of quality control in surgery. For kidney transplantation no such data exists so far. The aim of this study was to find out if there is a correlation between reoperation, organ function, loss of organ and survival. Methods: We retrospectively analysed all kidney transplantations performed from September 2002 until December 2010. Results: Out of 320 transplanted organs 46 reoperations took place, 40 organs where lost in the time of surveillance. Organ loss occurred in 37% of all reoperated patients compared to 9% in the not reoperated group (p < 0.001). The main complications that led to reoperation were vascular (14/46, 64% organ loss), haematomas or abscesses (13/46, 31% organ loss), urological (12/46, 8% organ loss), abdominal (4/46, 50% organ loss) and lymphatic (3/46, 33% organ loss). In relation to immunosuppression no statistically significant correlation could be found. Conclusions: Complications with the need of reoperation after kidney transplantation are related with early organ loss. Also the transplant function, measured in serum creatinine is worse in reoperated patients. Especially vascular complications predispose to early organ loss. Background: Aim of this single center randomized, clinical trial in kidney transplantation was to compare an immunosuppressive regimen based on the association of low-dose ER-tacrolimus and everolimus to a standard-dose ERtacrolimus and MMF regimen. Results after 1 year of follow up are presented. Methods: Forty-two primary deceased donor kidney transplant recipients were randomly assigned before transplantation to receive ER-tacrolimus plus everolimus (EVE group: 21 patients) or ER-tacrolimus plus mycophenolate mofetil (MMF group: 21 patients). As induction therapy all patients received a combination of basiliximab (20 mg IV on day 0 and day 4), thymoglobulin (50 mg/day IV from day 0 to day 3) and steroids. EVE and MMF patients received study medications orally, once a day, starting on p.o. day 4. Three to six months after transplantation, steroids were selectively withdrawn in patients with no acute rejection episodes, serum creatinine <2 mg/dL and proteinuria <300 mg/l/24 h. Results: Demographics were similar between groups. Efficacy and safety parameters after 1 year of follow up are summarized in the table. Conclusion: Our data show that 1 year after transplantation the association of low-dose ER-tacrolimus and everolimus when compared to a standard-dose ER-tacrolimus and MMF regimen provides similar patient survival, graft survival, acute rejection rates and renal function with significantly lower tacrolimus exposure. Purpose: Most successful protocols for ABO-incompatible (ABOi) renal transplantation have utilized anti-CD20 500~1000 mg/body monoclonal antibody as Standard Immunosuppression of the pre-conditioning process. Here, we described successful ABOi transplantation using only 200 mg/body of anti-CD20 Standard Immunosuppression in lieu of it in China. Material and Methods: Nine cases of ABO-i kidney transplantations were performed at the Second Affiliated Hospital, University of South China between December 2006 and November 2012. The blood type incompatible patients who received live donor renal transplants are A1 to O (4 patients), A1 to B (1 patient), B to A (1 patient) and B to O (3patient). Antibody removed was scheduled according to baseline anti-ABO antibody titer (median 1:256, range 1:16-1:1024). Perioperative antibody remove, used only 200 mg/body of anti-CD20 antibody and receiving an identical tacrolimus-based immunosuppressive regimen to contemporaneous ABOcompatible (ABOc) recipients. Results: All nine patients underwent successful transplantation and have a mean current serum creatinine of 97.3 (range: 78.4-134.4). There were no episodes of antibody mediated rejection. The elimination of the peripheral blood CD19 cells are effective in every recipient preoperative. Conclusion: We conclude that ABOi transplantation can be performed successfully with perioperative antibody removal, low-dose of anti-CD20 antibody and conventional immunosuppression. This suggests that access to ABOi transplantation can include a broader range of end-stage kidney disease patients in China. Key words: ABO incompatible, low-dose of anti-CD20. Background: Liver disease is an important cause of morbidity and mortality both before and after transplantation in patients with chronic kidney disease (CKD). Abnormal liver function tests (LFTs) is caused by hepatotropic viruses including HBV and HCV in 10-44% of CKD patients. In addtion CMV infection occurs in 20-60% of all transplant recipients. Methods: In a prospective study 70 patients of CKD taken up for renal transplantation at a northern tertiary hospital in India, PGIMER, Chandigarh were evaluated for deranged LFTs and viral markers (HBsAg, Anti-HCV, HCV-RNA (Qualitative), IgM CMV serology, pp65 antigen and PCR for CMV DNA (if required). Liver dysfunction was defined as ALT >1.5 times the upper limit of normal (i.e. 40 IU/ML) and/or total bilirubin ≥2 mg/dl. The standard immunosuppression protocol was tacrolimus, MMF and steroids. Cyclosporine was preferred over tacrolimus if the patient is HCV positive. Azathioprine was used in place of MMF in case of poor affordability or intolerance due to side-effects. For cellular rejection, Methylprednisolone AEATG and for humoral rejection, Methylprednisolone AEIVIG was used. Results: Pretransplant, deranged LFTs were found in 12 patients (17%). Of them, one each had HBV and HCV infection. Of the 58 patients with normal LFTs, two each were positive for HBV and HCV respectively whereas one had dual infection with HBV and HCV. At 3 months post-transplant, all 12 patients continued to have deranged LFTs with same HBV or HCV status. All 4 HCV positive cases were detected by HCV RNA. In addition one developed fever with deranged LFTs, pancytopenia and was positive for CMV-DNA on PCR, with negative IgM serology and pp65 antigenemia. Conclusions: Pre-transplant liver dysfunction was noted in 17% of patients. HBV and HCV were incriminated in 8.3% (1/12) of these patients which persisted at 3 months post-transplant. CMV was found in 7.6% (1/13) of renal transplant recipients with deranged LFTs. Background: There are no standard guidelines regarding the appropriate dose of mycophenolate acid (MPA) to be used in combination with extendedrelease tacrolimus (Tac-ER). In this study, we aimed to investigate the efficacy of a low toxicity immunosuppression protocol consisting of a reduced dose of Tac-ER and concentration-controlled (CC) mycophenolate mofetil (MMF). Methods: A total of 31 adult de novo living donor kidney transplant recipients were treated with reduced doses of Tac-ER, MMF, and methyl prednisolone for basic immunosuppression. Basiliximab was administered during the induction phase of immunosuppression. The dose of MMF was adjusted to achieve MPA levels, as measured by the area under the curve, within a target range of 50-60 mg/h/l. The dose of Tac-ER was adjusted to achieve a target trough level of 8 ng/ml for the first 2 weeks, after which the dose was tapered to 5 ng/ml for 6 months. Results: The patient survival rate was 100%. Graft loss resulting from BK virus nephropathy was observed in one patient. Acute rejection was noted in two patients in the early post-transplantation period. Leukocytosis and asymptomatic cytomegalovirus viremia were observed in six and 11 patients, respectively. The average estimated glomerular filtration rate 1 year posttransplantation was found to be 65.4 ml/min 1.73 m 2 , and protocol biopsy performed 1 year after transplantation indicated no toxic tubulopathy. Conclusion: We found that a low dose Tac-ER and CC MMF regimen was safe and less toxic in the short-term. Abstracts of the 16th Congress of the European Society for Organ Transplantation Background: Long-term effect of cinacalcet in normo-and hypercalcemic SHPT after renal transplant (RT) is scarcely described. Methods: Multicenter, retrospective, 3-year study in 32 patients with normoand 193 with hypercalcemic SHPT. Results: In normocalcemic SHPT, iPTH levels decreased by 48.6% at 6 months from initiation of cinacalcet (m; p = 0.001; n = 32), without changes in calcium (Ca) and phosphorus (P). In hypercalcemic SHPT, Ca decreased from a mean (SD) of 11.1(0.6) at baseline to 10.1(0.8) at 6 m (À9.0%, p < 0.001; n = 193). iPTH was reduced by 23.0% at 6 m (p < 0.001; n = 193) and P levels increased by 11.1% (p < 0.001; n = 193). The effects were maintained for 3 years (n = 6/44 normocalcemic/hypercalcemic). No changes were observed in renal function or anticalcineurin levels. 4.0% and 1.8% of patients discontinued drug due to intolerance and lack of efficacy, respectively. Conclusions: After initiation of cinacalcet in RT patients with SHPT, longterm control of blood levels of iPTH without changes in Ca or P were observed in normocalcemic patients, and blood levels of Ca, iPTH and P were controlled in hypercalcemic patients. Bernhard Banas Inadequate impairment of cell-mediated immunity (CMI) by immunosuppressive therapy is a major cause of severe clinical complications in solid organ transplantation. Assessment of CMI may help to predict the onset of complications, as well as to adjust immunosuppressive/antiviral therapy. The aim of this cross sectional multicenter study was to evaluate the feasibility of the novel tools [T-Track â ] CMV and [T-Track â ] EBV to assess the functionality of virus-specific CMI in a clinically relevant patient population. Applying activated viral stimulator antigens, [T-Track â ] assays provide information about the functionality of a broad network of virus-reactive effector cells including CD4 + , CD8 + , NK and NKT cells. The test sensitivities of [T-Track â ] CMV/ EBV assays were examined in a cohort of 124 hemodialysis patients and compared with Quantiferon â -CMV and a panel of 6 preselected CMV tetramers. Herein, positive [T-Track â ] CMV or [T-Track â ] EBV results were obtained in 60/67 (89.6%) of CMV-and 104/118 (88.1%) of EBV-seropositive hemodialysis patients, respectively. In addition, also 12/57 (21.1%) of CMVseronegative dialysis patients showed significant numbers of CMV-responsive cells. Quantiferon â -CMV and CMV tetramers revealed sensitivities of 72.6% (45/62) and 76.9% (40/52), respectively. [T-Track â ] CMV/EBV assays can be used in a broad population of hemodialysis patients neglecting their HLA-type. Thus, T-Track â assays may also represent valuable tools to assess functionality of CMI in transplant recipients and help to guide personalized therapy. Background: Microcirculation inflammation (MI) associated with Donor-Specific Antibody (DSA) with/without C4d deposits in peritubular capillaris currently defines humoral rejection with a poor graft survival. Outcome of isolated MI without C4d and DSA on graft function remains unclear. Methods: Restrospective comparaison of 40 patients diagnosed with isolated MI, with 46 controls with normal histology on one year surveillance biopsies. Anti-HLA DSA were identified by Luminex technique. Results: Patients had mild MI (mean g+ptc = 1.75 AE 1). In patients with MI and controls, the estimated Glomerular Filtration Rate (eGFR, MDRD) dropped from 52.7 to 47 ml/min and 62.3 to 58.5 ml/min respectively (p < 0.05) between one to three years after transplantation. Daily proteinuria significantly increased at the time of diagnosis (0.59 vs. 0.20 g/24 h p < 0.001) and persisted during follow-up (0.47 vs. 0.27 g/24 h p < 0.05). Graft loss was observed only in the MI group (10%). One person in each group developped DSA at 3 years without renal impairment. Conclusion: Isolated MI despite any evidence of humoral activity may worsens proteinuria and further impairs graft function. recurrence of MPGN type 1 was 25% vs. 90% in non-recurrence; mean graft survival was 40 AE 9 vs. 157.6 AE 9.6 months (p < 0.0001). Patients who lost their graft due to MPGN type 1 recurrence were younger; mean 23 AE 9.2 vs. 37.7 AE 12.5 years (p = 0.004), and had higher mean proteinuria: 7.2 AE 3.6 g/ day vs. 1.5 AE 0.25 g/day (p = 0.006). Conclusions: Graft survival for patients with MPGN type 1 in our cohort is better than previously reported. Graft loss as a result of disease recurrence was rather low. Patients with recurrent MPGN type 1 were younger and had a significantly shorter term graft survival. Transplant from living-donor was not associated with increased risk for recurrence. THE GABOIR-REGISTRY WILL HELP TO IMPROVE THE HEALTH AND RISK COMMUNICATION Przemyslaw Pisarski 1 , Silvia Hils 1 , Albrecht Kramer-Zucker 1 , Bernd J € anigen 1 , Marcel Geyer 2 1 University Clinic Freiburg; 2 Hegau Clinic Singen Background: Transplant institutions in Germany are facing a persistent and severe shortage in organ donors. This forces Transplant-Centers to search for new ways to expand the donor pool and explore novel therapeutic options. Therefore the Transplant-Center Freiburg performed the first German ABOincompatible Living-Kidney-Transplantation in 2004. Since than over 500 ABOi-Living-Kidney-Transplantations were realized at 32 German Transplant Centers. Method: The GABOiR-Registry is a data registry which offers the possibility to pool data gathered in all patients undergoing ABO-incompatible kidney transplantation in Germany. The registry is intended to allow for medicalscientific data analyses as well as economical analyses, with the intention of increasing the rate of living donor kidney transplantations in Germany and to improve the health and risk communication. The design and development of the registry for ABO-incompatible kidney transplantation patients provide important insights into success rates and safety issues concerning this novel therapeutic option in Germany and will help establish this procedure as being reliable and safe. Results: The aims of this registry were to insure transparency with regards to economical factors involving the medical procedure, to establish the safety of the therapeutic measure by recording outcome data and adverse events and provide a foundation for continued documentation of medical long term outcome data of a novel therapeutic intervention. Conclusion: The registry will allow to gather and access medical long term data for scientific analyses and will help to increase the rate of living donor kidney transplantations in Germany. Moreover the analysis of the registered data will help to establish that ABO-incompatible kidney transplantation in comparison to maintenance on dialysis is highly cost effective and carries a significant socioeconomic benefit-first model calculations have provided evidence for this hypothesis. Background: Results of recent studies suggest that metabolic acidosis (MA), which often in present in chronic kidney disease (CKD) patients accelerate the CKD progression. The aim of this clinical, single-center, cross-sectional, casecontrol study was to assess the prevalence of metabolic acidosis in KTP in comparison to CKD patients. Material and Methods: Venous blood bicarbonate [HCO3-] concentration was measured in 443 KTP (259 males, 184 females, age 50 AE 12 years; eGFR 50 AE 23 ml/min) and sex, age and eGFR matched CKD patients (259 males, 184 females, age 51 AE 14 years; eGFR 50 AE 26 ml/min). Metabolic acidosis was defined if [HCO3-] was lower than 22 mmol/l. Results: KTP and CKD patients did not differ with respect to [HCO3-] (25.31 AE 3.38 vs. 24.87 AE 3.69 mmol/l) and to the prevalence of metabolic acidosis (12.4% vs. 10.6%). In both groups [HCO3-] significantly (p < 0.001) decreased, and prevalence of metabolic acidosis significantly (p < 0.01) increased with the advancing CKD stages. In KTP and CKD patients the significant positive correlations were found between [HCO3-] and eGFR (R = 0.450, p < 0.001; R = 0.392, p < 0.001, respectively) Conclusion: In KTP the risk of metabolic acidosis is high and is related to the kidney graft function. Background and Aim of the work: Since 1980s many reports have been investigating for the steroid-resistant lymphoid population from many aspects. We studied the prevalence of steroid resistant lymphoid population among uremic patients and correlate it with the ten years outcome of kidney transplant as well as their predictive value regarding postoperative immunosuppressive protocols. Patients and Methods: Three hundred and fifty five uremic patients, were included in this study. The stimulation Index (SI) of one-way Mixed Lymphocytic Culture (MLC) against a potential donor was done before and after in vitro treatment of recipient lymphocytes with 1.0 lg/ml methyl prednisolone. The MLC response will be considered sensitive if the inhibition level (CH50) was 50% or greater or otherwise resistant. Morning plasma cortisol and morning serum ACTH levels were measured. Ten years follow up comparing the allograft outcome between steroid resistant and steroid sensitive groups. Results: The incidence of steroid resistant lymphoid population was 56.36% at a dose of 1.0 lg/ml and 34.18%at a dose of 2.0 lg/ml methyl prednisolone. Age, sex and duration of dialysis showed no effect on lymphocytic sensitivity to steroids whereas pregnancy, blood transfusion, previous treatment with steroids, morning plasma cortisol and morning serum ACTH showed significant impact on the development of steroid resistant lymphocytes (p < 0.0094, 0.006, 0.001, 0.001 and 0.001) respectively. Steroid sensitive group has a significant ten years better outcome than the steroid resistant group (p < 0.001). Conclusion: This study shows high incidence of steroid resistant lymphoid population and this resistance is dose dependent. The in-vitro steroid treatment one-way MLC test has a good predictive value to help clinicians to select the donor and the most appropriate immunosuppression on basis of pre-transplant assessment. Hiroki Shirakawa 1 , Jumpei Hasegawa 1 , Mariko Endo 1 , Sachiko Wakai 1 , Daishi Nozaki 2 , Tadahiko Tokumoto 3 , Kazunari Tanabe 2 1 Ohkubo hospital; 2 Tokyo Women's Medical University; 3 Shonan Kamakura General Hospital Background: A new protocol for ABO-incompatible (ABO-i) or highly sensitized kidney transplantation including rituximab was introduced in Tokyo Women's Medical University since 2005. However, ABO compatible recipients without DSA were thought to be low risk recipients and they underwent kidney transplantation without rituximab. We evaluated the necessity of rituximab induction in kidney transplantation. Methods: Between April 2009 and December 2012, 76 kidney transplantations were performed at our hospital. The immunosuppressive protocol, consisting of tacrolimus, mycophenolate mofetil and methylprednisolone, was started 1 week prior to the operation. All the patients received induction with basiliximab. Only ABO-i recipients and DSA positive recipients underwent preconditioning including with plasmapheresis and a single dose of rituximab. The Group I was rituximab group (n = 45) and Group II was non-ritximab group (n = 31). We compared the Group I with Group II. Results: Each one patient in each group lost the graft after one year later (one patient died of cerebral infarction with functioning graft and the other patient lost the graft due to nonadherence). Within 3 months, rejection rates were 15.6% (Group I) and 16.1% (Group II), respectively. After 1 year, rejection rates were 9.3% (Group I) and 4.5% (Group II), respectively. There were no adverse effects associated with rituximab in both groups. Conclusions: ABO-i and highly sensitized recipients with DSA are thought to be high risk recipients, however their rejection rate was equal to the low risk recipients. Rituximab was safe and useful drug for ABO-i and highly sensitized recipients. In the future, induction therapy of rituximab may be expanded to all the recipients also including low risk recipients in order to prevent the acute or chronic antibody mediated rejection. Abstracts of the 16th Congress of the European Society for Organ Transplantation Background: Cyclosporine A (CsA) crosses the placenta and therefore may interfere with fetal growth, causing different pathologies in adult life. The aim of this study in rats was to assess the effect of exposure to CsA during the gestation on kidney morphology in the offspring. Materials and Methods: Eight pregnant Sprague-Dawley rats were randomly allocated to two groups received CsA (3 mg/kg/day) or the corresponding volume of solvent (0.9% NaCl). These substances were administered subcutaneously, from the 10th day after the fertilization till the 7th day after the delivery. 12 weeks after delivery kidneys were obtained using glutaraldehyde perfusion. The number and volume of glomeruli was assessed using unbiased stereological methods. Results: The number of glomeruli was lower (19524 AE 758) and the glomerular volume was higher (2.44 AE 0.32 9 106 lm3) in the kidneys of offspring from mothers treated with CsA (n = 34) compared to the offspring of mothers treated with the solvent (n = 31; 24017 AE 861; 1.68 AE 0.19 9 106 lm3, respectively). Background: The risk for developing Renal Cell Carcinoma (RCC) of the native kidneys in renal transplant recipients (RTR) and end-stage renal disease (ESRD) patients is higher compared to the general population. Hand assisted laparoscopic nephrectomy (HALN) offers the advantage of increased safety over conventional pure laparoscopic techniques. Since 2011 we adopted this technique for living kidney donation and small native kidney tumors. We report our experience with RTR and ESRD patients undergoing HALN for small RCC (<3 cm). Methods: All RCC were incidentally detected during follow-up ultrasound screening of RTR and ESRD patients on the waiting list for renal transplant. From October 2011 to October 2012 five native kidneys were removed from four patients at our centre using a transperitoneal HALN technique. Three procedures were performed in RTR and two in ESRD patients. One RTR underwent bilateral HALN because of masses on both native kidneys. Results: HALN was successfully completed in all patients with no intraoperative or postoperative complications. No blood transfusion were required. Histology of renal masses revealed 4 RCC in four patients (2 papillary, 1 clear cell and 1 chromophobe subtype) and a fibrotic nodule in one patient, this occurred in the patient with bilateral lesions where the nodule on the right kidney was a cromophobe renal cell carcinoma, while the left one, which had on CT scan the same appearance of the right one, resulted to be a fibrotic nodule. All patients were stage T1N0M0. There were no episodes of rejection or graft loss. Graft function was not affected by the surgical procedure. None of the transplant patients had immunosuppression withheld. One ESRD patient who was on peritoneal dialysis was safely restarted on peritoneal dialysis within 7 days of the operation. Mean follow-up was 7.6 months (range 2.6-11.8), mean interval between kidney transplant and nephrectomy for RCC was 2.8 years (range 1.6-5). The average length of stay. Alicja Dę bska-Ślizien´, Joanna Galgowska, Bolesław Rutkowski Medical University of Gdañsk, Clinic of Nephrology, Transplantology and Internal Medicine Background: Successful pregnancy in hemodialysed women is rare. After kidney transplantation, pregnancy is possible, although the risk of maternal and fetal complications is higher than in general population. Material and Methods: The outcome of 22 pregnancies in 17 patients transplanted in Gdañsk center in the period 1987-2010 was studied. None of patients suffered from diabetes or lupus nephritis. Mean: maternal age at pregnancy was 30 AE 5 (range 23-39) years, interval between transplantation and conception was 41 AE 30 (range 7-132) months. Mean creatinine concentration before conception was 1.34 AE 0.4 (range 0.9-2) mg/dl and was stable during one year preceding pregnancy (mean increase 0.05 mg/dl). 9/17 patients received 1, 4/ 17 received two or more anti-hypertensive drugs, 1/17 had proteinuria. Results: At time of conception, 20pts received CNI (CsA-14, Tac-6), 15 antimetabolites (MMF-3, Aza-12), 1 mTOR (Rapa) and all prednisone. MMF and mTOR were discontinued before or during first weeks of pregnancy. All mothers survived the pregnancy. No rejections or graft losses were observed as a result of pregnancy. Maternal complications included edema (5/17), worsening of blood pressure control (5/17) and worsening (1/17) Introduction: Fertility is restored in women undergoing kidney transplantation. Objective: Evaluate the gestations of transplant patients, analyzing outcomes and complications. Methods: Retrospective study investigating the outcome of 101 pregnancies in 89 renal transplant recipients. variables analyzed: Type of nephropathy, patient age when dialysis started, at transplantation, at pregnancy, time between dialysis and transplantation, and between transplantation and baby birth. Immunosuppressive therapy, type of delivery, baby weight, Apgar score and mother and baby follow up were also considerate. Results: In nine patients were diagnosed: chronic pyelonephritis, post partum cortical necrosis (1 pt), IgA GN (11 pt), diabetic nephropathy (5 pt), unknown nephropathy (35 pt), ADPKD 1, 5 Nephroangiosclerosis, 26 Glomerulonephritis, two cistic Kidney disease, one Nephronoptsis, one Tubulo interstizial Nephropathy, one Obstructive Nephropathy, one Alport syndrome, one Renal displasia. The patients' age at start of hemodialysis (3 times/week) was 28.05 AE 2.35 years, the patients' age at transplantation was 30.25 AE 2.52 years, the patients' age at pregnancy was 33.9 AE 3.1 years, the interval between the start of hemodialisys and transplantation was 16 AE 22.3 months, the time between transplantation and childbirth was 4.45 AE 3.15 years. Immunosuppressive therapy included Prednisone, Azathioprine and CyA in 39 pt, Prednisone and Tacrolimus in 1, Prenisone e CyA in 16 pt, Aza e Prednisone in 3 pt, Prednisone, Aza, CyA, Fkin 1 pt,, Aza, Prednisone, Fk in 5 pt, Cya (2 pt), 5 FK (5 pt), Aza (1 pt) e CyA 7 pt. The renal function was normal before (serum creatinine 1.1 AE 0.115 mg/dl), during (0.9 AE 0.10 mg/dl) and after pregnancy (1. kidneys. At this time GFR was 66 ml/min. Immunosuppression consisted of CyA, Aza and PDN. Grossly, the kidneys were shrunken, but the perirenal fat was massively hypertrophic (Fig. 1) . Histology revealed renal replacement lipomatosis (RRL) with end-stage kidneys and massively increased perirenal fatty tissue with focal inflammation; no malignant cells. Case 2: A 62y old man was 1st transplanted in 1983 due to a MPGN. In 1984, cellular rejection occurred and was treated with PDN, ATG and graft irradiation. Due to graft failure, a 2nd transplant was realized in 1986. Twenty-eight years after the 1st transplantation, a tumor in the 1st graft was detected by MRI and nephrectomy was performed. At this time GFR was 25 ml/min. Immunosuppression consisted of CyA and PDN. Grossly, the kidney was shrunken and surrounded by predominantly myxoid tissue. Histology showed RRL with end-stage kidney and increased perirenal fatty tissue with extensive myxoid areas and fibrosis; no malignant cells. Conclusion: RRL is a rare condition described in renal allografts and native kidneys. RRL has been associated with kidney stones, recurring infections and rejection episodes. In immunosuppressed patients, the differential diagnosis between RRL and renal tumors or PTLD is crucial and can avoid unnecessary nephrectomies. YKL-40 (chitinase-3-like protein 1) is a novel inflammation and endothelial dysfunction biomarker. Although YKL-40 is associated with albuminuria and predicts cardiovascular morbidity and mortality in a nonuremic population, its status is not known in renal transplant patients. The aim of this study was to investigate plausible links between serum YKL-40, proteinuria and graft dysfunction. Methods: A total of 110 renal transplant recipients were included in this study. The level of proteinuria was calculated from spot urine using the protein/ creatinine ratio. The estimated glomerular filtration rate (GFR) was calculated using the Modification of Diet in Renal Disease (MDRD) formulae. Serum YKL-40 was determined by an ELISA (R&D Systems, USA). Results: The mean patient age was 40.5 AE 10 years. The mean YKL-40, GFR and proteinuria levels were 66 AE 46 ng/ml, 49 AE 24 ml/min/1.73 m 2 and 0.77 AE 1.15 g/day, respectively. Increases in the YKL-40 tertiles were correlated with increases in, proteinuria and C-reactive protein and decreases in the GFR and serum albumin. The mean YKL-40 level was higher in patients with proteinuria higher than 1 g/day compared to patients with proteinuria less than 1 g/day (p < 0.001; Figure) . An adjusted linear regression analysis demonstrated that the YKL-40 level (t = 3.28, P = 0.001), GFR (t = À3.00, P = 0.003) and systolic blood pressure (t = 2.51, P = 0.01) were independently associated with proteinuria. Conclusions: We are the first to show that increased serum YKL-40 is independently associated with proteinuria in renal transplant patients. YKL-40 may be responsible for the pathogenesis of cardiovascular injury. Background: Multi-detector computerized tomography (CT) is suggested to provide reliable estimation of nephron mass and renal functions. On the other hand, the significance of this method in predicting renal histology is lacking. In this study, we tried to explore the link between renal volume (RV) determined by CT and renal histology along with functional parameters in a healthy cohort; namely, renal transplant donors. Methods and Results: Of the 82 cases enrolled in the study, 62% were male and the mean age was 50.4 AE 12 years. Mean body mass index (BMI) was 28 AE 4.2 kg/m 2 ; of whom 32.9% were obese. Mean serum creatinine level and creatinine clearance were 0.79 AE 0.15 mg/dl and 122 AE 33 ml/min/1.73 m 2 , respectively. Mean RV was 196 AE 36 cm 3 and was positively correlated with BMI and surface area, proteinuria and creatinine clearance; negatively with HDL-cholesterol. In the biopsy samples, 4.6 AE 5.7% of the glomeruli was sclerotic and chronicity index was 2.4 AE 1.8. In the whole population, chronicity index was significantly associated with age but not with RV. However, in obese cases corrected RV was positively correlated with glomerular filtration rate (r = 0.46, p = 0.01) and negatively with sclerotic glomeruli (r = À0.38, p = 0.04) and chronicity index (r = À0.43, p = 0.02), In adjusted ordinal logistic regression analysis, corrected RV was significantly associated with chronicity index. Conclusions: In obese cases, decreased RV determined by CT is associated with worse renal histology. Kumiko Kitajima, Ichiro Nakajima, Shohei Fuchinoue Kidney Center Surgery, Tokyo Women's Medical University Hospital Background: The presence of donor-specific antibodies (DSA) is a leading cause of renal allograft failure. Although various attempts to remove DSA have been made, complete success has not yet been achieved. Methods: In nine renal transplant recipients with de novo DSA treated with tacrolimus and mycophenolate mofetil, we attempted to add everolimus on the basal immunosuppressant therapy. We then investigated the evolution of DSA using the mean fluorescence intensity (MFI), and the estimated glomerular filtration ratio (eGFR). Results: All but one patient exhibited donor-specific anti-HLA class II antibodies. Mean follow-up period was 9.9 months (range: 6.4-12.7). The MFI of five of the nine patients decreased after modification of immunosuppressants, and particularly, the DSA intensity of two patients in these five patients with DSA against DQ4 and DQ5, respectively, completely disappeared. The MFI in two patients continued to increase; no change was observed in the remaining two. The declines in the eGFR in the five patients with a reduced or undetectable MFI and remaining four patients were 5.0% and 19.7%, respectively. Conclusion: Although the DSA intensity reduced in more than half of patients in this study, the exact effect of everolimus on anti-HLA antibody-producing cells was not sufficiently elucidated. Further studies are needed to evaluate the ability of everolimus to prevent chronic rejection resulting in allograft failure. Background: mTOR inhibitors (Sirolimus) has been used as de novo base therapy in an effort to completely avoid the use of CNI. Recent studies found the kinase mTOR has emerged as an important regulator of the differentiation of helper T cells. So we focus on the changs of Th cells in recipients treated by sirolimus. Methods: We included 48 renal transplantation recipient (24 used sirolimus and 24 used tacrolimus) and 24 healthy controls. Of all these subjects, Th cells and the STAT proteins frequencies in the peripheral blood were analyzed by flow cytometry (FCM). Plasma levels of cytokines were analyzed by Bio-Plex â suspension array system. Results: We found that the recipients used sirolimus based regimen had better renal function after conversion. The recipients used SRL based regimen can increase Treg cell (3.9[2.5-5.5]%), decrease Th17, Th1 cells, Th1 related cytokine (IL-1â and IFN-r) and Th17 related cytokine (IL-17, IL-6) compared with tacrolimus group Treg (1. ABO-incompatible kidney transplantation (iABO Ktx) is effective and wellknown option for increasing living donation. Since the end of 1980-s a lot of different immunosuppressive protocols for iABO KTx were established. The iABO KTx program was started in our institution in 2011. For pre-transplant preparation we use combination: rituximab (Rtx) + plasmapheresis (PP) or anti-A/B immunoadsorption (IA) + high-dose IVIG and three-component maintenance immunosuppression: tacrolimus + MMF + steroids that continued after Tx. We modify original "Stockholm protocol": the duration of pre-transplant preparation, number pre-and post-transplant PP or IA sessions, doses of immunosuppressive medications depends on initial anti-A/B titers. 12 patients were transplanted. Mean follow-up period -18 months (range: 24-6). The initial ant-A/B titer range from 1:1024 to 1:2. All recipients are still alive. One transplant was lost 3 months after surgery because of atypical hemolytic uremic syndrome recurrence. We can't find any significant differences in patient and graft survival rates, glomerular filtration rate and frequency of infection complications between ABO-incompatible (n = 12) and ABO-compatible (n = 51) groups of our live-donor kidney recipients. Hakan Sozen, Kibriya Fidan, S € ukr € u Sinder, Metin Onaran, Ayd y n Dalgic Gazi University Urologic complications after kidney transplantation are associated with significant morbidity, mortality and prolonged hospital stay. An intervention or second surgical procedure is frequently required. Here we report urologic complications in adult renal recipients. during surgery. All patients received antibiotic treatment with seftriaxone (1 g every 12 hours) until the removal of surgical drain. The DJS was removed with cystoscopy by Urology in an out-patient clinic under sedation by postoperative 3rd week. All recipients received calcineurine based triple immunosuppression. Also, all recipients have received trimetoprim-sulphametoksazol prophylaxis for 3 months after transplantation. Results: We retrospectively analyzed 98 adult recipients for urologic complications. Source of the donor was in 47(48%) deceased and 51 (52%) living related. The mean age of the recipients were 36.6 AE 12.1 years old (median: 34 years old; range 18-67). Mean donor age was 44.1 AE 14.4, and median age was 46 years old. We focused on 4 specific urologic complications: urine leak, ureteric stenosis, hematuria, and symptomatic vesicoureteral reflux (SVUR) in this study. Totally 3 (3%) urologic complications were encountered. Two out of three were urine leak early after transplantation and one was distal ureter necrosis. We have not seen any hematuria, stenosis or SVUR in this group. Two urine leaks were treated succesfully by conventional radiology. For patient with distal ureter necrosis, conventional radiology did not succeed in treatment, thus surgical revision was done succesfully. We haven't lost neither patient nor graft due to urologic complications. Conclusion: In this study, the Haberal's corner saving suture technique with DJS seemed to protect against the development of urologic complications. Ayman Elsayed 1 , Nadia Marie 2 , Walaa Elbazz 2 , Laila Fawzy 2 1 OTC; 2 Faculty of medicine for girls Al-Azhar University Leptin is a 16 KD protein that is encoded by the ob gene and secreted by adipocytes. Leptin is important in regulation of appetite, food intakes and energy expenditure, sexual maturation and fertility, hematopoiesis and activity of the hypothalamic-pituitary-gonadal axis. Leptin is primarily cleared from the circulation by the kidney and elevated plasma leptin are reported in uremic patients. The present study aimed to assess plasma leptin concentrations in patients with kidney transplant during the early post renal transplant period. Serum leptin were measured in 30 ESRD patients undergoing renal transplant (22 males & 8 females), 20 subjects as a control (17 males & 3 females). This study showed hemodialysis patients (pre-transplant patients) had significantly lower mean BMI than the control subjects. The study showed the mean serum leptin concentration in hemodialysis patients was higher than the control subjects. Our study showed that post-transplant patients had mean serum leptin concentration similar to the control subjects and significantly lower than the hemodialysis patients. This study showed serum leptin levels are correlated positively with BMI in all groups and significantly decreased in post-transplant than pre-transplant. This work showed that there were no correlation between serum leptin and parameters commonly used to assess the extent of renal function. Our data revealed higher serum leptin levels in females than males' inspite of similar BMI. Conclusions: Successful renal transplant is followed by a significant decrease of leptin concentration. Successful renal transplant is followed by a significant increase of BMI *Significant correlation between serum leptin and BMI. Thus, leptin may play an important role in improvement of anorexia, weight gain after normalization of renal function after renal transplantation. Factors other than excretory capacity of the transplanted kidney are apparently in the post transplant decrease of leptin. Ahmed Daoud 1 , Amany Shoulqamy 2 1 Faculty of Medicine, Cairo University; 2 Cairo University New onset diabetes mellitus after transplantation has been reported to occur in 4% to 25% of renal transplant recipients, 2.5% to 25% of liver transplant recipients, 4% to 40% of heart transplant recipients, and 30% to 35% of lung transplant recipients. Risk factors for the development of NODAT can be categorized as non-modifiable, modifiable or potentially modifiable, the former category facilitates the identification of high risk individuals, and the latter two categories to optimize the management of NODAT. Diabetes leads to various medical complications in the post-transplant population. Diabetic patients suffer from an increased risk of cardiovascular complications, graft failure and death. Management of NODAT includes lifestyle modification, oral medications and insulin. Background: There is an unmet need in kidney transplant recipients (KTxR) for an immunosuppressive regimen that improves long-term outcomes. Methods: In this 24-month (mo), multicentre, open-label study with a 36-mo extension, approximately 2000 de novo KTxR will be randomised (1:1) to receive either everolimus (EVR; C0: 3-8 ng/ml) with reduced calcineurin inhibitor (CNI) exposure or mycophenolic acid with standard CNI exposure, all with basiliximab and steroids ( Figure) . The primary objective is to demonstrate superiority of the EVR arm on the composite rate of treated biopsy-proven acute rejection or eGFR<50 ml/min/1.72 m 2 at 12 months. The trial will also evaluate long-term outcomes up to 5 years, including renal function, patient and graft survival, and incidences of cardiovascular disease, malignancies and infections. Conclusion: TRANSFORM is a large study that will evaluate short-and longterm benefits of EVR-based regimen, and has the potential to change the treatment paradigm in de novo KTxR. No conversion to open surgery was necessary. In contrast to other studies the complication rate was not higher in the laparoscopic group. We had to perform two reoperations in the group of open nephrectomy (bleeding, ureter complications) and one reoperation in the laparoscopic group (wound infection). Donor creatinine 1 year after donation did not differ between the two groups. Conclusion: We were able to show that our fully laparoscopic donor nephrectomy technique is a safe approach with favourable donor acceptance. Operation and warm ischemia times were slightly longer. Although we had a complete change of our approach and an unavoidable learning curve, no higher rates of complications and no conversion to open surgery were observed. Laparoscopic donor nephrectomy might be the new standard for living kidney donation. Background: Although ABO-incompatible kidney transplantation is an immunologically high-risk procedure, the development of powerful immunosuppressant drug combinations including rituximab has resulted in excellent graft and patient survival. However, the intensity of immunosuppression may be linked to a higher risk of tumor development and viral infection. Everolimus provides safe and effective immunosuppression after kidney transplantation and has been suggested to have anti-tumor and anti-viral activities. Methods: An open-label design was used to examine the efficacy and safety of conversion of stable ABO-incompatible kidney transplant recipients from mycophenolate mofetil (MMF) with standard exposure calcineurin inhibitor (CNI) to everolimus with very low exposure CNI. A total of 16 recipients of ABOincompatible kidney transplantation at our institution were enrolled. The patients without acute rejection by graft biopsy were switched from MMF to everolimus with dose adjustments to target an everolimus trough level of 3-8 ng/ml. The CNI dose was reduced to a target trough level of 2-4 ng/ml (tacrolimus) or 25-50 ng/ml (cyclosporin). At 3 months after conversion, graft biopsies were performed to check acute rejection. At baseline and at 1, 2 and 3 months after conversion, the peripheral CD19 + cells and CD20 + cells and anti-A/B antibody titers were monitored. Results: Conversion to everolimus with CNI minimization did not induce acute rejection in the ABO-incompatible kidney transplant recipients. There were no significant changes in CD19 + cells and CD20 + cells during the study period, but a slight elevation in anti-A/B antibody titer (IgG; less than 2 times) occurred. Introduction: To gain information on new clinically relevant endpoints in kidney transplantation (KTx) for use in future trials, we retrospectively examined different endpoints in study A2309. Methods: This 24-month (mo), multicentre, study randomised 833 de novo KTx patients to compare 2 regimens of everolimus (EVR; 1.5 mg/day or 3.0 mg/day) + reduced cyclosporine A (CsA) vs. enteric-coated mycophenolate sodium (EC-MPS; 1.44 g/day) + standard CsA. Renal function (RF) was measured by estimated GFR (MDRD). Results: Analyses of RF at month 12 showed a benefit for EVR 1.5 mg vs. EC-MPS group across different cut-off points. Fewer patients in the EVR group experienced the composite endpoint of impaired RF or treated biopsy proven acute rejection (tBPAR) or a composite of RF event, tBPAR, graft loss, or death (Table) . Conclusion: Study endpoints that consider RF and various composites are a novel approach to clinically relevant graft outcomes. These endpoints need to be further explored in prospective trials. Eva Slimackova, Alena Verflova, Janka Slatinsk a, Eva Pokorna, Antonij Slavcev, Ond r ej Viklick y IKEM A possible approach to decrease the risk for development of antibody-mediated rejection (AMR) in patients waiting for transplantation is to avoid the same HLA mismatches from previous transplantation (s). However, there are no guidelines about how and which HLA mismatches to exclude in order not to unjustifiably limit the chance of patients to receive another transplant. Objective: The aim of our study was to find an optimal way of forbidding HLA antigens for the next transplantation, so that patients would have a good chance to receive a new graft, while diminishing the risk for development of AMR. Methods: In our center, testing for specificity of HLA antibodies by Luminex was introduced for all patients waiting for re-transplantation. In case antibodies specific to mismatched HLA antigens to the previous donor (s) were detected, these antigens were "forbidden" in the organ allocation algorithm for the next transplantation. Results: Out of 121 patients, 107 (88%) had HLA antibodies (65% class I and II, 11% class I and 12% class II). In 76 (63%) patients were forbidden both class I and II antigens, 11 (9%) class I and 3 (2%) only class II antigens. Twenty-six re-transplantations were performed in the study group in 2011 and the incidence of AMR and other complications were compared with a control group (62) in which forbidden antigens were not taken into account during the organ allocation. Lower incidence of delayed graft function in the study group was observed as compared with the control group (23% vs. 53%; p = 0.01), however the incidence of AMR was similar (19% vs. 26%; p = 0.5). There was a tendency towards better 6 months graft survival in the study group (96% vs. 82%; p = 0.1005). Conclusions: The implementation of forbidden HLA antigens based on Luminex technology in the allocation system might improve the outcome of kidney re-transplantation, however these results have to be confirmed in larger prospective studies. Background: Lipid peroxidation and atherosclerosis development remain accelerated in patients with chronic renal failure even after renal transplantation. Oxidative stress and inflammation facilitate atherosclerosis develepoment all over the peripherial, central and coronary arteries. We investigated the connection between lipid peroxidation and arterial stiffness parameters after renal transplantation. Methods: One hundred and thirty one renal transplanted patients (46.40 AE 14.20 years) and 63 healthy controls (48.20 AE 9.80 years) were involved in this study. Fasting serum creatinine, urea, cystatin-C, homocysteine, lipids, glucose, C-reactive protein (CRP), asymmetric-dimethyl arginine (ADMA), adiponectin (ADPN), leptin (LEP) concentrations were measured with ELISA and paraoxonase (PON1), arylesterase activities were measured spectrophotometrically. Arterial stiffness parameters (PWV-pulse wave velocity, AIx-augmentation index, PP-pulse pressure, SIA-systolic area index, DIAdiastolic area index, systolic and diastolic blood pressure, and MAP-mean arterial pressure) were measured with Arteriograph. Results: In case of kidney transplanted patients with dyslipidaemia we found significant lower PON1 activity (101.71 AE 52.31 U/l) compared to controlls (p < 0.01). Significant negative correlation were found between serum cystatin-C level, homocysteine (p < 0.05), and ADMA (p < 0.05), and there was significant positive correlation in case of cystatin-C and ADPN (p < 0.03) concentrations. Significant negative correlation were found in case of PON1 activity and PWV (r = À0.2315, p < 0.0488); DAI, LDL (p < 0.0452), and total cholesterol (p < 0.0301); MAP (p < 0.0057) and ADMA concentrations. There was positive correlation between PWV and CRP (p < 0.03); PWV and total cholesterol (p < 0.0215); PWV and LDL (p < 0.045). In obese transplanted patients we measured significant higher LDL and leptin levels (p < 0.05). Positive correlation was found between PWV and AIx; systolic, diastolic blood pressure and MAP (p < 0.01). Background: Incidence of urological complications after kidney transplantation remains high despite improvements in diagnosis and surgical techniques. Urinary tract reconstruction is usually done by ureteroneocystostomy, of which there are several techniques. In this study we evaluate the outcomes of two different techniques of ureteroneocystostomy performed in our department, the transvesical Leadbetter-Politano (L-P) and the extravesical Lich-Gregoire (L-G) technique. Methods: During 1st of July 2006 and 31st of December 2011 we performed 524 consecutive renal transplants, 264 cases using L-P technique (50.3%) and 260 cases with L-G technique (49.7%). Renal grafts were obtained from cadaveric donors in 146 cases (27.86%) and from living-related donors in 378 cases (72.14%). Ureteral stenting was performed in 103 cases (19.6%). Results: Urological complications after kidney transplantation occurred in 22 cases in the L-P ureteroneocystostomy group (8.33%). The most common complications were ureteral stenosis (3.41%) and leakage (2.65%). Compared with the L-P ureteroneocystostomy technique, the L-G technique was associated with fewer overall complications (6.15% vs. 8.33%; p = 0.06), a lower rate of ureteral stenosis (2.31% vs. 3.41%; p = 0.08) and a similar rate of leakage. However, statistical analysis revealed no significant differences between the two techniques (p = 0.06). In addition, we did not notice any differences in graft and patient survival between two groups. Conclusions: In our study, the extravesical L-G technique has a lower urological complications rate compared to transvesical L-P procedure but without statistical significant differences. Furthermore, Lich-Gregoire technique is easier to perform, faster, avoids a separate cystotomy and requires a shorter ureteral length. In conclusion, we recommend L-G technique as the technique of choice in kidney transplantation. Alexey Sharshatkin, Andrey Efimkin, Alexander Sushkov, Yan Moysyuk Academician V I Shumakov Federal Research Center of Transplantology and Artificial Organs Preferences and disadvantages of laparoscopic hand-assisted donor nephrectomy (LHADN) are well-known. The corner stone of living donation is donor guaranteed safety. Since 1999 more than 500 consecutive living donor kidney transplantations were performed. During the last 4 years we exclusively used LHADN. We have analyzed the frequency of complication incidences (Fisher exact criteria) in groups of open donor nephrectomy (ODN, n = 250) and LHADN (n = 170). There are no significant differences between groups in bleeding frequency. Two LHADNs (1.2%) were converted to open approach because of serious abdominal bleeding; one splenectomy has been performed. Another splenectomy was done in one case of LHADN reoperative donors. LHADN has significant advantages in wound complications. All donors have excellent renal function after surgery. Short hospital staing, excellent cosmetic effect, minimal postnephrectomy pain have positive impact on increasing living donor pool. Despite of existing minimal risk of severe surgical complications we consider LHADN as the most safety approach for living kidney donation. However, there is a long learning curve and experienced surgeons are required. Background: The recent introduction in Italy of generic tacrolimus has created concerns in the transplant community about the risk of possible changes in drug blood through level (BTL). Since 2011 in Piedmont (Italy) generic tacrolimus has replaced branded tacrolimus, so we realized a retrospective analysis comparing the generic and branded tacrolimus metabolism in two groups of kidney transplant recipients in one Center. Methods: Twenty-eight kidney transplant recipients (KTR, age 60.7 AE 7.2 years, male 18/28 = 64.3%) started generic tacrolimus ([Tacni â ] by Teva Pharmaceutical Industries LTD) in 2012 (group Gen): clinical data and drug dosage were recorded at the time of hospital discharge and they were screened for CYP3A4 and MDR1 C3435T alleles. For each patient one age and sex-matched control with the same genotype of tacrolimus-metabolizing enzymes receiving branded tacrolimus ([Prograf â ] by Astellas Pharma, US) was selected from a historical cohort from the same Center (group Brand). Results: In the Brand group the mean tacrolimus BTL was 12.1 AE 3.4 ng/ml, with a mean daily dose of 0.119 AE 0.068 mg/Kg (BTL/dose ratio: 135 AE 90), while in the Gen group the mean tacrolimus BTL was 11.3 AE 4.5 ng/ml (p = 0.45 vs. Brand group), with a mean daily dose of 0.125 AE 0.049 mg/Kg (BTL/dose ratio: 101 AE 49; p = 0.08 vs. Brand group). Moreover even if the patients are divided in classes according to the BTL/dose ratio in very fast (<90), fast (90-140), slow (141-210) and very slow (>210) there is no difference between Gen and Brand groups by Fisher exact test (p > 0.1). Lastly the incidence of new onset diabetes after transplant (NODAT) was 7/28 (58%) and 5/28 (48%) in the Gen and Brand groups respectively. Conclusions: Since the BTL/dose ratio is the best available indicator of tacrolimus AUC, we conclude that patients receiving generic tacrolimus have the same drug bioavailability and NODAT incidence as age, sex and genotype matched controls receiving branded tacrolimus. One for the cost of the surgical recovery of kidneys connected to a MP (808€, twice the amount of a standard recovery with cold storage) and one for the cost of the MP, maintenance, storage, return transport, and disposables (8814€ every 6 perfused kidneys). The rules for allocating lump sums have been validated by the ABM's Medical and Scientific committee: conditions are i) both kidneys retrieved from an ECD donor are connected to the MP at the end of the procurement process (exceptions will be examined case by case), ii) should a perfused kidney allograft be refused, the perfused organ will proposed to the next patient on the national waiting list. The MP programme is progressing steadily: at month nine, the number of ECD kidney donors put under MP has Methods: A case-control study in patients with AAN who underwent kidney transplantation. Patients' characteristics and outcomes were compared to a control group of patients with interstitial chronic nephropathy matched for gender and age at transplantation. Results: Twenty patients were transplanted since 1992 for AAN. Nineteen were female. All but one were Caucasian. Mean age at diagnosis was 45 AE 2 years (39 AE 2 in controls, p = ns). Time on dialysis was 19 AE 4 months (28 AE 3 in controls, p = ns). Time from diagnosis to transplantation was significantly shorter in AAN patients (5 AE 0.7 vs. 11 AE 1 year). Mean age at transplantation was 50 AE 3 years (49 AE 2 in controls, p = ns). Mean time of follow-up was 13 AE 1 year. Immunosuppressive therapy was comparable in both groups. Seven patients presented with urothelial carcinomas of the upper-tract; two of them with additional bladder urothelial carcinomas. Of these two patients, one required radical cystectomy. In the control group, none suffered from urological complications. Cardiovascular complications were comparable in both groups. Patient survival was 100% in AAN patients compared to 100, 92 and 92% in the control group (p=ns) at 5, 10 and 15 years respectively after transplantation. Graft survival at 5, 10, and 15 years was 95, 83, and 75% in the AAN group compared to 100, 92, and 92% in the control group (p=ns). Conclusion: AAN leads rapidly to end-stage renal disease requiring transplantation. Although 35% of patients presented urothelial carcinomas of the upper-tract and bladder, patients' survival is excellent and graft survival is not affected. Results: There were a total of 57 donations. The mean age was 50 years (range 24-71) with a mean BMI of 29 kg/m 2 (range 18-33.8 kg/m 2 ). The training surgeon assisted in three full procedures and a further three to mobilise the vessels. In a further eight procedures the training consultant required minimal help with either mobilisation or vessels dissection. From the 15th case no further assistance was required. The decision to remove a kidney was decided in a multidisciplinary team meeting. Fifty were left sided, and 33 had simple anatomy. Thirteen cases there were two arteries, two cases three arteries and one case four arteries. The mean operating time was 199 mins (range 129-358 min). Mean blood loss was recorded as 115 ml. One right sided procedure required a further incision to accommodate a gel port to help mobilise the upper pole of an adherent kidney. Post operatively the mean length of post-operative stay was 2 days. There were two recorded chest infections requiring antibiotics and one prolonged wound discharge. Two patients required a post-operative CT scan to investigate unexplained abdominal discomfort and an elevated CRP > 250. The scans showed no abnormal features and these donors were discharged on day 4. Conclusion: Retroperitoneal approach to donor nephrectomy is a safe technique to train a surgeon with previous live donor nephrectomy experience. Tainá Sandes-Freitas 1 , Fernanda Costa 2 , Alexandra Ferreira 2 , Elisa Conceic ßão 2 , H elio Tedesco-Silva 2 , Jos e Osmar Medina-Pestana 2 1 Physician; 2 Hospital do Rim e Hipertensão Backgroud: the use of kidneys from expanded criteria donors (ECD) is increasing but the ideal immunosuppressive strategy for these recipients has yet to be established. Materials and Methods: This study was an exploratory sequential investigation in 203 consecutive low risk recipients of kidneys from ECD. The first cohort (BSL-MPS, n = 43) received basiliximab, mycophenolate (MPS, 1080-1440 mg BID) and tacrolimus (TAC, 0.1 mg/Kg BID initiated at day 4). The second cohort (Thymo-SRL, n = 49) received thymoglobuline (Thymo, single 3 mg/Kg dose at day 1), TAC (0.1 mg/Kg BID) and azathioprine (2 mg/Kg/day) with conversion to sirolimus (SRL, 2 mg/day targeting blood concentrations of 5-15 ng/ml) 10 days after the transplant surgery. The third cohort (Thymo-EVL, n = 26) received Thymo (4 doses of 1.5 mg/Kg every other day), MPS (720 mg BID) and everolimus (EVR, 1.5 mg BID initiated at day 7 targeting blood concentration of 5-8 ng/ml). The fourth cohort (Thymo-MPS, n = 85) received Thymo (4 doses of 1.5 mg/kg every other day), MPS (720 mg BID) and TAC (0.05 mg/kg BID initiated at day 7). The TAC trough concentration was maintained around 3-8 ng/ml and all patients also received prednisone. None patient received prophylaxis for cytomegalovirus (CMV) infection. Results: There were no differences in main demographic characteristics. The mean recipient and donor age were 50 and 60 years, respectively. Mean cold ischemia time was 25 h and mean time on dialysis was 53 months. The main outcomes are presented in the table below. Conclusion: BSL-MPS regimen was associated with highest incidence of acute rejection (AR). Thymo-SRL was associated with high AR incidence, treatment discontinuation, and inferior renal function. Thymo-EVL regimen was associated with high incidence of AR, CMV infection and treatment discontinuation. Thymo-MPS was associated with lowest incidence of AR and highest incidence of CMV infection. None of these strategies showed superior survival outcomes. Background: The role of steroids on the risk of recurrent (R) or de novo (DeN) glomerulonephritis (Gn) is poorly investigated in RTRs Materials: We analyzed the association between steroid withdrawal (SW) and DeNIgAGn and RIgAGn in 1268 RTRs in our Center (1995) (1996) (1997) (1998) (1999) (2000) (2001) (2002) (2003) (2004) (2005) (2006) (2007) . In 484/1268 grafts (38.1%) a for cause biopsy was performed: > 20% increase in serum creatinine or >500 mg/ day proteinuria. Overall 87 Gn were found. Results: In 32/87 cases (36.7%) IgAGn was diagnosed (7/32 RIgAGn and 25/ 32 DeNIgAGn);17/25 DeNIgAGn (68%) occured after SW (p = 0.006). Median time to DeNIgAGn was 25.3 months (5.1-93) after SW. As for R+ DeNIgAGn altogether the association with SW was a tendency, but not significant. Compared to the other R+DeNGn, (n = 62), DeNIgAGn carried a statistically greater risk of developing after SW (OR 6.7). No other immunosuppressant showed a correlation with DeNIgAGn. Conclusion: We found a strong association (OR 6.7) between SW and DeNIgAGN. Further studies are needed to confirm our preliminary data. The balance between SW and maintenance of steroids to reduce IgAGn should be tailored on the basis of the recipient risk profile. Background: Several pneumotoxic drugs as amiodarone and m-TOR inhibitors (m-TORi) can be found associated in therapy of RTR. Differential diagnosis may promptly request invasive tests. We present a case of amiodarone pulmonary toxicity (APT) in a RTR treated with amiodarone and everolimus. Case Report A 57 year-old caucasian male in treatment both with everolimus-since 3 years-and amiodarone-since 2 months-for his second kidney transplant with suboptimal serum creatinine (3 mg/dl) presented with fever and dyspnoea, normal physical examination and negative chest X-Ray. A non-contrast high resolution computed tomography (HRTC) scan showed bilateral interstitial lung disease with associated reduction in carbon monoxide diffusing capacity (DLCO). Bronchoalveolar lavage (BAL) was negative for infection but BAL cytology was suitable for APT (50% of "foamy" macrophages). Complete recovery was obtained after amiodarone interruption and oral steroid therapy increase. Everolimus was not discontinued. The kidney function remained unchanged in the following months. Conclusion: We suggest a possible synergistic effect between m-TORi and amiodarone (as seen in the image below) and we recommend promptly performed tests as HRTC and BAL for the differential diagnosis in case of suspected lung toxicity. Background: Tacrolimus (Tac), a narrow therapeutic index drug is metabolized by CYP3A enzymes. Variants in several genes have been reported to impact the CYP3A activity. Recently a single-nucleotide polymorphism in the nuclear receptor peroxisome proliferator-activated receptor gene (PPARA) has been identified as a regulator of CYP3A4 expression and activity, but the effect of PPARA on Tac metabolism in renal transplant recipients (RTR) remains unknown. Methods: Hundred RTR were genotyped for CYP3A53 and PPARA. The potential association with steady state dose adjusted trough Tac concentration (C0/dose, lg/l/mg) 2-3 weeks post Tx was investigated. Results: CYP3A5 non-expressers (*3/*3) had significantly higher mean C0/ dose, 2.5 AE 1.0 vs. 1.5 AE 0.7 (p < 0.001). CYP3A5 expressers (*1/*3), carriers of at least one variant PPARA allele showed significantly higher C0/ dose, 1.9 AE 0.8 vs. Background: Although kidney transplantation has become a standard treatment for end-stage renal disease, complications associated with surgery compromise clinical outcomes. Because kidney transplant recipients have usually been on dialysis for a long time in Japan, post-operative urologic complications related to disused bladder are common. Methods: Uretero-ureterostomy technique was employed in five kidney transplant recipients with disused atrophic bladder (bladder capacity <50 ml). Results: The average dialysis was 11.8, 4.3(6.2-18.2) years. In three patients, the native ureter was ligated at the upper part of anastomotic site, leaving the native kidney in situ. A ureteral stent was placed in four patients, and then removed endoscopically removed after about 2 weeks. Two hydronephrosis in the native kidney were observed in patients with ligated ureter, both of which required no treatment. Conclusion: End-to-side uretero-ureterostomy was safely performed and may be a treatment option for reconstruction of the urinary tract in renal transplant recipients especially with disused atrophic bladder due to long-term dialysis. Introduction: Post-transplant lymphoproliferative disorder (PTLD) is one of the most severe and often fatal complications observed after solid organ and bone marrow transplantations. The histological subtypes of PTLD range from the early Epstein-Barr virus (EBV)-associated polymorphic lymphoid proliferation resembling infectious mononucleosis, to more aggressive EBV-positive or -negative monomorphic lymphomas of B-cell or less often T-cell origin. Case report: We presented a case of a patient HA, born 1989, who underwent liverelated donor renal transplantation at the age of 16. Induction therapy implicated administration of ATG and corticosteroids, and maintenance dose encompassed combination of three immunosuppressive agents: tacrolimus, mycophenolate mofetil and corticosteroid. The patient experienced first complications six months after transplantation, manifested as lacunar angina and subsequent dysphagic problems. Upon recommendation of ENT-specialist, tonsillectomy was performed in April 2006. Histopathological and immunohistochemical analysis of tonsillectomy specimens revealed a polymorphic PTLD (with high expression of EBV LMP antigen). Definitive diagnosis of diffuse large B-cell lymphoma (CD20 + ) was established upon analysis of oesophageal bioptate. Antiviral therapy was applied, along with rutiximab and CHOP therapy, whilst the dosage of basic immunosuppressive drugs was reduced. Complex diagnostic procedures confirmed the absence of disease recurrence and stable graft function five years after completing PTLD therapy. Conclusion: The presented case of our patient, who developed PTLD after renal transplantation, demonstrated that an appropriate early diagnosis, reduction of immunosuppressive regimens and vigilant application of immunomodulatory and chemotherapy could result in complete disease remission, yet preserving and maintaining the stable function of the transplant. Background: We reported our initial experience performing ABOiKtx with a low dose of rituximab instead of splenectomy at ESOT 2009. Here, we aim to review 1. The extended outcomes of our earlier ABOiKtx studies and 2. The early outcomes of recent studies involving ABOiKtx, where patients were pre-treated with either reduced antibody removal or no antibody depletion. Methods: Immunosuppression was induced by treatment with the following drugs: tacrolimus, mycophenolate mofetil, basiliximab, steroids, and rituximab. 1. Eight transplant recipients followed for more than five years were reviewed. Special emphasis was placed on graft function, infection rates, and malignancies. 2. Since 2010, antibody removal was not performed if the titre of anti-blood type antibodies was below 932. The rate of antibody-mediated acute rejection (AMR) was examined for eight recipients treated with these guidelines. 1. All recipients had stable graft function with serum creatinine levels of 0.9-1.7 mg/dl. One case of pneumonia and one case of colon cancer occurred during the observation period. 2. No AMR occurred in the recipients with reduced or no antibody removal. 1. ABOiKtx can be successfully performed with low dose rituximab with excellent graft function for more than 5 years. Care must be taken to avoid late onset infections and malignancies. 2. Candidates for ABOiKtx with anti-ABO antibody titres below 932 do not need antibody elimination prior to transplant to avoid AMR. A lymphocele is a common surgical complication after renal transplantation thought be due to disrupted lymphatic channels of the iliac vessels. Preventing lymphocele occurrence by ligation of lymphatic channels running along the iliac vessels using multiple surgical ties has been the standard treatment approach, but this requires significant time and can be tedious, labor intensive, and frustrating due to the friable nature of the tissue ligated. An alternative to control lymphatics is the use of ultrasonic scalpel for dissection, which has the advantage of quickly and reliably cutting and coagulating small bleeding sites and lymphatics during dissection around the iliac vessels and has been applied in many types of surgery to safely divide tissues while also achieving hemostasis. Patients and Methods: A total of 149 patients with end-stage renal disease underwent living donor kidney transplantation at Osaka City University Hospital between January 2000 and February 2013, of which 63 cases were kidney transplantation between spouses. ABO-incompatible kidney transplantation was performed in 20 of the 63 cases. We analyzed these recipients, focusing on the immunosuppressive protocols, complications, and patient/graft survivals. Results: Patient and graft survival rates were 100%. Thirty-six patients received cyclosporine, and 27 received tacrolimus, as calcineurin inhibitor. One patient experienced antibody-mediated rejection and intractable acute cellular rejection, one had antibody-mediated rejection, and one had an intractable acute cellular rejection episode that was treated using OKT-3. The incidence of acute rejection was 14.3%. There were no severe complications among the recipients. Conclusions: Previously, living unrelated kidney transplantation between spouses has met with some opposition due to poor tissue antigen compatibility. Recent significant improvements in immunosuppression and recipient care indicate that it has become a viable treatment option in Japan, which lacks deceased donors. Background: It is known that the Eichwald-Silmser effect, first demonstrated in female mice rejecting skin graft from male donors of the same strain, depends on the loci controlling weak transplantation antigens on the Y chromosome, responsible for H-Y incompatibility in transplants across a sex difference. This has been shown to have an impact on female recipients of male bone marrow transplant in humans, whereas conflicting results were reported in renal transplant. Aim of this study was to assess the clinical impact of the Eichwald-Silmser effect on a population of renal transplanted patients. Materials and Methods: We performed a retrospective cohort study (1998) (1999) (2000) (2001) (2002) (2003) (2004) (2005) (2006) (2007) (2008) (2009) (2010) at our Transplant Center. Overall, 289 women (mean age 50 AE 12 years, min 20 max 75) received single allografts from deceased donors (mean age 50 AE 17 years, min 15 max 83), 134 from male donors and 135 from female donors. Results: Graft loss was more common in female patients receiving kidneys from male donors than in the opposite situation (p < 0.04) only in the subgroup of patients receiving donors aged below 50 years, but not in other subgroups with older age. Furthermore, women recipients from donors <50 years had significantly lower age than in other subgroups (42 AE 10 years versus 51 AE 10 years and 60 AE 9 years, p < 0.001). Therefore an increased risk of kidney graft loss was only demonstrated in young female recipients being transplanted from young male donors. In this subset of patients graft loss occurred for immunological causes in all cases (chronic and acute rejection). Conclusions: Our results suggest that a role for H-Y minor histocompatibility in affecting human kidney transplantation has to be looked for in the setting of young-for-young transplant, and this could explain previous conflicting results. Aim: To analyze which factors have a significant influence on long term (10 years) renal function and survival of kidney transplants in our Center. Methods: All kidney-only recipients from deceased donors, transplanted in our Hospital from 30 July 1985 to 31 December 2005 and, functioning after 6 months, were included. Graft survival and renal function at 120 months were recorded. The following factors were analyzed: donor and receptor demographics, cause of death, early and late rejection (during or after the first year), delayed graft function (DGF), panel reactive antibodies (PRA), HLA compatibilities and cold ischemia time (CIT). Results: 413 kidney recipients followed for 10 years were studied. The mean survival rate was 95.6% at 60 months and 82.7% at 120 months (60-300 m). Cerebrovascular death, donor age > 60 years, late acute rejection, DGF and immunized receptors had worse survival rate (p < 0.05). CIT >12 h. was significant only when the donor was > 60 years. Although renal function was worse from the beginning in patients with these negative factors, it kept steady along the 10 years except in those patients who had a late rejection as can be seen in figure 1 the kidneys, were reclassified according to a severity-based score. Primary endpoints were recipient and graft survivals at 36 months posttransplant. Results: ECD had a mean age of 58 years old, 70% hypertensive, stroke being the main cause of death, and the final creatinine 1.7 mg/dl. Of the histological evaluated kidneys, 38% had a final ranking of "moderate changes" and 17% of "severe changes". Recipients had a mean age of 49 years, hypertension (17%) and diabetes mellitus (16%) the main cause of chronic renal failure, mean time on dialysis of 56 months, PRA < 50% in 94%. Mean cold ischemia time was 25 h. Global recipient and graft survival rates at 3 years were 81% and 69%. Improvement of outcome was noted: graft survival at 3 years was 61.4% for transplants between 1998 and 2006, and 70.4% for those between 2007 and 2009 (p = 0.18). Graft survival at 3-years was negatively associated to the severity of histological change: 78% for mild changes, 72% for moderate changes and 60% for severe changes (p = 0.10). Multivariable analysis, however, found recipient history of Diabetes Mellitus the only independent risk factor for graft loss (OR 2.1, CI 1.3-3.3, p = 0.003) and recipient death (OR 3.1, CI 1.6-5.8, p < 0.001). Conclusions: There was a reasonable long-term survival for ECD single kidneys transplants, pointing to improvement over time. Histological analysis was not an independent risk factor for worse outcomes. Diabetic recipient presented the worst outcomes independently, and subsequent studies are needed for this subgroup. Background: The increasing number of kidney recipients with abdominal aortic aneurysm is endovascularly treated with stent grafts. The aim of the study is to evaluate the impact of EVAR on kidney graft function. Materials and Methods: Among 12 recipients after EVAR serum creatinine (sCr), glomerular filtration rate (GFR) and development of contrast induced nephropathy (CIN) was assessed. The impact of stent graft main body introduction side on graft function was analysed. Results: Average serum creatinine levels before and after EVAR were 2.02 AE 0.8 mg/dl and 2.56 AE 1.3 mg/dl (ns) and GRF was 50.3 AE 18 ml/min and 45.6 AE 26.6 (ns), respectively. There was no impact of stent graft main body side introduction on kidney graft function. 50% of recipients met the criteria of CIN. Two patients required temporary hemodialysis and one of them died due to multiorgan failure. None of recipients returned to chronic hemodialysis during 48 AE 35 months follow-up. Conclusions: EVAR seems to be the optimal management for kidney transplant recipients and the deterioration of kidney graft function after intervention is transient. Bulent Unal 1 , Turgut Piskin 1 , Ruslan Mamedov 1 , Idris Sahin 2 , Sezai Yilmaz 1 1 Medical Faculty, Liver Transplantation Institute, Inonu University, Malatya; 2 Medical Faculty, Internal Medicine Unit, Inonu University, Malatya Background: We wanted to evaluate our surgical and non-surgical experiences about ureteral stenosis developed after renal transplantation as a center with initial experiences with renal transplantation in Turkey. Material and Method: We performed total 76 renal transplantations (with 23 cadaveric and 53 living donor kidney transplantation) between November 2010 and December 2012 at our center. Patients with ureteral stenosis after renal transplantation were evaluated. Result: the ureteral stenosis was observed at three of our patients during post-transplantation period: at 3rd week after cadaveric tranplantation (after removal of double J cathether), at 8 months after cadaveric transplantation and at 10 months after living donor kidney transplantation. We primarly applied by nonsurgical procedures (percutaneous nephrostomy, dilatation, percutaneous catheterizatation). End to side ureteropelvic anastomosis was performed between transplanted renal pelvis and native ureter at two patients ( Figure 1 ). New ureteroneocytostomy was performed after resection of fibrotic urethral segment at third patient. After reconstruction surgery, renal functions of all patients were normal and there is no problem was observed at their follow up period. Conclusion: Non surgical interventions might be insufficient in patients with ureteral strictures seen after renal transplanatation. In these patients surgical treatments should be applied before deterioration of graft functions. During surgical interventions, one should not insist on single procedures and the interventions with minimum harm to tranplanted kidney should be preferred. Background: Calcineurin inhibitors (CNIs), which are standard immunosuppressive drugs in kidney transplantation, are a risk factor for cardiovascular disease (CVD), and affect the long-term prognosis. Efforts to establish an immunosuppressive therapy free of renal toxicity has been an enduring theme. [Objective] To study safe and useful methods for administering everolimus (EVL), to renal transplant patients during the maintenance phase, and lowering the dosage of CNIs and other immunosuppressive drugs. Methods: Immunosuppression was altered by a regimen comprising the addition of 1.5 mg/day EVL, lowering the CNI dosage to 50%, and either discontinuing or lowering the mycophenolate mofetil (MMF) dosage. Results: There were 13 subjects (five men and eight women; average age 49.1 years) with an average of 5.3 years after transplantation. Eight of the subjects were tacrolimus (TAC) patients, whereas the remaining five were cyclosporine (CYA) patients. Reasons for inclusion were eight cases of CNI dose reduction, two cases of CMV infection, one case of malignant neoplasm, and three cases of CVD. Four of the eight TAC patients (50%) and one of the five CYA patients (20%) required an increased dosage to control the everolimus Cmin. Six patients (46.2%) showed exacerbated proteinuria, and four patients (30.8%) were started on oral administration and received increased dosages. Elevated total cholesterol and neutral lipids were observed in eight patients (61.5%), and two patients (15.3%) were started on oral administration and had increased dosages. Improved renal function was observed in four out of the 13 patients. In seven patients, renal function essentially did not change when the MMF dose or CNI dose was lowered. Rejection was not observed in any of the patients. Background: Even if it seems simple to close the fascia after surgery of renal transplant recepients patients, in case of carelessness post-operative morbidity may increase and quality of life decreases. In this study, we aimed to show details that should be considered in the fascia closure Methods: From January 2011 to December 2011, a total of 123 kidney transplants were performed in our Kidney Transplant Unit. Two patients developed eventrations in the incision; this represents an incidence of 1.62%. After Gibson incision made in the right or left lower quadrant, retroperitoneum is reached. After creating adequate space for the kidney in the retroperitoneal area, adhesions between the peritoneum and the transverse muscle are divided medailly with cautery. This process eliminates hesitation whether suture has passed through peritoneum or not during fascia closure. Starting from distal (pubic region), closure is proceeded proximally. Full-thickened layer transition, comprising the abdominal internal and external oblique muscles, transverse muscle and fascia, is made over three sutures, then closure is continued in the same layer with internal and transverse muscle. Then the external fascia is closed with the same suture material on a second layer. Results: Two patients developed eventrations in the incision; this represents an incidence of 1.62%. There were 78 living (63.4%) while 45 (36.6%) were cadaveric renal transplantation. All the patients were under triple immunosuppressive therapy with prednisolone, calcineurin inhibitors and antiproliferatif agents. The mean recepient age was 40.5 AE 10 years and mean donor age was 48 AE 14. Cold ischemia time was 14.8 AE 6 h for deceased kidneys. There were 4 (3.2%) mortalities and 3 (2.4%) graft loses during the first year. Discussion: Different closure techniques have been reported in renal transplantation. Fascia closure process we have described seems to be shorter and more reliable. The chronic use of immunosuppressive agents to prevent allograft rejection increases the long-term risk of malignancy compared with that of the general population. Adrenocortical carcinomas are rare, aggressive tumors, even at early stage, with incidence of approximately one to two per million population per year. We present the case of a 33-year-old Caucasian patient with IgA nephropathy that was transplanted a cadaveric kidney eight years ago. Four years later he developed recurrence of IgA nephropathy and acute humoral rejection. During hospitalization a mass lesion of 5 cm was incidentally discovered in a right suprarenal gland. The mass was taken out surgically and pathohistoloy revealed adrenocortical carcinoma. Therapy with mitotane was tried but quickly withdrawn due to serious side effects. Eight months later patient developed another humoral and cellular rejection. Our decision was not to intensify immunosuppression because of already gravely damaged kidney and prior adrenocortical carcinoma, therefore patient started hemodialysis. A fluorodeoxyglucose-PET/CT scan was performed every 6 months and as the patient is now disease free for four years we decided to put him again on a kidney transplant waiting list. Despite poor prognosis that was attributed in the past to patients with adrenocortical carcinoma, contemporary series suggest that these patients are living longer; especially patients who present with early stage and have complete primary resection. To best of our knowledge, this is first case of a transplanted patient developing an adrenocortical carcinoma reported in the literature. GADOLINIUM Methods: Patients that were at least 6 months post surgery who underwent laparoscopic donor nephrectomy from 2008 to 2011 were surveyed. Anonymous, validated pain assessment questionnaires (sf-BPI, EQ-5D and s-LANSS) were sent out asking patients whether they'd experienced any chronic pain following their operation, these were used to quantify pain severity, type of pain and how it was managed. Results: A total of 49 patients were identified as having undergone laparoscopic nephrectomy. Thirty-two of these responded but only 29 met the criteria to be entered in to our study. 16.7% reported to having chronic pain following the procedure with 7.9% of the group stating that they had pain affecting daily living. Of these only 3.7% of patients were classified as having neuropathic pain. When compared to previous open-nephrectomy studies no patients in our cohort reported having extreme pain. The incidence of chronic pain following open donor nephrectomy was found to be 26% and there was no significant difference compared to laparoscopic-assisted surgery (Fishers exact test p = 0.3654). Conclusion: We have previously found the incidence of chronic pain after open nephrectomy was higher than often quoted, though pain can be influenced by bio-socio-economic factors. We have studied the same sociodemographic population and found laparoscopic-assisted kidney donation to be associated with lower incidence of chronic pain markers following open nephrectomy however this did not reach statistical significance. Tarek Background: Generic tacrolimus [with Prograf â -Astellas (P) as the brand drug], seems to of provide reduction with comparable efficacy, as reported in literature. We present results with generic tacrolimus formulation [Tacni â -Teva (T)] in KT in our Center. Material and Methods: We compared 33 patients de novo treated with T and 67 P treated in case-control study, evaluating donors/recipients/KT characteristics, adverse events (AE), tacrolimus blood levels (TBL -HPLC assay) and doses in short (during hospitalization) and medium (at least 3 months) follow-up. Results: Donor age was greater in T patients (T 64 years-P 56 years; p = 0.003). Comparable parameters are: percentage target TBL, time to reach target levels in short-term follow-up, percentage acute rejections and percentage drop-out in medium-term follow-up. For a target TBL 12-15 ng/ml in the first month and for the daily same dose, we found initially in T lower TBL (T 12 ng/ml-P 13.2, p < 0.001). After 3 months no difference for doses or TBL were reported. Recently, it is demonstrated the new avenue in the management of ABOincompatible kidney transplantation by introducing an anti-CD20 monoclonal antibody, rituximab. Using rituximab, we have reported successful ABOincompatible renal transplantations without splenectomy as well as with high anti-A/B antibody titer in pre-transplant status. However, occasional episodes of late-onset neutropenia (LON) also have been reported during the administration of rituximab. Methods: Twenty-five patients underwent ABO-incompatible kidney transplantation with rituximab induction at Osaka City University Hospital. In our institution, rituximab (150 mg/m 2 ) was administered twice at 2 weeks prior to and on the day of transplantation except for elderly recipients. The recipients aged 65 years and older received consisting of only a single dose of rituximab 150 mg/m 2 at 2 weeks prior to the transplantation. The patients with high anti-A/B antibody titers (¡ Y1:512) received splenectomy and administration of two doses of rituximab. Results: Fourteen patients received two doses of rituximab administration and three elderly patients received single dose of rituximab without splenectomy. Eight with high titer received both two doses of rituximab and splenectomy. Twelve recipients experienced LON 3-12 months after transplantation. The primary causes of netropenia, such as viral and/or bacterial infection did not occur. Other drugs which could induce myelosuppression were not given to these patients. After administration of granulocyte colony stimulateing factor, neutropenia improved. Conclusion: In our study, 48% of the recipients using rituximab experienced LON. Our desensitization protocol may induce over-immunosuppression. The effort to estimate the lowest effective dose of rituximab for transplant recipients is necessary. retrospective study was conducted on two groups of patients: Group A undergo Double-J stent and group B no-stent ureterovesical anastomosis. We reviewed the urological complications: fistula, ureteral obstruction, urinary leakage and urinary tract infection. The patients were scheduled for stent removal after 2 weeks. Results: A total of 30 patients were randomized to a stent (15) and a no-stent (15) group. Group A: No ureteral obstruction and urinary leakage were developed in this group. Three patients (20%) had a positive urinary culture. Group B: Two patients (13%) developed ureteral obstruction and another four (26.7%) developed urinary leakage. Four patients (26.7%) had a positive urinary culture. Conclusion: The routine insertion of a double J stent in kidney transplants reduces the number of early complications urinary fistula and ureteral obstructions. Using a ureteral stent at renal transplantation significantly decreases the early urinary complications of urine leakage and obstruction. However, stent removal within 4 weeks of insertion appears advisable. Background: Aquaporins (AQP) are proteins that are responsible for the water permeability in cell membrane. Especially, AQP2 which mainly distributed in renal principle cells is related to water reabsorption in collecting duct under the control of arginine vasopressin (AVP). AVP level abnormally increases in chronic kidney disease (CKD) patients, but its mechanism has not been clear and studies on kidney transplant patients have rarely been reported. This report allows us to assess the changes in AVP and urine AQP2 (uAQP2) expression in kidney transplant patients. Method and Material: We enrolled 14 kidney transplant patients prospectively. We measured the serum AVP, serum osmolality, urine osmolality and urine AQP2 expression by western blot method before and until serum creatinine is normaized after transplantation. Result: The average age of the overall patients was 43.1 ¡¾ 13.7 years (range: 22-62 years) and the male to female ratio of the patients was 2.5:1. The frequency of patients with diabetes was 14.3%. Dialysis duration of pretransplant period was 78.2 ¡¾ 63.3 months (range: 2-180 months). Pretransplant AVP was elevated (21.42 ¡¾ 5.03 pg/ml), and the level was normalized (3.76 ¡¾ 0.6 pg/ml) relatively to sCr level after the transplantation. Contrary to the expectations, however, the pre-transplant uAQP2 expression was 5.63 and post transplant uAQP2 expression was elevated to 15.73. Posttransplant uAQP2 expression was significantly higher than pre-transplantation (p = 0.021). However, uAQP2 didnot significantly correlated with plasma AVP, serum creatinine, serum sodium, serum potassium, FENa, serum and urine osmolarity including urine volume. Abstracts of the Proteinuria, more than 300 mg/day, were observed more in EVR group (69%) than in MMF group (27%) respectively. There were two patients whose proteinuria developed over 2 g/day at 12 months or later in EVR group. We could not find any particular glomerular lesion in the graft biopsies, however neovascular hyalinosis at glomerular vascular pole was noticeable. The significant proteinuria in EVR group was successfully treated with angiotensin-II receptor blockade. Background: Post-transplant diabetes mellitus (PTDM) is a common and serious metabolic complication. Genetic polymorphisms of angiotensin-converting enzyme (ACE) and angiotensinogen (AGT) genes have been reported to be related to diabetes mellitus and insulin sensitivity; however, the role of these genes in the development of PTDM is not known. For this purpose, we investigated the association of ACE and AGT genetic polymorphisms with PTDM. Methods: A total of 302 subjects without previously diagnosed diabetes who had received kidney transplants were included. One ACE single nucleotide polymorphism (SNP; rs4291) and two AGT SNPs (rs 699 and rs 4762) were genotyped from genomic DNA with direct sequencing. Results: PTDM developed in 49 (16.2%) of 302 subjects. Subjects in the PTDM were older than those in the non-PTDM. There was a significant difference between the two groups in tacrolimus use (p = 0.03). Of the three SNPs, the rs4762 of the AGT gene was significantly associated with the development of PTDM in the dominant models (p = 0.03) after adjusting for age and tacrolimus usage. The function and protein structure of AGT was significantly affected by the Thr207Met missense SNP (rs4762). Background: Thrombotic Microangiopathy (TMA) is characterized by endothelial cells injury and formation of fibrin thrombi within capillary-arterioles. TMA mainly presents in renal allograft recipients as Hemolytic Uremic Syndrome (HUS), a rare and life-threatening condition, which requires early diagnosis and treatment. Drug toxicity, in particular from Calcineurin Inhibitors (CNIs) and mTORi, is TMA's most common cause after transplantation. The aim of the study was to investigate the role of mTORi as an added risk factor in the development of TMA, in order to develop strategies for modulation of the immunosuppressive therapy. Materials and Methods: From a database of 496 renal graft recipients we analyzed 350 renal graft biopsies performed at our Center from 1998 to 2012. Histological features of TMA were found in 36 patients (prevalence of 7.3%). We divided the cases in two groups: not drug-related TMA (n 19) and drugrelated TMA (n 17). In patients exposed to mTORi (alone or combined to CNIs) we measured mean immunosuppressants levels comparing TMA and TMA free groups Results: The prevalence of TMA in patients exposed to mTORi in our study was greater (5.3%) than exposed to other therapy (2.8%), but not statistically significant. However drugs blood levels resulted significantly higher in patients with TMA Discussion: The frequent lack of TMA systemic signs underscores the importance of graft biopsy in the differential diagnosis between TMA, rejection and viral infection. Our results confirm the pivotal role of immunosuppressive drugs in the onset of de novo TMA. Endothelial damage by CNI, followed by Everolimus induced delayed repair of endothelial injury, seem to predispose patients to post-transplantation HUS, with higher drugs levels relating to higher risk of TMA. Thus combined monitoring of these drugs may be used to prevent TMA. Our results suggest to keep blood levels of Everolimus TLC + (Cyclosporine 2nd hour/100) under a cut off of 11 AE 2 ng/ml. Background: Kidney biopsy (KB) is the gold standard for diagnostic information after kidney transplantation. Nevertheless, KB is associated with risk of bleeding complications (BCs). Bleeding time (BT) is an established predictor of BCs. The aim of our prospective study was to evaluate the association of platelet function analyzer (PFA-100) with BT in predicting the risk of BCs. Material and Methods: One hundred and nineteen transplanted patients undergoing KB were screened for PFA-100, BT, PT/PTT, Hb, PLT count, GFR and blood pressure. Our protocol is designed to perform KB with a BT≤ 8 min regardless of PFA-100 values, with BT>8 min in presence of normal PFA-100, with BT>8 min and abnormal PFA-100 desmopressin is administrated prior KB. Results: PFA-100 was abnormal in 56/119 pts. BT>8 min in 9/119 pts with 1 having abnormal PFA-100. 9/119 pts developed BCs. 2/9 pts with BCs displayed BT ≤8 min and abnormal PFA-100. 1/9 with BCs had BT>8 min and normal PFA-100. No correlation between PFA-100 and BT was observed. No significant differences in any clinical and hematological parameters and in the number of biopsy passes were observed regardless of BCs. When native nephrectomy is scheduled in potential kidney recipients, it is still not clear whether the operation should be performed before, after or during the transplantation the aim of the study is to evaluate the results of the patients who have undergone kidney transplantation concurrent with bilateral or unilateral native nephrectomy. The data of 1980 patients with end-stage renal disease who had undergone renal transplantation between June 2000 and December 2009 in the Organ Transplantation Institute at Akdeniz University were evaluated. We evaluated the outcome of kidney transplant patients who have undergone native nephrectomy unilaterally (n = 38) and bilaterally (125). Graft survivals at 1st, 3rd and 5th years were 93%, 90% and 89%, patient survival in the 1st, 3rd and 5th years were 97%, 94% and 94%, respectively. Surgical complications were significantly more frequent in nephrectomy patients due to higher complication rate in the polycystic kidney disease subgroup of nephrectomized patients. Despite additional surgery, the long term results of patients with complications were not affected negatively due to the early diagnosis and treatment. We believe that, native nephrectomy concurrent with transplantation can be performed when indicated in selected patients at experienced centers with large patient volume and with well-complication management. plantations were performed at our institution. Criteria for NHBD selection were established by the Agence de la Biom edecine. We used normothermic recirculation (NRC) over double-lumen catheter (DLC) perfusion prior to procurement whenever possible. Kidneys were preserved using the Lifeport â perfusion machine and transplanted within the shortest possible timeframe. Results: NRC was used in 33 and DLC in 20 cases. We did not observe any case of PNF. DGF occurred in 63.5% of all NHBD transplantations, and 21% on HBD transplantations (p < 0.0001). There was no difference in the number of dialysis treatments in case of DGF (4.7 AE 2.4 in NHBD, 3.7 AE 3.6 in HBD, p = 0.14). Graft survival Kaplan-Meier analysis showed a negative effect of DGF in HBD transplantations (p = 0.03), however there was no negative impact on graft survival analysis in the NHBD group (p = 0.67). Graft survival was identical when comparing NHBD grafts and standard-criteria HBD grafts, however NHBD graft survival was significantly better than extended-criteria HBD graft survival Conclusion: Our results indicate that NHBD grafts can be utilised with comparable results to those of HBD-SC grafts, and better results than HBD-EC grafts. Whereas DGF is a know negative factor in HBD transplantation, its impact in NHBD transplantation is negligible. Background: The transition between paediatric and adult care is a crucial time in the management of young adults with ESRD. As many as 35% of adolescent transplant recipients suffer graft loss within 3 years of transfer to adult care, which increases the strain on an already resource limited transplantation service as well as causing significant morbidity. In this retrospective study we investigated the outcomes of transition patients in the west of Scotland, and explored the reasons behind the high rates of graft failure. Methods: Data was retrospectively analysed from patients aged under 25 who underwent renal transplantation at either a dedicated paediatric unit or at an adult unit in the west of Scotland between 2001 and 2010. Graft failure rates at one year and five years were compared with the corresponding adult population, between patients who transitioned to adult care before and after transplantation, and between previously reported rates. Results: An overall graft failure rate of 8% after one year and of 21% after 5 years (n = 90) was seen in patients transplanted aged under 25, which is lower than that reported in the current literature for this age range. No significant difference in failure rates was seen between those who transitioned to adult care before or after transplantation, however, the failure rate in young adults (16-25) was double that of children aged 15 and under, at 22% compared with 11% (p < 0.05) Conclusion: Transition to adult care generally takes place during the 16-25 years age group and the higher rate of failure seen in this group is likely a result of patient non-adherence during this challenging period. It has been shown elsewhere that a fully integrated transition service can significantly improve compliance rates and reduce these high rates of graft loss in young adults. Improving this transition period nationwide is key to increasing the rates of long-term graft survival and lowering morbidity in young adult transplant recipients. In recent years, incidence of BK virus infection in the kidney transplant population is on rise. BK virus is a human polyomavirus which is a member of the Papovaviridae family. Polyomaviruses are ubiquitous in nature and were first isolated 1971 from the urine of a renal transplant patient who developed ureteral stenosis post-operatively. BK virus is known to cause severe renal dysfunction, ureteral stenosis, and hemorrhagic cystitis in renal transplant patients. The incidence of ureteral stenosis due to BK virus infection among allograft recipients is approximately three percent, although stenosis has been traditionally attributed to causes other than BK virus infection. In this report, we describe a case of the patient presenting with hydronephrosis due to BK virus-induced ureteral stricture after renal transplantation who successfully treated by partial ureterectomy and re-ureteroneocystostomy. A 44-year-old man who had undergone a second renal transplantation. Graft nephrectomy for the first renal transplantation was performed due to renal artery thrombosis and the patient underwent a kidney re-transplantation 1 year later graft nephrectomy. The 17 months postoperatively, he was diagnosed to have hydronephroureterosis attributable to BK virusinduced ureteral stricture. The diagnosis was made virologically by BK virus PCR detection. He successfully underwent partial ureterectomy and re-ureteroneocystostomy. He was discharged with normal kidney functions. The patient is maintaining satisfactory graft function 31 months after surgery without clinical and serological evidence of recurrent BK virus infection. Background: Brain dead patients are referred for organ donation at variable periods of time. The best physiologic management should be instituted for optimum organ viability. This paper aim to identify critical points in pre-recovery management that has impact on the outcome of organs transplanted. Method/Materials: Critical timelines and physiologic events prior to recovery were reviewed. The outcome on 41 kidney recipients from 21 donors from Quirino Memorial Medical Center, Philippines were folllowed up for 6 months to 3 years. Results: Donor age range from 18 to 49 years (mean -33 years). Recipient age range from 24 to 78 years (mean -50 years). The interval between head injury to brain death (10-93 h, mean -34 h) and from declaration to actual retrieval (6-17 h, mean -15 h) vary, but the physiological state of these 21 patients were maintained. Donor creatinine ranged from 37.9 to 187.38 mmol/l (mean -97.52) Three had transient cardiac arrest. Organs were transplanted at mean time of 12 h from brain death. Cold storage time ranged from 2 ½ hours to 25 h 50 min (mean -9 h). Twenty eight patients had at least 1DR (68%); one had a fullmatch and the rest had either 0DR or no ABDR match at all. They received induction therapy (ATG -32, Basiliximab -9), Calcineurin Inhibitor (FK506 -40, CyA -1), mycophenolate and steroids. Forty recipients had good graft function at 1 month. Five of them (12%) initially required 2-4 hemodialysis sessions (4-ATN, 1-AR). One patient never recovered (CIT-16 h) and died of pulmonary embolism in one month. One month, 6 months, 1-year, and 2-years patient and graft survival are 97.6%, 92.68%, 90%, 89.4%, respectively. All three recipients transplanted 3 years ago still have excellent function. Background: Antibody against donor is a barrier to successful kidney transplantation. Flowcytometry crossmatch (FCXM) is a useful method for detection and monitoring of anti-donor antibody; preoperatively, after desensitization, and after transplantation. Methods: From Dec 2008 to Feb 2013 we had performed 99 cases of FCXM positive KT. Rituximab (500 mg), plasmapheresis (PP), and early use immunosuppressant based preconditioning was used. Among them five patients were CDC crossmatch positive patients. Target MFI ratio after desensitization was less than 2.0 (less than 77 as MCS: mean channel shift). Results: FCXM positive KT accounts for approximately 15% of all living donor kidney transplantation in this center. In this cohort, Female was 65% (n = 64). Forty patients were high PRA (>50% by Luminex) including 10 re-transplantation. Mean recipient age was 45.4 year old (AE11.9). Mean baseline MFI ratio was 5.6 AE 5.6 [Median 3.55 (2.0-32.7)]. After desensitization pre operative MFI ratio was 1.50 AE 0.51, and postoperative MFI ratio was 1.86 AE 0.99. Nine patients dose not reached target MFI ratio after desensitization. Out of 36 patients in whom MFI ratio was elevated (2.0) after transplantation, only four patients showed clinical renal dysfunction. During 635 days (AE 420) of follow up period, six cases of early AMR, one case of mixed AMR/ACR, and three cases of ACR developed. All the rejection were responsive to anti rejection treatment especially PP & IVIG in AMR. Living kidney donation may increase the risk of cardiovascular diseases. It seems justified to identify cardiovascular risk factors and cardiological disorders (CD) prior to the kidney donation. Aim: To determine the cardiological status of persons qualified as a living kidney donor. Material and methods: We analyzed data of 109 potential living kidney donor, aged 25-70 years. They underwent clinical examination and lipid profile. The presence of risk factors of CD as hypercholesterolemia, diabetes mellitus, hypertension, obesity and smoking and any cardiological problems were registered. Results: Among 109 persons, 48 (44%) were qualified for living kidney donation. As many as 40 of them has have ¡ Y1 risk factors of CD (mild dislipidaemia, overweight, smoking, hypertension). In 1 pt we diagnosed preexcitation syndrome. The patient was treated successfully (ablation) and became a donor. In another person renal artery stenosis as the reason of hypertension was diagnosed. After nefrectomy renal artery angioplasty was performed and kidney was transplanted for his son. A normal function of the graft in the recipient and normalization of the donor's blood pressure was observed. 63 (56%) person were disqualified. In 15 (23.8%) person the reasons were cardiological. In 1 pt it was the abdominal aneurysm (AA) treated earlier with stentgraft, another person remain under observation due to AA. Both men smoked and have severe dyslipidaemias. In 3rd patient we observed atrial fibrillation and two risk factors of CD. The next 2 men have had the peripheral occlusive arterial disease. In 9 pts we have found ¡ Y2 risk factors and in the last one morbid obesity was present. Nobody has diabetes mellitus. Monoclonal gammopathies are rare cause of end-stage renal disease (ESRD). MGUS is asymptomatic premalignant single-clone plasma cell proliferation, resulting in secretion of excessive homogeneous monoclonal light/heavy or light chains only. Abnormal protein is deposited in all renal structures resulting in their damage. Male aged 57, with ESRD due to MGUS, underwent a preemptive living related donor kidney transplantation. Maintenance immunosuppression consisted of tacrolimus, mycofenolate mofetil, and steroids. The first post-transplant 18 months were free of proteinuria, with good kidney function, thereafter the patient started to have proteinuria. Graft biopsy revealed no signs of cellular rejection, a suspicion of transplant glomerulopathy, recurrence of MGUS related glomerulopathy, and IF/TA grade I. On FREELITE test kappa/ lambda serum and urine ratio were 3.6 (reference ranges: 0.4-3.1) and 147 (reference ranges: 2-10.4), respectively. Bone marrow biopsy was negative and diagnosis of recurrent monoclonal glomerulopathy was established. In order to treat MGUS and halt progression of glomerulopathy the administration of bortezomib/dexamethasone is now considered. Anemia is more prevalent in renal transplant recipients than in GFR-matched CKD patients. Hepcidin is a small defensin-like peptide whose production by hepatocytes is modulated in response to anemia, hypoxia or inflammation. Growth differentiation factor 15 (GDF-15) was recently identified as a hepcidinsuppression factor that is expressed at high levels in patients with ineffective erythropoiesis. The aim of the study was to assess GDF-15 levels with relation to iron parameters in 62 stable kidney allograft recipients maintained on triple immunosuppressive therapy. Methods: Complete blood count, urea, creatinine, and iron status were assessed by standard methods. We measured GDF-15, hepcidin, hemojuvelin, IL-6 and NGAL with commercially available assays. Results: Mean levels of GDF-15, NGAL, hepcidin and hemojuvelin were significantly higher in kidney allograft recipients when compared to the control group (p < 0.001 for all). GDF 15 was significantly higher in patients with anemia according to WHO definition when compared to non-anemic counterparts (p < 0.05). GDF 15 levels were not dependent on the type of immunosuppressive therapy. In univariate analysis GDF-15 was related to kidney function (creatinine r = 0.39, p < 0.01, eGFR by MDRD r = À0.37, p < 0.01), urea (r = 0.39, p < 0.01), uric acid (r = 0.42, p < 0.01), hepcidin (r = À0.32, p < 0.01), IL-6 (r = 0.28, p < 0.05), hemoglobin (r = À0.32, p < 0.05), and NGAL (r = À0.35, p < 0.01). GDF-15 was not related to serum iron, or ferritin. In multivariate analysis, hepcidin was found to be a predictor of GDF-15 (beta value 0.32, p = 0.03) explaining 38% of the variation in GDF15 levels. In conclusion, our preliminary data may suggest possible mutual relations between GDF 15 and hepcidin in patients with kidney disease and that GDF15 might be involved in the pathogenesis of anemia in kidney allograft recipients. However, the role of inflammation should be also elucidated. A CASE CONTROL STUDY OF FACTORS ASSOCIATED WITH DELAYED GRAFT FUNCTION IN FILIPINO KIDNEY TRANSPLANT PATIENTS study focused on delayed graft function (DGF) as a determinant of long-term kidney graft function. We assessed if duration of pre-transplant dialysis, sex match between donor and recipient, and total ischemia time were risk factors for DGF among Filipino patients after renal transplantation. Methods: Hospital charts of 77 Filipino patients who underwent kidney transplantation from living donors between 2007 and 2009 were reviewed. Fifty two (52/77) were selected as subjects based on data availability on recipient age, gender, and the transplant variables of interest. DGF was defined as serum creatinine of ≥2 mg/dl on the third day post-transplantation. Twenty six cases were age-matched (AE5 years) with 26 controls. Results: Mean age for both cases and controls were 46 AE 10 years. There were more males than females among cases (80.8%) than among controls (50%). No significant difference was noted between cases and controls for duration of pre-transplant dialysis and total ischemia time, while significant difference was noted for sex matching between graft donor and recipient (p = 0.0309). An inverse association was noted for the category "male donor to female recipient" (OR=0.13; 95% CI 0.02-0.84; using same-sex match as reference), suggesting that the factor was favorable. Conclusion: Duration of pre-transplant dialysis of up to 2500 days and total ischemia time of up to 130 min may not increase the risk for DGF. Being a female recipient of a graft from a male donor may be a favorable factor, although further studies are recommended. The results support previous studies on the gender disparities among transplant patients and the role of donor-recipient gender considerations in preventing DGF. Furthermore, an analysis on the long-term outcomes of these cases is warranted. Introduction: All living organisms have evolved sophisticated mechanisms to maintain appropriate iron levels in their cells and within their body. Recently our understanding of iron metabolism has dramatically increased. Overt LPI (Labile Plasma Iron) represents a component of non-transferrin bound iron-NTBI that is both redox active and chelatable, capable of permeating into organs and inducing tissue iron overload. LPI measures the iron-specific capacity of a given sample to produce reactive oxygen species. We studied for the first time NTBI correlations with markers of iron status, and inflammation in prevalent hemodialyzed patients and kidney transplant recipient. Methods: Complete blood count, urea, serum lipids, fasting glucose, creatinine, ferritin, serum iron, TIBC were studied by standard laboratory method in the hospital central laboratory. NTBI was assessed by FeROS¢â eLPI kit (florescence-based assay intended for the in vitro semi-quantitative detection of both over and cryptic redox active forms of NTBI) by Aferrix Ltd in Tel Aviv, Israel. A test result of 0.6 units of LPI or more indicates a potential for ironmediated production of reactive oxygen species in the sample. Results: Patients with LPI units ¡Ã 0.6 had higher serum iron, ESA dose, ferritin, hsCRP. In hemodialyzed NTBI correlated with hsCRP, ferritin. In kidney transplant recipients NTBI was correlated with TIBC, ferritin, and tended to correlate with CRP. Patients with LPI units ¡Ã 0.6 had higher serum iron (p < 0.05), TIBC (p < 0.05), ferritin (p < 0.001) and MCV. Very high ferritin together with high NTBI were found in patients undergoing multiple transfusion before and/or after transplantation. HD patients had higher NTBI when Conclusions: Elevated NTBI as well as ferritin levels, in kidney transplant patients and dialyzed patients may be due to disturbed iron metabolism, since human body have no possibility to remove iron excess. NTBI could be responsible for excessive synthesis of reactive oxygen species, therefore it may be linked to complications due this phenomenon, such as atherosclerosis, frequently encountered in this population. Results: The prevalence of decoy cells was 5% (3 /60), viruria 15% (9 /60), virema 5% (3 /60). BKVAN prevalence rate was 1.6% (1/60). In patinets with BK viremia, after reduction of immunosupresion (mycophenolate mofetil <1 g/day, tacrolimus level <6 ng/ml) and fluoroquinolone therapy, graft function was stabilized and urine cytology for decoy cells became negative. In the patient with BKVAN, graft function progressively deteoriate and graft loss occur in 16th month after transplantation. Conclusion: Screening for BKV viremia and preemptive therapy prevented development of BKVN and allograft dysfunction. Objectives and Aims: Cardiovascular diseases (CVD) is the main cause of morbidity and mortality in renal transplant recipients (RTR). The reninangiotensin-system (RAS) is considered that regulates blood-pressure (BP) and also independent risk factor for left ventricular mass-index (LVMI) and carotid-intima-media-thickness (CIMT). The RAS blockage have provided evidence for the presence of BP independent renoprotective and cardioprotective effects. Recently, it has been reported that urinary-ang yotensinogen levels provide a spesific index of the intrarenal RAS status (index of the locally RAS) was significantly correlated with blood-pressure and proteinuria. The aim of this study was to evaluate the relationship of local intrarenal RAS with LVH and CIMT in hypertensive RTR. Results: Ninety-six nondiabetic RTR (52 male 52.4 AE 18.6 years, 44 female 49.6 AE 16.6 years) were included in this study. All patients were in stable condition with GFR greater than 30 ml/min/1.73 m 2 ). Spot urine samples were obtained to measure urinary angiotensinogen (UAGT) and urinary creatinine (UCre). And also LVMI and CIMT were measured. UAGT/UCre was significantly higher in hypertensive patients compared with normotensivies (12.64 AE 9.36 lg/g vs. 6.64 AE 4.24 lg/g, p < 0.01). LVMI and CIMT were significantly higher in hypertensive patients compared with normotensivies (LVMI; 132.12 AE 32.08 g/m 2 vs. 96.64 AE 9.12 g/m 2 ; p < 0.001 and CIMT; 0.92 AE 0.22 mm vs. 0.72 AE 0.16 mm; p < 0.01). Importantly, significant positive correlation was found between UAGT/UCre levels and LVMI (r = 0.724, p = 0.012) and also CIMT (r = 0.452, p = 0.02) in hypertensive RTR. Conclusions: These data indicate that UAGT is increased in hypertensive renal RTR and local RAS probably plays a important role in the development of cardiovascular abnormalities in hypertensive RTR. Background: Intimal dissection of external iliac artery is a known complication of renal transplant recipient surgery. We report our experience in five cases of living donor renal allograft recipients with the use of PTFE interposition graft of the external iliac artery with simultaneous anastomosis of renal vessels to the graft. Methods: During our 25 year experience of over 3000 renal transplants we encountered five cases of progressive intimal dissection of external iliac artery which was jeopardising the lower limb perfusion. In all the five cases we found badly damaged intima not amenable to repair. Hence PTFE interposition graft was used and renal artery anastomosed to the graft end to side. Results: All the patients had stabilized normal graft function after the surgery with no surgical complication. Conclusion: It is a safe salvage procedure to save the lower limb and the graft kidney by using PTFE interposition graft following an intimal dissection. Methods: Eighty eight renal transplants carried out between March 2011 and February 2012 underwent routine post-transplant duplex scanning. The duplex scan velocities of renal artery were graded into Grade 0 (velocities-1-200 cm/ s), Grade 1(201-400 cm/s), Grade 2(401-600 cm/s) and Grade 3 (>600 cm/s) with grade 0 as normal. All the other grades were marked as renal artery stenosis (RAS). The serial duplex scans were followed till graft dysfunction or intervention. Medcalc 18.1 was used for statistical analysis. Non Parametric Correlation was derived with Spearmann Rho test. Parametric data was analysed using Mann-Whitney test. Univariate and multivariate analysis were done with significance levels set at <0.05. Results: Retrospective analysis showed that sixty (68%) were males, 28 (32%) were females. N = 220 duplex scans were done, Grade 0-175, Grade 1-37, Grade 2-06, Grade 3-02. RAS reported were not associated with graft dysfunction during the first 6 months but RAS persistent for 24 weeks and beyond correlated to worsening graft function (p = 0.2). None of the grafts were lost due to reported RAS. Recipient diabetes (p = 0.4), hypertension (spearman rank correlation) and absence of aortic patch on the renal artery (p = 0.3) were not associated with development of RAS. Per-operative atherosclerosis was significantly related to RAS at 4 weeks (p = .002). The overall allograft success rate at Liverpool was comparable to previous years. Conclusion: Probably because of the sensitive ultrasound technology and increasing experience of radiologist, there was reported increased incidence of RAS which was not significant in the first six months. Bigger sample size is required to prove the statistical significance and the study carries on prospectively. Objectives: The elevation of serum fibroblast growth factor-23(FGF-23) is a common feature in chronic kidney disease (CKD). FGF-23 levels decrease dramatically after renal transplatation, but were still above normal. Cardiovascular diseases that is the main cause of morbidity and mortality in renal transplant recipients. Several near recent studies have demonstrated that elevated FGF-23 may be also involved in the left ventricular hyperthrophy onset. In CKD patients, FGF-23 levels were significantly correlated with higher mean left ventricular mass index (LVMI). The aim of this study was to evaluate the relationship of FGF-23 with LVMI and CIMT in renal transplant recipients (RTR). Results: Sixty-four RTR (38 male 48.4 b16.6 years 26 female 46.6 b12.4 years) were included in this study. All patients were in stable condition with GFR greater than 30 ml/min/1.73 m 2 , mean GFR; 36 ml/min/1.73 m2. Plasma FGF-23 levels were measured using a C-terminal human ELISA. And also LVMI and CIMT were measured. Plasma FGF-23 levels were significantly higher in renal transplant recipients compared with control group (72.36 b32.16 RU/ml vs. 36.18 b16.12 RU/ml). LVMI and CIMT were also significantly higher in RTR compared with the controls (LVMI; 112.12 b 28.08 g/m 2 vs. 92.64, b8.24 g/m 2 ; p < 0.001 and CIMT; 0.86 b0.24 mm vs. 0.70 b0.18 mm; p < 0.01). Importantly, a significant positive correlation was found between FGF-23 levels and LVMI (r = 0.642, p = 0.016) and also CIMT (r = 0.542, p = 0.024) in renal transplant recipients. Conclusions: These data indicate that FGF-23 is higher in renal transplant recipients and elevated FGF-23 levels probably plays a important role in the development of cardiovascular abnormalities in renal transplant recipients. We report on a 45-year old man who developed teratoma and carcinoid tumor in the lung after kidney transplantation. He has end stage renal failure secondary to amyloidosis. He received kidney from his brother two years ago. Immunosuppression protocol was Tacrolimus, MMF and prednisolon. Posttransplant creatinine levels were between 1.3 and 1.5 mg/dl. He admitted with fever and graft disfunction in posttransplant 13th months. Banf1A cellular rejection, tacrolimus toxicity and BK virus nephropathy were determined in graft biopsy. Pulse steroid treatment was administered. Then immunosuppressive drug doses were decreased. Polypoid mass lesion at anterior segment of upper lobe of right lung was seen in Thorax CT. Then this lesion was removed via surgical operation. Pathologic findings was showing microscopic carcinoid tumor arising mature cystic teratoma. Beta HCG, AFP and LDH levels were normal. The patient was considered by oncologist who proposed PET CT imaging after 3 months. Teratoma is an tumor with tissue or organ components resembling normal derivates of all three germ layers. Carcinoid tumor is a slowgrowing type of neuroendocrine tumor. Carcinoid tumors can found in the lungs. After kidney transplantation, teratoma and carcinoid tumor is not seen commonly. There is no any case together carcinoid tumor and teratoma after kidney transplantation. Introduction: Reluctance to perform kidney transplants on children is an ongoing problem in Turkey. Moreover, urological pathologies still constitute the largest portion of the underlying etiologies in chronic renal failure patients. Here, we retrospectively analyzed the data acquired from our pediatric renal transplant patients and reviewed the registry of dialysis and transplantation data prepared by Turkish Society of Nephrology. Material and Methods: Fifty live donor kidney transplantations were performed in children between 2008 and March 2013. Eighteen of the 50 (38%) transplants were preemptive. The mean age at operation time was 10.8 AE 5 years. The mean patient weight was 31.3 AE 15.8 kg (Range 9.4 kg to 66.4 kg). A detailed urologic evaluation was performed in every child with an underlying lower urinary tract disease. One enterocystoplasty and two ureterocystoplasties were performed for augmentation of the bladder, simultaneously. Results: One-year death-censored graft survival and patient survival rates were 100% and 97.8%, respectively. Mean serum creatinine level was 0.8 AE 0.32 mg/dl (Range: 0.3-1.8 mg/dl). None of the patients had vascular complications or acute tubular necrosis. One patient suffered graft versus host disease at second month after renal transplantation and died with a functioning graft. In one patient with massive proteinuria detected after transplantation, recurrence of primary disease (Focal segmental glomerulosclerosis) was considered and the patient was treated successfully with plasmapheresis. One child had an acute cellular rejection and treated with pulse steroid treatment. Conclusion: While challenging, all patients in all pediatric age groups can successfully be operated and managed with a careful surgical technique and close postoperative follow-up and efforts by the experienced and respectful surgical teams in this country could change the negative trends to perform kidney transplantation in Turkish pediatric population. Background: The elevation of serum fibroblast growth factor-23 (FGF-23) is a common feature in chronic kidney disease (CKD). FGF-23 levels decrease dramatically after renal transplatation, but were still above normal. In CKD patients, FGF-23 levels were significantly correlated with inflammation, endothelial dyfunction and cardiovascular disease. Inflammation and endothelial dysfunction play a key role in the pathogenesis of atherosclerosis. Materials and Methods: The aim of this study was to evaluate the relationship of FGF-23 with inflammation (hs-CRP) and endothelial dysfunction in renal transplant recipients. Sixty-four renal transplant recipients (38 male 48.4 b16.6 years, 26 female 46.6 b12.4 years) were included in this study. All patients were in stable condition with GFR greater than 30 ml/min/1.73 m 2 , mean GFR; 36 ml/min/1.73 m 2 . Plasma FGF-23 levels were measured using a C-terminal human ELISA. And also we have examined the plasma levels of the PAI-1 and hs-CRP. Results: Plasma FGF-23 levels were significantly higher in renal transplant recipients compared with control group (72.36 b32.16 RU/ml vs. 36.18 b16.12 RU/ml). Plasma PAI-1 and hs-CRP levels were also significantly higher in renal transplant recipients compared with the controls (PAI-1; 32.4 b12.24 IU/ml vs. 12.2, b4.24 IU/ml; p < 0.001 and hs-CRP; 14.23, b9.6 mg/l vs. 3.80, b0.78 mg/ l; p < 0.01). Importantly, a significant possitive correlation was found between FGF-23 levels and plasma PAI-1 (r = 0.720, p = 0.022) and also hs-CRP (r = 0.486, p = 0.024) in renal transplant recipients. Conclusion: These data indicate that FGF-23 is higher in renal transplant recipients and elevated FGF-23 levels probably plays a important role in the development of endothelial dysfunction and cardiovascular abnormalities in renal transplant recipients. Abstracts of the Background: The renin-angiotensin-system (RAS) is considered that regulates blood pressure and also play a key role inflammation and endothelial dysfunction. Locally produced RAS in most tissues have been recently. The RAS blockage have provided evidence for the presence of blood pressure independent renoprotective and cardioprotective effects of RAS blockers. Therefore, assessment of locally RAS activation is essential to investigate the pathophysiological mechanisms of hypertension and cardiovascular disease Materials and Methods: Recently, it has been reported that urinary ang yotensinogen levels provide a spesific index of the intrarenal RAS status was significantly correlated with blood pressure and proteinuria. The aim of this study was to evaluate the relationship of local intrarenal RAS with inflammation (hs-CRP) and endothelial dysfunction (PAI-1) in hypertensive renal transplant recipients (RTR Background: Cold ischemia time (CIT) is a modifiable factor associated to poorer renal allograft outcomes. The present analysis aimed to compare the conventional approach of convoking the transplant candidates just after the final cross-math results (group 1) versus a new strategy of calling up them earlier, based on the absence of anti-HLA antibodies (group 2) and sough the effects on CIT, delayed graft function (DGF) and in-hospital staying. Methods: Two hundred consecutive first single non zero-mismatch kidney transplants performed between 02/15/2012 and 07/10/2012 (group 1) was compared to other 200 similar consecutive ones, performed between 07/12/ 2012 and 11/08/2012 (group 2). In both groups, the transplant was performed only after the final cross-match result. Results: Concerning donors, groups were similar according to age (44 vs. 42 years), brain death cause (cerebrovascular in 49% vs. 51%, trauma in 38% vs. 33%, other in 13% vs. 16%), initial serum creatinine (1.1 mg/dl in both groups) and final serum creatinine (1.9 mg/dl vs. 2.1 mg/dl). Concerning receptors, groups were similar according to male sex percentage (63% vs. 58%), age (44 vs. 45 years), time on dialysis (52 vs. 49 months) and sensitization (PRA < 20% in 81% vs. 80%). Calling up the candidates earlier (group 2) led to a significant 4.6 h reduction on CIT (24.4 vs. 19 .8 h, p < 0.001). Additionally, group 2 had a significant 3-day shorter length of inhospital staying (16.3 vs. 12.9 days, p = 0.012). Although there was no difference on the occurrence of DGF (64% vs. 61%), there was a trend on reduction on its length (11.9 vs. 9.1 days, p = 0.07 A7.12 years at time of KT. ESRD was due to neurogenic bladder in 6, posterior urethral valves (PUV) in 5, urethral strictures in 5, urolithiasis in 5, vesicoureteral reflux in 3, and prune-belly syndrome in 1. There were 25 ancillary procedure performed with 5 patients undergoing ¡ Y 2 procedures, either prior to or after KT. Pretransplantation nephrectomy, augmentation ileocystoplasty, fulgeration of PUV, VIU and urethroplasty were done in 16, 4, 5, 4 and 1, respectively. Mean follow-up was 24.96¡ A11.95 months. All patients were alive with functioning grafts at end of last followup. Mean creatinine (mg/ dL) at 3, 6 months, and 1, 2, 3 and 4 years was 0.99, 1.16, 1.14, 1.27, 1.08 and 1.11, respectively. UTI occurred in 4 (16%). Age and UTI significantly affected creatinine at 1 year (p < 0.04 and p < 0.01, respectively). No correlation was found between creatinine at 2 years and any of examined parameters. Conclusions: KT can be safely performed in ESRD patients due to OU and VD with acceptable outcomes. Ancillary procedures may be needed to optimize UT for KT. Only age and UTI significantly impacted creatinine at 1 but not 2 years following KT. Background: Chronic diseases, especially chronic kidney disease are often associated with malnutrition. Malnutrition is a negative prognostic factor influencing the course of every disease and surgery. Aim of this project is to assess the possible relationship between initial nutritional status of patients with end stage renal disease and subsequent renal function of the transplanted graft. Methods: The trial recruited patients after inclusion on the waiting list for a kidney transplant. The nutritional status using biochemical markers, bioimpedance measurements, anthropometry and measurement of muscle strength is assessed initially and periodically. The same observation is followed by one year after renal transplantation. Background: Interferon-c (IFN-c), a cytokine produced by Th1 T-cells, plays an important role in the pathogenesis of acute kidney rejection. IFN-c gene polymorphisms may cause increased or decreased cytokine production. The aim of this study was to examine the association between IFN-c gene polymorphisms and kidney graft function. Methods: The study included 92 kidney transplant recipients, treated by the same immunosuppressive protocol. DNA was isolated from whole blood samples. IFN-c gene polymorphisms 874T/A were detected and analysed using SSP-PCR method. During the first year after transplantation frequency of acute rejection (AR) and delayed graft function (DGF) were recorded. We also followed the allograft function, measured by serum creatinine concentration, creatinine clearance and proteinuria. AR was diagnosed by allograft biopsy, or on the basis of deterioration of allograft function which improved after highdose of corticosteroid treatment. DGF is defined as a need for hemodialysis during the first 2 weeks after transplantation. Results: According to the results obtained for IFN-c gene polymorphism, patients were divided into three groups. The first group included 25 TT genotype patients, the second 42 TA, ant the third 25 AA genotype patients. The groups didn't differ regarding age and gender. Thirty-five acute kidney rejection episodes were evidenced, but there was no significant difference of AR between three groups (40% vs 33.3% vs 44%, p 0.64). Allograft function also didn't differ between groups (p > 0.05). DGF was present in 25 patients, and the number of DGF was very evenly distributed among the groups (28% vs. 28.3% vs. 24%, p 0.95). Conclusion: According to our results, IFN-c gene polymorphism hasn't impact on allograft function, however, we examined small number of patients and it is difficult to conclude whether or not IFN-c gene polymorphisms have a significant impact on early kidney allograft function. Introduction: Anemia, leukopenia and thrombocytopenia are common complications during the first months after renal transplantation (RT). The aim of this study was to examine the influence of two different immunosuppressive protocols (IP) on blood count and need for blood transfusions during the first month after RT. Methods: The prospective, observational one-centre study included 183 renal recipients since January 2008 to December 2012. According to the applied IP, the patients (pts) were divided in two groups. Group 1 (101 pts, mean age 44 AE 10.8 years, 69 males) received antithymocyte globulin (ATG) 9 mg/kg, tacrolimus (TAC) 0.15 mg/kg, mycophenolic acid (MPA) 2000 or 1440 mg/day depending on the drug preparations and low doses of corticosteroids. Group 2 (82 pts, mean age 39 AE 10.8 years, 49 males) received ATG 9 mg/kg, then 3 mg/kg for the next four days, TAC 0.3 mg/kg, mycophenolic acid 1000 or 720 mg/day and high doses of corticosteroids. Pts in Group 1 also received valganciklovir prophylaxis for cytomegalovirus infection. Blood count was assessed by standard laboratory methods. We recorded frequency of post transplant complications and their impact on anemia. Results: Different IP and valganciklovir prophylaxis didn't influence significantly the incidence of anemia, leukopenia and thrombocytopenia in examined groups. Pts in group 1 needed a higher amount of blood transfusion (p = 0.03), they were older (p = 0.002), they had lower degree of MHC matching (p = 0.04) and longer cold-ischemia time (p = 0.002). The incidence of deceased donor transplantation was higher in Group 1 (p = 0.001). Multivariate regression model showed that older renal recipients need higher amount of blood transfusions (p = 0.003). Duration of cold ischemia time (p = 0.015) and incidence of surgical complications (p = 0.023) were predictive for DGF. Conclusion: Reduction of ATG, TAC and corticosteroids dose with increase of MMF dose and valganciklovir prophylaxis didn't lead to a significant decrease of blood count during the first month after RT. Older age and surgical complications influenced the degree of anemia after RT. Background: Delayed graft function (DGF) is common complication after kidney transplantation. The need for dialysis within the first week of transplantation is a common definition of DGF. In our study we try to find out if DGF can be diagnosed early and reliably by simple and objective criteria. Materials and Methods: We performed this study on 40 kidney recipients whom obtain kidney from cadaveric donor. In prospective study we measured creatinine and cistatin C concentration before and 12 h after transplantation. We evalueted GFR (glomerular filtration rate) using diffrent formulas based on cistatin C, creatinine or both concentration in two patient groups-with DGF and IGF (immediate graft function). Results: We find out that the fastes change in eGFR can be found when we were using forumlas based on cistatin C concentration or on cistatin C and creatinine concentration. Diagnosing DGF with creatinine concentration and formulas based on creatinine concentration was useless. Conclusion: We sugest that comparing eGFR before and after transplantation can be usefull in DGF diagnosing. Background: Pre-operative psychosocial factors have been implicated in post-operative wound healing and recovery. The aim of this study was to evaluate the effect of stress on wound healing and recovery in living kidney donors undergoing hand-assisted laparoscopic donor nephrectomy. Methods: Stress was measured pre-operatively using previously validated questionnaires. Wound healing was assessed on days 1-3 and at 2 weeks using 20 MHz high-resolution ultrasound. Median intensity (MI) was derived from image analysis to assess residual tissue oedema (lower MI = increased oedema). Comparative scores (normal skin MI minus follow-up wound MI) for each patient were computed. Higher scores suggest inferior wound healing. Results: Thirty one donors participated. Age and gender were not correlated with anxiety or mood. Women demonstrated increased stress (6.5 vs. 4.1; p < 0.05). Pre-operative stress correlated significantly with length of stay (r = 0.38, p < 0.05). On multiple regression analysis, after controlling for gender and age, stress predicted ultrasound-derived measures of wound healing (â = 0.80, p < 0.05). This was demonstrated across two separate wounds. Conclusion: Pre-operative stress has a negative impact on post-operative recovery in terms of length of stay and wound healing in living donors. Physical recovery may be improved by interventions to reduce pre-operative stress. Melanie Field 1 , Andrew Bentall 1 , Andrew Ready 1 , Mark Cobbold 2 , Simon T. Ball 1 , Nicholas Inston 1 1 Queen Elizabeth Hospitals; 2 MRC centre for Immune Regulation Background: ABOi transplantation has become increasingly common and comprises 7% of live donors in the UK. In view of the immunological complexity of these patients any mechanism of detecting rejection earlier than current methods would be useful. We aimed to evaluate previously suggested biomarkers of rejection in this cohort. Methods: Serum from 99 patients undergoing ABOi transplantation at 9 UK centres was analysed by Luminex for a panel of biomarkers (NGAL, KIM-1, VEGF, Cathepsin L, IP-10 and Cystatin C) at pre-transplant and posttransplant time points. Comparison was made between rejectors and non rejectors to see if differences in levels could be predictive of rejection. Results: In patients who did not develop acute rejection a fall in biomarker levels was seen between pre-operative levels and levels at day 3 (not statistically significant for IP-10). Levels of those who developed rejection did not show a comparable decrease. Conclusions: The failure of biomarker levels to decrease in patients who later go on to develop acute rejection may help identify those patients at higher risk of developing rejection and perhaps guide surveillance or immunosuppression, but certainly merits further examination in a larger groups of these immunologically complex patients. Abstracts of the Patients were divided in three groups depending on the ratio of donor kidney weight in grams to recipient body weight in kilograms (dkw/rbw-<2, 2 to 3, and more than three in group 1, 2, and 3 respectively). Serum creatinine in milligrams percent on the day of surgery, 7th day, 1, 6 months, 1, and 3 years after the surgery, was recorded and their means compared. Patients with acute tubular necrosis, spsis, drug toxicity and graft rejection were excluded. A Kruskal-Wallis test was conducted after which pariwise comparison was done using the Mann-Whitney U test. Results: The mean creatinine value at 7 days, 1, 6 months, 1 and 3 years respectively was compared among the three groups. The comparison showed that the decrease in mean creatinine level was statistically significant in group three patients at 7 and 30 days (p value 0.023 and 0.029 respectively) and did not show a significant difference at 6 months, 1 year and 3 years. Conclusion: The ratio of donor kidney weight to recipient body weight does not have a significant effect on long term graft function inspite of an early improvement in the function with increased donor kidney weight to recipient body weight ratio. There is no information about the relation between the absolute or relative changes in proteinuria in early stages of transplantation and long term prognosis. Aims: To analyze the effect of the magnitude of proteinuria and its relative changes from 3rd to 12th month after transplantation on long term graf and patient survival. Methods: Retrospective analysis. Of 701 kidney transplants from deceased donors. Mimimum follow-up: 1 year. Baseline proteinuria (3rd) and 12th month post-transplantation in 24 h urine were analyzed. It was categorized depending on its magnitude: 0-149, 150-299, 300-999 mg/day and >1 g/day, and the relative changes of proteinuria from 3rd to 12th month: reduction >50%, variation (Δ) <50%, and increase >50% from baseline. Results: Of 593 patients, mean follow-up: 84.5 AE 48.6 months. Proteinuria was present in 49.9% at 3rd and 47.0% at 12th months. Presence of increasing degrees of proteinuria at 3rd and 12th months were associated with long term graft failure (p = 0.000) and mortality at12th months (p = 0.000). The relative risk of graft failure and mortality increases from 300 mg/day at 3rd month (HR 2.083, p = 0.001) and in the 12th month (HR 2.271, p = 0.016). Progression of proteinuria >50% was an independent risk factor of graf failure (HR 5.385, p = 0.000) and mortality (HR 3.191 , p = 0.035) and was associated with graft failure (p = 0.000) in every category of proteinuria analyzed (p = 0.000), and with mortality (p = 0.023). Anti-HLA antibodies post-transplantation were the only independent risk factor related to the progression of proteinuria >50% (HR 2.723, p = 0.038) in multivariate analysis. Conclusion: The long term risk of graft failure and mortality increases with increasing amounts of proteinuria and with time from transplantation, since early stages of kidney transplant. Proteinuria progression >50% in early stages of renal transplantation could be considered as a marker of graft failure and mortality, regardless of baseline proteinuria, and expression of immunological damage. Background: Laparoscopy nephrectomy (LN) for living donor kidney transplantation (LDKT) is a safe and appealing procedure to potential live donors and has increased the living donor pool at our center. This study aims to examine the role of LN for LDKT, which is a reliable alternative to cadaveric kidney transplantation(CKT). Methods/materials: We performed 257 kidney recipients, including 126LDKT and 131CKT performed between 1999 and 2012. We report a single institution retrospective analysis from an ongoing clinical study on examining demographics, operative factors, and post-operative complications of donors for LN occurring over a 5-year period, focusing on the results of patients who underwent LN from 2007 to 2011 (n = 56). Results: Mean donor age was 48 AE 9 years; median operative time was 231 AE 44' with an average estimated blood loss of 8 AE 19 cc. The overall complication rate was 7%, with pleural effusion and prolonged post-operative pain(>4 days) being the most common. There were no cases of post-operative acute renal failure and no patients died during the post-operative course of 90 days. Donors from 2010 to 2011 (n = 32) enjoyed a shorter average length of stay (4 vs. 6 days) than patients from 2007 to 2009 (n = 24), (p = 0.04). Additionally, there was a trend towards decreased complications in the latter 2 years that did not reach significance. Conclusion: The minimally invasive approach for living kidney donation is considered the "gold standard" compared to other surgical techniques due to its association with shorter organ harvesting procedures and shorter post-surgical hospitalization. In ISMETT, LDKT represents 49% of all kidney transplants performed since 1999:living donors not only benefited their recipients but also made cadaveric kidney graft available to other recipients. LN confirms LDKT as the newest and, both technically and ethically, most challenging development in kidney transplantation helping to combat organ shortage in an area with a low rate of deceased organ donation. Background: ABOI kidney transplantation is an inevitable option to overcome serious organ shortage. Outcome of ABOI grafts improved and became equivalent to compatible grafts. Variable protocols are adapted in different centers, however, there are few data on success rates of ABO antibody removal or relating to patients in who antibody removal fails. The purpose of this study was to evaluate the likelihood of achieving transplantation depending on ABO antibody titers. Methods: Of 55 patients were enrolled between 2007 and 2012. We perform ABOI kidney transplantation using anti-CD20 antibody, tacrolimus and PP with IVIG. The median ABO titer was 1:64 (Range 8-4096). Transplantation was preceded when the ABO titer reached ¡Â 1:8. To determine the likelihood of achieving transplantation, the number of PP required to proceed transplantation and baseline ABO titer were analyzed. Results: All 55 patients (100%) successfully completed transplantation after 5.75¡¾4.3 PP with IVIG. Three patients did not reach target ABO titer and their achieved ABO titers at the time of transplantation were 1:16. The median follow-up duration was 18.1 month (Range 0.9-71.8). The mean age was 45.8¡¾9.9 year and 65.6% were female. The median ABO titer was 2 (Range 1-16) at the time of transplantation, 4 (range 1-64) at 1 month posttransplantation and 4 (range 4-128) at the last follow-up, respectively. The number of PP to reach an ABO titer of ¡Â 1:8 was significantly correlated with baseline ABO IgG titers (r 2 = 0.829, p < 0.001) (Figure1). Conclusions: All 55 patients successfully preformed ABOI kidney transplantation without failure to achieve transplantation. Three patients even failed to reach target titer at the time of transplantation, however, all of them were successfully transplanted. Though optimal ABO titer at the time of transplantation remains debatable, we carefully need to tailor protocol with target ABO titer of greater than or equal to 1:16 to expand kidney donor pool. , n = 83 (7.0%); Immune KD, n = 362 (30.6%); Unspecified Chronic KD, n = 276 (n = 23.4%); Chronic Tubulo-Interstitial Nephritis (CTIN), n = 106 (9.0%); Hypertensive Nephrosclerosis, n = 194 (n = 16.4%); and Type II Diabetic Nephropathy, n = 160 (13.5%). During the decade, there was a progressive increase of type II DM as native KD but the other diagnosis remained stable. At transplantation, groups differed statistically regarding age, race, gender, pre-emptive Tx, donors and type of induction therapy. There were 46 recurrences of Immune KD during this study period. The 10-year death-censored graft survival (GS) analysis revealed ADPKD with the highest survival and Immune KD and nephrosclerosis with the lowest (p < 0.01), mainly due to higher incidence of recurrence (11%) in Immune KD and chronic allograft dysfunction (20%) in both groups. With ADPKD as a reference, univariate Cox analysis for death-censored GS showed a HR of 4.4 (95% C.I.:1.07-33.38, p = 0.039) for Immune KD and 8.0 (95% C.I.:1.92-33.1, p = 0.004) for Hipertensive Nephrosclerosis. By multivariate analysis that included all statistically significant variables at baseline, Nephrosclerosis as the diagnosis of native KD (HR: 6.2; 95% C.I. 1.48-25.99, p = 0.03) and recurrence (HR: 4.42; 95% C.I. 2.70-7.23, p < 0.001) were the risk variables for death-censored GS. These data indicate that not all native KD have similar outcomes and emphasize the importance of a more intense and detailed diagnosis at the time of renal transplantation. Yan Ting Yeo, Petrina Fan, Li Fang Goh, Puay Hoon Lee, Wai Yoong Ng, Terence Kee, Deepika Mallya Singapore General Hospital Tacrolimus (FK) is an immunosuppressant used for prophylaxis of solid organ allograft rejection. It has a narrow therapeutic window and considerable intrapatient pharmacokinetic variability, making therapeutic drug monitoring (TDM) crucial. High performance liquid chromatography-tandem mass spectrometry (HPLC-TMS) is preferred to fluorescent polarization immunoassay (FPIA) as it measures the active parent FK drug and not its metabolites. Our hospital has replaced FPIA with a newer HPLC-TMS analytical method for TDM of FK. The primary aim of this study was to compare the performance of FPIA against HPLC-TMS for measurement of FK trough concentrations in solid organ transplant recipients (SOTRs). A secondary objective was to identify patientspecific factors that may influence the assay measurements of FK. A total of 528 pre-dose whole blood samples were drawn from 169 SOTRs receiving FK therapy. Samples were prospectively collected between June and September 2011. Analysis of FK concentrations was performed using HPLC-TMS and FPIA simultaneously. Relevant hematologic and biochemical data that could influence the assay results were collected. Median FK levels measured by HPLC-TMS was 0.6Î¼g/l (À4 to 4.0Î¼ g/l) lower compared to FPIA, corresponding to a percentage difference of 10.9% (À41 to 36.3%). The Spearman correlation coefficient was r = 0.95 and the resultant Deming regression equation was HPLC-TMS = 0.87 9 (FPIA) + 0.13. Multiple linear regression analysis suggests that the biochemical and hematological results have no significant influence on the difference in the assay results. Despite lower FK concentrations reported with HPLC-TMS as compared to FPIA, the difference was not clinically significant. High correlation was demonstrated between the methods. Thus our study suggests the transition of assay method from FPIA to HPLC-TMS for TDM of FK can be performed without adjustment to the current target therapeutic range. Background: Delayed graft function (DGF) and primary non function (PNF) are serious complications following transplantation of kidneys donated after brain death (DBD). A renoprotective effect of a-MSH has been observed in various models of acute kidney injury. We hypothesized that a-MSH treatment of the recipient improves early renal graft function and reduces inflammation following DBD kidney transplantation. Methods/materials: Twenty-four Danish landrace pigs were used. Brain death was induced in the donors (n = 8) by inflating a 22 Fr Foley urine catheter in the epidural space to increase intracranial pressure. After 4 h both kidneys were retrieved and stored for 18 h at 4€ ı¿½C in Custodiol€ ı¿½ UW preservation solution. The recipients (n = 16) were randomized in a paired design into two groups transplanted simultaneously and treated with either a-MSH (200 lg/kg) or placebo at start of surgery, during reperfusion and 2 h post-reperfusion. The follow-up of the recipients was 10 h. Results: a-MSH treatment reduced diuresis (Controls vs.Î AE -MSH: 2.1 vs. 1 ml/min at 10 h post-reperfusion; p < 0.05) and glomerular filtration rate (GFR, controls vs.Î AE -MSH: 14.4 vs. 9.6 ml/min at 10 h post-reperfusion; p < 0.01). Each gift of a-MSH resulted in decrease in mean arterial pressure (MAP) by 10 mmHg without any effect on heart rate. Also, at 10 h postreperfusion LDH levels were increased in the a-MSH group (460 vs. 335 U/l; p < 0.05) while no differences in urea, ASAT or ALAT were observed. Cortical IL-6, IL-1b or ICAM-1 mRNA expression was not reduced by a-MSH. Conclusion: a-MSH reduced diuresis and GFR, which may be explained by decreased MAP. Markers of renal inflammation were not affected by a-MSH treatment. Thus, a-MSH showed no potential to improve early graft function following DBD kidney transplantation. Hyun Hee Lee, Yeon Ho Park, Woo Kyung Chung, Ji Yong Jung, Jae Hyun Chang, Han Ro Gachon University We need better understand the risk factors, clinical features, and the role of prolonged immunosuppresion of late onset (>1 year) Posttransplant lymphoproliferative disorder (PTLD). Herein is reported an unusual presentation of very late onset PTLD. A 51 year old male received kidney transplantation in May 1995 and his immunosuppressive regimen was only cyclosporine with low trough level (70-90 ng/ml). He visited to the hospital with headache, tingling sensation of hand, and paresthesia on right cheek and right lower mandible area for 7 days. Neurologic examination including Brain MRI did not show abnormality. Ten days after, he admitted with aggravating paresthesia symptoms of right cheek and mandible area and newly developed pain on the left cervical lesion and parotid gland. The neck computed tomography showed infiltrative soft tissue involving left retropharyngeal, carotid space, and swelling of muscle within left masticate area. In addition, there were prevertebral soft tissue swelling and parotid gland enlargement. A biopsy of the soft tissue showed Burkitt lymphoma and Epstein Barr Virus (EBV)encoded small RNA in situ hybridization for EBV was positive. At the time of PTLD, EBV infection in blood was negative. He was scheduled for chemotherapy but PTLD progressed rapidly. He died 2 weeks after admission. Late onset PTLD are associated with poor prognosis. It is necessary to have a high level of clinical suspicion and patient monitoring for prompt diagnosis of very late onset PTLD. pressed with cyclosporine, azathioprine, did initially well with acceptable renal function. Steroid was stopped at post-transplant 1 month due to new onset diabetes mellitus after transplantation. In 2011, the patient visit OPD for the onset of multiple inflammatory nasal polyps and it did not improved with local treatment for 3 months. Nasal polyp biopsy was performed at otolaryngology and the biopsy showed squamous cell carcinoma. Surgeons and dermatologists recommended the wide excision but patient refused surgery due to old age and cosmetic reasons. So cyclosporine was replaced by sirolimus. The size of local lesion was reduced after immunosuppressant conversion. Of 12 months after conversion, the lesion was disappeared in naked eye and recurrence has not been observed. In summary, a case of squamous cell carcinoma on nasal cavity in a renal transplant was treated by conversion cyclosporine to sirolimus without surgical removal. After 1 year of immunosuppression conversion, the local lesion showed good response. CMV disease mostly invasive gastro-intestinal with low viremia occurs in approximately 16% of CMV seropositive renal transplant recipients not receiving Thymoglobuline (ATG). Pre-emptive therapy (PETh) to avoid disease in this group should cover the majority of patients at risk (high Negative Predictive Value -NPV). To define cut-offs for whole blood real-time quantitative PCR (qPCR) and antigenemia (pp65) assays and use PETh for CMV disease we collected blood samples weekly from day 7 to 120 after TX in pts CMV IgG+ (IgG+ donors) who did not receive ATG. A suspicion of CMV disease required new qPCR/pp65 or biopsy. The highest value of pp65 and qPCR in pts without CMV disease one week before disease were used in ROC curves. 92 pts had completed the collections or developed disease. They were males (54%), caucasians (69%), mean age 45 AE 14 years, 61% deceased donors, all under TAC/MPA/Prednisone. Overall 12 pts had CMV disease (11 invasive gastro-intestinal/1 syndrome), at 64 AE 21 days, and 80 did not. Of these 80 pts, 56% presented at least one episode of asymptomatic viremia and cleared it spontaneously (18% had PCR+/pp65+; 56% Pp65+/qPCRÀ and 24% qPCR+/Pp65À). Among pts with viremia or disease there was a trend for a higher pp65+ cells for disease than for viremia (152 AE 352 vs. 31 AE 131/106 cells, p = 0.073,) detected earlier for disease than viremia (64 AE 21 vs. 80 AE 25 days, p = 0.049). ROC curves (area 0.902 AE 0.036, p = 0.001) revealed that pp65 of four cells had 83% sensitivity and 83% specificity to predict CMV disease. Using this cut-off, the NPV was 97%. The CMV copies detected by qPCR was higher for disease than for viremia (46657 AE 50671 vs. 5438 AE 16681 copies, p = 0.001) but time for detection was similar for both (74 AE 25 vs. 59 AE 18 days, p = NS). ROC curve (area 0.903 AE 0.056, p = 0.001) revealed that qPCR=844 copies had 83% sensitivity and 86% specificity to predict disease with NPV of 97%. Both methods are adequate to detect CMV disease prior to its development in this low-risk population. Kristian Heldal 1 , Kjersti Lønning 2 , Karsten Midtvedt 2 1 Telemark Hospital; 2 Oslo University Hospital, Rikshospitalet Background: The incidence and age of patients who develop end stage renal disease (ESRD) are increasing. Consequently, an increasing number of elderly patients are becoming candidates for renal replacement therapy. Kidney transplantation is, in selected elderly patients, shown to provide superior survival compared to continued dialysis therapy. There is an ongoing debate whether elderly patients with ESRD should remain on dialysis or be wait-listed for transplantation. The documentation of how transplantation/immunosuppression interferes with health related quality of life (HRQOL) in elderly recipients is sparse. Methods/materials: Patients >65 years will be asked to fill out the KDQOL-SF form at time of acceptance and every 6 months until transplanted or permanently removed from the transplant list. Post transplant, patients will receive a new form after 10 weeks, 6 months, 1, 3 and 5 years. We perform 300 renal transplantation/year and 25-35% of the recipients are >65 years. Mean waiting time for 1st renal transplantation has always been <12 months. Estimated inclusion-time is 2 years. Primary aim is change in scores between time of acceptance and 1 year after transplantation. Power calculation have concluded that 65 patients have to complete the study to reveal a difference of 10% in SF-36 GH score with a significance level ( a) of 5% and a power (â) of 80%. The study is approved by the regional committee of medical ethics. Results: From January 1st 2013 a total of 45 patients have been included and 4 of them are transplanted. No data analyses have been performed. We believe that the study will provide important information about the effect of kidney transplantation on HRQOL in elderly recipients and thereby help clinicians in the choice between continued dialysis and transplantation for elderly patients with ESRD. Alma Idrizi, Myftar Barbullushi, Nestor Thereska UHC Mother Teresa Background: Post-transplant diabetes mellitus (PTDM) has a reported incidence of 4-41%. It has been identified as one of the most important, being associated with reduced graft function and patient survival, and increased risk of graft loss. We have studied the prevalence of PTDM in patients followed in our renal transplantation unit. Methods/materials: We undertook a retrospective analysis of the glycaemic status of 105 patients undergoing renal transplantation in the 5-year period. Results: Thirteen patients developed PTDM (12.3%), 10 were males (9.5%) and three were females (2.8%). There was a variable onset and a wide range of symptoms. Six of males patients had body mass index (BMI) more than 30 kg/ m 2 . Insulin therapy was required for six patients with variable durations and with resolution of PTDM in all of them. High serum cholesterol and tryglycerides levels were evidenced in all patients and hypertension was present in seven patients. PTDM did not adversely affect the renal graft function. Two of them were HVC positive. Conclusions: The prevalence of PTDM in our patients is similar to that found in the literature. PTDM requires increased awareness among nephrologists and endocrinologists for early recognition and prompt effective intervention. Background: The frequency of cardiovascular disease (CVD) is high after renal transplantation. Risk factors include pretransplant cardiovascular disease, diabetes, male sex, serum cholesterol, hypertension, cigarette smoking, and allograft dysfunction. The aim of this study is to find the frequency of CVD after renal transplantation. Methods/materials: 105 transplanted renal patients, 26 females and 79 males, (mean age 34.8 AE 11.3 years, range 16-58 years) were studied during a period of 6 years. Results: Patients with CVD were older than patients without CVD (age: 42.9 AE 12.08 vs. 36.7 AE 6.9, p < 0.01), predominantly male (70% vs. 30%, p < 0.05). Prevalence of medical conditions was as follows: hypertension 72% (mean age 36.2 AE 8.3 years), ischemic heart disease 4%, dyslipidemia 47% and 20% were treated with statins, diabetes mellitus 12.3%, peripheral vascular disease 5%, cerebrovascular disease 2%. Conclusions: CVD is the leading cause of mortality and morbidity. Arterial hypertension is highly prevalent after renal transplantation and may contribute to the risk of cardiovascular disease and graft failure. The prevalence and severity of CVD in our renal transplant recipients are frequent. They are related to numerous factors, including effects of kidney dysfunction and immunosuppressive drugs. Background: Routine CT anjiography for screening of potential donors for kidney transplantation has been associated with an increase in the number of the patients with kidney stones. The optimal management of stone bearing kidneys at transplant is still unknown. We consider patient with small, unilateral, nonobstructing, incidental renal calculi for eventual renal donation. We performed ex vivo flexible ureterorenoscopic lithotripsy to make the kidney stone free at the time of kidney transplantation. We inspect the efficiency of ev vivo flexible ureterorenoscopic lithotripsy. Methods/materials: After inspecting the metabolic evaluation, three patients with small nonobstructing unilateral urolithiasis diagnosed on preoperative CT angiography underwent donor nephrectomy. After cold arterial perfusion, flexible ureterorenoscopy was performed with cold saline irrigation. Stones was disintegrated with laser. Results: € Ureterorenoscpy was performed in three patients. A total of three calculi, largest diameter 4 mm, were visualized. Holmium laser lithotripsy was applied. After laser application all kidney was stone free. The mean treatment time was 20 min. There were no intraoperative complications.  Background: Brazil has the most public of transplants and occupies the second place (behind only the United States) in number (absolute) of surgeries of this size, with emphasis on the kidney transplant. OBJETIVES: this paper aims to check and analyse the institutional mechanisms and incentives offered to hospitals that perform the abstraction of organs (especially kidneys) for transplants in Brazil using the theory of principal-agent. Methods: The theoretical approach to be used is the principal-agent model under asymmetric information context (that is, when one side of the contract knows more on the other side). This theory is well suited to analyze this type of problem, because the main welfare (SUS) depends on the efforts of hospitals (agent) to capture the organs for transplants. SUS (principal) is responsible to prepare and propose a contract (developed from Brazilian legislation of transplants) hospitals (agent) to perform actions related to funding of organs for transplant. Results and discussion: It is noteworthy that the level of effort made by the hospital depends on some measures which this does to improve uptake in organs and tissues, which are: training of transplant coordinators, acquiring knowledge of the clinical phases, bureaucratic and logistical donation process; regional meetings with intensivistas; courses on organ donation and transplantation to all professionals who work in hospitals; regular meetings with journalists, communication experts and opinion formers; lectures and debates about organ donation. Implications: It was found that the SUS has adopted various measures incentives for hospitals that perform the abstraction of organs, such as: creating a specific fund for financing of transplants; uniform payment to hospitals and universities; expansion of the types of hospital procedures to be paid by SUS. Background: This study aimed to assess diagnostic accuracy of ultrasonography (US) and Doppler parameters of kidney graft measured at 1 month posttransplant to predict graft outcome. Methods: The study cohort included 266 adult recipients of a deceased donor kidney transplant between Jan 2006 and Dec 2011. All patients had US-Doppler examination performed at 1 month post-transplant. Data collected were: graft length, parenchyma thickness, and Doppler indices measured at mid-segmental artery level. Parenchyma size index (PSI) was calculated by dividing parenchyma thickness with graft length. The primary outcome of interest was combined graft loss or doubling of the serum creatinine. Results: After a median follow-up of 43 months, 37 patients reached the combined end-point. The receiver operator characteristic analyses demonstrated that PSI at 1 month post-transplant had good discriminatory ability to predict primary outcome with area under the curve (AUC) 0.71 (95% CI 0.63-0.78) and performed better when compared with graft size and parenchyma thickness (AUC 0.65 and 0.61, respectively). Among Doppler parameters, RI performed best with AUC 0.70 (95% CI 0.62-0.78). The PSI cutoff 1.35 mm/cm and RI cutoff 0.70 were associated with the best performance of the analyses (PSI: sensitivity 82%, specificity 72%; RI: sensitivity 85%, specificity 63% Background: Despite intensive cardiac screening for waitlisted patients, cardiac complications remain a leading cause of death in renal transplant recipients (RTR). We present our experience of tacrolimus(tac)-induced cardiomyopathy(TICM) in an adult recipient which resolved after switching to belatacept. Methods: A 62-year-old white female presented with new-onset congestive heart failure (CHF) and acute kidney injury six months after transplantation. She had received anti-thymocyte globulin induction and was maintained on tac (5-10 ng/ml), mycophenolate and prednisone. Left ventricular ejection fraction (LVEF), which was normal on stress echocardiography one month pretransplant, was 30-35% at presentation. Nuclear stress test was negative for ischemia. Her troponin levels, creatinine kinase, thyroid function, transplant doppler studies, B12 and folate levels, and viral screening were unremarkable. A transplant biopsy showed no evidence of rejection and donor specific antibodies were negative. She had two further hospitalizations for CHF exacerbation and creatinine remained elevated at 3 mg/dl despite maximal medical therapy for CHF. Due to the concern of TICM, tac was changed to belatacept at 7 months posttransplant. LVEF normalized (55-60%) four months after belatacept conversion, and her renal function returned to 1.4 mg/dl. Discussion: TICM has been reported in children and may involve its vasoconstrictive effects causing decreased blood supply to myocardium; however it is rare in adults. We describe a RTR with normal pre-transplant cardiac function developing non-ischemic cardiomyopathy within 6 months. LVEF normalized within months after tac withdrawal, and in the absence of other identifiable etiology and intervention strongly supports a TICM. Reinstitution of tac and recrudescence of CHF would have fulfilled Koch's postulates but was deemed unethical. Background: Delayed graft function (DGF) occurs in approximately 5-50% of deceased donor renal transplantation (DDRT). It is associated with increased risk of acute rejection and poorer long-term graft survival. If we can predict the DGF before DDRT, we may assist in the allocation of marginal organs or direct interventions to prevent or ameliorate DGF. A novel web-based DGF risk calculator (www.transplantcalculator.com) was developed by Irish et al. It is an easily accessible tool for predicting DGF, but the predictive performance of this model has not been tested in Asians. The aim of study is to assess the usefulness of this prediction model in Korean DDRT. Methods: A total of 195 subjects, who underwent DDRT in our hospital from January 2000 through December 2011, were reviewed. The recipient, donor, and transplant variables were recorded, and individual DGF risk was assessed using the web-based. Continuous variables were analyzed using Student's ttest and categorical data by chi square test. Logistic regression analysis was used to determine the odds ratio for DGF according to the calculated DGF risk value. DGF discrimination ability was measured by sensitivity, specificity, positive predictive value and ROC curve c statistic. All data analyses were performed using statistical software PASW Statistics 18 (SPSS, Chicago, IL, USA). Results: The overall rate of DGF in our study was 15.9% and the average individual web calculated risk of DGF was 16.1 ¡¾ 15.2%. The mean calculated DGF risk was significantly different between patients with DGF (30.2 ¡¾ 21.2%) and those without (13.3 ¡¾ 12.0%, p < 0.00). The area under the ROC curve to predict DGF was 0.820 (95% CI 0.733-0.907, p < 0.000 Methods: We performed a retrospective review of patients undergoing KT from June 2010 to July 2012. Among them, only 115 patients with functioning AV access on operation day were included. VA access patency was checked and recorded daily in hospital stay and every visit of outpatient clinic. Results: Mean patients age was 46.8 ¡¾ 9.3 years. There were 71 male. Mean duration from AV access construction to KT was 1937 ¡¾ 1864 days and mean follow-up after KT was 385 ¡¾ 25 day. The majority of patients (85.2%) had a native AV access and eighty patients (69.6%) had an AV access at wrist. At the end of follow-up, eighteen (15.7%) AV accesses were spontaneously closed. Mean time to closure was 119 ¡¾ 163 days, and 12 out of 18 were closed within 90 days after KT. AV access was spontaneously closed in 8.5% of male patients and 27.3% of female patients (p = 0.007), 12.2% of native AV access and 35.3% of artificial AV access (p = 0.016), and 11.3% of wrist AV access and 25.7% of elbow AV access (p = 0.049). Spontaneously closed AV access had lower mean access flow when compared functioning access (p = 0.019). On multivariate analysis, only female gender, and AV access flow volume affected spontaneous AV access closure. Conclusions: This study suggests the surgical closure of a functioning AV access in male patients or high output AV access could reduce unnecessary waiting times requiring spontaneous closure in patients with a high risk of AV access complications. Background: after kidney transplantation occurs reduction in BMD at the vertebral column and at the femoral neck, that is highest during the first months but can persistent in the long term. The etiology is multifactorial: persistent hyperparathyroidism, pre-existing renal osteodystrophy, immunosuppressive therapy, VitaminaD deficiency. The aim of the study is to analyze the role of PTH in BMD reduction. Patients and methods: Of 153 patients, 89 males and 64 females. Age 52.3 AE 0.8 years, follow-up 31.4 AE 1.4 months (mean AE standard error). Exclusion criteria: creatinine >2 mg/dl. Immunosuppressive therapy: basiliximab + steroids (1.6-2 mg/kg/die progressively reduced to 5 mg within 45 days) + calcineurin inhibitors + mycophenolate mofetil. The patients were studied by PTH and bone densitometry at the femur and at the vertebral column. Osteopenia was define for T-score between À1 and À2.5, and Osteoporosis for T-score <2.5. We considered two PTH levels to define hyperparathyroidism: 80 and 150 pg/ml. We analyze data by chi-quadro test. Results: 28.1% of patients had normal BMD at the femur and at the vertebral column. 46.4% and 16.3% of patients had respectively Osteopenia and Osteoporosis at the femur. 39.2% and 18.3% of patients had respectively Osteopenia and Osteoporosis at the column. 55.2% of patients had PTH > 80 pg/ml and 18.1% had PTH >150. In the group with PTH >80, 55.7% of patients had Osteoporosis/Osteopenia at the femur and 50.9% of patients had normal BMD (Odd Ratio 1.21, p > 0.05). 56.4% of patients had osteopenia/ osteoporosis at the column and 56.1% had normal BMD (Odd Ratio 1.1, p > 0.05). In the group with PTH >150, 16.9% of patients had Osteopenia/ Osteoporisis at the femur and 20% had normal BMD (Odd Ratio 0.75, p > 0.05). 16.4% of patients had Osteopenia/Osteoporosis at the column and 20.9% of patients had normal BMD (OR 0.75, p > 0.05). Conclusion: There were no significant differences in the levels of PTH between patients with Osteopenia/Osteoporosis and patients with normal BMD. Not only hyperparathyroidism but also low levels of PTH are associated with reduced BMD.  Background: Survival rates following kidney transplantation have improved significantly. However mortality in long-term kidney transplant patients (LKT) remains high compared to age-matched general populations. Cardiovascular disease (CVD) is a major cause of morbidity and death among this group. Proteinuria (P) is an important independent risk factor for CVD. The degree of P has prognostic and diagnostic implications. ACE/ARB therapy has been shown to reduce P in CKD patients, and some studies suggest their anti-P action is additive. Use of ACE/ARB in LKT is more complex and less well defined. Methods: Urinary PCR, GFR, BP measurements and drug lists of 335 LKT (>8 years from transplant) seen between 2010 and 2012 were retrieved and analysed. Results: Of 257 (77%) LKT had PCR<50, 40 (12%) PCR 50-100, and 38 (11%) PCR > 100. Mean GFR was 45 ml/min (range 15-122) and mean BP 136/77. PCR>100 was associated with raised BP (mean 140/80) and lower GFR (mean 41 ml/min). 33(13%)/19 (7%) LKT with PCR <50, 6 (15%)/5 (13%) with PCR 50-100 and 12 (32%)/15 (40%) with PCR >100 were on ACE/ARB respectively. 14 LKT with PCR >100 were not taking ACE/ARB. Of these: three had CKD stage 5; two died; four commenced ACE/ARB; two had PCR incorrectly recorded; two had recurrent UTIs and one had PCR >100 when pregnant. Three LKT with PCR >100 were on ACE and ARB: of these one had recurrent IgA; 1 FSGS and one had PCR >400. Conclusion: The majority of our LKT have stage 3 CKD. PCR >100 is uncommon but not rare and associated with raised BP and lower GFR. LKT with PCR >100 were more likely to be on ACE/ARB. A significant proportion not on ACE/ARB had graft failure or died. Targeted ACE/ARB use may improve long-term graft survival and reduce mortality. Prospective follow-up of this cohort is warranted. Introduction: Patients with solid organ transplants (excluding kidney transplant) might develop renal failure in a percentage between 10% and 80% and 20% of these patients have an end stage renal disease (ESRD) 0.6% of patients with LTX have renal failure and the 12% of these have ESRD. A possible cause is the employment of calcineurin inhibitors. This study reports the case of a 70 years old woman with lung transplant who was underwent to dialysis and who received KTX. Case report: Woman, 70 years old. When she was 4 years old, measles pneumonia and bronchietasiae were diagnosed. During the following years the patient had several respiratory infections and she developed respiratory insufficiency. When she was 56 years old, she underwent LTX. Immunosuppressive therapy: steroids + MMF + cyclosporine. After one year she developed renal failure and after 5 years she underwent dialysis. The Cyclosporine was stopped. For serious vascular access problems, she was placed on the waiting list for KTX. At that time the comorbidities were: HCV related hepatitis, CMV infection, recurrent pulmonary infectious episodes, respiratory insufficiency, pathological fractures. The patient underwent KTX 8 years after the start of dialysis. Immunosuppressive therapy: steroids + MMF. The postoperative course was characterized by the prompt recovery of renal function, but it was complicated by the onset of thrombosis at the femural vein and severe respiratory failure secondary to aspergillosis. At the hospital discharge the creatininemia was 1.2 mg% and the immunosoppressive therapy was prednisone 10 mg/day, tacrolimus 1 mg/day, MMF 180 mg/b.day. Results: Of 948 KT were performed at our institution and 93 (9.8%) were included in our PA program. Most PA patients (n = 86) had access failure. Mean follow up time was 32 (0-69) months. 5-year patient survival was lower in PA patients (76 vs. 86%, p = 0.001). Twenty (21.5%) PA patients died, being 70% of them in the first 3 months. Final causes of death: infection (10 patients), bleeding (n = 6), uremia (n = 1), mesenteric ischemia (n = 1) and unspecified shock (n = 2). Because of this high mortality rate we compared patients who died in the first 3 months (group A) vs. those who survived (group B). Age, gender, previous kidney transplants, sensitization, pre-transplant DSA, pretransplant diabetes, induction therapy, DGF, rejection, use of heparin and time from inscription in the PA program to transplantation were not statistically different between groups. Among 47 patients who were screened for thrombophilia, 83.3% from group A were positive vs. 31.7% from group B (p = 0.01). Infection after transplantation and hemorrhagic complications were more frequent in group A. Groups were not different regarding causes of death. Multivariate Cox proportional hazard models for patient survival showed a HR of 5.2 (95% CI, 1.02-26.74, p = 0.047) for thrombophilia.  Hakan Sozen 1 , Utku Yilmaz 2 , S€ ukr € u Sindel 3 , Galip G € ur 3 , Ayd y n Dalgic 4 1 Gazi Universsity Transplantation; 2 Gazi University Transplantation Center; 3 Gazi University Nephrology; 4 Gazi University General Surgery Delayed graft function(DGF) increases morbidity after transplantation, prolongs hospitalization and may lead to premature graft failure. Aim: To asses outcome of ATG implementation in DGF developed deceased donor kidney transplants(DDKT). Material and methods: Totally 62 DDKTs were performed at Gazi University Transplantation Center, Ankara/Turkey. Eight patients disqualified from study because of receiving only IL2r blocker. Fifty four patients received ATG and 42 out of 54 patients were suitable for DGF criteria. Data retrospectively collected from charts and hospital files who received ATG for DGF. ATG was given in case of DGF onset at D1 after transplantation from dose of 2-3 mg/kg/IV infusion until the serum creatinine(Cr) decreases spontaneously 50% or Cr <3 mg/dl. Results: DGF was detected in 42(68%) out of 62 DDKT. There were 24 female and 18 male recipients. In patients with DGF, mean cold ischemic time was found as 21 AE 6.1 h. Mean mismatch was 3 AE 1.7. Mean donor age was 41 AE 19 years. The duration of ATG administration was 9.4 AE 4 days (median 10, 8-15 days). The median length of follow-up was of 42.5 months (range, 1-77 months). Six (14%) acute rejection (ARx) episodes were seen during follow-up. ARx treated succesfully with pulse steroids. Totally five viral infections (3 BK, 1 CMV, 1 parvo) were detected. Totally six grafts were lost during median 42.5 months of follow-up; 2 BK, 2 HUS, 1 dual kidney, 1 unknown reason. No PDLD or other malignancies in this study. Patient and death-censored graft survivals for 1, 3 and 5 years are 100%, 97%, 93% and 89%, 86%, 86% respectively. Conclusion: Renal transplantation population continues to be negatively impacted by DGF. Patients with DGF seem similar patient and death censored graft survival compared with literature. However they experienced increased viral infections during the first year after transplantation and a substantially higher frequency of acute rejection rates. Intravenous Immunoglobulin (IVIG) preparations are increasingly used for controlling patients'immune response in kidney or heart transplantation to achieve desensitization or for prophylaxis/treatment of humoral acute rejection (HAR). In France, little is known about the management of renal and heart transplant patients. This French national survey aimed to identify indications requiring treatment with IVIG in transplant recipients and to evaluate management of these patients in each indication. Of 28 kidney and 16 heart transplant centers (76% of French centers) participated to face-to-face interviews between November 2011 and April 2012. The number of highly sensitized patients increased between 2009 and 2011: 38 to 64 patients in 16 heart centers and 600 to 973 in 28 kidney centers. In both pathologies, HAR prophylaxis increased between 2009 and 2011 (16 to 43 patients in heart centers and 137 to 251 patients in kidney centers). HAR treatment remained stable between 2009 and 2011 (19 to 22 in heart centers and 108 to 132 in kidney centers). Desensitization is seldom used in cardiology (11 patients in heart centers and 40 patients in kidney centers in 2011). In prophylaxis, patient's profile differs between kidney and heart transplant: MFI (Median Fluorescence Intensity) levels are taken into account by 88% cardiologists, whereas presence of DSA (Donor Specific Antibodies) or hyper-immunization are more relevant for kidney centers. In 2011, the HAR prophylaxis protocols are notified by seven heart versus 19 kidney centers: Plasmapheresis alone (14% vs. 26%); Plasmapheresis + IVIG (29% vs. 11%); Plasmapheresis + IVIG + rituximab (14% vs. 16%); IVIG alone (57% vs. 68%); IVIG + rituximab (14% vs. 21%). Heterogeneity of therapeutic care underlines the need for joint recommandations and for further clinical studies. Conclusions: In this small study, ESR was associated with an excess of UTI, and urological complications. EGFR at 12 months was higher with LSR. None of the differences reached statisitical significance. Graft loss was equivalent in both groups. Even though there are potential risks to the patient and extra costs associated with readmission of patients for stent removal, this small study suggests that LSR is associated with a lower rate of UTI and urological complications. Abstracts of the . We carried out a further biopsy of the ulcer and histological examination showed oral mucosa with necrotizing ulcerative, inflammatory granulation tissue and pseudoepithelioumatous hyperplasia, suggestive of necrotizing sialometaplasia (NS). Treatment was based on 75% reduction of Cyclosporine dose, ceftriaxone and meropenem, switched subsequently to tetracycline and azithromycin, associated with nystatin and benzydamine hydrocloride mouthwashes obtaining prompt resolution of symptoms. One year later the patient is still in fair condition, the palatal ulcer completely healed and dysgeusia and halitosis disapperead. Immunosuppressive therapy reduction has led to a complete healing of NS. NS is a rare benign inflammatory reactive necrotizing process, manifesting itselfs as an ulcerative lesion on the palate, that can involve minor and major salivary glands. Recognition of necrotizing sialometaplasia is important because this lesion may mimic malignancy, and misdiagnosis may result in unnecessary surgical therapy. Complete healing of NS usually occurs without treatment within 3-12 weeks. The clinical course of the ulcer in our patient, longer than usual, can be explained by the effect of immunosuppressive therapy. The exact pathophysiology of NS is unknown but gland tissue ischaemia has been proposed as the aetiology. Its correlation with immunosuppression is unknown. Francesco Nacchia, Umberto Tedeschi, Francesca Fior, Rostand E. Momo, Luigino Boschiero AOUI, Dipartimento di Chirurgia, Centro Trapianti Renali Introduction: Transplant experience with HKT is limited, though transplanted after split or en bloc. Literature reports 23 en bloc and 57 split HKT. Materials and methods: We report four HKT, one splitted and three en bloc; donors and recipients age was 33-72, 37-65 year-old respectively. The en bloc HKT consisted aorta end-to-side anastomosis to the common iliac artery (two cases) or external iliac artery (one case); inferior vena cava end-to-side to the common or external iliac vena. Cranial vessels ends closed immediately above the most cranial renal vessel to avoid a cul de sac. Separate stenting ureteroneocystostomies were performed. The split HKT had a single artery and complete double collecting system for each moiety; isthmus drained into left and right system separately by properly collecting system. Introduction: The widening gap between kidney transplant demand and supply prompted the expansion of selection criteria for donation to increase the available donor pool. Among donors with expanded criteria are even those with small renal cancers. We report our experience on transplantation of kidneys with small renal neoplasm. Materials and methods: We accidentaly found, at bench surgery time pretransplantation, six suspected neoplastic lesions on donor kidney. All lesions were excised and histological analyzed by frozen sections. Results was confirmed in permanent sections and staged with Fuhrman nuclear grade. Following cancer diagnosis surgical excision was enlarged with achievement of free resection margins. After informed consent all grafts except one were used for transplantation. Results: Histological lesions type were: one clear cell renal cell carcinoma (RCC), three cystic RCC, one papillary RCC and one oncocytoma. We not utilized the graft with papillary RCC for the described risk of multifocality. We transplanted the other five kidneys and contralateral kidney of clear cell RCC. Table 1 shows donors, recipients and neoplastic characteristics. All recipients has been treated with CNI based immunosuppressive regimen and at mean follow-up of 56 months (min 16, max 136) have functioning grafts and no signs of neoplastic disease. One patient died two years after transplant for cardiovascular event. Discussion: In our experience, kidneys with small tumors (T1a) can be used for transplantation. It is mandatory, in order to ensure to recipients an acceptable level of risk, carefull evaluation of histological type and grading of neoplastic disease, free resection margins and strict follow up. Lilia Ben Fatma, Nadia Amri, Lamia Rais, Ghada Boulahya, Rania Khedher, Wided Smaoui, Madiha Krid, Soumaya Beji, Karim Zouaghi, Fatma Ben Moussa La Rabta Hospital Introduction: Calcium lithiasis is the most frequently diagnosed renal lithiasis and is associated with a high percentage of patients with metabolic disorders, such as hypercalciuria, hypocitraturia, and hyperoxaluria. Is the presence of Oxalate-calcium stone in living kidney donor before transplantation should make them unselected for kidney donation in all cases? Patient and method: We conducted this study to analyze our experience in management of urolithiasis or hyperoxaluria in three renal potential donors. Results: This report is about three females aged 49, 43 and 38 years old. All are proposed for kidney donation to their sister. All are not obese, without any medical history and without any pathological symptom such as nephretic colic. We noted no urinary lithiasis on radiographs. We performed a 24-h urine test, and examined PH, calcium and oxalate. For the first patient, we note a family history of urinary lithiasis and initial nephropathy for the recipient was undetermined. In the two other cases, we noted on tomodensitometry renal arterial subcentimeter calculi in two cases. In case 3, we noted vitamin D deficiency related hyperparathyroidism. The urine analysis showed in case 1: PH at 5.7, hypercalciuria with Ca/creatinuria at 0.818 mM and weddelite. In patient 2 we noted PH at 5.5, hyperoxaluria at 0.48 mM and oxalate/creatinuria at 0.057. In patient 3 with calculi, we noted PH at 6.6, mild hyperoxaluria with oxalate/creatinuria at 0.035 (normal rate <0.03). This patient underwent pre transplant extracorporeal shock, hyperdiuresis regimen with stone clearance. She donated a kidney for her sister. After a follow up of 16 months, there was no stone recurrence in donor or recipient. The other two patients were refused for kidney donation. Conclusions: There is a controversial if the kidney stone formers can donate a kidney or not. Proper donor selection and follow up is crucial to success. This report shows the efficacy of pre transplant extracorporeal shock in living donors with subcentimeter calculi permitting kidney donation after stone clearance. When there is a family history of stone, metabolic disease or donor lumbar pain, screening for hypercalciuria and hyperoxaluria should be performed. American guidelines that a kidney stone former may donate a kidney if only one stone has ever formed or if stones have been multiple, but none have formed for >10 years and none are seen on radiograph and if the donor is screened for metabolic abnormalities and is offered life-long follow-up that includes periodic risk reassessment, medical treatment, and hydration. Introduction: A significant number of kidneys from potential deceased donors are discarded due to raised terminal creatinine. Outcome data of utilizing kidneys with severe acute kidney injury (AKI) are limited. We determined the outcomes of recipients who received kidneys from deceased donors with severe AKI. Methods: We included deceased kidney donors between 1/1/2000-30/7/12 with a terminal creatinine >300 lM. Primary outcomes were serum creatinine, patient and graft survival. Results (Table) : To date data were available for 35 patients. Ten donors (29%) fulfilled the criteria of expanded criteria donor. Mean creatinine on admission was 102 and 492 lM on retrieval. 43% of the donors had mean creatinine >500 lM. The cause of death was road traffic accident and cerebrovascular accident in 26% and 23% of patients respectively. The mean age of the recipients was 44 years. Mean cold ischemia time was 14 h and none of these kidneys were perfused by pulsatile perfusion machine. Most of the patients, 66%, had delayed graft function The common causes of end stage renal disease were diabetes 31%, undetermined 26%, and glomerulonephritis 23%. Eighty-two percent of the recipients completed a follow up of at least 2 years, 65% at least 3 years and 30% patients completed follow up of 5 years. At one year follow up one patient had lost the graft and no patient had died. To date there is no further graft loss and one patient had died after 4 years of follow up. At 12 months the mean serum creatinine was 104 lM. Mean creatinine was <150 lM in 74% and 80% of those patients who had completed 3 years and 5 years follow up respectively. Conclusion: The preliminary results of this study show excellent short-and long-term outcomes of recipients who received kidneys with severe AKI. This study should encourage the healthcare providers to accept such kidneys. Introduction: Hepatitis B infection in kidney transplantation has a reactivation risk under immunosuppression such as fulminate hepatitis. In kidney recipients, Lamivudine is a safe and effective antiviral HBV treatment both before and after renal transplantation; many studies confirmed that preemptive Lamivudine therapy improves survival of renal transplant recipients with HBV infection but Entecavir has demonstrated greater suppression of viral replication compared with Lamivudine and also a lower potential of resistance. Patients and method: Here we report 2 kidney recipient positive hepatitis B virus (HBV) young woman treated before transplantation by Lamivudine. Results: It's about a 28 and 34 years-old females presenting an chronic renal disease, with a pre-transplantation hepatitis B infection. At diagnosis a significant viral load 10 900 UI/ml was detected in the serum in patient 1 and 9900 UI/ml in patient 2. Fibrosis, before treatment, according to Metavir score was A0 F1 in the two patients. Treatment with Lamivudine was administrated during 6 months in patient 1 and Entecavir in patient 2 and HBV DNA levels became undetectable and kidney living donor transplantation was performed. In patient 2, the kidney transplantation was pre-emptive with MDRD creatinine clearance at 18 ml/min. Post-transplantation immunosuppressive drugs include steroids and calcineurin inhibitor-based regimen. After the transplantation, the HBV DNA remained low (451 UI/ml in patient 1 and 300 in patient 2). Two months after transplantation, Lamivudine was switched by Entecavir in patient 1 to avoid emergence of resistance. After a follow up period of 12 months, HVB DNA is undetectable. Conclusions: Antiviral nucleoside analogues are effective in the prevention and treatment of hepatitis B exacerbation in kidney transplant recipients, thereby improving patient survival rates. Background: Simultaneous kidney-pancreas transplant (SPKT) is the best therapeutic option for diabetic patients with end-stage kidney disease. However it presents high risk of surgical complications and pancreas graft failure. The aim of the study is to evaluate early pancreas graft failure in SPK transplantation and the risk for subsequent kidney failure. Methods: Retrospective observational study of 139 SPKT (enteric drainage) performed from year 2005 to 2011 with minimum follow up of 6 months and maximum of 24. All received induction immunosuppression and prednisone, FK and mycophenolic acid. We analyzed age, gender, time on dialysis and PRA. Results: Recipient age was 40 AE 6 years, 62.5% man, 92.8% had 0% PRA. Donor age 31 AE 10 years, 61% man. We documented rejection in 35% of patients, 25% occurring within first 6 months. 7.2% of patients had a kidney rejection, 14.4% pancreas rejection and 14.4% rejected both organs during the follow up. After a pancreas rejection 46% of patients had a following rejection episode (23% kidney, 27% pancreas, 4% both), 25% after kidney rejection (17% kidney, 0% pancreas, 17% both) and 50% after simultaneous rejection (25% kidney, 33% pancreas, 0% both). We did not find differences in donor characteristics, PRA, HLA mismatches or time on dialysis in rejection group. At 2 years followup rejection group showed creatinine 1.46 AE 1.15, Glucose 92 AE 18, peptide C 3.31 AE 2.5 vs. 1.15 AE 0.3, 92 AE 19, 2.44 AE 1.2 in non rejection group. We detected eight pancreas lost at 6 months of SPKT in nonrejection group due to surgical complications and thrombosis and 0 in rejection group. At 2 years followup, six patients with rejection lost pancreas and three lost kidney, none did it in non-rejection group. Conclusion: Suffering pancreas rejection after SPKT seems to be a risk factor for further rejection of pancreas, but also kidney. Most important causes of graft lost during the first 2 years after transplant are surgical complications for pancreas rejections for kidney. general transplanted population. However, there are no data on the use of steroid-free regimens in this subset of patients. Purpose: To evaluate the effectiveness and the safety of kidney transplantation in HIV+ subjects treated with an immunosuppressive protocol without steroids. Patients and methods: Between June 2007 and April 2012, 14 HIV+ patients, at low immunological risk (1°tx, PRA < 30%), underwent kidney transplantation from deceased donor, at our Centre. At tx, the length of dialysis was 5.0 AE 3.1 years but the time on the waiting list was 10 AE 8 months. The primary inclusion criteria were: CD4 count >200/mmc and HIV replication suppressed by antiretroviral therapy. In all cases, induction therapy consisted of Basiliximab plus Steroids, followed by the maintenance therapy with Calcineurin Inhibitors and Mycophenolate Mofetil. Steroids were withdrawn (SW) on day 5 post-tx in 13 out of 14 patients, but it was definitively resumed in the event of acute rejection. Results: The main study results have been reported in the table below. Donor age was 38 AE 12.5 years. After Tx, 7 out of 13 steroid-free patients (54%) suffered from acute rejection, biopsy proven in six cases (cellular AR = 2 cases, humoral AR = 1 case, Mixed AR = 3 cases). All the episodes recovered after the treatment with Steroids, plus Thymoglobuline in two cases and plasmapheresis plus Immune globulins IV in one case. One patient lost the graft 43 months later for chronic rejection associated with severe infectious disease. CMV pneumonia (1); malaria from donor (1) Steroids are potent immunosuppressive drugs but may induce deleterious metabolic side effects without adequate efficiency on the long-term outcome after kidney transplantation. In the present case steroids were stopped at day 7 after successful transplantation of a female, full-house kidney transplant in a 47 year old male. The patient was discharged with a creatinine of 138 € AlM, clearance 60 ml/min). Kidney function remained sufficient at 78 ml/min with cyclosporine and mycophenolate (MMF 2 g/day), when leukopenia (1500 leukocytes/ € All)occurred 6 weeks after transplantation. Leukopenia occurred after a treatment with azithromycin because of bronchitis and seemed to be drug induced together with cotrimoxazol and valganciclovir as concomitant prophylaxis for pneumocystis jerovicii and cytomegaly (D+/RÀ constellation), respectively. Leucocytes normalized within 2 weeks after stopping cotrimoxazol and reduction of MMF (1 g/day). After 2 weeks MMF was augmented to 1.5 g/day, cyclosporine levels 3 months after transplantation were 100-150 ng/ml. Kidney function remained stable and without albuminuria (II CKD, G2 A1, KDIGO 2009). It is discussed that similar to tacrolimus -in steroid free maintenance-high dosed cyclosporine (150-200 ng/ml) may induce leukopenia as well especially in combination with MMF, cotrimoxazol and valganciclovir. In the absence of steroids leukopenia might occur sooner than the wellknown dip after 3 months.  Three years after successful kidney transplantation on a triple therapy a 46 year old man developed creeping creatinine (crea). Kidney biopsy of the fullhouse organ revealed acute tubular injury and calcineurin inhibitor (CNI) toxicity but no recurrence of IgA nephropathy. During the previous 3 months cyclosporine levels had been fluctuating (52-101 ng/ml). The patient had confirmed to take his drugs regularly, but once he had been given another preparation of cyclosporine by his pharmacy. Although drug levels were kept stable, kidney function further deteriorated, diarrhrea and edema occurred. A second kidney biopsy in March diagnosed TMA with fragmentocytes in the glomerular capillaries. However, blood levels for thrombocytes, lactate dehydrogenase, complement remained normal and further differential diagnostics for hemolytic uremic syndrome were done. During therapy with plasma exchange (6x) and steroids, belatacept and low-dose tacrolimus (1-2 ng/ml) instead of cyclosporine, kidney function remained bad. A third biopsy in July showed still fresh signs of TMA, without other pathological signs. Only after cessation of the CNI and another six courses of plasma exchange, kidney function has stabilized until now. This case demonstrates drug-induced TMA in a kidney transplant, which stabilized during CNI free immunosuppression after ruling out D+/À HUS, rejection and recurrence of IgA-Nephropathy. Hyung Hwan Moon, Jae Berm Park, Shin-Seok Yang, Jinyong Choi, Wontae Cho, Sung-Joo Kim, Jong Man Kim Samsung Medical Center Background: BK virus-associated allograft nephropathy (BKVAN) is one of the important complications of kidney transplantation (KT) that leads to graft dysfunction and loss. There is no established anti-viral drug for BKVAN, and the reduction of immunosuppression has been used currently as a therapy to control BKVAN. Recent studies have reported that sirolimus, mammarian target of rapamycin (mTOR) inhibitor may control BK virus replication. We report the outcome of sirolimus-based treatment on BKVAN in a single center. Patients and methods: Between September 2007 and December 2011, 534 patients received KT at our center. BK viral replication was monitored with urine and blood BK virus PCR per our BK virus monitoring protocol. We reviewed medical records including biopsy and BK virus PCR in the patients, who were treated with sirolimus-based immunosuppression (IS) change. BKVAN were proven by needle biopsy. Results: In 15 among 534 patients BKVAN were proven by needle biopsy at a median of 5 months post transplantation. In nine recipients, their calcineurin inhibitor-based IS was changed into sirolimus-based therapy. Follow-up duration sirolimus-based therapy was a median of 18.8 months. In all nine patients BK viral load in blood decreased as with sirolimus-based IS. Six patients showed viral clearance in BK viral load PCR in blood at post-treatment 12 month. During the follow-up post-sirolimus treatment, one patient had biopsy-proven acute cellular rejection and received steroid pulse therapy. Another one patient showed sustained hypercholesterolemia, tacrolimusbased IS resumed maintaining in low trough level. There was no graft failure due to BKVAN after the treatment of sirolimus-based IS. Conclusion: In recipients with BKVAN,sirolimus-based IS led to decrease in BK viral load in blood PCR and maintaining their graft functions. Long-term follow-up and controlled studies should be required for elucidating the effect of sirolimus on BKVAN. Functioning nephron mass is a determinant of the graft function of kidney transplant recipients. The graft kidney volume and its weight have been reported to be surrogates of the nephron mass. To investigate the impact of the ratios of the surrogates to recipient body surface area (BSA) and body weight on the graft function within 6 months post-transplantation, we measured the graft kidney volume, using computed tomography with 3-dimensional reconstruction before transplantation, and measured the graft kidney weight during surgery. Ninety-four cases of live donor kidney transplants were included in this study. The graft kidney volume/recipient BSA ratio was correlated with the glomerular filtration rate (GFR) of recipients at 1 month and 6 months posttransplantation (r = 0.416, p < 0.001 and r = 0.381, p < 0.001, respectively). We found a difference in the graft function between recipients with a graft kidney volume/recipient BSA ratio ofî € A90.9 ml/m2 and those with a ratio of <90.9 ml/m2 (p < 0.001). Multivariate analysis demonstrated that the graft kidney volume/recipient BSA ratio and donor age are independent predictors of recipient GFR at 1 and 6 months post-transplantation (p < 0.05). During living donor and recipient matching, both the potential volume of the donated kidney and the body size of recipient should be considered. Objectives: To compare transplant outcomes between expanded criteria donor kidney and standard criteria donor kidneys. Methods: All adult renal transplants from deceased donors performed in Saudi Arabia over a 24-month period were included. Donor and recipient factors were recorded, and their effects on outcomes with expanded criteria donors and standard criteria donor kidneys were compared. Standard criteria donor kidneys were further subgrouped into optimal and suboptimal groups, and outcomes were compared. Results: A total of 280 deceased-donor kidney transplants were performed during the study period. Of these, 61 (21.8%) involved expanded criteria donor kidneys. Cold ischemia time and prevalence of delayed graft function were similar between expanded criteria and standard criteria kidneys (p = 0.7 and p = 0.8) Graft survival rates at 2 years were also similar (93.3% vs. 94.6%; p = 0.8). Delayed graft function exerted a negative effect on 2-year graft survival in both the expanded group (hazard ratio, 4.9; 95% CI 3.2-7.5; p = 0.001) and the standard group (hazard ratio, 4.6; 95% CI 3.24-7.5; p = 0.001). No difference was found between the 2 standard criteria subgroups with respect to serum creatinine value at the end of follow-up (p = 0.8), delayed graft function prevalence (p = 0.5), or 2-year graft survival (p = 0.8). The only independent factor affecting graft survival was delayed graft function (p = 0.001). No independent effect was seen for expanded criteria donor versus standard criteria donor, donor serum creatinine level, or recipient age. Conclusion: Similar short-term outcomes were found for the expanded criteria and standard criteria kidney recipients. Delayed graft function was associated with significant risk of graft loss in both groups, with decreases in 2year graft survival of 33.3% and 18.3%. No difference was seen between the two subtypes of standard criteria donor kidneys. TMA is a serious complication of renal transplantation (Tx) and is mostly related to the prothrombotic effect of CNI. A subset of TMA (29-38%) is localized only of the graft. A young woman suffering from APKD underwent Tx. After 2 months she showed renal deterioration (Scr from 1.9 to 3.1 mg/dl), without hematological signs of SEU; LDH transient increase was detected. Renal biopsy showed TMA: temporary withdraw of TAC and plasmapheresis was performed. The renal function recovered and stabilized (SCr 1.9 mg/dl). By thrombophilia screening, we find a mutation of Factor V Leiden. An old man affected by APKD underwent Tx, with prolonged DGF; a first biopsy showed NTA, but a second biopsy in 35°day show TMA; no signs of SEU was detected. Again we observed only a light increase of LDH. The TAC was halved and LDH levels were observed: LDH levels normalized within 10 days and renal function improved (Scr 2.9 mg/dl). By thrombophilia screening, we find a mutation of Prothrombin gene. Renal biopsy only clarifies the diagnosis of TMA localized only to the graft, but pay attention to light increasing level of LDH. Mutation of genes encoding factor H or I, anticardiolipin antibodies, vascular rejection, cytomegalovirus or parvovirus B19 infection are proposed by some to trigger TMA, but we detected mutations of Factor II and Factor V Leiden, as facilitating conditions for TMA.  Background: Patients with high Body Mass Index (BMI) are at higher risk of postoperative complications. We report the postoperative complications rate in different BMI groups immediately post renal transplantation. Methods: A total of 118 renal transplant recipients (mean age 50 AE 13 years old, 69 males) (between October 2011 and September 2012) were included. Patients were grouped according to their BMI into three groups (Group 1: <25, Group 2: 25-30 and Group 3: >30). Complications were defined as a single occurrence of an unexpected postoperative finding such as infection, haematoma, lymphocoele and urinary leak. Chi-square and Fisher Exact tests were used to compare groups. Results: Postoperative complication rate in all recipients was 30%. Complication rate was 33%, 24% and 40% for group 1, 2 and 3 respectively. Perinephric collection including lymphocele and haematoma was the commonest in groups 1, 2 and 3 (17%, 8% and 25% respectively). No significant differences in the post-transplant complications incidence between group 1 and 2 (p = 0.31), group 2 & 3 (p = 0.19) and group 1 and 3 (p = 0.59). Conclusions: While the high BMI group had the highest rate of complications, the difference was not statistically significant. Further analysis of a larger population is needed. Background: Calcineurin inhibitor is a mainstay of immunosuppressive therapy in kidney transplantation patients for decades. However, with recent advance in transplant pathology, physicians became more aware and cautious with calcineurin inhibitor related nephrotoxicity. Studies from other researchers showed that complete elimination of calcineurin inhibitor will incur more acute graft rejection. Therefore, in this preliminary study, we tested how low calcineurin inhibitor can be reduced to avoid nephrotoxicity without increase in acute rejection incidence, while enhance graft function. Method: Renal transplant recipients within first 1 year with eGFR >40 ml/min and urine total protein <800 mg/day were included in the study. Between month 3 to month 12 post transplantation, patients were recruited and everolimus 1.5 mg/day were added. Their calcineurin inhibitor and mycophenolic acid were reduced by 50% overnight. Calcicineurin inhibitors were further reduced to either cyclcosporine 25 mg/day or tacrolimus 0.5 mg/day within 2-4 weeks. Their prednisolone was kept at 5-2.5 mg/day. Renal function, urine protein and biochemistry were monitored monthly. The trough levels of everolimus were kept between 3 and 8 ng/ml. Result: Fifteen patients (N = 15) were included in this study. At the end of one year follow up, their eGFR increased by 7.1 AE 0.5 ml/min, while no acute rejection was noted. Urine daily total protein mildly increases by 118.6 AE 81.8 ml/min. There is no significant change in liver function, sugar, hematocrit, platelet and leukocyte count. Conclusion: Ultralow dose of calcineurin inhibitor combined with everolimus is an effective regimen for renal transplant recipients. This approach could improve graft function safely without increase in acute rejection incidence.  Delay in the diagnosis and treatment of bladder outlet obstruction (BOO) in male patients due to urethral stenosis and benign prostatic hypertrophy affects the graft function. Between 2004 and 2012 359 male kidney transplantation were performed and patients are evaluated by urologist. The immunsupressive regimen were triple immunsuppression, tacrolimus or cyclosporine,mycophenolate mofetil and corticosteroids and as a surgical technique extravesical ureteroneocystostomy using double j were performed in all cases and double j removed after 3 weeks. All patients underwent a complete urological assessment prior to surgery and posttransplant. Lower urinary tract symptoms (LUTS) were evaluated by urologist using internationel prostate symptoms score (IPSS), uroflowmeter for maximum urinary flow rate (Q max) and ultrasonography for postvoiding residual urine. If the Q max lower than 15 ml/s urethrography was performed. IPSS score was 9.6 AE 3.6 in patients without BOO and higher with 20 AE 4.2 in patients with BOO. The Q max also was lower Hemorheologic alterations (HA) are present in uremic patients (UP) undergoing dialysis (HD), but no definitive data are available on transplant patients (TP). We compared plasma viscosity (gP), blood viscosity at low (gS1) and high (gS200) shear rate, erythrocyte aggregation index (EAI), blood yeld stress (s0), erythrocyte-stiffness as Taylor's factor (Tk) and elastic modulus (G') in 47 healthy volunteers (controls), 90 UP pre and post-HD and 108 RT. Results are presented in table 1 and figure 1 : RT compared to HD promotes a normalization of most parameters while Tk and G' are worsened. Differences in antirejection drugs do not seems to affect most of hemorheologic parameters. RT improves uremia-induced HA while results on Tk and G' could support an endothelial injury with related chronic organ damage. Background: Damaged renal grafts were estimated to 11% in UK. The study determine feasibility, reliability of the integrated application of tele-radiology and the tele-pathology (virtual benching) evaluation of the renal graft using Telemedicine Systems (TS). Material and methods: The study was based on a sensitivity-specificity analysis after: a. the development of a experimental TS, b. a simulating comparison of tele-radiological evaluation of the graft on 15 MR abdominal images with the classic film evaluation by two examiners, c. the virtual benching of the renal graft by 26 specialists based assessing damages and lesions of the projected renal grafts. Results: (i) There was no statistically significant difference in the diagnostic performance between the two examiners. Their sensitivity and specificity rates, referred to renal injuries and lesions, were 100%. (ii) The virtual benching defined damages and lesions of the renal graft with a sensitivity of 96.2%. (iii) The overall remote evaluation of the renal graft has a sensitivity of 96.7% and a specificity of 100% (95% confidence intervals). Inversely to UGT1A9 98T allele homozygotes (n = 231), in minor alleleC carriers (n = 12) lower filtration rate and proteinuria presented within 2 weeks after engraftment and remained throughout observation (1, 2, 3, 6, 12 months, 2, 3, 5 and 8 years after transplantation), differences statistically significant for eGFRC&G (p < 0.001) and proteinuria (p < 0.067). Minor allele effect on filtration was independent from delayed graft function, temporary hemodialysis was necessary in 32.7% alleleC carriers and 30% of common allele homozygotes. No differences in biopsy-confirmed rejection and graft loss were found. Association of transplanted kidney dysfunction with presence of UGT1A9 98T>C polymorphism maybe of more complex nature than its role in mycophenolic acid metabolism and prevention of immunological injury. Thorough examination of its impact on early post-transplant course is tempting. Background: Donor organ quality is one of the most significant factors for kidney graft function. Donor kidney "0" biopsy is a "gold" standart for evaluation of kidney graft quality. The aim of this study was to evaluate the impact of the initial kidney graft condition on the post-transplant results. Methods/materials: This retrospective study include all consecutive kidney transplantations (n = 90) performed in the single transplant center in the time period from January 1, 2004 till November 30, 2007 , where donor kidney "0" biopsy results were available. Information about rates of delayed graft function (DGF), acute rejection (AR), recipient serum creatinine levels at the time of discharge from the hospital and 5 years after transplantation, graft losses and recipient deaths within 5 years were summarized. Results: According to Banff classification 97% (n = 87) of all biopsies were informative. Interstitial sclerosis higher than 15% was observed in 21% (n = 18) and was associated with increased donor age (p = 0.026) as also with increased duration of recipient stay in the hospital after transplantation (p = 0.036). Presence of glomerular sclerosis was observed in 23% (n = 20) and was associated with increased donor age (p = 0.014), increased duration of recipient stay in the hospital after transplantation (p = 0.017) and with increased risk of development of DGF (p ≤ 0.001). Presence of both interstitial and glomerular sclerosis was associated with increased recipient serum creatinine level at the time of discharge from hospital (p = 0.019), increased risk of development of AR (p = 0.029) and DGF (p ≤ 0.001). Presence of interstitial or glomerular sclerosis did not affect graft or recipient five-year survival after transplantation. Conclusion: Kidney "0" biopsy is an investigation method with high informativity that can provide information on graft chronic changes and for prediction of the development of DGF, AR and for kidney graft function in early posttransplant period. Alex Vesey 1 , Kerrick Hesse 2 , Emma Aitken 1 , Marc Clancy 1 1 NHS Greater Glasgow & Clyde; 2 Glasgow University Introduction: Due to the rising disparity between demand and availability, organs from expanded criteria donors (ECD) are increasingly used. The purpose of this study was to report outcomes in recipients of ECD renal allografts from a single centre. Methods: This was a retrospective analysis of prospectively gathered data from a single centre for all renal transplants performed between 2001 and 2010 inclusive. The primary outcomes were 4-year graft and patient survival. Kaplan-Meier survival analysis was undertaken with patients placed into four strata (SCD/DBD, ECD/DBD, SCD/DCD, ECD/DCD). Differences in recipient demographics, cold (CIT) and warm (WIT) ischaemic times and pre-transplant length of time on dialysis (surrogate of chronic illness) were also compared using appropriate statistical tests. p < 0.05 was defined as significant. Results: Of 730 renal transplants were performed. There was a significant difference in graft survival between groups (logrank for trend, p = 0.03) with ECD organs doing worse than SCD organs (Fig. 1) . For patient survival, there was a difference that did not achieve significance (p = 0.12). SCD/DCD organs had a better outcome than SCD/DBD organs. CIT was significantly shorter in SCD/DCD organs compared to SCD/DBD organs (p = 0.0001) but there were no differences in WIT (p = 0.19), time on dialysis (p = 0.09), recipient age (p = 0.30) or sex (0.74) between these two groups. Conclusions: As is already known, we have shown that ECD organs have a poorer outcome than SCD organs. SCD/DCD organs had the best outcomes. This is likely to be accounted for by shorter CIT as these organs are allocated locally. DBD organs also do not benefit from continuous ex-vivo perfusion preservation. Our study's main limitation is the number at risk in the ECD/DCD group; the graft survival curve was heavily influenced by a single death at 423 days. We had previously developed a Rapamycin-based sequential immunosuppression protocol for kidney transplantation comprising two phases: de novo Rapamycin (R) + cyclosporine A (CyA) + prednisolone (P) for three months, followed by switching to R + S+ mycophenolate mofetil (MMF). The two-year outcomes of patients on this protocol (Group A) showed a better graft survival compared to those on a conventional protocol comprising CyA + MMF + P (Group B) (Barsoum RS, et al. Exp Clin Transplant. 2007; 2:649-57 (s) Objective: Compare renal function and the incidence of CMV in KT of DD undergoing induction with thymoglobulin and early conversion from tacrolimus (TAC) to everolimus (EVR). Methods: A prospective and randomized study with low risk KT of DD. The initial immunosuppression consisted of thymoglobulin induction, prednisone and mycophenolate sodium and sequentially TAC. The patients were randomized to two groups: TAC or EVR. Between the 2nd and 5th week those randomized to EVR were converted during a 3-day overlap with TAC. The diagnosis of CMV was performed by a positive antigenemia of 10 or more cells/ 400 000 neutrophils. Renal function was assessed by serum creatinine (sCr). Results: The analysis included 31 patients, 16 in Tac group and 15 in EVR. Conversion to EVR occurred at a median of 30 days after the Tx. The incidence of CMV was 87.5% and 73.3% and the median time to diagnosis was 36 and 32 days after the Tx, respectively for TAC and EVR (NS). The mean sCr for EVR and TAC groups were respectively 1.6 and 2.6 mg/dl (p = 0.03); 1.3 and 1.6 mg/dl (NS) and 1.3 and 1.4 mg/dl (NS) for 30, 180 days and 1 year. There were six episodes of acute rejection after discharge (EVR = 4 and TAC = 2). Only two episodes were considered more severe: both in EVR group. The first was reconverted to TAC regimen, and the second lost the graft due to superimposed neoplasia and impossibility of treatement. Conclusion: Both strategies of immunosuppression showed comparable safety and renal function, however EVR group did not show significant reduction in the incidence of CMV. We believe that this reduction should most likely be achieved through the conversion even earlier than the currently practiced. Tahir Aziz, Ejaz Ahmed, Fazal Akhtar, Rubina Naqvi, Anwar Naqvi, Adib Rizvi Sindh Institute of Urology and Transplantation Introduction: The aim of this study was to evaluate the results of renal transplant in patients with Alport Syndrome vis a vis patient and graft survival, incidence of anti GBM and causes of graft failure. Material and method: Between 1985 and 2012 we performed 3700 live related renal transplants SIUT. Out of these a total of 15 patients with Alport Syndrome underwent renal transplant with male: female ratio of 14:1. The mean age of the recipients was 39 years. Rejection episodes, anti GBM nephritis and other causes of graft failure were assessed in these patients. Results: Patients with Alport Syndrome were compared with control group of 100 renal transplant recipients. One (7%) patient with Alport Syndrome and 10 (10%) in control group experienced delayed graft function. Acute rejection was confirmed in 3(18%) patients by graft biopsy in Alport Syndrome while control group had 17 (17%) rejection episodes and classic treatment yielded relative response. However two grafts in Alport patients failed after 24 and 36 months after renal transplantation. On pathologic examination no specific finding of anti GBM nephritis was found. Incidence of Cyclosporine toxicity and urinary tract infection were similar in both groups. Two patients returned to dialysis in patients with Alport Syndrome. The 1, 3 and 5 years graft survival rate in patients with Alport Syndrome was not different from those with the control group. Conclusion: Inspite of risk of anti GBM nephritis in patients with Alport Syndrome, it seems renal transplant can yield favorable results and anti GBM nephritis is not a common entity. Paolo Girotti, Silvio Nadalin University Hospital Background: Single kidney transplantation (sKTx) in children from small pediatric donors (age ≤5 years and weight ≤10 kg) was often performed with reluctance because of multiple factors influenced an high rate of early/long term post-operative complication and graft disfunction (DGF, PNF): -insufficient nephron mass -increase of incidence of acute cellular rejection -increase vascular and urinal complications Therefore small kidneys from pediatric donors are usually transplanted en-block also in children. Background: Neutrophil gelatinase-associated lipocalin (NGAL) has emerged as a new, noninvasive diagnostic tool for acute kidney injury. It is known that NGAL associates with delayed graft function; the association has been shown in urine and serum samples taken on the day of, and very soon after, transplantation. But little is known about the correlation NGAL with kidney function in patients with slow graft function. The aim of our study was to examine whether serum NGAL levels correlates with the level of kidney function in patients with slow graft function. Methods: Nineteen subjects with slow graft function were included in this study. Serum NGAL levels were measured at 14th and 21th day after transplantation in patients with slow graft function. And serum creatinine and estimated glomerular filtration rate (eGFR; MDRD equation) were measured at 2 and 3 month after transplantation. Correlation analysis was performed with this data. Results: The correlation coefficient between serum NGAL levels (posttransplant 14th day) and serum creatinine of post-transplant 1st, 2nd, 3rd month were 0.476, 0.547, 0.481. And those between NGAL (post-transplant 21th day) and serum creatinine of post-transplant 1st, 2nd, 3rd month were 0.310, 0.364, 0.311. The spearman correlation coefficient between serum NGAL levels (post-transplant 14th day) and eGFR of post-transplant 1st, 2nd, 3rd month were À0.204, À0.0412, À0.242. And those between NGAL (posttransplant 21th day) and eGFR of post-transplant 1st, 2nd, 3rd month were À0.076, À0.225, À0.114. The NGAL levels showed a positive correlation with serum creatinine and negative correlation with eGFR but it's statistically association is not strong. Conclusion: The serum NGAL levels on 2nd, 3rd week after transplantation may correlate with graft function up to 3 month post-transplant in patients with slow graft function. But the association is not strong, large-scale study will be needed. Laura Tariciotti 1 , Daniele Sforza 1 , Laura Fazzolari 2 , Alessandro Anselmo 1 , Giuseppe Iaria 1 , Giuseppe Tisone 1 1 University of Rome "Tor Vergata"; 2 University of Rome Background: Kidneys from expanded-criteria donors may be susceptible to calcineurin inhibitor (CI)-mediated vasoconstriction and nephrotoxicity. In the early post-transplant phase, using CI may prolong ischemic injury; in the long term, chronic CI nephrotoxicity is of greater concern. To avoid these consequences of CI in kidneys from marginal donors, CI-free protocols have been introduced for maintenance immunosuppressive therapy. A CI-free protocol of basiliximab induction, sirolimus, mycophenolate sodium (MPA) and steroids has been adopted at our centre in recipients of dual kidney transplantation (DKT) from marginal donors. Methods: Ten DKT performed since February 2009 on CI-free immunosuppression, retrospectively analysing patient/graft survival, surgical and medical complications, rejection episodes and renal function. Results: No deaths or graft losses occurred after median follow-up of 30 months. Incidence of acute rejection was 20% (n = 2). Delayed graft function (DGF) was recorded in 20% of patients (n = 2). Renal function: patients presented a median Serum-Creatinine of 106 lM at one month, of 97 lM at 6 months and of 93 lM at 1 year. Conclusions: After DKT from EDs, CI-free immunosuppressive regimen including basiliximab induction, sirolimus, MPA and steroids provides excellent results, with low DGF rate and good renal function. Background: Development of atherosclerosis is accelerated in kidney transplant patients. Impaired metabolic pathways have complex effect on the arterial wall which can be measured by non-invasive techniques. Only few data are available on the change of stiffness parameters in the postoperative course, so in this study we analysed the stiffness parameters of kidney transplant recipients during the perioperative period. Patients and methods: Seventeen successful primary kidney transplant patients with uneventful postoperative period (seven female, 10 male; 46.16 years A AE 12.19 years) were involved in our short-term prospective longitudinal study. We analysed the correlation between non-invasively assessed stiffness parameters (pulse wave velocity [PWV], augmentation index [Aix], pulse pressure [PP]), Systolic and Diastolic Area Index (SAI, DAI), Diastolic Refl ection Area (DRA) ankle-brachial index (ABI) and laboratory parameters (creatinine, glomerular filtration rate, urea, haemoglobin, Creactive protein). Stiffness parameters were measured with a TensiomedTM Arteriograph. These parameters were assessed before the transplantation, 24 h, 1 and 2 weeks after surgery under standard conditions. Results: We found that creatinine (p = 0.0008), C-reactive protein (CRP) (p = 0.006) serum levels decreased, and glomerular filtration rate (GFR) increased significantly (p = 0.0005). We revealed that PWV (p = 0.0075) and AIx (p = 0.013) improved significantly. There was no significant change concerning SAI and DAI. DRA had sinigficant correlation with SAI and DAI. There was no significant change in case of ABI, PP and the other monitored parameters. Conclusions: Along with the available data in the literature, our findings suggest that kidney transplantation has a positive effect on the arterial function. Improvement can be detected non invasively with Arteriograph in the early postoperative period. Kazuo Mizutani 1 , Ryohei Hattori 1 , Tsuneo Kinukawa 2 , Momokazu Gotoh 1 1 Nagoya University Graduate School of Medicine; 2 Urology, Chukyo Hospital Backgound: Recently, many studies showed effects of HAL antibody to kidney transplants. However, longer behavior and impact of HLA antibody were not clear. In this study, the role of HLA antibodies in allograft rejection was examined utilizing a unique resource of sera collected annually and stored over a 23-year period from patients with rejected or retained grafts. Methods: We selected 50 transplant patients who received kidney from 1984 to 1999, and whose serum samples were available annually. During 23 years, 32 patients were rejected their grafts and 28 had functioning grafts. Their samples were tested for HLA Class I and Class II antibodies by flow cytometry, ELISA, or cytotoxicity. For analyzing specific HLA antibodies, we used Labscreen Single antigen (One Lambda). Results: HLA antibodies were found in 81% of patients who rejected grafts, compared to 50% with functioning transplants (p < 0.05). In addition, even if living-related transplants had good kidney function for a longer time, some living-related patients gradually developed HLA antibodies with stable functioning grafts. Conclusions: In conclusion, patients who rejected transplants had HLA antibodies more frequently than those with functioning grafts. These antibodies found in the peripheral circulation, and their association with failure is consistent in long period. Background: Transplant renal artery stenosis (TRAS) is associated with allograft dysfunction and inferior allograft survival. This study reports a singlecentre experience on outcomes following intervention for TRAS. Methods: All patients with TRAS confirmed on Intra-Arterial Digital Subtraction Angiography from 2005 to 2012 were retrospectively reviewed. The type of intervention, complications and allograft function and survival were recorded. Results: Of 137 patients with confirmed TRAS, 113 (82.5%) were treated with angioplasty and stent, 6 (4.4%) angioplasty alone and 18 (13.1%) had no intervention. The overall complication rate in the intervention group was 15.1%, the most common being stent malposition (4.2%). Twelve (10.6%) stented patients developed a subsequent in-stent stenosis. There was a significant improvement in graft function in the treated TRAS group from 2 months post procedure (p = 0.02) which was sustained at 1 year (p = 0.007) and 3 years (p = 0.013). The presence of TRAS was an adverse prognostic factor for allograft survival (p = 0.014). Furthermore, allograft survival was better in the treated TRAS group compared to the non-treated group (p = 0.039). Objectives: Recent data suggest that mild to moderate obesity may be associated with increased survival in hemodialysis; on this other hand, it may be associated with more complications post-kidney transplant. The aim of the study was to evaluate the influence of the BMI on the rate of posttransplant complications and on graft survival. Methods: We retrospectively analysed data on the 208 patients who underwent kidney transplantation at our hospital between January 2008 and December 2010. We evaluated the BMI at transplantation, length of the postransplant hospitalization, number of acute rejection episodes, episodes of delayed graft function (DGF), finding of proteinuria 12 months postransplant, development of new onset Diabetes mellitus after transplant (NODAT) and graft (and patient) failure. Obesity was defined as BMI ≥ 30 kg/m 2 at transplantation. Results: Nineteen obese and 189 non-obese patients received a kidney allograft during the study period. The average follow up period was 36.6 AE 13.5 months. Obese patients were elder (p < 0.001) and had more frequently coronary artery stents (p = 0.018). Using univariate analysis, an elevated BMI was positively correlated with longer admission period posttransplant (r = 0.16, p = 0.02), more frequent finding of DGF (r = 0.15, p = 0.03), higher frequency of proteinuria (r = 0.16, p = 0.03) and the development of NODAT (r = 0.20, p = 0.005). The BMI had no correlation with the development of acute rejection, but had reduced graft survival (log rank = 5.02, p = 0.02). Using Cox regression, obesity was an independent predictor of graft failure (HR: 4.45, CI: 1.38-14.39, p = 0.013) adjusting for age, presence of a coronary stent and presence of acute rejection. Conclusion: An elevated BMI was associated with a longer admission period posttransplant, higher chance of DGF, proteinuria and NODAT, but had no influence in the number of acute rejection episodes. Obesity was also associated with reduced graft survival. Background: Delayed renal graft function has negative effect on both early and late posttransplant results, influencing also graft and patient survival. The aim of this study was to analyze factors associated with graft losses and patient deaths during the five years after kidney transplantation in patients with delayed and immediate graft function (DGF and IGF, respectively). Methods/material: Study included 248 consecutive deceased donor renal transplantations from performed in a single centre between January 01, 2004 to November 30, 2007, available for 5-year follow-up. All cases were divided according to the presence of DGF, defined as the need for at least one dialysis during the first posttransplant week. Donor and recipient transplantation factors were analyzed for association with graft losses (death-censored) and patient deaths during the follow-up. Results: DGF was observed in 53 cases (21.4%). Factors, associated with graft loss and patient death in kidney transplantation showed differences between DGF and IGF: graft losses in DGF group (n = 6) were significantly associated with donor age, donor female gender, recipient male gender, female donor kidney into male recipient, and in IGF group (n = 26)with donor age, recipient age, nontraumatic donor brain death diagnosis (p < 0.05 for all), as also trends toward significance observed for increased donor serum creatinine in DGF (p = 0.107) and for increased donor body mass index in IGF (p = 0.059). Patient deaths in DGF (n = 14) were significantly associated only with recipient age, but in IGF (n = 40)with recipient and donor ages, nontraumatic donor brain death diagnosis (p < 0.05 for all). Surgical complications following living-related kidney transplantation (LRKT) are known to compromise the immediate graft survival. In addition, evidence from earlier studies suggests that long term survival might be impaired by early surgical complications. Aim of the present study was therefore the investigation of the interrelation between complications requiring re-surgery and graft-as well as recipient survival. Prospectively registered data of 317 consecutive LRKTs between 07-1985 until 11-2011 were analyzed. Besides graft-and patient survival and the incidence of surgical complications, data of age, BMI, waiting time on dialysis, immunosuppression, immunological prerequisites (HLA-mismatch, panel-reactive antibodies, rejections, BANFF-classification) were determined. Early graft function was monitored according to creatinine serum level development within 12 months and by the incidence of early graft dysfunction. Data assessment included univariate and multivariate (Cox-Regression) statistical testing in terms of the study aim. Graft-and patient survival ranged between 93/92% (1 year), 89/91% (3 years) and 84/91% (5 years), respectively. The overall percentage of complications with the consequence of surgical revision was 17.5%, with a majority of revisions required due to lymphoceles (30%), ureter complications (20%) and hematoma formation (20%) while normal graft function. However, early graft dysfunction was significantly associated with the event of surgical revision. Log rank analysis identified surgical complications to diminish graft-(p = 0.019) as well as recipient survival (p = 0.008). The observation was reconfirmed by coxregression for patient-, but not for graft survival. However, the effect of a high degree HLA (DR) mismatch on patient survival was stronger than the impact of surgical complications. Complications requiring redo surgery impact long term survival following LRKT. A complication-free post-surgical result after LRKT determines. Magdalena Jankowska, Alicja De z bska-Slizie n, Bolesław Rutkowski Medical University of Gdansk, Poland Background: Acquired cystic kidney disease (ACKD) is a complication of chronic kidney disease that may influence outcome after organ transplantation. We describe prevalence and we investigate risk factors for ACKD among patients registered on the kidney transplant waiting list. We hypothesized that high parathyroid hormone (PTH) levels influence the ACKD incidence, because PTH is involved in cyst development in other kidney cystic diseases. Methods: We analyzed medical histories of 138 patients placed on kidney waiting list in our center. Of 100 patients met inclusion criteria and underwent further analysis. ACKD was diagnosed in patients having at least three cysts in each kidney in the ultrasound examination. We analyzed influence of age, gender, the time since diagnosis of the kidney failure, BMI (body mass index) and PTH levels on ACKD occurrence. We used t-Student and Pearson's chisquared tests for statistical analyses. Results: Thirteen percent out of 100 patients fulfilled criteria for ACKD. ACKD prevalence was influenced by the time since diagnosis of the kidney failure (p = 0.01) and by PTH values. ACKD did not occur in patients registered on the waiting list preemptively. We divided subjects into two groups according to PTH levels. Group 1 had iPTH below or equal 300 pg/ml (n = 46) and group 2 above 300 pg/ml (n = 54). Mean iPTH values in both groups were: 128 and 659 pg/ ml, respectively (<0.001). Groups were comparable in respect of age, gender and the time since diagnosis of kidney failure. The incidence of ACKD was higher in a group with higher PTH values (p = 0.002). No case of ACKD was noted in patients with PTH below 300 pg/ml. Conclusions: The prevalence of ACKD among patients registered on the kidney transplant waiting list was 13%. Patients placed late on the waiting list and those with increased PTH levels needs careful attention to prevent complications of ACKD after transplantation. Background: IgA nephropathy (IgAN) is one of the most common glomerulopathies, causing an end-stage renal disease requiring kidney transplantation in 3-6% of cases. Risk of IgAN post-transplant recurrence is up to 60%; however, immunosuppression could be related to the development of "de novo" tumors (DNT). In renal graft recipients, 4% of patients experience a DNT. Among DNT, development of a renal cell carcinoma (RCC) involving the renal graft is anecdotic (0.5% of cases). Case report: A case of a 50-year-old Caucasian man transplanted in 1987 for an end-stage renal disease caused by an IgAN is reported. The graft was from a living donor. Immunosuppression regimen was based on cyclosporine, azathioprine and steroids. After 25 years of uneventful follow-up, the patient developed a generalized edema and was hospitalized. At blood tests, serum creatinine was 4 mg/dl and a marked proteinuria was reported (18 g/24 h). No renal masses were observed at ultrasounds. A renal biopsy was performed, showing granular deposits of IgA (+++), IgM (++), C3 (+), kappa (+) and lambda (++) light chains in the mesangium: IgAN recurrence was diagnosed. Drug regimen was modified with the intent to treat both the IgAN recurrence and the proteinuria: however, the status of poor renal function persisted. Six months later, a new ultrasounds control was performed, showing three lesions at the level of the allograft. A CT scan confirmed the diagnosis. A renal biopsy showed of a papillary renal cell carcinoma type 1. The patient underwent the explantation of the allograft. The tumor was confirmed at pathology on the specimen. The post-operative course was uneventful, and the patient is still alive after a period of 6 months, having restarted the substitutive therapy with haemodyalisis. IgAN recurrence after transplant is common, while development of a tumor on the allograft is anecdotic: however no data exist in Literature about a contemporaneous presentation of both these pathologies. Alberto (Eurotransplant Report) . Along this lengthy period on dialysis, comorbidities arise and progress conditioning patient life expectancy. Nonetheless, waiting time is not commonly one of the primary determinants in most organ allocation scores. We aimed to explore its possible influence on graft and patient survival. Methods: All first adults kidney transplants performed in Andalusia, Spain, were prospectively included in the Andalusian Kidney Transplant Registry from 2000 to 2010. Descriptive statistics and survival analysis (Cox regression, Kaplan-Meier curves) were performed. Waiting time was categorized in quartiles. Results: Of 3194 first kidney transplants were performed in the decade; median waiting time was 1.9 year, although a continuous increase was observed ranging from 1.6 year in 2001 to 2.3 year in 2010 (p < 0.01). In 2001, 20% of the cohort had to wait more than 48 months for transplantation; in 2010 it increased up to 33%. After adjusting for age, sex, diabetes and HLA mismatch, time on dialysis was independently associated to higher mortality; relative risk was 1.6 for quartile 3 (1.9-3.6 year on waiting list; p < 0.01) and 2.1 for quartile 4 (>4 year; p < 0.001); reference, quartile 1. Furthermore, time on dialysis was also predictor for graft loss when not censored for death, but this association was lost when censoring for it. In conclusion, dialysis patients on waiting list over 2 years are at higher risk for graft loss and for increased mortality. Waiting time should have more relevant consideration in allocation schemes. Ninoslav Ivanovski, Elka Masin-Spasovska, Irena Rambabova-Busljetic, Igor Nikolov, Aleksandar Sikole University Clinic of Nephrology, Medical Faculty Introduction: Chronic use of CNI in transplant medicine is responsible for nephrotoxicity and graft loss during long-term follow-up. The early and late switch from CNI to m-TOR inhibitors based regimen have beneficial effect on long term graft function, post transplant malignancies and cardiovascular morbidity. Here we presented the long term follow up of kidney transplant recipients treated with Sirolimus based immunosuppression with a full avoidance of CNI after the surgery. Methods: In retrospective case control study, 20 first renal transplant recipients with sirolimus based immunosuppressive therapy with MMF and Pred and without any CNI were analysed during the follow up of 96 months. The mean age of the patients was 55.07 years. The prevalence of male recipients was 57%; the overall mean weight, 64 kg (range 51 to 95). Sirolimus dose was adjusted according to the blood level kept between 6 and 10 ng/ml. The actual creatinine, proteinuria, HBA1C, TGL, cholesterol and glycaemia were analysed after 96 months of floowup. The results were compared with 20 CNI based patients with comparable age (58.2 years) and mean follow up of 92 months. Results: After the follow up the m-TOR group has a better renal function compared with CNI group (GFR MDRD 57.61 vs. 49.51 ml/min, p < 0.01), better HbA1C (5.71 vs. 6.04%, p < 0.05). The cholesterol concentration was higher in m-TOR group (5.66 vs. 4.96, p < 0.05) as well as triglycerides (1.9 vs. 1.47) There was no difference in Glycaemia (5.3 vs. 5.7, p = ns) and actual creatinine 135.6 vs. 138.6, p = ns) and proteinuria (0.7 vs. 0.61 g/24 h, p = n.s.) Conclusion: The authors confirm the superior long term graft function in recipients with m-TOR based regimen and worse control of Cholesterol and triglycerides. Surprisingly there was no difference in proteinuria, glycaemia and actual cretainine. The authors conclude that m-TOR based regimen could be useful also from the very beginning after the surgery with complete avoidance of CNI in imunosuppresion. Background: Expanded criteria deceased donor (ECD) renal transplantation has been established as a framework to increase the donor pool. ECD donors are those aged ≥60 or aged 50-59 with two of the following factors: hypertension, death from cerebrovascular cause or terminal serum creatinine >1.5 mg/dl. Our use of organs from deceased donors aged ≥70, which we term super-ECD (sECD), has recently expanded. Data are limited for outcomes from such donors, and the impact on service provision is unclear. Method: We analysed results for all deceased donor (DD) kidney transplants performed at our centre in 2012. Variables included graft loss, 3 month eGFR (MDRD), biopsy rate and length of inpatient stay (LOS). Results: Of 114 DD transplants, 51% were ECD and 17% of all donors were aged ≥70 (sECD). Primary non-function rates were: 1.8% for standard criteria donors (SCD), 5.1% for ECD aged <70 years, and 10% for sECD, and allcause graft loss rates at 3 months were 5.4%, 7.7% and 10% respectively. Donor age negatively correlated with eGFR (r = À0.44, p < 0.001, Spearman test). ECD recipients had a lower median eGFR than SCD recipients (34 vs. 48 ml/min/1.73 m 2 , p = 0.003, Mann Whitney test), however there was no difference in median eGFR between sECD and ECD <70 years (30 vs. 36, p = 0.32, Mann Whitney test). Delayed graft function (DGF) was 32% in the SCD, 50% in ECD <70 years and 58% in sECD. There was no significant difference in LOS between SCD, ECD <70 years or sECD. There was weak positive correlation between donor age and number of biopsies within first 3 months (r = 0.21, p = 0.03, Spearman test). Conclusions: Although the sample was small, these data show that sECD renal transplantation gave early functional outcomes that are not significantly different from other ECD donors. Whilst length of stay was not significantly increased with older donors, there was a trend towards increased biopsy rate, possibly due to the higher DGF. These data support continued but careful use of sECD organs. Introduction: Both the KDIGO and KDOQI guidelines for haemodialysis patients recommend a target haemoglobin (Hb) ≥11 g/dl. Patients with lower Hb should be considered for Erythropoetin and iron therapy. However, this treatment is quite expensive and unaffordable in certain parts of the world. In addition, most of our haemodialysis patients frequently receive only two dialysis sessions per week. Hence, it is not unusual to find that patients with ESKD frequently have Hb <11 g/dl. Offering renal transplantation to these patients is the only way to improve their health and well being. The aim of this study was to review the Hb level in patients undergoing kidney transplantation and the need for blood transfusion during the perioperative period. The primary end point was anaemia-related cardiovascular events. Secondary end point was the episodes of acute rejection. Methods: Data of patients who underwent kidney transplantation during 2012 and had Hb < 11 g/dl were reviewed. Preoperative Hb and Hb on discharge, adverse cardiovascular events and episodes of acute rejection were recorded. Results: The cohort consisted of 23 patients. The mean age was 28.9 years (range: 19-55). The mean pre-operative Hb was 10.13 g/dl (6.1-10.9). Eight patients needed blood transfusion during the perioperative period. The mean number of blood units transfused was 2.88 (range: 2-6). The mean Hb at discharge was 7.8 g/dl (range: 5.5-11.5). None of the patients developed adverse cardiovascular event during the perioperative period. Three patients who received blood transfusion developed acute rejection (35%). Conclusion: Offering renal transplantation to ESKD patients with low Hb was not associated with adverse cardiovascular events. The frequency of acute rejection episodes in this group was not higher than expected. Background: Living donor kidney trasplantation is a good choice for renal sustitutive therapy. In our Hospital, we have started at then end of 2011, the living donor kidney trasplantation to add another alternative of treatment for the chronic renal failure. Materials and methods: Since 21st of November of 2013 until today, we have studied 12 pairs or donors and recepients, and we have done eight living donors kidney trasplants. The exclusions were Diabetes Mellitus in two of the donnors, trasplantation from a deceased donor in one of the recepients, and anatomical malformation in other donor. All the donors were relatives, and had compatible blood group. The HLA mismatches were variabe. The inmunosupresive regimen has been: tacrolimus, MMF, basiliximab and steroids. Recipients started to have inmunosupressive therapy 3 days before the surgery. We have done three preemptive, and five of patiens on dyalisis. Results: After 16 months, our survival is 100%. All the surgeries have been laparoscopic left renal remove. The mean of warm isquemia time has been 2.5 min and the cold isquemia time 1 h 30 min No surgical complications until the moment. All the allografts are working. The average of the creatinine after this time is 1.5 mg/dl. We have had four episodes of acute rejection, three in the same patient. This one was a son-mother, and they only had one missmatch. All of the rejections were mediated by Tcells, and had good response to the treatment. We also have had three infections by CMV all of them with good response to valganciclovir treatment. Conclusions: Living donor trasplantation is a very good choice for the people who are in the waiting list and/or waiting to start dyalisis. Less time of cold isquemia time, less probability of HLAmismatches, the posibility of doing it preemptive, and the posibility of getting a younger donor, may help to improve our results. However, we cannot forget, the high probability of of rejection and in the recipient and take care of them. Pregnancy itself is not contraindicated in renal transplant recipients under certain conditions. The opposite is associated with a risk for child and graft function deterioration. Aim of this study was to identify whether a pregnancy after renal transplantation affects long-term renal graft function. In this singlecentre retrospective observational study we investigated the outcome of 36 pregnancies in 32 renal transplant recipients who subsequently conceived. The non-pregnant controls were matched to studied cases on age at transplantation, years after transplantation and initial renal function. Patients were followed for 5 years after the delivery. We focused on long term graft function, incidence of rejections and graft loss. Differences between studied groups were compared using Mann-Whitney U test for non-normally distributed continuous variables. Data are expressed as median and interquartile range. The graft survival analysis was performed using Kaplan-Meier analysis. Median S-Cr at time of delivery (€ ı¿½M) was 104 (94.8-137) in the study group compared to 110 (101.5-148) in the control group (p = 0.592). 5 years after delivery, graft function remained the same in both groups in the study group, in the control group, p = 0.723). Pregnant patients with baseline S-Cr of above 150 € ı¿½ M have an increased risk of progression of allograft dysfunction resulting from the pregnancy (p < 0.0001) (Figure 1 ). There was an insignificant increase in proteinuria in the study group at the time (p = 0.015) and 3 months after delivery (p = 0.022) in comparison to the control group. Graft survival and rejection rate was similar in both groups. We confirm that pregnancy itself does not appear to have any adverse effect on the longâ€ term graft survival if initial graft function is ideal. Jonathon Olsburgh 1 , Kerem Atalar 1 , Clarissa Carvalho 2 , James Barron 2 , Neal Banga 3 1 Guy's Hospital; 2 KHP Simulation and Interactive Learning Centres; 3 Royal Background: Transplant surgical training is still often an apprenticeship orientated approach. Technical skills are learnt on patients and non-technical skills are learnt via trial and error. We developed a simulation training program for transplant surgical trainees that aims to address these deficiencies in a safe environment away from patients. Methods: The following domains were coveredtechnical skills for transplant surgery, patient safety, situational awareness, in-theatre error management and transplant organ resource allocation. Technical skills consisted of workshops practising open surgical techniques on porcine tissues and laparoscopic simulation training using the LapMentor TM laparoscopic nephrectomy module. Non-technical skills utilised high fidelity simulation manikins and patient actors. Simulation scenarios using the Simulation and Interactive Learning Centre (SaIL) Debrief Diamond Model to elucidate and explore Human Factors issues, Non-Technical Skills and Crisis Resource Management. Results: Results from feedback were gathered before, during and after the course (including debriefs, videos, feedback sheets). Technical skills improved with repetition of activities including reduction in path lengths and number of movements with increase time on the laparoscopic trainer. There was improved understanding of Human Factors issues and increased confidence in candidates' leadership and communication skills. Candidates felt combining technical and non-technical skills effective in training. Conclusion: We have developed a multi-modality transplant surgical simulation training program that addresses technical and non technical skills. This programme is transferable and modifiable for surgical trainees in a wide variety of specialties and countries. We believe simulation training should form an integral part of transplant surgical training in order to deliver safer surgeons for the future and optimise patient care and safety. Background: Simulation has long been used in surgical and medical specialities to improve proficiencies of the trainee clinicians. They test technical or non-technical skills and are postulated to aid the steep learning curve of trainees in a safe environment. Method: Material for the renal transplant surgery used to construct the RTSim is as follows: 500 g pot of yogurt, three way tap junctions for IV access, cannula connectors, and two bag of normal saline with red dye. To test the device a pig, or sheep's kidney with perinephric fat and pat of vasculature is required. Set-up: Initially four small holes are made at the bottom of the yogurt pot. One next to each other and the other two are placed opposite the first two holes. The holes are to accommodate the three way taps. Once the three way tap inserted two small vessels/fine plastic tubing (length = diameter of the pot) can be set onto the 3-way taps. The purpose of the 3-way taps is so they can imitate vascular clamps by switching the flow on/off. Next is to connect the bag of normal saline to the taps to create a flow in the vessels. Simulator properties: The depth of the yogurt pot has somewhat similar dimensions to an open abdomen during renal transplantation. This allows the trainee to practice vascular anastomosis in the confined area and acquire depth perception. In addition, it aids with gaining experience in technical skills such as vascular anastomosis. Conclusion: The RTSim is a simple wet lab simulator to aid transplant trainees to gain experience and improve their technical skills. The dimensions of the RTSim make it a suitable training device however its content validity remains to be proven. Republic, 604 primary (94.08%), from DCD and living donors. Retrospectively we analyzed occurrence of surgical complications of retransplantation group of 40 patients (6.23%) in average age 36, 37 years (9-57 years) Three of retransplanted patients were diabetic. Of 34 transplantations (5.2%) were secondary, five transplantations (0.7%) were tertiary and one graft (0.1%) was transplantated quaternary, which was the first successful 4th retransplantation in the Slovak Republic. We collected data from available medical documentation from the Archives of University Hospital of L.Pasteur and compared to results of larger transplantcenters published in the specialized literature. Results: Total occurrence of surgical complication we have observed in 10 cases (25%). Wound complications in six cases, Vascular in two cases, Urological in two retransplanted patiens. Lymphocele was not verified in our group of retransplanted patients. Conclusion: The limitations of our study are small group of patients and short time follow-up, thus we are not able to phrase responsible conclusions. Despite it we found our results comparable to larger analyses in world literature and our experience lead us to conclusion that we consider this method safe also in our conditions and we recommend it to our patients after previous graft failure. Dermot Mallon, Elizabeth Wlodek, Neil Russell, Gavin J. Pettigrew, Kourosh Saeb-Parsy Addenbrooke's Hospital Introduction: Marginal donors are increasingly being utilized to increase the number of organs available for transplantation. Impaired renal function is a common reason for a potential kidney donor to be declined. The effect of impaired renal function in Donation after Circulatory Death (DCD) has not been conclusively determined. Methods: A retrospective review of 255 DCD kidneys transplanted between August 2008 and August 2012 in a single centre in the UK was performed to determine the effect of pre-mortem impaired renal function on the incidence of Primary Non-Function (PNF) and Delayed Graft Function (DGF), serum creatinine at three months and graft survival. Survival analysis was performed using Kaplan-Meier plots and a Cox proportional hazards model. Impaired renal function was defined as donor serum creatinine >115 mg/dl or eGFR <60 ml/min/1.73 m 2 . Results: The incidence of PNF and DGF was not increased by either raised donor serum creatinine or reduced donor eGFR (p > 0.05). Similarly, three month serum creatinine was not affected by raised donor serum creatinine or reduced donor eGFR (p = 0.45 and p = 0.14, respectively). Moreover, Kaplan-Meier survival analysis as depicted in Figure 1 shows neither terminal eGFR nor terminal creatinine to be significantly associated with graft survival. This is also demonstrated by a Cox proportional hazards model that shows only Donor age and Recipient age to be significantly associated with graft survival. Conclusion: Whilst it is possible that the kidneys accepted for transplantation with impaired renal function were otherwise of exceptional quality, it is apparent that acute renal failure alone need not be reason to decline kidneys for transplantation. Corticosteroids are powerful antiinflamatory with immunosuppressant effects utilized in maintenance therapy following kidney transplantation and are associated with a higher rate of side events in comparison with protocols involving early corticosteroid withdrawl. The present paper reports the results of cessation of steroids in stable maintenance renal transplant patients. Patients and methods: One hundred fifty seven deceased kidney grafted patients (51% men), aged 56.5 AE 12.4 years, with follow-up of 72 months and steroids withdrawl period of 48 months follow-up steroid free were studied. Etiology of end stage renal disease was secondary to Glomerulonephritis 31%, Diabetes 22%, Policystic disease 14%, Tubulointerstitial nephropathy 13%, Vascular 5%, Unknown 17%. The patients were on Prednisone 5-10 mg dairy combined with Cyclosporine 50-150 mg/Tacrolimus 0. Introduction: Donation after circulatory determination of death has been reintroduced into clinical practice in many countries as a potential solution to organ shortage, but this kidney transplantation programs are not popular yet, mainly because of logistical concerns and uncertainty about the long-term warm ischaemia impact on transplanted kidneys. outcomes of kidney transplants that simultaneously exhibit donation after cardiac death (DCD) and expanded criteria donor (ECD) characteristics have not been well studied. We present preliminary results with DCD with ECD. Introduction: Prior to the introduction, in the mid 1970s of legislation defining the diagnosis of brain-stem death, transplant organs were removed from DCD. Despite renewed interest in DCD kidney transplantation, very few clinical programs have been developed this type of grafting. Renal transplantation is the best cost effective treatment for end-stage renal failure and improves quality of life, when compared with dialysis. We analyzed the function and outcome of kidney transplants performed from DCD in our hospital. Backround: Urinary tract infection (UTI) is the most common bacterial complication in patients following renal transplantion. UTI is a source of morbidity, is able to cause graft failure or death in renal recipients. Ureteral stents are inserted at the time of transplantation to prevent leakage or stenosis of the ureteroneocystostomy (UCN), but are associated with an increased relative risk of UTI. Intraoperative placement of urethral catheter should be also a source of bacterial UTIs after renal transplantation. We would present a collection of measures to reduce UTI-rate in renal transplant recipients. Methods/material: We included all renal transplant patients with follow-up at our institution in 2010 and 2011. Patient's data like demographics, immunosuppression, specific data for surgery and infections were considered. Followup averaged 300 days, accounted at the minimum 180 days. Patients were allocated into two groups, depending on time of ureteric stent removal: S = short time ≤ 30 days (n = 31) and L = long time ≥ 30 days (n = 44). Results: 57 patients received transplants from deceased donor and 18 from living donor. Seven simultaneous pancreas kidney transplantations and six "2for-1"-kidney-transplantation were done. Double-J-Catheter (DJC) for stenting UCN was used always. In 17 renal recipients overall occurred no UTI (S n = 8, L n = 9). Most frequent bacteria caused first UTI in renal transplant patients were gram-negative Enterobactericaea, followed by gram-positive Enterococci. Conclusion: Measures package to reduce UTI in patients following kidney transplantation composed of (i) Early removal of urinary catheter, (ii) Early removal of ureteral stent, (iii) Early calculated antimicrobial treatment in cases of typical symptoms. Methods: Out of 2206 renal transplant recipients who were transplanted at Hamed Al-Essa Organ transplant center of Kuwait, 183 of them (9.15%) were maintained on erythropoietin. Six months post-transplant, patients who did not achieve target hemoglobin (HB>12 g/dl) comprised group 1(n = 36), while those who had Hb <12 will comprise group 2 (n = 147). We evaluated these cases for possible causes of resistant anemia. Results: Majority of patients in both groups were females (p = 0.86) with mean age of 42.7 AE 16.3 vs. 37.2 AE 15.6 years (p = 0.11). Most of patients in both groups received anti-proliferative induction (p = 0.85) and were maintained on steroid, MMF and CNI (p = 0.98). Only 4(2.7%) cases of group 2 achieved target HB with EPO therapy. The majority of patients in both groups were comparable regarding C reactive protein, folic acid and vitamin b12, (p > 0.05); and most of them revealed negative proteinuria and low vitamin D level (p > 0.05). Serum iron was significantly lower in anemia group (p = 0.01). Most of the anemic patients received grafts from cadaveric or unrelated donors especially with preemptive cases, while most of non-anemic group got their grafts from related donors.(p = 0.04). We observed that patient age correlated negatively with serum iron(p = 0.048); serum ferritin correlate negatively with HB 6 months post-transplantation but not that at time of transplantation (p = 0.004 &0.5 respectively). There was no significant difference in patient or graft outcome among the two groups (p > 0.05). Conclusion: Post-transplant anemia is common, with suboptimal use of iron especially among pretransplant CKD patients. Live related donors and exogenous EPO gave protection. Presence of post-transplant anemia at 6 months did not influence graft or patient outcome in this short study. Background and aims: There are growing numbers of patients with ESRD globally at an unexpected rate. The biggest challenge in transplantation today is organ shortage; hence, using deceased donor is encouraging. The aim of study was to investigate differences of survival rates between kidney transplant recipients with deceased donor and living donor. Patients and methods: In a retrospective Cohort study of 218 kidney transplant recipients carried out in our institute from April 2008 to September 2010. Demographics and post-transplant follow up including immunosuppression regimens, rejection episodes, and survival rates were evaluated. The patients were divided into two groups according to donor kidney transplantation sources: group I, living donor kidney transplants; and group II, deceased donor kidney transplants. Results: Although, there were not significantly differences between 1 year patient and graft survival rates in both groups, three years of patient and graft survival rates were significantly higher in living donor kidney transplants as compared to recipients who received kidney from deceased donor (p = 0.006 and p = 0.004, respectively). In Cox-regression model after adjusting of other Introduction: With improvement in both short-term outcome and acute rejection rate, the main concerns in care of kidney transplantation (KT) recipients has shifted toward factors that constitute the long-term outcome such as safety profile, compliance and the patient's quality of life (QOL). The purpose of this study is to report our experiences of conversion to once-daily regimen using very low dose of advagraf (ADV) and sirolimus (SRL) in stable kidney recipients in comparison to Tac-MMF regimen. Methods/materials: Of 40 KT recipients with stable renal function (more than 6 months after KT, 24-h urine protein <400 mg, creatinine variance <30% within 3 months) underwent conversion from tacrolimus (TAC)-mycophenolate mofetil (MMF) based regimen to once-daily ADV-SRL regimen. Mean conversion day after KT was 25.7 months and mean follow-up day was 12.4 months. The target trough concentration (C0) of ADV and SRL were 2-4 and 5-10 ng/ ml, respectively. The renal functions, rejection rate as well as compliance profile and QOL questionnaire were compared with case-matched TAC-MMF group. Results: The ADV and SRL conversion group showed slight improvement in renal function at 3 months after conversion, evidenced by eGFR ( Since 1982 (CsA initiation), corticosteroids were designed to be stopped between 2 and 3 months after transplantation and since 2000 designed to be avoided the day after surgery. When Basiliximab was introduced in 1995 for induction in immunological low-risk patients, Thymoglobulin was restricted to the remaining "high-risk" categories (PRA >25%, retransplants, cold ischemia >36 h). When compared to Lymphoglobulin, Thymoglobulin was associated with a significant higher graft survival throughout the three decades with almost 20% difference (i.e. 70 vs. 50% at 10 years; 50 vs. 30% at 20 years, including death; p < 0.0001). Patient survival was similar with Thymoglobulin and Lymphoglobulin (50% at 30 years). When only Thymoglobulin patients were analyzed, there was no statistical difference in graft and patient survival in recipients of primary or retransplantation throughout f/u. No difference was neither observed when compared >8 and <8 days of induction duration. When arbitrarily graft survival not censored for death was evaluated in three consecutive periods: 1977-1990, n = 487; 1991-2001, n = 755; 2002-2013 , n = 696, a significant improvement was seen with a 30% gain in the last decade (p < 0.0006). This amelioration, despite the use of Thymoglobulin in a higherrisk transplant population within time (recipient age: 41, 44 and 46 years, p < 0.0001; retransplants: 15.6, 27 and 42%, p < 0.0001; donor age: 31.3, 37.3 and 44.6 years, p < 0.0001), was not due to less death (similar patient survival) but probably due to a significantly lower number of patients with acute rejection episode: 40.8%, 18% and 15.8%, respectively, p < 0.0001). CMV infection/disease was particularly decreased in the last decade from 28.8% to 11%, certainly due to the universal use of valacyclovir followed by valganciclovir. PTLD incidence decreased from 4% to 1% in the last d. transplanted with grafts affected by initial FMD and reconstructed at bench before transplantation are examined. In the entire series of 3082 kidney transplants, 14 kidneys (eight right and six left) coming from 12 LDs and two from DDs showed typical signs of FMD. The mean donors' age (11 females and three male) was 55.2 years. Two renal arteries were present in three cases. Various original microsurgical bench techniques were adopted to safeguard the following transplantation. All the 14 grafts showed immediate recovery and there were no postoperative complications or disease recurrence, either in the 12 LDs or in the recipients. The mean duration of the grafts was of 7.1 years, for a mean followup period of 8.4 years. Ten patients have their kidney still functioning, one patient died at 7 years after TX from a cancer, three patients lost their graft at a mean 7.6 years after transplantation. Reconstruction at bench of FMD-grafts prevents complications after transplantation, so safely widening the donor pool. Background: Although conception rate is high in the Middle East as a whole, rare reports are available in the transplant population. We therefore report here our experience from the Eastern Province of Saudi Arabia. Methods/materials: A total of 33 pregnancies in 15 kidney recipients transplanted in our center from 1992 to 2008 were reviewed. All data related to maternal, fetal and renal outcomes were recorded. Results: The mean age at the time of conception was 26.5 AE 7.5 years. Mean transplantation-to-pregnancy interval was 23.6 months (range: 5-60). Renal function was stable at the start of conception. Twelve pregnancies (36.4%) were unsuccessful (10 abortions and 2 stillbirths), and 21 were successful (63.6%) including one twin pregnancy. Ten patients had caesarian section and 11 had normal delivery. Birth weight was low (<2.5 kg) in six children and normal (>2.5 kg) in 15. Nine ladies (60%) had more than one pregnancy. We noticed hypertension in five patients and preeclampsia in 2. No patient had rejection or gestational diabetes. All recipients were on cyclosporine, azathioprine and prednisolone. Renal function remained stable during pregnancy. Background: The increase in the number of patients waiting for organ transplants all around the world and the insufficient number of cadavers, has led to increased interest in transplants from live donors. For volunteer donors, the traditional open donor nephrectomy causes a long scar after the flank incision on the thoraco-abdominal wall, severe pain, risk of pleural injury, incisional hernia, long-term hospital stay, wound problems and a relatively long period of recovery. Methods/materials: In a study of Laparoscopic Donor Nephrectomy (LDN) comprising 15 patients (seven female, eight male) the surgical technique, intraoperative findings, postoperative follow-up and morbidity were evaluated. Results: All patients underwent laparoscopic left nephrectomy with a transperitoneal approach. Due to artery and vein anomalies in one patient, the open procedure was performed. The mean operative time was 115 min (90-135), the mean follow-up was 8.2 months (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) (19) , the average length of hospitalization was 2.9 days (2-4), and the mean warm ischemia time was 190 s (100-240). No perioperative complications were observed and none of the patients showed signs postoperative wound infection. Conclusion: With increased surgical experience, LDN is a method that might have a lower rate of mortality and morbidity compared to open nephrectomy. We carry the conviction that LDN is the gold standard for living donor nephrectomy. Background: Tremor, a manifestation of tacrolimus (TAC)-associated neurotoxicity, is common in kidney transplant recipients (KTR). Two hour (peak) serum concentrations are correlated with this toxicity. Reduction or cessation of TAC dosing may reduce tremor symptoms but increases the risk for rejection. LCP-Tacro TM (extended-release once-daily MeltDose â formulation, Veloxis Pharmaceuticals) is a novel form of TAC that has a reduced peak concentration but comparable AUC exposure, at a reduced dose of~30% versus standard TAC. Converting patients who have tremor with a standard TAC formulation to LCP-Tacro resulted in a measurable reduction in tremor rating score (improve 15.6%, p < 0.05; Langone A., et al. American Transplant Congress, 2013 . The present analyses examined if patient reported quality of life (QoL) improves after conversion, and if changes in QoL correlate with tremor rating scale. In this open-label, multicenter, prospective Phase 3b exploratory clinical study, stable KTR on Prograf or generic TAC, experiencing tremor, were enrolled. Following seven days of their pre-enrollment twice-daily TAC, patients were switched to LCP-Tacro. Tremor pre-and 7 days post-conversion (Day 14) was evaluated using the Fahn-Tolosa-Marin (FTM) tremor rating scale; patients completed the QUEST (QoL in Essential Tremor). Results: Thirty-eight of the 44 enrolled KTR had FTM and QUEST data available. There was a significant (p < 0.001) improvement in QUEST score at Day 14 (mean [SD] absolute and percent change from baseline: À7.04 [9.41]; À39.08% [39.43%]). Change in QUEST score was significantly (p = 0.006) correlated (Pearson Coefficient R = 0.44) with change in FTM score (Figure) ; in particular, change in physical (R = 0.48) and psychosocial (R = 0.47) QUEST subscales were significantly (p < 0.004) correlated with change in the functional disabilities component of the FTM. There were no safety concerns. Conclusions: Results from this exploratory study suggest a significant improvement of QoL with tremor experienced by KTR who switch from Prograf or generic TAC to LCP-Tacro, and is consistent with improvement of tremor experience assessed by tremor rating scale. The impact of pre-existing and de novo circulating anti-HLA antibodies (DSA or not, in simultaneous liver-kidney transplants (SLKT) still remains controversial. We evaluated the impact of pre-transplant humoral sensitization in a group of 39 adult recipients that underwent a SLKT between 1988 and 2011. 11/39 patients had different degree of humoral sensitization; all recipients received an immunosuppressive regimen based on a calcineurin inhibitor, an antimetabolite and induction therapy with either monoclonal (19/30) or polyclonal (20/39) antibodies. Acute kidney rejection (AKR) occurred in three patients (2 AHR, and 1 T-cell mediated); eight patients developed post-transplant acute cellular liver rejection; neither type of maintenance immunosuppression, delayed graft function, HCV nor CMV infection influenced the development of AKR. Conversely, acute liver rejection (ALR) was numerically higher among patients receiving CsA as compared to those receiving TAC (p = 0.08), but not related to induction therapy, HCV or CMV infection. A positive pre-transplant CDC crossmatch was obtained in 5/39 SLKT. Four of them did also show pretransplant PRA>25%. Sensitized transplant recipients displayed a significantly higher incidence of AKR and those with a positive pre-transplant crossmatch developed Antibody-mediated AKR (p = 0.038). On the contrary; all eight patients developing T-cell mediated ALR had a negative cross-match. Kaplan-Meier analysis of kidney allograft survival regarding the degree of pretransplant peak of PRA sensitization showed that those SLKT recipients with a previous PRA>25% were at increased risk of kidney graft loss as compared to those with low or undetectable anti-HLA antibodies. In summary, liver allografts may not be fully protective of the renal allograft in terms of rejection or function, especially among sensitized patients. A major objective in clinical practice, including transplantation, is to develop more focused and personalized approaches for both diagnosis and treatment. There have been several recent successes in correlating specific polymorphisms with drug responses; however, the goal of personalized medicine is challenging for multiple reasons. (i) Humans are outbred with numerous genetic polymorphisms, (ii) each individual confronts different sets of environmental exposures, and (iii) as analysis focuses on smaller subsets or an individual patient the statistical power is increasingly diminished. In addition, the "gold standard" for diagnosis following kidney transplantation is pathological analysis of a graft biopsy; however, studies have shown approximately 20% variation among diagnoses between blinded pathologists. To address these challenges we focused on the largest available dataset of microarray data analyzing kidney biopsies (GEO accession GSE21374) and combined samples from multiple studies to increase statistical power. After filtering the data, we used multidimensional scaling (MDS) to eliminate 11 samples which were statistical outliers (>2 SD). The 11 outliers did not correlate with any of the diagnoses and appear to include excessive technical noise. Next, we identified subsets of each diagnosis based on silhouette width, Dunn index and connectivity criteria using three types of clustering algorithms (hierarchical, kmeans and pam). These results indicate that the dataset represented 21 distinct molecular diagnoses (expanded from the 11 pathological diagnoses). The subsets of a pathological diagnosis were often extensively different. For example, we identified 849 genes that were significantly different (fdr <0.05) between two subsets of T cell mediated rejection (TCMR) indicating substantial differences in gene expression despite the same pathological diagnosis between the two sub-clusters of TCMR. To identify the biological functions of each sub-diagnosis, we identified. Causes of dyslipidemia after renal transplantation are usually multifactorial, the type of immunosuppression regiments and genetic predisposition. Pglycoprotein (p-gp) is an important ATP-dependent membrane transporter which is involved in the absorption, distribution and elimination of numerous drugs, including lipid-lowering drugs. The difference of p-g's function resulted from single nucleotide polymorphisms in MDR1 may be the cause of interindividual difference. The aim of our study was to evaluate the effect of MDR1 polymorphism on serum levels of lipids before and after atorvastatin. Materials and methods: The study included 100 renal transplant patients. Of 35 hypercholesterolemic patients were selected and treated with 10 mg/day atorvastatin. C3435T and G2677T polymorphisms were determined by polymerase chain reaction (PCR) followed by restriction fragment length polymorphism (RFLP). Results: Genotype frequencies in C3435T polymorphism were 31.4%, 45.7%, 22.9% for CC, CT, TT respectively and genotype frequencies in G2677T polymorphism were 37.1%, 51.4%, 11.4% for GG, GT, TT respectively for 35 hypercholesterolemic patients. No significant difference was found between C3435T polymorphism and serum lipid levels. Similarly, there was no significant difference between baseline serum levels of lipids and G2677T polymorphism. However, we found a relationship of G2677T genotypes with atorvastatin response. Gendiag.exe; 4 Gencardio Background: The spectrum of kidney disease (KD) is broad ranging from mild chronic KD to end-stage renal disease, which requires dialysis and kidney transplantation (KT). Coronary heart disease (CHD) is prevalent in KD patients, and contributes substantially to the morbidity and mortality of these patients. However, the classical CHD risk equations have shown limited clinical utility in KD patients. Aims of our study were to assess the predictive capacity of a CHD risk function based on clinical variables and to evaluate whether the inclusion of genetic variants improve CHD risk estimation. Methods: Our cohort study included 632 KD patients (200 with KT) with a median follow-up of 9.13 years. Mean age was 53.4 (AE10.6) years and 32.4% of the patients were male. Seventy three coronary events (fatal-or non-fatal acute myocardial infarct or acute angina) were identified in the follow-up. The clinical CHD risk score included KD status, age, sex, HDL, diabetic condition, hypertension condition, dislypemic condition, hemoglobin A1c. In a second model, we also included a weighted genetic risk score (GRS) (Cardio inCode Score) with variants previously identified to be associated with CHD and not related with classical cardiovascular risk factors (rs10455872, rs12526453, rs1333049, rs17465637, rs501120, rs6725887, rs9818870, rs9982601, rs10507391, rs17222842, and rs9315051). Results: The discrimination of the CHD risk function improved with the GRS (c-statistic = 72.0 vs. 68, p-value = 0.015). The calibration assessed by the Hosmer-Lemeshow test was 9.6, p = 0088 (i.e., calibration was good with no statistical differences between the events predicted and the observed). The reclassification of the patients also improved with the GRS (Net reclassification improvement = 22; 95%CI: 5.5; 38.6). Methods: Kidney paired donation has been at first performed at our institution in 2003, until 2011 some three 2-way exchanges were performed. Since 2011 the kidney exchange started at our institution as proper program. All the incompatible pairs were collected prospectively in the database. The matching runs were performed every three months. Pairs get matched using specially designed software, matching is based on blood group as well as HLA match. Results: Since 2011 we performed twice the 2-way kidney exchange, one 6way domino chain and one 5-way domino chain, one 4-way kidney exchange, in total 19 live donor kidney transplants were performed. The participance of two altruistic Samaritan donors made the domino chains possible. Two surgeons preformed all the transplants, one did all the miniinvasive nephrectomies. Some 13 were first transplants, five were second and one third transplants. There was no delayed graft function observed, all kidneys started to work immediately. The program did help some 19 patients so far. Our scheme currently includes some 45 pairs awaiting matching run. Conclusions: Kidney paired donation program can be run at single institution, this limits some of the highly sensitised pairs as well as blood group 0 recipients. Wider possibility e.g. European scheme would increase the chance for even more exchange kidney transplants.  Background: The aims of our study were to examine (i) whether Fractalkine, IP-10, IFN-Ι € A and IL-17 predict the acute kidney allograft rejection; (ii) whether the sensitivity and specificity for prediction of allograft rejection are improved by combination of two markers. Methods: The expression of serum Fractalkine, IP-10, IFN-Ι € A and IL-17 in 77 kidney transplant recipients (including 32 recipients with AR and 45 recipients with STA) and 20 HC were researched, by high-throughput liquid protein microarray technology. The serum samples from patients were detected on pre-transplantation, days 1, 4, 7, 14, 21, and 28 after kidney transplantation. The values of those biomarkers for prediction of acute allograft rejection were evaluated. Results: The pre-transplantation mean levels of Fractalkine and IFN-Ι € A in AR were significantly higher than STA, however, the mean levels of IP-10 and IL-17 between AR and STA were no significant differences. The results of ROC analyses highlight the superiority of Fractalkine on day 0, IFN-Ι € A on the 1st, and IL-17 on the 4th post-KTx days over those on other post-transplantaion days in prediction of acute rejection episodes. The AUC in combination of Fractalkine on day 0 and the IL-17 level on the 4th day were the most for predicting acute rejection, and its sensitivity and specificity for the prediction of acute allograft rejection was 79.3% and 91.1%. Conclusion: This study was demonstrating the promising and elegant markers of serum Fractalkine and IL-17 for prediction of early acute rejection. The complex predictive model exhibits a better ROC score and provides a much more powerful prediction than any single-marker prediction model. College of Xi¡B ackground: The aims of our study were to examine (i) how IFN-Ι € A ELISPot concentrations change over time in the early KTx; (ii) whether IFN-Ι € AELISPot predict the acute kidney allograft rejection. Methods: There were 24 cases of acute rejection (AR, further pathological diagnosis, including nine cases of grade I, seven cases of grade IIA, four cases of grade IIB and four cases of grade III), 168 subjects with stable allograft function (STA)after surgery, randomly selected 64 cases of STA, 50 healthy donors served as healthy controls (HC). IFN-Ι € A ELISPot detect memory T cell frequency in different groups of patients before and after renal transplantation. ROC curves were evaluated the uniting value of IFN-Ι € A ELISPot in the diagnosis of acute rejection. A ELISPot values of AR group in AR occur significantly higher than that of STA group (p < 0.05) . Compared with HC group, STA group significantly increased (p < 0.05). Before and the 1th, 2th, 4th, 7th, 14th, 21th days after renal transplantation in AR group, IFN-Ι € AELISPot was higher than that in STA group (p < 0.05). Second day after operation in STA group reached maximum value. AR group at second and fourteenth days after operation appeared two peaks, and between second to fourteenth days continuously maintained at a high level, after fourteenth days decline to normal rapidly. There are no significant differences between before and after donor nephrectomy surgery, always remain at low levels (<5spots/5î A 105 PBLs). IFN-Ι € A ELISPot gradually increased before 1 week AR occurring, increased significantly in the first 5 days, decreased significantly at third day after treatment. A ELISPot is a clinical diagnosis of AR 5 days in advance. IFN-Ι € A ELISPot diagnosis of AR the best threshold was 15 spots/5 ı A105 PBLs, sensitivity 92%, specificity 87.5%, AUC 0.92. Kaposi's sarcoma was diagnosed in a leg lesion. Immunosuppression was altered to everolimus and treated with radiotherapy and chemotherapy (doxorubicin). In January 2011 pulmonary infiltrate and left pleural effusion was detected. The etiologic study was consistently negative for infectious cause. Flow cytometry study of the bronchoalveolar lavage performed revealed a predominance of CD8+ lymphocytes. Pleural biopsy was negative for malignant cells. Everolimus pneumonitis with pleural effusion was suspected and everolimus suspended. Despite this, patient presented recurrent pleural effusion. Afterwards, results of immunophenotyping and pleural fluid cytology were consistent with lymphoma of serous/cavities -"primary effusion lymphoma" (PEL). A multidisciplinary team (Nephrology, Pneumology, Hematology, Palliative Care) set a conservative strategy. The following year patient presented frequent hospitalizations by hypervolemia with pleural effusion and progressive deterioration of renal function. In February 2012 recurrence of pleural effusion occurred, large pericardial effusion was detected and patient started hemodialysis. The patient died one year later by cardiovascular cause. Conclusion: PEL is a rare condition associated to HHV-8, that should be part of the differential diagnosis of a lymphocytic pleural effusion in a renal transplant recipient. Flow cytometry may be an essential clue to this difficult diagnosis, associated with a high morbidity and mortality. This case highlights the important interaction between virus, imunosupression and neoplasm in renal transplant recipients. Background: The active metabolite of vitamin D is considered to exert renoprotective effects by different mechanisms of action such as modulation of the immune system and inhibition of the renin-angiotensin-aldosterone system. In kidney transplant recipients (KTRs), vitamin D deficiency is common and might impair these potential beneficial effects. So far, it is unknown whether correction of vitamin D deficiency would affect the outcome after kidney transplantation. Methods: The VITA-D study is a randomized double-blind placebo-controlled study (NCT00752401). It was designed to test the hypothesis that treatment of vitamin D deficient KTRs with vitamin D3 during the first year after transplantation improves the clinical outcome. As primary endpoints graft function as well as the occurrence of allograft rejections and infections one year after transplantation are assessed. Adult KTRs with vitamin D deficiency (calcidiol <50 nM) were stratified by calcidiol levels (<25 or 25-50 nM) and randomized in a 1:1 ratio to vitamin D3 at 6800 International Units/day or placebo. We excluded patients who underwent retransplantation more than twice or were highly immunized as well as those who had a history of gastrointestinal diseases that lead to impaired intestinal vitamin D absorption. Results: Of 577 kidney transplant recipients screened between May 2009 and July 2013, 202 were randomized. Approximately 75% of the screened patients had calcidiol levels <50 nM. Baseline characteristics of the study population will be presented. The study will be completed in one year and the final results are expected for autumn 2014. The VITA-D study should help to determine the potential beneficial effects of vitamin D3 on the post-transplant outcome as well as its safety in vitamin D deficient KTRs. Siddiq Anwar, Nima Naimi, Muhammad Ashraf, George Jarad, Helen Liapis, Daniel Brennan Washington University School of Medicine Recurrent focal segmental sclerosis (rFSGS) in kidney transplant (KT) is difficult to predict and causes graft loss. Early rFSGS is hypothesized to be secondary to one or more circulating factors: glomerular albumin permeability factor (Palb), soluble urokinase receptor (suPAR), and angiotension-1 receptor antibody (AT1Rab). Methods: We analyzed stored samples 1 year pre-transplant, at transplant and on recurrence for Palb, suPAR, and AT1Rab in a 23 years. white male. He presented 8 months after one haplotype match KT with rFSGS and acute renal injury (AKI) requiring dialysis (HD). Results: All three biomarkers were elevated 1 year pre-transplant when he was not on HD. At transplant, Palb and AT1Rab were elevated, but suPAR level was not. Four months later he developed CMV viremia and antimetabolite was stopped with resolution of viremia. Subsequently maintained on prednisone and tacrolimus. Eight months after KT, develops AKI and biopsy showed rFSGS with no rejection. C4d and anti-HLA antibodies were negative. At recurrence, all three biomarkers were elevated. Seven days after therapy with aborted plasma exchange (secondary to side effects) plus high dose steroids, Palb and suPAR remained significantly positive but AT1Rab was borderline positive. Twelve weeks into treatment with high-dose steroids, rituximab and galactose, patient remains on HD. Background: Hyperuricermia frequently develops during early post-renal transplantation. Patients with hyperuricemia experience poorer graft survival rates. We aimed to investigate the relationship between hyperuricemia in MDR1 polymorphism and graft survival among Turkish post-renal transplant patients receiving cyclosporine. Methods/materials: One hundred living-donor transplant patients receiving cyclosporine underwent C3435T (exon 26) and G2677T (exon 21) single nucleotide polymorphisms (SNP) genotyping using polymerase chain reactionrestriction fragment polymorphism. The normouricemic and hyperuricemic patients were evaluated regarding acute rejection. Results: There was no statistical significance in normo and hyperuricemic recipients regarding C3435T polymorphism frequencies. GG genotype was significantly (p = 0.046) more frequent compared to T allele in normo-uricemic, whereas TT genotype was significantly (p = 0.043) more frequent compared to G allele in hyperuricemic patients regarding G2677T polymorphism. No significant difference was found in normo and hyperuricemic patients regarding acute rejection among C3435T polymorphism. Whereas individuals with GG genotype (G2677T polymorphism) had significantly more frequent acute rejection episodes in hyperuricemic patients (p = 0.024). Conclusion: GG genotype may be risk factor of acute rejection in hyperuricemic renal allograft Turkish recipients using cyclosporine immunosuppression regarding MDR1 G2677T polymorphism. Introduction: Acute graft rejection is a complex process which involves several cells of the host immune system and might lead to chronic allograft dysfunction and organ destruction. The role of innate immunity has been revisited with a special interest in Toll-like receptors (TLRs). Clinical and laboratory studies have shown that TLRs may participate in organ graft rejection and transplant immune tolerance. Aim: In this study, we investigated, in Tunisian renal recipients, the distribution of genotypes and alleles frequencies of the Arg753Gln polymorphism (arginine [G] to glutamine [A] substitution) of TLR2 with the aim to explore a potential correlation with the occurrence of acute rejection (AR) or chronic allograft nephropathy (CAN). Patients and methods: The Arg753Gln polymorphism was genotyped using DNA samples from 125 renal recipients using Restriction Fragment Length Polymorphism (RFLP) assay. Patients were classified into two groups according to the HLA-haplotype similarity between donor and recipient: Group I included 29 HLA-identical haplotype allograft recipients and Group II included 96 recipients showing one or more mismatches in the HLA haplotype. Fortyseven patients (37.6%) developed at least one AR episode, and twenty-nine of them (23.2%) were identified as CAN cases by biopsy scored according to the Banff criteria. Results: Occurrence of AR and CAN was statistically associated with the preexisting anti-HLA antibodies in patients (p = 0.03; CI 95% OR = 3.85 [1.58-9 .39] and p = 0.017; CI 95% OR = 3.05 [1.21-7 .68] respectively). Incidence of CAN was also significantly more important in the Group II than Group I (p = 0.047; CI 95% OR = 3.21 [0.898-11.54]). The frequency of G/G genotype was higher in AR patients comparing with non-AR ones (p = 0.039; CI 95% OR = 2.87 [1.05-4.37] ). However, no differences were found in genotypes or alleles distribution according to CAN. No association either was noted with the incidence of infection in post-transplantation. Conclusion: In conclusion, this study showed that, set apart the immunological factors, the Arg753Gln polymorphism of TLR2 may increase the risk of acute renal allograft rejection in Tunisian patients. Background: Accurate knowledge of the anatomy of intrahepatic bile ducts (IHD) is critical for successfully hepato-biliary surgery and the implications of its variations are essential for living donor liver transplantation (LDLT). Methods: From 1996 to 2011 we have collected data of the main IHD classification and its anatomic variations. 2032 and 1014 anatomical variations of right and left IHD were reviewed and classified according to the branching pattern of the right anterior and posterior hepatic duct and also segment IV insertion. Results: The frequencies of each type of right IHD variations were: Type A1 -1247(61.4%); Type A2 -296(14.6%); Type A3 -272(13.4%); Type A4 -124 (6.1%); Type A5 -21(1%) and others -72 (3.5%) and of left IHD variations were: Type B1 -773(76.2%); Type B2 -153(15.1%); Type B3 -38(3.7%); Type B4 -9(0.9%); Type B5 -29(2.9%) and others -12 (1.2%). Conclusion: A preoperative understanding of bile duct variation, the knowledge of IHD, familiarity with the variations of hepatic confluence is useful for hepatic surgery and also will help to exclude donors with anatomical contraindications and avoid possible surgical misadventure in LDLT. Vincenzo Morabito 1 , Massimo Rossi 1 , Quirino Lai 2 , Francesco Pugliese 3 , Pasquale Bartolomeo Berloco 1 , Gilnardo Novelli 1 1 Sapienza University of Rome, General Surgery and Organs Transplant; 2 Azienda Ospedaliero Universitaria Pisana; 3 Anaesthesia and Intensive Care, Background: The aim of this study was to confirm the improvement of prognostic parameters after treatment with the Molecular Adsorbent Recirculating System (MARS) in patients (pts) with fulminant hepatitis (FH). Materials: Of 71 pts with FH, treated with MARS were enrolled. Results: The score showed a high AUC (91.4%). Arbitrary cut-off values of 2 and 4 showed high sensitivity (81.4 and 48.8%) and specificity (92.9 and 96.4), respectively. Pts corresponding to the low risk group (scoring points: 0-2; n = 36) did not experience deaths, and only 8 (23.5%) of them underwent a Liver Transplant (LT). Pts with intermediate risk (3-4 points; n = 22) were mainly transplanted (20 pts; 90.9%). In this group, only two patients survived without LT. In the high risk group (5-6 points; n = 13), no patient survived. Only 2 (15.4%) pts were transplanted, while the remaining cases died before LT. Conclusions: The following criteria: GCS ≥11 with ICP <15 mmHg, lactate level <3 mM, TNF-a < 20 pg/ml, IL-6 < 30 pg/ml, and a change in hemodynamic instability from hyperkinetic to normal kinetic conditions, enabled us to divide patients into three groups and determine their outcomes. Background: Hepatic artery (HA) complication in patients who underwent liver transplantation (LT) is an important risk factor for worse outcomes and graft loss. Transarterial chemoembolization (TACE) is widely used in patients before and during the waiting list for cancer control or downstaging. Conventional TACE is directly applied into the HA and may therefore damage it. Herein, we describe the relationship between the pre-operative TACE and the apparition of histological and radiological HA complications. Patients and methods: All patients with hepatocellular carcinoma who underwent LT in our center between January 2009 and October 2012 were included in this study and divided in two groups: TACE (group 1) and no-TACE (group 2). HA complications are reviewed and compared between groups. Recipient HA close to the anastomotic site underwent histological analysis to detect HA wall injury. Results: Sixty-seven patients were reviewed, 31 for group 1 and 36 for group 2. Both groups were similar for gender, age, cirrhosis origin, and ASA score. There were more patients classified WHO 2 and CHILD score C in group 1 compared to group 2 (p = 0.005 and p = 0.008, respectively). Fourteen patients were within Milan criteria in group 1 and 25 in group 2 (p = 0.03). In group 1 TACE was selective with drug-eluting beads in 24 patients. At 1 year of follow-up, eight radiological HA complications occurred; five in group 1 (1 HAT, three stenoses, one pseudoaneurym) and three in group 2 (one HAT, two stenoses) (p = 0.29). One-year overall graft and patient survival were 93%. Histological screening showed 10 histologic HA injuries in group 1 and 3 in group 2 (p = 0.05). Conclusion: Even if our study didn't show statistical difference between groups, we found a major trend towards HA complications in TACE group. Necdet Guler, Murat Dayangac, Onur Yaprak, Yusuf Gunay, Fatih Taskesen, Gulum Altaca, Yildiray Yuzer, Yaman Tokat Florence Nightingale Hospital In living donor liver transplantation (LDLT), portal vein (PV) variations are of immense clinical significance. Herein, we describe our PV reconstruction techniques in 52/386 (13%) right lobe (RL) grafts with variant PV anatomy and evaluate the impact of accompanying biliary variations. The PV reconstruction techniques included back-wall plasty (n = 21), saphenous vein (SV) graft interposition (n = 5), back-wall plasty with SV graft interposition (n = 6), iliac vein Y-graft interposition (n = 6), and quiltplasty (n = 3). There was no donor mortality. In a median follow-up of 29 months, none of the recipients had vascular complications. Anomalous PV anatomy was associated with a high (54%) incidence of biliary variations. Vascular and biliary variations render LDLT technically more challenging. By employing appropriate reconstruction techniques, it is possible to successfully use RL grafts with PV variations without endangering recipient and donor safety. OLT to 31 HCV-positive recipient were performed in our center in period from december 2004 to december 2012. Of the 14 patients who carried AVT with PEG IFN + ribavirin, 9 (64.3%) achieved a SVR. AVT in patients who achieved SVR, began a period of 2, 7, 12, 15 months after OLT on monotherapy with tacrolimus or cyclosporine A.1 case of fibrosing cholestatic hepatitis C.In four patients with rapid progression of fibrosis F0-F 2 for 6 months. 3 patients had genotype 3a, 6-1b. In 1 case, the AVT lasted 72 weeks in the form of a slow virologic response, in the other treatment was discontinued at week 6 in mind persistent increase in serum bilirubin despite negative HCV RNA at second week of treatment. Remaining patients treated by consistent protocol regarding genotype of hepatitis C virus (24-48 weeks).In 1 case, the AVT was stopped after EVR at 15 weeks, because of an abscess of the liver. After 3 months, in this case the level of viremia was 2.8*10*7 IU/ml.Retry after 8 months had led to a EVR and SVR. In conclusion: achieving high frequency SVR possible recipients after liver transplantation, regardless of the start time of antiviral therapy. Methods: Of 1085 patients listed for LT have been included in our analysis. Results: One, 3 and 5 years mortality on WL were 25%, 46.3% and 57.3% respectively. Death on the WL was significantly higher before 2008 (37% vs. 26.4%, p = 0.0001) and risk of dying while on WL was 60% higher. Waiting time on the WL was with 75% longer and time until LT was with 102% longer before 2008 compared to the second time period (p = 0.0001). After 2008, 62.3% of patients were listed for LT with Child Pugh class C compared to 22.1% (p < 0.0001). MELD score at inclusion was a good predictor of mortality on the WL during 2008-2011 (AUROC 0.72). Conclusion: A significant reduction of mortality has been registered on the Romanian WL for LT after 2008, despite the increased severity of liver disease. Abstracts of the 16th Congress of the European Society for Organ Transplantation  Background: Mammilian target of rapamycin inhibitors have been proposed to preserve renal function by estimated renal clearance rates. The presented study investigated their effect compared to calcineurin inhibitors (CNI) on renal function defined by a measured GFR. Methods: GFR was measured in patients on mTOR (n = 28) or on CNI (n = 51) treatment following liver transplantation using the inulin clearance (IC). Estimated GFR was determined using the MDRD 4 formula at baseline, 6, 12, 18 and 24 months. Changes in renal function were compared in patients on CNI or mTOR based immunosuppression. Results: The eGFR declined in patients on CNI (81 vs. 61 ml/min 1.73 m 2 , p = 0.01) and on mTORs (82 vs. 60 ml/min 1.73 m 2 , p = 0.01). The IC did not change throughout the study period in CNI (62 vs. 61 ml/min 1.73 m 2 , p = n.s.) or mTOR (58 vs. 60 ml/min 1.73 m 2 , p = n.s.) patients. The proportion of patients with proteinuria increased significantly in the mTOR group (50% vs. 62%, p ≤ 0.03) and not in the CNI group. Carl Axelsson, Maria Castedal, Styrbj € orn Friman, William Bennet Transplantation Center, Sahlgrenska university Hospital, Gothenburg, Sweden Background: The aim of this study was to evaluate the incidence of newonset diabetes mellitus (NODM), rejection rates and patient-and graft survival following liver transplantation (Ltx) using steroid-free immunosuppression (IS). Methods: Adult Ltx performed 2008-2011 were analysed retrospectively with regards to treatment and outcome. Group 1 (n = 155) received steroid-based IS (TAC, CS AE MMF) and group 2 (n = 83) steroid-free IS (TAC, MMF). The median follow-up times were 976 days and 412 days, respectively. Results: The incidence of NODM in the steroid-group was 31% compared to only 6% in the steroid free group (p < 0.0001). The incidence of biopsy proven acute rejection was 28% in both groups. The incidence of NODM in hepatitis C (HCV+) patients receiving steroid-based IS was 34% compared to 9% in HCV+ patients receiving steroid-free IS (p = 0.05). Conclusion: Steroid-free immunosuppression after Ltx is safe and reduces the incidence of NODM in both non-HCV+ and HCV+ recipients. Hassan Bouyabrine, Jean Pierre Carabalona, Francis Navarro, Fabrizio Panaro, Al Warith Al Hashmi Montpellier University Hospital Background: The incidence of hepatic artery pseudoaneurysm (HAP) is found in 1-2%of liver transplantation (LT) patients.This article discusses the presentation, etiology, types, treatment indications and vascular procedures used to manage this complication. Methods: From 2004 to 2011 LTs were performed at our institution.Of these, nine consecutive patients underwent surgical treatment of HAP. In all cases, revascularization with a reversed autologous saphenous vein by-pass was performed. Results: The median delay between the LT and the HAP diagnosis was 39.6 days.The median diameter was 15.3 mm. In six cases, a biliary leakage was associated with the LT and, in the remaining 3, a mycosis was recorded. At the 5-year follow-up, five patients had normal arterial anatomy and the other three patients had stenosis that was successfully treated by stents. Our conclusions support surgical revascularization with reversed saphenous grafts as a feasible and efficient treatment in cases of HAP. Background: Transarterial chemoembolization (TACE) in patients with hepatocellular carcinoma (HCC) is directly applied in hepatic artery (HA) and may injury it. We describe relationship between pre operative TACE and the apparition of radiologic and histologic HA complications. Methods: All cirrhotic patients with HCC underwent liver transplantation in between 2009 and 2012 are included and divided in two groups: TACE (1) and No-TACE (2). HA complications are reviewed and compared. The recipient HAs were histologically analysed. Results: Sixty-seven patients were reviewed, 32 for group 1 and 35 for group 2. At a mean follow up of 17 months, 10 radiologics HA complications occurred; six in group 1 and four in group 2 (p = 0.2953).Histological screening showed 12 HA injuries in group 1 and 3 in group 2 (p = 0.0124). Conclusion: We found a significant higher rates of histological HA injury in patients underwent to TACE. The demand for liver transplantation (LT) in older patients is increasing. In living donor LT (LDLT), older recipient age was reported to be a significant independent risk factor of graft failure. Thus, many centers now accept 70 years as the cut off limit for LDLT. This retrospective study was undertaken to review the outcome of LDLT in patients aged ≥70 years. Out of 256 patients who underwent LDLT between October 2005 and June 2011, there were eight patients (3.1%) who were 70 years or older at the time of LT. The major complications were limited to bile leak in one case, and vertebral fracture in another patient. There was no perioperative mortality and all patients are alive in a median follow-up of 34 (14-64) months. Our study emphasizes that age by itself should not be used to limit LT. With proper evaluation and careful consideration of donor and recipient factors, septuagenarians can undergo LDLT with acceptable outcome. Objectives: To study relationship between cirrhotic miocardiopathy determined by NT-proBNP plasmatic levels and cirrhosis etiology. Patients and methods: Of 81 candidates to a liver transplantation were studied, 40 enolic cirrhotic patients (group 1). 35 viral cirrhotic patients (group 2) and six primary biliary cirrhosis patients (group 3). Severity of cirrhosis was estimated using Child-Pugh and MELD scores. Clinical ascites was estimated, and Body Mass Index (BMI). A group of healthy volunteers was included as reference group. NT-pro-BNP values were determined in plasma blood samples. Results: There was no significant differences among groups in sex, age, BMI, ascites, and Child-Pugh or MELD scores. NT-proBNP values in male of groups 1 and 2 were significantly enhanced compared to reference group (p < 0.005). Male NT-proBNP values in group 1 were significantly higher than in male of group 2 (p < 0.005). There was no significant differences in female NT-proBNP values. Discussion: NT-proBNP plasma values are enhanced in cirrhotic patients, this is indicative of cirrhotic myocardiopathy. NT-proBNP plasma values were significantly enhanced in enolic patients suggesting an important myocardiopathy. Conclusion: An enhancement of NT-proBNP plasma values in cirrhotic patients is an indication of myocardiopathy, which is more severe in enolic cirrhotic patients. The aim of this study is to investigate whether pretransplant absolute monocyte count in peripheral blood (AMCPB) predicts posttransplant outcomes in patients undergoing liver transplantation (LT) for hepatocellular carcinoma (HCC). We retrospectively analyzed 256 patients who underwent LT for HCC between 2005 and 2012. By using ROC curve analysis, AMCPB >200/mm 3 was considered. On multivariate analysis, pretransplant high AMCPB, positivity of pretransplant 18F-FDG PET and pathologic maximal tumor size >5 cm and presence of microvascular invasion were independent risk factors for recurrence-free survival. When subgroup analysis was done according to the Milan criteria, AMCPB (>200/mm 3 ) was an independent factor to predict tumor recurrence in patients with HCC over the Milan criteria (p = 0.012). Pretransplant AMCPB would be considered as a useful and cost-effective biomarker to predict tumor recurrence after LT for HCC, particularly in patients over the Milan criteria. Background: Combination therapy with everolimus (EVR) and (SORA) is being investigated for recurrence of hepatocellular carcinoma after liver transplantation (LT). Methods: This was a single-center, retrospective analysis on LT recipients with unresectable recurrence of HCC undergoing combination therapy with EVR and SORA. Results: Seven patients (males 100%; median age [IQR] 53 [9] years) were included. HCC recurrence was diagnosed at a median (IQR) of 9 (126) months after LT, and patients received EVR+SORA at a median of 11 (126) months after LT. At a median (IQR) follow-up of 6.5 (14) months, 5 (71.4%) patients are alive and 4 (57.1%) with tumor progression as per mRECIST. Median (IQR) time to progression was 3.5 (12) months. Adverse events led to temporary SORA discontinuation in 2 (28.6%) patients, and to SORA dose reduction in 3 (42.8%). Background: Scanty information is available on feasibility of long-term everolimus (EVR) monotherapy after liver transplantation (LT). Materials: This was a retrospective analysis of EVR-based immunosuppression at a single institution. The endpoint was evaluation of feasibility of EVR monotherapy. Results: Of 212 patients who received EVR at any time point during their post-LT follow-up, 211 (99.5%) were included. 176 patients (83%) attempted EVR withdrawal, while 35 (16.5%) were on combination with EVR +reducedcalcineurin inhibitors (CNI) exposure (r-CNI). A total of 141 (66.5%) patients are alive and on EVR at the latest follow-up (range 1-84 months). Among these latter, 113 (53.3%) are on EVR monotherapy, while 28 (13.2%) are on combination with EVR and r-CNI. Feasibility of EVR monotherapy was 76.7% (135/176) and associated with a 13.9 AE 5.6 ml/min increase in eGFR. Conclusion: EVR monotherapy was feasible in 76.7% of patients and beneficial for renal function. This study assessed outcomes and identified risk factors of posttransplant hepatitis B virus (HBV) recurrence in patients who received prophylaxis with both entecavir (ETV) and hepatitis B immunoglobulin (HBIG) after liver transplantation (LT). We retrospectively analyzed the outcomes and risk factors of posttransplant HBV recurrence in the 155 patients who received prophylaxis with a combination of ETV and HBIG. Posttransplant HBV recurrence occurred in six patients (3.9%) without any ETV-resistant mutants. The overall rates of HBV recurrence at 1, 3 and 5 years were 1.3%, 4.7% and 6.8%, respectively. We found that recurrent HCC was an independent risk factor of HBV recurrence (p = 0.003). Prophylaxis with a combination of ETV and HBIG resulted in a low HBV recurrence rate following LT without any emergence of ETV-resistant mutants. Recurrent HCC was an independent risk factor of HBV recurrence in patients who received prophylaxis with both ETV and HBIG for prophylaxis following LT. The youngest child reported who underwent LT for amanita-induced liver failure was a 2 year old girl. To date no criteria for LT were evaluated in childs under 5 year old. A girl weighing 13 kg (BMI = 17.8) was referred to our center 5 days after poisoning, presented with vomiting and diarrhea 12 h after mushroom consumption. Her grandmother died because of the same poisoining 1 day before and grandfather developed liver and renal failure but survived. At admission the girl had a Glasgow coma score of 10, AST 2050 U/l, ALT 4019 U/l, INR 6, bilirubin 64 M, creatinine 11 M, factor V -23% and factor VII -4%. Her mother started prompt evaluation for possible emergent LDLT. Encephalopathy deteriorated rapidly and she developed seizeres and coma on the same night. Next morning (6th day after ingestion) the patient developed hypoglycaemia (2.2 mM), urea level dropped to 0.6 mM and cLac level raised up to 9.2 mM. That day a pediatric donor became available and she underwent full-size LT from 8-month-old deceased brain donor (BMI = 13, GW = 270 g) using piggy-back technique. HTK solution was used for preservation. Arterial anastomosis was performed between common hepatic arteries of both donor and recipient using the operative microscope and magnification 96-8. Biliary reconstruction was performed in duct-to-duct manner with interrupted 7-0 PDS stitches using the operative microscope and magnification 96-8. Both above mentioned anastomoses were performed with the help of microsurgeon. Explant pathology showed >60% necrosis. She became conscious and breathed spontaneously on POD 2. The girl was discharged 15 days later without complications. Of 18 months later the child is thriving with good graft function and no signs of arterial and biliary strictures. Background: In living-donor liver transplantation (LDLT) for primary biliary cirrhosis (PBC), the recurrence rates have been reported to range 1-40%. In this study, we review our experience in LDLT for PBC. Methods: From June 1997 to December 2012, 153 LDLT were performed, of which 18 (11.8%) patients were indicated for PBC at Tohoku University Hospital. Among them, 14 patients survived for more than 6 months, and were the subjects of the present study. The follow-up period for these patients ranged from 199 to 3524 days after transplantation (median 1758 days). Calcineurin inhibitor at 6 months was tacrolimus in nine patients and cyclosporine in five patients. Mycophenolate mofetil was administered in 10 patients. One patient who underwent ABO-incompatible LDLT received Rituximab. Basiliximab were administered in 11 patients. All patients were maintained by ursodeoxycholic acid. Steroid therapy was discontinued in all except four patients. Result: Male/female ratio was 1:13 and mean age was 52 years old. Two patients died from tongue cancer and drug-induced graft failure, respectively. Rate of biopsy proven rejection was 50%. Although biopsy proven PBC recurrence has not yet seen, increased ALP and rGTP or total bilirubin level probably due to recurrence was seen in five patients. All of them are asymptomatic. In multivariate analysis, the number of HLA mismatch <3 was related to recurrence. Non-or blood related donor factor, and type of immunosuppressant did not correlate with recurrence, prognosis and rate of biopsy proven rejection. Furthermore, sustained elevation of ALP level was seen in seven patients except the patient with metastatic bone cancer. Low serum anti-M2 level before LDLT was related to these abnormality in ALP after transplantation. Conclusion: Although there are some patients with a sign of recurrence, LDLT in PBC showed favorable long-term outcome. Low number of HLA mismatch seems to be a risk factor for recurrence of PBC after LDLT. Furthermore, low anti-M2 level may predict the sustained elevation of serum ALP after LDLT. Chun Soo Lim 1 , Jung Pyo Lee 1 , In Mok Jung 1 , Yon Su Kim 2 1 Seoul National University Boramae Medical Center; 2 Seoul National Liver transplantation (LT) is the treatment of choice for hepatorenal syndrome (HRS). We investigated the outcomes of LT in patients with AKI by acute HA comparing to those of patients with HRS by other causes. A total of 20 acute HA with AKI patients (HA group) were compared with 76 patients with HRS by other causes (HRS group). Preoperative prothrombin time and serum creatinine level were higher in HA group. Total bilirubin level was lower in HA group. There was no difference in model for end-stage liver disease score. Patients' and grafts' survival rate were not different. More patients in HA group needed posttransplant hemodialysis. However, posttransplant eGFR until two months was similar, thereafter, it was better in HAV group than in HRS group. No patients needed long term renal replacement therapy. Pre-and peri-transplant kidney function of HAV group was poorer than that of HRS group. However, posttransplant long term renal outcome could be better in HAV group. Background: Living donor liver transplantation has being increasingly performed to alleviate the shortage of cadaveric liver graft. The main disadvantage of this procedure is the risk of complications or even death in a healthy donor who does not derive any medical benefits from the operative procedure. We present the initial experience of donor morbidity following LDLT at Haeundae Paik hospital during 2 years after opening the hospital. Materials and methods: From August 2010 to July 2012, 13 LDLTs and 1 deceased donor LT were performed at our hospital. Donor demographics, graft type, complications, length of stay and overall survival were evaluated. Donor morbidity was assessed objectively using the modified Clavien-Dindo classification. Results: There were 11 cases of modified right lobe graft (MRL) and two cases of dual grafts (left lobe plus left lateral segment and two left lobe). Median follow-up was 18.5 months. Mean donor age, donor BMI and hospital stay was 25.6 years, 21.5 kg/m 2 and 12.4 days. There was no donor mortality. Wound problem was three cases and fever of unknown origin was developed in one case. All donor morbidities was Grade II (Clavein-Dindo classification) and donor morbidity was 4/15(26.6%). Conclusion: Although small cases, our experience shows that donor hepatectomy for living donor liver transplantation is a safe procedure in a small volume center. Our donor morbidity of 26.6% is comparable to most high volume centers across the world. Meticulous preoperative evaluation, careful operation and proper remnant volume are guarantee for the safety of donors in LDLT. Background: Living donor liver transplantation is widely used for patients with end-stage liver diseases. However, this procedure exposes the donor, a healthy individual, to morbidity and mortality. The overall donor complication is 14.5% and mortality is 0.2%. Patients and methods: This retrospective study analyzes the complications in 110 living donors. Male donors were 84 and females were 26. Right hepatectomy was done in 92 donors, left hepatectomy in four donors and left lateral segmentectomy in 14 donors. Results: We had 30 complications in 30 donors (27.3%). Biliary leakage occurred in 11% of donors, wound infection in 5.5%, re-exploration for hemoperitoneum in 4.5% and chest complications in 3.6%. According to the modified Clavien classification system 12 complications out of 30 were grade I (40%), nine complications were grade IIIa (30%) and nine complications were grade IIIb (30%). We had no donor mortality. Conclusion: Meticulous technical and preoperative evaluation will reduce complications. Natalie Vallant 1 , Herbert Maier 1 , Phillipp Schumpp 1 , Markus Kofler 1 , Stefan Schneeberger 1 , Robert € Ollinger, Johann Pratschke, Felix Aigner Department of General Surgery, Innsbruck Background: Lipocalin-2 (Lcn-2) has been described as a marker and modulator of inflammation during ischemia/reperfusion injury (IRI) following solid organ transplantation. Aim of this study was to analyze Lcn-2 serum expression in the early phase after liver transplantation and to correlate its expression with acute rejection episodes, renal function and longterm graft survival. Methods: Sera of 68 patients undergoing orthotopic liver transplantation were collected perioperatively from days 0 to 15. Lcn-2 expression was analyzed by ELISA and correlated with clinical parameters of allograft rejection, dialysis and graft survival. Results: Lcn-2 serum levels were significantly higher in patients with poor renal function and a significant increase of Lcn-2 was seen in patients before diagnosis of acute rejection. Furthermore, an increase of Lcn-2 expression of more than the median of 115 ng/ml during the observed period was associated with a worse 5-year graft survival compared to patients with an increase below (not statistically significant). Conclusion: Lcn-2 is a marker which is upregulated prior to and during acute graft rejection that can be used for the early diagnosis of acute rejection in liver transplantation and its increase during the early posttransplant phase may predict the outcome in the long term. Faisal Hanif 1 , R.S. Thethi 2 , Abdul Hakeem 1 , Magdy Attia 1 , Ernest Hidalgo 1 1 St James University Hospital; 2 University of Leeds Aims: To determine the renal function (Glomerular Filtration Rate) at 12 weeks in adults receiving a LT with a Tacrolimus based immunosuppression regimen and to identify potential predictive factors. Methods: Retrospective single centre analysis of 115 adult LT recipients from deceased donors in 2011/12. Immunosuppression consisted of Prograf (trough level 5-10 ng/l initial 3 months), Mycophenolate mofetil (1 gram twice daily) and Prednisolone (20 mg to be stopped in 6 weeks). We recorded GFR and tacrolimus trough levels pre and post-operative at week 1, 2, 3, 4, 6, 8 and 12. Variables were compared using student t test or Mann-Whitney when appropriate. Association between GFR week-12 and other variables was established by means of Correlation Coefficients and linear regression (SPSS 19.0). Results: Following LT, a gradual decline in renal function was noted (despite an initial improvement) with a mean and median GFR week-12 of 76 and 72 ml/ min/1.73 m 2 respectively (Table and Figure 1 ). That was significantly lower than pretransplantation (p = 0.001). Pretransplant renal function was significantly correlated with GFR week-12. Tacrolimus trough level plateaued at 7 lg/ l at week-4. At that point, GFR week-4 had a strongly significant correlation with future GFR week-12 (R = 0.716, square-R of 0.512, p = 0.001) and predicted accurately its value by means of a linear regression: GFR week-12 = 25.6+ (0.595 x GFR week-4). Conclusion: In our cohort of patients, tacrolimus level reached 7 lg/l at week-4 and remained largely unchanged until week-12. That was associated with a loss of a quarter of GFR at 3 months. Aiming for a Tacrolimus trough level of 3-5 lg/l at 4 weeks, may result in a better renal function after LT when using the triple immunosuppression regimen. Table 1 . Correlation of GFR week-12 with previous GFR (ml/min/1.73 m 2 ) and Tacrolimus trough levels (lg/l) after LT. Data expressed in mean (standard deviation) and median. Not Significant (NS). Methods: We retrospectively reviewed 806 adult patients who underwent LT in our centre. Evidence of HCC before LT was confirmed by two imaging methods and alpha-fetoprotein (AFP) level and/or biopsy. Incidental HCC was defined as HCC found postoperatively in the explant. Results: Eighty-one patients were transplanted for pkHCC and in 33 patients HCC was diagnosed incidentally in the explant. There were no differences in sex, aetiology of underlying liver disease, time on the waiting list (WL), and level of AFP between the group of pkHCC and iHCC. Further patients' and tumours' characteristics are shown in Table. Neither 3-and 5-year overall survival nor 3and 5-year recurrence-free survival differed in iHCC patients compared to those with pkHCC. The 3-and 5-year survival of both groups, iHCC and pkHCC, was significantly lower than in patients transplanted for other diagnoses (p < 0.001). Sixteen patients had recurrence of HCC (pkHCC vs. iHCC, p = NS). Risk factors for recurrence of HCC in iHCC patients were younger age (p = 0.038) and the presence of vascular invasion (p = 0.04) compared to the presence of vascular invasion (p = 0.003), the size of the largest lesion (p = 0.007), and shorter time on the WL (p = 0.006) in pkHCC patients. The only prognostic factor affecting significantly patients' survival was poor tumour differentiation-G3 (p = 0.03) in those with pkHCC, no factor was identified in the group of iHCC. Conclusion: Despite an incidental finding, patients with iHCC do not differ from pkHCC in terms of recurrence-free survival and overall survival. The occurrence of iHCC significantly influences the post-transplant prognosis similarly to the patients with pkHCC. Background: Incidence of hyperfibrinolysis and application of antifibrinolytics were widely studied during deceased donor liver transplantation. However, living donor liver transplantation (LDLT) may be different in many aspects including fibrinolysis. So we investigated the incidence of hyperfibrinolysis during LDLT. Methods/materials: We reviewed the medical records of 200 liver transplantation recipients from May 2011 to Sep 2013. Antifibrinolytics were not routinely administered during LDLT in our hospital. Histidine-tryptophan-ketoglutarate solution was used as preservation solution. Hyperfibrinolysis was diagnosed by thromboelastograph (TEG) when LY60 was greater than 15. Results: After excluding adult deceased donor liver transplantation (n = 44), pediatric recipients (n = 27), error TEG case (n = 1), and antifibrinolytics before reperfusion (n = 5), 123 adult LDLT recipients were included in the final analysis. Recipients included 94 men and 29 women, and age was 52.1 ¾ 8.5 years. MELD score of recipients was 15.0 ¾ 8.8. Main indications of LDLT were hepatitis B virus-related liver cirrhosis (13%) or hepatocelluar carcinoma (HCC) (55%). Other indications were hepatitis C virus-related liver cirrhosis (2%) or HCC (5%), alcoholic liver cirrhosis (10%), and etc. Hyperfibrinolysis were uncommon in preanhepatic phase; 2% before incision and 7% at the start of anhepatic phase. Hyperfibrinolysis was increased during anhepatic phase and peaked immediately after reperfusion; 30% at 1 h after anhepatic phase and 80% at 5 min after reperfusion. However, hyperfibrinolysis nearly disappeared without antifibrinolytics and did not recur; 2% at 1 h after reperfusion and 0% at 3 h after reperfusion. Conclusion: Hyperfibrinolysis frequently occurred after reperfusion of LDLT, and rapidly resolved without specific treatment. The significance of hyperfibrinolysis and the application of antifibrinolytics during LDLT should be investigated with further study. Sung-Gyu Lee, Chul-Soo Ahn, Ki-Hun Kim, Tae-yong Ha, HyungWoo Park, YongKyu Chung, EunKyung Jwa, Dong-Hwan Jung Division of Liver Transplantation and Hepatobiliary Surgery, Department of Surgery, Asan Medical Cen Backgrounds: First pediatric living donor liver transplantation (LDLT) was performed in 1994. In 1997, the first successful right-liver LDLT for adults was performed at the Asan Medical Center. The number of LDLTs has increased annually, with 317 transplantations performed in 2011. Methods: From 1994 to Sep.2012, we performed more than 3000 LDLT. We reviewed the recent changes of LDLT during this period. Results: Most common indication of pediatric LDLT was biliary atresia and acute liver failure. HBV associated liver cirrhosis (HBV LC) was most common indication of adult LDLT. Proportion of HBV LC has been decreasing from 80% to 67% and alcoholic LC and HCV LC have been increasing up to 11% and 6% recently. Recently urgent LDLT including UNOS I and 2A decreased due to national increase of DDLT. Proportion of hepatocellular carcinoma positive patient in adult LDLT has been increased up to 52.3%. The goal of donor evaluation is to determine whether the donor is medically and psychologically suitable for living donation. Anatomical limitation in living liver donor depends on availability of living donor and technical feasibility of individual centers and donor complication rate. Laparoscopic -assisted, hand-assisted, or minimal Incision donor hepatectomy has been increasing. Major reasons of rejection as suitable live-donors have been ABO blood group incompatibility, unsafe donor liver anatomy concerning small remnant liver volume, small-for-size graft, and the associated donor comorbidities. Dual LDLT, donor exchange LDLT, ABO incompatible LT can expand donor pool in LDLT field. We performed more than 300 adult dual LDLT with various types of graft. Background: Familial amyloid polyneuropathy (FAP) is most commonly associated with a mutation of the transthyretin-gene (TTR) with more than 8o amyloidogenic variants known so far. The phenotype is highly variable and linked to the underlying mutation, with significant effects on the outcome of liver transplantation, currently the only curative treatment option. To optimize patient selection for transplantation, emphasis should be placed on the specific mutation involved. High frequency mutations have been detected in endemic areas such as Sweden, Portugal and Japan. Minimization of damage from cold ischemia and reperfusion is critical to the success of liver transplantation (LT). A variety of solutions are today used worldwide. IGL-1 solution is a new solution containing the polyethylene glycol component but is not as yet widely used in liver grafts. The aim of this study was to compare the liver function of transplanted grafts stored in IGL-1 to that of grafts stored in CEL or UW. We analyzed data of 400 first cadaveric full-size LTs (117 IGL-1, 160 CEL and 123 UW) performed between 2007 and 2012 in our center. Primary dysfunction (PDF) and non-function (PNF), kinetics of liver function, reperfusion biopsy, patient and graft survival, and cause of death or graft loss were compared for the three groups. The three groups were similar in terms of donor, recipient, and surgical techniques variables. In post-LT outcome data: (i) the peak of Alanine aminotransferase was lower with IGL-1 than with CEL or UW (p < 0.04), and INR at day-5 was lower in CEL than in IGL-1 or UW (p < 0.03); (ii) proportion of PDF-PNF were similar in the three groups; (iii) graft survival was not statistically different with UW, CEL or IGL-1 (91%, 92% and 98%, respectively at 3 months, and 85%, 85% and 89%, respectively at 1-year); (iv) Cause of graft loss was similar in the three groups. In conclusion, liver graft injury seems to be reduced and liver function recovery better with IGL-1. However incidence of PDF-PNF and graft outcome were comparable with the three solutions. Background: Postoperative thrombocytopenia by increasing bleeding risk can become a serious problem in liver transplant (LT) recipients. The aim of the study was to assess risk factors for early postoperative thrombocytopenia. Material/method: After approval of the local ethics committee we retrospectively analyzed 50 consecutive patients who underwent LT between March and December 2012. Spleen size, coagulation status were recorded prior to surgery. Intraoperative blood loss and blood product transfusion (BPT) were measured. Platelet count (PLT) was assessed at 8 h interval for 48 h and then twice daily. A statistical analysis was performed using SPSS v.19.0. Results: Preoperatively, 23.6% of the patients had severe thrombocytopenia (<50 000 elem/mm 3 ); the mean PLT before LT being 70 000 elem/mm 3 . Eighty percent of patients (n = 40) had hypersplenism with a median spleen size of 159.5 mm. Median intraoperative blood loss was 4525 ml requiring a median BPT of 7 units packed red blood cells (PRBc). Twenty-one patients (43%) required platelet transfusion with a median value of 5 units. The mean value of PLT immediately postoperatively was 46 000 elem/mm 3 , on the 5th day of 39 000 elem/mm 3 and then of 50 000 elem/mm 3 on the 7th day. Risk factors for low PLT immediately after surgery were: pretransplant low PLT (p < 0.001), size of the spleen (p = 0.034), intraoperative blood loss (p = 0.043) and BPT (PRBc-p < 0.001). In the multivariate analyses only the size of the spleen and pretransplant PLT remained statistically significant. Conclusion: Intraoperative blood loss and transfusion requirements as well as low values for PLT due to hypersplenism before LT procedure influence PLT in the postoperative period, and at least one of those causes is amendable, the intraoperative blood loss. Leen Schepers 1 , Rik Gosselink 2 , Frederik Nevens 1 , Jacques Pirenne 1 , Diethard Monbaliu 1 1 University Hospitals Leuven; 2 Katholic University Leuven Background: Liver transplantation (LTx) has become the first line treatment for patients suffering from irreversible end-stage liver disease. Exercise capacity and muscle strength are often impaired in patients with end-stage liver disease and data of recovery after LTx are scarce. The aim of this study was to examine the effect of LTx on recovery of physical fitness. Methods: Patients on the active waiting list were included for this observational study. Maximal ergospirometry (VO2max) measuring exercise capacity, 6 min walking distance (6MWD) assessing functional exercise capacity and peripheral muscle strength (quadriceps and handgrip force) were measured the moment of activation on the waiting list (before LTx), shortly (~3 weeks) after LTx and 3 months after LTx. Results: Of 21 patients (age 55 AE 11 years,10 male) were included. Indications were cirrhosis (n = 6), HCC (n = 8), non-alcoholic steatohepatitis (n = 2), cholestatic liver disease (n = 3) and other (n = 2). Before LTx, 6MWD (69 AE 21%pred) and quadriceps force (61 AE 20%pred) were severely impaired. VO2max (84 AE 30%pred) and handgrip force (87 AE 27%pred) were moderately impaired. Using repeated measures ANOVA, significant changes were observed for 6MWD (p < 0.0001) and quadriceps force (p < 0.01): at 3 months, 6MWD (79 AE 19%pred) had improved compared to shortly after LTx (62 AE 20%pred; p < 0.001) and before LTx (p < 0.05). At 3 months, quadriceps force (68 AE 18%pred) had increased significantly compared to shortly after LTx (54 AE 14%pred; p < 0.01) in contrast to before LTx (p = 0.11). There were no significant changes of VO2max (p = 0.21) or handgrip force (p = 0.14), which at 3 months remained lower than predicted (75 AE 21%pred, and 86 AE 23%pred respectively). Conclusions: Exercise capacity and muscle strength are impaired in LTx candidates. At 3 months after LTx, quadriceps force and 6MWD improve but all measurements remain impaired. Longer follow-up data are now collected. Background aim: Muscle wasting is a common complication in patients undergoing liver transplantation (LT). Although malnutrition has been identified as a predictor of poor outcome after surgery, less information are available regarding the sequential changes of body composition after LT. This study aims to investigate changes in body composition after LT. Methods: Adult patients eligible for elective LT were included. Nutritional assessment (anthropometry and Dual-energy X-ray absorptiometry [DEXA]) was performed in all patients before and 1, 3, 6 and 12 months after LT. Triceps-skin fold thickness (TSF) was measured and Mid-arm muscle circumference (MAMC) was calculated according to standard equation. Fat-Free Mass Index (FFMI, kg/m 2 ) and Fat Mass Index (FMI, kg/m 2 ) were calculated by whole body DEXA scan. Results: Sixty-four adult patients awaiting for LT were initially studied. Results refer to 27 patients who were transplanted and completed 1 year of follow-up (Table 1 ). At LT 33% of patients presented a fat-free mass depletion while 4.8% showed a depletion in fat mass. During the first year after LT, while fat mass (TSF and FMI) increased progressively (form 15.4 to 19 mm, and from 6.7 to 7.7 kg/m 2 , before and 12 months after LT, respectively, p < 0.05), fat free mass (MAMC and FFMI) failed to ameliorate. The percentage of patients with fat-free mass depletion (FFMI below 10th percentile) was even increased 1 year after LT (from 33% before LT to 63% 12 months after LT p < 0.05) (Figs  1 and 2) . Conclusion: During the first year after LT the fat mass is progressively regained while the recovery of the fat free mass is insignificant and may require a longer period. Background: Calcinurin inhibitors (CNI) associated chronic nephrotoxicity has become a serious problem which threatens the prognosis of liver transplant recipients. This study was aimed to find out the relationship between serum cytokines, chemokines and chronic tacrolimus (Tac) induced nephrotoxicity. We detected the posttransplant serum inflammatory cytokines and chemokines levels in liver transplant recipients to illuminate the correlations of inflammatory cytokines or chemokines with the chronic renal injury. Methods: A total of 136 living donor liver transplant recipients (107 males and 29 females) and 150 healthy controls (120 males and 30 females) were enrolled in this study. All the recipients had normal Cystatin C (Cys-C) and normal urine microalbumin before transplantation and received Tac-based immunosuppressive regime (Tac+MMF+ prednisone) afterwards. A human 10plex antibody bead kit (BioSource, Camarillo, CA) was used to measure the levels of 10 cytokines and chemokines in 50 ml of serum from each transplant patient and controls. After transplantation, serum Cys-C and urine microproteins including ¦ A1 microalbumin (¦ A1M), microalbumin (MA), transferring (TRU) and IgG (IgU) were measured among 136 allo-liver recipients to evaluate whether they had early renal injury and the probable location of the renal lesion. Results: The levels of IL-6, IL-10, IFN-¦Ã, IP-10 and MCP-1 in the recipients' group were significantly higher than those in the control group (p < 0.05), while the levels of IL-8 was on the contrary (p < 0.05). In early renal damage group (Cys-C > 1 mg/l), the concentration of IP-10 was much higher compared to the group with normal renal function (Cys-C¡ € U1 mg/l), whereas the concentration of MCP-1 in early renal damage group was lower than the group with normal renal function. The concentration of IP-10 in the group with tubulointerstitial injury (¦ A1M >12.5 mg/l)was much higher compared with the group without such injury (¦ A1M¡ € U12.5 mg/l). Conclusions: IP10 may be the important cytokine leading to chronic CNIinduced nephrotoxicity, especially the tubulointe. Background: Chronic HCV infection is known as a national problem in Egypt. Egypt has a very high prevalence of HCV infection and a high morbidity and mortality from chronic liver disease, cirrhosis, and hepatocellular carcinoma. With the availability of liver transplantation as an effective therapy for chronic end stage liver disease and with the progressively improved outcome and survival; the occurrence and the prevalence of post transplantation complications are increasing. The occurrence of post liver transplantation diabetes mellitus, or hypertension are increasingly recognized as a contributor to cardiovascular complications and late morbidity and mortality in transplanted patients. Aim: The aim of our research was to study post-liver transplantation diabetes and hypertension as regards evaluation of the overall prevalence of the diabetes and hypertension and identification of the predictors for posttransplant diabetes and hypertension. Methods: Our study involved 40 patients. We collected the data of the patients from the database of the patients in the liver transplant unit in Almanial Altakhasosy hospital. We collected data reagarding age, sex, BMI, preoperative labs of the patients, their child class, cause of the liver transplant, the immunosuppressants received by the patients, whether they received pulse steroids or not, whether the patients were diabetic and hypertensive before the transplant and the treatment they used to receive if so, and whether they developed DM or hypertension after the transplant and if so the treatment they received. Results: 10% of the patients involved in our study were diabetic before the transplant, 25% of them acquired diabetes after the transplant to give a total of 35% diabetic patients after the transplant. Predictors of PTDM were pretransplant FBS and Child class C. 25% of the patients developed posttransplantation hypertension. Predictors of posttransplantation hypertension were BMI and using Neoral. Abstracts of the 16th Congress of the European Society for Organ Transplantation Background: Success of liver transplantation is limited by recurrent graft infection. This study is to explore the relationship between soluble costimulatory molecules and hepatitis recurrence. Method: Of 81 end-stage liver disease secondary to HBV who underwent liver transplantation were included. They received a calcineurin inhibitor (CNI) based regimen after transplantation. There were 11 patients had HBV recurrence. Soluble Cytotoxic T Lymphocyte-Associated Antigen-4 (sCTLA-4), sCD28, sCD80, sCD86 and IFN-¦Ã concentrations in plasma were measured by enzyme-linked immunosorbent assay (ELISA) (eBioscience). Results: There was no significant difference about plasma concentration of sCD28, sCTLA-4, sCD80 and sCD86 between the two groups: HBV recurrent and no recurrent after liver transplantation, however IFN-¦Ã significantly decreased in HBV recurrent recipients. Background: With increasing liver transplant recipients with chronic kidney lesion, we investigated the role of CYP2C8 and cytokines in the pathology of chronic kidney injury in the liver transplant recipients. Methods/materials: High resolution melting curve was used to genotype CYP2C8 polymorphism. Cytokines/chemokines in our study including IL-6, IL-8, IL-10, IL-17, IFN-¦Ã, IP-10 was assessed using Elisa kits. Results: In total, 185 patients were recruited in this study including 141 males and 44 females. We successfully genotyped CYP2C8 and found only two genotypes (160 patients with CYP2C8*1*1, 25 patients with CYP2C8*3*1) in the patients. After logistic regression adjusting for age and sex, Neither the CYP2C8 polymorphim nor cytokine/chemokine results (CYP2C8, p = 0.102; IL-6, p = 0.322; IL-8, p = 0.362; IL-10, p = 0.335; IL-17, p = 0.525; IFN-¦Ã, p = 0.332; IP-10, p = 0.588) associate with the chronic kidney injury. Conclusion: Our study showed that none of the surmised factors including CYP2C8, cytokine or chemokines contribute to chronic kidney injury based on our current data. With increasing survival after orthotopic liver transplantation (OLT), metabolic syndrome and its individual components, including diabetes mellitus, hypertension, dyslipidemia, and obesity, are increasingly being identified and contributing to cardiovascular complications and late morbidity and mortality. MS develops in 43% to 58% of patients after OLT; this is higher than the prevalence of MS reported in the normal adult population 24%. Metabolic Syndrome (MS) increases the risk for Coronary Artery Disease, stroke and diabetes. As a result of increased incidence of development of metabolic syndrome and its complications, outcome of liver transplantation becomes poor. Predisposing factors may include higher age at transplant, an increase in BMI post-OLT, pre-OLT diabetes, a history of smoking, the immunosuppressant regimen used, and the indication for OLT (hepatitis C, alcohol, or cryptogenic cirrhosis). There are some published studies that have specifically reported the development of individual components of MS following OLT especially Diabetes and Hypertension. The estimated prevalence of PTDM and posttransplant hypertension varied from a study to another and there is a debate between researchers about their predisposing factors. However, HCV ad Tacrolimus are considered by most authors to be predisposing to PTDM while Cyclosporine is believed to increase the incidence of posttransplant hypertension. Hakan Sozen, Utku Tonyuk, Ayd y n Dalgic Gazi University Living donor hepatectomy (LDH) for living related liver transplantation (LRLT) has begun an accepted and widely used worldwide. Aim: To assess surgical outcome of living donor hepatectomies as a single center experience. Material and methods: Totally 22 living donor hepatectomies were performed at Gazi University Transplantation Center/Ankara/Turkey since 2006.All data retrospectively collected from hospital charts. Results: There were 13 female, nine male as donor. Donors' origin was 12 parents, four siblings, two spouses, one aunt, 1nephiew and two others. Mean age of the donor was 32 AE 7.5 years (between 23-48 years). Mean BMI of the donor was 27.2 AE 1.9 (median 27). Eleven out of 22 right hepatectomies, 8 out of 22 left and 2 left-lateral hepatectomies were performed. The mean remnant liver left at the donor liver percentage for right hepatectomy was 33.8 AE 4 (median 35) and median graft-to-recipient body weight ratio of the right lobe was 1.7% (between 0.9% and 1.5%).The mean intraoperative blood transfusion was 1.3 AE 1.4 U (0-6 U ES). Donors' average hospital stay was 9 AE 3 days (6-17 days, median 9 days) found. We have not seen any late surgical complications. But as early surgical complication, postsurgical bleeding (n = 1; 4.5%) detected in this study group.Patient re-explored and was found that blood was coming from left gastric artery stump. Stump succesfully repaired again without any problem. This patient discharged at D7 after surgery. We have not seen any vascular complication at the post-hepatectomy period. Conclusion: Donor hepatectomy for living liver transplantation is a safe procedure. We believe that, donor safety should be the first priority of all living liver donor programs and it is efficient way of treatment method whom are at the waiting list. after LT presented with a mean disease-free survival of 11.9 months and an overall survival of 22.7 months. 9 of 15 patients died after a mean period of 5.6 months after diagnosis of tumour recurrence. The other 6 patients demonstrated a mean survival of 34.9 months. Their tumour-specific therapy included chemotherapy with Sorafenib, resection of a single metastasis, RFA of a recurrent tumour in the liver and switching immunosuppressive therapy to everolimus. In our study group neither Milan criteria, waiting time, bridging therapies, AFP blood levels nor pathological grading had an influence on the tumour recurrence. Only microvascular invasion was a major risk factor for HCC recurrence. Conclusion: Reliable prognostic markers related to tumour biology and adjuvant therapies are still missing. Novel molecular profiling techniques and novel therapies getting more and more important in times of severe organ shortage. The aim the study to present our experience in treatment of biliary structures after liver transplantation by placement fully covered self-expandable metallic stents (FCSEMS). From 12/2004 to 11/2012 we performed 136 cadaveric liver transplantations to adult recipients. Biliary reconstructions were choledochocholedohostomy without external drainage -96 (70.1%). With T-tube 20 case (14.7%). Choledochoenterostomy -20 recipients, accounting for 14.7%. Our data shows that the incidence of early and late biliary structures is 5.4%. Seven patients was treated by placement of FCSEMS. Four stents had been installed by retrograde cholangiopancreatography, 2 by ante-grade within 1-12 month after liver transplantation. Mean follow up time was 12 months. No severe complications were observed after, only two patients developed mild cholagitis. We can conclude that application of FCSEMS is safe and effective method of treatment biliary structures after liver transplantation. Long-term follow-up results should be evaluated. Background: The H2307 study is designed to evaluate the efficacy and safety of everolimus (EVR) with reduced tacrolimus (rTAC) versus standard TAC (TAC-C) in living donor liver transplant (LDLT) recipients. Methods: This is a 24-month (mo), multicentre, randomized study in de novo LDLT recipients. Patients will be randomized (1:1) to receive EVR+rTAC or TAC-C (figure). The primary endpoint is the rate of composite efficacy failure events (treated biopsy proven acute rejection, graft loss or death) at 12 mo post-transplantation. Secondary endpoints: evolution of renal function, inci-dence of adverse events, recurrence of hepatocellular carcinoma, load of hepatitis C virus and progression of graft fibrosis, and allograft regeneration. At least 470 de novo LDLT recipients will be enrolled from Europe, Asia and North America. Results: Expected in early 2016. Conclusion: This is the first study designed to evaluate the efficacy and safety of EVR+rTAC versus TAC-C in LDLT recipients. Background: Acute-on-chronic liver failure (AoCLF) occurs in lymphoma patients secondary to hepatitis B virus (HBV) reactivation due to chemotherapy. Liver transplantation (LT) is generally not performed in these patients. We aimed to identify characteristics of patients who underwent LT because of AoCLF that occurred due to HBV reactivation in the setting of lymphoma and to compare these patients with AoCLF patients who did not have lymphoma. Methods: Twenty patients underwent LT due to AoCLF between February 2009 and June 2011. Among these patients, five patients were diagnosed with lymphoma prior to liver transplantation and assigned to Group 1. The remaining patients (n = 15) did not have lymphoma were assigned to Group 2. Results: Hospitalization after transplantation in Group 2 was longer than in Group 1 (p = 0.014). However, there were no statistical differences in other variables between the two groups. The overall survival rate of Group 1 was lower than that of Group 2, but there was no statistically significant difference between the two groups (p = 0.134). With the exception of one patient, the median time from complete remission to liver transplantation in Group 1 was 4.5 months (range, 1-15) in Group 1. Lymphoma recurrence occurred in only one patient 8 months after transplantation. Conclusion: Our study revealed that LT is a feasible and effective approach in AoCLF due to HBV reactivation in selected lymphoma patients. Ynstitute. Mean age of donors was 31 (18-65) years, body mass index 27.4 (24-36) kg/m 2 , follow-up duration 39 month (2-58). Right hemihepatectomies were performed in 538 (89.6%) donors, left hemihepatectomies in 19 (3.1%) and left lateral sectorectomies (two and three segments) were done in 43 (7.2%) donors. Mean remnant liver volume for donors was 37% (26-87%), duration of operation -327 min (205-440 min), intraoperative blood loss -310 ml (100-800 ml) and hospital stay was 7.2 days (5-13 days). Results: There was no mortality. The 187 posoperative complications were observed in 116 of 600 (19.3%) donors. According to Clavien classification first degee complications were occured in 91 (15%) cases, second degree in 20 (3.3%), IIIa degree in 32 (5.3%), IIIb degree in 43 (7.3%) and IVa degree complication in 1 (0.16%) donor. Most of complications were mild (59.3%) and managed conservatively. Biliary complications wich included biliary likage, bilioma and strictures were observed more freqently (10.6%). Reoperations were nedeed in 34 donors. Conclusion: Most of the postoperative complications in living liver donors are mild degree and biliary complications are more frequent. pediatric ones; until the end of 2012 every liver was allocated in order to a regional rotation system. But this model not always allowed the transplant for patients in clinically worst conditions, except for those case of well defined urgency. Methods/materials: For this reason, at the beginning of 2013 CRTL started to use a new regional system that allocates the liver following an algorithm according to MELDNa value, time in waiting list, combined transplant, identity/ compatibility AB0. Results/conclusions: We observed that for the first two months of 2013 the medium MELD-Na value for transplanted patients was 22.3 (15 pts) vs. 19.8 of 2012 (98 pts) and it seems to confirm that we are going to a more ethical direction to give organs to clinically worst patients. Methods: Of 83 consecutive ALDLTs (71 right, 12 left) were planned with 3D CASP. Graft, remnant, and total liver volume compliance were compared to actual intra-operative values. Computed risk analysis encompassing territorial liver mapping, functional volumes, outflow congestion volumes in grafts/ remnants was utilized for the management of the middle hepatic vein (MHV). Results: Graft volume compliance was 13.5 AE 4.4%. Small-for-size (SFS) grafts with lethal SFS syndrome (SFSS) had poor volume compliance with maximal graft-volume-body-weight-ratios (GVBWR) <0.83. SFS grafts with reversible/absent SFSS had maximal GVBWR of 0.9-1.16. Significant differences were identified for: (i) graft/remnant congestion volumes of risky vs. nonrisky MHV-types (49 AE 6%/34 AE 7% vs. 29 AE 8%/33 AE 12%), (ii) functional-(f)-vs. surgical-(s)-volumes of grafts (527 AE 119 ml vs. 963 AE 176 ml) and remnants (419 AE 182 ml vs. 640 AE 213 ml). Conclusions: CASP allowed for (i) prevention of SFS syndrome in extremely small grafts by predicting donor liver plasticity (ii) individualized MHV management for donors and recipients based on computed risk analysis. Chutwichai Tovikkai 1 , Susan C. Charman 2 , Jan H.P. van der Meulen 3 , Alexander E. Gimson 4 , Raaj K. Praseedom 4 1 University of Cambridge; 2 Royal College of Surgeons of England; 3 London School of Hygiene and Tropical Medicine; 4 Cambridge University Hospital NHS Foundation Trust, Addenbrooke's Hospital Background: Emergency or unplanned readmission after liver transplantation can be resource-consuming, and should be minimised. We explored risk factors associated with emergency readmission after liver transplantation. Methods: A linked UK liver transplant -Hospital Episode Statistics database of adult first liver transplants between 2000 and 2009 was analysed. Emergency readmissions within 30 days after discharge were identified. Of 17 pretransplant recipient factors, six donor factors, four operative factors and transplant length of stay (LOS) were considered. Univariable logistic regression was used to identify factors associated with emergency readmission. Those factors with p < 0.2 in the univariable analysis were included in a multivariable model, which was further adjusted for age, sex, indication and centre. Results: Of 3311 adult liver transplant patients were included, of whom 929 (28.1%) had emergency readmission within 30 days. Life style activity score (p = 0.09) and LOS (p = 0.09) were weakly associated with emergency readmission rate; the odds ratio for patients with life style activity score 4-5 compared to 1-2 was 1.3 [95%CI: 1.0-1.6], while the odds ratio for patients with LOS > 60 days compared to 14-60 days was 1. Background: Patients with hypersplenism after liver transplantation (LTx) have low tolerance to early initiation of combined antiviral treatment with fulldose interferon (IFN) and ribavirin (RBV) for the recurrent hepatitis C. Thus we perform LTx without splenectomy and initially treat recurrent heptatits C with low-dose IFN/RBV and persist the treatment for the extended period. Objective: To evaluate the long-term result of antiviral treatment for hepatitis C virus (HCV) following living donor liver transplantation (LDLT) without splenectomy. Patients: We studied 23 adult recipients who underwent LDLT for HCV related liver cirrhosis. Antiviral treatment was initiated with low-dose pegylated IFN alpha2b (1 lg/kg/week) and RBV (300 mg/day) promptly after pathological diagnosis as hepatitis C. IFN/RBV was continued for at least 24 months after the serum HCV-RNA became negative with dosage adjusting. Even If recipient was null responder, antiviral treatment was not canceled. Result: The median age of the patients was 60y (39-68). The median Model for End-Stage Liver Disease score was 11 (5-24). Eighteen patients received antiviral treatment. Median platelet count at the initiation of antiviral treatment was 10.3 9 104/ll (4.1-31.4 9 104). The treatment was initiated an average of 4.1 months (0.7-12.1) after LTx. Even though, dose reduction was temporarily needed in all patients, HCV-RNA was not detected in 11 patients (61.1%) an average of 12.4 months (0.9-34.9) after the initiation. These 11 patients achieved sustained virological response (SVR). During follow-up period (median 47.4 months: 14.3-107.2), there was no Relapser in the SVR group and mild fibrosis of liver parenchyma was detected only in 2 of 7 patients (28.8%) who did not achieve SVR. At one year after LTx, platelet count was preserved (median 8.4 9 104: 2.2 9 104-14.7 9 104). Conclusion: Low dose and long-term persistence IFN/RBV therapy following LDLT without splenectomy is feasible with acceptable outcome. JunChul Jung, Choi Gyu-seong, HyungChul Kim Soon Chun Hyang university hospital Bucheon Background: Right-sided diaphragmatic hernia after living donor Right hepatectomy has been rare complication. we report a Right-sided diaphragmatic hernia in a living donor. Methods: A 26-year-old man underwent donor right hepatectomy for living donor liver transplantation. Three months after liver donation, he presented with upper abdominal pain and vomitting. Computed Tomography revealed a diaphragmatic hernia of the right thorax with stragnulation. Results: He underwent laparotomy and a 3 cm defect in the right diaphragm was identified and repaired with interrupted polypropylene suture, after operation, the patient remains well. Conclusions: Throughout the expansion of living donor liver transplantion, the safety of the donor is most important thing. Diaphragmatic hernia is a rare complication of right donor hepatectomy but may occur. And early diagnosis and prompt management is needed for donor safety. Purpose: Orthotopic liver transplantation is typically associated with large volume blood loss. Technological and pharmacological advances permit liver transplantation in patients who formerly were not candidates for this surgery because of strict limitations on blood product administration. We describe a liver transplant in a Jehovah's Witness with liver cirrhosis related with HBV infection. Clinical features: A 52-year-old Jehovah's Witness with liver cirrhosis related with HBV infection and end stage liver disease presenting with uncontrolled ascites underwent orthotopic liver transplantation. MELD score was 18. Recombinant human erythropoietin (10 000 IU sc every 2 days for 4 weeks, then 10 000 IU sc every day for one week) established a normal hemoglobin concentration preoperatively (>13.1 g/dl compared with 7.3 g/dl baseline). Intraoperatively, strategies for reducing risk of blood product transfusion included avoidance of hypothermia (temperature>35¡AEC), minimal blood sampling (1 ml samples only four times), normovolemic hemodilution (3 units) and return of blood (300 ml) scavenged from the operative field. Estimated blood loss was 800 ml. The preoperative and postoperative hemoglobin concentration was 13.4 g/dl (hematocrit 0.38) and 11.4 g/dl (hematocrit 0.32), respectively. No blood products were required and he was discharged 15 days postoperatively without complication. Conclusion: Technological and pharmacological advances allow patients to undergo surgery traditionally associated with large volume blood loss with reduced risk of blood product administration. Background: Highly sensitized patients in organ transplant field have more chance to meet rejection, which result in decreased graft function. Circulating donor specific antibodies (DSAs) immunologically challenge to vascular endothelium and bile duct. However, liver is well known as an immune tolerant organ that can escape from immunologic challenges. This study was designed for analysis of adult living donor liver transplantation (LDLT) undergone in recipients with DSA. Patients and methods: A total 219 recipients who underwent LDLT between June 2006 and August 2012 in our center were enrolled. We retrospectively analyzed the patients dividing into two groups according to presence of DSA. Results: Among 219 patients, 32 patients (14.6%) showed presence of DSA and 187 patients (85.4%) showed no DSA. Class 1 DSA presented in 19 patients, class 2 in six patients, and both in seven patients. Seven patients (3.2%) showed DSA in HLA-A, four patients (1.8%) showed in HLA-B, seven patients (3.2%) showed in HLA-DR, and 14 patients (6.4%) showed in two or more of them. Pre-transplant clinical features (donor sex, donor age, relation, recipient age, MELD score) of two groups were not different from each other. However, more female recipients showed DSA than male recipients in DSA+ group (59.4% vs. 16.0%, respectively). DSA+ group showed significantly higher both PRA class 1 and 2 than DSAÀ group (54.8¡¾39.5% vs. 4.7¡¾12.1% in class 1, and 42.1¡¾39.3% vs. 0.9¡¾1.6%, respectively). There were no significant differences in incidence of primary non-function, acute rejection, vascular complications, and biliary complications. Also, graft survival rate of two groups showed no significant difference (Fig. 1) . Conclusion: In LDLT, DSA cannot affect graft outcomes such as vascular and biliary complications, acute rejection, and graft survival rate. Background: Retransplantations are difficult procedures and have higher morbidities and mortalities due to dense adhesions. Some fascilitating maneuvers of retransplantations are challenging and here we described one of them. Methods/materials: A 27-year old man with chronic artery thrombosis after three months ago deceased liver transplantation was admitted for retransplantation. A related living right lob liver transplantation was planned. During recipient hepatectomy, hepatic hilum was transected first but retroperitoneal dissection and identification of the original vena cava were very difficult. Prolonged operative time and blood loss caused intestinal congestion and a temporary porto-caval shunt required. For porto-caval shunt, we used the recipient portal vein and the lower pole of the piggy-back vena cava. It was performed without clamping the original vena cava so caval blood from the first cava went on. The liver was removed by preserving bot vena cavas (Figure 1 ). Living donor graft was implanted to the piggyback vena cava as well. The temporary shunt was divided and portal vein was anastomosed to the graft portal vein. Arterial anastomosis was performed with recipients gastroepiploic artery and the biliary reconstruction was fashioned by Roux-en-Y hepaticojejunostomy. Conclusion: As a conclusion, when a temporary porto-caval shunt required during retransplantation, piggyback cava can be used safely. Background: The urgent retransplantation (reLT) (which take place in the first week after the first transplant, usually occurs by primary graft failure or vascular complications, retransplantation of the liver is the only option for survival when the transplanted graft fails. The causes for elective reLT are different from the urgent reLT. While ReLT remains controversial because of inferior survival outcomes compared with primary-LT, so elective retransplantation is controversial when donors want to optimize and prevent mortality on waiting lists. Methods/materials: We performed a retrospective analysis of 224 adult patients who underwent elective reLT with deceased donor, in 12 centers in Spain between 1 January 2000 and 31 December 2010. We performed a database of donor and recipient variables, patients were analyzed according to the risk scores Rosen (formula of Risk = 10*[0.0236*(age at second listing) + 0.125*(bilirubin) + 0.438 (creatinine) À 0.234 * (interval to reLT)] to separate patients into low (<16), intermediate (16.1-20.49) , and high (>20.5) risk groups) and MELD score>25 or MELD score<25 at the time of reLT. Patients were analyzed in two groups: 116 non-HCV and 100 HCV and has made a study of survival in these patients. Continuous data were reported as median _ standard error. Survival estimates were calculated using the Kaplan-Meier method, Comparisons of outcome among the groups were made using the log-rank test. A p value of <0.05 was considered statistically significant. SAS version 9.2 for Windows was used for data analysis. Results: The mean age of patients was 50, 2 (DE:11.7) years. The causes of elective reLT were: recurrence of base disease 30%, ischemic cholangiopathy 27% and 19% rejection. The mean age of the donor was 49 years (DE: 18.5). Overall survival of elective retransplantation at 1, 3 and 5 years was 66.4%, 56.9% and 51.4%. We found no differences in survival of elective retransplantation in HCV vs. non-HCV, at 1, 3 and 5 years: 65.8, 55.7 and 53.2 vs. 67.3, 58.3 and 49.4 (p = 0.9652) . No differences in survival of patients HCV and non-HCV in different age group of donors and recipients. We found differences in survival at 1.3 and 5 years of the 135 patients retransplanted with MELD score <25 and 52 patients with MELD score > 25: 74, 62.8 and 55.1 vs. 51.9, 45.5 and 45 .5 (p = 0.0093) We found differences according to Rosen index of 1, 3 and 5 years: Rosen low: 71.7, 60 and 53.9, Rosen moderate 71. 1, 63.8 and 56.9 and higher Rosen: 44.4, 39.5 and 39.5 (p = 0.047) . Conclusion: The ethical implications in reLT are many and diverse, especially with limited organ availability. At present in Spain found no differences in the survival of patients electively retransplanted HCV versus non-HCV. Therefore, recipients HCV is not a contraindication for reLT; all variables should be used to evaluate a potential candidate. Patients with high MELD score (>25) and high rate Rosen (>20.5) have a mortality of 50% in the first year, so they must be questioned in elective retransplantation. Patients candidates for elective retransplantation should be prioritized on waiting lists to prevent deterioration. Results: Fifteen open nephrectomies and 13 laparoscopic nephrectomies were performed. Cold ischemia time in the laparoscopic group (64 AE 17 min vs. 46 AE 10 min) was longer (p < 0.05). In the early period, there was no graft loss in both groups. Graft function was similar in both groups during the first month. There were no delayed graft function in both groups. Four acute rejection was detected in Open Donor Nephrectomy group, there was only 1 for Laparoscopic Donor Nephrectomy group. Acute rejection rate was higher for Open Donor Nephrectomy group but not significant, p = 0.19. According to the zero-hour biopsy results, there was no difference between the two groups in terms of tubular necrosis, tubular regenerative/degenerative changes, and interstitial infiltration, tubular atrophy and changes in blood vessels. While glomerular collapse was found in four patients in the laparoscopic group, it was not observed in the open nephrectomy group (p < 0.05). Background: Biliary complication is the most common and intractable complication after adult living donor liver transplantation (LDLT). We have performed external biliary drainage (EBD) with expectation to decrease biliary complications. This study intended to optimize the management protocol for EBD tube clamping during early posttransplant period. Methods: The study patients were selected from the adult LDLT pool during 4 months from January 2011 to April 2011. The selection conditions were right lobe graft implantation, single duct-to-duct anastomosis (DDA), DDA with EBD, and exclusion of salvage liver transplantation, by which 60 patients were selected. We prepared a protocol of rapid EBD tube clamping for 2-3 days. This study was prospectively performed with special concern on early successful clamping of EBD tube. Results: There was no difference in the success rates of tube clamping in lowoutput (<300 ml/day, n = 35) and high-output (¡Ã300 ml/day, n = 25) EBD groups (85.7% vs. 68%, p = 0.100). There was no statistical difference between the success and failure groups in graft duct size, serum aspartate transaminase, alanine transaminase, total bilirubin, alkaline phosphatase and posttransplant days at tube clamping. The transfixed external tube was released after 6 months and removed during 6 to 12 months after LDLT. Bile peritonitis from bile leak after spontaneous or incidental removal of the catheter occurred in 2 patients. Conclusions: Our current protocol based on bile output drainage appears to be effective method leading to uneventful clamping of EBD tube, leading to minimization of patient discomfort. In living donor liver transplantation (LDLT), vascular complications are more frequently seen than in deceased donor transplantation. In five patients who underwent liver transplantation, portal vein stenosis was associated with esophageal varices and significant ascites and these complications that can lead to graft loss and patient death. In a third liver transplant patient, portal vein stenosis was suspected when evidence of hepatic ischemia was revealed at liver CT scan. This patient was treated with percutaneous transhepatic portal vein angioplasty. The interval between liver transplantation and stent placement was 13 days. However, these treatments are limited due to their technical difficulty and multiple complicating factors. This early experience of percutaneous transhepatic primary stent suggests that transhepatic portal vein interventions are feasible in patients who have received liver transplants and may prove useful at least in the early postprocedure period. In addition, longterm PV patency following stent placement was excellent. Background: The survival rates of liver retransplantation (ReLT) are 20-50% lower than those of first transplantation. The objective of this report was to identify the risk factor of mortality after ReLT and suggest a proper decision process for ReLT. Patients and methods: Between October 1996 and December 2011, 39 patients underwent ReLT. We performed a retrospective analysis of these patients using their medical records. Clinical characteristics, postoperavative complications, survival rate and causes of death were investigated. Multivariate analysis was performed to identify the risk factors. Result: The rate of ReLT is 3.3% (39/1178). The overall survival rate for ReLT was 55.8%, 39.1% and 32.3% at 3 months, 1 and 3 years, respectively. Multivariate analysis revealed a serum total bilirubin of more than 22 mg/dl was the factors related to survival. (p = 0.039) Also, there were no differences between living donor ReLT and deceased donor ReLT in operation interval, operation time, post transplant ICU stay, total hospital stay and survival. Conclusion: ReLT for the patient with a serum total bilirubin level of more than 22 mg/dl should be considered cautiously. And, LDLT for ReLT may be an alternative for well-selected patients. Background: The Model for End-Stage Liver Disease (MELD) score is the system adopted for organ allocation and besides scores of 40 or higher are considered at very risk for transplantation, there are no guidelines describing limitations for transplantation. Since then, the number of transplants performed with scores over 40 has increased. The aim of this study is to analyze the outcome of patients with pretransplantation MELD score of 40 or higher. Methods: This retrospective study includes 860 consecutive deceased donor liver transplantations performed between June 2005 and September 2012 in a single transplant center. The patients were grouped according to the pretransplantation MELD score (MELD≥40 and MELD<40), calculated using the United Network for Organ Sharing formula and compared regarding hospital and intensive care unit (UCI) length of stay, incidence of biliary, renal and vascular complications and 1 year patient survival. Results: Median time of total hospitalization and length of stay UCI were longer for MELD≥40 (21 vs. 13 dayshospitalization; 8 vs. 2 days for UCI). Among incidence of posttransplant complications, renal was significantly higher on MELD ≥40 group (64.3% vs. 45.1%, pvalue = 0.003), whereas for other complications were similar: biliary (10% vs. 7%), vascular (7.1% vs. 6.7%) and graft (42.9% vs. 37.2%). Kaplan-Meier 1-year patient survivor rate was 66.2% for MELD≥40 group and 87.6% for MELD<40, p-value log rank<0.001. Conclusions: The increased complexity of patients with MELD≥40 requires more post-transplant health care resources. Furthermore, this study suggests a relationship between patient survival and MELD score, and besides inferior survival rate for MELD≥40 group, transplant is preferable to these patients rather than the waiting list. Background: Incidence of Portal vein thrombosis (PVT) in Liver transplant (LT) patients is 4.9-10.6% and re-thrombosis could reach 28% after the surgery. Unfortunately, patency of PV after thrombectomy can neither be adequately evaluated nor objectively assessed. Accurate knowledge of portal venous anatomy and hemodynamics is essential to strategize surgical options for graft inflow. Aim: Herein, we describe a modification of inflow restoration in patients with partial PVT. Case report: Two patients with liver disease and PVT underwent LT; however, after thrombectomy, portal flow was still inadequate; this might be either due to inadequate thrombectomy or due to collaterals and possible portosystemic shunts.Cryopreserved vein graft "Passing Loop" was tunneled through mesocolon; connecting dilated Superior Mesenteric Vein to a distal healthy part of PV. Intrahepatic portal flow improved by Intraoperative Ultrasound >35 cm/s. Results: Passing loop is patent in one patient after one year follow up. In second patient, it was thrombosed few days after transplant, yet, had patent inflow through main portal route. Both have satisfactory liver functions on follow up outpatient visits. Conclusion: Rerouting part of the portal flow through a "passing loop" might be a salvage "safeguard" procedure against deleterious complications of graft hypoperfusion due to portal vein pathological narrowing or re-thrombosis; however, augmenting or rerouting effects on portal pressures and hemodynamics are yet to be elucidated. Introduction: It was demonstrated that mean platelet volume, an easy to test and repetitive biochemical parameter, can be regarded as an indicator of increased platelets activity and a predictor of cardiovascular episodes. Increased values of MPV have been recognized as an independent risk factor for myocardial infarction and stroke. Aim: To compare the mean platelet volume in groups of patients with liver cirrhosis of different etiologies. Material and methods: The group of 124 patients qualified to liver transplantation was analyzed. Nobody have had the symptoms of spontaneous bacterial peritonitis or other bacterial infections. Studied patients were divided into 3 groups of comparable age. Group 1 consisted of 57 pts with hepatitis C virus-related liver cirrhosis, group 2 included 26 pts with alcohol-related cirrhosis, group 3 consisted of 41 pts with other etiologies of cirrhosis. Results: Mean values of platelet volume (MPV) in all examined groups did not exceed the norm (norm: 7-12 fL). In group 1 MPV was significantly higher than in group 2 (11.63 AE 1.23 fL vs. 10.81 AE 1.11 fL, p < 0.01) although the mean MELD score in group 1was significantly lower than in group 2 (13.69 AE 4.47 vs. 16.24 AE 5.01, p < 0.05). There were no statistical differences in MPV and the mean MELD score between group 1 and group 3 (respectively MPV: 11.63 AE 1.23 fL vs. 11.34 AE 1.19 fL, ns; MELD: 13.69 AE 4.47 vs. 13.66 AE 4.73, ns) . In group 2 MPV was insignificantly lower than in group 3 (10.81 AE 1.11 fL vs. 11.34 AE 1.19 fL, ns), although the mean MELD score was higher in the group 2 (16.24 AE 5.01 vs. 13.66 AE 4.73, p < 0.05). Conclusions: In studied group the patients with the alcohol-related liver cirrhosis had lower mean platelet volume than in patients with liver cirrhosis of another etiologies. Interestingly, in patients with alcohol-related liver cirrhosis mean platelet volume was significantly lower than in patients with hepatitis C virus-related liver cirrhosis although higher the mean MELD score. Introduction: In 1945, the world first atomic bomb was dropped on the city of Hiroshima. The 2011 tsunami led to nuclear disaster in Fukushima. Unfortunately, concern about irradiation exposure from Fukushima people to others exists that may be too intense or needless. (Case) A 61 year old female patient with cirrhosis had lived within 20 km from the Fukushima nuclear station when the tsunami disaster occurred on the 11th of March in 2011. To avoid radionuclear irradiation exposure, she moved to a city more than 100 km from the station. During her 1 month stay in this city, she consulted a hospital due to symptoms associated with cirrhosis. They expressed intense concern about their own irradiation exposure from her. After she returned to Fukushima, she often experienced hepatic encephalopathy and complained of massive ascites. She needed ABO incompatible liver transplantation (Ltx). However, there is no Ltx center which is very willing to perform ABO incompatible Ltx near the station. We hypothesized that there was less concern about a Fukushima patient in Hiroshima and Nagasaki which were victims of the atomic bomb. She was sent to Hiroshima University and received ABO incompatible liver graft from her son past August in 2012. She returned to her home town in Fukushima this February and she is followed at a hospital 40 km from the station under collaboration with Hiroshima University. Of note, she noticed no concern about their irradiation from her during her 6 month stay in Hiroshima and she was satisfied with hospitality there. Conclusion: To our knowledge, this is the first ABO-incompatible Ltx performed under collaboration between two victims of irradiation in Japan. If good hospitality experienced by our Fukushima patient in Hiroshima was associated with common catastrophic experience between the two, one may consider referring a Fukushima patient to Hiroshima for a psychosocial reason in addition to medical issue Background: Living donor liver transplantation (LDLT) is widely used for patients with end-stage liver diseases. However, this procedure exposes the donor, a healthy individual, to morbidity & mortality which makes it of low applicability. Methods: We did a retrospective analysis regarding our experience in LDLT of 116 cases during the past 9 years. Results: We transplanted 116 cases, 25 pediatric cases (due to congenital or hereditary disorders) and 91 are (mostly post hepatitis HCV cirrhosis) adult cases .we have mortalities 22.4% infections and severe spesis are the most common cause of mortality in our patirnts. The most common causes of morbidity among those patients are the biliary complications (31%), followed by rejection (20%), followed by infections (18%) mostly due to viral infections. Conclusion: Starting to take the left lobe in order to minimize the biliary complications.Venous outflow optimization by using the Anterior venous patch to the right hepatic vein more than 5 mm for reconstruction of segment V&VIII. using intraoperative biliary stents with interrupted sutures may decrease biliary complications. Portal pressure measurement intraoperative may help us in prediction of small for size syndrome. Hepatic artery thrombosis can be detected early befor shooting of liver enzymes. Patients with hepatocellular carcinoma are pereferably transplanted if they are within the MILLAN criteria as it has better out come on recurrence. Background: Orthotopic liver transplantation (LT) is the only reliable treatment for end stage liver disease. All over the world the common indications for liver transplantation are hepatitis B, hepatitis C, alcoholic cirrhosis and hepatocellular carcinoma. But we know that some rare clinical issues can lead to end-stage liver disease. The aim of this study was to evaluate the efficacy of liver transplantation for rare liver diseases. Methods/materials: The results were retrospectively analyzed from 340 patients, who underwent LT from 2001 to November 2012 at our liver transplant center in Turkey. 173 of them were adult patients and 167 of them were pediatric. Results: The rare indications for LT which performed in our center were, Alagille syndrome(n = 5), Caroli's disease (n = 1), Crigler Najjar syndrome type 2(n = 4), congenital hepatic fibrosis (n = 2), oxalosis (n = 2), neonatal hepatitis (n = 3), alpha 1 antitrypsin deficiency (n = 2), alveolar hydatid disease (n = 2), glycogen storage disease type 1 (n = 2). Four of them were cadaveric LT and 19 of them were living related LT. The 15 patients were male and eight patients were female. No protocol liver biopsy specimens were obtained, and biopsies were performed only for investigation of biochemical abnormalities (elevated serum transaminase or bilirubin levels). Acute cellular rejection occurred in 3 patients and all of them were treatment with steroid therapy and there were no graft lost. Five patients passed away after the early period of transplantation (brain death; n = 2, sepsis; n = 3). There was not any donor mortality or major morbidity. Conclusions: LT appears to be a feasible option and is associated with a better quality of life for patients with rare liver disease. Their outcomes were comparable with that of the common causes of end-stage liver disease. Background: The first known pregnancy following liver transplantation was in 1978. There wasn't any statistically significant difference in the incidence of fetal malformations between general population and the pregnant women with liver transplantation. It was also found that pregnancy didn't affect graft functions and survival. Case Report: In our center, the pregnancy, natal and postnatal periods of four women with liver transplantations, which were performed in 1988 due to Wilson disease and 2006 due to primary sclerosing cholangitis, in 2004 due to familial intrahepatic cholestasis and in 1999 owing to cryptogenic cirrhosis were examined and assessed. When these patients became pregnant, they were at the age of 21, 22, 24 and 29, respectively. All of the patients were using tacrolimus. Mycophenolate mofetil and steroid treatment of these patients were stopped before pregnancy. Two of these pregnant women gave birth through vaginal channel in the 39th week. The third patient is in her 20th week and the fourth patient is in her 16th week still pregnant. Conclusion: When we examine these four cases in terms of pregnancy and graft functions following a liver transplantation, they provide the evidence that patients in their reproduction age can have a healthy pregnancy period without having serious difficulties, of course with a close and careful follow-up. Although conceiving a baby is possible after liver transplantation, it should be remembered that the rates of complications are relatively higher when compared to general population. Pregnancy care requires a multi-disciplinary approach as well as high motivation and compliance of the pregnant patient. Background: The overall incidence of malignancy in the transplant recipient has been estimated to be as high as 20% in the 10-year period after transplantation. In the present study, we present our experience with de novo malignancies encountered after both deceased and living donor liver transplantations. Methods/materials: We retrospectively reviewed the medical records of 335 patients who underwent OLT at our institution from September 2001 to December 2012 to identify subjects with de novo malignancy in orthotopic liver transplantation recipients. Results: Fourteen patients (4.1%) developed de novo post-LT malignancies. De novo malignancies included post-LT lymphoproliferative disorders (PTLD) in seven patients who were treated with chemotherapy; thyroid papillary carcinoma in one patient who was treated with total thyroidectomy and radioactive iodine therapy; squamous cell carcinoma in two patients who were treated with surgical resection; gastric stromal tumor in one patient who was treated with surgical resection; ovarian carcinomas in one patient who was treated with radical surgical resection and chemotherapy but passed away within 1 year of diagnosis; lung cancer in one patient who was treated with chemotherapy but he had bone metastasis and passed away within 1 year of diagnosis; and neuroblastoma one patient who was treated with chemotherapy. In all patients the immunosuppression therapy were changed. Conclusion: Transplant recipients generally have advanced stage cancers at the time of diagnosis with a poor prognosis. Since some neoplasms are common early detection of cancer is important to decrease cancer related mortality and morbidity. Background: Fulminant hepatic failure (FHF) is a clinical condition characterized by a severe, acute decline in liver function associated with encephalopathy. FHF, is defined as an international normalized ratio of at least 1.5 and any degree of mental alteration (encephalopathy) in a patient without preexisting cirrhosis and with an illness of more than 26 weeks' duration. FHF is a potentially fatal condition if emergency liver transplantation (LT) is not performed. In this study, we examined the epidemiology, causes, complications, and mortality of liver transplantation following fulminant hepatic failure at our hospital. Methods/materials: Among the 335 liver transplantations (LT) performed from September 2001 to November 2012, 32 of them (9.5%) were performed for FHF in 25 pediatric and seven adult cases. We retrospectively analyzed the data of these patients. Results: 4(12.5%) of them were cadaveric LT and 28 (87.5%) of them were living related LT. The 18 (56.3%) patients were male and 14 (43.7%) patients were female. The patients mean age were 12.5 years old (range, 18 month to 42 years). The etiology of the FHF was; acute hepatitis B in four cases, hepatitis A in eight cases, hepatitis non A non E in 7, Wilson disease in eight cases, autoimmune hepatitis in two cases, CMV hepatitis in 1 and toxic hepatitis in 2. Seven patients passed away after the early period of transplantation (brain death; n = 4, sepsis; n = 3). Two patients developed chronic rejection during the long term follow up. There was not any donor mortality or major morbidity. Conclusions: LT should be considered one of the first-line treatment options in patients with FHF. LT offers a safe and effective modality of treatment for FHF for both pediatric and adult patients. In this study, results appear comparable to other liver transplant recipients. Background: In this study, we examined the incidence and management of postoperative abdominal bleeding after orthotopic liver transplantation (OLT) and to identify risk factors for abdominal bleeding. Methods/materials: We retrospectively reviewed the medical records of 335 patients who underwent OLT at our institution from September 2001 to December 2012 to identify subjects with posttransplantation abdominal bleeding, defined as any hemorrhage requiring laparotomy within the first month. Results: 42 (13.5%) patients showed abdominal bleeding, requiring laparotomy within the first month, occurring at a mean of 4.9 days (range, day 1 to 21 days). 11(23.8%) of them were cadaveric LT and 32(76.2%) of them were living related LT. The 26(62%) patients were male and 16(38%) patients were female. The bleeding sites requiring laparotomy were the hepatic artery (n = 3), diaphragm (n = 2), inferior vena cava (n = 12), abdominal drain insertion site (n = 1), portal vein anastomosis (n = 2), abdominal wall (n = 5), liver graft cut surface (n = 9), hilar plate (n = 3), and greater omentum (n = 5). In all patients, active bleeding was controlled with surgical ligation or vascular reconstruction. No patients passed away due to abdominal bleeding. Conclusions: The risk of bleeding from coagulopathy, because of used anticoagulants and iatrogenic injury is high during the early posttransplantation period. This risk of bleeding can be minimized by meticulous surgical dissection and bleeding control. Introduction: The timing of extubation in patients undergoing liver transplatation (LT) is still in debate. The aim of this study was to determine risk factors for prolonged mechanical ventilation (MV) and reintubation in the early postoperative period. Methods/materials: We retrospectively analyzed 44 consecutive patients who underwent LT between March -December 2012. Preoperative, intraoperative and postoperative data were collected from the patients charts including acid-base status, arterial oxigen pressure (PaO2) and arterial carbon dioxide (PaCO2) pressure, fraction of inspired oxigen (FiO2), pulmonary complications, timing of extubation, need for non-invasive mechanical ventilation (NIV) and reintubation (RI). Results: The median duration of postoperative MV was 12 h (range 0-128 h). Sixteen patients (26.3%) required NIV in the early postoperative period and 6.5% (n = 4) had to be reintubated. Pulmonary complications were observed in 57% of patients ranging from mild (22.7%) to severe (4.5%). Risk factors for prolonged mechanical ventilation were: age (p = 0.014), intraoperatory blood loss (p = 0.002), blood products transfusion (p = 0.001), haemodynamic instability (p = 0.026), high vasopressor dose (p = 0.036) and PaO2/ FiO2 under 300 at the end of surgery (p = 0.011). Pulmonary complications were associated with platelets transfusion (p < 0.001), intraoperatory vasopressor dose (p = 0.039) and duration of postoperative mechanical ventilation (p = 0.003). Non-invasive ventilation was used in 36.4% (n = 16). In a multivariate analyses risk factors for RI were platlet transfusion (p = 0.025), reintervention (p = 0.05) and pulmonary complications (p = 0.05). Conclusion: Mechanical ventilation is associated with a higher risk of pulmonary complications. Age, intraoperatory haemodynamic profile, blood loss and platelets products transfusion represent risk factors for prolonged postanaesthesia mechanical ventilation.  Surgical procedure for liver transplantation are multiple and if there seems to be a consensus on a peegy back realisation with retrohepatic vena cava preservation, reperfusion of the graft could be un discussion subject. At reperfusion time, the blood flow is then generally restored via the portal vein but some surgeons have suggested that restoring the circulation through the hepatic artery initially may improve the outcomes. Method: We studied 16 pediatrics patients undergoing liver transplantation, five girls and 12 boys. Nine of them underwent a portal vein reperfusion (group 1), but seven had a temporary portocaval anastomosis and an hepatic artery initial graft reperfusion (groupe 2). We compared the venous blood lactates levels at the end of anhepatic phase and 30 min after graft reperfusion. We looked at the incidence of reperfusion syndrome and the necessity to use norepinephrine to maintain the haemodynamic status of the patients. Results: We did not found any difference between the both surgical techniques regarding to the onset of postreperfusion syndrome (PRS) or use of norepinephrine. Concerning the lactates levels, although lactate levels at the end of anhepathy were not different between the two groups, we found a significant difference in the level of lactate after reperfusion. Patients/lactates mM End anhepatie Reperfusion * Groupe 1: portal vein 3.25 (AE1.6) 3.92 (AE1.1) Groupe 2: hepatic artery 4.97 (AE2.6) 7.92 (AE3.2) **p = 0.0019 (Test F). Conclusion: Lactic acidosis is responsible for myocardial failure, vascular hyporesponsiveness and a decrease in sensitivity to vasopressor agents. Restoring the blood flow in the liver graft through the hepatic artery seems to present more risks than benefits for paediatrics patients. Background: EH is the only curative procedure for large or multi nodular, particularly centrally located liver tumors. Methods: We present the analytic results of our non-selected EH experiences during the last decade. Pre-, intra-and post-operative data of 171 EHs, were obtained from our center database, analyzed and compared in term of right or left EH (rEH or lEH). In our review of the literature, after searching the Medline database, all original articles about EH with more than 20 cases were selected, analyzed and lately compared with the result of our center. Result: Data of 122 rEH and 49 lEH were evaluated in our case-series. Portal vein embolization was performed in 6.6% of the cases, all in rEH group. The mean operative time was 310 min and Pringle maneuver was applied in 17% of the cases with mean duration of 15 min. The average amount of blood loss during our EH was 1560 ml. Intraoperative RBC and FFP transfusions were recorded in 42% and 29% of our entire patients, respectively. Except from blood loss all the other evaluated variables were observed with higher rate in our rEH rather than lEH which is also supported by the result of the review of literature. The amount of postoperative substituted RBC and FFP as well as the mortality rate were significantly higher in rEH group compare to lEH group. The average overall morbidity and mortality rates were 56% and 9%, respectively.Despite occurring postoperative complications in about ⅓ of lEH group, there was no in-hospital mortality in this group; whereas, all of our deaths occurred after rEH with an average rate of 13%. All these findings were within the range of analyzed review of the literature. Conclusion: lEH can be safely performed specially for centrally-located liver tumors, when the surgeon has the choice to decide the side of the EH; however, rEH is technically easier. Better surgical outcomes associated with lEH, showing the high value of preserving the RPS rather than left lateral one. Method: During the different phases routine tests are taken prior to the first phase. Furthermore, MRI diagnostic, biliary system, hepatic vasculature, celiac angiography, abdominal ultrasound, 3D reconstruction of CT scan for precise liver volume calculation and abdication as well as a detailed psychological interview take place. Results: Of 648 documented potential living donors were assessed. Total 76.4% of the candidates have been rejected for donation due to various reasons. 30.1% of the potential donors were abandoned from living donation due to general medical contraindications, prior to the three-phases-evaluation. Within the first phase 28.3% of the potential donors have been excluded from donation because of medical contraindications due to specific blood test results. During the second phase, 31.9% of living donors failed due to CT scan findings. Within the third phase, 8.1% of the donors were declined due to different reasons. In 1.6% cases the donor operation was aborted. Conclusion: Finally (22.4%) living donor liver transplantations took place. Among the documented donors, parents were the biggest group of likely donors (51%) followed by first degree related children (25%), siblings (4%) and spouses (3%). The rest of the donors (17%) consisted of relatives (12%) and emotionally related people (5%).Finally 22.4% transplantation took place. Alessandro Perrella, Donatella Pisaniello, Antonio Ceriello, Fulvio Calise, Oreste Cuomo, Alfonso Galeota Lanza Liver Transplant Center AORN A. Cardarelli HBV recurrence after OLTx may represent a severe clinical comorbidity after liver transplantation represents a plausible and severe condition may represent a severe. The current standard for prophylaxis essentially comprises specific immunoglobulin and lamivudin. However at the present time, other effective antiviral drugs are available, particularly some of these (Telbivudin) seems to have a minor impact on renal function. In the present study we report our experience on 10 transplanted patients receiving Telbivudin 600 mg/day while on the waiting list followed by treatment after liver transplantation with 12 months follow-up compared to 10 trasnplanted patients under lamivudin prophylaxis. Methods: Our series consisted of males with HBV related end stage liver disease. The viral load decreased rapidly while on the waiting list once the patient was started on antiviral treatment. All patients were evaluated for liver and renal function tests, immunosuppression trough levels, CPK before liver transplant at (T0), 1 month (T1), 3 months (T3), 6 months (T6) and 12 months (T12). Results: All patients received a CNI immunosuppression based regimen. Creatinin Clearance (MDRD) did not show any different a T0 between two groups, however patients receiving Telbivudin showed and improvement of Creatinine Clearence during follow-up (p < 0.05 U Mann-Whitney Test). Neither CPK or transaminase serum levels increased throughout the studied period and once HBV-DNA was cleared while on waiting list, it remained negative throughout follow-up period in both groups. Conclusion: Telbivudin prophylaxis for HBV is safe and effective and seem to be related to renal function improvement compared to Lamivudin. Further studies are required to better elucidate these results.  Background: Plasmacytoid dendritic cells (PDC) are cells of the innate immune system that play a major role in anti-viral immunity as the principal producers of interferon (IFN-a). PDC are abundantly found in hepatitis C virus (HCV) infected livers, and HCV-infected hepatocytes directly stimulate IFN-a secretion. Corticosteroid treatment of acute cellular rejection is associated with severe HCV recurrence after liver transplantation (LTX), but the mechanism is unknown. The aim of this study was to investigate the effect of corticosteroids on the antiviral activity of PDC and on IFN-a signalling. Methods: HCV-replication and IFN-signalling were investigated in Huh7 hepatoma cells, stably expressing luciferase reporter genes coupled to an HCV replicon (Huh7-ET) or an interferon response element (Huh7-ISRE-luc). Human PDC were stimulated with a synthetic TLR7-agonist or co-cultured with Huh7-ET cells, in the absence or presence of corticosteroids. In addition, conditioned media of stimulated PDC (CM) were tested. Results: Both co-culture of PDC and Huh7-ET, and addition of PDC-CM significantly inhibited HCV replication. These anti-viral effects of PDCs were completely abrogated by treatment with corticosteroids. No apoptosis of PDC was observed at these corticosteroid concentrations. The inhibitory effect could be recapitulated by addition of PDC-CM and was completely abrogated by addition of an IFN-a receptor blocking antibody to Huh7-ET cells, showing that the antiviral effect of PDC is mediated through secretion of IFN-a. Corticos-teroids alone did not directly affect HCV replication, IFN-a mediated inhibition of HCV replication or IFN-a signalling. Conclusion: Corticosteroids do not directly affect HCV replication or interfere with the antiviral action of IFN-a, but inhibit the antiviral capacity of PDC by suppressing IFN-a production. This mechanism may contribute to aggravated HCV recurrence associated with high-dose corticosteroid treatment after LTX. Dario Lorenzin, Edoardo Scarpa, Mina Carducci, Silvia Lazzaro, Serena Concina, Umberto Baccarani, Andrea Risaliti University Hospital Udine Liver transplantation (LT) is a treatment for HCC on cirrhosis within defined criteria. Aim of the study is to analyze a single center long-term experience in LT for HCC. From 1998 to 2012, 108 patients underwent LT for HCC. 98 male (90.7%) and 10 female (9.3%) mean age was 56 (range 37-68). All patients fulfilled the Milan criteria preoperatively. HCC diagnosis was based on preoparative imaging and alfa-fetoprotein, no tumor biopsy was performed. Number and diameter of HCC noduls were respectively 2 AE 1, 3 AE 1 cm at CT and 2 AE 1, 4.3 AE 3.2 cm at pathology, alfa-fetoprotein was 79 AE 244. TACE or RF/PEI were done in all cases, 6 patients (5.5%) performed major hepatic resection prior to LT. Mean MELD was 11 (range 6-23). At histology 14.8% (16 cases) had microvascular invasion. Tumor grading was 1 in 8%, 2 in 61%, 3 in 31%. According to the modified pTNM 16% were T1, 27% T2 and 56% T3. Immunosuppression was tacrolimus in 71 patients (65.5%) and ciclosporin in 29 (26.8%), tacrolimus plus everolimus in 8 (7.4%). 14 patients (13%) developed HCC recurrence. Eight patients (7.4%) hepatic, 4 (3.7%) lung and 2 (1.8%) bone. All patients died, except two which are alive with recurrent disease. At histology 7 of 14 patients who experienced recurrence (50%) had microvascular invasion. Tumor grading was G2 in 6, G3 in 7, G4 in 1 patient. All patients were switched to mTOR inhibitors and received Sorafenib after HCC recurence, those with localized hepatic recurrence had TACE, one performed pulmonary resection. At a mean follow-up of 52 month (range 1-164) the estimated 1, 3, 5 and 10 years survival rates were 87%, 76%, 68% and 61%. Our data confirm that LT represents the principal option for patients with HCC within well definde criteria achieving an optimal survival not only in the mid-term but also at 10 years after transplantation. Alfred Koenigsrainer, Ruth Ladurner, Silvio Nadalin, Doerte Wichmann Universitiy of Tuebingen, Department of General, Visceral and Transplantation Surgery Background: Toxic liver syndrome and fulminant hepatic failure (FHF) are synonymous for acute, severe, and extensive liver necrosis associated with cardiovascular shock and acute renal failure with or without respiratory failure. The etiology of this multiorgan failure (MOF) in acute liver failure is multifactorial, caused by toxic metabolites released from the necrotic liver and vasoactive effects. By eliminating the source of toxins, other organs can recover. Hepatectomy ensued with the objective of temporary hemodynamic and metabolic stabilization. Pre-emptive hepatectomy (PEH) denote hepatectomy with temporary portocaval shunt as a bridging procedure before transplantation. Indications for emergency, PEH in the case of acute liver failure remain controversial. It is difficult to identify patients who benefit from this procedure. Results: We cover five cases of acute liver failure with PEH following liver transplantation and three cases with PEH without an opportunely graft-offer. Conclusion: In sufficient time a PEH in selected patients may have benefit to improve toxic liver syndrome. We introduce a new score to detect patients, who profit by pre-emptive hepatectomy. Case report: A 61 year old lady with no co-morbidities presented with acute upper gastrointestinal bleeding to her local hospital. Oesophagogastroduodenoscopy (OGD) revealed a bleeding duodenal ulcer which was controlled with adrenaline injection. She developed recurrent bleeding within 24 h and repeat OGD showed an actively bleeding vessel in the ulcer. The bleeding ulcer was injected with cyanoacrylate glue (N-butyl-2-cyanoacrylate) and lipiodol, successfully controlling the haemorrhage. Shortly thereafter she developed severe abdominal pain. This appeared to settle initially with conservative management. However, she developed recurrent right upper quadrant abdominal pain and a computed tomography (CT) scan of the abdomen showed total occlusion of the entire hepatic artery and its distal intra hepatic branches. At this stage she was managed conservatively. However, she subsequently presented with recurrent abdominal pain, rigors and fever. A further CT scan and MRI showed no flow through the intrahepatic part of hepatic artery, intrahepatic abscesses, and multiple strictures of the intrahepatic biliary tree suggesting ischaemic biliary necrosis. Liver biochemistry remained stable without decompensation. Blood cultures were negative. The patient continued to get biliary sepsis, inspite of broad spectrum antibiotics, and had several relapses. As she had progressive worsening of sepsis with multiple liver abscesses, she was assessed for liver transplantation and listed for it. She was transplanted 3 weeks after listing. As the hepatic artery was occluded, she needed an infrarenal conduit for arterial inflow. She also required a roux loop reconstruction of the bile duct. The histopathology of the explanted liver showed ischaemic cholangiopathy with candida albicans cholangitis. She made an uneventful recovery from the transplant and is currently doing well. Background: Incidence of obesity is increasing in the general population. There is a proportionate increase in BMI of the liver transplant recipients. Worse outcome is predicted in high BMI patients following major surgery. We analysed the short and long term outcomes of the liver transplants recipients with high BMI. Methods: We analysed a retrospective cohort of 875 consecutive liver transplants from 2000 to 2012. The liver transplant recipients were classified into two BMI groups were; <30-697 (80%), >À30 to 178 (20%). The impact of BMI on various graft outcomes such as primary non-function(PNF), Acute rejection, early dysfunction, retransplantation, patient and graft survival were assessed. Results: There was significantly higher incidence of diabetes in the high BMI recipients. (Table 1 ) Non alcoholic steatohepatitis (NASH) related cirrhosis was a significant etiology in the high BMI group. PNF, acute rejection and retransplantation were significantly high in the high BMI group. Early graft dysfunction, IT stay, Hospital stay and 30 day mortality were similar in both groups. The 5 year graft survival was 79% and 75% respectively in low and high BMI groups. The 5 year patient survival was 80% and 78% respectively in both groups. Conclusion: High BMI recipients were at higher risk of Primary non-function and re-transplantation. However, high BMI recipients had similar long term graft outcomes as in low BMI recipients. Background: Left lateral split liver transplant (SLT) creates two allografts from a single deceased donor (DBD), a left lateral (LLS)and a right extended liver graft (ERL) to be transplanted into a one child and one adult respectively. This brief report is the first to outline the experience in Left Lateral Split Liver Transplant in Saudi Arabia (KSA). Methods: Since Nov 2010, fifty two whole livers out of 128 potential DBD (40.6%) were utilized, 26% of Donor pool (Living and deceased); three (5.7% of usable livers) were found 'splittable'; three adults received (ERL) and 2 pediatric recipients received 3 (LLS). Results: LT in KSA is driven by LD; 27% received grafts from DBD of which 2.5% received split grafts. Mean survival for whole group was 294 days, median follow up of 8 months (range 6 days-20 months). One child received two SLT due to segmental hepatic artery thrombosis, and one adult patient died on day 18 from pulmonary embolism. Conclusion: SLT has been already established as a feasible option. Previous results showed that safety and outcomes in ERL and LLS were comparable to other recipients. However, patient selection and use of good quality organs are paramount to ensure best outcomes. Patient and methods: This is the first article from Saudi Arabia to describe our experience in LT in patients with BCS. Data for patients, who underwent LT between Mar 2001 and Oct 2012, were analyzed. Six patients with BCS underwent LT (1.4%). Diagnostic work up such as imaging modalities and hematological evaluation was part of work up. Results: All patients received whole liver transplant from deceased donor. They were started on therapeutic heparin infusion and triple therapy immunosuppression, according to our protocol, then warfarin was introduced for long term control. Two patients (33%) died; one from bleeding caused by DIC; second succumbed after 5 months of pneumonia and multiorgan failure. One patient had recurrence after portal vein thrombosis nine months post LT. The predictors of mortality in our cases are renal failure, previous abdominal surgery and low BMI. Conclusion: Treatment of BCS follows a therapeutic algorithm that should start by anticoagulation and might end by liver transplantation, which seems to be feasible in our experience. Background and purpose: Complete necrosis of hepatocellular carcinoma (HCC) lesions has been occasionally found in the explant pathology after neoadjuvant treatment such as transarterial chemoembolization and radiofrequency ablation. This study intended to investigate the long-term prognostic effect of loss of tumor viability after pretransplant HCC treatment in living donor liver transplantation (LDLT) recipients. Methods: The study patients were 37 patients who demonstrated non-viable HCC on explant pathology and followed up for more than 5 years. Patient medical records were reviewed retrospectively. Patients who did not met the Milan criteria at any time before LDLT operation, patients undergone salvage transplantation and perioperative mortality cases were excluded. Results: Common primary disease was hepatitis B virus-associated liver cirrhosis (n = 37). Their explant tumor profiles were single tumor in 29 and maximal tumor size was 35 mm. There was no case showing microvascular invasion. Their median value of alpha-fetoprotein was 12 ng/ml (range: . Only one patient showed recurrence at 20 months, but he is still alive for more than 6 years after adrenalectomy and repeated pulmonary metastasectomy. Five-year recurrence rate was 2.1%. There were only two late mortality cases, each one due to graft failure and gastric cancer recurrence. Overall patient survival rate was 97.3% at 5 years and 92.7% at 10 years. Conclusions: The results of this study revealed that pretransplant treatmentinduced loss of tumor viability definitely decreased the risk of posttransplant HCC recurrence. Therefore, the patients showing non-viable HCC can be regarded as belonging to the super-Milan or super-selection group having minimal risk of HCC recurrence, thus routine HCC screening is exempted. Introduction: Bile duct injuries (BDI) are infrequent but potentially devastating complications after biliary tract surgery and have become more common since the introduction of laparoscopic cholecystectomy (LC). We also have seen an increase in associated vascular injuries, which normally have a subclinical course. A right approach of these patients requires a mutidisciplinar treatment. There are several reported cases, in which vascular injuries can produce liver necrosis with progression to acute liver failure (ALF), requiring liver transplantation (LT). Case report: We report the case of a 55 years female with no past history who underwent LC developing iatrogenic BDI. The patient was reoperated performing biliary tract reconstruction with Roux-en-Y hepaticojejunostomy. Five days after this surgery, a CT-scan showed the presence of right hepatic artery (RHA) pseudoaneurysm with active bleeding. A selective arteriography with embolization of the RHA was performed. After 48 h, a new arteriography proved persistent bleeding, so a new embolization was tried. The clinical course worsens and the patient developed an ALF. She was transferred to our department and was accepted for emergency LT. LT was performed with a whole graft from brain death donor. The postoperative period was complicated but successful. One year after LT, the patient remained asymptomatic with normal graft function. There are 14 cases reported in the literature in which LT was required due to vascular injuries associated with iatrogenic BDI after LC. Only 4 of these cases describe a pure injury of the RHA. In two of them, LT was performed due to secondary biliary cirrhosis and in the other two cases because of ALF. Introduction: Hepatitis C (HCV) remains the most common indication for liver transplantation (LT). Early data suggests that patients with HCV who receive a partial liver graft have worse outcomes, but more recent data also underlines that there is no difference in recurrent HCV between recipients of partial grafts and a whole one. Patients and methods: Retrospective review of all our HCV patients undergoing LT with grafts from liver bipartition (Split) and study of the results. Results: From April 1986 to December 2012 we have performed 6 LT with Split grafts in HCV patients. All patients were male with positive CMV serology, without associated alcoholic disease, and only two patients had associated hepatocarcinoma (HCC). Two cases were HCV genotype 1 (33%) and only one patient received antiviral treatment before LT, but without virological response. All donors were male, with a mean age of 28 + 16 years. The transplantation was uneventful in all cases with a warm and cold ischemia mean times of 451 + 283 min, and 67 + 13 min, respectively. After a mean follow-up of 96 + 46 months, the histologic progression of HCV recurrence was normal/ minimal changes in 2 cases (33%), moderate hepatitis (<= " td=">. The optimal management of patients with hepatocellular carcinoma (HCC) and early cirrhosis is still under debate. The aim of our study is to compare outcomes of patient with HCC within UCSF criteria who underwent liver transplantation or resection at our institution. Methods: From April 2004 to November 2010, 33 patients underwent liver transplantation and 16 patients underwent liver resection for HCC meeting UCSF criteria. Overall and recurrence-free survival rates were calculated using Kaplan-Meier method. Groups were compared by log-rank test. Results: Overall and disease-free 1-, 3-and 5-year survival rates were 88%, 76%, 76% and 85%, 76% and 71% for transplanted patients and 81%, 75%, 63% and 75%, 63% and 21% for patients after liver resection. The difference was not significant (p = 0.61 and 0.11). In a subset of patients within Milan criteria 1-, 3-and 5-year overall and disease-free survival rates were 90%, 90%, 79% and 86%, 79% and 74% in the transplant group and 89%, 89%, 67% and 78%, 67% and 0% for resected patients. The results were not statistically different (p = 0.90 and 0.13). In patients with solitary tumour and in patients with multiple lesions, the overall survival was not statistically different between transplantation and resection in both groups (p = 0.49 and 0.41). In patients within UCSF criteria the overall survival does not depend on the size of the lesion (p = 0.57, Cox proportional regression model). Conclusion: Our data show that there is no statistically significant difference in survival of patients with HCC within UCSF criteria between liver resection and transplantation either for patients with solitary or multiple lesions. The study shows higher recurrence-free survival in the transplantation group, however, we were not able to prove the statistical significance due to the small number of patients. Background: Nonalcoholic steatohepatitis (NASH) is prone to become one of the leading indication for liver transplantation in the future. The aim of this study was to describe the clinical post-transplant outcome of NASH patients compared to patients with other common indications for liver transplantation. Methods: We conducted a retrospective analysis of a prospectively collected single center database of 370 patients who underwent orthotopic liver transplantation between 2005 and 2011. Outcomes were compared between NASH patients and the remaining study group. Results: The incidence of NASH as primary indication for liver transplantation was 15.4% (57/370). The average MELD score was 22, the average BMI 25.1. NASH patients with HCC were associated with a significantly higher BMI compared to NASH patients with no evidence of HCC (28.3 vs. 26 p = 0.02). NASH patients had significantly longer operative times (p = 0.01) and higher infectious complications (p = 0.01). Patient survival was 3.28 years (3.16 years for NASH patients). Discussion: Our center performed a significant number of liver transplantations in patients with NASH. Transplantation in this cohort was associated with longer operation times and higher infectious complications most likely due to obesity and presence of metabolic syndrome. Weight reduction prior transplant could therefore lead to better postoperative outcomes. Arterial 'steal' phenomenon after orthotopic liver transplantation (OLT) is an important but often underdiagnosed cause of graft ischemia occurring in about 3-8% of cases. It indicates a decreased perfusion of the hepatic artery (HA) because of diversion of the blood flow into the splenic, gastroduodenal or left gastric artery, which leads to graft dysfunction. Splenic artery steal syndrome (SASS) usually occurs within days or weeks after transplantation. Its clinical spectrum is highly variable from a mild disorder to graft failure or ischemic biliary injury cases. We report the case of a liver transplant recipient who developed SASS successfully treated by partial splenic embolization. A 45year-old man received cadaveric liver transplantation in our center as treatment for HBV-LC decompensated cirrhosis. After the third postoperative day, the patient showed increasing levels of bilirubin and prolongation of the prothrombin time. Doppler sonogram revealed sluggish hepatic arterial flow. After evaluation for other causes for graft dysfunction we performed splenic artery embolization. After splenic embolization, the hepatic artery flow markedly improved and the patient recovered without sequelae. In conclusion, since it can be successfully treated with splenic artery embolization, SASS should be considered following liver transplantation when there is no other cause for graft dysfunction. Background/aims: Acute-on-chronic liver failure is an increasingly recognized entity encompassing an acute deterioration of liver function in patients with cirrhosis, either secondary to superimposed liver injury or due to extrahepatic precipitating factors such as infection culminating in the endorgan dysfunction. In order to improve survival in these patients, it is imperative to preserve them in suitable condition till transplantation. Methods: The medical records of patients who received liver transplantation due to acute on chronic liver failure were reviewed. Results: There were three patients whose condition deteriorated due to acute cholecystitis. All patients were child class C and presented with fever and abdominal pain. The average model for end stage liver disease (MELD) score was 18. Although initial imaging revealed diffuse wall thickening of the gallbladder in all of the patients, it was considered a finding related to liver cirrhosis. Due to persistent symptoms and without evidence of spontaneous bacterial peritonitis, acute cholecystitis was suspected and antibiotic therapy was initiated. Also, percutaneous cholecystostomy was performed in two patients. All patients showed improvement of patient condition and symptoms and received timely liver transplantation with two patients receiving deceased donor liver and the remaining patient receiving living donor liver transplantation. Results: Different methods and modifications have been described. The following major steps have been discussed in detail: donor liver preparation, recipient operation including recipient hepatectomy, and reconstruction phase, including the reconstruction of suprahepatic inferior vena cava (SHIVC), portal vein (PV), infrahepatic inferior vena cava (IHIVC), hepatic artery (HA) and bile duct (BD). IHIVC and SHIVC are anastomosed end to end directly or with the use of prosthesis anastomosed side to side. The PV anastomosis is performed end to end between donor and recipient PV, Cuff method or Stump method. Arterialization has been accomplished via carrel patch or donor HA end to end with recipient HA. There are three major methods for reconstruction of BD: end to end or end to side choledochocholedochostomy and choledojejunostomy with Roux-en-Y jejunal loop. Conclusion: Each method has advantages and disadvantages regarding the objectives of the study; the most physiological techniques may be preferred for long-term survival studies, while the faster techniques may be selected for experimentations aiming the direct postoperative phase. Background: Neonatal hemochromatosis (NH) is a rare disease of iron metabolism that starts at intrauterine period causing liver failure and extrahepatic siderosis. The etiology has not been understood exactly, it is accepted that is a maternofetal alloimmune disorder. The prognosis of NH is generally bad and death is inevitable if left untreated. The efficiency of chelationantioxidant cocktail used in medical treatment is between 10% and 20% and these patients frequently need liver transplantation (LT). Materials and methods: We report a sixteen days old female infant LT secondary of NH diagnosis without medical treatment response. Results: A sixteen days old infant, with 2.225 grams weight, was diagnosed of NH based on clinical, laboratory (high ferritin and transferrin saturation), radiological (decreased T2 signal intensituy of hepatic parenchyma) and liver biopsy (hepatic nonreticuloendothelial iron deposition). Chelation-antioxidant cocktail was established without response, with severe coagulopathy and encephalopathy, because of she required LT, which made with II-III cadaveric split liver. She had a postoperative torpid with hepatic artery thrombosis and secondary aortic thrombosis caused death, probably related to low weight of infant and technical difficulties with vessel diameter in one of smallest weight liver transplant made. Discussion NH is a rare condition but the most common cause of acute liver failure and LT in the neonatal period. LT, with 50% longterm survival, remains the treatment of choice and should be promptly offered to those infants who do not improve with supportive medical treatment. Background: Liver transplant recipients are frequently in malnutrition status. Even after the transplantation, oral-intake often does not increase as expected even in cases with ideal recovery of liver function. Postoperative malnutrition is considered high risk of infection as a result of immune deficiency. Aim: To clarify the association of total nutritional management including symbiotics, early enteral feeding and bile replacement and postoperative infection or immunological status in living donor liver transplant recipients. Methods: Among 168 patients who underwent living donor liver transplantation between Jan 1997 and Dec 2012, consecutive cases during the certain time period were evaluated as to following parametes: incidence of postoperative infection (n = 50), diamine oxidase (DAO) activity as a marker of villous integrity of small intestine (n = 13), and CD4+ adenosine triphosphate (ATP) activity (ImmuKnow assay) (n = 24). Results: Incidence of postoperative infection was significantly low in patients with symbioitics compared to patients without symbiotics (1/25, 4% vs. 6/25, 24%, p < 0.05). Patients with early enteral feeding with bile replacement tended to show higher DAO increment ratio (DAO of postoperative day 28/day 7) (p = 0.07). Low ATP activity was significantly correlated with levels of preoperative retinol binding protein (p < 0.05). Conclusions: Early enteral feeding, bile replacement was considered effective to prevent postoperative infection probably due to the effect on enterobacterial flora and villous integrity of small intestine. In addition, preoperative nutrition status such as retinol binding protein seems to effect even postoperative immunological status. Background: Biliary complications still remain the most common cause of morbidity in living donor liver transplantation (LDLT). According to recent reports, the application of a microsurgical technique in biliary reconstruction has been shown more excellent results. However, many transplant surgeon fear the acceptance of unfamiliar microsurgical technique. Hence, we introduce the simplified microsurgical technique for biliary reconstruction and present our results. Methods/materials: Forty-seven right lobe LDLTs who underwent biliary reconstruction under microscopic field were enrolled for this study. Transplantations were performed between December 2010 and March 2012. External stent in all patients was inserted and tailored telescopic technique was also used. Results: We have not experienced biliary complications including bile leak and early biliary stricture at anastomotic site in enrolled LDLTs for 1 year follow-up period. Five ABO-incompatible LDLTs was included and biliary complications were not demonstrated in clinical presentations including imaging and laboratory studies. Conclusion: Our Simplified biliary reconstruction technique under microscopic field will allow easier access to many transplant surgeons. And, our good results recommend the routine use of microsurgical biliary reconstruction in right lobe LDLT. Rhabdomyolylis is a syndrome characterized by skeletal muscle's lesion, resulting in release of intracellular contents into circulation. The most common potentially lethal complication of rhabdomyolylis is acute renal failure. Although episodic cases of rhabdomyolysis have been reported after lamivudine (LAM) administration, none was associated with liver dysfunction in the transplant (LTx) setting. A 32-y.o. Caucasian female, underwent LTx for autoimmune cirrhosis and hepato-pulmonary syndrome with severe hypoxemia. Due to an anti-HBc liver graft, HBV reactivation prophylaxis with i.v. anti-HBV immunoglobulins (10000 U during the anhepatic phase of LTx and 1000 U/day for 7 days thereafter) and oral LAM (100 mg/day from the 1st post-operative day, POD) was administered. In the 4th POD serum potassium (7.1 mEq/l), ALT (1983 U/l) and CK (31 672 U/l) increased, followed by oliguria and metabolic acidosis (lactic acid, 11.9 mM) (table). LAM was withdrawn and rehydratation, sodium bicarbonate and mannitol were started. Despite therapy, urine output further decreased and continuous venovenous hemofiltration (CVVH) was started. ALT rapidly decreased, whereas the peak of CK (135 752 U/l) was recorded at 6th POD and returned to normal only after several days. Causes of rhabdomyolylis other than LAM (trauma, viral infections) were ruled out. Liver biopsy performed at the 17th POD showed only cytolysis without rejection. At the 45th POD, liver function is almost normal, but the patient is still anuric. This case has some peculiarities: the very low total dose of LAM (400 mg), that caused rhabdomyolylis, the extreme severity of the muscular damage and the association with acute liver damage. It can be hypothesized that primitive mitochondrial dysfunction (lung, muscle, liver) due to hepato-pulmunary syndrome may be enhanced by toxic mitochondrial damage caused by LAM. This case report raises questions about the safety of LAM in pts with longlasting chronic hypoxia. Paolo Girotti, Silvio Nadalin University Hospital Background: Ischemia-Reperfusion Injury (IRI) represents a complex series of intracellular and extracellular events that results in molecular, cellular and tissue damage. It's induced by the transient deprivation of blood flow and oxygen, with lack of aerobic methabolism, and the return of blood flow during reperfusion with concomitant induction of innate and adaptive immunity, due to a release of oxygen-free radicals (OFR), cytokines/chemokines, and upregulation of adhesion molecules, with consequent cellular and organ dysfunction Focused on solid organ transplantation field, IRI is the main physiophatological event, resulting from an activation of TNF (figure 1.), that induce always an initial damage and that potentially could improvement the damage and the development of clinical syndromes, (DGF, PNF). Material and method trial design: Prosective, monocentric, placebo-controlled study to evaluate of Infliximab (one shot) in the early post operative period (72 h) after liver graft reperfusion. Endpoints: Primary Endpoints Evaluation of significant statistical reduction of IRI due to the following laboratory values at 1 POD: -mean ALAT level -mean Bilirubin level -mean CHE level -mean Leukocytes (CD4+) level Secondary Endpoints Statistical reduction of the occurrence of PDF, PNF, Acute rejection, biliary complication. Results: Study group: seven patients receiving infliximab after 30 min the Control group: seven patient. Results are showed in Table 1 . Study group Group control -mean ALAT level 80 U/l 201 U/l -mean Bilirubin direct level 1.2, 1.8 mg/dl -mean CHE level 7010, 1056 UI/ml -mean (CD4+) level 800 1/ll 2400 1/ll No PNF and AR were detected in the study group. Conclusion: Infliximab injection after 30 min after liver graft reperfusion showed good results in term of fast reduction of injury labor liver values. It seam influences a reduction of iperacute complications (PNF and AR) but not t. Background: Hepatitis C virus(HCV) cirrhosis is one of the leading indications for liver transplantation(LT). Due to the shortage of donors nowadays, donation after cardiac death is becoming a more frequent source of organs. However, there is few information of the impact of using DCD livers in HCV patients. Materials and methods: Between January 2006 and November 2010, 43 patients underwent LT with DCD (MAASTRICHT II) allografts of whom 21 had HCV-related cirrosis. In the same period of time, 85 HCV(+) adult patients underwent LT from donors after brain death (DBD). A retrospective analysis was performed comparing three groups of liver recipients: HCV(+)using DCD allografts(Group A), HCV negative using DCD allografts(Group B), and HCV(+) with DBD grafts (Group C). Results: A total of 43 patients underwent LT using DCD allografts, 19 of whom were HCV+ after excluding two HIV patients (Group A), 22 HCV negative (Group B); and 85 HCV patients from DBD allografts (Group C). The mean age of recipients was 57 years in group A, 59 in group B and 52.7 in group C. The donors were statistically younger in DCD groups. The mean MELD score was 14.44, 15.15 and 15.87 in groups A, B and C respectively. No statistically significant differences were observed with respect to blood transfusion in groups A & B, where as these requirements were higher than in group C (RBC: 16.11 units, 19.22, and 9.76 in groups A, B, and C respectively) The graft survival rates at 1 and 3 years were 72.3% and 59.6% in group A, 55% and 55% in group B, and 85.4% and 70.2% in group C. The patient survival rates at 1 and 3 years were 68.4% and 52.7% in group A, 71.3% and 71.3% in group B, and 85.4% and 70.2% in group C. Conclusions: There seems to be worse results in DCD allografts used in HCV(+) patients in comparison to HCV patients with DBD grafts or DCD organs in HCV(À) recipients. Background: Adult liver poliquistosis(ALP) is a rare congenital disease, of dominant autosomic transmission, characterized by the presence of multiple bilateral hepatic cysts,variable in number and size, and is associated in more than 70-90% of the cases with renal poliquistosis. It affects mostly women between 40-60 years old, growing through the reproductive period and reaching their maximum in the fifth decade of life. They start as a massive hepatomegaly resulting in abdominal tenderness, vena cava obstruction and hemorrhage. Surgical treatment has very poor results and must be considered especially in sintomatic patients. Liver transplantation (LT) is a valid option for this disease. Materials and methods: Between April 1986 and January 2012, 1580 LT were performed at our center. Ten cases of ALP were found. Results: Ten patients underwent LT for ALP, of whom seven were women.The mean recipient age was 54 + 10 years and the mean donor age 40 + 19 years.The mean cold ischemia time was 351 + 153 min and that of warm ischemia time was 64 + 12 min.The mean transfusional requirements during surgery were 21 units of red blood cells, 16 units of fresh frozen plasma and 6 pools of platelets. The mean MELD score was 20 + 4. In 90% of the cases, there was concomitant renal inufficiency, requiring a simultaneous renal transplant. The recipient survival rates were 75%, 75% and 60% at 1, 3 and 5 years respectively. Conclusions: ALP is a rare indication for LT, usually accompanied with renal insufficiency requiring a simultaneous liver and kidney transplantation. modified-release once-daily formulation (QD) has been developed and licensed for use. This study aims at analyzing the safety, efficacy and blood levels of QD in comparison with BID formulation. Methods: All patients liver transplanted from January 2010 to December 2012 who assumed tacrolimus de novo as immunosuppressive therapy were considered for the study. Population was divided in two groups. The QD group included liver transplant patients who received initial immunosuppression with tacrolimus QD.This group was compared with the group who received equivalent immunosuppression with twice-daily tacrolimus administration (BID). Results: We retrospective analyzed 40 liver recipients .Of these 24 QD (60%) and 16 BID (40%). Patient characteristics were similar between groups except Hepatocellular Carcinoma (p = 0.09) Levels of TAC during the first week (5.2 AE 4.2 ng/ml in QD group vs. 5.6 AE 3 ng/ml in BID group; p = 0.6) and the first month (5.3 AE 1.8 ng/ml in QD group vs. 5.4 AE 1.6 ng/ml in BID group; p = 0.9) after liver transplantation were well-adjusted in both groups. There was not significative difference in number of patients requiring change of immunosuppressive drug due to an inadequate tacrolimus blood level (p = 0.6). The rejection rate in the QD group was low, and only 2 patients experienced biopsy-proven acute rejection versus 0 in the BID (p = 0.23). Adverse events profiles were similar for both tacrolimus BID and QD. Diabetes Mellitus (p = 0.24), Arterial Hypertension (p = 0.5), Dyslipidaemia (p = 0.8), Acute Renal Failure (p = 0.2) Chronic Renal Failure (p = 0.8). There was no difference in graft and patients survival between the groups. Conclusions: Tacrolimus QD have an excellent patient adherence and, in our study, a good efficacy and safe.  Background: Ischemia-Reperfusion Injury (IRI) represents a complex series of intracellular and extracellular events that results in molecular, cellular and tissue damage. It′s induced by the transient deprivation of blood flow and oxygen, with lack of aerobic methabolism, and the return of blood flow during reperfusion with concomitant induction of innate and adaptive immunity, due to a release of oxygen-free radicals (OFR), cytokines/chemokines, and upregulation of adhesion molecules, with consequent cellular and organ dysfunction Focused on solid organ transplantation field, IRI is the main physiophatological event, resulting from an activation of TNF, that induce always an initial damage and that potentially could improvement the damage and the development of clinical syndromes, (DGF, PNF). Material and method trial design: Prosective, monocentric, placebo-controlled study to evaluate of Infliximab (one shot) in the early post operative period (72 h) after liver graft reperfusion. Endpoints: Primary Endpoints Evaluation of significant statistical reduction of IRI due to the following laboratory values at 1 POD: -mean ALAT level -mean Bilirubin level -mean CHE level -mean Leukocytes (CD4+) level Secondary Endpoints Statistical reduction of the occurrence of PDF, PNF, Acute rejection, biliary complication Results Study group: seven patients receiving infliximab after 30 min the Control group: seven patient. Results: Study group Group control -mean ALAT level 80 U/l, 201 U/l -mean Bilirubin direct level 1.2, 1.8 mg/dl -mean CHE level 7010 UI/ml, 1056 UI/ml -mean (CD4+) level 800 1/ll 2400 1/ll No PNF and AR were detected in the study group. Conclusion: Infliximab injection after 30 min after liver graft reperfusion showed good results in term of fast reduction of injury labor liver values. It seam influences a reduction of iperacute complications (PNF and AR) but not the risk of de. Background: Acute liver failure (ALF) is often associated with toxic liver syndrome (TLS) with consequent multiorgan failure (MOF) and death before transplantation. Through pre-emptive hepatectomy (PHE) the patient may be successfully transplanted. Indication and timing for emergency PEH remain controversial. Material and methods: A PEH with temporary porto-caval shunt was performed in 8 patients with TLS and MOF secondary to ALF. Indication to PEH: 1. MOF, 2. hemodynamic instability with high dose of vasopressor 3. Therapy-refractory lactate acidosis. The clinical, metabolic and hemodynamic aspects of each patient and their outcome were analyzed. Results: Etiology of ALF: acute liver transplant failure in two cases, acute on chronic liver failure in 5 and postoperative liver failure in 1. After a mean time of anhepatic phase of 24.5 h (range 4-46), five out of eight patients were successfully transplanted. Two of them died at mean 110 days and 3 are still alive 627 days after LT (153-1415 days Background: The indication for liver transplantation for hepatitis B (HBV) infected patients are hepatic de-compensation, fulminant liver failure or development of hepatocellular carcinoma. Currently, adequate control of viral replication can be achieved with potent antiviral therapy. We suggest that with better control of viral replication using potent medication (entecavir and tenofovir) compensation, but now with control of viral replication, less decompensation and more hepatocellular carcinoma (HCC) is the reason for liver transplantation. Method: We retrospectively reviewed 133 liver transplantation performed for HBV from 1990 till 2012 at our institution. We divided them into two eras, the first era from 1990 till 2006 and the second era from 2007 till 2012, we looked at the number of HCC in each group and the hepatic de-compensation among HCC patients. Result: Among 133 patients transplanted for HBV, 43 patients has HCC (32.3%), 66 patients were transplanted between 1990 to 2006 of which 18 patients has HCC (27%), hepatic de-compensation was seen in 60 out of 66 patients in this group with only one third of the HCC group being transplanted for MELD exception without de-compensation. While 67 were transplanted between 2007 to 2012 of which 26 patients has HCC (39.4%), hepatic decompensation was seen in 48 out of 66, 73% of patients with HCC transplanted with MELD exception without de-compensation. In our cohort there was 40% overall increase in transplantation for HCC from the first era to the second with more than 4 fold increase in HCC cases without de-compensation done with MELD exception. Conclusion: Due to use of highly potent antivirals against hepatitis B (tenofovir or entecavir) with sustained viral suppression, there is a changing trend of indication for liver transplantation for Hepatitis B from hepatic decompensation to hepatocellular carcinoma. Nicolas Meurisse, Ina Jochmans, Wim Laleman, Raymond Aerts, Frederik Nevens, Jacques Pirenne, Diethard Monbaliu University Hospitals Leuven Background: Delayed graft function (DGF), the immediate consequence of Ischemia Reperfusion Injury (IRI) severity, is characterized by a poor graft function after Liver Transplantation (LTx). DGF is defined by one of the following: peak AST/ALT>2000 IU/l during the first 7 days post-LTx, total bilirubin>10 mg/dl on day 7 or INR>1.6 on day 7 post-LTx (Olthoff). We (i) identified risk factors of DGF and (ii) studied its impact on patient survival. Methods: Between 01/2000 to 12/2010, we performed 541 LTx. Donor/ recipient demographics, procurement/preservation/LTx data and patient survival were analyzed retrospectively. Results: Of 137 patients developed DGF (26%). Univariate and multivariate analyses revealed cold (p = 0.01) and intra-operative warm ischemia (P = 0.02) times as independent risk factors of DGF. Recipient ICU/hospital stay and death were significantly associated with DGF. The 1 and 5-years patient survival (81.8% and 66.3%) in recipients with DGF was lower compared to recipients without DGF (94.5, 81.9%), p < 0.01 (). Conclusion: Cold and intra-operative warm ischemia times were identified as independent risk factors for DGF post-LTx in our series. DGF is associated with a lower patient survival. Whenever possible, cold and intra-operative warm ischemia times should be kept as short as possible whilst strategies to further decrease IRI and DGF are needed. Abstracts of the Background: A recent systemic review analysing three previous trials in hepatic artery first reperfusion of DBD grafts concluded there remains a scarcity of data in this area. DCD grafts are subject to functional warm ischaemia and it is in these organs that there may indeed be a benefit of early reperfusion with arterialised blood. We aim to perform a matched pair analysis of grafts with artery first reperfusion compared to portal venous reperfusion. Methods: Using a prospectively held database we compared all DCD grafts that underwent artery first reperfusion (AR) against a matched cohort of potal venous reperfusion (PVR). Matching was based on donor age, donor BMI, recipient MELD and cold ischaemic time; blinded to outcome. A comparative analysis of the donor and recipient factors between groups were performed. Post operative liver function, in-hospital and patient/graft survival was undertaken. Results: A comparative analysis was performed on 11 matched pairs. There was no significant difference in donor and recipient characteristics between the AR and PVR groups. There was no significant difference in recipient WIT, acute kidney injury, in-hospital mortality, patient and graft survival. However, there was a trend towards a lower peak ALT and a significantly lower peak bilirubin in the AR compared to the PVR group (71 vs. 124 mM; p = 0.03). Conclusion: This small retrospective analysis has demonstrates that outcomes following AR in DCD grafts are comparable to conventional PVR with a trend towards improved post-operative liver function following AR in DCD liver transplantation. A prospective randomised trial in this area is warranted. Objective: Early graft loss secondary to arterial inflow problems remains a major challenge in liver transplantation. Revascularisation of the liver using donor iliac artery conduits is a well-recognised procedure. This study analyzes the outcomes of aorto-hepatic conduits in adult deceased donor liver transplantation. Methods: We retrospectively reviewed 702 orthotopic liver transplants (OLT) from January 2000 to September 2010. The data on indication, type of graft, complications and survival were obtained from the transplant database and patient case notes. We compared the outcomes of the liver transplants with aorto-hepatic conduits to those without conduits. Results: Aorto-hepatic conduits were required in 54(7.6%) liver transplants. The median age of the recipients with conduits was 50 years (Range: 19-69). The male to female ratio was 1.5:1. Three (5%) of the recipients received the liver from DCD donor. Four patients had supracoeliac conduits. A higher 30 day mortality of 11% compared to those without conduits(4%) was noted. Five out of six deaths were following hepatic artery thrombosis and retransplantation. The conduit patency at 3 years was 81%. Higher incidence of postoperative renal failure and need for renal support was noted in those requiring aorto-hepatic conduits. Five year graft survival of the liver transplants with conduits and those without conduits were 63% and 70% respectively. Results: Aorto-hepatic conduits in liver transplantation have good long term results and has no negative impact on graft survival. In the short term, there is increased incidence of renal failure and 30 day mortality. Background: Due to the perpetual shortage of donor organs living donor liver transplantation (LDLT) has emerged as an option to perform liver transplantation independent from the current deceased donor allocation system. However, donor safety is imperative and new methods need to be explored to improve the safety of LDLT. Beyond that, the fine pathophysiological mechanism of regeneration of liver function after partial resection and partial transplantation remains unclear. Methods In this case-report data of two donor-recipient pairs was used. LiMAx (Liver Maximum Capacity) test and MRT examinations are routinely performed for donor evaluation. Based on volumetric analysis future remnant liver function (FRLF) is estimated to ensure maximal donor safety. LiMAx tests are performed on postoperative day (POD) 1, 3, 5 and 10 in both, recipients and donors. We reviewed the accuracy of preoperative estimated future remnant liver function and the pace of liver function recovery. Results: Volumetric analysis accurately predicted intraoperative measured graft weight. (Pair 1: 1136 ml vs. 1107 ml respectively; pair 2: 1365 ml vs. 1175 ml respectively). Preoperative donor FRLF showed good correlation to measured liver function on POD 1 (Donor 1: 227 vs. 244 lg/kg/h respectively; donor 2: 110 vs. 99 lg/kg/h respectively). Preoperative liver function was decreased in LDLT recipients (155 AE 102 lg/kg/h) compared with donors (440 AE 183 lg/kg/h). After surgery LiMAx values dropped in donors but liver function seems to recover within 10 days after surgery (566 lg/kg/h). Also recipients showed constant improvement in liver function after successful transplantation reaching normal values (329 AE 34 lg/kg/h) on POD 10. Conclusion: In conclusion LiMAx and MRT based volumetric analysis might provide accurate estimation of postoperative liver function of the donor. Liver function seems to recover rapidly within the first postoperative days in both, donors and recipients, after successful LDLT. Background: Non Anastomotic Strictures (NAS) are often referred to as the 'Achilles heel' of Liver Transplantation (LTx). We aimed to (i) identify risk factors to develop NAS and (ii) study its impact on patient survival. Methods: Between 01/2000 to 12/2010, 535 LTx were performed in our center. Donor/recipient demographics, procurement/preservation/LTx data and patient survival were analyzed retrospectively. Results: Of 68 patients developed NAS (13%). Univariate analysis revealed acute liver failure (ALF) (p < 0.01), donor height/weight (p = 0.04), imported livers (vs. locally procured) (p < 0.01), donation after circulatory death (DCD) (p = 0.02), Histidine-Tryptophan-ketoglutarate (HTK) (p < 0.01) and cold ischemic time (CIT) (p < 0.01) as significant risk factors to develop NAS. The total bilirubine (mg/dl) at day 7 in recipient was significantly associated with risk to develop NAS (0.01). Upon multivariate analysis, ALF, imported livers, DCD and CIT remained significantly associated with the risk to develop NAS. The risk of death was not increased in case of NAS. Conclusion: We identified ALF, imported livers, DCD and CIT as risk factors to develop NAS post-LTx in our series. The development of strategies to decrease the incidence of NAS especially with the increased use of less than ideal liver grafts remains warranted. Background: Incisional hernias (IHs) are common complications after liver transplantation (LT) with a reported incidence of 1.7% to 34.3%. The traditional repair techniques have been refined because of the high rate of incisional hernia recurrence up to 20%. Perioperative, mTORi or MMF are usually omitted to reduce wound healing complications. The purpose of this retrospective study was to evaluate the risk factors for hernia recurrence with focus on the role of immunosuppressive therapy at the perioperative phase. Patient and methods: The study included the patients with incisional hernia repair consecutively between 2008 to 2012. Risk factors such as type of incision for liver transplantation, time to hernia repair after transplantation, maintenance immunosuppressive therapy, age, gender, BMI, ascites, diabetes, hernia size, complication within 1 month after hernia repair were collected retrospectively from the database. The recurrence of incisional hernia was diagnosed by clinical and sonographical examination. Univariate and multivariate analysis were performed. Results: There were 142 hernia repair carried out in our department. Among them, 48 were after liver transplantation. The surgical repair consisted of laparoscopic IPOM, open sublay, open onlay technique. Immunsuppression was changed perioperatively in 19 patients (12 had MMF, 7 had mTORi), and not changed in 29 patients (10 had MMF, 8 had mTORi). Four patients had an impaired wound healing or infectious complications. During the follow-up of (4-43 months), 9 patients developed recurrent hernia. The multivariated analysis failed to identify the immunosuppression switch to be a risk factor for heria recurrence. Conclusion: Perioperative switch of immunosuppression, such as MMF or mTORi, is not justified. Objective: To describe our experience in HCC liver transplantation. Material and methods: The study included recipients on the waiting list including diagnosed with HCC who met Milan criteria, between 2002 and 2012 at the Hospital Virgen de las Nieves, Granada. Spain. We analyzed the diagnostic studies performed at enrollment (US-TAC-MRI) and pathological study of liver after explant. The embodiment of TACE and pathological results in the liver explant. We analized the use of TACE in HCC recipients and the incidence of arterial thrombosis. Analysis of survival in this group of patients. The study was performed using SPSS version 15 for Windows. Results: Between March 2002 and 2012 there were a total of 250 liver transplants, including 58 recipients included on the waiting list with a diagnosis of HCC. The mean age was 56 7 years, 82% were men. The average time on the waiting list was 187 AE 167 days. At inclusion 18 patients were diagnosed by CT + US, whereas in 12 patients MRI was also performed. In 25 patients underwent TACE. Two patients were included after making dowstaging after TACE. In two patients underwent FNA pretransplant tests being inconclusive (one negative and one inconclusive for HCC). In analyzing the results of the explant was found embolized 1 lesion with complete necrosis in 10 patients and incomplete necrosis in 6. While in three patients were completely embolized two lesions and two with incomplete necrosis. In a patient with three lesions were found to include three completely necrotic lesions. The degree of differentiation had the following distribution: 24% good, 25.9% moderate and 3.4% poorly differentiated. In a patient cell nests were found in necrosis. In 15% of patients diagnosed with HCC were no found lesions. Only one patient who had undergone TACE file an arterial thrombosis. At the end of the study, with a mean follow-up through 51 AE 33 months, 62% of the patients was alive. Background: Late hepatic artery thrombosis (HAT) is a very rare phenomenon after whole graft liver transplantation (OLT). A combination of HAT and portal vein thrombosis (PVT) has not been reported yet. We would like to present the successful management of a patient with HAT and PVT after OLT. Case: A 59 years old male presented in 09/2012 after his OLT 02/2011 with right sided abdominal pain and episodes of fever. Liver and biliary enzymes were elevated, inflammatory signs were moderately higher. A CT scan showed HAT of the right hepatic artery branch and PVT of the right portal vein branch in combination with a complete necrosis of the right lobe. As no radiological intervention was possible hyperbaric oxygenation (HBO) was installed to ameliorate oxygenation for 3 months. The follow up CT scan showed no progression of the necrosis or signs for abscesses. The right lobe was resected completely and the patient continued with postoperative HBO therapy. He recovered; liver enzymes restored until normal with an uneventfull follow up for 3 months. Discussion: This surely is a unique case of HAT and PVT after OLT. Surgical management in combination with HBO therapy worked well for our patient. Background: Orthotopic liver transplantation (OLT) is the only definitive therapeutic modality for patients with end-stage liver diseases.Hepatic artery (HA) reconstruction is considered as the key to the success of liver transplantation and reducing postoperative complications, due to maintain good hepatic arterial blood supply. To explore the indications, surgical method, and postoperative treatment by studying in-hospital and follow-up outcomes of Chinese patients undergoing orthotopic liver transplantation (OLT) after heaptic artery (HA) reconstruction with iliac interposition graft. Methods: Of 17 patients underwent conventional OLT (non-bypass group) and 17 patients underwent OLT with heaptic artery reconstruction by iliac interposition bypass (bypass group). Complications were evaluated by the clinical presentations, liver function changes, and hepatic artery ultrasound findings. Results: There were no differences between groups in terms of age, sex, and primary disease. The average surgery time of bypass group was longer than that of non-bypass group (82.29 ı A22.00 vs. 48.47 ı A11.86 min, p < 0.01). Recipients of bypass had more blood loss than non-bypass group (7047.06 ı A976.04 vs. 4841.18 ı A 1268.39 ml, p < 0.01). One patient was suffered from biliary fistula and one patient experienced biliary infection combined with intrahepatic bile neoplasia. The rest 14 patients were doing well postoperatively. The hepatic function of two groups was recovered well. In postoperative continuous 10 days, there was no significantly difference of HA peak blood flow velocity between bypass group and non-bypass group. The bypass patients had been followed up for an average time of 45.2 months (20-56 months). The patients had no complications such as artery stenosis and arterial thrombosis. And no one died of artery complications. Conclusion: Iliac arterial interpositional graft is an effective and reliable method of HA reconstruction in OLT when the use of hepatic artery is not possible. Methicillin-resistant Staphylococcus aureus (MRSA) infection frequently complicates the postoperative course of liver transplant recipients. It has been well described that MRSA associated bacteremia, pneumonia and surgical site infection are common. But, MRSA infection manifesting as pyogenic spondylodiscitis is very rare. To our knowledge, pyogenic spodylodiscitis due to MRSA in lumbar spine after living donor liver transplantation (LDLT) has not been previously reported. Here, we report a 50-year-old man who developed pyogenic spondylodiscitis caused by MRSA after LDLT. Our patient underwent LDLT for HBV related cirrhosis using modified right lobe. Immnosuppressive treatment was administered with basiliximab, tacrolimus, corticosteroids and mycophenolate mofetil. He discharged on postoperative 28th day with uncomplicated course. At one week after discharge the patient was readmitted for abdominal pain and high fever. Bile leakage at the anastomosis site was found by endoscopic retrograde cholangiopancreaticography (ERCP) and managed successfully with endoscopic nasobiliary drainage (ENBD). The culture of drained fluid showed MRSA and the patient was treated with vancomycin for 4 weeks, and resulted in resolution of the infection. However, one month later the patient presented with severe back pain. At this time, MRI showed massive spondylodiscitis of lumbar 2-3 spine and paraspinal abscess formation. Our patient was treated by surgical debridement and primary bone graft. MRSA was cultured from the abscess specimen. Postoperatively, the patient received intravenous vancomycin for 2 weeks and revealed satisfactory outcome without any neurological sequelae. Presently the patient is followed up without rejection and other complications. Introduction: In Egypt, where LDLT is the only available option, most transplanted cases are due to HCV related ESLD or HCC. However, other etiologies co-exist as hepatitis B virus (HBV). Without preventive therapy, HBV recurrence after liver transplantation was common and can lead to graft failure and death. The antiviral regimen should be robust and minimize the risk of breakthrough mutations. Patients and methods: In the period from March 2008 till April 2013 we transplanted 124 cases of LDLT, 4 of them were due to HBV related end stage liver disease and/or HCC and 2were combined HCV and HBV. According to our protocol all patients were HBV DNA negative before transplant and received intra and postoperative IM anti HBV immunoglobulin and lifelong post transplant nucleo(s)tide analogue. We recorded a single case of virologic breakthrough on Entecavir after 32 months in male patient 45 years who was transplanted for HBV related ESLD and on strict and adherent follow up on entecavir. Breakthrough was documented pathologically by liver biopsy; unfortunately genetic mutation analysis was not available. Patient was treated by adding Adifovir for 2 weeks then shifted to Tenofovir when became available in Egyptian market with normalization of liver enzymes and negative HBV DNA PCR up till now (13 months). Conclusion: Liver transplantation for HBV carries risk of recurrence even with drugs with high genetic barrier. Regular follow up and early detection of breakthrough is mandatory. Rescue therapy is life saving before graft failure. Abstracts of the Tryptophan-derived metabolites, such as 3-hydroxyanthranilicacid, 3-hydroxykynurenic acid and quinolinicacid, induce activated T cell apoptosis, which is an important mechanism in indoleamine 2,3-dioxygenase(IDO)-mediated T cells uppression. In this research, the murine orthotopic liver transplantation model was utilized to investigate the immunosuppressive effect of 3,4-DAA on allogeneic graft rejection. The DA-Lewis rat orthotopic liver transplantation model was established and divided into four groups: group A, negative control group, treatment with normal saline 2 ml/day; group B, treatment with 3,4-DAA (400 mg/kg/day); group C, treatment with cyclosporin A(CsA) (2.5 mg/kg/day); group C, treatment with cyclosporin A(CsA) (5 mg/kg/day); group D, treatment with 3,4-DAA (400 mg/kg/day) and CsA (2.5 mg/kg/day). We found that 3,4-DAA possesses immunosuppressive function, moreover, the regimen ( were analyzed and correlated with graft and patient survival by univariable/ multivariable logistic regression and cox proportional hazards. Results: After adjustment by multivariable cox proportional hazards recipient's BMI (p = 0.0100), labMELD before OLT (p = 0.0233) and labMELD pop1 (p = 0.0062) were independently associated with patient survival. 30-days and 12 months-survival in patients with a labMELD pop1 higher than 30.8 was 21.4%, respectively, while patients with a labMELD pop1 lower than 30.8 displayed 30-days and 12 months survival rates of 80% and 71.8%, respectively (p < 0.0001). In the Republic of Kazakhstan the problem of liver diseases complicated with terminal liver failure is an actual one. The only way of radical treating of these patients is to provide a Liver Transplantation. This kind of service was unavailable in Kazakhstan before 2011. The main problem was the country's lack of cadaveric donation, due to specific mentality of the population and imperfect legislation. Liver Transplantation program of the Republic of Kazakhstan is now in its initial stage, but it develops. First case of Liver Transplantation was performed in 2011, 9th December. For today, three Centers in two big cities have made 11 cases of Living Donor Liver Transplantations for adult recipients. Six of them (54.5%) had liver cirrhosis caused viral hepatitis, another fiveliver cirrhosis of non-viral ethiology: primary biliary cirrhosistwo cases (18.2%), autoimmune hepatitistwo cases (18.2%), idiopathic liver cirrhosisone case (9.1%). The patients' age ranged from 20 to 52 years. MELD score ranged from 13 to 25. By relation degree, most of the donors of liver fragments were siblings (brothers or sisters)nine cases (81.8%). In one case, donor was mother of the patient (9.1%), in another one casepatients' wife (9.1%). The preliminary findings based on a small experience showed a good perceptiveness of developing of Living Donor Liver Transplantation program in Kazakhstan. Despite the numerous problems, Liver Transplantation Program tends to its development, as only way of radical treatment of patients with end stages of the liver diseases. There is reason to believe that the number of such operations in the Republic of Kazakhstan will increase in the future. Background: Advances in surgical techniques and management have decreased the morbidity and mortality after hepatobiliary operations, however, bile duct injuries remain a major cause of postoperative morbidity and mortality. Early recognition and adequate multidisciplinary approach is the cornerstone for the optimal final outcome. Patients and methods: A prospective study including 10 cases with severed bile duct injuries (post cholecystectomy). The suggested hybrid technique involves preoperative insertion of percutaneous transhepatic draining (PTD) catheter and intraoperative introduction of these catheters into a suitable jejunal conduit. Percutaneous cholangiography is done one week postoperative to assess the anastomosis. A Follow up magnetic resonance cholangiopancreatography (MRCP) was done at 6 and 12 months. Results: The technique showed significant improvement in the outcome of biliary reconstruction. Eight patients showed rapid recovery post operatively. One patient needed a redo surgery after migration of the stent and leakage from the anastomosis. Another patient in the follow up MRCP revealed diltated intrahepatic biliary radicles, however with no rise in bilirubin and cholestatic enzymes. Conclusion: This technique provides a safe and sound bilio-enteric continuity with early rehabilitation of the patients, low incidence of complications and long term patency of the bilio-enteric anastomosis. Cava (IVC) is technically challenging. Additionally; it poses considerable risk for tumor recurrence and risk of thrombosis related to IVC reconstruction. Methods and results: We report two cases of LDLT combined with IVC reconstruction using cryopreserved iliac vein graft (CPIVG) after en bloc resection of the liver with all or part of retrohepatic IVC for a case of hepatoblastoma and hepatocellular carcinoma respectively. The first patient is 10 years old boy with history of right hepatectomy followed by adjuvant chemotherapy for hepatoblastoma, he had local recurrence and he was subjected to non-anatomical resection of segment IV followed by adjuvant chemotherapy. Unfortunately; patient had 2nd local recurrence and he was referred to our institution for management, he received pretransplant chemotherapy followed by LDLT using left lateral segment form his father. During the procedure completion hepatectomy was done with total resection of retro hepatic IVC. Reconstruction was done using CPIVG. The second patient is 59 years old female patient who had HBV related cirrhosis with HCC at segment VII abutting IVC (Fig 1) . Total hepatectomy was performed along with partial resection of IVC (7 cm in length and around 50% of IVC circumference Background: A major challenge in liver transplantation (LT) is shifting towards improving survival beyond the first year. Understanding the causes for premature death is a prerequisite for improving long-term outcome. Methods: Overall and cause-specific mortality rates among all LT patients in the Nordic countries transplanted in 1985-2009 and survived 1 year post-LT were divided by expected rates in the general population adjusted for age, sex, calendar time, and country to yield standardised mortality ratios (SMRs). Patient data came from the Nordic LT Registry, and general population data from national cause-of-death statistics. Results: Among 3299 patients (23 691 person-year follow-up, mean 8.2 years), 763 deaths occurred. Patient survival >1 year remained unchanged over time and a gap of 20% at 10 years was noted to the expected survival in the matched general population. SMR >1 year post-LT was 2.4 (95% CI 2.2-2.6), and SMR for death before age 75 was 5.8 (95% CI 5.4-6.3). Significantly elevated cause-specific SMRs were noted for infection, malignancy, liver disease, genitourinary disease, and suicide and intentional self-harm, but not for cardiovascular disease (Table) . According to primary LT indication, allcause SMR for death before age 75 was highest in HCC (SMR 33, 95% CI 26-41), followed by alcoholic liver disease (SMR 18, (14) (15) (16) (17) (18) (19) (20) (21) (22) and HCV (SMR 12, 10-16). Acute liver failure and HCV showed highest SMRs for infection, HCC for malignancy, and ALD for liver disease (mostly disease recurrence). SMR from cardiovascular disease was significantly elevated only in PBC, alcoholic disease and patients aged 45-59 at LT. Conclusions: Mortality >1 year after LT is considerable higher than in the general population and has not improved over time. High relative mortality from infection, genitourinary disease, liver disease, suicide, and malignancies merits increased attention in clinical practice and future research. Background: Biliary stricture remains a significant cause of morbidity after liver transplantation. The incidence of biliary strictures in patients who have undergone liver transplantation (LT) with duct-to-duct biliary reconstruction ranges from 10% to 30%. Most of the initial experience on self-expandable biodegradable stents has been in urological applications. Encouraging experience in these medical fields led to the trial of these stents in experimental liver surgery also. In the past, some authors achieved encouraging results with the biodegradable stent in pancreatic and biliary applications. Methods/materials: On preliminary group of the five patients we investigated the role of absorbable biliary stent with aim to proof patency of duct-to-duct biliary anastomosis and toxicity of a stent. The stents are made of machineknitted polydioxanone monofilaments. The recipients of the liver graft were followed up for 12 months. Results: Our first results demonstrate that duct-to-duct biliary reconstruction using an absorbable internal stent had good patency in all four patients. The anastomoses were not accompanied with signs of biliary leakage or stricture in any of the cases. There was no stone formation or pancreatic irritation caused by stent degradation observed after liver transplantation. The biliary stent was absorbed completely without any adverse effects. Nobody developed primary non function of the liver graft. Conclusion: The novel stent seems to be easy to insert, nontoxic, disappears safely from the anastomosis Further prospective randomized study is needed to estimate the efficacy of the bioabsorbable stents. Background: Ex vivo machine perfusion holds the potential to strongly increase the quality of a donor liver and improve post-transplantation function and reducing complications. Ex vivo machine perfusion holds the potential to strongly increase the quality of a donor liver and improving post-transplantation function and reducing complications. Methods: We received 15 discarded human donor livers and machine perfused them in our acellular subnormothermic machine perfusion (SNMP) system for 3 h. Livers are monitored in perfusion for metabolic function and hepatic injury to assess the feasibility of this system for preserving and even recovering discarded human livers. Oxygen consumption and metabolite fluxes are measured as indicators of metabolic function, while AST/ALT and LDH are used to assess hepatocyte injury. Additionally, to assess the function of the biliary system, bile flow, biliary pH and bicarbonate were measured. H&E and EM was performed on the liver and the common bile duct. Results: Resistance on the portal vein and arterial system decrease during perfusion. During perfusion we observe an increasing oxygen uptake, which coincides with the increase of ATP content. pH normalized after an initial acidosis and lactate normalized after a steep initial increase. Bile production is nearly immediate in most livers and production increases with the duration of perfusion. Biliary pH increases as well as biliary bicarbonate. Histologically the liver maintains it's architecture during perfusion. The bile ducts retain a normal looking stroma. Conclusion: This study demonstrates the first use of SNMP for the preservation and recovery of human livers. Our results show that SNMP sustains hepatic metabolism and improves the energy status of the liver and improves the function of the biliary system. These findings are instrumental in the clinical translation of SNMP in liver transplantation. The success of donor exchange programs for kidney transplants has stimulated interest in similar arrangements for liver transplantation (LT). The concept of donor exchange is proposed mainly to avoid blood type incompatibility problems in adult living donor LT (LDLT). However, inappropriate graft and remnant liver volume is the main reason for donor exclusion in both pediatric and adult LDLT. To cope with living donor incompatibility, we started an exchange living donor program for LDLT in 2012. The first recipient was a 6-month-old baby with a PELD score of 18, who had a history of failed Kasai operation for biliary atresia 5 months ago. Her potential donor was her 25-year-old mother, who was rejected because of the large-for-size status of her left lateral segment with a graft-to-recipient weight ratio of 5.8%. The second recipient was a 69-year-old male patient with a MELD score of 14, who had a history decompensated cryptogenic cirrhosis. His potential donor was his 32-year-old son, who was rejected because the future liver remnant was estimated to be less than 30%. After having been informed of all aspects of donor exchange, both pairs consented to participate in exchange LDLT program. The recipients and their potential donors were blood group O. Further studies showed that, the 735 g-left liver of the first donor would be suitable for the 63 kg-second recipient, and the 147 g-left lateral segment of the second donor would be suitable for the 6.6 kg-first donor. To prevent potential conflicts, both pairs of LDLT operations were performed simultaneously on April 10, 2013. Both procedures were successful; the donors were discharged on the seventh postoperative day. The adult and the pediatric recipients were discharged 20 and 45 days after the operation, respectively. Background: Hepatic alveolar echinococcosis (HAE) is a slow-grow parasitic disease lethal in absence of the treatment. Radical surgical resection for HAE is the only chance for cure. However most of patients are diagnosed in advanced stage and resection is performed in less than 35% of the cases. Thus, liver transplantation (LT) associated with bezimidazole may be the only chance for long-term survival and cure. Objective: To present a case of unresectable HAE extent to the heart (atrium) treated by combined living donor liver transplantation (LDLT) with cardiac surgery in a young female patient. Methods: We present a first worldwide case about liver transplantation using right hemiliver from a 26 years old donor associated with cava replacement by allograft iliac vein from a cadaveric donor with same blood type. Because of diaphragm and right atrium were infiltrated, both were resected under extracorporeal circulation. Results: Donor presented an uneventful recovery. Recipient presented Stage IV disease (P4, N1M0), evolved with 3a Clavien grade complication, but recovered well, while liver graft function remained excellent in absence of immunossupressant. Conclusion: Liver transplantation should be considered for unresectable HAE without spread disease. The alternative of LDLT offers the possibility of overcome waiting list issues offering a chance of cure for patients with advanced HAE. Introduction: The prevalence of portal vein thrombosis (PVT) in patients that have been undergone liver transplantation (LT) is 9.7% AE 4.5%. The factors associated with its presence and involvements in post-transplant prognosis are unknown. The aim of our study was to determine the prevalence, assess the factors that are associated with its presence as well as to clarify their association with the prognosis in patients with liver cirrhosis (LC) and LT. Background: Heart valve disease is not common in OLT candidates. Moderate end stage liver disease (MELD >13) contraindicates surgical correction because of poor outcome. Severe aortic regurgitation (AR) with cardiac decompensation constitutes a contraindication to OLT. Material and methods: We report the case of a 48 yo man, CHILD Pugh 14, MELD 32, with acute cardiac decompensation secondary to AR (jet diameter/ LVOT diameter >60%) who was considered for Trans Aortic Valve Implantation (TAVI, TF core valve 31) as a bridge to OLT (Jan 2012). The pt underwent an uneventful TAVI procedure, recovered from the acute heart decompensation without residual AR and one month later (February 2012), underwent under ASA, a succesfull OLT. Intraoperative hemodynamic stability was acceptable: blood loss were close to 6000 ml, transfusion requirements included PRC 12, FFP 16, PLT 2 apheresis units. The pt was extubated on POD 1, was discharged from the ICU on POD 6 and from Hospital on POD 30. Conclusion: As far as we know this is the first case of TAVI used as a bridge to OLT in a ESLD pt. Combined surgery was in the past considered as an option, but results were poor. Instead, TAVI might be considered a feasible option for severe aortic valve disease in OLT candidates. Arash Nickkholgh, Sandra Weih, Markus Kessler, Mohammad Golriz, Stefan Holland-Cunz, Arianeb Mehrabi Ruprecht-Karls University, Heidelberg Background: To present a review of different surgical techniques of SBTx in the porcine model. Materials/methods: Analysis of Medline-cited studies dealing with different techniques of SBTx in porcine models with particular focus on surgical aspects. Results: With regard to graft procurement and enterectomy, the reported techniques vary widely. Arterial reconstruction is mainly conducted by performing the anastomosis between the superior mesenteric artery (SMA) of the donor and SMA or infrarenal aorta of the recipient. Alternatively, an aortic segment of the donor can be anastomosed to the infrarenal aorta of the recipient. Venous anastomosis is frequently performed between the superior mesenteric vein (SMV) of the donor and SMV or the inferior vena cava (IVC) of the recipient. Some studies also report venous anastomosis between the portal vein of the donor and the recipient. Bowel continuity is then restored by end-toend or end-to-side anastomosis. Remarkable results were generated thanks to improved techniques which include proximal side-to-side ileo-ileal anastomosis with double-barrel ileostomy, or so-called "Paul-Mikulicz-Ileostomy". Most frequently used were jejunostomy and the "Bishop-Koop-Ileostomy"where the proximal part of the bowel is anastomosed end-to-side to the distal part, which is then exteriorized as a Stoma. Conclusion: Based on the techniques presented in this review, one must select the most suitable surgical technique of porcine SBTx among those various models. Arash Nickkholgh, Sandra Weih, Markus Kessler, Giovanni Frongia, Mohammadreza Hafezi, Stefan Holland-Cunz, Arianeb Mehrabi Ruprecht-Karls University, Heidelberg Introduction: In Short Bowel Syndrome (SBS), the resorptive capacity of the intestine is not sufficient due to anatomic or functional reasons. Porcine models of SBS are used to simulate anatomical and physiological conditions similar to those in humans for the purpose of research. Material/methods: Through a Medline literature search, this work presents an overview of different techniques used to induce the SBS-model and outline the differences between various models regarding surgical procedures, monitoring, and methods of assessment. Results: Generally, female pigs or piglets 3-8 weeks weighing 10-30 kg were used. The percentage of the resected small bowel ranged from 75% to 100%. The majority of researchers performed a mid-intestinal resection in which the remaining small bowel comprises equal parts of jejunum and ileum. End-to-end anastomoses with single-layer technique with interrupted monofilament absorbable sutures were usually performed. Besides extended bowel resection, small bowel transplantation, bowel lengthening procedures, bowel dilatation, or pharmaceutical treatments for SBS, often in the course of weeks after the extended bowel resection were performed. The period of observation varied widely from 7 days up to 19 weeks. Nutrition was provided parenterally or enterally, according to the objectives of the study. Body weight, food intake, stool output, the general condition of the animal and blood tests were used for monitoring. Functional assessment, morphological assessment, molecular assessment, immunoblotting and immunohistological methods have been also performed. Remote synchronous revascularisation microsurgical technique' (non-dominant forearm) was used for the abdominal wall whilst the intestinal graft was placed intra-abdominally. Two patients presented to hospital around postoperative day 60 with neutropaenia and a peri-follicular, micro-papular pink rash limited to the abdominal wall graft. Histology revealed grade II-III rejection in each case. Both patients were systemically well, had normal stoma output (<20 ml/kg/24 h), citrulline levels >25 lM and endoscopically healthy bowel. Ileal biopsies revealed histologically normal mucosa. Treatment in each case was with a single dose of 20 mg Basiliximab IV, three pulses of 500 mg methylprednisolone IV and mycophenolate sodium or azathioprine. The rash improved within 48 h and neither patient suffered further rejection. Conclusion: Around post-operative day 60 is the high-risk period for abdominal wall rejection, and presentation is with neutropaenia and rash. CD25 down-regulation with Basiliximab, combined with methylprednisolone is effective in treating acute rejection. Abdominal wall grafts appear to reject whilst underlying bowel remains healthy. Right sided lung transplantation (RLTx) was done at Feb 2010 on a 29 year old male with airway-centered interstitial fibrosis (AIF) and class IV dyspnea and hypoxia despite prednisolone and azathioprine use. He developed bronchial anastomotic stricture and malacia and RUL bronchial stenosis after aspergillous infection of the bronchial anastomosis extending to RUL bronchi. Repeated episodes of RUL collapse and abscess occurred which were treated with balloon dilatation, bronchoscopical drainage and antibiotic. Repeat HRCT showed hypo vascularity of the right lung and Lung V/Q scan revealed 86% ventilation and perfusion of the left and 16% of the right lung. Pulmonary artery angiography showed little perfusion of the right pulmonary artery. Right pneumonectomy of the transplanted lung was done at Feb 2012 with discontinuation of immunosuppression except prednisolone 5 mg /day. The patient was well during the first week after pneumonectomy. However, the spirometric parameters decreased and HRCT showed patchy ground glass opacity in the left lung that was not responded to increasing prednisolone dose. The patient's dyspnea, spirometric parameters, 6 min walk test and HRCT findings were improved after restarting of mycofenolate, although the indexes were lower in comparison with the early post-pneumonectomy period. Conclusion: AIF is a rare life-threatening form of non-reversible obstructive lung disease that usually doesn't respond to treatment and progressive cases may require lung transplantation. The mechanism of increased naive left lung function is unknown. However, as it was initiated after right sided lung transplantation, it could be due to post-transplant immunosuppression. We studied the impact of different immunosuppressive combinations on bronchial healing in LTx. We conducted a retrospective study on all LTx performed in a single center between January 2004 and May 2012. We focused on denutrition, graft ischemia, mechanical ventilation support, lung infection, and the combination of immunosuppressive therapy. Bronchial complications was defined as symptomatic dehiscence or symptomatic stenosis. We found 35 bronchial complications leading to death in seven patients. Of 134 patients remained unharmed.Both groups received overall the same amount of steroids. Patients with the combination basiliximab/steroid/tacrolimus/mycophenolate had significantly more bronchial complications (p = 0.03) in comparison to patients with the combination steroid/ciclosporin/azathioprine. The combination basiliximab/steroid/tacrolimus/mycophenolate has a negative effect on bronchial healing. The effects of immunosuppressive drugs should be studied when given in a combination. Background: CLAD is the leading cause of late mortality following lung transplantation. Studies show a 26-32% survival at 5 years after developing CLAD. In the Lausanne-Geneva lung transplantation program about three patients a year die of CLAD. Our experience shows that patients with CLAD suffer not only from physical symptoms but also from psychological, social and spiritual distress. Method: We made the hypothesis that quality of life of these patients can be improved by incorporating palliative care early in the management of CLAD. As in the literature there are no reports about CLAD/palliatives care and in order to better take the patients in charge we have to explore their needs through a qualitative study. We will make interviews that will be recorded and analyzed through a framework approach. The evolution of symptoms and quality of life will be evaluated by (ESAS/SF36). Results: We will present the first results of the interviews in September and expose the strategies of collaborative management based on these data. Background: Voriconazole has been largely demonstrated to be, alone or in combination with other agents, an effective treatment for invasive fungal infections among lung transplant recipients (1) (2) . Unfortunately its usage is often limited by several adverse reactions including acute and chronic cutaneous effects, mainly due to a phototoxicity mechanism (3). The most likely mechanisms of phototoxicity is directly related to either voriconazole or to its N-oxide main metabolite(NOX), and an interaction with retinoid metabolism (3). There are currently no studies available to state that the presence of higher level of NOX is definitively associated with increase photosensitivity. Methods: Of 73 lung transplant recipient in treatment with voriconazole have been tested for voriconazole and NOX levels from September 2011 to January 2013. All the patients were asked to complete a surveillance questionnaire specifically generated to assess the presence of photosensitivity. Patients admitted in to hospital during the treatment and patients for whom treatment was suspended for other reasons (liver toxicity, persistent visual hallucinations, etc) were excluded from the study. Results: Of 33 patients were included in the study. 20 patients had normal NOX levels and none experienced photosensitivity; 61.5% of patients had photosensitivity associated with high level of NOX (despite voriconazole levels being within the therapeutic range); five patients had high NOX level but none experienced photosensitivity (four Cystic Fibrosis and one with a1 antitripsin deficiency). Conclusion: The preliminary results of the study suggested that there is a correlation between the presence of high level of NOX and photosensitivity. We believe that increased levels of NOX could be associated with a particular subgroup of patients having an "intrinsic susceptibility" to voriconazole. The potential to identify this sub-group could improve short and long term outcomes especially in prolonged treatment. Background: The incidence of respiratory viruses associated communityacquired pneumonitis (CARVs) is increasing in lung transplant recipient population.In particular virus members of the Paramyxoviridae family (PV) such as respiratory syncytial (RSV), parainfluenza virus (PIV), human Metapneumovirus (hMPV) play an important role in the etiology of this infection (1) .PV infections are also a well recognized risk factor for the development of bronchiolitis obliterans syndrome (BOS) (2-3). The use of intravenous immunoglobulin (IvIg) for an increasing number of conditions has more than doubled in the last decade (4) and in transplant recipient for treatment of antibodies mediated rejection and viral pneumonitis resistant to antiviral treatment (mainly CMV related). There are very few data about the use of IvIg in CARVs. We retrospectively reviewed data in our population of lung transplant recipient over a period of 64 months. Methods: Of 35(36 treatment) lung transplant recipients presenting with drop in lung function and flu-like symptoms were tested with chest imaging, bronchoscopy with bronchoalveolar lavage and biopsy and/or nasal pharyngeal swab/aspirate. Patients with positive PCR for respiratory viruses and biopsy consisted with interstitial viral pneumonitis and/or radiological changes consistent with pneumonitis were treated with IvIg for 5 days. Results: PCR was positive for PIV in 11 patients, Hmpv in 9, RSV in 6, H1N1 in 1, Adenovirus in 2, negative in seven patients. In 24 of 36 treatment episodes the respiratory symptoms resolved completely, with RFTs returning to baseline. Nine patients died post-treatment and three patient developed BOS. There were minor adverse drug reactions in four patients: bradycardia (1), headache (3) and nausea (1), none necessitated treatment discontinuation. Conclusion: CARVs incidence is increasing in lung transplant recipient and is a well established risk for the incidence of BOS. Treatment with IvIg effective and generally well tolerated Background: Hyperammonemia related encephalopathy (HRE) post orthoptic lung transplantation (OLT), is a rare but fatal complication. Various interventions affecting ammonia generation, pathways of nitrogen excretion, and methods for removing ammonia have been described. Methods: We describe three cases that developed HRE immediate post OLT. (i) 67 year male with idiopathic interstitial lung disease, day 7 following OLT, became drowsy. Serum ammonia (NH4) level was 302 lM (normal <40). In addition to renal replacement therapy (RRT), rifaximin, arginine, and levocarnitine were commenced. (ii) 46 year male with a1-antitrypsin on day 9 following OLT became agitated, progressing to coma. NH4 level was 269 lM. In addition to RRT, neomycin, lactulose, arginine, sodium benzoate, sodium phenylacetate and acetohydroxamic acid were commenced. (iii) 59 year male with Idiopathic Pulmonary Fibrosis on day 7 developed agitation. NH4 level was 155 lM. in addition to RRT, levocarnitine, arginine, phenylbutyrate, lactulose and rifaximin were commenced. Dosage and modality for RRT in the three cases are illustrated in figure 1, 2 and 3 respectively. Discussion: NH4 clearence depends on rate of ammoniagenesis, volume of distribution, and rate of removal. However, even at Continuous veno-venous hemofiltration doses of 40 ml/kg/h and Sustained low-efficiency dialysis (SLED) doses of 250 ml/kg/h, NH4 clearance was not significant. Intermittent hemodialysis (IHD) using a large surface area dialyzer (2.1 m 2 ) and maximum tolerated blood flows (450-500 ml/min) is the most effective RRT. Case 1 died due to development of brain edema and retrospectively, with use of more aggressive RRT to reduce NH4 as with the other cases might have altered the outcome. Conclusions: Prompt and aggressive ammonia reduction with prolonged daily IHD in conjunction with early weaning of steroids and other therapeutic measures may prevent HRE. We also recommend discontinuation of drugs which impair urea cycle. Persons of Jehovah's Witness (JW) faith present complex and challenging surgical cases due to their religious belief preventing use of blood and blood products transfusions. Lung transplantation (LTX) is now recognized treatment for many end stage lung diseases. However, LTX still presents a difficult surgical case as patients can sustain significant blood loss requiring transfusions. Consequently, patients of JW faith with end stage lung disease present a particularly difficult surgical case and management of immune suppressants for LTX where blood transfusion is not possible. We present our experience in caring for a lung LTX recipient who is of JW faith. Patient is a 69 year old Caucasian male with IPF, who was referred to our center for LTX evaluation with a 2 years history of progressively worsening SOB especially with exertion. Patient's FEV1 was 2.17 L and FVC was 2.6 L (82%, 78% predicted) 1 month prior to transplant. Patient was NYHA 3, had noncontributory surgical and family history, and a 20 pack year history of smoking. Because he was unwilling to consent for blood transfusion during LTX, he was given weekly 100 lg SQ darbepoetin injections, premedication with pentoxifylline and methylprednisolone, and 324 mg ferrous fumerate TID. Hemoglobin/hematocrit levels were measured regularly while he awaited transplantation. Patient was listed for single left LTX and a donor became available 6 months after listing. He was admitted to the hospital with hemoglobin/hematocrit at 14.9 g/dl/43.2%, he received 125 mg sodium ferric gluconate in 110 ml NS at 100 ml/h and 200 lg of darbepoetin 6 h prior to surgery. He underwent surgery without CPB. Estimated blood loss was 400 mL. He received two units of Cell Safer intraoperatively. Hemoglobin/hematocrit after LTX measured 13.7 g/dl/40%. Post operatively results remained low for the first two days and returned to normal levels on day five. At discharge, patient's hemoglobin was 14 g/dl. At one year post transplant, patient was classified as NYHA 1. Patient's hemoglobin/hematocrit were 14.6 g/dl/44.1%, with immensely improved lung function: FEV1 of 3.07 L and FVC of 3.76 L (117%, 114% predicted). Neeraj Sinha, Harish Seethamraju, Thomas Kaleekal, Soma Jyothula, Babith Mankidy, Scott Scheinin The Methodist Hospital Background: As HIV (human immunodeficiency virus) infected patients have lived longer with the use of effective combination antiretroviral treatment (cART), chronic illnesses including advanced lung diseases have increasingly affected them. Methods/materials: Study design was a single-center case series. Results: Since April, 2010, two HIV infected patients (on cART with negative viral load) have received lung transplantation at our hospital. Both patients were Caucasian males in their early sixties with idiopathic pulmonary fibrosis. Both had positive hepatitis B core IgG antibodies without viremia. One patient had hepatitis C antibodies without viremia. Both had pulmonary arterial hypertension. Both patients are alive, well and free of bronchiolitis obliterans syndrome (BOS) at 38 and 13 months post bilateral and right single lung transplantation respectively. Both of them had only one episode of acute rejection each (both A1 grade) in the first year. Both have remained without HIV, hepatitis B, CMV (cytomegalovirus) and EBV (Ebstein-Barr virus) viremia. Both have remained free from hepatocellular dysfunction/cirrhosis. Except for pseudomonas aeruginosa pneumonia in the third year post transplant in one patient, no significant infectious complications were noted. Significant drug-drug interactions were noted, especially with protease inhibitors. Conclusion: Lung transplantation can safely be performed and prolong survival in HIV infected patients with advanced lung diseases. Drug-drug interactions pose a significant, but surpassable, challenge. Background: Prolonged-release once-daily Tacrolimus (OD-TAC) can improve safety by avoiding toxic peak levels, as well improving adherence to I/S regime, compared with twice-daily Tacrolimus (BID-TAC). However, published data on use of OD-TAC post lung transplantation (LTx) has been minimal to date. Methods: From June 2011 at our institution, OD-TAC was approved for use in selected LTx recipients with a 1:1 conversion from BID-TAC to OD-TAC. Data Abstracts of the Methodology of assessment of the pancreatic transplant program to improve the quality after spktx was established. Complications after 112 spktx were classified by Dindo-Clavien scale and divided into: complications due to transplanted pancreas (n = 66), transplanted kidney (n = 23) and general surgical complications (n = 31). Risk adjusted model using multivariable logistic regression and the observed to expected ratio of mortality (O/E RM) was assessed for three eras of transplant program. Mortality due to complications originated from transplanted pancreas, kidney and general surgery complications were: 12.5%, 1.7% and 1.7% respectively. The model for mortal complications of transplanted pancreas is: p = 4.08 + 0.064 9 donor age + 1.37 9 transplanted pancreas vascular anastomoses pancreas above 35 min À1.93 9 duration of dialysis therapy above 24 months. O/E RM for three eras of pancreatic transplant program were: 0.89, 1.69, 0.92 respectively. This methodology objectively evaluated our program. Results: We performed eighty-seven pancreas or pancreas and kidney transplantations (83 SPK, 1 PAK, 3 PTA). We present three cases of massive bleeding from the gastrointestinal tract in the 2nd, 6th and 10th months after transplantation. Each of these patients required an urgent operation as a result of arterial-graft duodenal fistula. Medical records of these patients were analysed. Conclusion: Massive gastrointestinal bleeding with concomitant rapid general health state collapse in patients after pancreas transplantation may be the result of an arterial-graft duodenal fistula. Immediate diagnosis and endovascular treatment involving stenting the artery are crucial for the patient's survival. In every case the patient required resection of the pancreatic allograft. Sally Finlay, Elijah Ablorsu, Argiris Asderakis, Dawn Chapman Cardiff and Vale ULHB Introduction: There is limited research into the role of nutrition within Simultaneous Pancreas Kidney Transplant (SPK) candidates. Malnutrition is considered one of the late complications of chronic kidney disease and type-1 diabetes. It is important to actively manage these patients prior to transplantation and provide adequate, intense nutrition after surgery. Early Enteral Nutrition (EEN) has been proven to improve the postoperative course after major surgery. Method: Prospective data was gathered from 23 consecutive SPK recipients who underwent transplantation between Jan-2010 and Jul-2012. All candidates received nutritional assessment prior to activation on the WL and posttransplant nutrition was planned according to their nutritional status (early oral intake with supplementation [O] or early jejunal feeding, via NJ tube inserted during surgery [J] ). The end-point was to assess nutritional intake between the two groups: achievement of ¡ Y60% energy requirements by day-7 (7d-60%) and at the time of discharge (total-60%). Results: From 23 recipients, 13 received J-feed and 10 O-feed. We found no difference between these groups in demographics. However J-group had lower BMI (24.17 vs. 24.9, p = 0.14) and lower pre-transplant Albumin (30.4 vs. 35.1, p = 0.05). Despite features of malnutrition in J-group, they reached 60% energy requirements significantly faster (7 vs. 15 days, p = 0.02); with higher 7d-60% (87% vs. 60%, p = 0.31) and shorter period of reinstitution of pretransplant albumin levels (56 vs. 69 days, p = 0.55). Only one patient in each group required TPN. Conclusion: Results suggest both types of EEN provide sufficient nutritional intake for SPK recipients; and more importantly minimize need of TPN. Furthermore, careful pre-transplant nutritional assessment can identify malnourished candidates and recommend early jejunal feeding. Background: Due to the ongoing shortage of cadaver organs the use of extended criteria donors for pancreas transplantation should be considered. The use of organs after "rescue allocation" within EUROTRANSPLANT region, could be a possibility to expand the donor pool. Material and methods: Between 2007 und 2010, 31 pancreas transplantations were performed at our centre. Among these, in seven cases (six SPKTs, 1PTA) "rescue organs" (RO) were used. These organs had been officially offered to and rejected by at least three consecutive centers for medical reasons (donor instability, medical history of the donor and/or logistical problems). Donor, recipient and clinical/laboratory transplantation/post-transplantation outcomes from patients receiving "rescue organs" were collected and compared with organs from conventional (CONV) donors. Results: The mean donor age was higher in the RO-group than in the CONV donor-group (28.3 AE 10.7 years vs. 23.0 AE 12.5 years). With a similar mean follow-up period (2.3 AE 0.6 years RO-group vs. 3.9 AE 1.2 years CONVgroup), patient, kidney and pancreas graft survival rates were 85% in all three categories in the RO-group respectively, whereas outcomes for CONV donors were 88%, 85% and 83%, respectively. Incidences of pancreatic graft thrombosis, delayed graft function, acute and late rejection episodes such as relaparatomy rates and infections were comparable between both groups. There were no differences between mean Hb1Ac levels between both groups 2 years after transplantation. Whereas, mean serum creatinine levels (ROgroup: 78.8 AE 21.0 lM vs. 114.3 AE 28.4 lM in the CONV donor-group p < 0.05) 2 years postoperative showed significant differences between both groups. Discussion: Long-term outcomes of transplanted pancreas from the ROgroup were comparable to organs from the CONV -group. Based on the good results, the use of organs from donors with extended criteria's could be a good possibility to expand the donor pool. Clinical case: A 57 years old man received a SPK with enteric esocrine drainage with duodeno-ileal mechanical anastomosis. Post operative course was complicated in 8th PO by leakage of the duodenal-ileal anastomosis. The patient underwent two surgical procedures with reconstruction of the duodenalileal anastomosis and, due to a further leakage, suture of the anastomotic hole. Nevertheless, the persistance of high flow fistula (800 ml/die with amylase of 40 000 U/l) led to an alternative approach with peri-anastomotical abdominal drainages placed by interventional radiologist. The patient was discharged and underwent serial contrastographical controls for the following months, showing a progressive resolution of the fistula. After 7 months peri-anastomotical drainages were removed; the patient has always had optimal renal function and normal glycemia with no need of insuline therapy. Conclusions: Healing of a EF in a SPK transplantation recipient is a slow process which can be obtained with conservative treatment, allowing to preserve graft function. Background: It is well established the association between obesity and diabetes, metabolic syndrome, pancreas insufficiency and progression of chronic kidney disease. Recent evidences showed the improving of renal and pancreatic function after bariatric surgery. We reported a single case of obese patient with a functioning pancreatic graft subjected to sleeve gastrectomy. Clinical case: A 49 year-old obese man of 118 kg, BMI 35.5, underwent pancreas transplantation in 2004 owing to uncontrolled type 1 diabetes came to our attention. He was affected by mildly chronic kidney disease (Serum creatinine: 1.39 mg/dl, Plasma filtration rate: 61 ml/min) with the evidence of microalbuminuria (55.5 mg/l), arterial hypertension, dyslipidemia. There was a good metabolic control (Hb1ac: 41 mmol/mol, Fasting plasma glucose: 107 mg/dl). Current immunosuppressive therapy was mycophenolate and FK 506. The patient underwent to gastroscopy, gastrografin swallow, abdominal ultrasound before surgery, with the finding of hepatic steatosis. To improve metabolic control and kidney function a laparoscopic sleeve gastrectomy was planned. The section of the stomach was started at 6 cm from pylorus, with a gastric calibration of 12.7 mm (42 French), all fondus of the stomach was then completely removed, with cardias distance from the end staple-line of 1.5 cm. The patient is currently recovered with no complication. Background: Diabetes mellitus is one of the major chronic metabolic diseases affects at least 200 million people worldwide. Pancreas and Islet cell transplantation is an effective way for treatment of diabetes. The aim of this study is to produce insulin-producing cells (IPC) from umbilical cord Wharton's jelly mesenchymal stem cells. Methods: The isolated MSCS from Wharton's jelly were positive for CD44 and CD90 and CD105 and negative for CD133, CD45and CD34. The cells were cultured in Dulbecco Modified Eagle Medium-F12 (DMEM-F12) with retinoic acid (RA), Epidermal Growth Factor (EGF), exendin-4 and 10% FBS in three step protocol for 20 days. Results: HUMSCS morphology changed from fibroblast like cells in to round epithelioid cell clusters. The IPCs expressed the insulin, PDX1 and Ngn3 mRNA in RT-PCR method. DTZ staining was employed and the red granule was observed in clusters. The insulin secretion was measured by ELISA assay. Conclusion: Although we produced the IPC cells, but our yield was low. However, HUMSCS could be considered as the cell of choice for cell-based treatment of type 1 diabetes. Aim: There is limited evidence currently available to explain the psychosocial aspects of pancreas transplantation especially after graft failure. The aim of this study was to investigate different aspects of patient well being relevant to pancreas transplantation. Methods: Questionnaires were sent out to patients who had undergone Simultaneous Pancreas Kidney (SPK) transplantation along with those on the waiting list (W/L). Questionnaires included The Hospital Anxiety and Depression Scale (HADS), Clinical Outcomes in Routine Evaluation (CORE-10), Generalised Anxiety Disorder Assessment 7 (GAD-7), Roland Morris Disability Questionnaire Abbreviated (RMDQ-A), work and social adjustment scale (WSAS) and WHO Quality of Life-BREF (WHO-QOL BREF) within four domains. Results are expressed as mean AE SD and p value ≤0.05 (ANOVA) was considered significant. Results: Overall response rate was (45%) including those on the W/L (n = 6), functioning SPK (FSPK) (n = 24) and non-functioning SPK (NFSPK) (n = 6). The HADS responses did not reveal any significant difference between the three groups (p values of 0.078 and 0.079 for anxiety and depression scores respectively). The scores for CORE-10 questionnaires revealed significantly higher levels of psychological distress in patients with NFSPK (17.83 AE 3.0) compared to FSPK group (9.44 AE 6.5) (p = 0.014). A similar pattern was noted with the RMDQ-A questionnaire which revealed higher levels of disability in FSPK group (6.1 AE 6) compared to NFSPK group (14.4 AE 3.2) (p = 0.028). Scores were similar in all groups for GAD-7 (p = 0.069), WSAS (p = 0.061) and Domains 1, 2 and 3 in WHOQOL-BREF (p = 0.054, 0.066 and 0.087 respectively) with better indices in post transplant group for domain 4 (p = 0.001). Conclusion: This study demonstrates that despite correction of uraemia those patients with a failed pancreas graft do experience significantly reduced impairment in some aspects of their quality of life which should be addressed during their rehabilitation. Background: Simultaneous pancreas and kidney (SPK) transplantation is a recognised treatment for Type I diabetes mellitus (DM) but suitability as a treatment for Type II DM remains controversial. C-peptide levels are used to aid differentiation between Type I and II diabetics. We identified patients with a raised c-peptide prior to pancreas transplantation and assessed post-transplant outcomes. Methods: All patients undergoing pancreas transplantation at a single centre between January 2008 and September 2012 were identified. Patients with a pre-operative c-peptide >0.02 ng/ml were extracted from this group and analysed. Patient demographics and pre-operative data specific to DM were recorded. Post-operative outcomes including incidence of complications and short and long term graft and recipient survival were assessed. Results: Three-hundred-and-sixty-five pancreas transplants were performed during the study period. Twenty five (6.8%) patients had a preoperative c-peptide >0.02 ng/ml with a median level of 0.49 ng/ml (range = 0.04-4.51 ng/ml). All patients underwent SPK transplantation. Median age at diagnosis of DM was 16 years (range = 2-51 years) and mean body mass index (BMI) was 24.6 kg/m 2 . In the immediate postoperative period, 3 (12%) patients developed vascular complications and 2 (8%) patients developed infected pelvic collections requiring surgical and percutaneous drainage. One (4%) patient required a laparotomy for small bowel obstruction and 1 (4%) patient died 66 days post-operatively following graft pancreatectomy. Twenty four (96%) patients had a functioning graft at time of discharge and at last follow-up (range 0.25-4.5 years), 22 (88%) patients had functioning grafts. Conclusion: We report favourable early late outcomes in this patient population that are comparable to patients without pre-operative c-peptide production. Background: Simultaneous pancreas and kidney (SPK) transplantation provides insulin and dialysis independence. However, the recipient may have comorbidities contributing to malnutrition and a chronic catabolic state, strong predictors of adverse outcome. Current trends favour early enteral feeding. However, in SPK patients, concerns exist due to perceived risks of gastroparesis, ileus and a fragile enteric anastomosis. Total parenteral nutrition (TPN) is therefore routine therapy in some units. We aimed to assess outcomes of this nutritional modality. Methods: A retrospective study was performed of SPK recipients in a single centre over 2 years (11/10-11/12) focusing on nutritional therapies and subsequent clinical outcomes. Nutritional parameters included TPN duration, time to enteral diet, and complications directly attributed to TPN. Clinical outcomes included critical care and total hospital stays. Post-operative nutritional biomarkers were assessed. Results 52 patients were included (32 male, 20 female; mean age 42.9, [SD = 7.9]; mean BMI 24.0 [SD = 2.8]). 77% started TPN on day 1 post-transplant and mean duration was 9.8 days (range 3-23; SD = 4.2). Mean ITU and total lengths of stay were 6 (SD = 6) and 30 days (SD = 26) respectively. Complications attributable to TPN included sepsis (5.8%), feeding catheter leak (3.8%), fluid overload (1.9%) and hyperglycaemia (9.6%) which normalised after a TPN break. Serum albumin dropped by >30% immediately and remained below normal in the first week post-surgery. Alkaline phosphatase levels increased above normal range after 6 days with no long term sequelae. Conclusions: TPN appears to provide a safe modality of nutritional support for early post-SPK nutrition with a low rate of reversible complications. However, its potential advantages remain unclear. Further randomised comparative studies against enteral nutrition are required to clarify the optimal approach in this challenging group of patients. edat, Nadja Niclauss, Axel Andres, Anne-Sophie Jannot, Christian Toso, Philippe Morel, Thierry Berney University Hospital of Geneva Background: The prevalence of obesity is rising in the surgical population. In pancreas transplantation, the impact of recipient BMI on short and long term pancreas graft survival has not been studied. Methods: We analyzed data from all individuals who underwent a first pancreas transplant from October 1, 1987 to August 30, 2011 and recorded in the Scientific Registry of Transplant Recipients. Recipients were categorized into BMI classes. Long-term graft failure was defined as return to insulin therapy and therefore includes post-transplant diabetes mellitus (PTDM). Patient and graft survival were analyzed by Kaplan-Meyer. Groups were compared using the logrank test for univariate analysis and Cox proportional hazard regression for multivariate analysis. Results: Of 21 075 individuals were included in the analysis. Median follow-up was 4 years. Subjects were overweight or obese in 39%. Early pancreas graft loss increased with recipient BMI (p < 0.001). Compared to normal or low BMI, risk of early graft failure at 90 days increased by 21%, 50% and 74%, for overweight, obese class I and obese class II recipients, respectively. Early mortality was similar in all groups, except for class II obese recipients in whom risk of death increased by 84% as compared to other groups. Compared to normal or overweight BMI, risk of graft failure at 4 years increased by 23%, 15% and 35%, for underweight, obese class I and obese class II recipients, respectively. The low Abstracts of the 16th Congress of the European Society for Organ Transplantation graft survival in underweight recipients was associated with a risk of death increased by 67% as compared to normal BMI recipients at 4 years. Conclusion: Increased BMI is associated with an increased risk of early graft loss and early mortality. Increased BMI does not seem to be associated with an increased incidence of PTDM. Underweight is associated with an increased risk of death in the long term. Background: Pancreas graft is a fragile organ that requires optimal conditions to be retriveed. If we also consider organ shortage, we observe that the number of patients on the waiting list is growing. That is why we must make a special effort to maximize the use of donor pancreas. Methods: We report three cases of pancreatic harvesting in challenging circumstances. One of them in a donor with a previous splenectomy and the other two cases in two different donors in which we found an annular pancreas (AP). Two of the cases were simultaneous pancreas-kidney transplantation, and the other one was a pancreas after liver transplantation. Results: The average age of the recipients was 40 years and 66% of them were male. All patients had a graft normal function after transplantation and were discharged without insulin requirements. Only one case transplanted with an AP, suffered a graft thrombosis a year after transplantation and nowadays is in the waiting list for retransplantation. Conclusions: Pancreas grafts retrieval in donors with previous surgeries and AP grafts are challenging from a technical point of view, but do offer good results in recipients. There are no association between AP transplantation and a higher rate of graft thrombosis. Given the limited numbers of donors, we must evaluate every pancreas graft with these features. Background: We studied 28 patients who had received simultaneous pancreas and kidney transplants from 27th February 2010 to 1st of February 2013. Creatinine, amylase, lipase and glycosylated hemoglobin were collected, at discharge and again after 1 month, 6 months, 1 year and 2 years. All patients were treated with Thymoglobulin, corticosteroids, calcineurin inhibitor and mycophenolate mofetil. Methods and material: We studied the evolution of creatinine at discharge and at two years, also how long cold ischemia and laboratory parameters were at discharge. Pancreatic and renal functions were assessed using Student's t test and are presented as mean and standard deviation. The analysis was conducted using SPSS (v15.0). We determined a confidence level of 95% and the results were considered statistically significant, the differences if p < 0.05. Results: During this period 28 patients received pancreas-kidney transplants in our service. The average cold ischemia time of the pancreas was 11 h 57 min and of the kidney was 14 h 58 min. The mean creatinine, amylase and lipase at discharge were 1.31 mg/dl, 74 and 32.5 U/l respectively. We observed no statistically significant changes between values of creatinine, lipase and amylase at discharge and at six months, one, two, three and four years. However, HbA1c showed a statistically significant decrease between the values at the time of transplant and three months being the average of 7.41% and 5.03% respectively. Four years later after the start of our program, all our patients are alive. One patient (a woman) died in the operating theatre and because of that, she was excluded from the study. Considering this, our survival is 96.4% at 4 years, with all the allografts working. Conclusions: Pancreas and kidney transplantation is a very suitable treatment option for type I diabetes patients, who need renal replacement therapy, with improvement evident in the levels of glycosylated haemoglobin. Tor J. Eide, Ole Øyen, Rune Horneland, Aksel Foss, Vemund Paulsen, Jørn P. Lindahl, Knut Lundin, Lars Aabakken, Trond Jenssen Oslo University Hospital Rikshospitalet Background: To further improve on rejection surveillance after pancreas-Tx (PTx), we have now performed a series with enteroanastomosis against native duodenum (END; at the junction of pars descendens/horizontalis), allowing endoscopic transduodenal ultrasound-guided biopsies of the pancreas (EUS-BP). Material and methods: From sep. 2012 to may 2013, 27 PTx's have been performed by END. Scheduled biopises of the duodenal segment and pancreas were planned at weeks 3 and 6, and 1 year post-Tx. Results: This PTx-END material, which represents the largest series published so far, has been divided into an early (first 13) and late (last 14) era, to demonstrate the experience gained. The PTx-END was easy to perform, without tension, and none of the complications were directly attributable to the END. In the patients with graftectomy, the duodenotomy was closed without complications. The case with exocrine leakage was solved by endoscopic stenting of the pancreatic duct. Fig. 1 : Endoscoping stenting of the PTx-END duct. Guide-wire and contrast in duct (lright). Final placement of stent (left); Tx-duodenal segment below; distal duodenom below. However, the more "retrovisceral positioning" of the pancreas gave rise to tension on the portal vein/caval anastomosisreflected in the high rate of reoperations during the first era. Through this series, we have adjusted several technical details, and do think we are about to "crack the code". The portal vein should be elongated in the majority of cases. The END was easy to access endoscopicallypreferably by 0-30°optique. Biopsies were easier and faster to obtain than by Double ballon enteroscopy. Conclusions: By technical adjustments, our PTx-END results have improved through this series. The PTx-END and EUSBP seem safe, and may provide improved rejection surveillanceas well as improved therapeutic options towards exocrine leakage. However, the procedure is still considered "under evolution". Reem Ezzat 1 , Hussein Okasha 2 , Hala Moustafa 1 , Mahmoud Ashry 1 , Mohamed Naguib 2 , Emad Elgemeie 3 1 Assuit University Hospital; 2 Cairo University Hospital; 3 National Cancer Institute Background: Recently, many imaging techniques helped in increasing frequency of detection of pancreatic cystic lesions. The addition of fine needle aspiration for the used imaging methods has raised the accuracy a lot for early detection of neoplasm. Aim: To differentiate between benign and neoplastic pancreatic cystic lesions by evaluating cyst fluid CEA, mucin stain, amylase and CA19-9 compared to conventional cytopathologic examination. Subjects and methods: This prospective study included 61 patients with pancreatic cystic lesions. After having written consents, the patients were subjected to US-FNA or EUS-FNA according to the accessibility of the lesion. The aspirated specimens taken from the cysts were subjected to cytopathological examination (including mucin staining), tumor markers (CEA, CA19-9) and amylase level. Results: Using the appropriate statistical tools, specificity, sensitivity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic accuracy were calculated. Mucin stain alone in cystic fluid showed sensitivity 86%, specificity 94%, PPV 90%, NPV 92% and accuracy 92% for neoplastic detection. Cytopathological examination alone showed sensitivity 83%, specificity 91%, PPV 89%, NPV 85% and accuracy 87% for detecting neoplastic lesions.CEA level had sensitivity of 69%, specificity 59%, PPV 55%, NPV 73% and accuracy 64% for neoplastic detection. Adding CEA level to mucin level with cytopathological examination of the aspirate showed sensitivity 97%, specificity 50%, PPV 63%, NPV 94% and accuracy 72% for neoplastic detection. Endoscopic ultrasound had sensitivity 40%, specificity 100%, PPV 100%, NPV 10% and accuracy 44% but abdominal ultrasound was inconclusive. CA19-9 did not show statistical significant difference between neoplastic and benign cysts. Conclusion: The combination of CEA, mucin and cytopathology in fine needle aspiration of pancreatic cystic lesions showed better sensitivity than each analysis when done alone and are suggestive but not diagnostic .  Little information is available to advise patients during the consent process about the necessity for-and likely quantities of packed red blood cell transfusions for pancreas transplants. In 2012, 77 pancreas transplant procedures were performed in Oxford, (15 pancreas alone transplants PAT and 62 simultaneous pancreas and kidney SPK transplants). The actual quantities of packed red blood cells used, both intra-operatively and during the admission were recorded. Pancreas transplant patients received an average of 4.77 units of packed red blood cells (5.29 for SPK, 2.6 for PAT). On average, of 1.46 units (1.58 SPK, 0.93 PAT) was transfused on the day of operation and a further 3.31 units (3.71 SPK and 1.67 PAT) were given during the rest of the admission to hospital.Only 24.68% of patients did not require a blood transfusion (16% SPK, 60% PAT). Admission haemoglobulin and dialysis technique were the only predictors demonstrated for transfusion quantity for each procedure (age, BMI, HbA1C, cold ischaemic time also assessed). Information is now available to better advise pancreas transplant patients on the need for blood transfusions both intra-and post-operatively. Abstracts of the 16th Congress of the European Society for Organ Transplantation Objective: To evaluate the current status of pediatric kidney transplantation (PKT) activity in the Arab world.Methods:A questionnaire was mailed to all kidney transplant centers in Arab countries to collect data on kidney transplant activity in a recent single year. Results: Of 3309 kidney transplants were performed in one year with a transplant rate of 9.5 per million populations (pmp); 298 were performed for children with a PKT rate of 0.87 pmp.The pediatric share of all transplants is 9% 0.93.5% of all transplants were from living donors. Deceased transplant activity in Arab countries accounts for 14-31% of all transplants in the three countries with deceased donor programs. Out of 212 adult and pediatric transplants that were performed from deceased donors in 8 countries; only 29 cases were for pediatric recipients. Conclusion: PKT is still inactive in most Arab countries and mostly relying on living donors. The lacking of well developed deceased programs is the main issue to be addressed. Background: Early introduction of everolimus (EVR) may address the concern with long term use of calcineurin inhibitors and steroids in pediatric renal transplant recipients (pRTxR). Methods: This is a 12-month (mo) study with 24-mo additional safety follow-up in pRTxR ( ıc1 and <18 years). Following a 4-6 weeks run-in period post-Tx, pRTxR (eGFR >50 ml/min/1.73 m 2 ) treated with tacrolimus (TAC) + mycophenolate mofetil + steroids will be randomized (RND) to either continue this regimen or start EVR + reduced TAC + steroid withdrawal at month 6 (figure). Co-primary objectives at Mo12 are to estimate the rate of composite efficacy endpoint of biopsy proven acute rejection, graft loss or death and to evaluate the renal function. Results: Approximately 106 pRTxR will be RND in 2012 and 2013 across 30 sites in 12 countries. Till date, nine patients were enrolled of whom four were RND. Mo12 results are expected in Q4 2014. Conclusions: This study will validate the benefits with early introduction of EVR to reduced TAC exposure and steroid withdrawal at Mo6 in pRTxR. Ismail Sert, € Onder Yavascan, Cem Tuðmen, Selc ßuk K yl ync ß, Orhan Deniz Kara, Alkan Bal, Sait Murat Doðan, Caner Aksu, Cezmi Karaca, Nejat Aksu Tepecik Training and Research Hospital Although short-term renal allograft survival in children has improved over the years, long-term graft outcomes remain unclear. We report the characteristics and other variables that impact long-term kidney graft survival in children. Records of 61 pediatric kidney transplant recipients performed at our institution between 1995 and 2011, were evaluated. Patients were divided into two groups (functional and non-functional grafts) to investigate the factors that impact graft survival. The groups were compared in terms of recipient characteristics, underlying disease, HLA status, immunosuppressive therapy, donor characteristics as well as acute rejection and delayed graft function (DGF). Overall graft survival at 1, 5, 10 and 15 years were 93%, 74%, 55% and 41%, respectively. The median graft survival was 128.4 months. Donor age, acute rejection and DGF strongly predicted the chance of graft survival. We consider that several modifiable risk factors can partially account for poorer graft survival in pediatric kidney transplant recipients. Introduction: Although the number of recipients under 12 months on the waiting-list is small, children often die before transplantation due to the limitation of size-match. To estimate the potential of donors and the need of organs from that group we investigated the situation in Germany. Methods: We reviewed the DSO-data-base for donors realized and recipients transplanted under 12 months in Germany from 2007 to 2012. We analysed the number of donors, causes of brain-death and number of organs transplanted. Results: We identified about 5 organ donors under 12 months per year. In total 27donors provided 62 grafts, mostly livers (24), hearts (20) and kidneys (17). Of 174 organs were transplanted into recipients under 12 months. Livertransplantations dominated (135), followed by heart-transplantations (33) and kidney-transplantations (5). Conclusion: Brain-death on a neonatological ICU is a rare but realistic event. When focusing on the organs donated mostly to be sized-matched more organs were transplanted than donated in Germany (despite liver-splitting). Demand for such organs exceeds the supply provided within the country. Consequently organ donation on neonatological ICUs is an very important issue. In spite of the difficult setting there should be a clear commitment of the whole staff towards organ donation. Hakan Sozen, Kibriya Fidan, Necla Buyan, Oguz Soylemezoglu, Enver Hasanoðlu, Ayd y n Dalgic Gazi University In Gazi University Transplantation Center between 1996 and 2013; out of 240 recipients; sixty one pediatric kidney transplantation were performed to fifty nine pediatric recipients ages between 4.5-17 years old (27 female, 34 male). There were 18 (30%) deceased donors and 43 (70%) living related donors. Among 61 pediatric renal transplantations, totally 12 (19.6%) surgical complications were seen. While 8 of them were early, 4 were occurred as a late complication. In the early period of transplantation, five (8%) surgical, two (3.2%) vascular and one (1.6%) urologic complications were seen. Among 5 surgical complications, there were 3(4.9%) lymphocele and 2(3.2%) bleeding. Totally 8(13%) grafts were lost in 15 years of follow-up. These are as follows: chronic allograf nephropathy in 4, BK virus nephropathy in 3 and thrombus of renal artery in 1 patient. Re-transplantation was applied to 2 patients. Total 2 recipients have died. The reasons were familiar mediterranean fever (FMF) associated multi-organ failure and traffic accident. Now, 50 patients go on their lives with normal graft functions in 2-177 months follow-up period. The overall 1, 5, 10, 15 year graft and patients survival rates were 100%, 85%, 78%, 78% and 100%, 98%, 95%, 95% respectively for all recipients. For cadaveric donors, 1, 5, 10, 15 years graft and patient survival rates were 100%, 95%, 78%, 78% and 100%, 85%, 85%, 85% respectively. Our datas in 15 years time have got advantages in comparison to datas of international developed centers. Renal transplantation is accepted as the most suitable treatment in our center for end stage renal disease patients in all age groups and it is applied successfully. Background: Early introduction of everolimus (EVR) may allow to reduce the exposure to calcineurin inhibitors and steroids, without loss of efficacy, in paediatric renal transplant recipients (pRTxR). Methods: This is a 12-month study with a 24-month additional safety followup in pRTxR (1 to <18 years). After a 4-6 weeks run-in period post-Tx, pRTxR on tacrolimus (TAC) + mycophenolate mofetil + steroids will be randomised to either continue the regimen or start EVR + reduced TAC with steroid withdrawal at month 6 (figure). Co-primary objectives at month 12 are to estimate rate of composite efficacy failure events (biopsy proven acute rejection, graft loss or death) and to evaluate renal function. Approximately 106 pRTxR will be randomised in 2012 and 2013 across 30 sites in 13 countries. Results: Month 12 results are expected in Q4 2014. Conclusions: This study will evaluate the benefits of early introduction of EVR to reduce TAC exposure and withdraw steroids at month 6 in pRTxR. Background: Maintaining normothermia essential during liver transplant. Serious adverse outcomes from perioperative hypothermia are well documented. Objective: Evaluation the core temperature changes during graft warm ischemia and reperfusion periods in adult and pediatric cases. Method: 30recipients, (adult n = 15and pediatric n = 15) enrolled in this study. Nasopharyngeal core temperature (NCT) was recorded at the following points: 5:30 min after induction of anesthesia (temp1 and 2), the Lowest NCT during dissection phase(temp3),the Lowest NCT during the anhepatic phase and before implantation of the graft (temp4), Lowest NCT during warm ischemia (putting the graft at its bed till reperfusion) (temp5),also at 5 (temp6),and 30 min (temp7 after reperfusion, then before the end of surgery(temp8). Results: Significant decrease in core temperature during the anhepatic phase (temp4), warm ischemia time (temp5), 5 min after reperfusion (temp6) and 30 min after reperfusion (temp7) CLKT is a treatment modality in pediatric patients with severe liver and kidney disease. Simultaneous CLKT from living donors (LD) is entirely a different procedure bringing other issues specific to living donation. Most of the transplantations are performed from two different LDs simultaneously. This is a major surgery in children with extremely difficult technique requiring high level of expertise in order to perform two LD procedures on two adults and a major LD transplantation of two adult organs in a sick child. Six LD CLKT were performed in children between 2007 and 2012 in our department. Patient demographics are given in Table 1 . Case 3 had roux en y anastomotic bleeding requiring surgical exploration. Greft nephrectomy was performed due to greft thrombosis arising secondary to severe hypovolemia from vascular leak syndrome. She died on POD43 secondary to sepsis. Case 5 had bile leakage from roux en y anastomosis requiring surgical exploration twice. He died on POD29 secondary to sepsis. Case 1 required surgical exploration due to abdominal hematoma. He had bile duct stenosis treated with percutanous dilatation in the long-term. Case 2 required surgical exploration due to abdominal hematoma. Case 4 had de novo HUS in the transplanted kidney treated with plasmapheresis and medication switch from Tacrolimus to Sirolimus. 4 cases had good liver function with mean serum cr level of 0.4 mg/dl. In midst of cadaveric organ shortage, simultaneous combined LKT from a LD may be a reasonable therapeutic alternative in children with severe liver and kidney disease. One should remember that this is a major procedure with considerable mortality and morbidity requiring high level of expertise. Backgrounds: Nowadays, the main focus of pediatricians, pediatric transplant hepatologists and transplant surgeons taking care of children with endstage liver disease is not only to find a way to get these children transplanted, but is the long-term follow-up with prevention of immunosuppression-related complications, adherence and promotion of a growth as normal as possible. We aimed to determine whether parental education level, social and economic status in a cohort of pediatric liver transplant recipients in the south of Italy were potential predictors of graft and children survival. Materials and methods: This retrospective study included 116 consecutive liver transplant recipients younger than 18 years at ISMETT between 2001 and 2012. Donor gender and age, extended criteria donors, recipient age, gender, primary aetiology, retransplantation, Pediatric end-stage liver disease score, co-morbidities, patient growth and development assessed on the basis of clinical follow-up, highest parental level of education achieved, social and economic status were collected and analyzed. Results: Kaplan-Meier analysis measured by parental higher education level, social and economic status showed a better survival rate without significative associations, for patients (p = 0.07, p = 0.12, p = 0.31), and graft survival (p = 0.23, p = 0.22, p = 0.76), respectively. After adjusting for co-variables, results of the multivariate Cox regression analyses confirmed that parental educational level or socioeconomic status are not independent or significant predictors of patients and graft survival. Conclusion: ISMETT optimization of adherence with the pediatric transplant medical and nursing management enhanced the chances for a successful outcome from liver transplantation in children, reducing the impact of the lack of access to quality health care. Prospective clinical studies are necessary to fully identify the impact of parental connection between the care of the child and his/ her family. Hakan Sozen 1 , Kibriya Fidan 2 , Utku Y y lmaz 3 , Necla Buyan 2 , Oguz Soylemezoglu 2 , Sevcan Bakkaloðlu 2 , Enver Hasanoglu 2 1 Gazi University; 2 Gazi University Pediatric Nephrology; 3 Gazi University Transplantation Renal transplantation in patients with lower urinary tract dysfunction (LUTD) of various origins is a challenging issue in the field of pediatric transplantation. Aim: To evaluate patient and graft survivals as well as the risks of the surgery and immunosuppressive therapy pediatric patients of LUTD at Gazi University Transplantation Center. Patients and methods: Among 61 pediatric transplantation recipients since 1996, LUTD was displayed in 6 (9.8%) pediatric recipients. The cause of urologic disorders were as follows; PUV (n = 4), PUV+neurogenic bladder (n = 1) meningiomyocele+neurogenic bladder (n = 1). Clean intermittent catheterization (CIC) was needed in two patients to empty the bladder. Three out of three patients received kidneys from cadaveric and three from living donors. All patients were received calcineurine-based triple immunosuppressive therapy. None of patients had pre-transplantation augmentation. Only one patient whom has VUR + neurogenic bladder had augmentation operation during transplantation surgery. Haberal's corner saving suture technique was used with ureteral stenting for ureteroneocystostomy anastomosis. Results: The mean age at transplantation was 10.7 AE 3.8 years old (4-15 years old). The median follow-up after transplantation was 53.7 months (1.8 to 168 months). Two patients who have neurogenic urine bladder had recurrent symptomatic curable urinary tract infections. Two out of 6 recipients had BK virus nephropathy (BKVN). One out of two graft was lost due to BKVN and other one has normal graft functions. None of the recipient had urologic or surgical complications after transplantation. No patients died after transplantation during follow-up. Three grafts were lost (BKVN, immunologic, traffic accident), but remaining patients are doing well with mean creatinine 1.5 AE 1.1 mg/dl (median 1.2 mg/dl). Conclusion: Renal transplantation is a safe and effe. Rainer Ganschow 1 , Lutz Fischer 1 , Giuliano Torre 2 , Robert Langer 3 , Bo-G € oran Ericzon 4 , Andrea Brunati 5 , Carole Sips 6 , Alison Balfour 6 , Guido Junge 6 1 University Medical Centre Hamburg-Eppendorf, Hamburg, Germany; 2 Bambino Ges u Children's Hospital, Rome, Italy; 3 Department of Transplantation and Surgery, Semmelweis University, Budapest, Hungary; 4 Karolinska University Hospital, Stockholm, Sweden; 5 Liver Transplantation centre, San Giovanni Battista Hospital, University of Turin, Italy; 6 Novartis Pharma AG, Basel, Switzerland Background: Nephrotoxicity due to calcineurin inhibitors (CNIs; cyclosporine and tacrolimus) is a major concern in paediatric liver transplant (LTx) recipients (pLTxR). Reducing CNI dosing to ameliorate renal function in pLTxR is an important goal. Methods: H2305 is a 24-month (mo) study with a target to enrol 75 pLTxR aged ≥1 month and <18 years with a body weight >5 kg. Eligible patients will start everolimus (EVR) with reduced CNI between mo1 and mo6 post-LTx and continue treatment for 24 month (Figure) . The primary objective is to assess the change in renal function (Schwartz formula) from start of EVR to month 12. Other objectives are to assess the rate of efficacy failure events (treated Background: Organ shortage resulting in delisting and mortality on the waiting list due to deterioration of patients condition remains a challenge; more exaggerated in pediatric patients. The option of living donor liver transplantation, size reduction of an adult cadaveric liver or the use of segments was implemented to overcome the size mismatch in pediatric recipients. However, the remaining liver was discarded, which led to donor organ shift from adults to children. Split liver transplantation allowed the whole liver to be divided into two allografts; hence, the total number of grafts was increased. Patients/methods: We report two ex situ and two in situ split liver transplantation performed in at KFSH & RC in Riyadh, Saudi Arabia. Between May 2011 till March 2013, four livers harvested from heart beating hemodynamically stable brain dead donors. Two ex situ and two in situ splits were performed. Four adult patients received an extended right grafts and three children received four left lateral lobes (one child required a re transplant for hepatic artery thrombosis). The demographic data and diagnoses for both recipients and donors were described including: the donor liver graft condition, cold, warm and total ischemia time, the operative technique, the aetiology of the liver disease in the recipients, ICU and hospital stay, morbidity and complications, patient and graft survival. Results: Three adult females and one male with ESLD received an extended right lobe graft. Two female and one male children received four left lateral lobe grafts. We report 75% graft & patient survival in the adult population and 100% patient survival with 75% graft survival in the pediatric age group. No major events were encountered during their hospital stay; apart from one adult mortality due to pulmonary embolism. Conclusion: Split liver transplantation can be performed for non-urgent recipients with ESLD with good results. Increasing the organ pool for pediatric recipients, without affecting the adult recipient outcome. Silvie Bloudı´cková-Rajnochová 1 , Ond r ej Viklick y 1 , Tom a s Seeman 2 1 Institute for Clinical and Experimental Medicine; 2 Motol Univesity Hospital Background: Transfer of pediatric kidney transplant recipients to adult care is considered as a risk factor of graft failure because of higher incidence of rejections and problematic compliance with therapy. The goal of our study is to evaluate kidney graft survival after transition from the only Czech pediatric transplant center (Motol University Hospital) to adult transplant center in Institute for Clinical and Experimental Medicine (IKEM). Methods: We retrospectively analyzed a group of 64 pediatric kidney transplant recipients, who underwent kidney transplant surgery in Motol University Hospital between 1987 and 2006, and after reaching adulthood were transitioned to adult transplant center in IKEM. The complete laboratory and clinical data over the period of 12 month before and 36 months after transition were obtained in 42 (65.6%) patients. Results: At the time of transplantation, the mean age of patients was 13.2 years (6-18 years), three patients underwent two kidney transplantations. At the time of transition, the mean age of patients was 20.6 years (17-24 years). In nine patients (21.4%) the renal graft failed during the first 36 month and in 6 patients (14.2%) during the first 12 months after transition. In analyzed period, we observed graft failure in 7/13 (53.8%) patients with serum creatinine levels above 200 lM and in 3/29 (10.3%) patients with serum creatinine levels below 200 lm/l at the time of transfer. Chronic rejection was the main cause of graft failure with the mean graft survival of 12.5 years (6-18 years). The non-compliance with therapy was clearly demonstrated in 3 (7.1%) patients. In one patient, non-compliance led to graft failure during 5 months after transition. Conclusion: The transfer of pediatric kidney transplant recipients to adult care is one of risk factors of graft failure. Regarding the specific attributes of this group of patients, the transition process should comprise both special medical and psychosocial care. Introduction: Acute antibody-mediated rejections (aAMR) after renal transplantation are defined as rapidly deteriorating graft function, donor-specific antibodies and characteristic histology. Anti-rejection strategies among children with aAMR are lacking. Aim of the work: To evaluate pediatric renal transplant recipients who experienced at least one episode of antibody mediated rejection and received different modalities of treatment protocols. Patients and methods: Out of 105 pediatric renal transplants performed in Hamed Al-Essa organ transplant center, 21(20%) experienced at least one episode of biopsy proven antibody mediated rejection. Most of these episodes occurred within 1st two years after their 1st renal transplantation (20 AE 2.6 months). Pre-transplant cross matches were negative. Basic immunosuppression comprised Tacrolimus, MMF and steroids. The diagnosis was made according to Banff classification 2007 and cases were subdivided into 2 groups: aAMR (n = 10) and mixed rejection (n = 10). Results: Mean patients age was 12.5 AE 4.9 and13.5 AE 2.3 in both groups respectively and both were matched regarding donor source and age, original kidney disease, HLA mismatches, type of immunosuppression, basal graft function and hemogram. The majority of our patients received PE, IVIG and rituximab, however we found that graft outcome was significantly better only in those who received rituximab (p = 0.002). On the other hand, graft survival was significantly worse in those who received lymphocyte depleting agents (p = 0.036).Graft function-at last follow up-in both groups were comparable as measured by serum creatinine (132 AE 33 vs. 143 AE 65, p = 0.88 respectively). Patients with mixed rejection received significantly more steroid pulses but without significant impact on graft survival. Patient survival was comparable. Conclusion: Combined therapy of IVIG, plasmapheresis and rituximab is effective in the treatment of aAMR in pediatric renal transplants. Background: The effect of paricalcitol on renal ischemia-reperfusion injury (IRI) and its mechanism has not been investigated. Methods. Paricalcitol was administered to mice 24 h before IRI. Bilateral kidneys were subjected to 23 min of ischemia, and mice were killed 72 h after IRI. Results: Paricalcitol improved renal function, tubular necrosis and apoptotic cell death in IRI-mice kidneys. The infiltration of inflammatory cells, and production of proinflammatory cytokine were reduced in paricalcitol-treated mice with IRI. Paricalcitol upregulated cyclooxygenase (COX)-2 expression and prostaglandine E2 (PGE2) synthesis in postischemic renal tissue. The cotreatment of selective COX-2 inhibitor with paricalcitol restored functional injury and tubular necrosis in paricalcitol-treated mice with IRI. Conclusions: Our study demonstrates that paricalcitol pretreatment prevents renal inflammation in IRI, and upregulation of COX-2 and PGE2 is one of the protective mechanism of paricalcitol. Background: There is growing evidence of the roles of B-cell after Ischemiareperfusion (IRI) renal injury, and we investigated pretreatment effects with rituximab against subsequent IRI injury in mice kidney. Methods. Rituximab (10 mg/kg) was administered to mice 7 days before IRI injury by clamping both renal pedicles for 22 min. Results: Rituximab decreased serum creatinine and tubular necrosis scores in post-ischemic kidney. The infiltration of CD19+ B-cells and CD40+ tubular cells were decreased in the rituximab-treated kidneys, which was accompanied with decreased production of interleukin (IL)-12. Rituximab inhibited the infiltration of T-cells and macrophages, and decreased production of IL-1b, interferon-c and tumor necrosis factor-a in mice kidney with IRI. Coclusion. Rituximab has a protective effect on renal IRI and that this effect is associated with reduced antigen-presentation and decreased activation of inflammatory cytokine associated with Th1-pathway. Alexey Zulkarnaev, Andrey Vatazin M.F Vladimirsky Moscow Regional Research Clinical Institute Background: Kidney transplant always has ischemic injury. Ischemic injury causes the release of many mediators. One of the inflammatory mediators is IL-6. We have studied the dynamics of its concentration in the early postoperative period after kidney transplantation, and the factors that influence on it. Methods/materials: The study included 28 patients. The selected time points: T0before surgery, T1 -10-15 min after reperfusion, T2 -4-6 h after reperfusion; T3in 12-14 h after reperfusion; T4 day after reperfusion. Results: Found that most of the patients showed a significant increase in IL-6 levels. We have identified four groups of patients, depending on the shape of the concentration curve of IL-6. Though the baseline, all patients had normal levels of IL-6 -<10 pg/ml. Conclusion: The study of IL-6 profile and the role of cytokines in the postoperative period in recipients of renal graft may identify new targets for specific therapy. Numerous steatotic livers are discarded for transplantation because of their poor tolerance to ischemia/reperfusion. Toll-like receptor 4 (TLR4), signaling is mediated by two distinct intracellular adaptor proteins: myeloid differentiation factor 88 (MyD88) and TIR domain-containing-adaptor inducing IFNb (TRIF); both activate intracelular signaling cascades that ultimately trigger an inflammatory response. Herein we evaluated the role of TLR4 in steatotic liver grafts under cold ischemia. We also investigated whether TLR4 pathway could be regulated by PPARc in steatotic liver transplantation. This was based in our previous results indicating the benefits of PPARc agonists in steatotic liver grafts and the changes in TLR4 expression induced by PPARc regulators in non-steatotic livers undergoing warm ischemia. Methods: Steatotic liver transplantation was induced in Zucker rats. PPARc and TLR4 were altered pharmacologically. Results: The PPARc antagonist treatment protected steatotic livers grafts and this was associated with higher TLR4 levels than those observed in the Transplantation group. Protein levels of MyD88 were unchanged. A pattern similar to that observed for TLR4 protein levels were observed for TRIF protein levels. When TLR4 action was inhibited, PPARc antagonists did not protect steatotic liver grafts. TLR4 agonist treatment reduced damage in steatotic liver grafts. The benefits of TLR4 induction might be not explained by changes in the mechanisms potentially involved in the vulnerability of steatotic liver to I/R damage including neutrophil accumulation, TNF, IL-1 and IL-6 levels. Background: We previously reported the stronger ability of modified UW with 30%-D2O (Dsol) than UW, in rat hearts. The present study was designed to assess the ability of Dsol against hepatic CP, and combination effect of hydrogen gas (H2) against reperfusion injury. Methods: Livers were subjected to 48-h CP in UW or Dsol, and were reperfused with or without H2, using isolated perfusion apparatus for 90 min. Groups; UW, Dsol, UW+H2, and Dsol+H2. Perfusion kinetics, liver functions and injury, and cytoskeletal integrity were assessed. Results: The highest portal resistance, LDH leakage, 8-OHdG and endothelin-1 staining, cytoskeletal degradation (Fodrin, dephosphorylated-Slingshot), and the least bile production and oxygen consumption were shown in UW group, whereas significantly improved in UW+H2 and Dsol groups. Further drastic improvement was shown in Dsol+H2 group. Background: Ischemia reperfusion injury (IRI) remains a critical issue in transplantation. C1 inhibitor (C1INH) regulates complement and contact system activation, but also has protease-independent anti-inflammatory functions. Methods/materials: We investigated functional outcomes using a recombinant human C1INH (rhC1INH) in a preclinical pig model of kidney autotransplantation (n = 7). Results: Serum creatinine (Fig 1) measurements showed that while Vehicle animals could never recover proper kidney function, rhC1INH animals recovered quickly, reaching pretransplant levels by D11 (p < 0.05 AUC comparison). In regards to chronic graft outcome (Fig 2) rhC1INH treatment prevented chronic loss of function and fibrosis development compared to vehicle (p < 0.05). Further data on modulation of complement activation and markers of inflammation will be presented. Conclusion: RhC1INH offers a high degree of protection against IRI and preserves graft integrity, significantly improving outcomes. Background: We investigated the Unfolded Protein Response (UPR) in Ischemia-reperfusion injury (IRI), a critical issue in transplantation. Material and methods: In vitro evaluation of cold storage (24 h of hypoxia in UW at 4°C) and reperfusion (6 h in culture medium at 37°C) in human aortic endothelial cells. Interconnections between cell survival and UPR were studied by fluorometry, RT-qPCR and Western-Blot (WB). Results: RT-qPCR analysis showed that UPR pathways are activated during hypoxia, proportionally to duration. We thus targeted the UPR during hypoxia (IRE1a or ATF6 inhibition and PERK activation) and significantly improved cell survival. Moreover,WB analysis showed that IRE1a inhibition fostered an early activation of the PERK pathway. siRNA modulation and protective mechanisms will be discussed. Conclusion: PERK appears to be the main protective pathway during cold storage and could represent an important therapeutic target towards improving organ preservation. , a subpopulation of multipotent cells identified in amniotic fluid, are known to secrete growth factors and anti inflammatory cytokines. We expect that AFSC could limit IRI consequences in renal graft. Methods/materials: To determine the efficiency and safety of AFSC infusion in a preclinical porcine model of renal auto-transplantation mimicking deceased after cardiac arrest donor conditions and specifically targeting IRI, we injected autologous AFSC in renal artery 6 days after transplantation. Results: AFSC injection improved graft viability with full renal function recovery and abrogated fibrosis development up to 3 months. The reduction of tubular atrophy and proteinuria observed in AFSC treatment group was associated with a drastic decrease of inflammatory cell infiltration in graft. The strong proof of concept supported by this work could be the first step before evaluation of AFSC-based therapies in human kidney transplantation. (i) For a clinically relevant description of transplantation renal IR injury, here we validate a quantitative model of cortical (CTX) oxygenation (O 2 ). (ii) NetLogo(R) agent-based platform is used. CTX (10 lm thick) consists in 1024 patches (100 lm 2 ) able to diffuse and/or consume O 2 (vascul./epith./lumin./interst.). Values are taken within reported range (eg. 6% interstitium). Model is fed for blood (Hb 15 g/dl, 40-70 mmHg O 2 , dissolved and Hb-bound, Ht 0.45, FF 0.3) via transverse peritubular capillaries PTC (20-70 ml/min); tubules flow rate 10-50 ml/min. Inputs: RBF (2-10 ml/min) and efferent arteriole O 2 (40-60 mmHg); consumption M(O 2 ) = 2-10 mM/min; output: mean PO 2 . (iii) At steady-state, model is sensitive to diffusion constant and consumption. Model reproduces CTX PO 2 values of both normo (38 vs. 42 mmHg) and hypertensive (32 vs. 31 mmHg) rats by Welch et al. 2001. (iv) Human and pig renal IR injury will be next addressed via the influence of oxygenation on inflammatory and fibrogenic processes. Aliaksei Shcherba 1 , Andrew Minou 1 , Evgeni Santotski 1 , Sergei Korotkov 1 , Olga Lebedz 2 , Alexander Dzyadzko 1 , Oleg Rumo 1 1 RSPC for Tissue and Organ Transplantation; 2 Minsk City Pathology Bureau Hypothermic machine perfusion (HMP) is a promising field in liver transplantation (Guarrera JV et al. Liver Transplantation. 2012; S31-3) . Objective: To compare the results of HMP and cold static storage (CSS) with HTK in the same donor organ. Methods: Five discarded donor livers were submitted for the study. The mean steatosis rate was 30% (20-45). Organs were procured with standard technique using 10 l of HTK. After transporting to the center HMP of RL was performed through a cannula in the main p.v. with biopump (Medtronic) and free venous outflow. Volume of perfusate was 2000 ml. No active oxygenation was used. CSS of left lobe (LL) was achieved by clamping of the left portal vein (p.v.). P.V. pressure was monitored (Draeger Infinity Delta XL) in the inflow line and maintained at 7-9 mmHg. The flow was maintained at 25-30 ml/100 g of liver parenchyma. Cooling was achieved with ice packing of the liver and lines. Temperature was monitored (Philips Intelli Vye MP 70) with a probe inserted in hepatic veins. Pre and postperfusion effluents and serial tissue samples from both lobes were taken. Results: HMP was started since 4.6 AE 1.5 h and lasted till 15.1 AE 0.8 h after procurement. Mean temperature dropped from initial 8.1-5°C after 2 h of HMP but increased to 7.6°C after 11 h. AST, ALT, LDH levels were decreased in RL compared to LL post-perfusion effluent, but only AST reached statistical significance (2430 vs. 3940). PH of perfusate changed from 6.62 at 3 h to 6.48 at 8 h of HMP and cLac of perfusate changed from 7.5 at 3 h to 15.7 at 8 h of HMP. A trend toward lower mean necrosis rate was found in HMP compared to CSS lobe at 8 and 11 h of perfusion, 1.6% and 6.3% vs. 5% and 12.3% correspondingly. Conclusion: HMP with HTK seems to be safe in terms of liver function tests and histology. Background: Cold storage of livers for transplantation requires the flush-out of blood with a chilled preservation fluid before storage on ice. Our aim was to appraise the evidence for the efficacy of available preservation solutions. Methods: A systematic literature search was performed using MEDLINE, EMBASE, the Cochrane Library, the Transplant Library, and the International Clinical Trials Registry Platform. Inclusion criteria specified any Randomised Controlled Trial (RCT) of preservation solutions for liver allografts from deceased donors. Studies were assessed for methodological quality. Outcomes analysed were: early dysfunction, primary non-function, re-transplantation rate, patient survival, graft survival, and peak serum ALT in the first week. Fixed effects (FEM) were used where appropriate. Summary effects are presented as Relative Risk (RR) for binary outcomes and Relative Log Survival (RLS) for survival outcomes. Both are presented with 95% confidence intervals (95%CI). Results: 3364 unique abstracts were retrieved and from these, 16 RCTs met the full inclusion criteria (1620 liver transplants). The majority of trials were of poor quality. Comparing University of Wisconsin Solution (UW) with Celsior Solution, there was no evidence of a difference in early dysfunction (FEM RR = 1.08, 95%CI = 0.63-1.08, p = 0.77), in patient survival (FEM, RLS = 0.86, 95%CI = 0.58-1.28, p = 0.46) or graft loss (FEM, RLS = 0.85, 95%CI = 0.59-1.21, p = 0.39). No other significant differences were demonstrated between Celsior Solution, Histidine-Tryptophan-Ketoglutarate Solution (HTK) and UW in terms of the outcomes of interest. Conclusions: The best available studies show no evidence for a superiority of Celsior, HTK or UW Solutions. The quality of available studies also means that we have only moderate evidence of equivalence. An adequately powered and well conducted RCT is required to establish the most cost effective solution for liver preservation. Introduction: Renal ischemia-reperfusion injury (IRI) is inevitable during kidney transplantation leading to oxidative stress and inflammation and is a risk factor for delayed graft function, rejection and transplant loss. Our previous research showed protection of preoperative fasting against IRI in young-lean male mice. Because of heterogeneity and (co)morbidities in patients, we investigated the effects of fasting on oxidative stress induced by IRI in mice of another age, sex, bodyweight and genetic background. Methods: Male and female F1-FVB/C57BL6-hybrid mice, mean age 73 weeks and weight 47.4 respectively 47.1 grams, were randomized in preoperative normal food or 72 h fasting. Induction of renal IRI was performed by clamping both renal pedicles: in males 37 min, in females 60 min. Wellbeing, bodyweight, kidney function and survival of the animals were monitored until day 28 postoperatively. Results: Preoperative fasting improved survival after renal IRI in both sexes compared with normal fed mice. All normal fed males died or were sacrificed because of morbidity indicative of irreversible kidney failure, whereas 88% of the fasted males survived. Of the ad libitum fed females, 82% died or had to be sacrificed, whereas 70% fasted mice survived. Both fasted groups had a better kidney function shown by lower serum urea levels after IRI. Histopathology showed less necrosis and more regeneration in kidneys from fasted mice. In the first week after IRI, bodyweight declined followed by recovery in the weeks thereafter. Conclusions: Similar to young healthy male mice, preoperative fasting protects against renal IRI in male and female aged obese mice. These findings suggest a general protective response of dietary restriction against renal IRI regardless of age, sex, bodyweight and genetic background. Therefore, dietary restriction could be a non-invasive intervention inducing increased oxidative stress resistance in older and obese patients as well. MEASUREMENT OF RENOVASCULAR CIRCULATING VOLUME DURING HYPOTHERMIC ORGAN PERFUSION Eva de Vries 1 , Tim van Smaalen 2 , Jorine Boer 3 , Pieter Hoogland 2 , Nikolai Krivitski 4 , Maarten Snoeijs 5 , Ernest van Heurn 2 1 Medisch Centrum Alkmaar; 2 Maastricht University Medical Center; 3 University Medical Center Nijmegen; 4 Transonic Systems Inc.; 5 Atrium Medisch Centrum Heerlen Background: Kidney donation after cardiac death leads to vascular damage as a result of warm ischemia, affecting renovascular circulating volume. Novel ultrasound dilution techniques may be used to measure renovascular circulating volumes during hypothermic machine perfusion of donor kidneys. Methods: Renovascular circulating volumes of machine perfused porcine kidneys were repeatedly measured by ultrasound dilution at different perfusion pressures (30, 40, 50, and 60 mmHg), durations of perfusion (1 and 24 h) and warm ischemia times (15 and 45 min). Validity of ultrasound dilution was assessed by comparing volume changes after clamping of renal artery branches. Results: Repeatability of ultrasound dilution measurements of renovascular circulating volumes was good (mean coefficient of variation: 7.6%). Renovascular circulating volumes significantly increased with higher perfusion pressures, remained constant over time, and significantly decreased with longer warm ischemia times. Changes in ultrasound dilution measurements after renal artery branch clamping did not correlate with changes in actual perfused volumes. Conclusions: Ultrasound dilution is a reproducible method to assess renovascular circulating volumes in machine perfused kidneys, which is susceptible to changes in warm ischemia times. Future studies should evaluate the value of renovascular volume in pretransplantation kidney viability testing. the perfusion liquid. Then, kidneys were transplanted and creatininemia assessment was performed. Results: MP preservation with KPS-1 alone induced an increase in extracellular lactate and ASAT levels in liquid perfusion. In HEMO2life â treated groups, 2 g/l dose reduced lactate release and 0.5 g/l dose level led to about 3 fold reduction in ASAT release after 24 h of preservation. A benefit was also observed in 1 g/l treated group in comparison to MP control group with a weaker creatininemia peak (about 1100 vs. 400 lM respectively) and a faster return to pre-surgery values. Conclusion: This pilot study reported that HEMO2life â supplementation protected kidney cells during MP preservation.; Creatininemia follow-up in Ctrl MP and MP+ HEMO2life â groups. Background: The Italian legislation provides a mandatory 20-min no-touch period after cardiac arrest before organ retrieval in Donor after Circulatory Death (DCD); for this reason doubts on viability of these organs discouraged Italian surgeons to perform DCD transplants. However, in 2008 we started the "Alba" DCD programme using the most performing tools for preservation of these organs including normothermic regional perfusion (NRP) and pulsatile machine perfusion. Methods/materials: Initial experience using only NRP and cold storage (CS) leaded to a transplantation of 4 kidneys from 3 donors, and 2 of them are still functioning grafts with an acceptable 1-month SCr (2.6 AE 0.1). After the inclusion of machine perfusion (MP), 10 kidneys were transplanted from 7 donors. Histology and cold ischemia time (15.7 vs. 15.9 h, NS), were similar between the CS and MP kidneys, although significantly the longer cold ischemia time (CIT) reached 23 h in MP group. Results: From the 4 CS kidneys, 2 showed DGF and 1 PNF and 1 graft loss due to renal vein thrombosis (IX day postop), while in the MP group 3 didn't show DGF, no PNF was observed and DGF time was significantly shorter (9.7 vs. 20.5 days, p < 0.05). CS kidneys showed extremely difficult reperfusion in all cases when compared to MP kidneys. MP kidneys demonstrated better function (Scr mg/dl) at 1 month (2.5 AE 1.16 vs. 4.4 AE 2.55) and improved at 3 months (1.65 AE 0.61 vs. 3.2 AE 1.98). Out of 10 MP kidneys only 1 kidney was discarded due to high resistances during MP. Conclusion: DCD kidney transplantation is feasible even after a 20-min notouch period with the use of pulsatile machine perfusion, increasing the number of transplants with good graft function. MP gives us additional information of the quality of the organs that allows a more efficient use for transplantation. Introduction: The shortage of available organs is a major problem for a wider access to kidney transplant. Recently Non Hearth Beating Donors (NHBD) have been proposed as a new resource and proven clinically effective. The Italian law requires a prolonged "no touch period" to declare one dead. Thus NHBDs come with an abnormally long warm ischemia. Graft reconditioning is mandatory in such situation. IGL-I is an effective rinse solution to perfuse damaged organs. Several studies have demonstrated that measurement of flow and trend of resistance are reliable parameters to predict the graft outcome prior to perform the transplant. Methods: Of 21 male Lewis rats were stratified into three groups and euthanized to collect the kidneys under non heart beating status (Table 1 shows the induced ischemia and solutions used). The grafts were perfused on the bench by a hydrostatic device fixed at 40 mmHg, with real time evaluation of renal flow and resistance. Results: Data were analyzed by ANOVA. As expected, Group 1 had a much better performance then group 2 and 3. However, the use of IGL-I (Group 3) was beneficial, with a significantly better flow and resistance than in Group 2 (ANOVA, p < 0.05). These data were confirmed at histologic evaluation that showed less thrombosis and glomerular sclerosis in kidney perfused with IGL-1, while tubular necrosis was similar in Group 2 and 3. Conclusions: While kidneys from NHBD show a significant damage compared to HBD, new approaches to the treatment of ischemic damage demonstrate a promise of savage for a pool of grafts. Modern solutions like IGL-I are effective. Further studies will demonstrate the long-term beneficial effect of reconditioning and the overall survival of such graft after KTx. Brain dead-derived kidney grafts have inferior transplantation outcomes compared to living donated kidneys. The protective heat shock proteins (HSP) are known to be up-regulated, but at the end of the brain death period. To reduce the brain death-related kidney injury, we want to increase the Hsp72 expression at the start of brain death. We investigated whether geranylgeranylacetone (GGA), an Hsp72 inducer, can reduce the pro-inflammatory changes and improve kidney donor quality in an in vivo brain death rat model. Male F344 rats (275-300 g, n = 15) underwent slow induction of brain death and were kept brain dead for 4 h. We administered GGA (400 mg/kg orally) or a saline vehicle 20 h and 1 h prior to brain death induction. Shamoperated animals (n = 14) received the same treatment. At the moment of organ retrieval, the expression of Hsp72 is not increased by GGA. However, kidney interleukin-6 mRNA levels in GGA pre-treated brain dead rats were lower compared to saline-treated controls. Systemic ASAT levels were also reduced by GGA, indicating decreased inflammation. These results suggest that GGA reduces pro-inflammation during the brain death period, despite the unchanged expression of Hsp72. To further explore the effects of GGA on HSP expression, we want to assess expression of HSF-1 and other stress-induced HSP: Hsp90, Hsp32. Background: The cornerstone of cold ischemic storage of donor hearts is immediate electro-mechanical arrest of the donor heart with a preservation solution and maintenance of hypothermia. The current practice of cold storage using an "Igloo" cooler relies on crushed ice to maintain hypothermia. However, clinical experience suggests that these storage temperatures may be highly unpredictable and some donor hearts become frozen solid. These temperature uncertainties are sub-optimal and potentially detrimental on the myocardium due to focal super cooling. This study assesses the temperature profile of donor hearts stored in the Sherpa Pak Cardiac Transport System (CTS) and those stored in the conventional Igloo with ice. Methods/materials: The Paragonix Sherpa Pak TM CTS is a single-use device that utilizes cold chain shipping technology and FDA cleared organ cold storage solutions. This portable device weighs 15 kg and is designed to transport donor hearts with transport times of up to 4 h. In one set of test, temperature profiles (n = 3 runs) were recorded for the Paragonix Sherpa Pak TM CTS. In a second test, a 500 g pig heart was placed in plastic bags with 2 l of storage solution in an igloo with 15 kg of crushed ice, and a second 500 g pig heart was placed inside the Sherpa Pak TM CTS. Two temperature probes (ESCORT iMiniPlus) were placed inside the left ventricle and at the cardiac apex. Temperatures were monitored at 5 min. intervals for 12 h. Results: Temperature performance runs demonstrated that the Sherpa Pak TM CTS was able to maintain stable cardiac temperatures between 4 and 8°C for over 12 h. Comparable Igloo storage results demonstrated temperatures near and below 0°C following 2 h of static storage. Conclusion: The Sherpa Pak TM CTS provides more reliably and clinically acceptable storage temperature for the donor heart compared with conventional storage using an "igloo" cooler and ice. reperfusion injury (IRI). ROS cause impaired function or death of cells through direct damage to biomolecules or the activation of intracellular signaling pathways. Moreover, they play an important part in the amplification of damage through e.g. inflammasome activation. The use of antioxidants provided limited therapeutic benefit in the clinical setting and thus novel strategies for avoiding early ischemia-reperfusion injury (IRI) are essential. Ischemia and in particular also early reperfusion are linked to the activation of intracellular signaling pathways, whose contribution to damage progression is only partially understood. In our work we focused on preventing ROS-induced damage by exploiting intracellular signaling pathways. Methods/materials: Experimental models used included established and newly derived cell lines obtained from genetically altered animals and kidney clamping in the rat. As stress stimuli we analysed ischemia/reperfusion, hypoxia/reoxygenation, pro-oxidant treatment and growth factor abrogation. Molecular, biochemical, imaging and histological assays were used to quantify damage and function. Results: Our work demonstrates the activation of p38, ERK, JNK, members of the mitogen-activated protein kinase (MAPK) family, during early reperfusion/reoxygenation, when we also observe most pronounced ROS production. The activation of ERK could be linked to limiting ROS levels and cell survival, while p38 clearly increased ROS levels and enhanced cell death. Consequently inhibiting p38. Post-transplant events such as acute allograft failure and rejection are highly choreographed on the molecular level. Aim of this study was to study the molecular regulation in the human kidney allograft. We plan for ten samples of each clinical condition, currently eight have been obtained and analysed. The Affymetrix GeneChip human Gene 2.0 and miRNA 3.0 arrays for gene expression and miRNA profiling were used. An integrative bioinformatics approach was chosen to combine differentially regulated mRNA and miRNA targets before and after transplantation. Target genes were further evaluated based on their functional annotation. miRNA target prediction was verified by experimental data. Allografts with postischemic non-function exhibited a distinct molecular pattern compare to acute rejection and protocol biopsies on the mRNA and miRNA levels. T-cell and B-cell activation (p = 0.002 and p = 0.03, respectively) before transplantation, Integrin signalling pathway (p = 0.008) after transplantation and the p53 pathway (p = 0.02) and the Ras pathway (p = 0.04) were associated with the development of postischemic injury. These data show that distinct miRNA and mRNA signatures are associated with the development of postischemic injury. A detailed analysis of the miRNAs and target genes will be presented at the meeting. Background: Reperfusion injury after cold storage (CS) of organs is an inevitable consequence of a transplant procedure. We hypothesize that the sudden warm reperfusion after CS is detrimental for the graft. We therefore evaluated different warming-up temperatures of the organ before reperfusion in order to improve organ quality. Methods: Rat left kidneys were retrieved and stored in University of Wisconsin solution for 24 h at 4°C followed by immediate reperfusion at 38°C (control n = 4) or gradually warming-up (WU) to 10°C (n = 5), 25°C (n = 5) or 38°C (n = 5), using isolated machine perfusion. Renal function (GFR) and renal injury was assessed by isolated kidney perfusion with a modified Williams Medium E solution for a total of 90 min. Results: Compared to control, rewarming resulted in all groups in reduced AST levels in the perfusate indicating less mitochondrial injury as well as reduced LDH levels indicating cell injury. GFR at the end of the observation period was similar in all groups. Sodium reabsorption tended to be improved in WU groups. Conclusion: Gradually warming up is associated with less renal injury and better renal function indicating that reperfusion injury might be reduces. Background: Prolonged cold storage during transplantation remains a risk factor for the viability of grafts, especially when steatosis is present. Steatotic livers exhibit exacerbated endoplasmic reticulum (ER) stress that occurs in response to cold IRl. In addition, a defective liver autophagy correlates with liver damage.This study evaluated how the use of combination of additives, as melatonin (ML) and trimetazidine (TMZ) to IGL-1 preservation solution can increase the sources of AMPK and affect ER stress and autophagy. Methods: Steatotic livers were preserved for 24 h (4°C) in UW or IGL-1 solutions with or without ML(100 lM) +TMZ(10-6 M) and subjected to 2-h reperfusion (37°C). In a further group, steatotic livers preserved for 24 h in IGL-1 solution enriched with ML+ TMZ+ AraA (AMPK inhibitor) and reperfused as previously. We assessed hepatic injury (AST/ALT) and function [bile production, BSP clearance, vascular resistance], as well as oxidative stress (MDA) and nitric oxide. We also evaluated ER stress (GRP78, PERK, CHOP) and autophagy (beclin-l, ATG7, LC3B, P62). Results: Fatty livers preserved in IGL-1 enriched with ML+TMZ showed lower injury and better function compared to those preserved in IGL-1 alone. Moreover, IGL-l+MEL+TMZ induced a significant decrease in ER stress after reperfusion. This was consistent with a major activation of autophagic parameters and AMPK phosphorylation. The inhibition of AMPK induced an increase in ER stress and a significant reduction in autophagy. These benefits correlated with the generation of nitric oxide (through constitutive e-NOS activation) and the prevention of oxidative stress. Conclusion: The addition of ML and TMZ to IGL-1 preservation solution improved steatotic liver graft preservation, through AMPK activation which reduces ER stress and increases autophagy. Background: Ischemia-reperfusion (IR) injury and cyclosporine A (CsA), mainstay immunosuppressant, nephrotoxicity are unavoidable in kidney transplantation affecting allograft survival. In this study, a novel tissue protective peptide, helix B-surface peptide (HBSP) derived from erythropoietin, was hypothesized to eliminate IR and CsA induced renal injury in a rat model. Methods: The right kidney was subjected 45 min ischemia and followed by 2week reperfusion with the left nephrectomy. HBSP 8 nmol/kg/d was administered daily after reperfusion, together with or without CsA 25 mg/kg/d. The effects of HBSP on IR and/or CsA induced tubulointerstitial damage were evaluated focusing on renal function and structure, caspase-3 activation, apoptosis and inflammation. Results: The level of blood urea nitrogen was increased by CsA, but decreased by HBSP in the IR+CsA kidneys at 1 week and 2 weeks, while the same changes were revealed in urinary protein/creatinine only at 2 weeks. The caspase-3 mRNA was also decreased by HBSP only in the IR+CsA kidneys. The number of active caspase-3+ cells, apoptotic cells and MPO+ cells was greatly reduced by HBSP in the both IR and IR+CsA groups. In addition, HBSP mainly decreased CsAincreased MPO+ cells in interstitial areas, but reduced apoptotic cells in tubular areas. The tubulointerstitial damage was gradually increased by ischemia alone, IR and CsA; but significantly ameliorated by HBSP treatment. Conclusions: It has been revealed, for the first time, that HBSP effectively improved renal function and tissue damage induced by IR and/or CsA, which might be through reducing caspase-3 synthesis and activation, apoptosis and inflammation. Background: The hypoxia inducible factor (HIF) pathway has been shown to be able to precondition organs against ischemic injury. The characterisation of HIF in deceased donor kidneys has not yet been reported on. Abstracts of the 16th Congress of the European Society for Organ Transplantation Subsequently cervical dislocation was performed and rodents exposed to 30 min of WI prior to harvesting of the left kidney. (iv) DBD model (Fischer rats): Brain death induction was performed as previously described. Kidney and liver samples were obtained after 4 h of BD. Sham procedures were performed as controls. Tissues/cells were prepared using a Ureas SDS lysis buffer. Western blots were performed using monoclonal antibodies to HIF1a (Novus Biologicals NB100-479 1:1000) and HO1 (Assay Designs OSA-111 1:1000) with B-actin as control. Results: Our results demonstrate: -HIF1a is detected in the cell culture and IRI models (Image 1). -Less HIF1a is signal detectable compared to controls in a DCD model of 30 min of WI, a HO-1 signal persists (Image 1). -A HIF1a signal is detectable following 4 h of brain death, although the results are heterogeneous in both kidney ( Figure 2 ) and liver tissues (Figure 3) . Conclusion: In DCD donors HIF1a appears to be abolished after 30 min of WI, whereas a small HO1 response persists. In DBD donors a HIF1a signal is detectable, however there is variability in expression between experimental groups. In both DCD and DBD donors up-regulation of HIF1a and its downstream protective effectors represents a novel therapeutic target target to improve the quality of kidney and liver allografts procured for transplantation. The relationship between parameters determined from kidneys before transplant and their subsequent outcome continues to be controversial with advocators for and against. We initially used machine perfusion to determine which kidneys were 'viable' and we found this useful for Maastricht II donors where the warm ischaemia was particularly protracted. However the majority of DCD's utilised now in the UK are Maastricht III where the relevance of machine perfusion characteristics are more controversial. We have reviewed the outcome of 94 single kidneys transplanted from MIII DCD's where the flow characteristics and GST perfusate levels were known at 3 h after commencing machine perfusion. Follow up data was available for these kidneys up to 7 years post transplantation. The parameters were divided into thirds (good, satisfactory and poor) and these groups compared for glomerular filtration rate, graft and recipient outcome. Findings: there was no correlation with perfusion characteristics or GST with recipient survival. However for both graft function and graft survival there was a significant correlation between flow and outcome particularly flow/mmHg-perfusion flow index (p < 0.0005). No such correlation was found with perfusate GST. In a separate analysis of PFI with donor age there was a 2 tailed correlation between the two (p < 0.01), though the correlation coefficient was only 0.154. Therefore the flow parameters which correlated with outcome for Maastricht III donor kidneys are likely to be explained by its cause namely donor age (and presumably donor hypertension) which is known to influence graft outcome. Viability assessment during the preservation period is imperative to avoid unnecessary discarding of marginal organs and maximising graft outcomes. To address this need, we have developed a novel system based on a rapidsampling microdialysis analyser that allows continuous tissue monitoring and measurement of the metabolic markers of cell damage. We report the results from our ongoing study. We aim to develop a new tool that allows for accurate organ viability assessment during preservation. Methods: Twenty-two kidneys were retrieved from cadaveric pigs, flushed and transported to the laboratory (Warm Ishaemia Time = 15 min, Static Cold Ischaemia Time = 4-5 h). 10 kidneys underwent 24 h of static cold storage (SCS); 12 underwent 10 h of hypothermic machine perfusion (HMP, Waters Medical Systems RM3). Kidneys were monitored for tissue lactate throughout by tunnelling a probe superficially into the parenchyma of the lateral cortex; online measurements of lactate concentrations were made every 60 s. Following preservation monitoring continued while tissue temperature increased passively to ambient temperature. Results: On commencement of monitoring quantifiable lactate concentrations were successfully detected within 15mins. During the initial 1.5 h lactate concentrations were similar during SCS (88.0 lM) and HMP (140.5 lM, p > 0.05). Lactate concentrations were however lower after 10 h of SCS preservation compared with HMP (77.3 vs. 266.8 lM, p < 0.01). Overall lactate levels during SCS remained low and stable during preservation while in HMP lactate increased between 1.5 and 10 h from 140.5 to 266.8 lM (p < 0.01). Warming data suggests a resilience of HMP kidneys to subsequent temperature induced ischaemia compared to SCS kidneys. Conclusion: This preliminary work provides the baseline ischaemic profile for porcine kidneys whilst validating the technique of microdialysis as a tool for organ viability assessment during preservation with potential for clinical application. Differences can be seen between the preservation methods with cortical lactate progressively increasing in HMP, while remaining stable in SCS. The data here may help elucidate why HMP is clinically superior to SCS, and allow development of further interventions to augment these benefits. A The gold standard perfusate for renal hypothermic machine perfusion is University of Wisconsin solution (UW). Adenocaine â (AL) is a relatively low-cost novel adenosine/lidocaine composite solution that has proven to exert protective effects in cardiac preservation and resuscitation. Machine perfusion (MP) is beneficial for marginal kidneys with perfusate constituents a potential factor in optimising organs. The optimal solution for MP is yet to be established. Using a porcine MP and normothermic reperfusion (NMR) model, we investigate whether AL's novel characteristics translate favourably to kidney preservation compared to UW. Methods: Of 12 cadaveric porcine kidneys (warm ischaemia = 45mins) were randomized into two groups (AL, n = 6 and UW, n = 6). After flushing and transport (transport cold ischaemia=5 h) all kidneys underwent MP with UW or AL at 4°C using clinical protocols for 10 h on Waters Medical Systems RM3 devices. Kidneys then underwent 2 h of NMR at 38°C with modified Krebs Henseleit Buffer solution. Perfusion dynamics, functional parameters, histology, and real-time microdialysis was used to assess kidney responses and viability. Results: MP: Systolic pressure declined progressively in the UW group at 5-10 h, which was not as evident in the AL group (p < 0.02). Flow rates remained persistently higher overall in the AL group vs. the UW group (15.5 vs. 13.3 ml/ min/100 g, p = 0.01 AUC). Resistance was low, stable, and viable (<0.5 mmHg/ml) from onset and throughout AL perfusion (0.49 mmHg/ml [0.51-0.44]) while time to a viable resistance was 9 h with the UW group (range: 0.7-0.44 mmHg/ml). NMR: Urine output remained stable with UW while trending to increase in the AL group. There were no differences in creatinine clearance, oxygen and glucose consumption between the two groups. Lower perfusate lactate 4.07 vs. 5.45 mM was evident during NMR in the AL group (p = 0.03). Histology showed similar degrees of reperfusion injury. Conclusion: MP with AL solution is feasible and produces a more rapid stabilisation of perfusion dynamics to viable levels, with higher flow rates and lower resistance compared to UW potentially allowing earlier viability categorisation. NMR shows similar kidney function and viability profiles (AL versus UW) with a trend of increasing urine production in the AL versus UW group. Development of AL as an alternative MP solution is a step towards maximising the benefits of MP, improve marginal graft viability assessment, and the delivery of potential cost-savings in relation to current techniques, while potentially expanding donor pools.  Introduction: Hypothermic preservation has formed the mainstay for organ maintenance in transplantation, with static cold storage (SCS) constituting the commonest and simplest method. Prolonged static storage is associated with deleterious graft outcomes, especially in marginal allografts. Hypothermic machine perfusion (HMP) preservation however has been shown to be beneficial for marginal organs. We investigate whether HMP is able to ameliorate the ischemic damage caused by extremely prolonged cold static storage. Methods: Eight cadaveric porcine kidneys were isolated and randomized into two groups thereby undergoing either 4-h (SCS4, n = 4) or 52-h (SCS52, n = 4) of SCS. Following SCS all kidneys underwent HMP with UW solution at 4°C over 12 h, and were finally subjected to 2 h of normothermic machine reperfusion (NMR) at 38°C. Perfusion dynamics, perfusate samples, renal function parameters, histology, and novel real-time microdialysis techniques were used to assess kidney responses. Results: All kidneys showed stable and viable perfusion dynamics during HMP. During NMR, flow dynamics and resistance characteristics followed the well-described, within-subject decline over time (p < 0.001), however betweengroup repeated-measures analyses showed no significant difference (p = 0.230). Urine output trended to be higher in SCS4 versus SCS52 kidneys (p > 0.2), while oxygen and glucose consumption, and perfusate lactate levels were similar between groups (p > 0.2). Conclusion: This early data shows that porcine kidneys, despite exposure to extremely prolonged static cold storage, have similar functional outcomes and viability profiles following optimisation with HMP as those with shortened static cold storage times. In contrast to traditional static cold preservation of donor livers, normothermic machine perfusion may reduce preservation injury, improve graft viability, and potentially allows ex-vivo assessment of graft viability prior to transplantation. We have studied the feasibility of normothermic machine perfusion in four discarded human donor livers. Normothermic machine perfusion consisted of pressure and temperature controlled pulsatile perfusion of the hepatic artery and continuous portal perfusion for 6 h. Two hollow fiber membrane oxygenators provided oxygenation of the perfusion fluid. Biochemical markers in the perfusion fluid reflected minimal hepatic injury and improving function. Lactate levels decreased to normal values, reflecting active metabolism by the liver (mean lactate 10.0 AE 2.3 mM at 30 min to 2.3 AE 1.2 mM at 6 h). Bile production was observed throughout the 6 h perfusion period (mean rate 8.16 AE 0.65 g/h after the first hour). Histological examination before and after 6 h of perfusion showed well preserved liver morphology without signs of hepatocellular ischemia, biliary injury, or sinusoidal damage. In conclusion, this study shows that normothermic machine perfusion of human donor livers is technically feasible. It allows assessment of graft function before transplantation, which opens new avenues for organ selection, therapeutic interventions and preconditioning. 
