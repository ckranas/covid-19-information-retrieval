eb36dc936e232f9ee3c6afff4a0c8f4f1d04336a




Barriers to evidence-informed health policymaking are well-established [1] . Although many barriers are technical in nature (e.g., poor communication of research findings) [2] , a major impediment stems from the political nature of policymaking [3] [4] . Public opinion is a key aspect of politics; and one that is relevant to efforts to promote evidenceinformed policymaking because public opinion influences policymakers' behaviors [5] [6] . Thus, if policymakers learn that the public wants their decisions to be supported by evidence, this information could spur policymakers to make more evidence-informed health policy decisions and demonstrate evidence use to their constituents. However, no prior research has examined public opinion about evidenceinformed policymaking. This study sought to characterize public opinion about the influence that evidence should, and does, have on health policy development in U.S. Congress relative to other factors and examine differences in opinion by political party affiliation. A public opinion survey was conducted in 2018 using the SSRS Probability Panel (N=532), a nationally representative internet panel. Respondents separately rated the extent to which six factors (e.g., evidence, budget impact, industry interests) "should have" and "currently have" influence on U.S. congresspersons' health policy decisions. Results Evidence (59%) was the most frequently identified factor that should have "a lot of influence" on health policy development, but only 11% of respondents thought that evidence currently has "a lot of influence" (p<.001). Opinions about evidence did not vary significantly by respondent political party affiliation. There is strong bi-partisan public support for evidence to have much more influence on health policymaking in U.S. Congress. This finding is promising in a time of elevated political polarization in the United States. The survey results have implications for interventions that aim to promote evidence-informed health policymaking. As findings suggest public demand for evidence-informed health policymaking, and prior research demonstrating that public opinion often influences elected policymakers' behaviors [5] [6] , interventions that systematically document the extent to which elected policymakers' actions (e.g., public statements, content of bills introduced, tweets) are evidence-supported and disseminate this information to the public could encourage policymakers to make more evidence-informed health policy decisions. Mental health problems affect millions of individuals and cost over $240 billion annually in increased healthcare, criminal justice, child welfare, education, and labor costs [1] . Ongoing efforts to take evidence-based mental health strategies to scale have encountered a number of barriers to successful uptake and sustained use [2] [3] [4] . To overcome these barriers, researchers and advocates often seek to influence public policy to facilitate increased investment in mental health [5] [6] [7] . Yet, little work has systematically sought to understand the specific content of past mental health legislation and how the content of the legislation is related to whether a bill becomes law. In order to answer these pressing questions about mental health policy, we conducted a mixed methods review of all federal bills introduced to Congress over the last three decades (1989-2019; N= 171,861) . This includes systematic coding of mental health's inclusion in federal legislation, quantitative analyses of that inclusion's relationship with bills becoming law, and qualitative analyses of how mental health policy may be used to improve population health. In the 101st Congress (January 3, 1989, to January 3, 1991) , only 14 mental health bills were introduced, comprising only .001% of all bills introduced. By the 115th Congress (January 3, 2017, to January 3, 2019), over 4% of all bills of any type included mental health provisions. In addition to increases in mental health policy across time, we will also present results of analyses that identify characteristics of bills that are more likely to be successfully enacted into law. Finally, results from qualitative analyses will be used to illustrate how elements of mental health policies can facilitate or restrict high-quality implementation. We will discuss implications of these findings through the lens of the outer context of the implementation ecology; specifically, by identifying supports and barriers from federal legislation and policy that may be most likely to promote successful implementation of evidence-based treatments. We will also discuss implications for how best to engage directly with policymakers to support increased availability and effectiveness of mental health services. Legislation in Washington State (HB2536), passed in 2012, mandated the reporting of evidence-based practices (EBPs) for all children-serving systems in Washington State. In response, the Division of Behavioral Health and Recovery and University of Washington's Evidence-Based Practice Institute developed a measurement method to track use of EBPs in routine services statewide. This method provides a cost effective and adaptable surveillance tool to monitor evidence-based practices (EBPs) and can also be merged with other data sources to monitor disparities in utilization and effectiveness. In this paper we will present this as an example of "outer setting" influences on EBP use as well as proof of concept for this integrated data infrastructure as a means to guide decision-making at the policy level. We analyzed a sample of youth (<21 years old) from Washington State who had received at least one hour of publicly funded outpatient mental health (MH) service. Current procedural terminology (CPT) billing codes were used to identify if clients in the sample received any valid EBP psychotherapy sessions during the observation period (May -Oct 2015). Billing data were then tied to self-reported perceptions of outcomes of service from the Child-Family Mental Health Consumer Survey. These outcome data were compared between youth who did and did not receive a valid EBP session during the observation period Results Among this sample of 1,580 youth, 19.7% (n=312) received at least one valid EBP psychotherapy session. Youth from rural (21.4%) versus urban (16.2%) providers were more likely to have received an EBP session (χ2=6.02, p=0.014). There were significant differences by race/ethnicity (χ2=14.71, p=0.04). Non-Hispanic Whites (20.2%) and American Indians (33.3%) were more likely, while African Americans (12.3%) and Hispanics (15.7%) were less likely to have received a valid EBP session. There was a trend for an interaction between race/ ethnicity and receipt of an EBP session on self-reported positive services outcomes, with receipt of an EBP session potentially being associated with more positive services outcomes among youth who were non-White versus White. As a proof of concept, we demonstrate that billing data provides a cost-effective tool to monitor the receipt of EBP MH sessions and can be tied to other data sources to examine outcomes across a health network. Successful implementation of Wraparound care coordination for youth with complex behavioral health needs requires hospitable policy and financing conditions [1] . Thus, when the "rubber meets the road," implementation support for Wraparound requires attention to the "outer setting" of the implementation ecology [2] , including cross-agency coordination, Medicaid payment reform, and cross-sector information systems. Unfortunately, existing implementation measures are scarce at the outer context [3] , as is research on relevant outer setting strategies [4] . This presentation describes efforts to track Wraparound implementation at system and organizational levels using an adaptation of the Stages of Implementation Completion (SIC) [5] . The SIC assesses implementation across eight stages and three phases: preimplementation, implementation, and sustainment. We adapted and added SIC items to align with multilevel Wraparound implementation support as enacted by the National Wraparound Implementation Center (NWIC), including an array of state systems (outer setting) variables such as state leadership engagement, cross-system communication and collaboration, financing strategies, and contract requirements. We have collected data for two pilot states and are completing collation for eight additional states. Adaptation of the SIC entailed adding 12 items and removing 4. Furthermore, we operationalized each SIC variable in terms of measurable Wraparound processes and activities. Preliminary results from two pilot states indicate high completion rates across stages for both states (completion percentages from 60% to 100%). However, states differed significantly in their time to completion, with State 1 averaging 3.75 months for completion of stages and state 2 averaging 26.38 months. Item-and stage-level analyses revealed that State 2 struggled to engage state leadership in implementation. State 1 adopted a new approach to building Wraparound implementation infrastructureinvesting in Care Management Entities (CMEs) [6] , while State 2 relied on Community Mental Health Centers. Conclusions Findings provide proof of concept for incorporating outer setting items into an established implementation measure and underscore the influence of outer context in Wraparound implementation. The presentation will show how NWIC is using this measure to support states to build systems that facilitate better implementation and outcomes, while also promoting new and needed research for mental health and implementation science. EvidenceNOW is an Agency for Healthcare Research and Quality (AHRQ)funded research initiative focused on helping primary care practices improve the delivery of the "ABCS" of cardiovascular disease (CVD) prevention: Aspirin in high-risk individuals, Blood pressure control, Cholesterol management, and Smoking cessation. Seven cooperatives used practice facilitation (PF) as a unifying strategy to support the implementation and dissemination of evidence-based care for CVD risk factors. Each cooperative enrolled over 200 practices in their region. Cooperatives created an infrastructure to engage stakeholder organizations in their region to facilitate the initiative. AHRQ created infrastructure that included a national evaluator (ESCALATES) and committees and meetings that fostered cross-cooperative collaboration and dissemination. This panel includes an AHRQ program officer who will discuss the infrastructure created and lessons learned for guiding the design of future funding opportunities [1] and case studies demonstrating how two cooperatives, HealthyHearts New York City [2] and Healthy Hearts Northwest [3] , partnered with community and government agencies in their region to accomplish EvidenceNOW goals. The discussant is the ESCALATES Principal Investigator. The aligned efforts of Cooperatives, AHRQ, and ESCALATES facilitated the collective expansion of capacity for practice transformation and rigorous evaluation. We found that: (a) large-scale, federally-funded research initiatives were strengthened through infrastructure that fostered collaboration across grantees (demonstrated by 12 cross-cooperative publications to date); (b) an external evaluator added tremendous value in supporting cross-cooperative collaboration and amplified opportunities for dissemination; (c) engaging with partner organizations early helped assess fit with organizational strategic plans, capacity, readiness for change, and data collection systems; (d) applying an implementation science framework [4] was necessary to guide intervention development and assessment; and (e) stakeholder organizations valued being included in research and funder meetings and dissemination activities. Conclusions For cooperatives, aligning goals, and attending to opportunities to grow research and quality improvement capacity among partnering agencies facilitated strong, enduring partnerships for practice transformation. Funders have a role to play in facilitating collaborations among cooperatives and evaluation. The findings that emerge through the efforts of multi-level partners are greater than the sum of the parts and further the field of dissemination and implementation science. While evidence-based treatments (EBTs) exist to ameliorate traumarelated mental health problems, many children do not receive them [1] . Possible reasons to account for this include limited availability of EBTs and poor collaboration amongst professionals involved in youth service provision [2] . Brokers, often child welfare workers, serve an important intermediary role in improving service access for youth [3] , but they are often trained separately from clinical providers, precluding the opportunity to promote cross-discipline collaboration. Community Based Learning Collaboratives (CBLC) use specific training/ implementation strategies involving multidisciplinary stakeholders to foster collaboration and build community capacity for trauma-focused EBTs [4] . The broker curriculum includes information about trauma impact, trauma-focused EBTs, family engagement strategies, and trauma-focused treatment planning, while also providing opportunities for cross-discipline training. This presentation examines changes in trauma-related knowledge, practices and interprofessional collaboration among n = 33 brokers participating in CBLCs conducted as part of a statewide dissemination initiative. Brokers completed self-report measures examining knowledge of trauma-related topics taught as part of the CBLC curriculum, organizational climate, interprofessional collaboration, and trauma-related practices (e.g., assessment, psychoeducation) pre-and post-CBLC. Bivariate correlations were computed in SPSS, and interaction effects were probed using the PROCESS macro in SPSS. Analyses revealed that increases in knowledge about the trauma-related curriculum topics were significantly associated with positive changes in broker practices following CBLC participation. However, neither changes related to interprofessional collaboration nor organizational climate were significantly related to changes in broker practices. Moderation analyses revealed a significant interaction effect between interprofessional collaboration and knowledge of evidence-based treatment planning pre-and post-CBLC [F (1, 29) = 5.14; p = .03; R2 = .25]. Those participants who reported the greatest pre-to post-CBLC change in interprofessional collaboration also reported a significant increase in skills related to evidencebased treatment planning (t = 2.62, p = .03, 95% CI = .04, 0.84). Conclusions Study findings suggest that brokers play an important role in building community capacity for EBT access and that cross-discipline strategies help to foster collaborative relationships among youth service providers. Implications for future research, policy and practice will be addressed. comparative effectiveness of augmentations to low-level implementation strategies for non-responding clinics [2] [3] . In this Hybrid Type III implementation-effectiveness study [4] , we compare the effectiveness of two augmentation strategies, External Facilitation (EF) vs. External + Internal Facilitation (EF/IF) [5] for improving uptake of an evidence-based collaborative care model (CCM) on 18-month mental health outcomes for patients with depression at community-based clinics initially non-responsive to lower-level implementation support. Providers initially received support using a low-level implementation strategy, Replicating Effective Programs (REP). After 6 months, nonresponsive clinics that had failed to deliver a clinically significant dose of the CCM to >10 patients were randomized to augment REP with either EF or EF/IF. Mixed effects models evaluated the comparative effectiveness of the two augmentations on patient outcomes at 18 months. The primary outcome was patient SF-12 mental health score; secondary outcomes were PHQ-9 depression score and self-reported receipt of the CCM during months 6 through 18. 27 clinics were non-responsive after 6 months of REP. 13 clinics (N=77 patients) were randomized to REP+EF and 14 (N=92) to REP+EF/IF. At 18 months, patients in the REP+EF/IF arm had worse SF-12 (diff=8.38; 95%CI= 3.59, 13.18) and PHQ-9 scores (diff=1.82; 95%CI=-0.14, 3.79), and lower odds of CCM receipt (OR=0.67, 95% CI=0.30,1.49) than REP+EF patients. Patients at initially non-responsive community-based clinics that were randomized to receive the more intensive EF/IF augmentation saw less improvement in mood symptoms at 18 months than those the received the EF augmentation, and were also no more likely to receive the CCM. While EF generally appeared to help clinics, a number of EF/IF clinics experienced barriers in implementing the IF strategy with fidelity, including failing to identify an IF. For large-scale implementation in community-based clinics, augmenting REP with EF for sites that need additional support may be more feasible, and ultimately more effective, than a more intensive EF/IF augmentation. Trial Registration: ClinicalTrials.gov NCT02151331 Evidence-based collaborative care interventions (CCIs) can improve health by mitigating the access gap in mental health care treatment. However, CCIs can be difficult to implement and efforts to scale up CCIs are often stymied by a lack of practitioner knowledge for identifying and addressing barriers to implementation [1] . Implementation roadmaps provide a playbook outlining critical steps practitioners should follow in scaling up CCIs to new settings that overcome implementation barriers, measure implementation success, and garnering leadership support for longer-term CCI sustainability [2] . We present an Implementation Roadmap [3] that guides community-based CCI implementation based on the experiences of stakeholders successfully implementing a broad spectrum of CCIs through the Michigan Mental Health Integration Partnership (MIP) [4] . The goal of MIP is to support the scale up and spread of CCIs that enhance access to care for Medicaid-eligible consumers with behavioral healthcare needs, while also providing an in-situ implementation laboratory for informing sustained uptake of CCIs across a variety of community-based settings. Semi-structured interviews were carried out with stakeholders from successfully adopted MIP CCI projects to define common barriers, challenges, and implementation strategies deployed by the project teams. Interviews were transcribed and analyzed for common themes that identified a series of critical steps scaffolding the CCI implementation process and accompanying metrics for evaluating implementation progress. 25 interviews of key stakeholders were conducted across 7 successful MIP implementation teams, including 11 providers at implementation sites and 14 researchers/project managers. Stakeholders commonly identified specific steps that overcame barriers to CCI implementation, including deployment of web-based tools for facilitating implementation, embedding key metrics of implementation success, garnering upper level administration buy-in upfront, and specifying a process for tailoring implementation strategy deployment to specific site needs. These findings informed our resulting Implementation Roadmap, which includes eleven critical implementation steps and evaluative metrics for investigators implementing CCIs to consider across pre-implementation, implementation, and sustainability phases. Maximal CCI public health impact requires improved reach. Our Implementation Roadmap provides a clear and practical guide for early stage community CCI implementation efforts, and ensure practitioners collect key metrics and systematically address barriers in ways that are foundational for larger scale, sustainable implementation efforts. Collaborative Chronic Care Models (CCMs) have extensive controlled trial evidence for effectiveness in serious mental illnesses [1] , but there is little evidence regarding feasibility or impact in typical practice conditions. We determined the effectiveness of implementation facilitation on establishing the CCM in mental health teams, and its impact on health outcomes of team-treated individuals. We used a randomized stepped wedge trial in Behavioral Health Interdisciplinary Program (BHIP) teams in outpatient general mental health clinics of nine VA facilities, using blended internal-external facilitation. Facilitation combined a study-funded external facilitator with a facility-funded internal facilitator working with a designated team for one year. We hypothesized that facilitation would be associated with improvements in both implementation and intervention outcomes (hybrid-II trial) [2] . Implementation outcomes included the clinician Team Development Measure (TDM) and proportion of CCMconcordant team care processes. The study was powered for the primary health outcome, VR-12 Mental Component Score (MCS). All Veterans treated by designated teams were included for hospitalization analyses, based on administrative data; a randomly selected sample was identified for health status interview. Individuals with dementia were excluded. For implementation outcomes, 62 clinicians were surveyed; site process summaries were rated for CCM concordance. The population (n=5,596) included 881 (15%) women, average age 52.2+14.5. The interviewed sample (n=1,050) was similar, but oversampled for women (n=210, 20.0%). Facilitation was associated with improvements in TDM subscales for role clarity and team primacy. Percentage of CCM-concordant processes achieved varied (44-89%). No improvement in veteran self-ratings, including the primary outcome, was seen. However, in post-hoc analyses MCS improved in veterans with >3 treated mental health diagnoses versus others. Mental health hospitalization rate demonstrated a robust drop during facilitation; this finding withstood four internal validity tests [3] . Conclusions Working solely at the clinician level with minimal study-funded support, CCM implementation yielded provider and Veteran benefits. Although impact on self-reported overall population health status was negligible, health status improved for complex individuals, and hospitalization rate declined. Facilitating CCM implementation provides a potential model for realigning VA outpatient general mental health care with an evidence-based model that improves provider team function and Veteran outcomes. Trial Registration: ClinicalTrials.gov NCT02543840 This presentation describes the development of the Leadership and Organizational Change for Implementation (LOCI) strategy [1] , subsequent adaptation, and preliminary data for implementing Motivational Interviewing (MI) in substance abuse treatment settings [2] . LOCI is an implementation strategy developed to align higher level organizational strategies with first-level leader development to create a strategic organizational climate to support implementation and sustainment of evidence-based practices (EBPs) [3] . Adaptations to the general design of LOCI that have occurred over time, as well as adaptations built into LOCI to tailor the strategy to particular settings will be described. LOCI provides a general structure, curricula, and process for leading implementation, allowing for flexibility so that leaders across levels can prioritize issues most relevant at a given time for a given context. We also describe mechanisms of change central to LOCI. The current study involves 3 cohorts of 20 clinics in which clinics are being randomized to LOCI vs. webinar control conditions. For this presentation we utilize data from the first cohort 19 clinics and quantitatively examine differences in implementation leadership and climate by condition. Qualitative data were collected from and analyzed to identify factors influencing EBP implementation. Fourteen leaders across intervention and control conditions responded to an online survey and provided rankings (order of importance) and ratings of factors affecting EBP implementation. These data were supplemented with qualitative interviews. Preliminary results from the first cohort demonstrated that LOCI, compared to the control condition, showed significant improvements in implementation leadership and implementation climate. Qualitative analyses showed that compared to control leaders, LOCI leaders were more focused on staff competency and overcoming resistance. Time, turnover, and the influence of external contracts emerged as key themes. The LOCI implementation strategy was designed to improve general and implementation leadership, subsequent implementation climate, and provider implementation behaviors including the adoption and use of EBP with fidelity. The ultimate goal is to improve client engagement in services and patient outcomes. Preliminary results suggest that LOCI can improve the context for implementation or EBPs, and that LOCI can help to focus leaders' attention on improving implementation. Trial Registration: ClinicalTrials.gov NCT03042832 Children with ASD are a high priority population served in multiple public service systems. Evidence-based behavioral interventions are available [1] [2] , however, they are not routinely delivered in community care [3] [4] [5] [6] . In response, our research groups used communitypartnered approaches to adapt and test ASD interventions for routine delivery -"AIM HI" in children's mental health [7] and "CPRT" in education [8] . We identified implementation leadership and climate as key implementation mechanisms in recent community effectiveness trials. We are conducting two, coordinated studies testing the effectiveness of an adapted version of the Leadership and Organizational Change for implementation (LOCI) strategy [9] as part of an implementation package [10] . This presentation describes the application of LOCI in two ASD services contexts for two EBIs. The TEAMS project includes two linked randomized Hybrid Type 3 implementation trials to test two implementation strategies when paired with AIM HI or CPRT and examine mechanisms of these strategies, including implementation leadership and climate. The TEAMS Leadership Institute (TLI) applies LOCI as follows: (1) uses the LOCI components linked to mechanisms identified in the AIM HI and CPRT community effectiveness trials (i.e. implementation leadership and climate modules); (2) targets executive and mid-level leaders required to coordinate implementation; and (3) targets implementation of specific ASD interventions. We present process data on TLI implementation and initial themes from qualitative interviews to examine leader perceptions of the utility of TLI components and their impact on EBI implementation. To date, TLI has been conducted in 18 programs/districts in three California counties including 18 workshops and 152 coaching calls. Preliminary themes from interviews with 6 leaders who completed TLI indicate that TLI is feasible and useful to (1) convey to staff the importance of systematically planning EBI implementation, and (2) to maintain leader motivation and focus on executing strategic initiatives around AIM HI and CPRT amidst competing demands. Preliminary data indicate the TEAMS application of LOCI is feasible and perceived as effective in facilitating the implementation of two ASD interventions. Future analyses will examine the impact of LOCI on targeted mechanismsimplementation leadership and climate. Trial Registration: ClinicalTrials.gov NCT03380078 The Norwegian Centre for Violence and Traumatic Stress Studies (NKVT S) is commissioned by the Ministry of Health and Care Services to implement evidence-based treatment for post-traumatic stress disorder (PTSD) in both child and adult mental health care services. As part of this effort, the Leadership and Organizational Change for Implementation (LOCI) [1] was translated and adapted for the implementation of trauma treatment in Norwegian health trusts. The aim of the project is to evaluate the effectiveness of LOCI in supporting the implementation of evidence-based treatment for PTSD in Norwegian specialized mental health clinics [2] . The presentation will identify the implementation determinants, targets, and mechanisms being examined. The study is a Type III scale-out project [3] . Several a-priori adaptations were made, including translation of the LOCI materials into Norwegian, and tailoring of the LOCI fidelity tool. The study design is a stepped wedge cluster randomized trial with random and sequential enrollment of clinics into three cohorts, with crossover of clusters from control conditions to active intervention conditions based on time intervals. Executives, clinic leaders, and therapists complete surveys assessing leadership and implementation climate at baseline, 4, 8, 12, 16 , and 20 months. At baseline, all therapists at the participating clinics were trained in trauma screening and a sub sample in the treatment models for PTSD (TF-CBT, EMDR, CT-PTSD), and units were randomly assigned to one of three cohorts. In addition, the strategy uses the 360 degrees assessments to inform subsequent work on tailored leadership and climate development plans to enhance implementation. Therapy sessions are audio or video recorded and scored for fidelity. Patients complete surveys assessing symptom development during the therapy process. Consistent with the LOCI theoretical model, assessment of mechanisms will examine the effects of leadership on EBP fidelity through its effect on implementation climate. Conclusions This study will provide knowledge about the effect of the LOCI program within a Norwegian context. As such, the results might inform evidence-supported implementation strategies that could help sustain national-wide implementation of evidence-based trauma treatment and increase the quality and effectiveness of Norwegian health services. The uptake of evidence-based healthcare interventions is challenging, with, on average, a 17-year time gap between the generation of evidence and implementation of interventions into routine practice [1] . Although contextual factors such as culture are strong influences for successful implementation [2] , context remains a poorly understood construct, with a lack of consensus regarding how it should be defined and accounted for within research [3] . A systematic review was conducted to address this issue by providing an insight into how context is defined and assessed within healthcare implementation science literature and develops a definition to better enable effective measurement of context. The databases of PubMed, PsycInfo, CINAHL, and EMBASE were searched. English language empirical studies published in the previous 10 years were included if context was treated as a key component in implementing a healthcare initiative. Articles also needed to provide a definition and measure of context in order to be included. Results were synthesised using a narrative approach and supported using PRISMA guidelines for the conduct and reporting of systematic reviews. The searches yielded 3,021 records of which 64 met the eligibility criteria and were included. Studies used a variety of definitions. Some listed contextual factors (n=19) while others documented subelements of a framework that included context (n=19). Remaining articles provided a rich definition of an aspect of context (n=14) or context generally (n=12). Quantitative studies mostly employed the Alberta Context Tool while qualitative papers used a variety of frameworks with Promoting Action on Research Implementation in Health Services framework the most highly cited. Mixed methods studies used diverse approaches to assess context. Some used frameworks to inform the methods chosen while others used quantitative measures to inform qualitative data collection. Most papers (n=50) applied the chosen measure to all aspects of study design with a majority analysing context at an individual or level (n=51). This review highlighted inconsistencies in defining and measuring context which supported the development of an enhanced understanding for this construct. By providing this consensus, improvements in implementation processes may result as greater understanding will help researchers appropriately account for context in research. The dual objectives of juvenile justice are to assure youth safety while in custody and to facilitate rehabilitation. Suicide is the second leading cause of death among 10-25 year olds [1] , and is four times more likely among youth who enter juvenile justice (JJ) settings [2] . As youth in juvenile detention are at risk for engaging in suicidal behaviors, it is critical that behavioral health clinicians in juvenile detention settings conduct systematic evidence-based suicide risk, as well as general mental health, assessment. Recommendations for assessment in juvenile detention exist [3] , but there is little guidance regarding how to implement them among behavioral health clinicians. The current presentation will describe a community academic (CAP) partnership, and the process that the partners underwent to implement a systemic protocol for assessing youth in a juvenile detention behavioral health unit. A CAP was developed and a quality improvement procedure was utilized to develop and implement the assessment protocol. The CAP team included the service clinicians (Snyder and Whyte), and clinical supervisor (Cliggitt) in a behavioral health unit housed in a large, juvenile detention center in an urban city in Pennsylvania, as well as researchers from the University of Pennsylvania (Rudd, George, and Beidas) . The development of the assessment protocol was an iterative process that occurred over eight months. The process started with a comprehensive review of current workflow and workflow infrastructure, including how youth were referred to the behavioral health unit and the information behavioral health unit staff had about youth prior to their intake. Iterative changes to workflow procedures were needed, including developing infrastructure to support assessment (e.g., developing report templates) during the behavioral health intake appointment. Finally, several assessment measures were piloted to determine fit. The creation of a CAP was key to developing and implementing a comprehensive and feasible mental health and suicide assessment protocol. Lessons learned from the application of implementation science to the juvenile detention context from the joint perspectives of researcher (Rudd) and clinician (Synder) stakeholder perspectives will be presented. Reports of implementation efforts initiated at the practitioner level are uncommon. To address this gap, we describe the results of and lessons from an ongoing practitioner-led implementation of Acceptance and Commitment Therapy (ACT), an evidence-based practice, in a community mental health center team. We used a variety of implementation strategies (mostly training) during an ongoing implementation of ACT. Initially, we conducted a mixed methods study of the facilitators and barriers to implementation, collecting qualitative and quantitative survey data anonymously at two time points, sampled from all clinical staff (N=39) at our agency. The survey measured attitudes, knowledge, experience, and acceptability of the EBP. We assessed the significance of changes in Likert ratings using the sign test [1] . We used thematic analysis to code qualitative data. Recently, penetration was measured by relative use of ACT in a one-month sample of progress notes and by the relative percentage of team members using ACT. Implementation strategies used were identified by retrospective review and coded in accordance with the Expert Recommendations for Implementing Change (ERIC) project [2] and classified into concept mapping clusters for ERIC strategies [3] . We created a timeline of implementation activities and identified key individuals who facilitated these activities. Results 15 pairs of pre-post survey measures indicated that initial training was associated with increases in identification as an ACT therapist (Z=-2.12,p= 0.035), perceived ability to demonstrate ACT (Z=-3.00,p=0.002), and a trend toward increased use of ACT (Z=-1.90,p=0.055). Qualitative analyses were consistent with the existing literature on facilitators and barriers to EBP adoption in community mental health. ACT use in a recent onemonth window was evidenced with 7.9% of progress notes documenting use of ACT (baseline before implementation: 0%) and 32% of eligible clinicians documenting ACT use in progress notes (initial baseline: 0%). Evidence for use of 21 of the 73 ERIC implementation strategies was documented. The strategies are distributed across all 9 concept mapping clusters, with the Train and Educate Stakeholders cluster most represented (5 of 11 strategies). Three key individuals were identified. Practitioner-led implementation is feasible. Implementation strategies can inform practitioner efforts. Background A chronic and increasing challenge to employee wellness in schools is teacher stress [1] . Teachers are tied with nurses as having the highest rates of daily stress among occupations [2] . Chronic high levels of teacher stress are associated with (a) increased rates of physical and psychological health problems, including anxiety, depression, cardiovascular disease, and poor sleep quality; (b) poor job performance, including absenteeism, negative interactions, poor relationships with students, and poor classroom management, and (c) poor student outcomes, including low rates of academic achievement, lower levels of social adjustment, and increased rates of problem behavior [1, 3] . Further, chronic teacher stress is the primary factor associated with the high rate of teachers leaving the profession for reasons other than retirement, which has nearly doubled over the past 25 years, constituting the primary cause of teacher shortages nationwide [4] . A critical need to address teacher health and wellbeing exists, yet, on average, only 31.4% of schools offer workplace health and wellness promotion programs; most of these programs are top-down, one-size-fits-all approaches that are either ineffective or unsustainable [5] . The purpose of this mixed methods study was to implement the Healthy Workplace Participatory Program (HWPP), an evidence-based approach that engages front-line employees (i.e., teachers) and supervisors (e.g., administrators) in a collaborative, iterative design of workplace health and wellness interventions [6] . This participatory approach allows for (a) identification of health and wellness issues most salient to employees; (b) development of a wider range of interventions as employees are more aware of complex interactions between their work organization, workplace, and lifestyle; and (c) identification of potential intervention barriers and facilitators; (d) increased buy-in to problem definition and intervention design; and (e) establishment of a supportive organizational culture and processes for a self-correcting and sustainable health and wellness promotion program. The HWPP has been shown to effectively increased employee health and wellbeing in a wide range of worksites [6] ; this is the first implementation effort in schools. Results of focus groups as well as formative and summative data related to implementation and intervention processes, strategies, and outcomes across EPIS phases in two 3rd-5th grade elementary schools in the Northeast will be presented. Many evidence-based practices (EBPs) rely on multiple dissemination supports to assist scaling to achieve population benefits. Intermediary organizations (IOs) are often key in leveraging critical functions in the overall support system to enhance diffusion strategies [1] [2] [3] . Despite the prevalence of intermediaries as important accelerators of evidence-based practices, little is known about which IO strategies are most effective in ensuring implementation and scaling success or how strategies link to existing IO capacities [3] . Further, there is a dearth of information regarding IO capacity assessments relative to their capabilities to effectively diffuse EBP's or to perform active implementation support.  The IOCA is demonstrating good alignment with known classes of IO support functions. It is also providing practical usability relative to understanding baseline IO capacity to deliver ongoing supports for scaling of EBPs. IOs that have experience with the tool report improved understanding of implementation science-informed strategies and tools that can better guide them in their support activities. The panel will discuss integration of practical lessons learned from clinicians and administrators with principles of implementation science to develop a program to increase use of evidence-based psychotherapy (EBP) for PTSD in military treatment facilities (MTFs). Despite efforts to train military providers in EBPs, only a minority of service members receive them [1] . Implementation barriers likely vary across MTFs, which differ in size, resources, command structure, and implementation climate. Increased use of EBPs likely requires a tailored approach that aligns implementation strategies to local conditions [2] . The Targeted Assessment and Context-Tailored Implementation of Change Strategies (TACTICS) program combines needs assessment, a rubric for aligning implementation strategies to local barriers and facilitators, and external facilitation to help clinics enact a collaboratively developed implementation plan. Through experience working with MTFs, the Center for Deployment Psychology (intermediaries) identified common implementation barriers and potential contextspecific strategies to address them. These were augmented with additional relevant strategies from the Expert Recommendations for Implementing Change project [3] and input from experienced implementers. Barriers and facilitators in the resulting TACTICS rubric were then mapped backed to domains of the Consolidated Framework for Implementation Research [4] . After getting leadership approval and identifying a site champion, the five-month TACTICS process involves conducting needs assessment interviews with relevant staff and reviewing clinic data to identify barriers and facilitators, using the TACTICS rubric to identify potential change targets and strategies to address local conditions, and meeting with staff to develop the implementation plan. This is followed by weekly coaching calls (external facilitation) to support the champion in enacting changes to increase use of evidence-based psychotherapy. Results TACTICS rubric development is completed and is being pilot tested at one site. After this development phase, TACTICS will be tested in a stepped-wedge randomized trial in eight military treatment facilities. Development of the TACTICS program was informed by intermediaries' practical knowledge from military clinicians, implementation experience, and by implementation science frameworks. If successful, TACTICS provides a barrier-to-solution tailoring framework informed by implementation practitioners, researchers, and local staff. Intermediary organizations are entities that help agencies or systems develop, implement, and sustain evidence-based practices [1] . Little is known about how implementation science frameworks, strategies and tools that are used by intermediary organizations charged with scaling evidence-based practices for a large state system of behavioral health. The Center for Practice Innovations (CPI), at Columbia Psychiatry and the New York State Psychiatric Institute, is an intermediary organization whose mission is to support the New York State Office of Mental Health in the use of EBPs throughout community-based mental health agencies in New York State. CPI's role includes: (a) public awareness, and education; (b) scalable dissemination of training in EBPs; (c) implementation support through learning collaboratives; (d) quality improvement; and (e) outcome evaluation. We will describe empirical approaches to the development, dissemination of scalable training and implementation support for a range of initiatives at CPI. Grounded in the Consolidated Framework for Implementation Research [2] , we will present on the CPI practice change model and how the CFIR assists in planning for post-training implementation support and the identification of barriers and facilitators to implementation. Using the published taxonomy, Expert Recommendations for Implementing Change [3] , we will describe a range of implementation strategies (e.g., instructional design methods, user-centered design, stakeholder engagement) that inform the development of scalable online training and identify targets for post-training implementation activities. Lastly, we will provide examples of online training evaluation [4] and challenges faced in reporting on the impact of implementation strategies [5] [6] within a large system of behavioral healthcare. Although a balancing act, it is possible for intermediary organizations to remain flexible, efficient, and rapid in response to the mission of real-world dissemination and implementation of EBPs and use empirically-driven distance and E-learning and implementation science approaches. There are opportunities for mutual learning, synergy and collaboration to advance the field of implementation science for researchers and practitioners. Train-the-Trainer programs (TTTs) refer to "a program or course where individuals in a specific field receive training in a given subject and instruction on how to train, monitor, and supervise other individuals in the approach [1] ." TTTs are implementation strategies intended to increase the reach and sustainment of evidence-based interventions in mental health agencies, and address other challenges such as therapist attrition and developer succession planning [2] [3] . Several traumainformed interventions for children have TTTs; however, there is no standardized protocol for developing or delivering TTTs. As the need to disseminate and sustain trauma-informed interventions grows, the need to develop guidelines for TTTs becomes imperative. The objective of this project is to better understand the state of TTTs for traumainformed interventions utilized by members and consumers of the National Child Traumatic Stress Network (NCTSN). Duke University study staff partnered with members of the NCTSN Implementation Advisory Committee to develop a survey exploring TTTs in the NCTSN. The survey was designed to gather the perspective of developers of treatments, practices, and curricula; professionals that become trainers through TTTs; and agency training directors that serve as consumers of TTTs. Developers will answer a series of questions about the development and implementation of their TTT program. Trainers and agency directors will be asked about their experience participating in a TTT program. All respondents will be asked about the components of their TTTs, barriers to using or developing TTTs, and facilitators of developing or using TTTs. No results are currently available. The study has secured IRB approval and the survey will launch in April 2019. Results will be analyzed in summer 2019. Surveying each of these audiences will help us to better understand the varying components of TTTs, and barriers and facilitators of their use within the NCTSN. We plan to use the survey results for training purposes and resource development to enhance the use of TTTs within the NCTSN (and in other relevant settings) to implement and sustain trauma-informed interventions.  This project will engage in a participatory process with key stakeholders to design implementation strategies to increase universal depression screening in primary care. In particular, we fill focus on designing a subset of implementation strategies-nudges, as they are called in behavioral economics [1] -that alter the choice architecture, or the way options are presented to optimize choices. First, we began by conducting an innovation tournament, a crowdsourcing technique [2] , with physicians, nurses, medical assistants, behavioral health clinicians, and front-desk stuff currently involved in administering the electronic depression screener, the two-item Patient Health Questionnaire (PHQ-2) at their practices. The tournament will generate ideas on how to increase the implementation of the PHQ-2. Next, we will fine-tune the ideas generated from the innovation tournament with a team of stakeholders, behavioral economists, and implementation scientists using behavioral economic theory [3] . The product of this project will be a toolkit of implementation strategies, that are theoretically motivated and acceptable to a range of relevant stakeholders, a subset of which will be later refined through a more rigorous piloting process. The innovation tournament closes mid-April, 2019. Ideas from the tournament will be refined into a toolkit of implementation strategies by September 2019. Our study responds to the need for interdisciplinary, theoretically informed, and participatory approaches to designing implementation strategies. The results from our work will shed light on whether these approaches show promise. Using stakeholder values to promote implementation of an evidence-based mHealth intervention for addiction treatment in primary care Correspondence: Andrew Quanbeck (arquanbe@wisc.edu) College of Engineering, University of Wisconsin -Madison, Madison, WI, USA Implementation Science 2020, 15(Suppl 2):A24 The majority of evidence-based practices do not find their way into clinical use, including mobile health (mHealth) technologies. This presentation describes a novel decision-framing model that gives implementers a method for eliciting the perceived gains and losses that different stakeholder groups trade off when faced with the decision of whether to adopt an evidence-based mHealth intervention. The decision-framing model integrates insights from behavioral economics [1, 2] and game theory [3] . The approach was applied retrospectively in a parent implementation research trial that introduced an mHealth system to 268 patients in three U.S. clinics offering primary and behavioral healthcare services. The mHealth system, called Seva, supports patients with addiction. Individual and group interviews were conducted to elicit stakeholder considerations from 23 clinic staff members and 6 patients who were involved in implementing Seva. Considerations were used to construct "decision frames" that trade off the perceived value of adopting Seva vs. maintaining the status quo from each stakeholder group's perspective. The face validity of the decision-framing model was assessed by soliciting feedback from the stakeholders whose input was used to build it. Primary implementation considerations were identified for each stakeholder group. Clinic managers perceived the greatest potential gain to be providing better care for patients, and the greatest potential loss to be cost, expressed in terms of staff time, sustainability, and opportunity cost. All clinical staff considered time their foremost consideration-primarily in negative terms (e.g., cognitive burden associated with learning a new system) but potentially positively (e.g., if Seva could automate functions done manually). Patients considered safety (anonymity, privacy, and coming from a trusted source) to be paramount. When considerations were compiled into decision frames that traded off the gains and losses associated with adopting Seva, only one stakeholder group-patients-expressed a positive overall value, and these were the stakeholders who used Seva most. This paper presents a systematic method of inquiry to elicit stakeholders' considerations when deciding to adopt a new technology. Stakeholder considerations may be used to adapt mHealth interventions and tailor implementation, potentially increasing the likelihood of implementation success for evidence-based practices and technologies. Public behavioral health systems have increasingly invested in the implementation of evidence-based practices (EBPs), including Philadelphia's Department of Behavioral Health. Training and technical assistance continue to be the most commonly used strategies to increase use of EBPs, despite findings that organizational barriers matter. Few organizational implementation strategies exist and little is known about how to best design organizational strategies to increase implementation of EBPs using participatory design approaches. We partnered with front line clinicians to develop organizational implementation strategies to improve EBP implementation in community mental health clinics. We engaged in a three-step process to design organizational implementation strategies. First, we launched an innovation tournament to engage clinicians employed within the Philadelphia public behavioral health system to crowd-source how their organizations can support them to use EBPs. We held a community-facing event during which the 6 clinicians who submitted winning ideas presented their ideas to 85 attendees representing a range of stakeholders. Second, we worked with behavioral scientists to refine the ideas to optimize their effectiveness. Third, we launched a system-wide survey targeting approximately 300 stakeholders to elicit preferences for the clinician generated organizational implementation strategies. We report on the outcomes of the innovation tournament and systemwide survey. A total of 65 ideas were submitted in the innovation tournament by 55 participants representing 38 organizations. The most common categories of ideas pertained to training (42%), compensation (26%), clinician support tools (22%), and EBP-focused supervision (17%). Using an innovation tournament to generate ideas for implementation strategies was feasible and acceptable as demonstrated by the high levels of engagement. However, we also identified barriers (e.g., ensuring that the stakeholder voice was adequately represented throughout all stages). The system-wide survey will be launched in March, 2019; and will close April, 2019. The approach that we took in designing implementation strategies is promising. Research is needed to test whether strategies developed via these methods are more effective than strategies developed through competing approaches. Leveraging normative pressure to increase data collection among therapists working with children with autism David S. Mandell, Heather Nuske, Emily Becker-Haimes Department of Psychiatry, University of Pennsylvania, Philadelphia, PA, USA Correspondence: Emily Becker-Haimes (embecker@upenn.edu) Implementation Science 2020, 15(Suppl 2):A26 Background Evidence-based practices for children with autism generally follow the principles of applied behavior analysis, which require frequent, systematic data collection. In Philadelphia, as in many systems, children with autism often are accompanied by a one-to-one aide, who is responsible for collecting these data as part of implementing a treatment plan. Direct observations and interviews with these aides and their supervisors confirm that aides rarely collect data in a rigorous manner. These aides often work in isolation and rarely receive consistent supervision, which may lead to the perception that data collection is not expected of them, nor do people in their position collect data in this manner. We use participatory methods combined with innovative methods borrowed from industry that incorporate the principles of behavioral economics to design implementation strategies to increase aides' data collection. We partnered with five community agencies and used time-andmotion study methods, an observational technique drawn from scientific management, to understand how one-to-one aides collect data. This process involved querying aides about the decisions they made regarding data collection in the moment. We used participatory design strategies, including an innovation tournament-a method to crowdsource strategy ideas from stakeholders-and a rapid-cycle approach-a method that involves iterative testing and refining implementation strategies-to increase one-to-one aides' data collection. We applied theoretical principles from behavioral economics to refine the implementation strategies generated from the innovation tournament and to test them using our rapid cycling approach. Data collection is ongoing. Here we present on the time-and-motion studies and results of our innovation tournament. We provide a framework for the rapid-cycle process that is ongoing at the time of this presentation. This method of data collection in the service of identifying implementation strategies and rapidly testing them holds promise. the Teen Marijuana Check-Up (TMCU) [3] , a school-based adaptation of motivational enhancement therapy, incorporates SPs for both purposes [4] . In this trial, a set of SPs portray marijuana-using adolescent characters in dyadic interactions with participating school-based staff. As components of TMCU training, two SP-involved training cases-each offering consequence-free opportunities for staff to receive performance-based trainer feedback-supplemented an initial workshop. As components of pre-and post-training outcome assessments, two more SP interactions provided behavioral outcome measures. All four SP interactions involved travel to staff workplaces to record a simulated TMCU session, later scored for the following fidelity indices: ratio of reflective listening statements to questions (R:Q), percentage of 'open-ended' questions (%OQ), and percentage of 'complex' reflective listening statements (%CR). Recruited from seven high schools, twenty staff completed all four SP interactions. Pre-training SP interactions revealed variable staff performances, with two staff members achieving a TMCU proficiency standard by exceeding benchmarks for all three fidelity indices. In SP-involved training cases, this proficiency standard was achieved by eight staff in an initial case, and by six staff in a more challenging latter case. In eventual post-training SP interactions, five staff met the TMCU proficiency standard. As for mean training impact, Cohen's d effect sizes suggest small-to-medium effects on R:Q (d=.20), %CR (d=.36), and %OQ (d=.43), and documented expected needs for subsequent support of TMCU implementation via purveyor coaching as a targeted form of post-training technical assistance. This trial-wherein SP methodology further extends to monitoring of TMCU fidelity in biannual assessments for two years after training-includes SP roles in outcome assessment and training. Fidelity data from the collective SP interactions evidence sensitivity to hypothesized changes in staff learning, further supporting the use of SPs as means to measure and monitor fidelity in trials examining behavior therapy implementation. The gravity of the opioid epidemic requires innovative and promising solutions that can be rapidly scaled [1] . Hybrid type 1 designs can speed the translation of such interventions by accomplishing the dual tasks of (a) establishing effectiveness of interventions as they are being rolled out under real-world conditions and (b) identifying determinants of implementation that can assist with planning of future scaling activities [2] [3] . The current study aims to accomplish just such a task through the replication and testing of Project Planned Outreach, Intervention, Naloxone, and Treatment (POINT), an EDbased peer support intervention aimed at connecting people with opioid use disorder to medication assisted treatment (i.e., methadone-, buprenorphine-, or naltrexone-facilitated treatment). This study is funded by a unique federal mechanism that aims to improve rapid translation of research to practice through academic-state partnerships. In this presentation, we will provide an overview of our pragmatic hybrid design before focusing on results of the study's 6month pilot phase. The researchers partnered with the Indiana Division of Mental Health and Addiction to carry out this study. Per the project's funding mechanism, success of the pilot was to be determined by the achievement of 3 milestones, including our ability to successfully replicate the POINT intervention with 75% fidelity to previously identified critical components within a new implementation context. Overall implementation of the study protocols was successful, with only minor refinements to proposed procedures being required in light of challenges with (a) data access, (b) recruitment, and (c) identification of the expansion hospitals. All three milestones were reached, including 77% fidelity to the original POINT programs' components. Challenges in implementing protocols and reaching milestones resulted in refinements that improved the study design overall. The subsequent trial will add to the limited but growing evidence on ED-based peer supports. Capitalizing Indiana's current efforts in order to study an already scaling and promising intervention is likely to lead to faster and more sustainable results with greater generalizability than traditional, efficacy-focused clinical research. Trial Registration: ClinicalTrials.gov NCT03336268 Associations between contextual barriers, implementation strategies, and program performance can be evaluated using data from ongoing quality improvement programs in healthcare operations [1] . The Psychotropic Drug Safety Initiative (PDSI) is a system-wide program guiding quality improvement for psychotropic prescribing in 140 Veterans Health Administration (VHA) facilities. In 2017, PDSI began a program to increase medication assisted therapy (MAT) for Opiate Use Disorder (OUD) and Alcohol Use Disorder (AUD). This analysis characterizes perceived barriers, providing a foundation for analyzing associations between barriers, implementation strategies, and program performance. Among six core policies, PDSI provides metrics of local MAT use and requires facilities to identify a champion. Facility assessments are submitted, which identify disorder focus (AUD and/or OUD) and perceived barriers (including 18 barriers previously identified by key informants as well as free text) [2] . Barriers are characterized by Consolidated Framework for Implementation Research (CFIR) construct, selection frequencies, intercorrelations, and associations with facility characteristics [3] . All 140 VHA facilities responded: 74 (52.9%) focused on AUD, 47 (33.6%) on OUD, and 19 (13.6%) on both. Frequently selected barriers, including free text, clustered in the "individual characteristic" and "inner setting" CFIR domains: "Patients frequently refuse treatment or referral" (107 [76.4%]) and "Providers have too many competing demands" (98 [70.0%]). Neither disorder focus nor frequency of barrier identification varied significantly with level of MAT use at the facility. There was moderate intercorrelation of selected barriers (Cronbach's alpha = 0.67). The barriers of "Not enough x-waiver providers" and "MAT required enrollment in intensive treatment programs" were selected more frequently in OUD-focused programs. Associations with specific improvement strategies used and program performance will be reported in June 2019. The most frequently perceived barriers to increasing MAT were characteristics of patients, providers, and the local organization. Associations between barriers, disorder focus, and MAT use were weak. Data suggest a disconnect between perceived barriers and knowledge of organization performance. Linking program barriers, implementation strategies, and performance may be an implicit assumption of healthcare improvement programs. Analyzing these links demonstrates intersections between implementation science research, quality improvement practice, and health system policy. Background A foundation of basic supports and resources is required for the successful implementation of evidence-based practices (EBPs). Inner and outer context determinants for this foundation remain unclear. As part of a cluster randomized trial testing the Leadership and Organizational Change for Implementation (LOCI) intervention for motivational interviewing (MI) implementation across substance use treatment agencies [1] , we use qualitative methods to explore experiences of agency executives, supervisors, and providers regarding the multilevel determinants of strategic implementation. Preliminary data from 29 individual interviews and 15 focus groups with 10 executives, 23 supervisors, and 80 providers across five agencies were examined. Notes from coaching calls conducted with supervisors randomized to the LOCI condition were explored to further contextualize engagement in the implementation strategy and MI implementation over time. The Framework Method [2] was used to synthesize data withinand between-agencies and identify emergent themes in accordance with the Exploration, Preparation, Implementation, Sustainment (EPIS) framework [3] and Edgar Schein's organizational culture change model [4] . Determinants of LOCI engagement and MI implementation included the structural make-up of the agency and/or clinic, timing of state-wide policy initiatives, and professional role at the agency. Agency executives, supervisors, and providers all agreed that inadequate staffing and high turnover limited the time available for LOCI engagement and MI implementation. Participants detailed how the lack of basic resources, such as not having therapy rooms, negatively impacted their ability to participate in LOCI and implement MI. Additionally, all agreed that changes in policy introduced new requirements (e.g., new EHR, billing and reporting requirements) that interfered with LOCI participation. In order for organizations to engage effectively in implementation strategies like LOCI, a foundation of basic supports and resources is needed. The introduction of such strategic initiatives are held to be a secondary priority after basic organizational needs such as fiscal and operational viability are met. Therefore, understanding the determinants for establishing a foundation for successful EBP implementation in real-world practice is necessary to ensure that implementation strategies are successful and implementation outcomes are achieved. Implications for improving implementation strategies to target these determinants are discussed. Background Despite evidence that diabetic retinopathy screening (DRS) is effective [1] , uptake remains sub-optimal in many countries, including Ireland [2] [3] [4] [5] . Implementation strategies to enhance uptake of interventions like DRS, are not always a good fit for the context in which they are used, or do not align with stakeholder preferences [6] . We report a systematic process combining theory, stakeholder consultation and existing evidence to develop an implementation intervention to increase DRS uptake. Target behaviours were identified through stakeholder interviews (n= 19), and an audit of screening attendance in two primary care centres. Using patient (n=48) and health care professional (HCP) (n=30) interviews, barriers and enablers were coded using the Theoretical Domains Framework and mapped to behaviour change techniques. The APEASE (affordability, practicability, effectiveness, acceptability, side effects, equity) criteria were used to select intervention components. Effectiveness of components and delivery modes was determined through a rapid evidence review. Feasibility, local relevance and acceptability were determined through a collaborative process; consensus meetings with patients (n=15) and HCPs (n=16), and key stakeholder consultations, including the national DRS programme. Three target behaviours were identified; patient registration by HCP, patient consent for the programme to hold their details, and patient attendance. Patient barriers included confusion between screening and routine eye checks, forgetting, and fear of a negative result. Enablers included a recommendation from friends/family or HCPs, recognising screening importance, and ownership over their condition. HCP barriers included the time to register patients impeded or supported by practice resources, and a lack of readily available information on uptake in their local area/practice. Consensus meeting participants agreed HCPendorsed reminders and patient information leaflets were acceptable. They felt certain delivery modes (i.e. in-person, phone and letter) were feasible and equitable, while others may exclude some practices and patients (e.g., text messages). The final intervention comprises reimbursement, training, audit/feedback and electronic prompts for HCPs, and HCP-endorsed patient reminders with an information leaflet. A collaborative process involving multiple stakeholder consultations helped shape an intervention deemed acceptable to both patients and HCPs. The feasibility of intervention delivery in real world primary care will be evaluated through a pilot trial. Statins can reduce cardiovascular disease (CVD) risk in patients with diabetes (DM), but prescribing often lags behind recommendations. We compared how three increasingly intensive implementation support strategies impacted community health centers' (CHCs) adoption of electronic health record (EHR) clinical decision support tools targeting guideline-concordant statin prescribing in DM [1] [2] [3] . The tools (the 'CVD Bundle') were adapted from a previously successful intervention [4] . In this mixed methods, pragmatic trial, 29 CHCs with a shared EHR were randomized to 3 Arms that received implementation support: 1) Implementation Toolkit (CVD Bundle use instructions; Quality Improvement practice change techniques); 2) Toolkit + in-person training with followup webinars; or, 3) Toolkit, training, webinars, + offered practice facilitation. All study CHCs also identified a Champion to oversee related clinic activities. Statin prescription rates were compared across Arms, and with those in >300 additional CHCs which received no implementation support, a non-randomized comparison group. Prescribing (per national guidelines) was measured from 12 months pre-intervention through 36 months post-intervention. We gathered qualitative data from the randomized CHCs via on-site observations, interviews, and phone calls. Statin prescribing increased pre-to post-intervention for all Arms; only Arm 2 demonstrated a statistically significant change relative to comparison CHCs. Prescribing rates improved more in the study CHCs (7%, 8%, and 5% for Arms 1, 2 and 3 respectively) than the comparison CHCs (3%). These differences were not additive -CHCs that received more intensive implementation support did not have greater improvements in prescribing rates. Qualitative data suggest numerous clinic-and intervention-level factors underlying these results. Implementation strategies were not always applied as planned: the Toolkit was infrequently used, webinar attendance was poor, staff turnover was substantial, and few Arm 3 clinics were able to fully benefit from the offered practice facilitation. This is one of the first studies to directly compare implementation strategies. The strategies employed here were associated with small improvements in the study CHCs' guideline-concordant prescribing. Level of implementation support was less impactful than clinic ability to make changes. Guideline dissemination efforts should evaluate adopters' needs / preferences so that subsequently deployed implementation strategies are well-received. Trial Registration ClinicalTrials.gov NCT03001713 Improving the integration of substance use services within HIV service settings is an important public health concern [1] . To help understand how best to improve the integration of substance use services within HIV service settings, the National Institute on Drug Abuse funded a type 2 effectiveness-implementation hybrid trial entitled the Substance Abuse Treatment to HIV Care (SAT2HIV) Project [2] [3] . This presentation focuses on the SAT2HIV Project's main findings. Using a cluster-randomized design, 39 HIV service organizations and their staff were randomized to either implementation-as-usual (IAU) or IAU plus Implementation & Sustainment Facilitation (IAU+ISF). As part of the IAU condition, staff received training, feedback, and coaching in a motivational interviewing-based brief intervention (BI) for substance use. As part of the IAU+ISF, staff received the IAU strategy, as well as participated in external facilitation meetings with an ISF coach. Within each HIV service organization, eligible and consenting clients were randomized to usual care (UC) or UC plus BI (UC+BI). The analytic sample included 678 clients (82% follow-up rate), nested within 78 BI staff, nested within the 39 HIV service organizations. The preparation-phase outcome was staff time-to-proficiency (i.e., a staff-level measure of the number of days between completing the initial training and demonstrating BI proficiency). Implementation-phase outcomes were: staff implementation effectiveness (i.e., a staff-level measure of the consistency and quality of BI implementation) and client substance use at follow-up (i.e., a client-level measure of past-28 day primary substance use). The ISF strategy reduced time-to-proficiency (β = -.66), but this reduction was not significantly less (p < .05) than what was achieved by staff in the IAU condition. However, the ISF did significantly improved implementation effectiveness (β = .73, p < .001) beyond what was achieved in the IAU condition. Moreover, the ISF strategy did significantly improved the BI's effectiveness for reducing client substance use (β = -2.25, p < .05). Training, feedback, and coaching was sufficient for helping staff demonstrate proficiency in a motivational interviewing-based BI for substance use. However, the ISF strategy was found to help significantly improve implementation effectiveness and help significantly reduce client substance use. Background Despite a growing body of evidence of implementation strategies for evidence-based care, a lack of sufficient detail often impedes successful reproducibility and adequate evaluation of their efficiency [1] . Development and specific description of operational and reproducible strategies are crucial to efficiently and sustainably promoting uptake of evidence-based practice. In our effort to design a sustainable cervical cancer screening program in Iquitos, Peru, we developed the Integrative Systems Practice for Implementation Research (INSPIRE) Model, a multifaceted strategy that blends together existing theoretical frameworks and defines specific tools for use at each phase. INSPIRE is a participatory, iterative process involving four phases: system understanding, finding leverage, acting, and learning/adapting. Mixed methods are used to create the shared understanding of the screening system and to facilitate identification of leverage points for change. A systems modeling tool was designed to compare alternative screening systems to facilitate the decision-making process in a design workshop setting and working groups were formed to design new system processes. Through phases 1-3 of the INSPIRE model, we engaged more than 90 multi-level stakeholders in the design of a new and improved screen and treat system. Elaboration of system process maps through triangulation of the mixed-methods data served to create a shared reference of the current system in participatory discussions. Significant leverage opportunities were identified, including reducing fragmentation, inefficiency, and a lack of standardization to increase women's acceptability of screening and adherence to continuum of care. A variety of interventions were evaluated and ultimately, stakeholders recommended adoption of HPV testing/self-sampling to increase coverage and ablative treatment of all HPV-positive women to reduce loss to follow up. Continued success in engagement of stakeholders in shared decision making, including current development of a detailed implementation plan using similar user-centered design, suggests that using a SPF in designing implementation strategies increases a sense of ownership in the process, which may lead to more sustainable screening programs in LMIC compared with 'top-down' approaches. [1] [2] . School-based health centers (SBHCs), a comprehensive service delivery model integrating physical and MH services within school settings, reduce healthcare access barriers by functioning as medical centers for children in low-income areas. While many SBHCs in the U.S. offer some type of MH service, not all centers are equipped to provide needed MH services. MH service variations may be attributed to state-based policies, including funding, oversight support and standards. These outer contextual factors are thought to influence MH service provision by contributing to expansion and sustainment of services over time [3] [4] [5] [6] [7] . This study aimed to examine how state-based outer contextual variables influence the number of SBHC-reported MH services over time. The Implementation barriers exist at all levels of service provision within an organization, yet implementation is ultimately dependent on individuals [1] . Converging lines of research have demonstrated that individual beliefs and attitudes are associated with implementation outcomes [2] [3] . Active-implementation strategies targeting individuals can be effective for preventing implementer drift, yet they occur after implementation is underway. Pre-implementation strategies occurring prior to uptake may be effective in aligning beliefs and attitudes resulting in positive shifts in individuals' contemplation and intention for implementation [4] . Historically, pre-implementation strategies have produced low implementation outcomes, especially when lacking a strong theoretical foundation [5] . The purpose of this study was to collect stakeholder feedback on the development of a blended preimplementation strategy, Beliefs and Attitudes for Successful Implementation in Schools for Teacher (BASIS-T), to precede an evidencebased training in classroom management. Twenty-two teachers and support staff from three Midwest school districts of diverse urbanicity engaged in a 3.5 hour demonstration of BASIS-T, which is grounded in the Theory of Planned Behavior [4] , thus targeting teachers' attitudes, social norm perceptions, and self-efficacy beliefs. Throughout the demonstration, teachers rated each segment for its acceptability and impact on shifting beliefs and attitudes. Participants completed pre-and post-ratings of their own beliefs, attitudes, and intentions, engaged in a nominal group process to elicit feedback for revising the strategies, and answered open-ended questions. Participant feedback from nominal group processes highlighted modifications to the pre-implementation strategy to improve its impact on beliefs, attitudes and implementation. Participants identified a need for more evocative and engaging activities to better encode the importance of EBP implementation, bolster their self-efficacy, and address social norm perceptions. Average ratings indicated BASIS-T content was highly impactful and acceptable. Relatively lower-rated segments were considered for revision. Pre-implementation strategies represent potentially useful techniques for aligning providers' beliefs and attitudes prior to implementation to facilitate better adoption. Stakeholder feedback is an effective method for informing the development of these strategies. The results of this demonstration study provided several recommendations and guidelines for how to build effective, school-based preimplementation strategies to boost EBP adoption. that the strategy is compelling and easy to use; and (b) strategy effectiveness, to ensure that the strategy influences its targeted mechanisms of action. This presentation will present findings from a project that designed and tested a brief, multifaceted online training and post-training consultation strategy to target each strategy's putative mechanisms of action and support measurement-based care (MBC) practices among school-based mental health clinicians. Iterative development of the online training and post-training consultation strategies involved gathering stakeholder input via four rounds of usability testing and two group cognitive walkthrough sessions with representative clinician users. This culminated in randomized trial in which 77 geographically diverse school-based mental health clinicians were randomized to (1) implementation as usual (IAU; no training or consultation, n = 40), or to online training plus one of three consultation dosages: (2) 2 weeks, (3) 4 weeks, or (4) 8 weeks. Consultation included live consultation video calls (once every two weeks) and asynchronous message board discussion. Following training, training mechanisms (knowledge, attitudes, skill), consultation mechanisms (collaboration, responsiveness, accountability), and self-reported clinician MBC practices were tracked for 16 weeks. Preliminary analysis (multilevel modeling) showed that online training led to an immediate increase in MBC knowledge relative to controls (β= .06, p<.05). Following consultation, participants demonstrated greater growth in self-reported MBC skills (β=.028, p< 0.01) and attitudes (e.g., perceived benefit of MBC, β=.028, p<0.05) and superior MBC practices (e.g., use of standardized and individualized assessments, β=.013, .032, respectively, p<0.01). Clear consultation dosage effects have yet to emerge from preliminary analyses with 16 (of 32) weeks of follow-up data. It is possible that the consultation groups may become more disparate with longer follow-up. Few studies have examined implementation strategy mechanisms of action. The current findings suggest that the online training and consultation package influenced many of its target mechanisms and also lead to higher MBC practices among school mental health clinicians than IAU. Thus far, preliminary results suggest that shorter durations of consultation may be comparable to longer durations. Service cascade models move individuals across systems through a sequence of screening, assessment, referral, treatment, and monitoring activities. Successful implementation depends on strong collaboration and change across systems, but these models have received limited empirical attention. This case study examines fidelity of a cascade model implemented across child welfare and mental health systems (intended to improve children's access to specialty mental health care), and identifies collaboration strategies and challenges at each stage. Fidelity to initial mental health screening and assessment was high and attributed to service co-location, collaborative workflow planning, and linked data systems. However, fidelity to referral/treatment components was low and associated with case planning challenges, contract disruptions, and workforce shortages. Our findings suggest that fidelity breakdowns at any point in the service cascade can negatively affect clients' access to services, especially during key service transitions. Implementing these models likely depends on cross-system collaboration approaches that align front-line practice and agency operations at each stage of the model. Background Strategies to implement evidence-based practices consume scarce resources and incur costs. Although critical for decision makers with constrained budgets and limited resources, such resource use and cost information are not typically reported. This is at least partly due to a lack of clearly defined and standardized costing methods for use in implementation science. This study presents a pragmatic approach to systemically estimating resource use and costs of implementation strategies using a well-established business accounting system. The method is demonstrated by estimating the first-year implementation costs of a group-based cognitive behavioral therapy program for students with externalizing disorders in six Philadelphia schools. Time-driven activity-based costing (TDABC) is combined with the existing guidelines for implementation strategy specification and reporting. Implementation protocol, measures, project notes and key personnel interviews were used to map the implementation process by specifying the strategies with their actors, specific action steps, temporality, and dose. The dose is defined for each action step as the person-hours invested in its completion, and accounts both for frequency and intensity of the action step. Implementation strategy dose is the sum of person-hours on each action step that constitute the strategy. Project resources are identified, and the price per unit person-hour is calculated as per the TDABC. Costs of action steps, strategies and implementation project is reported from a payer perspective. Estimated total cost was $63,842; $10,640 per school. The largest cost incurred was for the communication efforts ($30,691), which involved in-person meetings, phone calls, and email exchanges. Next largest costs were for the stakeholder engagement, consultation/coaching, and supervision, which comprised 19%, 15%, 12% of total costs, respectively. Assessment/evaluation and training constituted the smallest costs, at 4% and 3% respectively. This method allows for inclusion of implementation costs in the efforts of strategy specification, tracking and reporting. It serves as a pragmatic tool to operationalize the conduct of the implementation activities, track the resources consumed and estimate associated costs. It could facilitate the routine incorporation of cost analysis and economic evaluations into implementation research. It provides granular cost information which could be used to identify and address the inefficiencies in the implementation process. Background Implementation science and social entrepreneurship share a common objective of maximizing the uptake of new practices and innovations. Both disciplines offer complementary tools which could be leveraged to improve the ultimate impact of innovations, their scale-up, and sustainment. For example, entrepreneurship's focus on market assessment, financial outlook, etc. can be coupled with implementation science use of data, models, and methods. However, communication between these fields has been limited. To explore how these complementary groups might learn from each other, this paper presents data about how implementation researchers understand and respond to the kinds of questions entrepreneurs ask about innovation roll-out. We conducted one-on-one cognitive interviews [1] with 15 dissemination and implementation researchers recruited from training programs in implementation science to capture their ability to understand and answer key questions from entrepreneurs and refine a tool to support dialogue. Participants were guided through the tool item-by-item. Prompts from the interviewer helped identify problems with question clarity and comprehension. A summary of the responses was developed to identify problematic elements and identify revisions necessary to improve clarity. The discussions tapped the researchers' perception of demand for the innovation, estimates of benefit, knowledge of who would pay, sustainment challenges, and comfort working with business and entrepreneurial partners. Results Implementation researchers understood and were able to answer questions about the problem their innovation seeks to solve, their roll-out plans, and stakeholders and team members involved. They reported the following types of questions as easy to understand but hard to answer: who would pay for the innovation, numbers of people who would benefit, and how to sustain the innovation once adopted. Researchers varied in their comfort with technology supports and business/entrepreneurial partnerships. Entrepreneurial partnerships can provide important supports to successful implementation and sustained delivery of interventions, including technology supports, market analysis, and financial investment. Implementation researchers understand the types of questions entrepreneurs pose about their projects, but find those questions difficult to answer, suggesting the importance of establishing interface between these fields. Tools to prepare researchers to interact with entrepreneurs could take these factors into account to facilitate communication between audiences. Background If diffusion is "letting it happen," and dissemination is "helping it happen," implementation is the business of "making it happen" [1] . To make change happen within large systems, relationships between implementation scientists, intermediaries, and system leaders are created. These relationships, which serve as the vehicle for translating science into practice, are often understated and under examined. This panel presents two initiatives designed to implement best practices within a large child welfare service system focused on all three perspectives: system leadership, presented by Kimberly Giardina, MSW; implementation science, presented by Greg Aarons, PhD., and intermediary implementation, presented by Brent Crandal, PhD., and Melissa Bernstein, PhD. The two system changes that will provide context for this panel include, first, the Advancing California's Trauma Informed Systems (ACTS) Initiative. ACTS was developed to create collaborative partnerships with childwelfare county leaders across California to advance trauma-and evidence-informed system change through implementation planning, followed by technical assistance, training, outcome monitoring, and sustainment planning. Second, the Community-Academic Partnerships for the Translational Use of Research Evidence (CAPTURE) project explores how research can be used to improve child welfare policy, programs and practices through a partnership between the University of California at San Diego (UCSD) and the County of San Diego, Health and Human Services Agency, Child Welfare Services. Using a mixed-methods research design, CAPTURE examines the processes that shape instrumental and conceptual use of research evidence (URE) and investigates how change mechanisms influence URE. Guided by the Exploration, Preparation, Implementation, Sustainment (EPIS) implementation framework, we will highlight the translation of implementation science into concrete strategies used to create change within a child welfare system, including leadership engagement, team development, data utilization, stakeholder involvement, quality improvement methods, and the use of consultation. Tailoring implementation strategies to site-specific determinants (barriers and facilitators) is a promising way of improving implementation and clinical outcomes [1] . However, more empirical work is needed to determine whether tailored approaches to implementation are more effective than standard multifaceted strategies, and to develop optimal methods for linking implementation strategies to identified determinants [2] . The NIMH-funded "Implementing Measurement-Based Care (iMBC) for Depression in Community Mental Health" study addressed these gaps by comparing a standard multifaceted strategy to a tailored approach to implementation in a dynamic cluster randomized trial [3] . This study draws upon data from the intervention group (i.e., tailored condition) of the iMBC study to 1) describe how clinics tailored implementation strategies to site-specific barriers, and 2) evaluate the extent to which the implementation strategies they used could plausibly address identified determinants. The six clinics in the tailored condition were compared to each other using a multiple case study design. Descriptions of each clinic's approach to tailoring, the determinants they attempted to address, and the implementation strategies they used were derived from recordings and notes from implementation team meetings across five months. Determinants were deductively coded using the Consolidated Framework for Implementation Research (CFIR) [4] and implementation strategies were deductively coded using an established taxonomy [5] . Plausibility of linkages between barriers and strategies was determined in two ways. First, two authors independently rated plausibility using a 5-point Likert scale. Second, each strategy-determinant linkage was compared to the results of a previous study that established preliminary linkages between CFIR determinants and implementation strategies [6] . Four of the six clinics prioritized barriers identified quantitatively during the needs assessment phase of the study, and explicitly selected implementation strategies to address them. Clinics reported using an average of 39 implementation strategies, which were categorized into 26 of the 68 discrete implementation strategies identified by Powell et al. [7] . Plausibility of the linkages between barriers identified and strategies selected will also be presented. This study contributes to implementation science and practice by highlighting strengths and weaknesses of community mental health clinics' approaches to tailoring implementation strategies, and by suggesting ways in which methods for tailoring could be improved. Trial registration: ClinicalTrials.gov NCT02266134 Evidence-based public health translation of research to practice is essential to improving the public's health. Adaptation of evidence-based interventions (EBIs) to promote health and prevent disease is an essential process for implementation and dissemination research and practice. Challenges faced in practice include identifying EBIs that are suitable for new populations and settings and adapting them to fit needs. A recently published scoping review by our team summarized 13 adaptation frameworks and identified common steps to guide the adaptation process [1] . We also conducted a systematic review of adapted interventions and described reasons for adaptation according to previously identified categories [2] [3] . These studies have shown that while many examples and adaptation models exist, they provide only limited guidance on how to make decisions about what should change and what should remain the same. We present a framework based on the Intervention Mapping protocol that provides step-by-step guidance on selection and adaptation of EBIs [4] [5] . The process includes the development of a logic model of change (LMC) based on the community assessment. An LMC is a diagram of what that describes the relationship between changes needed in determinants, behavior and environment to bring about improvements in health and quality of life. The LMC is then compared with the basic features of available EBIs (determinants addressed, resources needed, etc.) to assess potential fit with the new population or setting. Following selection, planners further examine the internal logic of the EBI including the behaviors and environmental conditions that were the targets of the original EBI, the determinants addressed, and the change methods and/ or strategies used. Planners then compare the EBI features to the LMC to determine what needs to be adapted while maintaining change methods used in the original intervention since these often represent the intervention's core elements. We describe the development and testing of an online tool (I M ADAPT) for finding and adapting evidence based interventions for cancer control. We also describe how we are applying Intervention Mapping and the online tool in a project to improve the use of interventions from the National Cancer Institute's Research Tested Intervention Programs (RTIPs) resource. Youths in the child welfare (CW) system face a myriad of poor outcomes with regard to social/emotional development and behavioral health. While there is research evidence relevant for CW services, integration and use of such evidence in policy, planning, and service delivery is limited. The Community Academic Partnership for Translational Use of Research Evidence (CAPTURE), is a communityacademic partnership to increase use of research evidence in policy, programs, and practice. Guided by the Exploration, Preparation, Implementation, Sustainment (EPIS) framework, CAPTURE engages outer context system level stakeholders, inner context organizational stakeholders and academic partners in a bidirectional partnership. The aims of CAPTURE are: 1) To establish and test the use of a partnership model to increase use of research evidence (URE) in policy, program, and practice, and 2) To identify key mechanisms by which CAPTURE operates including -but not limited to -cultural exchange between researchers and community partners, leadership and organizational change, and use of quality improvement methods to test and put goals into practice. Mixed-methods will provide a detailed and nuanced understanding of the process of collaboration and URE in a large public sector service system, and describe the complexity of instantiating URE across system and organization levels. Quantitative data assessing cultural exchange, leadership and climate for URE are being collected by online surveys of providers and stakeholders. Qualitative methods include interviews, focus groups, observation of CAPTURE meetings, and document review. Community-academic partnerships are a promising approach to improving collaboration and integrating research evidence in decision making for policy and practice. A better understanding of ways to develop and establish community-academic partnerships can help to promote their use in other settings. Developing a strategic implementation research plan within an integrated healthcare system Sara J. The US Department of Veterans Affairs (VA) Quality Enhancement Research Initiative (QUERI) funds quality improvement and program evaluation studies to support implementation and evaluation efforts needed to improve healthcare for our nation's veterans [1] . QUERI funds programs that focus on areas of care and/or implementation strategies. The Behavioral Health QUERI program, one of 15 currently funded programs, has developed a structured method for strategic planning to match program priorities and implementation research projects with priorities of stakeholders and the healthcare system. Embedded with the organizational structure of the Behavioral Health QUERI are a Stakeholder Council (SC) comprised of veterans of all eras, family members, providers, and local and regional leadership; and a Strategic Advisory Group (SAG) comprised of national healthcare leaders inside and outside of VA and veteran representatives. The strategic planning methods are iterative and include stakeholders from multiple levels of the national health care system (e.g., providers, leadership at various levels, veterans, and subject matter experts). The strategic planning methods include identification of priorities of the healthcare system, creation of a planning committee, development of a key stakeholder interview, and identifying key informants. Stakeholder interviews are conducted across multiple layers of the organization (e.g., veterans, local medical center, network level, and national leadership). Qualitative data are synthesized across key question domains and findings are matched to existing initiatives and/or research opportunities by the planning committee. Priorities and potential projects are identified and prioritized with the SC and SAG. These are vetted with a sample of the initial key informants. Behavioral Health QUERI is currently conducting strategic planning. VA priorities have been identified by the SC and SAG. Stakeholder interviews have been completed with three network leaders and three national leaders (mental health operations, suicide prevention, and technology). Results of themes will be presented, with a focus on how to conduct strategic implementation research planning in collaboration with a variety of stakeholders. Strategic implementation research planning is critical to developing a research plan that both helps the healthcare system move forward in its goals and advances implementation science. The intersection between the various perspectives is critical in influencing the extent to which implementation science can be translated into implementation practice. At this juncture of the development of implementation science it is critical that we develop the capacity to integrate the knowledge from each perspective to ensure that implementation science achieves its ultimate goal of "bridging the gap". Collaboration will promote the awareness, understanding and ability to consider all perspectives whilst further developing the science and supports for application of implementation science. Having explored the "constructive tension" between implementation researchers/intermediaries/purveyors/implementing organisations at GIC 2017, at which themes were identified that reflected the challenges between implementation science and implementation practice, the themes were furthered discussed at Global Evidence and Implementation Symposium, 2018. Greater insight was generated into the challenges for each perspective and how they might be addressed. The panel proposed for SIRC 2019, with active participation from the attendees, will build on the previous discussions. This participatory discussion will focus on solutions, exploring and developing potential next steps to address identified barriers, and build on existing partnerships across perspectives. The session will open with a brief reference to information gathered at the previous two sessions. Each panelist will then offer thoughts from their perspectives on what might promote greater integration between each perspective. Following the brief presentations, the floor will be opened for a facilitated discussion framed around three questions: 1) What are the actions we can take to increase the collaboration between the various contributors to implementation science and practice? 2) What are the barriers you experience that might interfere with these actions? 3) What are the opportunities/enablers you could use to promote collaborative development of implementation science and practice? The session will close with a summary from the discussant. The objectives for the panel discussion include: 1) Increasing awareness of the needs, challenges and opportunities for collaboration across perspectives 2) Identifying priorities for research and partnerships for action 3) Confirm 3 areas for action for 2019 -2021 This is a single theme symposium with brief presentations from the panelists followed by open-floor discussion. [2] and uses a comprehensive mixed methods approach including analysis of routinely collected hospital data using a BACI design [3] , a quality of life patient survey, workforce interviews and costings data. The overall aim of the HLCC evaluation is to determine if flexible funding enables health services to develop and implement alternative models to inpatient acute care that provide better experiences and outcomes for patients with chronic conditions, at equal or lower cost. This session will provide an overview of HLCC and aims to describe key challenges and learnings of the trial from three different perspectives: DHHS -policy developers/funders: Implications of a pragmatic approach to implementation will be discussed, including the pros and cons of having implemented the trial at several health services and allowing tailored intervention models. Health Services -implementers: Results from qualitative focus groups assessing workforce perceptions of key barriers and enablers to implementation will be presented. CSIRO -evaluators: The feasibility of evaluation frameworks in a data driven environment will be discussed, including how data lags, data availability and outcome measures impact reporting and short-term policy decisions. The Integrating evidence-based practices into clinical care is essential for mission readiness. However, research demonstrates, that despite the availability of effective clinical interventions, service members frequently do not receive guideline-concordant care that reflects the uptake of the most recent scientific advancements [1] . To improve the access, quality, effectiveness, and efficiency of psychological healthcare for veterans and service members, the Department of Defense (DoD) established the Practice-Based Implementation (PBI) Network. The PBI Network engages healthcare administrators and providers in implementation pilots to evaluate the feasibility and acceptability of DoD-wide implementation of an evidence-based clinical practice, and develops solutions to any implementation challenges that could impede successful uptake and sustained use of the practice change. The purpose of this presentation is to review the PBI Network's process for mapping implementation strategies to barriers in the Military Health System (MHS). This presentation will review a case study showcasing the PBI Network's efforts to partner with DoD leadership, clinicians, and researchers to enhance access to evidence-based practices in the MHS. The case study will demonstrate the PBI Network's use of Intervention Mapping (IM) [2] guided by the Consolidated Framework for Implementation Research (CFIR) [3] and the Integrated Promoting Action on Research in Health Services (i-PARIHS) [4] frameworks to develop an implementation program that strategically addresses the unique challenges facing military health providers and leaders. Time constraints, multiple competing demands, and limited resources [5] [6] are significant barriers to the uptake and adoption of evidence-based practices in the MHS. Many implementation strategies can be leveraged to overcome these barriers and effectively implement evidence-based practices in the MHS. Implementation of evidence-based intervention is a complicated process. It has been suggested that implementation strategies should be selected and tailored to address the contextual needs of specific efforts; however, there is limited guidance as to how to do this. The PBI Network's experiences provide insight into methodologies for mapping implementation strategies to address the complex barriers to implementation in the MHS which may have broad application to other similar complex healthcare systems. Optimizing public health interventions by using mechanistic evaluations: a case example from a school-based physical activity implementation trial Hopin Lee 1 , Nicole Nathan 2 , Kirsty Hope 2 , Luke Wolfenden 2 1 University of Oxford, Oxford, England, UK; 2 University of Newcastle, Newcastle, New South Wales, Australia Correspondence: Hopin Lee (hopin.lee@ndorms.ox.ac.uk) Implementation Science 2020, 15(Suppl 2):A49 Background Public health implementation strategies often comprise of multiple components that are combined and delivered as a complex intervention [1] . Within a complex social-ecological system, there are multiple mechanisms by which an intervention could have its effect on the distal implementation outcome. To successfully implement health policies, the implementation strategy must collectively have a causal effect on the mechanisms that drive successful implementation [2] . Understanding these mechanisms are critical to optimizing and scaling complex implementation strategies [3] . The study aim was to understand the mechanisms of a complex implementation strategy on increasing physical activity minutes scheduled by school teachers in New South Wales, Australia [4] . We conducted a causal mediation analysis [5] [6] of a cluster randomised controlled trial conducted in 62 primary schools. Schools were randomly allocated to receive either a complex implementation strategy that included; obtaining executive support, provision of tools and resources, implementation prompts, reminders and feedback; or usual practice. The primary trial outcome was the average minutes of physical activity scheduled by teachers across the school week at 12 months. We estimated path specific effects and average indirect and direct effects of the implementation strategies through four putative mechanisms. The  Although the implementation strategy caused meaningful improvements in scheduled minutes of physical activity, this effect was not mediated by targeted mechanisms. Future research should explore the role of other potential mechanisms and evaluate system-level mechanisms informed by an ecological framework. How policy mandates for evidence-based practices filter into clinical routines: a mixed methods study Lorella Palazzo 1 , Peter Mendel 2 , Kelli Scott 3 , Cara C. Lewis Background Federal and state policies mandating evidence-based practice (EBP) implementation in community mental health settings are increasingly common. Measurement based care (MBC), the use of progress/ outcome monitoring measures to guide treatment [1] , is one such EBP mandated for use. It is crucial to understand the process by which mandates are received by organizations, as contextual factors may influence mandate implementation success. The goal of this study is to employ mixed methods to characterize how a mandate plays out in community mental health settings that implement MBC using the Patient Health Questionnaire-9 (PHQ-9). We utilized data from a cluster randomized trial comparing tailored vs standardized approaches to implementing the PHQ-9 in community mental health settings in two states [2] . Qualitative data were collected through semi-structured interviews with community mental health clinicians (N = 36). Interview questions covered MBC domains (e.g. clinicians' attitudes towards and usage of MBC practices with the PHQ-9). Quantitative data were obtained from clinician surveys and included demographics and contextual constructs (e.g. norms, structures, processes) known to influence implementation. Data have been collected and are undergoing case-based analysis that relies on: 1. Qualitative thematic analysis to capture clinician descriptions of mandate implementation; 2. Cross-case analysis of qualitative and quantitative data to derive site-level indicators; 3. Qualitative Comparative Analysis (QCA) to identify contextual factors associated with mandate implementation outcomes. [3] Conclusions Organizations implementing policy mandates for EBPs should consider how site-specific contextual drivers may interact with implementation efforts, affect mandate outcomes, and need to be addressed through targeted implementation strategies. The fields of implementation science and knowledge translation have evolved somewhat independently from the field of policy implementation research, despite calls for better integration [1] . As a result, implementation theory and empirical work do not often reflect the implementation experience from a policy lens nor benefit from the scholarship in all three fields. This means policy makers, researchers and practitioners may find it challenging to draw from theory that adequately reflects their implementation efforts. We developed an integrated theoretical framework of the implementation process from a policy perspective by combining findings from these fields using the critical interpretive synthesis method [2] . We began with the compass question: how is policy currently described in implementation theory and processes and what aspects of policy are important for implementation success? We then searched 12 databases as well as grey literature and supplemented these documents with other sources to fill conceptual gaps. Using a grounded and interpretive approach to analysis, we built the framework constructs and used our findings to consider improvements to existing theory. A total of 7850 documents were retrieved and assessed for eligibility and 34 additional documents were identified through other sources. Eightytwo unique documents were ultimately included in the analysis. Our findings indicate that policy is described as: 1) the context; 2) a focusing lens; 3) the innovation itself; 4) a lever of influence; 5) an enabler/facilitator or barrier; or 6) an outcome. Policy actors were also identified as important participants or leaders of implementation. Our analysis led to the development of a two-part conceptual framework, including process and determinant components. We also used our findings to modify the Interactive Systems Framework for Dissemination and Implementation [3] . Finally, we provide an example of how the framework can be applied using a policy implementation case from Ontario, Canada. This framework begins to bridge the divide between disciplines and offers a new way of thinking about implementation processes at the systems level. Integrating research, policy, and practice to implement the largest suicide risk identification strategy in a United Research suggests that a significant number of individuals who died by suicide were not identified as psychiatric patients nor were they receiving mental health care; rather, they were often seen in primary care, ED or other medical settings before their death [1] [2] [3] . In response to these findings and a Joint Commission Sentinel Event Alert [4] , in October 2018, the Department of Veterans Affairs (VA) launched the VA Suicide Risk Identification Strategy (VA Risk ID), the largest population-based screening and evaluation strategy in any United States healthcare system. Successful implementation of VA Risk ID relies on collaboration between researchers, policy makers, and supervisors and providers within the field. Consistent with the Evidence-Based System for Innovation Support Logic Model [5] , the VA Risk ID implementation team combined tools, training and technical assistance (TA) with a quality assurance measure to develop a robust support system for implementation. Proactive TA is delivered via weekly conference calls (~250 attendees/week) and a support email address (~250 emails/month). A SharePoint site which houses a variety of tools developed for VA Risk ID is also utilized. The team also conducted a webinar series, offering training on the overall strategy and practice components, which was converted into VA online learning system trainings. A fallout report was developed for quality assurance, which provides information about patients who did not receive indicated levels of the screening and evaluation process. The above strategies allowed the implementation team to get real-time feedback from the field, which was then communicated directly to VA policy makers on a weekly basis. As a result, major alterations have been made to the VA Risk ID implementation timeline and requirements. The presenters will discuss how VA Risk ID implementation serves as a rich and useful example of how research, policy, implementation science and practice inform one another to result in the successful implementation of the largest suicide risk screening and evaluation strategy in any United States healthcare system. The role of implementation science in achieving health equity Background Inequities in healthcare are unfair differences between populations in the access, use, quality and outcomes of care. These inequities are persistent, detrimental and costly. Implementation science has great potential to improve the health of communities and individuals that experience disparities. Equitable implementation occurs when strong equity components (including explicit attention to culture, history, values, and needs of the community) are integrated into the principles and tools of implementation science to facilitate quality implementation of effective programs for a specific community or group of communities. This presentation includes two approaches to using implementation methods and frameworks to address healthcare inequities. The first approach uses Proctor et al. [1] framework to reframe five elements of implementation science to: 1) focus on reach from the very beginning; 2) design and select interventions for vulnerable populations with implementation in mind; 3) implement what works and develop implementation strategies that can help reduce inequities in care; 4) develop the science of adaptations; and 5) use an equity lens for implementation outcomes. The second approach discusses three innovative implementation method paradigms to improve scientific and health equity: 1) making efficient use of existing data by applying epidemiologic and simulation modeling to understand what drives disparities and how they can be overcome; 2) designing new research studies that include, but do not focus exclusively on populations experiencing disparities in such areas as cardiovascular disease and co-occurring mental health conditions; and 3) research that focuses exclusively on populations that have experienced high levels of disparities. Conceptual approaches will initiate a much-needed dialogue on how to critically infuse an equity approach in implementation science to proactively address healthcare inequities. These approaches raise numerous barriers for implementation research and how they can exacerbate disparities [2] . This work extends examples in behavioral health [3] . Discussion will center on themes for taking action to ensure implementation science amplifies equity. Themes were identified through structured facilitations with 21 researchers and include: employ strategies and build structures that elevate equity concerns; shift funding incentives to value practice expertise and questions; and promote exchanges between researchers and community members. Economic evaluation of implementation strategies: making the business case for implementation science in the real world Amy M. Kilbourne Background Implementation strategies are methods used to help provider organizations deploy evidence-based practices. To date, few studies have compared the effectiveness of different implementation strategies, and rarely have they assessed economic impact. Estimating costs of implementation strategiesand comparing those costs to value generatedis crucial if health care providers are to make informed decisions about investment in specific strategies to improve uptake of effective practices. We describe two studies involving economic evaluations of the Replicating Effective Programs (REP) implementation strategy. Both studies had adaptive designs in which sites that did not respond to 6 months of REP were randomized to receive additional implementation support (i.e., Facilitation). First, Re-Engage was an adaptive implementation trial comparing REP alone to Enhanced REP (added External Facilitation) to enhance the uptake of a brief care management program for Veterans with serious mental illness among a national cohort of 88 VA facilities. Second, the Adaptive Implementation of Effective Programs Trial (ADEP T) was a cluster-randomized sequential multiple assignment randomized trial (SMART) trial that compared REP only to REP adding External Facilitation or External+Internal Facilitation to improve the uptake of a collaborative care model for mood disorders across 57 community practices in Michigan and Colorado. In the first study, the rate of Re-Engage uptake (number of attempted patient contacts) was greater for enhanced REP sites compared with standard REP sites (41% versus 31%, p=.01). An initial cost analysis found that the additional time cost of Facilitation was 7.3 hours per site, or~$2500 per 6-month dose of Facilitation. In ADEPT, patients at sites receiving External Facilitation alone compared to External+Internal Facilitation had improved SF-12 and mood symptom scores and higher odds of receiving collaborative care. The added costs of Internal Facilitation did not lead to greater implementation value, suggesting that REP plus External Facilitation was the most cost-effective combination of implementation strategies. We discuss strengths and limitations of the economic evaluations performed in these studies. We also highlight how adaptive and SMART designs are practical ways to assess the costs of implementation strategies and inform more efficient use of these strategies. The discrete choice experiment (DCE) is a stated preference technique from health economics for eliciting individual preferences over hypothetical alternative scenarios. This dynamic approach can be used to systematically measure the health preferences of various stakeholderssuch as patients, providers, and administratorsand thus engage those stakeholders' perspectives in decisions about investing time, money, and resources into implementation. The purpose of this presentation is to discuss the application of DCEs as a stakeholder engagement strategy to inform implementation of evidence-based interventions in health. This presentation will cover findings from a recent systematic review by Salloum et al. [1] reporting on DCE applications in implementation research. In addition, the presentation will include examples of DCE applications from cancer prevention and control (e.g., tobacco control and HPV vaccination) that vary by application type. The presentation will discuss considerations for designing and conducting DCEs in implementation research at each of the following stages: (1) identify and characterize alternative scenarios; (2) experimental design to determine choices; (3) data collection; and (4) data analysis and interpretation. Results DCE applications in implementation research can be categorized into four types: (1) characterizing demand for therapies and treatment technologies; (2) comparing implementation strategies; (3) prioritizing interventions; and (4) incentivizing providers. An example of each application type will be presented. A variety of stakeholders can be engaged using DCEs, including healthcare providers, patients, caregivers, and healthcare administrators. DCEs can be conducted across settings and contexts, including clinical settings (inpatient and outpatient), community-based settings, and at the policy/population level. The use of DCEs to inform implementation of health interventions has been growing in recent years. As DCEs are more widely used in health-related assessments, there is a wide range of applications for them in the area of stakeholder engagement. Using DCEs can inform stakeholder decision making and support successful investment into implementation of health interventions. Background For over 15 years, VA has implemented national dissemination efforts to train providers in evidence-based addiction and mental health practices (EBPs). VA mandates EBPs and supports their implementation with substantial investment in infrastructure to support quality improvement (e.g., incentivized VA-wide quality measures), yet only 3-28% of the patient population receives the highest quality care. To improve EBP access, the National Center for PTSD developed a simulation-learning program designed to help frontline teams identify locally calibrated EBP improvement strategies [1] . We piloted participatory system dynamics (PSD) for improving EBP reach based on its effectiveness in business and engineering [2] [3] . PSD synthesizes engagement principles and state of the science technologies for understanding and changing systems. As a systems science method, PSD demonstrates how causal system properties vary as a function of local resources (e.g., financial, personnel). Over the last four years, in partnership with patient, provider, and policy-maker stakeholders, we co-developed a PSD program entitled Modeling to Learn (MTL). MTL supports multidisciplinary frontline teams of providers to address high priority areas (e.g., Suicide Prevention, Access to Care, Opioid Misuse, PTSD) by conserving local staff time in simulation learning models that evaluate and compare implementation scenarios. Results MTL helped two pilot clinics increase EBP reach with existing local staff resources. Preliminary statistical process control analyses indicate pilot clinics demonstrated a three standard deviation increase in EBP reach and maintained improvement for 12 and 8 months, respectively. We will present example simulation experiments for different VA clinics, highlighting how simulation helps staff optimize local staff resources to meet patients' needs. Most cost analysis in implementation research focuses on the costs of EBP adoption. But, VA-adopted EBPs and VA budgets facilitate/constrain the resources needed to expand reach. We posit that MTL created greater consensus about change (front-end optimization) and guided more effective investment decisions within local system resources (back-end optimization). Additional study of the MTL national rollout is underway: a multisite cluster randomized trial will test the superiority of MTL over audit-and-feedback for its effectiveness improving the reach of EBPs. Mixed-method approaches to strengthen economic and cost research methods in implementation science Alex R. Background Guidance on the costs and economic impacts of implementing evidence-based practices is critical to informing investments in implementation efforts. However, the results of traditional methodssuch as economic evaluations, discrete choice modeling, and participatory system dynamics modelingare limited by a remaining "qualitative residual" of contextual information and stakeholders' perspectives. This residual, which is particularly prevalent in implementation research, cannot be fully captured by the quantitatively-based analyses and models used in these methods. The emergence of qualitative methods for studying economics and costs offers a promising solution. We recommend that researchers maximize their contributions related to economics and costs within implementation science by embracing a mixed-methods research agenda that merges traditional quantitative approaches with innovative, contextually grounded qualitative methods. Such studies are exceedingly rare at present. To assist implementation scientists in making use of mixed methods in this research context, we will present an adapted taxonomy that describes the structure and function mixed-method studies relevant to economic and cost research. We will then illustrate the application of mixed methods in exemplar studies that used economic evaluation, discrete choice modeling, or system dynamics methods to study implementation. The examples presented will emphasize the breadth of qualitative methods for data collection (e.g., interviews, focus groups, site visits, review of records, ethnography) and analysis (e.g., content analysis, thematic analysis, grounded theory, case studies) that can be incorporated into studies of implementation costs and economics. Finally, we will review reporting guidelines for these methods (e.g., Consolidated Health Economic Evaluation Reporting Standards) with an emphasis on how to incorporate mixed methods into existing guidelines. By incorporating qualitative methods, implementation researchers can enrich their research on economics and costs with detailed, context-specific information to tell the full story of the economic impacts of implementation. We will end by providing suggestions for building a research agenda in mixed-method economic evaluation, along with more resources and training to support investigators who wish to answer our call to action. Background Implementation science is shifting from qualifying adaptations as good or bad towards understanding nuances of adaptations and their impact. Existing adaptation classification frameworks are largely descriptive (e.g., who made the adaptation) and geared towards researchers. They do not help practitioners in decision-making around adaptationsis an adaptation likely to have negative impacts? Should it be pursued? Moreover, they lack constructs to consider potentially disparate impact on intervention and implementation outcomes (e.g., whether an adaptation might improve implementation outcomes but weaken intervention outcomes). We consolidated two adaptation frameworks [1] [2] and one intervention-implementation outcome framework [3] . We reviewed each framework to refine constructs and group them into domains. We then coded qualitative descriptions of 14 adaptations from an existing intervention being adapted to a new context to test fit of our framework. To bridge the research-practice gap, we then developed guidance to help practitioners in the field apply this framework to adaptation efforts. Our framework has 3 domains and our applied guidance for each domain is as follows: Criteria for making adaptations: useful in considering whether adaptations will have a positive or negative impact to help decide whether to move forward with the adaptation. Systematic adaptations with a positive valence are more likely to have a positive impact. Impact of adaptations: useful in considering adaptations' impact on intervention outcomes (intervention effectiveness) and implementation outcomes (acceptability, cost, etc.). to help anticipate and mitigate negative consequences of adaptations (e.g., plan for implementation of an adaptation that might improve intervention effectiveness but decrease acceptability). Adaptation Typology: classifies adaptation attributes (e.g., type, nature of adaptation), providing consistency in reporting Conclusions Our guidance takes a consolidated framework developed for research and translates it to be helpful to practitioners. Our guidance helps practitioners "back-up" and re-think adaptations suspected to have negative impacts and helps practitioners think through "ripple effects" and tradeoffs of adaptations to plan accordingly (e.g., put in place an implementation strategy to monitor/boost fidelity if an adaptation is suspect to have positive impacts on acceptability, but negative impacts on fidelity). Striking the right balance: tracking adaptations to communitybased prevention programs to enhance guidance to implementers Brittany The adoption of effective programs is insufficient for achieving positive youth and family outcomes community-based organizations seek; high quality implementation is also critical. However, making decisions about dosage, content, and structure of an evidence-based program as it was originally designed (i.e., fidelity) while adapting to local contexts is challenging and complex, especially under resource strain. Implementers are often left to make these decisions without much empirically-based guidance. We used data from an ongoing, large-scale evaluation of Strengthening Families Program (SFP; a 7-week substance use prevention program with youth 10-14 years old and their parents) implemented in natural contexts across Washington State. Our previous work applied and extended two multidimensional coding systems [1] [2] to 154 implementer-reported adaptations of SFP [3] . Based on these results, we designed a quantitative measure to track the extent to which implementers modified, added, and deleted program content/ processes; the most common types and reasons for adaptations; and the extent to which adaptations proactive or reactive. Preliminary results from 28 SFP implementations show that over half report modifying the program content/processes "a little", but 60% report "not at all" when asked about addition or deletion of content/processes. The most commonly reported modifications were made to games and activities/icebreakers, and the most commonly reported reason was lack of time/competing demands on time. "Need for a more culturally appropriate program" was reported by 24% despite 39% of implementations being delivered in Spanish or bilingually. Planning in advance "some" or "a lot" for adaptations was reported by 37%, whereas 15% reported "some" or "a lot" for making reactive adaptations. These results help describe the adaptations being made and how/ why they are being made. Future analyses will examine links between these dimensions of adaptation and participant engagement, which increasingly is shown to be a critical mediator/moderator between adaptations and program outcomes. Ultimately, this work will help develop a theoretically-and empirically-grounded tool to track real-world adaptations and their impacts, in turn enhancing program implementation guidance on how to strike the right balance between program fidelity and adaptation. Rapid adaptation: making adaptations work for real world systems, services, and science Sarah Cusworth Walker 1 , Michael Graham-Squire 2 1 University of Washington, Seattle, WA, USA; 2 Neighborhood House, Seattle, WA, USA Correspondence: Sarah Cusworth Walker (secwalkr@uw.edu) Implementation Science 2020, 15(Suppl 2):A60 To reach scale, public health agencies and researchers will need to partner in new ways to meet the prevention needs of diverse and dynamic communities. Building from concepts proposed in the Dynamic Adaptation Framework [1] , common elements [2] , and adaptation models [3] , we present preliminary results from a codesign process developed to provide tailored, rapid guidance for delivering more culturally congruent prevention services. We present data from a six-month codesign demonstration project in Seattle, WA between the University of Washington and a local social services agency with over 100 years of delivering social welfare and prevention services. The model is proceeding in four stages with distinct data capture at each phase: 1) Identify areas of strain; 2) Derive Core Elements; 3) Develop guidance; 4) Test acceptability. We present data on the need for adaptation and the feasibility of the codesign model from the 21 facilitator respondents and the feasibility of the codesign process from community and research participants. Strain was assessed through surveys distributed to 21 GGC facilitators. The surveys asked respondents to score each activity in the curriculum for ease of delivery and need for adaptation. Qualitative responses were coded using the theoretical framework of structure and content adaptations [3] . The fidelity of delivery to specific activities within GGC varied significantly, with some activities rarely delivered according to manualized instructions and other always or almost always delivered as written (range of 2.05-4.48 on a 5-point scale with 5 keyed to "always"). Activities rarely delivered as written were more likely to be experiential activities (e.g., group sculpture or scavenger hunt). Activities delivered as intended but rated as poor on cultural responsivity included videos and scripted content delivered by facilitators. Conclusions A number of structural and content adaptations needs were indicated, including the need to address divergent cultural views about some core assumptions of the GGC model. Background Together, We Inspire Smart Eating (WISE) is a nutrition promotion intervention designed for delivery by early care and education teachers. Data from a prior implementation of WISE showed suboptimal fidelity to its four, key evidence-based practices (i.e., hands-on exposure to fruits and vegetables (FV), use of mascot to promote FV, positive feeding practices, and role modeling). We are currently testing strategies to support uptake of WISE. This study presents preliminary findings on the behaviors observed by teachers. A two-arm implementation trial is ongoing in 40 classrooms to implement WISE with a focus on its evidence-based practices. All classrooms are observed on a quarterly basis for fidelity by data collectors trained to 85% reliability. Classrooms in the treatment condition (i.e., enhanced support, N = 17) receive targeted implementation support based on their observed fidelity, which included facilitation. After the first and second quarter of the school year, 5 classrooms from the pool of poorest fidelity performers in the enhanced condition were randomly selected for semi-structured interviews. To date, the second quarter of data collection, 6 months of enhanced support, and both rounds of interviews are complete. Facilitators derived types of adopters and resisters based on analysis of observational and interview data. Four types of adopters and resisters were identified: enthusiastic adopters (35%), over-adapting adopters (24%), soft resisters (17%), and hard resisters (24%). Enthusiastic adopters exhibited positive attitudes towards WISE and moderate to strong fidelity. Over-adapting adopters, while exhibiting positive attitudes toward WISE, made fidelityinconsistent adaptations that were potentially detrimental (i.e., using mascot to shame children). Soft resisters demonstrated poor to moderate fidelity and showed lack of interest in adopting WISE or receiving facilitation support. Hard resisters were vocal about their complaints in adopting WISE and/or noticeably against receipt of facilitation support; most, but not all, hard resisters had poor fidelity. There are nuances in low fidelity not captured by quantitative scores. Different types of resisters may be best served with different implementation strategies. For example, hard resisters may benefit from strategies to enhance motivation whereas over-adapting adopters may need support for goal setting and/or appropriate adaptations. Background Policy makers across Sweden are pushing implementation of person centered care (PCC) in health care settings as a way to promote high quality health care across the country [1] . However, there is a lack of valid and reliable instruments to measure and compare patients' experiences of PCC across health care settings and patient groups. As part of a research project aimed at investigating implementation strategies of PCC at a regional level, we set out to develop a generic instrument to measure patients' experiences of PCC as an outcome of the implementation efforts [2, 3] . In this project, we collaborate with the Swedish association of local authorities and regions (SALAR) who are responsible for the administration of the largest patient survey in Sweden. When complete, the instrument will be available to healthcare regions for evaluating implementation and development of the PCC approach. A mixed methods design is used, entailing the following phases: construction of a preliminary questionnaire based on questions from SALA R's existing item pool, content validation of items via experts (patients, healthcare practitioners and researchers) in a Delphi study, cognitive interviewing with patients, data collection and psychometric evaluation through Rasch analyses. The last two phases are repeated in two rounds. Finally, the instrument will be handed over to SALAR who will be responsible for translation into seven languages, design of web and paper-based surveys, and procedures for recruitment of patients. Data collection for the first psychometric evaluation will end by mid-April. Preliminary results from the first phase of Rasch analyses are expected by the end of May. The results from the second phase are expected by the end of August. The finalized instrument will be launched by SALAR in the beginning of 2020. We set out to develop a robust and psychometrically sound instrument to measure patients' perceptions on PCC. The collaboration with SALAR has been fruitful and will greatly expand survey opportunities. We expect the instrument to be widely used for evaluating implementation efforts and benchmarking regarding PCC. There are many implementation and dissemination frameworks to help to bridge the gap between research and practice. As implementation science has grown, we must avoid the paradoxical gap between implementation research and implementation practice. This presentation will describe the collaboration between researchers and practitioners in the development and application of organizational readiness and the continued use of the R=MC2 heuristic in research, evaluation, and practice. We will first briefly describe the development of a new definition and conceptualization of Organizational Readiness for understanding and facilitating the implementation of innovations into new settings. Derived from work in the Interactive Systems Framework, the R=MC2 model proposes that readiness is not a singular, static condition, but rather a collection of dynamic constructs that includes motivation, general capacity, and innovation-specific capacity. Readiness can be used to monitor and facilitate implementation over time. The Wandersman Center developed a measure (the Readiness Diagnostic Tool) with good initial psychometric validity to help gather comprehensive information about facilitators of a change effort. A goal in the development of the RDT was that it could be used in multiple settings and for different interventions. Therefore, in this joint presentation between a researcher and a practitioner, we will also briefly describe the adaptation and design process for using the RDT in distinct settings and a new study to rigorously validate the measure. The potential to adapt the readiness measure is key for the application of implementation science constructs in real-world conditions. We will talk about how practitioners negotiate tradeoffs in making implementation constructs more specialized and application to their specific setting. Using the RDT as an example, we will share how we collaboratively worked through these adaptation issues. The adaptation process and lessons learned were bidirectional. We will discuss how applied findings in real world settings informed changes in the underlying theory and measure, specifically about what and how the constructs were useful. This presentation will highlight how theory and practice can inform one another in an iterative manner to help to move the science forward while promoting a deeper understanding of implementation facilitators. How can implementation quality be evaluated? an example from a pilot initiative in Australian child and family services Correspondence: Vanessa Rose (vanessa.rose@ceiglobal.org) Centre for Evidence & Implementation, Sydney, Australia Implementation Science 2020, 15(Suppl 2):A64 Background High-quality program implementation is a pre-condition to program effectiveness. However, evaluation of the implementation process is rare, resulting in uncertainty around interpretation of impact evaluations with null effects (i.e. was the program ineffective, or implemented poorly?). We report on an implementation evaluation of the Victorian Government's pilot of five manualized therapeutic programs for vulnerable families (four developed in the USA) across seven service provider agencies; the first evaluation of this nature and scope in Australia. The aim was to provide an indication of the comprehensiveness, pace and quality of program implementation to inform government decisions about if/ how such programs should be funded, implemented, supported and scaled. A real-world mixed-methods observational study design was used. The Stages of Implementation Completion checklist assessed implementation pace and comprehensiveness [1] . Theory-based structured interviews were conducted with agency staff (N=29) to explore program appropriateness, acceptability and feasibility [2] . Implementation strategies were explored with manualized program purveyors [3] . Fidelity data were extracted from agency databases. Most agencies (n=6) were still in early implementation, having not yet achieved sustainability. Highly-concentrated and overlapping implementation activity was observed, reflective of funding pressures, putting implementation quality at risk. The programs were generally well-accepted, perceived as high-quality and a good fit. While most agency staff 'believed in' the programs, perceived appropriateness was compromised by the lack of adaptability for Aboriginal and Torres Strait Islander communities. Threats to feasibility included high demands on practitioners and lack of Australian-based implementation support (trainers, consultants). It was too early for valid fidelity assessments. Policy-makers should afford agencies more time/resources to incorporate initiatives into 'business as usual'. Ongoing monitoring of implementation outcomes is highly recommended to facilitate datadriven decisions about when to start impact evaluation (i.e. when sustainability is achieved, and fidelity has been demonstrated). Implementation science for depression interventions in low-and middle-income countries: a systematic Background Quality Improvement (QI) initiatives are proposed as key vehicles to shift our health system from disease-focused, episodic care to comprehensive care for older adults living with chronic conditions. With the proportion of older Canadians set to double over the next two decades, the need for QI is pressing, yet there is a dearth of research on whether QI yields long-term changes in practice (sustainment) or benefits (sustainability) for older patients and residents [1] . Our study responds to call to "test theories, frameworks and models for their ability to explain and predict sustainability" [2] . We employed a Kohonen self-organizing map (SOM) [3] (an artificial neural network) to identify factors associated with sustainment and sustainability for QI interventions. To create our training dataset, we searched Medline, PsychINFO and CINAHL for articles which reported on the long-term (1+ years post-implementation) sustainability of QI programs targeted to older adults. After screening 3127 abstracts, 54 articles were selected. Two coders independently extracted study characteristics, including organizational & clinical context, implementation & post-implementation strategies, and adaptations. We performed leave-one-out cross-validation using the extracted variables to assess the sensitivity and specificity of the self-organizing map's predictions of sustainment and sustainability. The SOM achieved 38% sensitivity and 73% specificity for sustainment and 89% sensitivity and 42% specificity with respect to sustainability. The diagnostic odds ratio was not significant for sustainment but was 5.2 (statistically significant p<0.05) for sustainability. We also estimated the relative contribution of different determinants to the prediction of sustainment and sustainability by observing how their omission affected the predictive power of the SOM. Clinical targets, adaptations, postimplementation (sustainability) strategies, and organizational context were all significant predictors of sustainability; however, a larger training set would be required for a predictive model of sustainment and to generalize the SOM beyond QI initiatives in health care for older adults. Our study presents a novel method for investigating relationships between (post-)implementation factors and sustainability, which could be extended (with a larger training dataset) to produce predictions of-and tailored recommendations for-intervention sustainment and sustainability. The incorporation and use of reliable, valid measures in implementation practice, outside of research, will remain limited if measures are not pragmatic. Previous research has identified the need for pragmatic measures, though the pragmatic properties identified were developed using only expert opinion and literature review. Our team carried out four studies with the goal of developing a stakeholder-driven pragmatic rating criteria for implementation measures. We previously published Studies 1 (populating the dimensions of the pragmatic construct via a literature review + stakeholder interviews) and 2 (clarifying the internal structure via concept mapping) that yielded 47 terms and phrases across four categories: Useful, Compatible, Acceptable, and Easy that were culled to 17 terms. This study presents the results of Studies 3 and 4: a Delphi to ascertain stakeholder-prioritized dimensions and a pilot study applying the dimensions as rating criteria. Stakeholders (practitioners and implementation intermediaries; N= 26) participated in an online modified Delphi and rated the relevance of 17 terms and phrases to the pragmatic construct. The investigative team pruned the list further and developed anchors for the pragmatic properties based on all available data sources (i.e., stakeholder interviews, literature review, concept mapping ratings, Delphi ratings). The final criteria were piloted with 60 existing implementation measures utilizing both empirical and grey literature. The Delphi methodology confirmed the importance of all identified pragmatic measure properties, but provided little guidance on relative importance. Following the Delphi, investigators removed/combined 6 more terms to obtain the final set of 11 criteria across four categories (Useful, Acceptable, Easy, Compatible) and assigned a 6-point rating system to each criterion.  The systematic review methodology is described fully elsewhere [1] . Consistent with SIRC's mission and NIMH's priorities, the review focused on measures used in mental or behavioral healthcare. The review proceeded in three phases. Phase I, data collection, involved search string generation, title and abstract screening, full text review, construct assignment, and measure forward searches. Phase II, data extraction, involved coding relevant psychometric and pragmatic information. Phase III, data analysis, involved two trained specialists independently rating each measure using PAPERS (Psychometric And Pragmatic Evidence Rating Scale) [1] . Frequencies and central tendencies summarized information availability and PAPERS ratings. Searches identified nine measures of readiness for implementation, 24 measures of leadership engagement, 17 measures of available resources, and 6 measures of access to knowledge and information. Information about internal consistency was available for most measures. Information about other psychometric properties was often not available. Ratings for internal consistency were "adequate" or "good." Ratings for other psychometric properties were less than "adequate." Information was often available regarding cost, language readability, and brevity. Information was less often available regarding training burden and interpretation burden. Cost and language readability generally exhibited "good" or "excellent" ratings, interpretation burden generally exhibiting "minimal" ratings, and training burden and brevity exhibiting mixed ratings across measures. Measures of readiness for implementation and its sub-constructs used in mental health and behavioral healthcare are unevenly distributed, exhibit unknown or low psychometric quality, and demonstrate mixed pragmatic properties. This review identified a few promising measures, but targeted efforts are needed to systematically develop and test measures that are useful for both research and practice.  This systematic review was conducted as a part of a larger study, and the full protocol is published elsewhere [1] . The review proceeded in three phases. Phase I, data collection, involved search string generation, title and abstract screening, full text review, construct assignment, and measure forward searches. Phase II, data extraction, involved coding relevant psychometric and pragmatic information. Phase III, data analysis, involved two trained specialists independently rating each measures' psychometric properties. Frequencies and central tendencies summarized information availability and psychometric ratings. Searches identified 65 measures or subscales assessing molar organizational culture or climate, 6 measures of implementation climate, 4 of which were subscales of other measures; and a number of other subscales for constructs related to the CFIR's conceptualization of implementation climate, including: 2 assessing tension for change; 6 assessing compatibility; 2 assessing relative priority; 3 assessing organizational incentives and rewards; 3 assessing goals and feedback; and 2 assessing learning climate. Information about internal consistency and norms was available for most measures. Information about other psychometric properties was often not available. Ratings for internal consistency were most often "adequate" or "good." Ratings for other psychometric properties were typically lower. This review suggests some promising measures of organizational culture, climate, and related constructs; however, it also suggests a lack of conceptual clarity with respect to the differentiation between molar organizational culture and molar organizational climate. Implications for measure development and refinement will be discussed. One of the main challenges to measurement of implementationrelevant constructs is the mismatch between the level of measurement and the level of analysis [1] [2] . This alignment is particularly challenging when measuring constructs relating to the outer setting, given the predominance of self-report in implementation science. The objective of this review is to assess the reliability, validity, and practicality of measures of outer setting and its CFIR-delineated constructs used in mental or behavioral healthcare. This review of outer setting measures follows the same study protocol as the other systematic reviews initiated through this larger project [3] . Phase I, data collection, occurred in five steps: a) search string generation, b) title and abstract screening, c) full text review, d) construct assignment, and e) measure forward searches. Particular to this review, during search string generation an additional level was included for each of the CFIR constructs [4] ; 1) Patient needs and resources, 2) Cosmopolitanism, 3) Peer Pressure, and 4) External Policy & Incentives. Phase II, data extraction, consisted of coding relevant information to the nine psychometric rating criteria using the Psychometric And Pragmatic Evidence Rating Scales (PAPERS) [3] . Phase III, data analysis, is underway. For each construct, frequencies will be used to summarize the availability of psychometric information for each PAPERS criterion for the measures for that construct. The median and the range of final ratings for each psychometric PAPERS criterion will be used to summarize the psychometric strength of the measures for that construct. Electronic searches yielded four measures of outer setting; four measures of patient needs and resources; eight measures of cosmopolitanism; one measure of peer pressure and six measures of external policy and incentives. Five of these measures were unsuitable for rating. Analysis of the psychometric properties of the remaining measures if ongoing. The outer setting is the CFIR domain with the fewest measures identified. This paper advances implementation science and practice through consideration of how the outer setting should be conceptualized and measured. Outer setting constructs may be more appropriately assessed at a system rather than individual level, and by using direct measurement instead of latent variables. [2] . One causal theory that may explain the infrequent use of TNs is the Theory of Planned Behavior (TPB; [3] ). The TPB states that intentions, which are informed by attitudes, subjective norms, and self-efficacy, are the strongest predictor of actual behavior. The TPB also acknowledges that certain contextual factors need to be present in order for intentions to translate into actual behavior. Implementation science frameworks, such as the Consolidated Framework for Implementation Research (CFIR; [4] ), provide insight into the types of contextual factors that may affect clinician behavior (e.g., organizational variables). This study aimed to identify barriers to TN use by integrating a causal theory of behavior change (TPB) and a widely used contextual framework (CFIR). Sixty-five mental-health therapists working in community settings and trained through a city-wide TF-CBT initiative participated by completing a survey about their use of and beliefs about TNs. Content analysis was conducted to identify common beliefs about TNs. A subset of participants (n=17) completed in-depth qualitative interviews focused on perceptions of TNs. Qualitative interviews were analyzed using an integrated approach informed by the CFIR. While most participants reported high intentions to use TNs, nearly half reported that they did not use TNs in the last six months. The initial survey identified beliefs related to TPB constructs, including clinician attitudes (e.g., TN may worsen symptoms), norms (e.g., caregivers may disapprove), and self-efficacy (e.g., insufficient training). CFIR-informed qualitative interviews yielded themes related to client and family characteristics (e.g., client reluctance, instability in caregivers) and organizational factors (e.g., brief sessions). Results indicate a discrepancy between intentions and TN use. Responses to the survey and qualitative interviews indicate that there are contextual factors that may moderate the relationship between intentions and behaviors. For example, organizational constraints, such as time limitations, may prevent TN use even among therapists with high intentions. Results from this study highlight the importance of integrating theories that address multiple determinants of clinician behavior to identify potential targets for implementation strategies. The relationship between therapist-driven adaptations to evidence-based practices (EBP) and the extensiveness of EBP strategy delivery in community implementation Background Community therapists adapt evidence-based practices (EBPs) to enhance fit for their complex settings and clients when implemented [1] . Yet, few studies have examined the potential implications therapist-driven adaptations have for the quality of EBP delivery [2] . We examined the extent to which different types of therapistreported adaptations were associated with the extensiveness of EBP strategy delivery in a system-driven implementation of multiple EBPs. Data were drawn from an observational study investigating the sustainment of six EBPs for youth in the Los Angeles County Department of Mental Health [3] . Community therapists (n=103) provided descriptions of any adaptations they made in 680 sessions with 273 clients. Trained coders rated the extensiveness of EBP strategy delivery via the EBP Concordant Care Assessment (ECCA) from session recordings [3] . We examined how different types of therapist adaptations were associated with ECCA extensiveness ratings. Adaptations were categorized as: 1) modifying presentation, 2) integrating (integrating components, combining practices, providing psychoeducation), 3) extending (repeating components, lengthening), 4) reducing (removing, reordering, or shortening components), and 5) other (adaptations that could not be coded within our framework due to lack of fit) [4] . Furthermore, we examined these relationships through an augmenting (modifying presentation, integrating, extending) vs. reducing (removing, reorder, shortening) vs. "other" framework [4] . Preliminary analysis revealed that the overall number of therapist adaptations did not significantly predict extensiveness ratings (β = .067, p = .059). However, specific adaptations were related to extensiveness. Modifying presentation was associated with higher extensiveness (β = .098, p = .046), while "other" adaptations were associated with lower extensiveness (β = -.119, p = .034). When compared through an augmenting vs. reducing vs. "other" framework, "other" adaptations predicted lower extensiveness (β = -.127, p = .023). Quality of EBP delivery may be robust to some types of therapistdriven adaptations. In fact, adaptations that tailor the presentation of interventions were associated with more extensive EBP delivery. In contrast, "Other" adaptations were more likely to be associated with lower EBP extensiveness and thus may represent "drift." Additional analyses to further characterize the content of the "other" adaptations will be included in the proposed presentation. Developing implementation strategies to increase clinicians' use of evidence-based practices (EBPs) is important for improving the quality of mental health care. Our prior work with school-based services for youth with autism demonstrated that studying practitioners' intentions to use specific EBP components rather than their intentions to use broader intervention protocols, may point to levers by which to tailor implementation strategies as a function of the specific EBPs themselves (e.g., their salience, complexity) [1] . We extend this work by examining variability in community clinicians' intentions to use different components of cognitive-behavioral therapy (CBT). CBT has long been a target of implementation efforts [2] [3] yet remains underutilized in community settings [4] [5] . CBT comprises multiple, distinct components that vary in their complexity, ranging from relatively simple (e.g., homework review) to more complex interventions (e.g., cognitive restructuring). Examining how intentions vary across specific CBT components may yield insights into how to tailor implementation strategies to increase CBT use in community settings. Community mental health providers (N = 149, mean age = 40.8 years, 57.7% female) who had received intensive training and consultation in CBT were surveyed about their intentions to use six key elements of CBT interventions (exposure therapy, cognitive restructuring, behavioral activation, planning homework, reviewing homework, and agendasetting) for seven different clinical presentations. Clinicians also reported on their intentions to use "EBP" broadly. Demographic and clinical background characteristics also were collected. Analyses are ongoing. Nearly all clinicians reported high intentions to use "EBPs" broadly across all seven clinical presentations. However, intentions varied widely when clinicians reported on specific CBT components. In general, higher intentions were observed for CBT components that were simpler and part of the session structure (e.g., reviewing homework vs. exposure therapy). Additional analyses will examine clinician characteristics as predictors of intentions. Findings highlight variability in clinician intentions across specific elements of CBT and suggest that CBT implementation strategies may need to be tailored as a function of specific intervention components. Results also suggest that implementation efforts may benefit from dismantling complicated interventions, highly specifying the practitioner behavior of interest, and tailoring implementation strategies to each one. Research has demonstrated that workshops alone do not lead to sufficient skill in delivering evidence-based psychotherapies (EBP), and that strategies such as follow-up consultation are needed. Yet, there is little research to inform how to best provide consultation to ensure sustained, high-quality delivery of EBPs. The parent randomized controlled implementation trial assessed the impact of three post-cognitive processing therapy (CPT) training workshop conditions (No consultation, Standard consultation without session audio review, Consultation with audio review) on the patient (N=188) PTSD treatment outcomes of participating therapists (n=134) in over 30 routine care settings in Canada. The current mixedmethods study examines associations between consultation activities and therapist fidelity and patient treatment outcomes, as well as the accuracy of consultant perceptions of the skill and engagement of therapist consultees. Consultation occurred weekly for six months. After each recorded call, consultants (n=5) completed a post-call checklist of strategies and rating of perceived levels of enthusiasm, skill, and participation for each consultee. A subset of therapists (n= 30) were interviewed at the end of the consultation phase. While there was variability, three primary categories of activities emerged: case conceptualization and intervention planning, feedback on fidelity, and distractions/technical difficulties. Similarities and differences in consultant and therapist perceptions of consultation activities will be presented. Additionally, analyses revealed evidence of a consultant effect on therapist treatment adherence (B=0.439, SE=0.171, p=.012), but not competence (-B=0.341, SE=0.247, p=.168). This will be explored in relation to consultation condition and strategies, including whether different consultants engaged in specific activities more frequently. Finally, we found that while consultants perceived overall improvements over the course of consultation (b = 0.03, t = 6.12, p < .01), their ratings of therapist skill did not predict clinician adherence (b = 0.03, t = 0.46, p = .65), competence (b = 0.03, t = 0.31, p =.76), or patient PTSD symptom change (b = -.12, t = -0.31, p = .76). It is possible that cognitive biases (e.g., halo effect) may reduce the accuracy of consultant perceptions. Practical implications of this and the other study findings will be presented in a broader discussion of barriers/facilitators of EBP sustainment. Background This panel is for implementation practitioners interested in systems science and participatory modeling approaches to evidence-based practice (EBP) implementation. Panelists will review participatory development of "Modeling to Learn (MTL)," a program for improving EBP implementation in the Veterans Health Administration (VA) [1] [2] . Study of MTL is underway to determine its effectiveness increasing delivery of evidence-based addiction and mental health care (R01DA046651). Preliminary statistical process control analyses indicate pilot clinics demonstrated a three standard deviation increase in EBP reach and maintained improvement for 12 and 8 months, respectively (R21DA042198). Using the MTL example, this panel answers commonly asked questions about systems science approaches to implementation through demonstration. Four years ago, panelists began learning with frontline multidisciplinary teams about determinants of local reach of evidence-based psychotherapies and pharmacotherapies (EBPs). Support for modeling to identify locally tailored implementation plans grew among VA stakeholders, and each panelist joined the project to contribute systems modeling expertise: Dr. Lounsbury as an NIHfunded researcher, Ms. Kibbe as a public health facilitator, and Col. Rollins (Ret.) as an online simulation user interface developer. Panelists will present participatory modeling activities, linking them to free, online open science resources. Dr. Lounsbury will describe initial qualitative group model building exercises, developed in the field of system dynamics [4] [5] . These activities illustrate how to determine the right modeling problem via participatory engagement. Ms. Kibbe will describe the participatory principles and pragmatic constraints used to refine MTL online facilitation resources for teams to develop systems thinking skills at national scale [3] ; this includes the MTL session guides and fidelity checklist. Col. Rollins will describe design iterations to produce an interface for frontline teams to simulate improvement scenarios using team data. Attendees will be provided access to a demonstration website developed to help users understand how simulation makes local EBP barriers and facilitators more transparent and locally manageable. As discussant, Dr. Zimmerman will synthesize the activities described by panelists in relation to the learning objectives, to help implementation practitioners and intermediaries get started with participatory modeling. Background Mood and anxiety disorders affect approximately 30% of youth [1] . Cognitive Behavioral Therapy (CBT) is an evidence-based treatment for these disorders, but only a fraction of adolescents in need have access to high quality treatment. Access could be substantially increased if school professionals (SPs) were trained to deliver CBT. However, typical professional development and clinical training opportunities are often unsuccessful because they lack post-training support necessary for producing sustained behavioral change. TRAILS is an implementation and training model designed to increase utilization of CBT among SPs. In addition to clinical training and resources, TRAILS is unique in that it also provides in-person coaching to support SPs as they co-lead student CBT skills groups. To build capacity for large-scale and sustainable implementation of CBT, TRAILS established a statewide network of expert "coaches", recruiting primarily from Community Mental Health (CMH) agencies across Michigan. Participation was incentivized via provision of training and CEUs at no cost to potential coaches and up to 10 (noncoaching) clinicians per partner agency. Coaches participated in a daylong CBT training, followed by 12 weeks of individual case consultation from an expert clinician. Coaches were assessed pre-and post-consultation and successful completers were recommended for subsequent training in the TRAILS coaching protocol. [2] , and the Parental Attitudes Toward Psychological Services Inventory (PATPSI) [3] . Exploratory factor analysis was conducted with principal axis factoring and oblique rotation, Cronbach alpha coefficients were used to calculate internal consistencies, and Pearson correlations were computed to investigate convergent validity. Exploratory factor analysis suggested a five-factor structure (50 items, alpha = .86). Items grouped along the dimensions of SN (11 items, alpha = .80), treatment barriers (10 items, = .71), treatment knowledge (6 items, alpha = .72), evidence-informed action (11 items, alpha = .83), and PBC (12 items, alpha = .83), that accounted for 38.07% of the total variance. Regarding Pearson bivariate correlations, PEEBS' PBC was significantly and positively associated with evidence-informed action (r = .50, p < .01) and SN (r = .35, p < .01). As expected, the FES family scale was significantly and positively associated with the PEEBS' knowledge factor (r = .42, p < .01), PBC (r = .32, p < .01), and evidenceinformed action (r = .17, p < .01). PATPSI's help-seeking intentions were significantly and positively correlated with the PEEBS' PBC (r = .37, p < .01), evidence-informed action (r = .33, p < .01), knowledge (r = .29, p < .01), and subjective norms (r = .22, p < .01). Based on promising psychometric results, the PEEBS appears to be a potentially useful instrument to understand parent consumers. What works best in practice? the effectiveness of 'real-world' [2] . To determine the most effective facilitation strategies, a decision forest [3] algorithm was developed. We collected 1131 data points from six facilitators, which were cate-  By understanding that the most prevalent barrier to implementation was an 'inability to plan for change', this provides pharmacy practice policy makers, tertiary educators, researchers and change facilitators an idea of where to target strategies to not only overcome, but prevent this barrier from occurring. This tool can be reproduced to understand implementation barriers specific to other industries and the most effective strategies to overcome these. Despite the known health benefits of physical activity (PA), 87% of Canadian older adults do not meet recommended PA guidelines. Community-based PA interventions show promise, but few were scaled-up. With partners, the Active Aging Research Team (AART) cocreated Choose to Move (CTM), a 6-month, choice-based health promotion intervention that aims to improve older adults' social connectedness and mobility through PA. During small scale-up, two community delivery partner organizations delivered 56 CTM programs in 26 urban communities across BC. We previously demonstrated that CTM effectively improved PA, mobility and social connectedness in 458 older adults [1] . The objective of this study was to evaluate effectiveness of CTM implementation strategies to guide broad scale-up (175 programs) of CTM. Grounded in implementation frameworks (e.g., QIF [2] , Powell et. al. [3] ), CTM adopted eight key implementation strategies: 1. develop strong community partnerships; 2. develop an implementation blueprint; 3. ongoing implementation monitoring; 4. promote adaptability; 5. provision of program materials and tools; 6. centralized training and technical assistance; 7. convene advisory committees, and 8. a staged implementation scale-up approach. To assess effectiveness of implementation strategies, we measured four implementation outcomes (reach, participant responsiveness, quality, and delivery partners' perceptions of the strategy). We administered surveys and conducted interviews with CTM participants (n=42) and delivery partners across four levels of influence (19 decision makers, 6 recreation managers, 27 recreation coordinators, 23 activity coaches) at mid-and post-intervention. CTM implementation strategies were effective across all levels of evaluation. Of 458 participants, 82% attended ≥75% of group meetings; 95% completed ≥70% of check-ins (reach); 75.3% were satisfied with CTM (participant responsiveness). From interviews, CTM was implemented with quality. Participants' had very positive perceptions of their ACs. Delivery partners noted that intervention materials were appropriate and CTM was flexible and easy to implement. Central support (e.g., training, integration) provided by AART was instrumental to effectively implementing CTM. Implementation strategies must be adapted to provide "best fit" for the delivery context. Our findings support a suite of implementation strategies that promoted scale up a health promotion intervention that other interventions can adopt, modify and evaluate in future. Large scale dissemination and implementation of evidence-based interventions is limited by funding. Further, agencies are often required to shoulder the burden of costs while monetary benefits are realized in other service sectors. Thus, novel funding strategies are warranted. Pay for Success (PfS), also known as social impact bonds, is one such strategy [1] . Under PfS, governments may leverage private or philanthropic upfront capital to fund interventions, and subsequently repay those funders based on outcomes. However, there are notable considerations as it relates to implementation of this strategy, as described by Lowe et al. (2019) [2] . According to their model, it is easier to achieve agreement at the macro-policy levels, but challenges arise in meso-and micro-levels. In 2015, the Colorado state legislature approved a law that enabled the state to enter into PfS arrangements. Shortly thereafter, a "Call for Innovation" was released from the Governor's Office to identify potential PfS projects to improve outcomes for at-risk teens. The present project was one of three selected, and focuses on bringing an evidencebased intervention, Multisystemic Therapy [3] , to under-served regions of the state. This presentation includes the perspectives of a state partner and the University-based entity implementing the project. The Lowe et al. (2019) [2] framework is used to contextualize the PfS structuring of the initiative, which required alignment of funders, state partners, evaluators, and the project-based implementation team. This is the first PfS initiative that partnered with a non-profit, private university as the primary fiscal agent. This presentation describes the successful launch of the Coloradobased PfS initiative in December, 2018. Three cohorts, each containing two MST teams, are being rolled out over the next two years. The evaluation, on which the success payments are connected, uses a propensity score matching procedure because of the relatively lower population density in the service areas. Over the course of the project, we anticipate over 600 families to be served. Although complicated to enact, PfS may become an important strategy to support large scale dissemination. Strategies to simplify the contracting process and support the meso-and micro-policy tensions is necessary for broad-scale uptake. Using common elements and co-creation to enhance implementability of evidence-informed interventions: example from an academic intervention in Norwegian child welfare Background Implementation and sustainment of effective interventions remains a struggle across public services, especially in settings with limited readiness for implementation. Increasing the implementability of interventions can facilitate more successful implementation. There is growing interest in identifying and studying discrete elements that are common across interventions for the purpose of hypothesis generation, intervention optimization and re-design, and implementation in practice. We combine common elements methodology with collaborative design approaches to develop and test implementable evidence-informed interventions tailored to individual and contextual needs. This session will present preliminary results from a common elements-based academic intervention for children in child welfare. We used common elements methodology to identify common practice-, process-, and implementation elements in systematically reviewed academic interventions for children at risk. We compared frequencies of the most common elements and combinations in effective interventions with frequencies in ineffective interventions. Using facilitated cocreation with stakeholders, practitioners and user-representatives, we aimed to unify perspectives of researchers, implementers, managers, practitioners, and end-users to develop an implementable academic intervention based on the identified common elements. We developed dynamic fidelity monitoring encouraging flexible use of elements and adaptations, and we co-created blueprints for implementing, evaluating, and sustaining the intervention. We are now conducting a mixedmethods hybrid pragmatic trial where we assess the child welfare contexts' readiness for implementation, intervention implementability (feasibility, appropriateness, acceptability, usability), implementation quality, and intervention effectiveness. We included 30 effective and 6 ineffective academic interventions for children at risk in a systematic review. We identified 62 practice elements, 49 process elements, and 34 implementation elements used in the interventions. Frequency count values (FVs; inclusion in effective vs ineffective interventions) were calculated for each element and commonly used combinations of elements. Elements and combinations with the highest FVs were used in facilitated co-creation to develop the intervention Enhanced Academic Support (EAS). Preliminary mixed methods results on the implementability of EAS and associations with readiness will be presented at the conference. Combining common elements methodology with collaborative approaches for intervention design can be a viable approach for developing implementable interventions tailored to individual and contextual needs In the delivery of youth-focused evidence-based practices (EBPs), high levels of client engagement have been positively associated with improved clinical outcomes [1] . In the literature, engagement has been primarily indexed by attendance [2] , and more refined qualitative measures of engagement are needed. Thus, in the current study, we used an observational coding system to examine specific in-session client engagement challenges within a county-wide implementation of multiple EBPs in youth mental health services. The aims of the study were twofold: (1) characterize the frequency of client engagement challenges and (2) examine whether these challenges are associated with the extent to which community therapists deliver EBP strategies. Extensiveness of EBP strategies was measured via therapist-report and observer-ratings. The sample included 103 therapists who provided recordings of 680 sessions in which they delivered an EBP to 273 youths (Mean age=9.75 years). Using observational coding, in-session youth and parent engagement challenges (i.e., client expressed concerns, refusal to participate in activities) were measured with good reliability (Mean ICC=.64). Across both youth only and youth + parent sessions, 66.29% of sessions had ≥ 1 engagement challenge occur. In parent only and youth + parent sessions, engagement challenges were observed in fewer sessions (30.47%). When examining the association between engagement challenges and therapist delivery of EBP strategies, there was no significant association with occurrence of youth engagement challenges and EBP strategies delivered (indexed by both observer or therapist report). For parent challenges, the relationship was nonsignificant using therapistreported EBP delivery. In contrast, parent engagement challenges were positively associated with observer-rated therapist delivery of EBP strategies (b=.15; p=.04). This relationship seems to be driven by parents expressing concerns about the relevance/acceptability/helpfulness of the EBP. Overall, these findings imply that youth/parent behaviors that we may conceptualize as engagement challenges do not necessarily derail therapists from EBP delivery in session. Future analyses will further examine the relationship thematically by types of engagement challenges. Discussion will focus on therapist perceptions of client behaviors as engagement challenges, and whether they can be deemed opportunities for alliance building. Evidence-based assessment (EBA) can improve clinical outcomes, and it is embedded in many evidence-based practices (EBP) [1] . However, EBA is not well implemented in community practice due to perceived low usefulness [2] . Additionally, therapist characteristics such as nonpsychology disciplines and years of practice may be associated with negative EBA attitudes [3] . Research is needed on factors that predict EBA use in community practice and how attitudes change with exposure to EBP. The current study examined how therapist characteristics, use of EBA within the delivery of EBPs, and interactions between these variables may be associated with subsequent perceptions of EBA. Therapists (n=117) in an initial survey reported on their use of clinical dashboards, an EBA strategy for repeated assessments of client outcomes to inform treatment planning. They reported on their perceptions of EBA in another survey approximately 10 months later. Separate linear regression models were conducted for each of the four dimensions of EBA perceptions: clinical utility, practicality, benefit to clients and treatment, and harm to clients. Results showed that dashboard use significantly predicted perceptions of clinical utility (b=-0.100, p=0.006). Theoretical orientation moderated the relationship between dashboard use and clinical utility (b=0.107, p=0.028). For therapists who did not identify as having a cognitive/behavioral orientation in their practice, more extensive dashboard use predicted lower perceptions of clinical utility of EBA. For other EBA perceptions, years of practice significantly predicted perceived practicality (b=0.037, p=0.020), where longer years of practice predicted positive perceptions of EBA. Therapist discipline also significantly predicted perceived harm of EBA for clients (b=-0.495, p=0.022), where having a psychology discipline predicted lower perceived harm relative to other disciplines. These results replicate therapist characteristics as important predictors of EBA perceptions and suggest that on-the-job use of EBA strategies can predict future perceptions. However, for some clinicians (non-cognitive/behavioral), mandated use of EBA may further entrench negative perceptions. Non-psychologists and less experienced therapists perceived EBA as burdensome and more harmful to therapeutic process perhaps due to inefficient training or support. Future studies could examine implementation strategies that may promote positive perceptions of EBA and positive outcomes of EBA use for clients. Looking In an effort to increase the use of evidence-based practices (EBPs) in community mental health settings, large-scale implementation efforts are becoming increasingly common, prompting efforts to better understand determinants of implementation [1] [2] . While much attention has been given to the inner and outer organizational and leaderships contexts that influence implementation efforts, [3] [4] there has been less focus on the links between therapist factors and the community neighborhood in which they work. Clients from high risk neighborhoods have been shown to present with more severe symptoms [5] and an increased number of emergent life events that can impact the treatment process [6] . This may influence implementation efforts in the form of therapist burnout, which is linked to higher turnover [7] . The current study utilized survey data from therapists in Los Angeles County collected within the context of a system-driven multiple EBP implementation effort as well as publicly available data published by the Los Angeles Times "Mapping L.A." project [8] (e.g., mean income, race/ethnicity, home ownership, education etc.). Clinic addresses were used to identify the neighborhood of the clinic as determined by the "Mapping L.A." project, and neighborhood characteristics were collected and matched to survey data. Multilevel modeling was used (level 1=therapist, level 2=program, level 3=neighborhood) to examine the relationship between therapist emotional exhaustion and characteristics of the community of the clinic. Analyses showed population density (β=.14, p<.05), median income (β=-.30, p<.05), and home ownership (β=.30, p<.05) of the neighborhood surrounding the clinic to be significant predictors of therapist emotional exhaustion. Results can help target specific implementation supports towards clinics with therapists at higher risk of emotional exhaustion, thus potentially improving the implementation of EBPs. Background Poor engagement of youth and families in mental health services is a significant barrier to implementing psychosocial interventions, given that more than 50% of youth drop out of services before the completion of treatment. Detecting engagement problems early is a critical step in preventing premature termination and promoting successful implementation of psychosocial interventions in community settings. Despite this, little is known about how providers assess client engagement in therapy in the absence of structured feedback. The current study examines the indicators that providers use to detect engagement and disengagement in a variety of community mental health settings. As a part of a training workshop, 39 mental health providers were asked to report a case example that represented an engagement challenge, a case example that represented an engagement success, and indicators used to assess engagement for each case. Participating providers worked primarily in schools, as well as community mental health centers, juvenile detention centers, and private practices. Case examples and described indicators were coded based on five domains of engagement (relationship, expectancy, attendance, clarity, and homework).  The purpose of this study was to investigate how providers detect engagement during treatment. While these results are limited due to small sample size and reporting single case examples, our study suggests that providers focus on attendance when assessing client disengagement, and homework completion when assessing client engagement. These results highlight an opportunity to train providers in understanding the multidimensional nature of engagement, so that they may address signs of attitudinal disengagement before they lead to disruptions in attendance and treatment dropout. Background Less than 1% of children in low-and middle-income countries (LMICs) with mental healthcare needs will receive treatment, in part due to a dearth of trained providers. Task-sharing, in which lay counselors deliver treatment, is an implementation solution; however, more research is needed on counselors' experience in this role. Although providing trauma treatment has been linked to provider burnout in the US, to our knowledge no one has examined this question with lay counselors in LMICs. The present study compares burnout and turnover between lay counselors in two systems in Kenya. Lay counselors included 60 teachers and community health volunteers (CHVs) delivering group-based Traumafocused Cognitive Behavioral Therapy (TF-CBT) as part of a large NIMHfunded trial. These lay counselors embedded in different systems, with differing supports, role definitions, and time demands, may have differing experiences of adding a counseling role to their existing one (as teacher or CHV). Immediately after completing TF-CBT training, the lay counselors reported their baseline job burnout and turnover intention for their original role as either a teacher or CHV. Approximately six months later, after leading two rounds of TF-CBT groups, they completed postimplementation surveys assessing constructs of interest. Analyses used independent samples t-tests to determine if there were significant differences between teacher and CHV reports. At baseline, CHVs reported significantly higher burnout in their original role than teachers (p<.001) but there was no difference in turnover intention. Post-implementation, teachers reported significantly higher counseling-specific burnout (p=0.005) and compassion fatigue (p=0.007). They also reported higher job turnover intention (p=0.003) than CHVs. There were no differences for post-implementation compassion satisfaction (p=0.91) or intention to continue their counselor role (p=0.04). Our findings contribute to the limited literature on the lived experience of lay counselors providing mental health treatment to families in LMICs. Some aspects of experience differ by system, and these differences may suggest points for intervention to retain lay counselors for scale-up and sustainment or to determine which systems may be more viable for "adding" a counseling role. Retaining lay counselors after investing in their training is critical for efforts aimed at reducing the substantial treatment gap in LMICs. Trial Registration: Clinicaltrials.gov NCT03243396 Maintaining community partnership and program fidelity while replicating a community-based mental health intervention: a case study of the New Haven MOMS Partnership® replication in Bridgeport, Connecticut, New York City, and Washington D.C Sonia Taneja, Megan Smith Yale School of Medicine, New Haven, CT, USA Correspondence: Sonia Taneja (sonia.taneja@yale.edu) Implementation Science 2020, 15(Suppl 2):A88 The Mental health Outreach for MotherS (MOMS) Partnership is a community-academic partnership in New Haven responsible for developing a maternal mental health interventiona cognitive behavioral group therapy course co-led by a clinician and a community mental health worker at a convenient, neighborhood hub site. MOMS is in the process of expanding to Bridgeport, Connecticut; New York City; and Washington D.C. This expansion highlights the interplay of two common paradigms of program replicationdesigning program components using community-based participatory research methods and implementing programs with a high degree of fidelity. These two goals are often seen as contradictory, but successful programs are known to appraise both. Our first objective is thus to describe MOMS replication through community partners, identifying which components have been malleable based on community feedback and which were static. Our second objective is to provide the framework to measure program fidelity to the original model. Three case studies are presented: the first two discuss lessons learned from early program development in Bridgeport and New York, beginning with iterative co-design of a needs assessment. The third examines D.C. MOMS beginning with the needs assessment distributed through the Technical Assistance for Needy Families (TANF) program. Results of a structural fidelity assessment in D.C., which operationalizes fidelity components including content and process, participant engagement, adherence to goals and needs assessment and theory of change, and acceptability of programs, are also provided. Insights from these case studies span issues of fostering and maintaining positive relationships with community groups, identifying government partners through which replication can be sustainable, but still acceptable to community members, managing capacity constraints particularly in environments that are saturated with nonprofit programming, navigating issues of population representation, and overcoming unforeseen challenges based on context. Centering community nuance while replicating successful mental health interventions is an essential, iterative, and difficult process. Experiences of the early career investigators at MOMS while replicating program in three new cities provide reflections on lessons learned when entering new communities ethically and effectively, learning how to work towards program fidelity while valuing responsiveness to community need. Background Cognitive-behavioral therapy (CBT) can improve anxiety and depression in autistic adults [1] , who frequently struggle with these cooccurring psychiatric conditions [2] . Most autistic adults do not receive CBT, however, because of a lack of clinicians who are willing and able to treat them. We applied the Theory of Planned Behavior (TPB) [3] , a leading model of behavior change, to examine malleable factors that may influence community clinicians' use of CBT for autistic adults with anxiety or depression. These factors can be targeted with tailored implementation strategies to improve implementation of evidence-based practice [4] . One hundred clinicians completed an online survey. We used standardized procedures from social psychology to measure clinicians' intentions, attitudes, norms, and self-efficacy, [5] and adapted them to focus on using CBT with adult clients (both autistic and non-autistic) who present for anxiety or depression treatment. Clinicians reported weaker intentions (p = .001, d = .34), less favorable attitudes (p < .001, d = .69), less descriptive normative pressure (p < .001, d = .39), less injunctive normative pressure (p < .001, d = .66), and worse self-efficacy (p < .001, d = .81) to start CBT with autistic adults than with non-autistic adults. The only significant predictor of intentions to begin CBT with clients (both autistic and non-autistic) who present for anxiety or depression treatment was clinicians' attitudes (p < .001), with more favorable attitudes predicting stronger intentions. For the purposes of this study, attitudes refer to the clinicians' perceived advantages and disadvantages of starting CBT with their adult clients with anxiety or depression. This concept is similar to the implementation science constructs of "acceptability" and "appropriateness" [4, 6] . Knowing that clinicians' attitudes strongly predicted intentions is valuable for designing effective, tailored implementation strategies to increase clinicians' adoption of CBT for autistic adults. For example, an implementation strategy targeting attitudes could include message content to change thinking around the perceived fit of CBT with autistic adults. Social psychologists have successfully used this type of approach to change attitudes about complex behaviors, [5] but it has not yet been applied to improving the implementation of evidence-based practice for autistic adults. Harnessing implementation science with community-based social service organizations to address depression and social isolation for older adults living in poverty Correspondence: Lesley Steinman (lesles@uw.edu) University of Washington, Seattle, WA, USA Implementation Science 2020, 15(Suppl 2):A90 Background Late-life depression (LLD) is a major public health issue that impacts older adults, families, communities, and health systems. Often unrecognized or undertreated among older populations, those living in poverty experience disparities in access to LLD care. PEARLS is a home-based collaborative care model (CCM) for LLD developed with social service community-based organizations (CBOs) to reach underserved older adults. Since demonstrating effectiveness via RCT in 2004, [1] we have partnered with CBOs to apply implementation science (IS) tools and strategies to improve PEARLS delivery. One of our current projects is to evaluate whether and how PEARLS may help address the recent "epidemic" of social isolation [2] in five US sites. The PEARLS Connect Study is a concurrent mixed methods evaluation. Implementation data will be collected via surveys and semi-structured interviews with 10 CBO administrators and 30 PEARLS practitioners. The interview guide asks about implementation strategies, determinants, adaptations, and outcomes. We will use framework analysis [3] [4] to map text data to a priori domains from IS frameworks -ERIC implementation strategies, [5] EPIS implementation determinants (Aarons) , QUERI Adapted Stirman [6] Adaptation Framework (QASAF) [7] and implementation outcomes [8] . We will also use inductive thematic analysis to pull out any other key implementation themes that emerge from the conversations with practitioners. Data are currently being collected (Spring 2019) and will be analyzed in Summer 2019. We will report on implementation strategies (planning, educating, financing, restructuring, quality management, policy); practitioner, organization, and contextual determinants influencing implementation; local adaptations (what, when, how, why, by whom, where, and what impact the modification had). We will also share whether PEAR LS is acceptable, feasible, and appropriate as an intervention to increase social connectedness. Local CBO partners will share how partnering with implementation scientists has impacted their practice and policymaking, including facilitators, barriers and opportunities to partnership and application of IS. Many of the IS frameworks applied in this study have been developed with clinical or public mental health settings. This scaling-out [9] evaluation will share learnings from researchers and practitioners who are applying IS to improve practice and equity [10] for older adults living in poverty. Reflections on a decade of policy/practice-driven implementation research: strategies for meaningful collaboration Correspondence: Sarah Kaye (sarah@kayeimplementation.com) Kaye Implementation & Evaluation, LLC, Washington, DC, USA Implementation Science 2020, 15(Suppl 2):A91 Background This presentation aims to discuss three questions of interest to the Society for Implementation Research Collaboration (SIRC) at the 2019 conference: (1) What can implementation researchers, practitioners and intermediaries learn from each other? (2) How can we adapt lessons learned from implementation science in ways that are culturally and contextually appropriate? (3) What are examples of strategies for collaboration between policy makers/funders and implementation experts? Two-way communication between the research world and the real world is vital to minimizing the gap between research and practice. Understanding the needs of policy makers and practitioners is critical to producing research findings that are relevant to the users that studies are intended to support. Moreover, research projects benefit from acknowledging policy, practice, and community expertise-and recognizing community members' meaningful contributions to a better understanding of implementation strategies, processes, and causal mechanisms. Drawing on principles from community-engaged research [1] and research/evaluation capacity-building [2] , this presentation offers strategies that implementation researchers might consider when partnering with communities. Examples of these strategies include: Co-designing a theory of change for the intervention(s) and implementation; Utilizing sequential explanatory research designs [3] through a process of read, listen, share, discuss, adapt; Offering community empowerment opportunities through voice and choice about design, measures, and theories/ frameworks; Addressing questions and requirements that are critical to policy makers and practitioners; Identifying dissemination strategies that meet the needs of communities. Background Stakeholder engagement is often considered critical to implementation science [1] . This study illustrates the value of engaging a wide variety of stakeholders in the development of an implementation intervention. This project was funded by the National Institutes of Mental Health to develop and pilot the Collaborative Organizational Approach to Selecting and Tailoring Implementation Strategies (COAST-IS). The COAST-IS intervention will equip organizations to use Intervention Mapping to select and tailor implementation strategies to address site-specific determinants of treatment implementation and sustainment [2] . Intervention Mapping is a multistep process that incorporates theory, evidence, and stakeholder perspectives to ensure that intervention components effectively address key determinants of change [3] . The first year of the grant focused on engaging national and local experts, organizational leaders, clinicians, caregivers, and youth in the development of COAST-IS for a trauma-focused treatment. The approaches to engagement in this project range from full partnership to stakeholder consultation. The project is being conducted in partnership with leadership from the UCLA-Duke National Center for Child Traumatic Stress (NCCTS) and the North Carolina Child Treatment Program (NC CTP). NCCTS and NC CTP continue to shape project planning and intervention development through continuous feedback on intervention structure, organizational assessment, and dissemination planning. The research team worked with NC CTP to convene an Organizational Advisory Board (OAB) to solicit the perspectives of organizational stakeholders similar to potential research participants. OAB members reviewed draft intervention materials and provided feedback on the structure and content of the COAST-IS intervention. They continue to influence intervention material development. To incorporate the perspectives of families and youth during intervention development, NCCTS leadership connected the research team with two existing client groups. The Family and Youth Insight Advisory Group and the Youth Task Force met with the research team to discuss barriers to their engagement in trauma-focused treatments and recommend strategies to address these barriers. The research team synthesized these recommendations to share with future intervention participants to promote client-focused implementation. This study illustrates the potential impact of engaging diverse stakeholders in the development of implementation interventions. The study team will continue engagement efforts during intervention testing, planning for future research, and dissemination. Background Advance care planning (ACP) is the process by which patients, alongside their healthcare providers, consider options about future healthcare decisions. Although ACP is associated with improved outcomes as people near end-of-life [1] [2] [3] , many providers report discomfort with ACP and subsequent goals-of-care (GOC) conversations [4] . There are also many organizational, community, and system barriers to these conversations [5] [6] . Changing practice, and ultimately improving patient/family outcomes, will require collaborative efforts from multi-level/sector partners. Through collaboration amongst government, the provincial cancer agency, care providers, a communitybased organization, and an implementation scientist, we sought to develop provider capacity in initiating, and increase the frequency of, ACP/GOC conversations with cancer patients. Informed by the knowledge-to-action framework [7] and data gathered from various sources, including formal research studies and local context, we co-designed an intervention (communication skills training workshop, clinician guides and documentation tools, and patient/family guide). We tested the intervention with 51 providers in oncology, palliative, and primary care; evaluated it using postworkshop surveys, focus groups, and chart reviews; and adapted it via iterative team dialogue and debriefing. Data from the first two (of five) workshops revealed that most providers were uncomfortable with ACP/GOC conversations and it was premature, at that point, to expect them to complete documentation. Thus, we focused on refining/enhancing the workshop and encouraging use of the clinician/patient guides. Our findings demonstrated increased provider confidence across most ACP/GOC domains and an increased number of ACP/GOC conversations with patients, and provided critical insight for scale-up (e.g., train-the-trainer strategies, integration with existing education events). The adapted intervention was subsequently implemented province-wide. Team reflection and debriefing revealed at least 6 factors critical to successful implementation: 1. underpinned by research and local evidence; 2. driven collaboratively by multi-level/sector stakeholders; 3. guided by a plan but a willingness to adapt as needed; 4. ongoing evaluation; 5. clinical champions; and 6. a dedicated coordinator to bring to all together. Collaboration amongst multi-level/sector stakeholders has the potential to change clinical practice. Evidence from multiple sources is critical to designing an evidence-based, locally-adapted intervention and convincing a myriad of stakeholders to support it. Comparing state mental health agency and state insurance agency directors' perspectives on the benefits and barriers to inter-agency collaboration related to implementation of federal mental health parity policy Katherine Nelson, Jonathan Purtle Drexel University, Philadelphia, PA, USA Correspondence: Katherine Nelson (kml383@drexel.edu) Implementation Science 2020, 15(Suppl 2):A94 Background There is substantial state-level variation in the implementation of federal mental health parity policy-which requires that insurance companies provided equal coverage for mental and physical health care [1] . One possible reason for this variation could be differences in how state mental health and insurance agencies are collaborating to support implementation [2] . This study aimed to: characterize perceptions of the benefits and barriers to inter-agency collaboration related to implementation of federal parity policy, and compare how these perceptions differ between state mental health agency and state insurance agency directors. Web-based surveys of state mental health agency directors (n=43, response rate= 84%) and state insurance agency directors (n=34, response rate= 67%) were conducted in 2017. One item assessed the perceived benefit of collaboration between two the agencies and five items assessed specific barriers to collaboration. All items were explicitly about implementation of federal mental health parity policy. Bivariate analyses assessed differences in the perceptions between state mental health agency and state insurance agency directors. A significantly higher proportion of state mental health agency directors thought that there would be a benefit to inter-agency collaboration than state insurance agency directors (95.4% vs. 67.7%, χ2 p= .001). A significantly higher proportion of state mental health agency directors identified different agency culture (e.g., "norms, values") (51.2% vs. 24.2%, χ2 p= .017) and different agency terminology (51.2% vs. 18.2%, χ2 p=.003) as major barriers to inter-agency collaboration than state insurance agency directors. For all five barriers to inter-agency collaboration, the proportion of respondents identifying each as a major barrier was higher among state mental health agency directors that state insurance agency directors. State mental health agency directors believe that there is more benefit to inter-agency collaboration related to the implementation of federal mental health parity policy than state insurance agency directors, but also believe that there are more barriers to collaboration. Implementation strategies such as consensus discussions, facilitation between state mental health agencies and state insurance agencies, and the development of an implementation glossary could improve inter-agency collaboration and enhance the implementation of federal mental health parity policy [2] [3] . Current methods or approaches used in scientific practice have failed to rapidly and rigorously integrate cultivated knowledge into feasible and sustainable real-world practices and policies [1] . Continuing to use traditional scientific approaches runs the risk of implementation science falling short of expectations [1] . Different methods are needed to foster the rapid integration of science and practice while maintaining rigor [1] . The purpose of this study is to conduct a rapid review of the literature to identify implementation determinants and strategies that impact adoption, implementation, and sustainability of family-based mental health interventions in primary care. A rapid review will be conducted that involves a primary literature search of Medline, Embase, PsycInfo, CINAHL databases to identify existing implementation strategies used to foster the uptake and use of family-based interventions in primary care settings. A secondary search will be performed as an iterative process and included bibliographic and grey literature searches of reference lists, authors and specifically the journal, Implementation Science. A systematic approach to data extraction will be used to illuminate key determinants, strategies, and outcomes related to implementation. The results of the rapid review will be presented along with method parameters (e.g., time to complete, cost and resources, streamlining processes). Findings will directly inform an actionable plan to implement the intervention in primary care settings. Results will be used to inform stakeholder decisions regarding implementation supports provided during a multi-site rollout of FBCI in integrated primary care settings throughout the USA. Rapid reviews can be used to integrate implementation research into practice or policy. While it is not exhaustive, rapid reviews provide a pragmatic and systematic approach to synthesizing evidence to inform decision-making in real-world efforts. Future work will compare results of rapid review to results of a gold-standard systematic review. Background Rural children are frequently exposed to adverse experiences, which are associated with negative long-term health outcomes [1] [2] . Traumainformed integrated primary care provides a model of care that takes into account the impact of social determinants of health both at the prevention and treatment levels [3] . Developing into trauma-informed integrated primary care involves complex organizational change processes that are challenging for rural primary care facilities burdened with multiple priorities [4] . Community partnership presents capacity building opportunities for rural primary healthcare clinics in such processes [5] [6] . The purpose of this study was to examine facilitators and barriers in rural primary care organizational changes toward Trauma-Informed Integrated Primary Care based on theoretical frameworks of organizational change and implementation science, with an emphasis on partnering as a key process of the organizational change efforts. This study was a community engaged organizational case study funded by HRSA, Doris Duke Foundation, and NY Community Trust Fund. The study was conducted in collaboration with a Federally Qualified Health Center in a rural community of a midwestern state, a non-profit organization, and an academic research and development center. Data collection involved key informant interviews, surveys, direct observation of formal and informal interactions with key stakeholders. Data analyses focused on identifying facilitating and/or interfering contexts and mechanisms in the organizational change efforts. This poster focuses on contexts and mechanisms pertaining to the partnering aspect. Facilitating contexts included shared mission and values, commitment to learning and innovation, increased awareness of social determinants of health among leadership, core work group, and transparent communication. The key facilitating mechanisms were leveraged resources and shared expertise that positively influenced change readiness. Major interfering contexts included limited understanding of the workflow, adaptability, and performance measurement. The key interfering mechanism was the culture clash that negatively influenced engaging key stakeholders. Partnering is a key process in rural primary care capacity building to meet the complex healthcare needs of children in under-resourced communities through trauma-informed integrated care. Understanding facilitating and interfering contexts and mechanisms in partnering can inform the process of building strategic partnerships for collective actions toward building a healthy community in underserved regions. The  MInD-I (maternal infant dyad-implementation), is an NIMH funded (R01MH108548) implementation trial of CoCM for perinatal depression with five sites in Washington and thirteen outside. Despite the availability of CoCM CPT codes to support the work of team care for depression they have not been widely utilized even in settings with collaborative care already in place. The UW Neighborhood Clinic primary care network undertook steps needed to document and process these codes for billing. The availability of these billing codes was used to support implementation of CoCM for perinatal depression within four sites of this network. New administrative, work flow, and interdisciplinary elements of this care represented challenges. Members of the panel will describe the national and state health policy goals underlying the promulgation of these codes and the current rate of utilization of these codes. The impact of these codes on implementation of CoCM for perinatal depression will be explored from the health system and primary care clinic level provider perspectives. The panel will provide a unique multi-level perspective on the impact of a novel funding policy on the implementation of a highly evidence based complex intervention requiring change in practice organization. Background Efforts to generate an evidence base for implementation strategies are frustrated by insufficient description [1] . The ERIC compilation names and defines implementation strategies [2] ; however, further work is required to operationalise strategies to clearly describe the specific actions involved [1] . The purpose of this project is to examine the extent to which strategies can be specified according to behaviour change techniques [3] , 'active ingredients' of interventions with the potential to change behaviour. The primary data source was the definitions of 73 strategies contained in the ERIC compilation [2] . The definition of each strategy was deductively coded using the BCT Taxonomy, [3] which contains 93 discrete techniques with the potential to change behaviour. A typology was developed iteratively to categorise the extent of overlap between strategies and BCTs. Three implementation scientists independently rated their level of agreement with and confidence in the categorisation. During preliminary analysis, 86 BCTs were linked to 73 strategies. Five types of overlap were identified. 1) In 6 instances, there was a direct overlap between strategies and BCTs (e.g., strategy: remind clinicians, BCT: prompts and cues). 2) In 36 instances, there was at least 1 BCT clearly subsumed under the strategy description which could be used to guide initial operationalisation (e.g., strategy: clinical supervision, BCT: restructure social environment). 3) In 42 instances, a BCT(s) was probably subsumed under the strategy given its definition and/ or title, but other BCTs were possible depending on how the strategy was operationalised (e.g., strategy: visit other implementation sites, BCT: social comparison). For 8 strategies, there were no BCTs clearly indicated in the strategy definition or title (e.g., strategy: make training dynamic). Finally, 14 strategies did not focus on behaviour change to support implementation (e.g., strategy: access new funding). Many implementation strategies rely on assumptions and inference on the part of the intervention developer, be it researcher or practitioner, to apply them in a setting. This study is the first step towards moving from general descriptions of implementation strategies to full and consistent descriptions of their active ingredients. This is essential to understanding the mechanisms by which implementation strategies exert their effects. Background Barriers and facilitators assessments (BFAs) are regarded as a key step in implementation, yet our understanding of how to conduct BFAs effectively has stalled. There is an abundance of literature on barriers and facilitators (BFs) to adopting a multitude of interventions and programs, but these studies do not offer any additional insight on how BFAs can be made more meaningful and rigorous. We argue that BFAs should be reconsidered in order to close important gaps in how barriers and facilitators impact intervention implementation. We synthesized current approaches to conducting BFAs, and offered alternate methods and considerations for BFAs. BFAs published in the literature typically either report lists of BFs without describing specific relationships between BFs and implementation or clinical outcomes, or they report how the BFA contributed to program development, planning, adaptation, or evaluation (e.g., BFs were used to select strategies to implement the program). However, these studies have substantial limitations and do little to better interpret BFs, which is necessary to adapt programs and/or systematically develop implementation strategies. First, they are typically conducted before or after implementation, and do not explore the relationship between anticipated versus actual/experienced BFs. Second, they rely primarily upon self-report, although individuals tend to have a poor understanding of their own behavior. Third, they fail to examine dependencies between BFs (e.g., removing one barrier may uncover unintended consequences or "masked" barriers). BFAs would be enhanced by: 1) continuous assessment throughout implementation process; 2) considering their proximity to, and impact on, implementation; 3) integrating prioritization processes; 4) increased use of observation, qualitative, and mixed methods; and 5) integrating systems science methods that facilitate exploration of interdependencies. Given the centrality of BFAs in implementation science, it is critical that we continue to examine how they can be improved methodologically and how they might yield more accurate and actionable data. This study advances the field by presenting concrete suggestions for how BFAs could be improved. Demonstrating the value of coincidence analysis for identifying successful implementation strategies Sarah Birken 1 Background Coincidence analysis (CNA) is a configurational comparative method similar to qualitative comparative analysis, designed for causal inference when combinations of co-occurring conditions determine outcomes and multiple paths to one outcome may existas is often the case in implementation research. To demonstrate its usefulness in implementation research, we will use CNA to identify the strategies that cancer programs have used to develop comprehensive approaches to survivorship care plan implementation. The Commission on Cancer (CoC) requires cancer care providers to develop and deliver survivorship care plans (SCPs) to survivors and their primary care providers (PCPs). Cancer programs' approaches to implementing SCPs in practice substantially vary, ranging from cursory (i.e., developing SCPs to meet requirements without delivering them to survivors or PCPs) to comprehensive (i.e., promoting adherence to screening and health behavior guidelines and recommended utilization of follow-up care). We have characterized cancer programs' approaches to implementing SCPs using semi-structured telephone interviews with providers/ staff in 48 CoC-accredited cancer programs. We are using template analysis, combining a priori and emergent codes, and calibrating qualitative data for CNA purposes (e.g., the presence of a formal survivorship implementation committee). By the time of the conference, we will have used CNA to identify strategies that are unique to cancer programs with comprehensive approaches to implementing SCPs, using cancer programs with cursory approaches as a comparison group. The outcome of CNA will be a parsimonious list of strategies that are associated with comprehensive approaches to SCP implementation. Preliminary qualitative analyses suggest that programs varied in their approaches to SCP implementation. Key variables included human and financial resources and infrastructure, including standing committees and mechanisms of communication and garnering leadership support and provider buy-in. We will present CNA results at the conference. Conclusions CNA is a promising method for implementation research, where outcomes may be explained by combinations of co-occurring conditions, and when multiple paths to one outcome may exist. CNA findings are policy-relevant since they identify multiple combinations of strategies that diverse organizations may deem appropriate; findings from this study will inform more than 1500 CoC-accredited cancer programs with recommended SCP implementation strategies. Background Nationwide, 576,000 students were served for Autism Spectrum Disorder (ASD) during the 2014-15 school year, an increase of 51% from 2007-08 [1] . Given the significant increase in demand for educational services for students with ASD, there is urgent demand to improve implementation and sustainment of evidence-based practices (EBP) in school settings. However, the organizational and leadership structure for school-based services for ASD is complex and involves a team of providers to account for the complexity of care needed [2] [3] . Organizational culture and leadership have been found to impact EBP use in a variety of settings, but less is known about their impact in schools. As a first step toward tailoring implementation intervention for this context, the current proposal explores implementation leadership and implementation climate in relationship with provider factors. Participants were 340 school-based providers and administrators who are involved in supporting students with ASD. Participants included 19 Highlevel administrators (Special Education Directors, District-level Administrators), 112 Mid-level specialists (Autism Specialist, Behavior Specialist, Program Specialist) 15 School-site principals or administrators, 153 Teachers and direct service providers (DSP) and 33 Mental health providers (school psychologist, MFT). To explore the leadership structure within school-based services for ASD and the effect on implementation processes, a survey including the Implementation Climate Scale (ICS) [4] and the Implementation Leadership Scale (ILS) [5] was distributed to participants. Results Implementation climate and implementation leadership varied by profession. For the Selection for Openness domain on the ICS, Mental health providers (B=-2.28, p=.022), Mid-level specialists (B=-2.09, p=.020), and Teachers/DSP (B=-2.55, p=.004) all reported lower ratings than High-level administrators. For the Educational Supports domain on the ICS, Mental health providers (B=-2.08, p=.035), Teachers/ DSP (B=-2.16, p=.010), and School-site principals/administrators (B=-2.70, p=.029) all reported lower ratings than High-level administrators, while Teachers/DSP also reported lower ratings than Mid-level specialists (B=-.99, p=.018). For the Proactive Leadership domain on the ILS, Mental health providers (B=-2.39, p=.003), Mid-level specialists (B=-2.12, p=.002), and Teachers/DSP (B=-1.64, p=.016) all reported lower ratings than High-level administrators. Conclusion Implementation leadership and implementation climate vary across participants suggesting variability more broadly. Implications for implementation and sustainment of EBPs in school-based services will be discussed. A survey of supervisors' and managers' practices and needs to support evidence-based practice implementation in large behavioral health care system in New York state Sapana Patel 1 Background Managers and supervisors are the lynchpin of success to practice change within any organization. In a time when behavioral health organizations are being asked to shift culture, practice and delivery of care from volume to value, manager and supervisor roles are moving towards ensuring quality of evidence-based practice (EBP) implementation. We developed a survey to assess supervisor and manager experience with and needed supports for EBP implementation in community mental health agencies. We created surveys using the implementation science literature [1] [2] [3] and guidance provided by the Center for Practice Innovations [4] provider advisory committee. In March 2019, behavioral health agency leadership (N=4) across New York State invited their managers and supervisors to take part in the survey. Both surveys queried level of commitment and preparedness (scored on a Likert scale, e.g., 1 = not at all committed/prepared to 5 = very committed/prepared) to implement EBPs along with needed tools and supports to implement EPBs to fidelity. Surveys also included questions about EBP topics for additional training. Data collection will finish in June 2019. Of the 23 survey respondents (supervisors: n of 13; managers n of 10) half are social workers (n=12). Supervisors report that, although they are highly committed to EBP implementation (M = 4.42, SD = 1.11), they are only moderately prepared to implement EBPs (M = 3.92, SD = 1.11). Needed resources included example case conceptualizations, and workbooks to use with consumers. Managers' reports were similar: highly committed to EBP implementation (M = 4.80, SD = .40) and moderately prepared to implement EBPs (M = 4.10, SD = .83). Needed resources include worksheets for role modeling and train the trainers to support EBPs. Managers and supervisors identified trauma informed care and shared decision making as EBP topics that they need more training in. Managers and supervisors' commitment to EBP implementation is necessary, but far from sufficient. Managers and supervisors report feeling only moderately prepared to implement EBP and would benefit from training focusing on their roles in implementation, as well as tools and resources designed to help them. Background Provider attitudes, including knowledge-of and confidence using evidence-based interventions (EBIs), are important outcomes of training interventions and potential mechanisms of EBI delivery. This study utilized data from a Hybrid Type-1 effectiveness trial of AIM-HI (An Individualized Mental Health Intervention for Children with ASD), an intervention to reduce challenging behaviors in children with Autism Spectrum Disorder (ASD). The following objectives were addressed: 1) examine the effectiveness of AIM-HI training/consultation on changes in therapists' perceived knowledge and confidence (K&C) of ASD strategies, and 2) examine therapist demographic and professional characteristics as moderators of training effects. Data were extracted from a cluster randomized trial. Therapist/client dyads were randomized to AIM-HI or usual care. AIM-HI therapists received training/consultation for 6 months. Therapists (N=156) reported K&C at baseline and 6 months. Three K&C subscales were used in analyses: ASD Knowledge (ASD), (2) Knowledge of EBI ASD strategies (KNOW), and (3) Confidence in EBI ASD strategies (CONF). Repeatedmeasures ANOVAs were used in analyses*. A main effect of AIM-HI training was found for all K&C constructs; AIM-HI therapists reported greater increases compared to usual care therapists (p<.001). For AIM-HI, therapist role (Staff vs. Trainee) moderated changes in ASD (F(1,154)=4.72, p<.05), KNOW (F(1,154)=11.19, p<.01), and CONF (F(1,154)=6.60, p=.01); trainees reported greater increases than staff. Therapists' perceived ASD expertise moderated changes in ASD (F(1,154)=11.00, p<.001) and KNOW (F(1,154)=16.29, p< .001); therapists who did not consider themselves ASD specialists reported greater increases than their counterparts. Ethnicity moderated changes in CONF (F(1,154) =7.73, p<.05); minority therapists made more gains compared to White therapists. For usual care therapists, role moderated changes in ASD K&C (F(1,154) =7.4, p<.05); staff therapists reported increases in ASD knowledge, while trainees reported decreases. Therapists who received AIM-HI training reported greater changes in K&C compared to those in usual care. Additionally, for those in AIM-HI, therapist's cultural (ethnicity) and professional (role and ASD expertise) characteristics moderated the effect of training on K&C. Next steps include combining results with qualitative data to inform adaptations to improve intervention fit and maximize outcomes. *Results from multiple level modeling accounting for the nested structure of the data will be reported. The field of implementation science has advanced in recent years, but unfortunately this has coincided with a growing divide between the science and practice of implementation. One strategy to bridge this gap is training implementation practitioners to apply implementation science to their initiatives in a thoughtful and proactive way. Effective implementation capacity building should be based on core competencies -the knowledge, skills, attitudes, and behaviors needed to apply implementation science. There is a growing body of literature on core competencies for implementation scientists, but same progress has not been made for core competencies for implementation practitioners. Building applied implementation science capacity at the practitioner level can foster better implementation and overall improved population-level impacts; therefore, understanding the core competencies for applying implementation science at the front line is paramount. The goal of this project was to extrapolate and synthesize core competencies for implementation practitioners. We scanned the published and gray literature to identify core competencies for implementation practice. Six documents outlining (or including components of) core competencies for implementation practice were retrieved. Two analysts reviewed each document using a content analysis approach. Competencies relevant to implementation practice were extracted into an abstraction form and consolidated into a list of common competencies. The refined list of competencies was then grouped thematically into overarching implementation "activities" (e.g., understanding the problem, facilitating implementation). We identified 40 core competencies which we categorized into 10 implementation activities: Inspiring Stakeholders and Developing Relationships; Building Implementation Teams; Understanding the Problem; Using Evidence to Inform all Aspects of KT; Assessing the Context; Facilitating Implementation; Evaluation; Planning for Sustainability; Brokering Knowledge; and Disseminating Evidence. Additionally, we identified 5 values or guiding principles for implementation practice, which emerged from the document review. We are building an Implementation Practice Core Competency Tool which will be finalized by September. Conclusions This presentation will briefly highlight the methods and then focus on how to prioritize and select relevant core competencies for projects and individuals. The competencies can be used as a guide to prioritize capacity building efforts. The increased influence of implementation science has prompted an important question: if an organisation does not have personnel who are fluent in implementation science how do they apply it? Often an implementation expert, intermediary organisation or consultant is engaged. But who are they and what knowledge, skills and abilities must they have? There is limited literature on the core competencies of implementation practitioners including a lack of common terminology and title. However, there is emerging literature on the role, knowledge, skills and abilities that contribute to effective consultation for implementation [1] [2] . This presentation draws on this literature, our experience developing the implementation support capabilities of a purveyor/intermediary organisation (Triple P International) [3] learnings from Triple P International Implementation Consultants (TPI-ICs), who for over five years have supported organisations in the application of implementation science and with implementing organisations and practitioners. The presentation will use data from experience and the competencies and coaching literature to promote discussion about required competencies for implementation practitioners. A review was undertaken to examine the role and responsibilities of the TPI-ICs. This included a review of existing literature; a survey of TPI-ICs (n=27) and a review of internal support systems and processes. The following areas were identified as areas of significance for competencies: Partnering with implementing organisations; determining fit; establishing relationships and roles; facilitating implementation planning; monitoring and evaluating; establishing the innovation as usual practice. Results from the survey identified self-reported levels of confidence and competence in knowledge, skills and abilities related to implementation consultation. The review of existing systems and process identified areas for improvement and increased structure to support desired outcomes. Results were then used to inform the development of TPI-IC Competencies, and a comprehensive IC Management and Support Process. The presentation will describe knowledge-base, processes and characteristics for IC Competencies, IC Management and Support Process. It aims to promote discussion on future areas of practice development as well as exploring ways that additional research could help advance our understanding and further develop the field. Despite rigorous efforts to disseminate evidence-based treatments (EBTs) for posttraumatic stress disorder (PTSD) in community settings and major medical systems such as the Veterans Health Administration, penetration rates for these treatments have been suboptimal [1] [2] . Understanding of provider-related and client-related barriers and challenges to EBT implementation is crucial to improving EBT reach with community mental health settings. This is a naturalistic study of perceived implementation barriers and challenges for EBTs for PTSD in a sample of community providers who were trained in cognitive processing therapy or prolonged exposure for PTSD by the STRONG STAR Training Initiative (SSTI), a comprehensive competency-based training program designed to disseminate EBTs. To date, 42 community-based mental health providers completed a survey 12 months after completing an in-person SSTI training workshop. The follow-up survey assessed the barriers to initiating evidence-based treatments as well as the challenges with implementing EBTs with PTSD clients. At 12-month post-training, 64% of providers endorsed at least one client-related barrier, while 19% reported at least one therapist-related barrier to initiating an EBT with clients diagnosed with PTSD. The most common barrier to initiating treatment was client's declining the use of an EBT (57% of providers). The barrier endorsed the least was discomfort introducing EBTs (0%). When looking at challenges to implementing EBT for PTSD, 83% of providers reported at least one challenge, with 55% of providers reporting 1-2 challenges, and 29% reporting 3 or more. The most common challenges to implementing an EBT included: client disinterest in engaging in EBT (50%), a difficulty obtaining an appropriate referral (45%), a lack of clients with PTSD on caseload (31%), and a difficulty taking time away from regular work to attend consultation call (14%). The challenge endorsed the least was the lack of motivation to use a new treatment (2%). The results of this study suggest that the majority of community providers report experiencing challenges with both, EBT initiation and implementation. Understanding barriers to initiation and implementation can guide trainers and organizations in addressing provider concerns thereby improving dissemination and implementation efforts. High quality mental health services do not reach the youth who need them, leading to efforts to implement effective treatments more broadly. One focus of these efforts concerns training the mental health workforce, of which masters-level social workers represent a large proportion. However, the curricula of master's in social work (MSW) programs do not often emphasize evidence-based approaches. One possible solution is Managing and Adapting Practice (MAP; Practice-Wise, LLC), a system that allows clinicians to (1) identify clinically indicated evidence-based programs by searching a growing evidence-base of randomized controlled trials (RCTs) and (2) build individualized evidence-informed treatment plans by focusing on common practice elements. MAP may also address the concerns about manual-based programs (e.g., inflexibility). Although some MSW programs have integrated MAP, the benefits of MAP training within MSW education have not yet been evaluated. This project evaluated multiple mechanisms of training [1] in a semester-long MSW-focused MAP course relative to curriculum-as-usual control at a large public university. Participants were advanced MSW students (mean age = 27, SD = 5.8; 92.3% women; 59% white) either enrolled in the MAP course (n = 17) or enrolled in curriculum-as-usual (n = 22). The MAP course was cotaught by an expert MAP trainer and a MAP-trained social worker. Pre-and post-semester, participants completed a battery that included: (1) role-plays with standardized patients that were videotaped and coded using the Therapy Observational Coding System of Child Psychotherapy -Revised Strategies scale [2] ; (2) a written task that was subsequently coded to assess participants' clinical decisionmaking skills during different phases of a standardized case; and (3) attitudinal factors that may be predictive of future MAP usage, such as attitudes toward evidence-based practice [3] and the acceptability and feasibility of MAP [4] . Results indicate significant uptake of cognitive and behavioral therapeutic strategies in the MAP condition. Overall, participants endorsed positive attitudes toward evidence-based practice broadly and MAP specifically. Findings may be used to inform the development of more effective evidence-informed curriculum for masters-level clinical programs and future workforce training initiatives. Methodological considerations may inform advances in instrumentation to measure multidimensional training outcomes. Few evidence-based practices (EBPs) are successfully installed into school settings [1] . Integrating implementation considerations into early stages of intervention evaluation and collaborating with relevant stakeholders are recommended to reduce the gap between EBP evaluation, adoption, implementation, and sustainability [2] [3] [4] . As part of a schoolbased prevention trial, school stakeholders participated in intervention training and implementation with a goal of sustaining the intervention at the schools after the study's conclusion. This presentation explicates lessons learned via the study of stakeholder involvement, which in-turn informed subsequent implementation and evaluation efforts. Over three years, 20 urban public schools were recruited for a randomized trial assessing two wellness programs, one targeting eighth graders' emotion regulation and decision-making (RAP Club) and the other health education (Healthy Topics). At each school, middleschool teachers and school-based mental health providers were recruited as intervention "co-facilitators in training." One school mental health provider per school received training in RAP Club, and one middle school teacher per school received training in Healthy Topics (N = 40 across all schools). Stakeholder attendance and engagement during intervention training, supervision calls, and intervention sessions were recorded. School characteristics (e.g., organizational health), stakeholder interviews, and process notes further informed our investigation of stakeholder engagement in training and implementation. Most stakeholders attended intervention training; however, attendance on supervision calls was limited. Two-thirds of school personnel were regularly present during intervention sessions, but fewer than half actively participated. Stakeholder participation and engagement increased each year of the trial. Individual-and school-level factors were related to participation in training, supervision, and implementation. Findings will be used to refine personnel training and supervision (e.g., augmenting structure, explicating goals) for the final year of trial implementation. Evaluating stakeholder involvement in intervention training and implementation has been critical in informing this research team's approach to stakeholder training and supervision to support implementation and sustainability. Our findings illustrate both challenges and opportunities for increased stakeholder involvement in implementation. Factors influencing stakeholder participation, assessed during controlled trials, can be leveraged to inform subsequent evaluations, as well as program adoption, implementation, and sustainability. [1] [2] . However, the reach of these implementation initiatives has rarely been studied. In the current study, we describe a county-wide youth mental health (MH) initiative supported by a voter-approved sales tax. This initiative aims to improve access to effective youth MH services by providing free training, consultation, and support in evidence-based practices (EBPs) to MH service providers. The current study has three aims: 1) describe the providers reached by the initiative, 2) examine which training activities providers engage in (i.e., formal workshops; learning collaboratives; individual consultation), and 3) explore differences in providers (e.g., discipline; attitudes; knowledge) who do and do not invest in training activities. Participants (N = 523) were community MH providers who completed a web-based baseline assessment prior to registering for the EBP trainings. Measures included demographics, clinical practice information, self-reported confidence, organizational climate [3] , and EBP knowledge [4] , attitudes [5] , and practice [6] . The initiative reached over 500 providers who were part of over 100 different organizations and private practices. Registered providers were predominantly master's level (N = 277, 53.06%), representing social work (N=178, 34.10%), counseling (N=140, 26.82%), psychology (N=61, 11.69%), and other MH disciplines (N=143, 27.34%). Some 159 (34.40%) were fully licensed MH providers, 69 (13.19%) post-degree but unlicensed, 119 (22.75%) student trainees, and 176 (33.65%) none or other types of licensure (e.g., RN, MD). Providers on average had been providing MH services for 8.13 years (SD = 8.52, range = 0 to 45). Registered providers participated most frequently in formal workshops (69.79%, N=365,) and less often in small group learning collaboratives (7.07%, N=37) and individual consultation (6.88%, N= 36). Initial findings showed significant, positive associations between baseline EBP attitudes (r=.11, p=.01) and knowledge (r=.13, p<.01) and the number of formal workshops attended. The initiative reached a high proportion of MH providers and organizations; however, far fewer actually participated in any training activities. The more in-depth, personal training and support components were the least utilized. Implications for voluntary implementation initiatives within community MH care will be discussed. Background Successful implementation reflects the interplay between intervention, implementation strategy, and context [1] . Hybrid effectivenessimplementation studies allow investigators to assess intervention effects on patient health alongside implementation strategy effects on implementation outcomes [2] [3] [4] , though the role of context as a third independent variable (IV) is incompletely specified. Our objective is to expand the hybrid effectiveness-implementation framework to include mixtures of all three types of IVs: intervention, implementation strategy, and context. We propose to use I to represent the IV of intervention, IS to represent implementation strategy, and C to represent context. The expanded framework specifies nine two-variable hybrid designs: I/is, I/IS, IS/i, IS/c, IS/C, C/is, C/i, I/C, and I/c. We describe four in detail: I/is, IS/c, IS/C, and C/is. We also specify seven three-variable hybrid designs that follow from the two-variable designs. We argue that many studies already meet our definition of two-or three-variable hybrids. Our proposal builds naturally from the typology proposed by Curran et al. [2] , but offers a more complete and clear specification of designs that might be of interest to implementation researchers. We need studies that are designed and powered to measure the implementation-related effects of variations in contextual determinants, both to advance the science and to optimize delivery of interventions in the real world. Prototypical implementation studies that evaluate the effectiveness of an implementation strategy, in isolation from its context, risk perpetuating the persistent gap between evidence and practice, as they will not generate essential contextspecific knowledge around implementation, scale-up, and deimplementation. The Promoting Action on Research Implementation in Health Services (PARIHS) framework was developed two decades ago and conceptualizes successful implementation (SI) as a function (f) of the evidence (E) nature and type, context (C) quality and the facilitation (F), [SI = f (E,C,F)] [1] [2] [3] [4] . Despite a growing number of citations of theoretical frameworks including the PARIHS, details of how theoretical frameworks are used remains largely unknown. This review aimed to enhance the understanding of the breadth and depth of the use of the PARIHS framework. This citation analysis departed from four core articles representing the key stages of the framework's development. The citation search was performed in Web of Science and Scopus. After exclusion, we undertook an initial assessment aimed to identify articles using PARI HS and not only referencing any of the core articles. To assess this, all articles were read in full. Further data extraction included capturing information about where (country/countries and setting/s) PARI HS had been used, as well as categorizing how the framework was applied. Also, strengths and weaknesses, as well as efforts to validate the framework, were explored in detail. The citation search yielded 1,163 articles. After applying exclusion criteria, 1,059 articles were read in full, and the initial assessment yielded a total of 259 articles reported to have used the PARIHS framework. These articles were included for data extraction. The framework had been used in a variety of settings and in both high-, middle-and low-income countries. With regards to types of use, 28% used the PARIHS in planning and delivering an intervention, 49% in data analysis, 55% in the evaluation of study findings, and/or 46% in any other way. Further analysis showed that its actual application was frequently partial, and generally not well elaborated. In line with previous citation analysis of the use of theoretical frameworks in implementation science we found a rather superficial description also of the use of the PARIHS. Thus, we propose the development and adoption of reporting guidelines on how framework(s) are used in implementation studies, with the expectation that it enhances the maturity of implementation science. How are health policy implementation outcomes measured quantitatively? a review protocol Peg Allen 1 , Cole Hooley 1 , Meagan R. Pilar 1 , Cara C. Lewis Background Evidence about effective strategies in clinical care and population health is growing, with a number of evidence-based policy approaches now recommended in the Community Guide [1] and other systematic reviews. But understanding lags on how best to implement recommended policies to reap the full population health benefits. Information is limited on how to quantitatively measure policy implementation outcomes [2] . To address this gap a systematic review has begun to identify and rate quantitative measures of health policy implementation outcomes and predictors. We are reviewing published academic journal articles to identify the state of quantitative measurement of health policy implementation. To guide the systematic measures review, we combined two frameworks impacting policy implementation: 1) for internal context, the Consolidated Framework for Implementation Research; [3] and 2) for external context, Bullock's policy implementation determinants framework (under review). We are applying Lewis et al.'s measures review protocol and PAPERS rating system [4] . We searched these databases: CINAHL Plus, Medline, PsychInfo, PAIS, ERIC, and Worldwide Political. The four search strings included multiple search terms for: health, public policy, implementation, and measurement. We will code measures to implementation outcomes [5] and predictors. Inclusion criteria: 1) empirical study of the implementation of public policies already passed or approved addressing physical or behavioral health; 2) quantitative selfreport or archival measures utilized; 3) peer-reviewed journal publication 1995 through April 2019; and 4) English language text. We will screen abstracts April-June 2019. In July-August 2019 we will review and extract full texts. We will present yields, characteristics of included articles, and description of several identified quantitative policy implementation outcome measures. We will show plans for fall/winter 2019 pragmatic measure rating, summarization, and web-based posting. We seek feedback from policy implementers and researchers on remaining procedures. We especially want feedback on design of a publicly available web-based summary of identified measures and pragmatic properties to ensure usefulness to policy implementers and researchers. We are collaborating with SIRC on methodology and dissemination. The measures summary is intended to stimulate further assessment of health policy implementation outcomes and predictors to help practitioners and researchers spread evidence-informed policies to improve population health. Background Collaborative Care (CoCM) has been shown to be an effective way to treat depression and other mental illness in primary care and other settings. Evaluating whether or not clinics that receive training and technical assistance to implement CoCM maintain fidelity to the core components proven in other research to predict better patient outcomes has received little attention. A scalable measure clinics can use to measure fidelity is needed. This analysis discusses the creation and evaluation of an instrument specifically designed to measure multiple domains of CoCM fidelity. Development of the CoCM fidelity tool occurred in three steps. Step one was development of a rubric that was utilized during in-person site visits with a group of HRSA-funded clinics. In Step two the rubric domains were adapted based on the outcomes of these site visits and incorporated into a qualitative interview guide administered to care managers trained in CoCM within the preceding six months to assess fidelity. Step three focused on converting the rubric to a selfadministered format so it can be used by organizations to self-assess fidelity to core CoCM components. In Step one, clinics had an average rubric score of 3.09 "core features Implemented" (range 2.16-4.59) out of a possible 5.0 which indicates "exceptional Implementation." Step two transcript data from qualitative interviews revealed that care managers are able to link their clinic's current CoCM processes to core CoCM concepts in the fidelity rubric. Findings from development of the rubric and qualitative interviews will be presented. The Step three self-administered rubric will be tested in 24 clinics across the United States participating in a CoCM implementation. We will compare this data to clinic outcomes in order to determine validity. Conclusions A self-administered instrument to assess CoCM fidelity in primary care clinics is feasible and further evaluation will allow us to connect use of the rubric to patient-level clinical outcomes and provider-level outcomes among all members of the CoCM team (care manager, primary care provider, psychiatric consultant).  In collaboration with PBM, in 2017 for the DMF initiative (n=143) and in 2018 for the remaining four initiatives (n=142) all VISN Pharmacy Executives (VPEs) emailed web-based surveys to a designated pharmacist at each of their facilities. Goal was to understand which among the seven strategies were being used by the facilities to implement the specific MUET initiative, and their perceived value. We also assessed barriers for facilities not using the implementation strategies. Response rates were as follows: 2017 (n=127, 89.0%) and 2018 (n=131, 93.2%). The most commonly used implementation strategies by pharmacists were provider education (26.6%), patient mailings (23.5%), using electronic reminders (21.2%) and entering draft orders (14.3%). Comparatively, pharmacists perceived provider education as being most useful (27.6%) along with having patient specific care plans (24.6%) and using electronic reminders (18.8%). Pharmacists at facilities which did not implement one or more strategies reported barriers like time-consuming/not enough staff (43.6%), they didn't believe this would work (22.7%), to implement they needed help from other services/departments (18.6%) and some pharmacists believed this was inappropriate work for a pharmacist (14.9%). Pharmacists perceived provider education as the most useful strategy to monitor medication safety for their patients. Formative evaluation focuses on the identification and adoption of best practices to improve medication safety for the Veterans. While certain studies define sustainability as the continuation of programmatic activities over time, others conceptualize sustainability as the continued delivery of benefits to target populations and the maintenance of collaborative structures within communities [1] . Ultimately, conflicts between these definitions disrupt the continuity of program sustainability research and focus. With public health funding in perpetual jeopardy, a cohesive, solidified definition of program sustainability has never been more necessary. The study began with an extensive systematic literature review of program sustainability research, including empirical research, case studies, fieldwork, and commentaries. This process outlined various proposed definitions of sustainability and cataloged organizational metrics tied to sustainability outcomes. The target audience for the current study utilized evidence-based state tobacco control (TC) programs. Therefore, the second part of the methodology included consultations and interviews with key tobacco control specialists, sustainability experts, academics, and practice-oriented professionals. These interviews were then cross-referenced with the literature to find commonalities between theory and practice. Finally, the study team collected and analyzed federal progress reports submitted annually by these TC programs. The items outlined in these reports were referenced back to the previously identified sustainability metrics [2] [3] . The organizational metrics described in the literature were aligned to the evidence-based Program Sustainability Framework. This framework defines the internal and external factors operationalized into eight domains that affect a program's capacity for sustainability [4] [5] . Through this process, institutionalization emerged as the primary measure of sustainability found in both the literature and dialogue. To this effect, the establishment of a program through formal organizational rules and funding was widely perceived to ensure the delivery of continued program initiatives and benefits. The results further distinguish between programmatic, organizational, community-level factors, and funder support, suggesting sustainability planning must account for institutional scope. This concise definition will enable valid, empirical comparisons of sustainability across programs in various public health contexts. Background Training healthcare providers in Motivational Interviewing or similar patient-centered behavioral interventions is increasingly popular [1] ; however, gold-standard methods to assess skill acquisition and ongoing quality assessment are laborious and impractical in busy healthcare settings. We examined the utility of a brief measure requiring modest training, the Behavior Change Counseling Index (BECCI) [2] , to pragmatically capture provider skill in patient-centered alcohol counseling. The present study includes a multidisciplinary sample of routine trauma center providers (N = 69) trained to counsel trauma patients about risky alcohol use as part of a 25-site National Institutes of Health-funded pragmatic trial of a collaborative care intervention [3] . Providers were predominantly White (79%) females (87%) with at minimum a bachelor's degree. Providers completed a pre-training 20-minute standardized patient role-play in which they counseled a patient actor about alcohol use. At the end of the role-play, the standardized patient actor completed the brief (<5 minute) 12-item BECCI measure. Audio recordings of the role-plays were subsequently coded by an objective rater using the Motivational Interviewing Treatment Integrity Scale (MITI), a longer gold-standard measure that requires intensive training [4] . No previous studies have directly compared the BECCI and the MITI. We examined correlation coefficients (Spearman's rho for skewed MITI variables) between overall BECCI scores and MITI empathy and summary scores. The overall BECCI scores were highly and statistically significantly (p < .05) correlated with key patient-centered counseling style MITI scores (empathy r = .70, spirit r = .74, MI-adherent r = .51) and the behavioral count scores of percent open questions. (rs = .56) and reflection-toquestion ratio (rs = .60). BECCI scores were moderately and statistically significantly correlated with percent open questions (rs = .33). The BECCI is a pragmatic measure of patient-centered behavior change counseling that may be useful for routine use in healthcare settings to assess counseling quality. Given that the BECCI does not require extensive training it may be used by either a trainer/supervisor or peer to pragmatically assess various training sessions (e.g., behavioral rehearsal [5] ) as well real patient interactions (live or audio-recorded). To ensure appropriate transfer of successful implementation strategies from research to policy and practice, it is important to use tools or processes to measure and support fidelity to a given strategy's core components [1] . Unfortunately, this aspect of implementation science is underdeveloped and infrequently applied [2] . Implementation facilitation (IF) is a dynamic strategy involving interactive problem-solving and support to help clinical personnel implement and sustain a new program or practice that occurs in the context of a recognized need for improvement and a supportive interpersonal relationship [3] . Identifying core components of IF is a foundational step in efforts to develop tools to assess fidelity to the strategy. First, we conducted a scoping literature review to identify the range of activities applied in IF strategies. PubMed, CINAHL, and Thompson Scientific Web of Science databases were searched for English-language articles that included the term "facilitation" or other commonly used terms for the strategy published from January 1996 -December 2015. Initially, 1,489 citations/abstracts were identified and screened for relevance by two independent reviewers. Ultimately, 135 articles (from 94 studies) were identified for abstraction of data on facilitator characteristics and roles/activities, clinical setting, patient population, clinical innovation targeted for implementation, and implementation outcomes. Next, we engaged an Expert Panel in a rigorous 3-stage modified Delphi process to develop consensus on core IF activities for high complexity and low complexity clinical innovations in three implementation phases (pre-implementation, implementation, sustainment). Background All over the word medical interventions in child-birth are increasing [1] . Since 2014, in Germany, there exists a national nursing expert standard to promote physiological child-birth, which demands antenatal consultation conducted by midwives who are employed by a hospital. National expert standards define an evidence-based and practitioners consented quality level using Donabedian's model of structure, process and outcome criteria [2] . During the pilot implementation period (6 month in 2015) in 13 German hospitals, the antenatal consultation was not evaluated. Thus, to what extent antenatal consultation was implemented and how implementation success looks like remained unclear. The aim of this study is to investigate implementation fidelity (adherence, participant responsiveness) [3] and sustainability (benefits, institutionalization, development) [4] of antenatal consultation in two hospitals. A mixed-methods design has been chosen, including a quantitative content analysis of consultation documents (n=154) and 34 qualitative semi structured interviews with midwifes, pregnant women, physicians and managers in two hospitals in Germany. A descriptive analysis was undertaken for the documents. The interviews were analyzed using framework analysis [5] . Adherence is higher in hospital B, which had a longer timeframe for implementation than hospital A. Furthermore, hospital B had already experience in consultations. Participant responsiveness was very positive in both hospitals. In both hospitals, the interviewed persons saw benefits. Institutionalization is also given in both hospitals, but differs regarding time frame and consultation process. A need for evaluation of the change over time of the needs of women and tailoring interventions to these needs was seen in hospital B, but not in hospital A. Implementing antenatal consultation in German hospitals is feasible but it needs more time than the pilot implementation of 6 month. Based on the study, it seems that a longer time period (~12 months) and a positive attitude to adapt to new developments increases implementation outcomes. Furthermore, flexibility in applying the 4step implementation model, securing resources, and convincing all stakeholders might have had an impact on feasibility. Additionally, there is a need to evaluate antenatal consultation after the woman gave birth. Background A substantial evidence base supports the use of practice facilitation as an effective strategy to enable implementation of evidence-based practices and related quality improvement (QI) efforts in learning healthcare systems [1] [2] [3] . Yet, challenges with implementing and maintaining facilitation exist and may impede efforts to grow and sustain an experienced facilitator workforce. This study identifies potential challenges facilitators may experience when working with QI teams in real world settings and recommends strategies to address these challenges. The Coordination Toolkit and Coaching (CTAC) project is a VA-funded QI initiative to improve patient experience of care coordination in primary care. Using a cluster-randomized design, 12 primary care clinics were randomized to either a passive strategy (access to the CTAC online toolkit) or an active strategy (distance-based coaching plus access to the toolkit). Over a 12-month period, two facilitators delivered weekly, one-hour coaching calls to six clinics implementing a QI project of the clinic's choice. Data sources included facilitator reflections catalogued after all coaching calls (n=232) and notes from debrief sessions between facilitators. We identified nine facilitation stressors: lack of progress/followthrough; changes to the coached team; emotion/frustration directed at the facilitator; mismatched expectations between the facilitator and coached team; managing project timeline and deliverables; supporting QI methods and data collection; managing team dynamics; promoting effective communication; and documenting implementation and facilitation processes. Given these stressors, we recommend that facilitators: continually re-assess process improvement activities and QI methods (e.g., aligning goals with project timeline); moderate discussions to help anticipate and resolve common challenges to process improvement (e.g., staffing turnover, within-team conflict); support teams with appropriate data collection and analysis; and set aside time to self-reflect (e.g., debrief sessions), discuss (e.g., with a co-facilitator), and make necessary adjustments to their facilitation process. Understanding how facilitation affects facilitators and providing facilitators with tools to address stressors are essential for sustainability of QI and other process improvement efforts, and for continued use of facilitation as an implementation strategy. Identifying facilitation stressors and strategies to overcome them may enhance the development and maintenance of an experienced facilitator workforce to support the next generation of process improvement. What makes an enabling context for mental health delivery? differential workload adjustment to sustain task-sharing delivery across education and health sectors in a low resource setting Background Evidence suggests mental health interventions can be effectively delivered via task-sharing in low-resource settings with high need for mental health interventions; [1] [2] [3] however, research is needed to identify approaches to sustain the delivery in these settings. [4] Materials and Methods We examine qualitative reports of lay counselors experienced in delivering group-based trauma-focused cognitive behavioral therapy (TF-CBT) for orphaned children and adolescents in western Kenya. We analyze implementation policies and practices (IPPs) associated with delivering TF-CBT in the health and education sectors in order to determine impactful and feasible IPPs to sustain task-sharing delivery in a low-resource setting. Eighteen teachers and 18 community health volunteers (CHVs; N = 36) participated in qualitative interviews after delivering two groups of TF-CBT. Thematic coding for IPPs was conducted by a team including one PI. Interviews were double-coded and discussed to consensus; a third coder was consulted when discordant. Less than half (n = 17) of the interviews were in Swahili and were coded by a member of the study team fluent in Swahili and English; then, all Swahili interviews were translated verbally and discussed to consensus with a PI. Workload adjustment emerged as a critical and feasible IPP for sustaining task-sharing in the education sector: 83% of teachers (n = 15/18) indicated that limited or no workload adjustment was a barrier to implementation. However, it was minimally important in the health sector, with only 17% of CHVs (n = 3/18) indicating workload adjustment was a barrier. Teachers at urban schools (n = 6) were more likely to report workload adjustment as a facilitator than teachers at rural schools (n = 12). Examples of workload adjustments include adjustments of individual schedules (68% urban teachers versus 0% rural teachers), adjustment of school schedules (50% versus 8%), and exemption from meetings (50% versus 17%). Sustainable implementation strategies are needed to address large-scale health inequities in low-resource settings. [5] We found differential use and importance of workload adjustment in two sectors (both unique and overlapping), which enables tailored implementation support depending on the sector and setting (urban, rural). Our results can inform future implementation and sustainment of task-sharing interventions in low resource settings. A key question in implementation science is how to balance adaptation and fidelity in translating interventions to new settings. Most psychological interventions carried out in low-and-middle-income countries (LMICs) were originally developed in high-income countries. There is growing consensus regarding the importance of, and processes for, planned adaptations so that interventions are delivered in contextually sensitive ways. However, little research has examined ad hoc adaptations, or those that occur spontaneously in the course of intervention delivery. A key question is whether ad hoc adaptations ultimately contribute to or detract from intervention effectiveness. This study aimed to (a) identify ad hoc adaptations made during delivery of a family therapy intervention and (b) assess whether they promoted or hindered intervention goals. Tuko Pamoja (Swahili: "We are Together") is an evidence-based family therapy intervention aiming to improve family dynamics and mental health, being delivered in Eldoret, Kenya. Tuko Pamoja is delivered by lay counselors, who are afforded a degree of flexibility in the way they present intervention content and the practices they use in therapy sessions. This study used transcripts of therapy sessions with 14 families to develop a taxonomy of ad hoc adaptations used by counselors. We first identified and characterized these adaptations. Then, we evaluated to what extent they were in the spirit of the intervention or went against the goals of the intervention. Ad hoc adaptations included the incorporation of metaphors and proverbs, religious content, self-disclosure, examples and role models, discussing interpersonal relationships outside of the family, and community dynamics and resources. For the most part, practices were Tuko Pamoja-promoting, though Tuko Pamoja-contrary practices were also identified. Identifying helpful ad hoc adaptations and incorporating them into interventions could improve acceptability, feasibility, and effectiveness. There is increasing recognition that local program adaptations may be instrumental to sustaining evidence-based interventions in routine clinical practice. [1] However, few empirical studies have documented naturally occurring adaptations made during the implementation process by providers and agencies in health care settings. Our research directly addresses the SIRC conference theme, "Where the Rubber Meets the Road," by identifying and categorizing provider-initiated adaptations to an evidence-based health promotion practice implemented nationally in routine mental health care settings. Our team conducted semi-structured telephone interviews with program staff from 35 behavioral health organizations 24 months after they implemented InShape, a manualized evidence-based health promotion practice for persons with serious mental illness, within the context of an NIMH-funded implementation study. The interview protocol included questions that assessed core fidelity components of the InSHAPE model, with probes used to explore any adaptations made to core components. An adaptation was defined as a change to the intervention content or method of delivery that was not specified in the original treatment manual. We explored the reasons why an adaptation was made as well as who initiated it at the agency. Two investigators independently reviewed interview transcripts to identify adaptations to the program. Adaptations to InSHAPE included hybrid individual and group programs, home-based exercise programs, technology-based enhancements, such as mobile fitness apps and wearable activity trackers, and use of peer support specialists to deliver program components. The next level of analysis will involve classifying adaptations as fidelityconsistent (i.e., changes that do not significantly alter core model elements) and fidelity-inconsistent adaptations (i.e., changes that reduce the delivery of core model elements), [2] and categorizing the drivers of adaptations (e.g., client-driven, financially-driven). We will then evaluate the impact of these adaptations on client-level health outcomes. Evidence-based practices are often modified by agencies when translated from research environments to real world health care settings. [3] However, the impact of these adaptations on client health outcomes is not well understood. By identifying and characterizing site-specific adaptations, we will be able to explore the relationship of adaptations to program-and participant-level outcomes and sustainability of the InSHAPE program at the completion of the study. Evidence-based quality improvement for accelerating patientcentered medical home implementation: impact on patientprovider communication Background High-quality patient-provider communication is foundational to patientcentered care and a core component of the Patient-Centered Medical Home (PCMH) [1] . The PCMH model could disrupt patient-provider communication by shifting communication responsibilities to non-provider PCMH team members [2, 3] . We introduced Evidence-Based Quality Improvement for PCMH transformation (EBQI-PCMH) at seven Veterans Affairs (VHA) primary care practices. Quality improvement (QI) methods to address PCMH implementation challenges included improving patientprovider communication. This paper examines EBQI-PCMH effectiveness for improving patient-provider communication over time, compared with standard PCMH implementation (PCMH-only). We used a non-randomized stepped wedge design in which sites entered in three phases, 6-8 quarters apart. We compared Veterans' experiences at 10 VHA practices (seven EBQI-PCMH versus three PCMH-only) on patient-provider communication. In PCMH-only transformation, providers and staff in all primary care sites received training in motivational interviewing and patient-centered communication. In EBQI-PCMH sites researchers partnered with clinical leaders to support local development of QI projects addressing patient-provider communication. We used repeated cross-sections of nationally-administered patient experience surveys from 2009-2015 to assess EBQI-PCMH impacts (N=34,193) . Outcome measures included patient ratings of four provider communication skills: 1) explaining information (EXPLAIN), 2) listening (LISTEN), 3) showing respect (RESPECT), and 4) spending enough time (TIME), and rated as optimal for scores 9-10 vs lower. Predictors included time, EBQI-PCMH implementation, and length of exposure to EBQI-PCMH. We compared EBQI-PCMH to PCMH-only practice sites using multilevel, multivariate modelling controlling for patient and site characteristics and weighted for non-response. Patient ratings of all provider communication skills improved with longer exposure to EBQI-PCMH, adjusting for patient and site characteristics. Each additional quarter of exposure to EBQI-PCMH was associated with improved odds of optimal communication: 2.75% increase in EXPLAIN, 2.95% increase in LISTEN, 2.70% increase in RESPECT, and 2.29% increase in TIME. For example, over the span of the evaluation period (23 quarters), the predicted probability of higher rating for EXPLAIN was 76%, 73%, and 68%, for EBQI-PCMH for Phase 1, 2, 3 versus 63% for PCMH-only. Conclusions EBQI-PCMH that engages leaders, providers and staff in researchersupported QI to accelerate patient centered transformation can be effective in improving patient-provider communication. Background Quality improvement efforts and implementation science use facilitation as an effective implementation strategy. Limited work has examined the successes and challenges of this strategy from the facilitator's perspective, which could shed light on evaluation of facilitation effectiveness and success of implementation efforts [1] [2] . We conducted thematic analysis on qualitative data from the Coordination Toolkit and Coaching (CTAC) project, a multi-site quality improvement initiative within the VA healthcare system. Two CTAC facilitators ("coaches") logged their perceptions of the successes and challenges in a "reflection" template completed after each weekly one-hour coaching call over the 12-month project period. Given CTAC is ongoing, this analysis examines the successes and challenges identified for one coached site (n=41 reflections). Two members of the project team independently coded the reflections to identify common themes related to successes and challenges resulting from the coaching process. We identified 15 total themes related to successes or challenges, of which six were categorized as both a success and a challenge: Project participation and engagement; Communication between coach and coached team members; Managing team dynamics; Conflict resolution; Time management; and Call productivity (e.g., progress on CTAC deliverables, project tasks, or products). For example, for the theme of moderating team dynamics, coaches described obtaining "buy-in from all the stakeholders and facilitating the discussions between them" as a success but simultaneously noted that "balancing nursing priorities/frustrations with administrative staff's priorities/frustrations" was a challenge. Similarly, for the theme of communication, coaches noted "encouraging more people to speak up" as a success but also "getting them to be more verbal during the call" as a challenge. Facilitation is increasingly used as an implementation strategy, yet the successes and challenges experienced by facilitators during the facilitation process are not well-defined [3] . Given that effective facilitation may lead to positive implementation outcomes, facilitation success should be examined carefully. Our findings indicate that some aspects of coaching can be assessed as both successes and challenges, highlighting the complexity of the facilitation process. Better understanding facilitation effectiveness will support a more nuanced conceptualization of how implementation efforts that use facilitation either fail or succeed. Trial Registration ClinicalTrials.gov NCT03063294 Building an impactful implementation support model to scale-up a quality improvement program in long-term care Andrea Chaplin, Sam MacFarlane Public Health Ontario, Toronto, Ontario, Canada Correspondence: Andrea Chaplin (andrea.chaplin@oahpp.ca) Implementation Science 2020, 15(Suppl 2):A125 Background A provincial agency is working to scale an organizational improvement program that supports long-term care homes overcome barriers to aligning with evidence based practices related to the assessment and management of urinary tract infections [1] [2] . These practices, if addressed, could help reduce the overuse of antibiotics that are contributing to antibiotic resistance and increased risk of antibiotic side effects. The initial pilot of this program involved agency staff delivering in-person support to an implementation team that was established in 12 long-term care homes. With over 600 long-term care homes in the province of Ontario, a more efficient implementation support model was needed. The purpose of this phase of the project was to apply best practices from implementation science to develop and evaluate a new implementation model that could be used to scale-up the program. The Quality Implementation Framework [3] and evidence-based system for innovation support [4] were used to inform the development of implementation supports at the agency and long-term care home level. Five agency staff conducted readiness conversations and delivered group-based online implementation training sessions to leads from 44 long-term care homes. Two online surveys were administered to the leads from each home to assess fidelity to the program recommendations and to gather feedback on the quality of the training sessions. Participation rates were variable, with only 29% of long-term care homes attending all three scheduled sessions. Of the homes that continued with the program, over 70% had adopted implementation strategies designed to support readiness and buy-in for the practice changes. In April, data from the final survey will be analyzed to describe what program strategies were used by participating homes based on a fidelity measurement tool established for the program. An online and group-based implementation support model has proven to be efficient in reaching more homes; however, there is a need to assess the implications of this higher touch approach on program fidelity. This model has raised questions about how an intermediary can support stakeholders secure buy-in, plan for sustainability, and be inspired to adopt approaches from implementation science. Early lessons from formative evaluation of an implementation intervention to improve reach of evidence-based psychotherapies for PSTD Princess Ackland 1,2 , Shannon We used toolkit-guided external facilitation to improve access to evidence-based psychotherapies (EBPs) for PTSD in two outpatient PTSD clinics with low reach of EBPs (≤15% Veterans with PTSD) at baseline. The Promoting Action on Research Implementation in Health Services framework informed the implementation strategy and evaluation [1] . The objective of this study is to describe preliminary results from the formative evaluation. Developmental evaluation data included pre-site visit interviews with 4-6 key informants and baseline data on the primary implementation outcome-EBP reach, defined as the percentage of unique patients who receive a session of Prolonged Exposure or Cognitive Processing Therapy in the PTSD clinic. Implementation-focused evaluation data was extracted from a facilitation log used to track facilitation activities, time spent in these activities and contact with the champion and other local staff. Progress-focused evaluation data included monthly audit and feedback reports on EBP reach, based on administrative data, and narrative review of goal attainment recorded in the site-specific guide. Interpretive evaluation data included post-intervention interviews with the same key informants interviewed at baseline. Interviews were analyzed using rapid turn-around approach [2] . Results EBP reach more than doubled during the 6-month intervention period in both clinics. Clinic A achieved its reach goal of 20% in month 2 and continued to increase linearly to 36% at month 6. Clinic B's reach increased slightly then plateaued until month 6 when it achieved its goal of 25%. External facilitation hours were 70% greater in Clinic A. Clinic A implemented organizational changes consistently over the 6 months while Clinic B enacted significant changes shortly before the 6-month reach increase. Clinic A's champion was more committed and empowered to make organizational changes compared with Clinic B's champion. Implementation strategies associated with reach at both sites included audit and feedback reports, an inperson site visit at project launch, and toolkit resources. Conclusions Improvement trajectories may not be consistent across sites. Implementation interventions should vary in duration according to local champion characteristics. Toolkit-guided external facilitation accompanied by a strong local champion has the potential to help clinics reorganize to improve reach of EBPs to patients. Addressing social disconnection among frequent users of community hospital emergency departments: a statewide implementation authorized Massachusetts to establish the Community Hospital Acceleration, Revitalization, and Transformation (CHART) investment program. The Massachusetts Health Policy Commission (HPC) oversees the CHART program, which awarded $120 million to 27 community hospitals to develop innovations aimed at enhancing the delivery of efficient, effective care, and readying them for value-based care [2] . Objective: Through a contract with the HPC, we conducted an implementation evaluation of CHART innovations between 2016-2018. Through this evaluation, we examined how CHART stakeholders described social disconnection, a public health priority, and which levels of a social connection framework CHART innovations addressed (structural, functional, quality or multilevel) [3] among frequent emergency department (ED) users. Qualitative interviews with 236 stakeholders (hospital managers, CHART providers, staff, and community partners) one year post CHAR T implementation were audiorecorded and transcribed verbatim. Interviews were analyzed using a directed content analysis approach [4] . We assessed reliability and validity of our coding frame through joint coding by four analysts on two transcripts. Data were then mapped to the levels of the social connection framework. Each coded transcript was discussed in depth until consensus on coding definitions was reached. Following this process, six analysts independently coded between 30-40 transcripts. Data were checked and entered into the NVivo software package for ease of organization and reporting. Results Social disconnection, described as "loneliness" and "social isolation" by stakeholders, led patients to the ED for problems not always related to their physical health. These definitions mapped to the structural level of the social connection framework. Innovations involving home visit programs, elder services interventions, workflow changes in the ED, and regular telephone follow-ups provided functional level emotional and tangible support. Stakeholders did not mention relationship distress or quality of relationships in describing social disconnection or hospital innovations. Innovations to address high ED use, according to stakeholders, provided functional level emotional and tangible support to address structural level definitions of social disconnection. Future work should examine the sustainability of these innovations in a valuebased healthcare climate, and the effectiveness of these programs on reducing ED utilization. Evaluation of The Implementation Game © : a learning and planning resource Correspondence: Melanie Barwick (melanie.barwick@sickkids.ca) The Hospital for Sick Children, Toronto, Ontario, Canada Implementation Science 2020, 15(Suppl 2):A128 The presentation will share evaluation findings for a new planning and learning resource to support implementation of evidence into care. Implementation is a complex process with many moving parts, and many practitioners and organizations struggle to do it successfully. The Implementation Game© (TIG) supports autonomous, selfdirect implementation by simplifying the process into five main components to provide an implementation planning experience for an identified scenario or implementation endeavor. It is based on key implementation theories, models, and frameworks [1] [2] [3] [4] .The Implementation Game is relevant to any discipline because the concepts are high level. The Game components include a game board, playing cards, and an implementation worksheet to capture the plan. The goal is either to learn, or to plan, or both. The presentation will provide an overview of the Game and preliminary evaluation data. An online survey has been shared with 36 (and counting) individuals who either purchased or received a copy of The Implementation Game© beginning in December 2018. The survey captures evidence of use, usefulness, spread, quality, and satisfaction. Currently in data collection. Background Despite implementation research on supporting evidence-based prevention programs in high-income countries, research is lacking on consultation support in schools in low-resourced countries like high schools surrounding Cape Town, South Africa [1] . This study is part of a larger factorial design implementation trial of HealthWise, a teacher taught program for preventing youths' risky sexual and substance use behaviors [2] . After initial randomization, 22 schools with 33 teachers received the consultation condition while 26 schools with 41 teachers did not. The consultation condition included three meetings between the consultant and a teacher representative per school, text message reminders, support kits with prepared HealthWise materials, and lesson plans integrating HealthWise content. Teachers self-reported how much content they delivered and adapted, and students' interests in HealthWise lessons during 9th grade. Observer coded videos captured teachers' fidelity to HealthWise curriculum. School risk was calculated using publicly available data on school and community safety, poverty, density and geographical location. Post-intervention qualitative interviews with the consultant, 11 teachers and 4 principals expand on quantitative findings and broader policy and community priorities. Based on as-treated regression analyses, teachers in the consultation condition reported delivering more HealthWise content (B = .13, p < .01) but did not differ in their observed fidelity. Moderation analyses found teachers with lower educational degrees who received the consultation condition reported more student interest in HealthWise (B = -.17, p < .01), and teachers in higher risk schools that received the consultation condition reported more adaptation (B = .22, p < .01). Initial qualitative findings suggest there was a need to adapt, especially to address higher risk school needs. Additionally, the consultant's interview suggested racial, educational, and gender differences may play a role in teachers' receptivity to consultation. Findings suggest even a low dose of consultation support can facilitate implementation outcomes in this context. As this study occurred during South African education policy changes regarding teaching life skills in high schools [3] , we will discuss how consultation can support implementation to meet community, teacher and student needs in the context of policy changes, as well as potential shortcomings of consultation. Trial Registration ClinicalTrials.gov NCT00336180 High rates of childhood trauma exposure (over 68%) create significant concern given the negative outcomes associated with traumarelated symptoms [1] [2] . Numerous trauma-focused evidence-based practices (EBPs) have been developed; however, little is known about why school systems, especially those serving rural areas, adopt (or do not adopt) trauma-focused EBPs. This qualitative study explored factors that might influence the adoption of trauma-focused interventions among clinicians working in rural schools using two implementation science frameworks: the Consolidated Framework for Implementation Research (CFIR) and the Implementation Outcome Framework (IOF) [3] [4] . A semi-structured protocol was used to interview school-based clinicians (N = 12) about their knowledge, views, and adoption of trauma-focused interventions. Specific attention was given to IOF outcomes known to influence innovation adoption (i.e., acceptability, appropriateness, and feasibility) [5] . Transcripts were double coded using a deductive content analysis approach and a CFIR-and IOFbased coding manual. Every participant (100%) reported adopting some form of mental health intervention to treat symptoms of posttraumatic stress within their school setting, though only 25% had adopted a trauma-focused EBP. One participant (8.33%) was also working in a school that declined an opportunity to adopt the practice of delivering traumafocused care. Thematic analyses revealed that most participants reported the same acceptability and appropriateness factors as both facilitators and barriers to adoption of trauma-focused interventions in rural schools. Nine participants (75%) believed that it was not feasible to implement trauma-focused EBPs within their current school system. Several CFIR constructs (e.g., cosmopolitanism, structural characteristics, leadership engagement, access to knowledge and information, available resources, relative priority, self-efficacy) were commonly identified as influencing the feasibility of implementing trauma-focused interventions within a rural school. The acceptability and appropriateness of delivering trauma-focused care within school settings appears to positively influence the adoption of trauma-focused interventions within rural schools. However, limited feasibility of implementing trauma-focused EBPs within rural schools might be negatively influencing adoption. These results have the capacity to inform a targeted approach to select implementation strategies that could enhance the adoption of trauma-focused EBPs within schools, thereby increasing the accessibility of trauma-focused care in rural areas. The Background Organizational factors are critical to successful implementation of evidence-based behavioral health interventions. Previous research has demonstrated that the alignment or misalignment between leadership and providers on organizational constructs (e.g., implementation leadership) impacts successful implementation [1] . In particular, positive misalignment, which occurs when leaders rate the implementation context significantly lower than the staff, may facilitate the successful implementation of evidence-based practices, and negative misalignment may hinder these processes. This paper examines alignment between school administrators and their staff on implementation leadership (i.e., specific leadership behaviors that support or inhibit effective implementation) and implementation climate (i.e., shared norms and expectations among staff related to implementation). The OASIS study collected data for alignment in 35 schools (6 school districts in 3 states). Leadership (n=35) and staff (n=289) were asked to rate the implementation leadership (IL) and implementation climate (IC) of their site. Alignment and directionality of alignment (i.e., a positive relationship between leadership and staff ratings, or negative misalignment) between these two groups was calculated as less than a half standard deviation in the difference between mean scores [2] [3] . Fidelity assessments for two universal behavioral health prevention programs were then conducted, and further analysis will determine if alignment directionality affects implementation fidelity. Results A significant proportion of sites reported negative misalignment between leadership and staff. 37.1% of sites reported negative misalignment on overall perceptions of IL, and 51.4% reported negative misalignment on overall perceptions of IC. Additionally, negative misalignment across the seven IL subscales (i.e., proactive, knowledgeable, supportive, perseverant, communication, vision, and availability) ranged from 25.7% to 51.4%, and negative misalignment across the seven IC subscales (i.e., focus, rewards, use of data, integration, existing support, recognition, and educational support) ranged from 34.3% to 60.0%. This paper illuminates important findings with implications for implementation research and practice. First, negative misalignment was found for over half of the schools, indicating a likely need to improve communication and collaboration across levels. Second, although fewer in number, positive alignment and positive misalignment was noted, indicating opportunities to study the factors associated with optimal alignment on key organizational implementation constructs. LIFT Together with Boys Town: an implementation system bridging schools, providers, and researchers Jasney Cogua 1 , W. Background For over 100 years, Boys Town has provided services for children who have suffered adverse experiences, trauma, and other challenges [1] . Since 2012, Boys Town has been working to implement a comprehensive prevention strategy that goes beyond serving individual youth and families to impacting targeted populations to build well-being through the LIFT Together program [2] . LIFT Together is a community-based implementation system that convenes schools, service providers, and researchers to facilitate the delivery of a multi-tier, multi-component intervention package. The intervention package uses school [3] -and family-based [4] [5] [6] programs to generate school-wide impact. Outcomes are measured at the school population level (such as preventing and reducing school disciplinary referrals or increasing parental engagement at schools), instead of upon individual children and families. This intervention system is being implemented within highly vulnerable communities in three sites: South Omaha, Nebraska; North Las Vegas, Nevada; and Pawtucket, Rhode Island. This presentation will include: 1) A brief explanation of the LIFT Together System (processes, components, and outcomes). 2) A description of the lessons learned and challenges faced in the implementation of LIFT Together from the perspectives of the school, collaborating providers, and researchers. Examples include developing a common understanding of the goals and processes, establishing protocols for access to the critical populations, and implementing practices for school engagement. 3) A description of data collection processes for the evaluation of LIFT Together implementation and goals (e.g., integrating school and service provider data to evaluate outcomes). This presentation provides an illustration of implementation practice in real-world settings in the delivery and evaluation of a systematic, community-based system for mobilizing schools to address student concerns with a tiered package of school-and family-based programs. This presentation will not only illuminate the specific nature of LIFT Together, but it also will elucidate contextual factors for local success and highlight the types of expertise and knowledge needed to facilitate local partnerships and implement initiatives that benefit vulnerable youth and families in community settings. Implementation studies are often criticized for engaging only early adopter sites, thus limiting study generalizability. Better implementation science requires understanding optimal tactics for engaging stakeholders in implementation research. Adaptive School-based Implementation of CBT (ASIC) is a large-scale randomized trial designed to test different implementation strategies to support school professional (SP) delivery of cognitive-behavioral therapy (CBT) in high schools across Michigan [1] . We analyzed methods used to recruit SPs at more than 100 diverse schools for ASIC participation and describe successful strategies used in this large-scale implementation study across different settings [2] and stages of change [3] . Schools were recruited to ASIC over a 6-month period. A post-hoc process evaluation of recruitment was conducted. Metrics collected include quantitative measures (e.g., number of attempts) and qualitative feedback from recruiters on successful recruitment strategies. Following recruitment, data were analyzed to identify patterns in successful recruitment efforts and codify effective strategies for recruiting SPs to ASIC. With a goal of recruiting 100 schools, ASIC reached out to 272 schools identified as candidates and ultimately, SPs at 114 schools were recruited over 6 months. The average SP required 5 contacts before agreeing to participate (range: 1-16). Following early low recruitment numbers, the study team mobilized seven clinicians and research assistants with mental health service experience, as well as members of a statewide CBT coaching network to reach out to schools. Leveraging these existing community partnerships served to significantly increase recruitment success, with average number of schools recruited increasing from 6/month prior to coach involvement to 39/month after. Further, discussion with SPs about their concerns regarding participation also proved helpful, as most were related to implementation of CBT in their work, rather than study participation. Discussing the experiences of past program participants, as well as program flexibility, helped assuage these concerns. Notably, SPs were generally not persuaded by discussion of study incentives ($330 over 18 months), but rather by empirical evidence related to student mental health improvement. Engagement of community members and personalized recruitment efforts were necessary to overcome barriers to study participation among schools. This resulted in engaging SPs from diverse school settings and exceeding recruitment targets. The Results ICS, ILS, and ASD EBP Resource scores varied by SELPA size. Large SELPA directors reported better implementation climate in regards to focus on EBPs and existing supports to deliver EBPs than small SELP As, and better educational support for EBPs compared to medium SELPAs (p-values < .05). Large SELPA directors also reported higher proactive, supportive and perseverant implementation leadership than small SELPAs, and higher knowledgeable and proactive implementation leadership than medium SELPAs (p-values < .05). Large SELPAs also reported greater partnerships with community stakeholders related to ASD EBP use than small SELPAs (p = .01). ICS scores varied by whether the SELPA consisted of one school district (single) or multiple school districts (multi), with multi-district SELPAs reporting higher selection for EBPs and selection for openness than single-district SELPAs (p-values < .02). Proactive leadership was a significant predictor of CAPTAIN performance (B = 3.77, p = .04). Conclusions Implementation leadership and climate vary across organizations suggesting variability more broadly. Proactive leadership relates to frequency and quality of EBP training and coaching in schools. Matching targeted implementation efforts to context and organizational functioning will be discussed. One-to-one instruction is a critical component of evidence-based practices (EBPs) for students with autism spectrum disorder (ASD) [1] , but is not used as often as recommended. As described in the Consolidated Framework for Implementation Research [2] , an important outer setting characteristic when considering EBPs is clients' needs based on their characteristics. Indeed, student characteristics may affect teachers' decisions to select a treatment and/or implement one-to-one instruction [3] . This study examined whether teachers' reported use of one-to-one discrete trial training (DTT) and pivotal response training (PRT) was associated with students' clinical and demographic characteristics. Participants were kindergarten-through-second-grade autism support teachers (n=80) and children aged 5-9 years with ASD (n=228). All teachers received training and consultation in the EBPs, and rated children in several symptom domains using the Pervasive Developmental Disorders Behavior Inventory. Children were assessed on cognitive and language abilities using the Differential Abilities Scales, and on self-regulation difficulties using the Behavioral Interference Coding Scheme. Each month, teachers reported on their use of two EBPs with each student during the past week. Children's higher sensory symptoms, lower social approach, lower verbal skills and higher self-regulation difficulties were associated with more frequent 1:1 DTT and PRT; significant child symptom domains each explained 8-15% of the variance in reported receipt of treatment. Children's age, sex and race were not statistically significant predictors of children's receipt of these EBPs. These results provide an example of a situation where client characteristics seem to influence providers' use of EBPs. More obviously impaired students received more of each EBP. The findings beg the questions of whether teachers are accurate in their decisions regarding who benefits from 1:1 instruction, and whether children should be matched to specific types of 1:1 instruction based on their clinical characteristics. To the extent that experts think that less obviously impaired students would benefit from 1:1 instruction, those working with teachers should address practical, attitudinal and structural barriers to providing 1:1 instruction to a larger proportion of students. This study highlights the importance of considering client characteristics in the development and study of implementation strategies, across EBPs and contexts. The Veterans Health Administration recommends that patients with PTSD receive either of the two evidence-based psychotherapies (EBPs), Cognitive Processing Therapy (CPT) and Prolonged Exposure (PE). However, in one survey, clinicians who completed the national PE training program reported that they only treated one or two patients at a time with PE [1] . In another survey, 69% of the clinicians who were trained in CPT provided CPT "rarely" or "less than half the time" [2] . Because underutiliziation of the EBPs leads to fewer patients receiving the optimal treatments, it is important to identify and remediate clinician-level barriers that lead to low reach. In our current study, we surveyed clinicians across the United States who primarily work on PTSD clinical teams (PCTs; [3] ). They reported whether they received graduate school training (GST) in structured cognitive behavioral therapy (CBT) protocols and rated agreement to the following clinician-level barriers to EBPs: discomfort of exposing patients to distress during PE and concerns of patients' difficulty understanding CPT. We conducted mediation analyses with bootstrapping between GST, EBP barriers, and EBP usage. We found that GST (b = -0.27, t(222) = -2.08, p = .04) led to lower discomfort of exposing patients to distress during PE, and in turn, lower discomfort (b = -6.84, t(222) = -4.83, p < .001) predicted greater PE usage. GST and PE usage had a significant average causal mediation effect (b = 1.83, 95% CI [0.00, 4.10], p = .05). Because GST (b = 0.13, t(222) = 0.82, p = .41) was not significantly associated with the CPT barrier, there was no statistical ground to test for the mediation between GST, CPT barrier, and CPT usage. Our results indicate that clinicians who used structured CBT protocols as part of their graduate school training are less likely to shy away from an EBP even when it might ask them of discomfort of exposing their patients to distress. To increase EBP reach, policy makers should promote for the inclusion of using structured CBT protocols in graduate school curriculums. The Exploration, Planning, Implementation and Sustainment framework (EPIS) [3] has impacted targeted strategy use for statewide scale up of EBPs by informing the development of key partnerships, implementation goals, and collaborative processes within CAPTAIN. The panel will highlight how education policy and implementation data have influenced CAPTAIN practices and procedures within a community-academic partnership. These factors will be presented by purveyors, intermediaries and implementation science researchers. The founding co-coordinator of CAPTAIN and a purveyor of this initiative will share information about the policies that have influenced the development of the network and how key partnerships have been formed. A fellow founding co-coordinator of CAPTAIN that serves as an intermediary in the CAPTAIN project will share how implementation science and the EPIS Model have informed the CAPTAIN implementation goals and procedures and how this information has been shared with state and local agencies through continuous improvement cycles. The research director for CAPTAIN will present current funded research initiatives involving CAPTAIN and will facilitate discussion. Mixed-methods data will be presented, informed by an internal survey of CAPTAIN members (n=414), a statewide survey of educational professionals and administrators (n=1700), and qualitative focus group outcomes from providers and CAPTAIN members (n=30). A subset of outcomes will be presented with a focus on multiple perspectives on barriers, implementation leadership and implementation climate, implementation strategy use, and the distribution of decision making across organizational levels. Intervention research in education science has produced a plethora of evidence-based practices (EBP) to improve student social, emotional, and behavioral (SEB) outcomes [1] . To ensure students benefit from these practices, implementation strategies (techniques and methods to improve implementation outcomes) [2] , have been developed to bolster schoolbased practitioners' EBP treatment integrity. These include action planning, prompts and reminders, coaching, and performance feedback [3] [4] [5] [6] . However, because these strategies are often delivered simultaneously, mechanisms by which they produce effects remains unknown, hindering further understanding of causal relationships and efficient service delivery. Therefore, the purpose of this study was to conduct a meta-analysis categorizing and analyzing the effectiveness of discrete school-based implementation strategies across service provision levels to inform limited school resource allocation and identify future directions for research. Published studies of strategies used to increase teacher implementation of SEB EBPs were included. Effect sizes were calculated, and a robust variance estimation meta-regression model (RVE) was used to hierarchically analyze average effects and conduct moderator analyses [7] . Funnel plots and Egger's test were used to assess publication bias [8] . Preliminary results of 31 single-subject studies indicate that activeimplementation strategies targeting performance deficits were effective overall for increasing teacher adherence to EBPs above baseline and pre-implementation training alone (Hedge's g = 2.45). Maintenance strategies, such as dynamic fading of supports, while sparse, indicated effective sustainment of implementation behavior (g = 0.8). Performance-feedback was the most common strategy (n = 23; 74%), though preliminary results indicate it may not be the most effective strategy across all intervention tiers. Twenty group-design studies were included and analyses are underway. Teacher treatment integrity improved with added supports; however, once supports were removed, implementation decreased in over 40% of the studies that collected follow-up data. As is true in the greater implementation literature, [9] , further methods for sustaining implementation are needed. Gradual fading reduced implementer drift, and practitioners should consider it with active-implementation supports. This study contributes to the broader implementation literature by providing discrete strategy effectiveness of practitionerlevel performance-based implementation strategies and informs future research categorizing and analyzing implementation strategies within existing frameworks [2] . Background Getting Research into Policy and Practice [1] (GRIPP) is a continued concern in education with several studies citing limited knowledge and use of evidence-based practices (EBP) by school practitioners [2, 3] . Although studies exist evaluating practitioners' perspectives on GRIPP [4] , there are presently no studies examining researchers' approaches to dissemination. Given that they generate the evidencebase for school-based practice, an understanding of how researchers communicate their findings is an important piece in understanding implementation of EBPs. The purpose of the present study was to understand education researchers' engagement in dissemination activities targeting non-research audiences. School psychology and special education researchers (n = 226) at Research Intensive institutions completed on online survey related to their dissemination practices. Respondents answered items pertaining to their most frequently used dissemination modalities, target audiences, barriers, and time dedicated to dissemination. Participants were also asked to rank which dissemination activities they perceived as having the greatest impact on education practice. Over half of sample (59.9%) reported spending less than two hours per week on dissemination activities targeting non-research audiences. Participants were asked to rank order their most frequently used dissemination practices and indicated that academic journal articles (rated as primary dissemination activity by 63% of sample) and conference presentations (rated primary activity by 15%) were the most frequently used modalities for dissemination. Although participants reported that they felt that professional development sessions, meetings with stakeholders, and practitioner-focused books have the greatest impact on educational practice, they were not as frequently utilized by respondents as peerreviewed articles and conference sessions. Common barriers reported by respondents were limited time to dedicate to dissemination (rated as primary barrier by 37% of sample) and that dissemination is a low priority at institutions (rated as primary barrier by 20%). Overall, respondents reported engaging in low rates of dissemination targeting applied, non-research audiences. With limited time, education researchers appear to focus their resources on activities associated with promotion and tenure (e.g., publishing peer-reviewed journal articles). Although participants valued the importance of dissemination targeting those in applied settings, they reported that these activities are largely not valued by their institutions. Children in rural America face unique health disparities compared to their urban counterparts, including higher substance use; sexual activity and teen pregnancy; and suicide rates [1] [2] [3] . While there are numerous evidence-based practices (EBPs) K-12 schools can implement to promote students' physical, social-emotional, and academic wellbeing [4] [5] [6] [7] [8] [9] [10] [11] , little is known about the contextual factors that facilitate or inhibit rural school districts' selection of EBPs. Our center is currently facilitating 21 high-poverty, rural school districts through a strategic planning process to create comprehensive health and wellness plans that include EBPs for physical and mental health. The process is completed by a school district task force comprised of school administrators, teachers, students, parents, and community members under the guidance of an external facilitator. In this study, we adapted the Consolidated Framework for Implementation Research (CFIR) [12] to the rural school context to understand the contextual factors associated with school districts' selection of EBPs. We explore (1) the EBPs selected by these rural school districts, (2) the prevalence of contextual factors amongst districts, and (3) the association of contextual factors with EBPs selected. We have developed (and are currently administering) an 81 item survey to evaluate the contextual factors of implementation for this initiative. This pen and paper survey, which was designed for rural schools completing the planning process, accounts for all 39 CFIR constructs. The survey is administered at the end of the final meeting of the process and completed by members of the 21 rural school district task forces. All survey data will be collected by May 2019. Results will reveal the prevalence and relationships of contextual factors and EBPs selected by rural school districts as a result of the process. These results will be instructive concerning the importance of particular contextual factors as they apply to the selection of EBPs in rural schools. Additionally, the survey developed and administered provides an example of evaluating CFIR constructs in K-12 school settings, which contributes to the growing SIRC instrument review project. Community Background Evidence-based parent training, in which providers systematically train parents to implement specific intervention strategies with their child, is an underutilized treatment for children with autism spectrum disorder (ASD) [1] . In 2012, Michigan passed the Medicaid Autism Benefit for Behavioral Health Treatment, which provides funds for Medicaid-enrolled children with ASD for applied behavior analysis (ABA) services, including parent training. However, a review of billing data shows that few parent training sessions have been billed under the Medicaid Autism Benefit, despite providers having the ability to bill for the service at a high reimbursement rate. To our knowledge, no other study to date has examined reasons for why parent training for ASD is underutilized within community mental health settings. This mixed-methods project examined the use of parent training during ABA under the Michigan Medicaid Autism Benefit for children with ASD under age 21. Descriptive statistics and multiple regression were used to analyze Medicaid claims data for 879 children and survey data from 97 ABA providers. Content analysis was used to analyze open-ended survey items and thematic analysis was used to analyze interviews from a subset of 13 providers. Results demonstrated that: a) frequency of parent training encounters was very low, b) ABA providers' conceptualization of parent training is inconsistent with the literature; c) providers report using evidence-based parent training strategies at a moderate-to-high level on the survey, but infrequently spontaneously mention those strategies in interviews; d) providers use sessions for other purposes; e) providers report having limited related training experiences; f) and providers report numerous barriers and facilitators which are related to their reported extensiveness of parent training. Barriers and facilitators were identified at the family-, provider-, and organization-levels and map well onto the Consolidated Framework for Implementation Research, including outer setting (policy regarding Medicaid Autism Benefit), inner setting (agency-level characteristics), and the individuals involved (providers). Results from this study will be used to design an intervention to increase uptake of evidence-based parent training in this system. No single approach can meet the multi-dimensional needs of impoverished, high-risk families. With this in mind, the Building Healthy Children (BHC) intervention program was designed as a collaborative community initiative to prevent child maltreatment and support healthy development in newborns of young mothers [1] [2] . This inter-agency collaborative was comprised of medical, university and community partners, with a strong focus exporting evidence-based models and translating research to practice. BHC was designed as a home visitation program that employed a tiered model of service delivery based on families' individual needs, in order to effectively and efficiently deliver outreach and evidence-based treatment models. These treatment models addressed parenting (Parents as Teachers), attachment (Child-Parent Psychotherapy), and maternal depression (Interpersonal Psychotherapy for Depression), and each has received substantial evidentiary support [3] [4] [5] [6] . The current study utilizes a longitudinal follow-up design, to examine the effects of BHC on parenting and child behavior once the child is in elementary school (6-10 years old). The anticipated sample size is 100 children (45% male) and their biological mothers (baseline age, M=19). In addition, data is also being collected from the child's teacher regarding child behavior in the classroom in order to provide a multi-informant perspective across settings. Thus far, data has been collected from approximately 50 families. Data collection is scheduled to conclude by 7/1/19. This presentation will examine the long-term effects of BHC on child maltreatment, out-of-home placement and harsh and inconsistent parenting, as well as positive parenting practices. In addition, it will examine the effects of BHC on child externalizing behavior and self-regulation. The information gleaned from this study will help us to better understand how to develop effective inter-agency partnerships in order to increase accessibility to high-quality, evidence-based mental health services for vulnerable children and families. This effectiveness study provides information about implementing efficacious interventions within existing community infrastructure. Finally, the results of this study will help us to better understand how to prevent violence against children, and to foster a safe and healthy caregiving environment for children to grow and thrive. Postpartum Anxiety (PPA) and Postpartum Depression (PPD) are common mental health issues that go largely undiagnosed and untreated in the United States [1] . There are no federal policies requiring screening of new mothers, and only thirteen states have passed legislature or convened task forces to promote screening for PPD in perinatal care. Similar efforts have not been made to promote PPA screening [2] . Although screening is recognized as a valuable practice that may increase new mothers' access to mental health care, there is limited data available on how this legislature has translated to real-world screening and referral practice. The current study examines current screening and referral practices of perinatal providers in West Virginiaa state that has taken legislative action to promote depression screening in perinatal women. Barriers to screening and referral that could be targeted by future implementation or advocacy efforts are also explored. Approximately 50 perinatal providers in urban and rural settings across West Virginia will be recruited to complete an online survey. Current screening and referral practices for PPA and PPD, perspectives on best screening practices, and barriers to discussing mental health issues with patients will be assessed. Providers' perceived feasibility, acceptability, norms, and intention to use screening tools or referrals with perinatal women will also be examined. Data collection for the current study is ongoing. Preliminary analyses on a small subset of providers have indicated that obstetrician/gynecologists in urban clinics screen a majority of patients for anxiety and depression symptoms, but providers do not consistently conduct screening at each visit. Approximately 4-5% of providers' caseloads were referred for mental health care in the past year, and referral rates were higher for patients endorsing depression symptoms compared to patients endorsing anxiety symptoms. Providers reported limited time as a barrier to screening, and a lack of consistent screening as a barrier to providing mental health referrals to women. Perinatal providers in West Virginia screen for depression and anxiety; however, screening and referral may be inconsistent across disorders. Having limited time to screen patients may interfere with mandated screening in perinatal care. Factors influencing implementation of the To address a critical gap in resources for depressed Latina pregnant and early parenting women in rural settings, we co-designed and evaluated the Alma Program utilizing an innovative model of "task-sharing" [1] , where peers are trained to mentor perinatal women experiencing depression. In-depth examination of the extent to which contextual factors influence implementation outcomes has the potential to advance understanding of the relationships among contextual adaptation, success of a program, and dissemination to new settings. We conducted a case study of the Alma program to identify the organizational, contextual, and cultural factors that served as barriers or facilitators to the implementation of the Alma program within a rural Colorado community. Key informants who participated in the case study included staff and administrators from partner organizations, members of the research team, local community members, and Alma peer mentors. All key informants (N=15) completed a survey that assessed the organizational and contextual factors known to influence the implementation of programs, developed using the Practical, Robust, Implementation and Sustainability Model (PRISM) [2] . All key informants were given the opportunity to participate in individual interviews or focus groups to explore qualitatively factors associated with the successful implementation of Alma, and to follow-up on findings from the survey. We will identify key facilitators and barriers that were identified at the following contextual levels: broader community/environment, organization, program, participant. For example, at the broader community/environment level, the most commonly reported facilitator for Alma program implementation (92.3% of the sample) was, "a need for mental health resources in the community and the most commonly reported barrier (38.5% of the sample) was, "poor communication streams in the community." The organizational and program characteristics were identified to be overall key facilitators for implementation of the Alma program in this setting, whereas the broader community and environment context was identified to be an overall barrier. Specific barriers and facilitators within each of these levels are identified, which could inform broader implementation and spread of the program to new sites. This study examines fidelity to the Family Check-Up 4 Health (FCU4-Health) in a randomized hybrid trial evaluating effects on the prevention of excess weight gain in pediatric primary care [1] . The program includes a comprehensive assessment, followed by a feedback and motivation session, in which Motivational Interviewing (MI) is used to engage families in follow-up parenting modules and communitybased programs to address social determinants of health. The COACH observational rating system assesses fidelity to the FCU4-Health. In a prior trial, COACH ratings have been associated with higher concurrent ratings of parent engagement, and in turn, longitudinal improvements in parenting and child behaviors [2] . Further, coordinators with more training had better MI skills, and this was positively linked with parent engagement [3] suggesting that MI skills are a core component of change. This study extends prior work to advance the science of fidelity assessment when implementing a preventive parenting program. The trial includes families (n=240) with children ages 6-12 years identified in pediatric primary care with elevated body mass index (BMI) for age and gender (≥85th percentile). 68% of parents were Latino and 38% spoke Spanish. After completing the baseline assessment, families were randomized to the FCU4Health program (n=140) or usual care (n=100). The FCU4Health involved 3 feedback sessions, with parenting support sessions and referrals to community programs (e.g., nutrition, physical activity, social services, health/mental health programs), over a 6-month period. COACH coding of this sample is nearly complete. Analyses will be completed in July 2019. We first plan to examine the temporal associations between the FCU4Health coordinator's use of MI in the 3 feedback sessions with caregiver engagement over time using a cross-lagged panel model. Second, using multiple regression, we will examine associations between ratings of MI skills with families' engagement in community-based programs, accounting for salient family demographic factors such as income, insurance, parent health, and acculturation markers. This study will inform the ways in which fidelity to MI is associated with behavior change in an evidence-based parenting program-adding valuable knowledge to the field that has implications for fidelity monitoring, coordinator training, and program development. To effectively promote evidence-based practice (EBP), it is important to consider whether caregivers understand and view the concept favorably. Previous research found that caregivers with lower education, with lower SES, and from a minority racial group were less likely to correctly define EBP and had a less favorable view of EBP [1] . This study examined how caregivers define, value, and prefer to describe EBP, and how responses varied based on caregiver and teen psychopathology and treatment history. Caregivers (N=411; 86% female; 88% non-Hispanic Caucasian) concerned about their teen's (age [12] [13] [14] [15] [16] [17] [18] [19] substance use completed an online survey as part of a larger study. Caregivers selected the correct definition of EBP, indicated their preference for describing EBP, and indicated whether they valued EBP treatment principles (proven vs. individualized treatment; treatment process vs. treatment outcome). Chisquare analyses evaluated caregiver responses by caregiver and teen treatment history, and teen mental health and substance use problems. Multivariate logistic regressions examined which variables were associated with the greatest likelihood of response selection. Most caregivers correctly defined EBP, preferred the concept of "therapy based on evidence", preferred proven over individualized treatment, and valued the outcome over the process of therapy. Caregivers who had received mental health therapy were more likely to correctly define EBP (p<.01), and those whose teens had received mental health therapy less strongly valued the outcome over the process of therapy (p<.01). Multivariate analyses revealed that having a teens with legal problems and substance use problems significantly influenced how strongly caregivers preferred the term "therapy based on evidence". Caregivers whose teens had internalizing problems and legal problems less strongly favored proven treatment over an individualized approach (ps<.01); only teen legal problems was significant in the multivariate analysis. Although most caregivers correctly defined and valued EBP, caregiver and teen treatment history and teen psychopathology moderated this effect. Most notably, caregivers of teens with psychopathology symptoms and a therapy history were less likely to value principles of EBP. Caregivers of teens with substance use and legal problems also tended to prefer other terms over EBP. Background Children with behavior difficulties reared by child welfare (CW)-involved families often fail to receive needed mental health (MH) treatment due to limited service capacity and chronic engagement difficulties [1] . Task-shifting strategies (World Health Organization, 2008) can increase MH treatment access by relocating treatment to alternative service platforms (e.g., CW service settings) and utilizing a non-specialized workforce (e.g., CW caseworkers) to deliver MH interventions while supervised by trained clinicians. In this study, an evidence-based, multiple family group intervention (The 4Rs and 2Ss Program for Strengthening Families [4R2S]; [2] [3] [4] ) to reduce child disruptive behavioral difficulties was modified so that it could be delivered by CW caseworkers without advanced MH training. This study examines the degree to which CW staff perceived delivering 4R2S in CW placement prevention services as feasible and acceptable, as well as those factors reported to facilitate or hinder feasibility and acceptability. This mixed methods study collected quantitative and qualitative data from caseworkers (n=6), supervisors (n=4) and administrators (n=2). Quantitative and qualitative data focused on feasibility (e.g., participant flow, treatment fidelity, treatment attendance, CW staff perspectives on feasibility and appropriateness) and acceptability (CW staff perspectives on acceptability and attitudes towards evidence-based practices). Descriptive statistics compared quantitative data to pre-determined study benchmarks for high feasibility and acceptability. Qualitative data were coded into relevant a priori (feasibility, acceptability) and emergent themes. Mixed methods analytic strategies focused on integration at the analysis stage, comparing quantitative and qualitative findings side-by-side to identify points of convergence or expansion. Results indicate that CW staff perceived implementing a modified version of the 4R2S in placement prevention services as generally feasible and acceptable, with some exceptions (e.g., inconsistent family attendance). Factors facilitating feasibility and acceptability include agency and logistical support, provider characteristics, 4R2S content & strength-based focus, 4R2S ease of use, and perceived benefits for families and providers. Barriers to feasibility and acceptability included family characteristics, eligibility/recruitment procedures, logistical challenges, as well as issues with external supervision. Conclusions Findings from these key stakeholders can inform similar efforts to implement child MH EBPs within CW services. Seventy-six present of youth living in child welfare institutions in Norway meet criteria for 1 or more psychiatric disorders [1] . This high prevalence of emotional distress presents a significant challenge for Norwegian child welfare services. In order to provide effective help, institutional employees must be motivated, trained, and engaged. From 2011 to 2014, a systematic implementation called Module-Based Support (MBS) was adopted to increase the quality of institutional care through therapist training and supervision. The current study examines which program factors contributed to therapist development and job engagement. A quantitative cross-sectional design was utilized. The independent variable was job engagement, and High Performance Cycle (HPC) factors [2] including: demands, performance, contingent rewards, consequences, and job satisfaction were the dependent variables. Employees and leaders in Norway's Region North working day and/or evening shifts participated. In 2011, 320 employees and 12 leaders were recruited (62% women, 38% men). The number of participants decreased to 230 in 2013 due to organizational restructuring. Participants completed the Empowered Thinking Questionnaire (ETQ) 3 times between 2011 and 2014. Question topics involved: leader support, goal orientation, self-efficacy, attachment to the organization, job engagement, job satisfaction, demands, and organizational practice [3] . A Structural Equation Modelling (SEM) analysis was conducted to test the relationship between job engagement and the dependent variables. The analysis demonstrated a significant relationship between demands and performance (b = .54), performance and contingent rewards (b = .85), contingent rewards and job satisfaction (b = .94), contingent rewards and job engagement (b = .58), and job satisfaction and consequences (b = .88). However, significant relationships were not found between job engagement and self-efficacy (b = .04), nor job engagement and job satisfaction (b = .02). The results from the SEM analysis suggest that there are significant relationships between job engagement and HPC factors, which indicates that the HPC model is a valid tool for improving care quality in Norwegian child welfare institutions. Future implementation of the HPC model has significant implications for future policy developments, institutional practitioners, and implementation researchers. Background Evidence suggests mental health interventions can be effectively delivered via task-sharing in low-resource settings [1] . However, research focused on how to embed evidence-based treatments in government-funded systems to enable population-level scale-up and sustainment is limited [2, 3] . We examined implementation policies and practices (IPPs) associated with facilitating group-based trauma-focused cognitive behavioral therapy (TF-CBT) for children and adolescents within the health and education systems in Kenya. Eighteen teachers and 18 community health volunteers (CHVs) from each system (N = 36) participated in qualitative interviews after delivering 2 consecutive TF-CBT groups. Interviews examined several IPPs, including rewards and incentives. Thematic coding was conducted by a team including the study's principal investigator. Interviews were double-coded and discussed to consensus; a third coder was consulted when discordant. Rewards and incentives were perceived differently between systems. Teachers highlighted rewards and incentives within their profession. Most teachers felt they were able to be more effective teachers due to participating in the intervention (72%), while only 44% of CHVs reported improvement in their role due to participation. As salaried professionals, teachers did not receive compensation for participation; however, as volunteers, the CHVs received a stipend, which was endorsed by 61% as a reward/incentive. Further, CHVs-often considered the health system's extension into the community-perceived additional rewards and incentives in relation to their communities that teachers did not. Nearly half of CHVs (44%) reported receiving rewards and incentives from outside their job (e.g., gifts/acknowledgment from community members), whereas only 2 teachers (11%) reported rewards/incentives from outside their profession. CHVs reported benefit to their personal life slightly more frequently than teachers (56% v 44%). Conclusions Encouraging participation and sustaining task-sharing interventions requires understanding how rewards and incentives are perceived. For professionals, like teachers, emphasizing rewards and incentives related to their profession may encourage participation and enable sustainment. For non-salaried volunteers, highlighting rewards and incentives from their communities might be more beneficial. In both systems, counselors reported similar levels of personal benefit, like using skills to manage their own grief, suggesting participation goes beyond profession and stipend to add value to counselors' personal lives. Trial Registration ClinicalTrials.gov NCT01822366 Mental health disorders in low and middle-income countries (LMICs) account for nearly the same disease burden as HIV/AIDS [1, 2] . While efficacious mental health treatments exist, access is severely limited [3] . This treatment gap is fueled by structural determinants rooted in a lack of research and policy capacity. The goal of this abstract is to describe the capacity building procedures and preliminary results of the sub-Saharan Africa Regional Partnership (SHARP) for Mental Health Capacity Building. SHARP 1) strengthens implementation skills among Malawian and Tanzanian mental health researchers and policymakers to successfully apply research on evidence-based mental health programs into routine practice and 2) supports dialogue between researchers and policymakers leading to efficient and sustainable scale-up of mental health services. SHARP comprises five capacity building components for mental health researchers and policymakers including: 1) introductory and advanced short courses focused on implementation science, evidence-based mental health interventions, and grant writing; 2) a multifaceted dialogue platform; 3) an on-the-job training program; 4) annual pilot grants; and 5) mentorship courses. The impact of the program will be measured using dose, participant knowledge, participant satisfaction, and participant academic output. Results A group of 21 researchers and policymakers attended the introductory short courses (implementation science and evidence-based mental health interventions) in June 2018. Post-test knowledge scores increased by 87% and 15% respectively and received average user satisfaction ratings of 89% and 85%. Pilot grants focused on implementation science and mental health were awarded to 4 teams of one researcher and one policymaker in August 2018. Also, SHARP partners delivered 3 journal clubs to 41 researchers and policymakers in 2018. Given the widespread lack of evidence-based mental health interventions brought to scale in LMICs, the experiences gained from the SHARP Capacity Building Program in Malawi and Tanzania will hold meaningful implications for a model of capacity building that could be replicated in other LMICs. If impactful, the SHARP Capacity Building Program could be used to sustainably increase the knowledge, skills, and mentorship capabilities of researchers and policymakers regarding evidence-based mental health treatment. Background Researchers could benefit from methodological advancements to advance uptake of new treatments while also improving health equity. A determinants framework for healthcare disparity implementation challenges is essential to understand an implementation problem and select implementation strategies. We integrated and modified two conceptual frameworks-one from implementation science and one from healthcare disparities research to develop the Health Equity Implementation Framework. We applied the Health Equity Implementation Framework to a historical health disparity challenge-Hepatitis C Virus (HCV) and its treatment among Black patients seeking care in the U.S. Department of Veterans Affairs (VA). A specific implementation assessment at the patient level was needed to understand barriers to increasing uptake of HCV treatment, independent of cost. We conducted a preliminary study to assess how feasible it was for researchers to use the Health Equity Implementation Framework. We applied the framework to design the qualitative interview guide and interpret results. Using quantitative data to screen potential participants, this preliminary study consisted of semi-structured interviews with a purposively selected sample of Black, rural-dwelling, older adult VA patients (N=12), living with HCV, from VA medical clinics in the Southern part of the United States. The Health Equity Implementation Framework was feasible for implementation researchers. Barriers and facilitators were identified at all levels including the patient, provider (recipients), patient-provider interaction (clinical encounter), characteristics of treatment (innovation), and healthcare system (inner and outer context). Some barriers reflected general implementation issues (e.g., poor care coordination after testing positive for HCV). Other barriers were related to healthcare disparities and likely unique to racial minority patients (e.g., testimonials from Black peers about racial discrimination at VA). We identified several facilitators, including patient enthusiasm to obtain treatment because of its high cure rates, and VA clinics that offset HCV stigma by protecting patient confidentiality. The Health Equity Implementation Framework showcases one way to modify an implementation framework to better assess health equity determinants as well. Researchers may be able to optimize the scientific yield of research inquiries by identifying and addressing factors that promote or impede implementation of novel treatments while also improving health equity. The broader health care literature shows substantial racial and ethnic disparities in the implementation of evidence-based practices (EBPs) [1] , but there is a paucity of literature examining disparities in mental health care implementation. Cognitive-behavioral therapy (CBT) is a gold-standard EBP for multiple youth mental health conditions yet is variably implemented in community mental health settings [2] . To date, little work has examined whether variability in CBT implementation differs as a function of client race and ethnicity; such findings would suggest the possibility of mental health disparities to target in future implementation research. We examined the relationship between therapists' fidelity to CBT and clients' race and ethnicity in community mental health settings using data drawn from a larger study. Therapists (N=72, median age=34 years (IQR 29-44), 74% female, 69% white non-Hispanic/Latinx) audio-recorded CBT therapy sessions for three unique clients. Sessions were coded for the extent to which therapists delivered six CBT interventions (psychoeducation, cognitive education, cognitive distortion, functional analysis of behavior, relaxation strategies, and coping skills; other CBT interventions were excluded due to low use rates across the sample) using the Therapy Process Observational Coding System for Child Psychotherapy-Revised Strategies Scale. We classified clients into two groups: non-Hispanic/Latinx whites (N=53) and racial/ethnic minority (N=144) and examined whether therapist CBT scores differed as a function of client racial/ethnic minority status. Therapists used more relaxation strategies when treating racial/ethnic minority clients than when treating non-Hispanic/Latinx white clients (t=-2.847, p=.005). No other differences were observed (all ps>.05). Results did not suggest that therapists in community settings used CBT differentially based on clients' race and ethnicity. Study limitations include an overall restricted range of CBT intervention use, regardless of client racial/ethnic minority status. Implications for CBT implementation will be discussed. Implementing internet-based CBT as part of a digital stepped care service in Australian general practice Isabel Zbukvic 1 Background iCBT is an effective resource for GPs, who are often the first contact for people experiencing mental ill-health and psychological distress [1] . However, use of iCBT in primary care is not always routine. This study aims to improve GP and patient engagement with the evidence-based iCBT program myCompass [2] , through tailored implementation of Black Dog Institute's digital stepped care service StepCare [3] . This study forms part of the international implementation research project, ImpleMentAll [4] . StepCare is a digital mental health service designed for general practice. Using a smart tablet, patients screen for symptoms of depression, anxiety and alcohol misuse in the waiting room. Treatment recommendations based on symptom severity are sent from the tablet to the GP in real-time; patients with mild symptoms are recommended the self-guided iCBT program myCompass. Implementationas-usual for the StepCare Service uses a train-the-trainer model, with collaboration between the PHN and Black Dog Institute. Implementers in IT, practice support, research, and project management operate within an integrated model of knowledge translation to roll-out the service using a phased approach. Data collection for this study is currently underway. Following a stepped-wedge trial design, a tailored implementation intervention (ItFits-toolkit) will be tested across 12 organizations in 9 countries over a period of 27 months. Longitudinal repeated-measures design will allow comparison of a baseline period of implementation-asusual versus tailored implementation. Monthly implementation reporting captures activities commenced/stopped and barriers over time. Normalisation of GP use of myCompass as part of the StepCare service will be measured quarterly using the NoMAD and ORIC. Outcome measures will also include patient uptake of myCompass via StepCare as well as implementation costs. Implementer experience using the ItFits-toolkit will also be assessed at each site, along with a process evaluation of the ImpleMentAll trial. The StepCare Service uses a technology solution to overcome known barriers to GP and patient engagement with online mental health care. This study will provide invaluable evidence on the effectiveness of tailored implementation strategies aimed at further improving engagement with iCBT in primary care. Background eScreening is a VA mobile health technology that provides customized and automated self-report health screening via iPad, clinical alerts, patient feedback and medical record integration [1] . eScreening supports early identification of health problems and measurement-based care initiatives. We set out to evaluate an implementation strategy for this technology-based, self-screening tool that has shown promise for improving the provision of healthcare services and patient outcomes. The Lean/Six Sigma Rapid Process Improvement Workshop (RPIW) and related playbook are commonly used in VA quality improvement efforts. We used this approach as an implementation strategy to prepare adopters of eScreening in VA facilities. We adapted a Lean Six Sigma RPIW [2] to develop an implementation strategy. Our multicomponent implementation strategy consisted of a modified RPIW, a playbook (roadmap for programs to implement eScreening, including how to conduct their own RPIW), internal champions, and external facilitation through bi-monthly calls, a site visit, and technical assistance. We conducted a feasibility study in 2 VHA clinics to evaluate the impact of RPIW on implementation. We gathered qualitative data from site visits and consultation calls, and conducted post implementation interviews. Two of our team members independently reviewed qualitative data using a rapid analytic approach to identify challenges and solutions. The implementation strategy was used with slight variation across the two sites. One site conducted a comprehensive RPIW (Site 1) and the other relied on the other components of the implementation strategy (Site 2). Data from the pilot revealed three types of implementation challenges that occurred at both sites: technology-related, system level, and educational. Workflow and staffing resources were challenges only at Site 2. All four types of implementation barriers were resolved using the external facilitator and the playbook. Findings suggest that the use of the modified RPIW may have solved workflow/staffing issues more efficiently than locally identified strategies. The modified RPIW to implement new programs in VA health care systems shows promise. External facilitation helped overcome challenges with or without the RPIW. Our findings support prior research highlighting the importance of considering multiple change mechanisms of implementation strategies in mental health services [3] . The Department of Veterans Affairs (VA) is currently deploying an automated texting system (ATS) to support patient self-management. Guided by the Non-adoption, Abandonment, Scale-Up, Spread, and Sustainability Framework (NASSS) which is intended to support the evaluation of novel technologies, we conducted a qualitative study to examine barriers and facilitators to national rollout of the ATS. Semi-structured interviews were conducted with 33 providers and 38 patients at formative and summative stages of ATS implementation. Interviews explored the roles of site personnel in ATS implementation, processes for enrolling patients, and ATS user experiences. Interviews were recorded and transcribed verbatim. Data were analyzed via qualitative content analysis using emergent coding and a priori codes based on the NASSS framework. We identified themes across NASSS domains: 1) Condition: perceptions of patient appropriateness for the ATS were guided by texting experience and health complexity rather than potential benefit; 2) Technology: for providers, although the ATS resides outside the electronic health record, use was generally not considered laborious; 3) Value Proposition: patient-driven demand for the ATS was limited; 4) Adopters: providers recommended more efficient ATS enrollment processes to reduce workload; 5) Organization: providers did not have observable results from the ATS early in the implementation phase, noting that such evidence of patient progress/use could enhance uptake among other providers; 6) Wider System: despite being a national program, autonomy at the local level yielded varied experiences with the ATS; and 7) Embedding and Adaptation Over Time: once using the ATS, providers recognized potential for use with other conditions. Conclusions This is among the first studies to explore implementation of VA's ATS and through the lens of the NASSS framework. The NASSS framework highlighted how the system can be better embedded into current practices, which patients might benefit most from its functionality, and which aspects of ATS messages are potentially most relevant to self-management. Mobile phone SMS texting is rapidly becoming an accepted means of asynchronous communication between healthcare systems and patients. Our findings reveal that VA's ATS has potential to expand the reach of VA care; however, providers require additional support to adopt, implement, and sustain ATS use. Beyond journalsusing visual abstracts to promote wider research dissemination Adam Hoffberg 1 , Joe Huggins 1 , Audrey Cobb 1 , Jeri Forster 1,2 , Nazanin Bahraini 1,2 1 Rocky Mountain MIRECC, Denver, CO, USA; 2 University of Colorado, Boulder, CO, USA Correspondence: Adam Hoffberg (adam.hoffberg@va.gov) Implementation Science 2020, 15(Suppl 2):A157 Background Many academic and journal organizations disseminate research via social media to increase accessibility and reach a wider audience. With the widespread utilization of Twitter, more research is needed to study the extent to which social media strategies influence outcomes on awareness and readership of journal publications. "Visual Abstracts" have been adopted by some organizations as a novel approach to increase engagement with academic content. Visual Abstracts are a visual representation of key methods and findings found in a traditional written publication [1] . This study will help organizations understand the potential impact of adopting Visual Abstracts into their social media dissemination efforts. Potential pitfalls will also be discussed. A prospective, case-control crossover design was utilized to randomize n=50 journal publications comparing Twitter posts with a Visual Abstract to those with simple screen grab of the PubMed abstract. We used native Twitter Analytics to track the outcomes of impressions, retweets, total engagements, and link clicks about 28 days post-Tweet, and Altmetric It to track additional alternative metric outcomes. As of this submission, n=47 out of n=50 articles have been randomized, with complete follow-up data available for n=33 publications. Preliminary analyses indicate that overall, Visual Abstract tweets on average have 432 more impressions, 2 additional retweets, 1 additional link click, 5 additional total engagements, and increase the Altmetric score by 3 compared with Text Tweets. Full results from the study will be analyzed and presented. Conclusions are pending, but it is expected that in line with results from prior studies [2,3] we will find a significant association between the use of Visual Abstract tweets and increased dissemination on social media. These findings may provide further evidence that Twitter is an effective platform for research dissemination and highlight the importance of social media for suicide prevention researchers and other stakeholders to communicate findings. Future efforts will be discussed to implement Visual Abstracts at scale and refine processes to maximize engagement. Forty percent of youth experience mental illness [1] , yet access to evidence-based treatments (EBTs) is limited by a shortage of trained providers, poor treatment fidelity, and low consumer help-seeking knowledge [2] [3] . School-based delivery of EBTs can improve access [4] and research demonstrates that EBTs can be delivered effectively by school-based mental health professionals (SMHPs) [5] . Implementation strategies, such as consultation, coaching, and facilitation, promote adoption and sustainment of EBTs in schools [6] [7] [8] , however, evaluation of implementation interventions requires collection of appropriate implementation metrics [9] that is hindered in schools by absence of a unified, acceptable reporting system. TRAILS is a statewide implementation model designed to increase SMHP delivery of CBT, and incorporates didactic instruction, technical support, and in-person coaching. To enable program evaluation, TRAI LS developed a web application, the TRAILS Dashboard, which allows SMHPs to easily record weekly delivery of treatment components, self-reported fidelity, and track student clinical outcomes. Self-report data are cross-validated with standardized assessments and observer (Coach) ratings to inform TRAILS implementation efforts. Development of the TRAILS Dashboard included concept design, wireframing, user testing, and build. Currently, the Dashboard is being utilized within a randomized implementation-effectiveness trial, ASIC, evaluating implementation strategies. All collection of implementation (SMHP-level) and clinical effectiveness (student-level) data occurs through the Dashboard, as does management of student suicide risk. A coach dashboard documents delivery of coaching elements as well as observational ratings of SMHP treatment fidelity. 169 SMHPs are actively using the Dashboard, recording their weekly CBT delivery since November 2018; and have identified 1,347 student participants for clinical outcomes data collection. Response rates for weekly data are consistently above 80% independent of implementation strategy treatment arm. The TRAILS Dashboard presents a novel solution to a common problem in non-clinical implementation research-the lack of a unified system for tracking implementation outcomes. Deployment within the ASIC study allows testing of basic utility and ease of use, but ongoing initiatives are informing future functions to further tailor TRAI LS implementation support, namely dynamic training targeting SMPH skill deficiencies, "nudges" to increase treatment frequency or fidelity, and prompts recommending specific treatment components for students based on clinical data. In Nepal, the second highest ranking risk factor for death and disability combined is indoor air pollution (IAP) [1] . IAP is a risk factor for numerous diseases including pneumonia, stroke, ischemic heart disease, chronic obstructive pulmonary disease (COPD), and lung cancer [2] . Improved Cooking Stove (ICS) is known to reduce the exposure to IAP [3] , but its implementation can have its challenges based on its context and setting. The JWLEE CGM and Dhulikhel Hospital collaborated to conduct formative research prior to the implementation of the project. This study presents the results of the baseline survey for phase 1 and qualitative results. A pragmatic hybrid type 1 design with a step-wedged trial is used. The study is focused on ward 4 for Panchpokhari-Thanpalkot rural municipality, Sindupalchowk District in the north-eastern part of Nepal. Out of all 480 households, a total of 363 households and a total of 663 household individuals were surveyed for the baseline study and data were collected digitally through CommCare HQ. The household-level questions included the main cook's fuel use, cooking dynamics, and health symptoms. The individual-level questions asked for fuel use of household members and their quality of life. To assess the implementation of facilitators and challenges, the planning team conducted focus groups of key stakeholders and community leaders to plan the intervention specifications. Data were analyzed qualitatively using NVivo. The baseline survey results showed that 211 (59.8%) were currently using three-stone fire and 219 (79.0%) were using wood for their primary cooking fuel. 343 (97.2%) participants used charcoal as their alternative option for cooking fuel. 226 (64.0%) of the participants preferred a cookstove design with less smoke. The qualitative analysis revealed that enhancing cultural sensitivity and cultural relevance for adoption, implementation, and maintenance are relevant to effectiveness. Perceptions of complexibility can become a potential barrier in implementing ICS. This baseline study shows that the ICS project can potentially have an impact on the targeted households. Ensuring the adoption of optimal and appropriate technologies by conducting formative research can lead to facilitation of the intervention and improvement in the quality of the overall project. Increasingly it is important to align funding priorities with practice and system realities. It is necessary to ground research and knowledge generation activities in real-world settings and engage broad stakeholders with interest in the research results in program and system planning, delivery and implementation [1] . As a funder we still aim to identify knowledge gaps and share the results with key stakeholders, but we recognize that knowledge translation/mobilization although necessary cannot be enough to bring evidence-based findings into practice. Our approach has moved to funding fewer projects addressing practice gaps and priorities in healthcare with a view to implementing results and innovations, using an implementation science framework. The funding approach has further evolved from funding only individual projects to now funding collaborative and system-level initiatives. Evidence exists that implementation processes rooted in implementation science can be effective, but there are issues of sustainability if the implementation is not embedded at the system level [2] . It is necessary to foster partnerships and involve broad stakeholders in all phases of implementation. The key pillars of our integrative approach are knowledge generation, knowledge mobilisation and effective implementation approaches. As a funder this approach works well as we can specify the type of services that we provide and can be nimble to respond to real-world challenges. Sometimes it is not possible to apply the full spectrum of implementation science activities from beginning to end; action must occur where it is needed to increase capacity of implementing organisations within the system they work in. All our efforts are designed with a view for scalability and sustainability [3] . Within our three streams of activity (injury prevention, acquired brain injury and spinal cord injury) we have amassed a wealth of knowledge around implementation at the local and system levels and have developed an implementation support service resource to coordinate our implementation efforts in an explicit and consistent way. Examples will be discussed that illustrate our systematic approach across the three streams and the lessons learned in moving from traditional funding to impact funding. New directions for implementation strategy design: applying behavioral economic insights to design EBP implementation strategies in community mental health settings Vivian Byeon 1 , Rebecca Stewart 1 The field of behavioral economics provides ro bust explanations for why individuals choose and behave as they do [1] , yet little work has applied these insights to the development of implementation strategies that influence community mental health clinicians' choices and behavior with regard to evidence-based practice. In this study, a team of behavioral scientists and frontline mental health clinicians in the city of Philadelphia used a systematic approach to the identification of behavioral barriers to EBP use in order to develop novel implementation strategies for community mental health settings. This poster describes our approach and results. We followed a four-step process to 1) define our target problem; 2) map the relevant decisions and actions underlying the behavior; 3) brainstorm hypothesized behavioral barriers using previouslycollected contextual inquiry data (implementation strategy ideas that therapists generated during an innovation tournament) [2] [3] , linked to specific behavioral science constructs; and 4) conduct rapid validation of hypothesized barriers through expert consultation, literature review, and a clinician focus group. Drawing on the crowdsourcing data from clinicians, the investigative team generated 156 hypotheses of behavioral barriers to EBP use. Two investigators then de-duplicated and synthesized hypotheses down to a list of 21. We are currently in the last stages of the rapid validation process with community clinicians and will present the final hypotheses to support implementation strategy design in our poster session. To our knowledge, this is the first study incorporating principles of behavioral economics and participatory design to the development of implementation strategies. This systematic, rigorous, and innovative process will allow us to develop candidate implementation strategies from the insights of clinicians. Results from this participatory and behavioral process will drive the design of tailored implementation strategies that will explicitly address and overcome the identified behavioral barriers. Most efficient procedure to engage and guide healthcare professionals in collaborative processes that seek to optimize practice is unknown [1] . The PREDIAPS project aims to assess the effectiveness and feasibility of different engagement procedures to perform a facilitated interprofessional collaborative process to optimize type-2 diabetes prevention in routine Primary Care [2] . Randomized cluster implementation trial conducted in nine PHC centers from the Basque Health Service. All centers received training on effective healthy lifestyles promotion. Headed by a local leader and an external facilitator, centers conducted a collaborative structured process to adapt the intervention and its implementation to their specific context [3] . One of the groups was allocated to apply this strategy globally, promoting the cooperation of all health professionals from the beginning. The other performed it sequentially, centered first on nurses, who lately seek the pragmatic cooperation of physicians. All patients without diabetes aged ≥30 years old with a known CVD risk factor and an abnormal glucose level (≥110-125 mg/ dl) who attended centers during the study period were eligible for program inclusion. Main outcome measures focus on changes in T2D prevention practice indicators after 12 months. Exposition rate of professionals to the implementation strategy actions were similar in both groups but higher in nurses (86%) than in physicians (75%). After 12 months, 2916 eligible at risk patients attended at least once to their family physician, of which 401 (13.8%) have been addressed by assessing their healthy lifestyles in both comparison groups. The proportion of attending patients at risk of T2D receiving a personalized prescription of a healthy lifestyle change (N=214; 7.3%) was slightly higher in the Sequential (7.8%; range 5.5%-10.8%) than in the Global group (6.3%; range 5.8%-6.7%). The proportion of patients receiving a lifestyle prescription from those assessed is also higher in the Sequential than in the Global group (55% vs. 50%). Preliminary results showed that the reach of the implanted intervention programs derived by the PREDIAPS implementation strategy is acceptable but slightly higher in the Sequential group. Center's organizational context has determined implementation results (professional commitment, work overload, multiple corporative initiatives, staff turn-over, etc.). Healthy Hearts Northwest (H2N), one of seven AHRQ-funded Eviden-ceNOW cooperatives, is a pragmatic clinical trial to test different strategies for implementing evidence-based interventions to improve heart health in primary care practice [1] . One intervention was a virtual educational outreach visit (EOV) to increase use of cardiovascular disease (CVD) risk calculation to inform statin use for prevention of CVD [2] . Five physician educators conducted 30-minute EOVs in 44 H2N practices and elicited 13 barriers to implementing CVD risk calculation. To compare the implementation strategies that implementation scientists and primary care clinicians chose as most likely to overcome barriers to implementing a CVD risk calculator in practice. Modified nominal group exercise involving implementation scientists and primary care clinicians, with synthesis of the exercise results Participants: 5 implementation scientists and 26 clinicians from primary care clinics in the WWAMI region Practice and Research Network. Every implementation scientist and clinician chose their top 5 implementation strategies from a list of the 73 evidence-based, published strategies from the Expert Recommendations for Implementing Change (ERIC) study [3] for the 13 barriers. For each barrier, we examined the degree of agreement among ≥30% of clinicians, ≥30% of scientists, or ≥30% of both on chosen strategies. Results ≥ 30% of clinicians and/or scientists chose 39/73 top implementation strategies they felt were the most important to address barriers to CVD risk calculation. Implementation scientists chose 34 of these 39 top strategies; clinicians chose 21. Scientists and clinicians agreed on the choice of 14 of the top implementation strategies. On average, a total of 7 top implementation strategies were chosen by either scientists or clinicians for each barrier; however, scientists and clinicians agreed on only 1 of these top strategies. Conclusions Implementation scientists and clinicians generally choose different implementation strategies to overcome barriers to implementing a CVD risk calculator in practice. Collaboration between these stakeholders could guide the choice of a broader range of strategies to overcome barriers to evidence-based practice. Background Cardiovascular (CV) disease is the main cause of death in American women and CV risk factors are often less controlled in women compared to men. To address CV risk among women Veterans, we developed a CV toolkit comprised of a patient screener, an electronic health record template, and a health education group tailored for women to target CV goal-setting. We describe how iterative cycles of adaptation during implementation allows us to improve fit with local context, address barriers, and increase engagement with CV toolkit components. Guided by Replicating Effective Programs (REP) enhanced with complexity theory, we are conducting an 18-month CV Toolkit study in four sites to increase engagement in CV risk reduction services. During implementation, we monitor staff/provider use of the template and track patient engagement in VA services. Periodic reflections are used to review monthly progress and document multilevel stakeholder engagement and sense-making. Despite early and frequent engagement, there was limited utilization of the patient screener and template over a one-year period at the first site, with staff and providers reporting difficulty remembering to use these tools. While providers made frequent referrals to health education group, participation was low, and remained low even after employing several strategies to increase participation, including audio-care calls and secure messaging. Implementation at later sites indicated that scheduling patients for group classes increased participation and clinical reminders helped care teams incorporate CV toolkit into routine workflow; these suggestions were then incorporated at the first site. Stakeholder (patient, provider and operational partners) feedback led us to develop a telephone facilitated group to increase engagement. The emphasis on nonlinear cycles of tailoring and adaptation in REP gave our team a structured process by which to proactively learn from early failures, engaging stakeholders consistently in identifying pragmatic solutions that aligned with routine workflow. These solutions became real-time modifications to the implementation process to mold tools to the local context, observe uptake and document outcomes. To increase access to evidence-based treatments for hepatitis C (HCV), the Department of Veterans Affairs (VA) established a national collaborative composed of regional teams of providers, leaders, and staff tasked with conducting local implementation strategies to increase HCV treatment initiations. The aim of this longitudinal evaluation was to assess how site-level implementation strategies were associated with HCV treatment initiation. A representative from each VA site (N=130) was asked in four consecutive fiscal years (FYs) to complete an online survey examining use of 73 implementation strategies organized into nine clusters as described by the Expert Recommendations for Implementing Change (ERIC) study. The number of Veterans initiating treatment for HCV, or "treatment starts", at each site was captured using administrative data. Descriptive, nonparametric, and multivariate analyses were conducted on the respondents in FY15 (N=80), FY16 (N=105), FY17 (N= 109), and FY18 (N=88). Of 130 sites, 127 (98%) responded at least once and 54 (42%) responded across all four years. A mean of 25±14 strategies were endorsed in FY15, 28±14, 26±15, and 35±26 in FY16, FY17, and FY18, respectively. While the number of strategies increased over time, the correlation between number of strategies and HCV treatment decreased over time. The most commonly endorsed strategies across all years were: data warehousing techniques, tailoring strategies to deliver HCV care, and intervening with patients to promote uptake and adherence to HCV treatment. One strategy ("make efforts to identify early adopters to learn from their experiences") was significantly associated with treatment starts in all four years. In FY15, strategies were focused on developing interrelationships, FY16 focused on using evaluative and iterative strategies, FY17 focused on training and educating stakeholders, and FY18 focused on providing interactive assistance. The important strategies in each year were then mapped to Exploration, Preparation, Implementation, Sustainment framework stages. This evaluation represents the first large-scale four-year assessment of implementation strategies nationwide. Surveying providers about ERIC strategies is a feasible way to understand the associations between strategies and clinical outcomes over time. These results add to our understanding of the implementation strategies used over time and across stages of planning, implementation, and sustainability. Background Up-to-date human papillomavirus (HPV) vaccination in the US has increased since the vaccine's introduction over a decade ago to 49% of adolescents ages 13-17 in 2017 [1] . However, vaccination coverage remains far below the Healthy People 2020 goal of 80% for adolescents ages 13-15 [1] . As a strategy to improve uptake, the President's Cancer Panel [2] and the National Vaccine Advisory Committee [3] have recommended expanding HPV vaccine provision in pharmacies. Pharmacies are promising alternative settings for HPV vaccination because of their population reach, convenience, and existing infrastructure for vaccine delivery. As a result, pilot projects conducted in five states aimed to demonstrate the utility of pharmacy-located HPV vaccination services for adolescents. To date, no study we are aware of has documented the experiences of implementing HPV vaccination programs in real-world pharmacy settings. We sought to document challenges and opportunities of implementing pharmacylocated HPV vaccination services in five US states. We evaluated the success of the pilot projects by mapping reported results to key implementation science constructs: service penetration, acceptability, appropriateness, feasibility, fidelity, adoption, and sustainability [4, 5] . Pilot projects were planned in North Carolina (k=2 pharmacies), Michigan (k=10), Iowa (k=2), Kentucky (k=1), and Oregon (no pharmacy recruited) with varying procedures and recruitment strategies. Sites had open enrollment for a combined 12 months. Despite substantial efforts in these states, only 13 HPV vaccine doses were administered to adolescents and three doses to age-eligible young adults. We identified two major reasons for these underperforming results. First, poor outcomes on service penetration and appropriateness pointed to engagement barriers: low parent demand and engagement among pharmacy staff. Second, poor outcomes on feasibility, adoption, and sustainability appeared to result from administrative hurdles: lacking third party reimbursement (i.e., billing commercial payers, participation in Vaccines for Children program) and limited integration into primary care systems. In summary, pilot projects in five states all struggled to administer HPV vaccines. Opportunities for making pharmacies a successful setting for adolescent HPV vaccination include expanding third party reimbursement to cover all vaccines administered by pharmacists, increasing public awareness of pharmacists' immunization training, and improving care coordination with primary care providers. Identifying facilitators and barriers for the implementation of a complex intervention for patients with metastatic lung cancer Anja Siegle 1 The German National Cancer Plan and the American Society of Clinical Oncology (ASCO) [1] recommend early integration of palliative care and advance care planning for patients with metastatic lung cancer. To address these recommendations, the Heidelberg Milestone communication approach (MCA) has been developed [2] . MCA is a complex intervention involving tandems of physicians and nurses. It aims at providing coherent care along the disease trajectory and integrates palliative care early. The MCA has been implemented in a theory-led way [3] in the in-and out-patient departments of a comprehensive cancer center (hospital setting). While the degree of the implementation success is still under scrutiny, the importance of identifying barriers and facilitators of the MCA is already apparent. The aim of this study is to identify barriers and facilitators of the MCA implementation. A qualitative content analysis [4] of written minutes (n= 47) of implementation meetings with nurses, doctors and hospital managers is conducted. The data analysis comprises open coding, development of main categories, identification of sub categories and application of these categories. As a theoretical framework for implementation evaluation of the MCA, the Consolidated Framework for Implementation research (CFIR) [5] is used. MAXQDA is used to organize the collected data. Preliminary results will be presented on aspects facilitating or hindering implementation in the following dimensions: characteristics of the intervention (e.g. adaption, fit), inner (e.g. communications, climate, readiness) and outer (e.g. economic, political, social context) settings, individuals involved (e.g. interaction between individuals, influence of individual or organizational behavior) and implementation process (and sub-processes). Knowing facilitators and barriers of the MCA supports future implementation processes in this hospital. Understanding this implementation process helps to identify determinants for successful implementation processes of the MCA in other organizations. Despite the highest rates of tobacco use and tobacco-related morbidity and mortality, smokers with behavioral health disorders rarely receive tobacco dependence treatment within behavioral health care settings. Taking Texas Tobacco Free (TTTF) has successfully targeted this disparity by delivering a multi-component, tobacco-free workplace program providing policy implementation and enforcement, education, provider training in tobacco screenings and treatments, and nicotine replacement therapies to behavioral health clinics across Texas [1] [2] [3] . Via a mixed methods [4, 5] approach we used a formative evaluation process to adapt implementation strategies to local contexts and evaluated program outcomes and characterized processes influencing implementation in two local mental health authorities serving 17 clinics. Varied data collection included pre and post-implementation leader, provider, and staff surveys; and pre, mid, and post-implementation provider, staff and consumer focus groups. During implementation, data were collected via various logs (tobacco screenings, nicotine replacement therapy delivery) to monitor program content delivery. All clinics adopted a 100% tobacco-free workplace policy, integrated tobacco screenings into routine practice, delivered evidence-based interventions, dispensed nicotine replacement therapies to consumers and staff, and recorded significant increases in provider knowledge on how to address tobacco dependence. Pre, mid, and post-implementation qualitative findings served to: 1) develop program strategies (educational tools, videos) and materials (brochures, posters) adapted to local contexts and populations and address barriers; 2) adjust delivery systems of key components to enhance implementation; 3) understand reasons for success or failure to implement specific practices, respectively; and 4) reveal program integration into clinic culture, enhancing sustainability. Conclusions TTTF has proven successful in integrating tobacco cessation interventions into regular clinical practice to address tobacco use within behavioral health clinics. Mixing methods involved program adopters and recipients as collaborators who directly impacted implementation by shaping the intervention to their individual context and needs. Collaboration of such key stakeholders was vital to increasing program fit, ownership, adoption and sustainability; closing the gap between research and practice. These findings contribute to the development of flexible strategies and tailored interventions responsive to real-world conditions in diverse settings which better address implementation barriers thus enhancing the effectiveness and sustainability of a tobacco-free workplace program. Background A greater understanding and uptake of implementation science frameworks and measures can help both cancer control practitioners and researchers leverage crucial insights into how to best deliver research-based initiatives in the complex communities where they are crucially needed. In April, the National Cancer Institute (NCI) released Implementation Science at a Glance, a workbook to introduce practitioners and policymakers to the building blocks of implementation science. This resource is a natural extension of our experiences funding [1] and training researchers in implementation science as well as perspectives NCI gained through this work [2] . A preliminary draft of the resource was reviewed by fifty-eight cancer control researchers and practitioners for clarity and concept. The final version reflected advances both in our understanding of implementation science and how to communicate it to support and inform the work of cancer control practitioners. Case studies illustrate implementation science in practice, provide lessons learned in the field, and brief practitioners about the components of IS including evidence-based interventions, fidelity, adaptations, stakeholder engagements, theories, models, and frameworks, strategies, evaluation, and sustainability. Conclusions This presentation will outline how Implementation Science at a Glance illustrates implementation science frameworks, models and measures to help drive community and organizational transformation and, in turn, develop broader disparities-reducing implementation strategies. By providing insights supporting greater uptake of Implementation science research designs, the resource offers rigorous methods that could accelerate the pace at which equity is achieved in real-world practice. Rural populations have lower rates of colorectal cancer (CRC) screening [1] [2] [3] and sub-optimal access to preventive care services [4] . In North Carolina, geospatial analyses have revealed that sub-optimal access to health services in rural regions significantly related to higher rates of CRC mortality in rural "hotspots" [4] . As such, identifying alternative health care settings in rural areas that could deliver CRC screenings may be one way to alleviating this health inequity. Pharmacies may be an opportune setting to distribute fecal immunochemical test (FIT) kits for CRC screening in rural areas as one way to improve access to CRC screening in communities with poorer access to traditional care delivery settings. FIT kits are a guidelinerecommended screening test that patients can complete at home [5] [6] [7] . This formative work will assess the feasibility and acceptability of delivering FIT kits for CRC screening in pharmacy settings (PharmFIT). We are conducting semi-structured interviews with key informants to elicit: 1) knowledge, attitudes, and perceptions of a PharmFIT intervention; 2) barriers and facilitators to implementing PharmFIT; and 3) recommendations for implementation strategies that would support successful delivery of a PharmFIT intervention. We are interviewing 12 primary care providers (PCP), 12 pharmacists and pharmacy technicians, and 12 patients (n=36). PCP and pharmacy staff interviews are focused on care coordination and follow-up processes and procedures, whereas patient interviews are focused on the acceptability and relative advantage of receiving FIT kits from pharmacies. Interviews are audio-recorded, transcribed and independently coded by two team members using a directed content analysis approach [8, 9] PRISM [10] and Diffusion of Innovations Theory guide analysis and organization of themes. Pharmacies are well-positioned to increase access to preventive health services such as colorectal cancer screening. Patients, pharmacists, and primary care providers have voiced support for an extended role for pharmacists in delivering FIT kits for colorectal cancer screening. Results from this study can be used to elucidate key care coordination and follow-up issues for primary care providers and pharmacy staff and to identify implementation strategies [11] needed to target identified barriers (e.g., training pharmacists) to test intervention implementation and effectiveness. Menu labelling has gathered growing public and legislative support in response to the increased consumption of foods outside the home and the associated risks of overweight and obesity. A recent systematic review has shown menu labelling effects consumer food choice and the food industry behaviour [1] . Several countries have introduced menu labelling policies on a voluntary or mandatory basis; however, challenges to implementation have arisen (e.g. poor uptake, inaccurate nutritional information). The aim of this systematic review was to synthesise the evidence on the barriers and enablers to menu labelling implementation from the food industry perspective. The review adopted the 'best fit' framework synthesis approach, designed for policy urgent questions [2] . No restrictions applied to publication type, study design, data collection method, language or publication year. At least two independent reviewers performed study selection, data extraction and quality appraisal. A combination of deductive coding, using the Consolidated Framework for Implementation Research [3] as the a priori framework, and inductive analysis, using secondary thematic analysis were undertaken. The overall process led to the construction of an adapted version of the CFIR. Of the 2,806 articles identified, 17 studies met the eligibility criteria. Most frequently cited barriers were coded to the CFIR constructs 'Consumer Needs & Resources' (e.g. lack of customer demand and understanding) and 'Compatibility' (e.g. lack of standardised recipes, limited space on menus). Commonly cited facilitators were coded to the CFIR constructs 'Relative Advantage' (e.g. improved business image/reputation) and 'Consumer Needs & Resources' (e.g. customer demand, enabling healthier food choices). Relationships between constructs (across and within domains) were also evident. The revised framework, based on the final list of constructs from the deductive and inductive coding, maintained many of the essential elements of the CFIR but a number of (sub)constructs with no supporting data were removed and newly developed constructs incorporated. Conclusions Findings from this review provide a foundation for selecting and tailoring implementation strategies to improve adoption, implementation, sustainment, and scale-up of menu labelling interventions. Moreover, in refining the CFIR, this review provides a theoretical contribution to help advance the field of implementation science. Malnutrition is common among older adults and contributes to poor health and premature death [1] [2] [3] . Malnutrition is a complex condition with medical and social risk factors [4] [5] [6] , including food insecurity. We are developing and implementing a two-phase screening study to identify older patients at-risk for malnutrition and food insecurity in the emergency department (ED) and connect them to a community-based organization (CBO) to address social needs. During Phase 1, multiple stakeholder perspectives (i.e., ED, patient, CBO) were collected on how best to implement a sustainable EDbased screening process that considers the complexities and rapid pace of the ED. ED stakeholders included registered nurses (RNs), nursing assistants (NAs), social workers (SWs). To understand ED perspectives, research staff conducted semi-structured interviews (SSIs) with interview guides developed using the Consolidated Framework for Implementation Research (CFIR) [7] Guides included constructs from four CFIR domains (i.e., intervention characteristics, inner setting, characteristics of individuals, process). SSIs were transcribed and analyzed using framework-guided rapid analysis [8] [9] . To understand the patient perspective, research staff tested screening questions with 75 older patients to identify how many are at-risk, and gauge receptivity to screening and referrals within the ED. Research staff worked with a CBO to understand their perspective on data sharing, referral pathways and "closing-the-loop." Results Nine SSIs (n=3 RNs, n=2 NAs, n=4 SWs) were analyzed. Common themes related to constructs from CFIR domains were identified, including building the screener into the EHR, comparing to existing screening processes, and educating ED staff. A critical finding was that NAs, not RNs, should screen patients. From the sample of patients screened, approximately 35% were positive for malnutrition, 18% for food insecurity and 8% for both. Patients were receptive to being screened in the ED and indicated they would be willing to receive help connecting to CBOs. The CBO informed the development of referral workflows, particularly bidirectional communication and datapoints to facilitate data sharing. The stakeholders' perspectives informed the workflows that will be implemented and evaluated in Phase 2, including NAs screening, SWs connecting patients to the CBO, and the CBO sharing updates on the status of services provided to patients. Effective implementation strategies for male engagement in a program for Zambian couples experiencing IPV and substance mis-use Laura Eise 1 , Stephanie Skavenski van Wyk 2 , Jeremy C. Kane 2 , Kristina Metz 2 , Laura K. Murray 2 1 University of Washington, Seattle, WA, USA; 2 Johns Hopkins University, Baltimore, MD, USA Correspondence: Laura Eise (laura.m.eise@gmail.com) Implementation Science 2020, 15(Suppl 2):A173 The link between violence and substance use is well established. However, the violence literature has largely evaluated prevention programs, or those focused on women only. The need to include male counterparts is recognized, yet challenging. Evidence indicates that males disconnect from health-care services at high rates and, furthermore, information specific to low-and middle-income countries (LMIC) is scarce. In order to offer effective care, we must better understand how to engage men in these situations, which may include economic barriers, pervasive societal attitudes, and self-stigma to access available services. We recently completed a randomized controlled trial (RCT) of a transdiagnostic psychotherapy (the Common Elements Treatment Approach; CETA) delivered to Zambian couples who indicated recent intimate partner violence (IPV), as well as male substance misuse. In order to recruit participants within a concentrated period (i.e., 12 weeks), we worked closely with a local partner that had successfully engaged men in an alcohol mis-use program. The partner utilized a multi-tiered process of community word-of-mouth and engagement by respected peers, with an emphasis on a non-stigmatizing process of screening. Throughout the study, there were high rates of male engagement and significant treatment effects both for the reduction of violence and alcohol use. To gain a more in-depth understanding of the RCT findings, including the male engagement and retention, we qualitatively explored mechanisms of behavior change related to male perpetration of IPV. We sampled adult men and women from the 123 couples randomized to the intervention arm. We conducted 30 first round interviews (16 women; 14 men) and then re-interviewed 20 participants (13 women; 7 men). In addition, we conducted 4 focus groups (2 women; 2 men). We also analyzed an implementation log maintained by study staff documenting engagement and retention strategies, challenges, and successes throughout the study. Based on the results of this data collection and analysis, our poster will highlight the successful implementation strategies used in this RCT on IPV and substance use, present the data documenting the engagement and retention of male participants, and summarize the qualitative responses from men themselves that highlight key facilitators and barriers to engagement. Trial Registration: ClinicalTrials.gov NCT02790827 Changing policy and practice in substance use treatment clinics through the implementation of a tailored, comprehensive tobacco free workplace program Lorraine Reitzel 1 , Bryce Kyburz 2 , Isabel Leal 1 , Kathy Le 1 , Virmarie Correa-Fernandez 1 , Teresa Williams 2 , Daniel O'Connor 1 , Ezemenari Obasi 1 , Kathleen Casey 2 1 University of Houston, Houston, TX, USA; 2 Integral Care, Austin, TX, USA Correspondence: Lorraine Reitzel (lrreitzel@uh.edu) Implementation Science 2020, 15(Suppl 2):A174 Despite elevated tobacco use rates among individuals in treatment for substance use disorders in Texas, only 70.2% of treatment clinics screen consumers for tobacco use, 55.4% provide cessation counseling, 24% offer nicotine replacement therapies, and 34.3% have a tobacco-free workplace policy [1] . Comprehensive tobacco-free workplace programs that include all of these evidence-based strategies are known to be effective in reducing tobacco use among this vulnerable population [1] . Taking Texas Tobacco Free is one such tobacco-free workplace program that has been successfully implemented within hundreds of behavioral health clinics in Texas (www.takingtexastobaccofree. 65 (8) :1741-1747 com) [2] [3] [4] [5] . In 2017, we were funded to expand the program to dedicated substance use treatment centers. Taking Texas Tobacco Free implementation includes a tobacco-free workplace policy along with the provision of education and specialized provider training to enable the institution of regular tobacco-use assessments and treatment provision or referral for tobacco dependence. A mixed-methods, formative evaluation process is used to understand clinic-specific facilitators and potential barriers, which guides the implementation strategies within diverse contexts. Consultation, practical guidance, and treatment resources are provided and mechanisms for program sustainability are emphasized. Enrolled clinics (N=8) serve~70,000 unique consumers annually, including some special groups (e.g., sexual minorities, women with children). Thus far, Taking Texas Tobacco Free has educated 1,119 professionals through 61 discrete sessions and reached 92,521 individuals through passive material dissemination. Each clinic has adopted a 100% tobacco-free workplace policy, integrated tobacco-use assessments into routine practice, delivered evidence-based interventions, and dispensed nicotine replacement therapies to consumers and staff. Recruitment is ongoing. Taking Texas Tobacco Free is an effective comprehensive tobacco control program that has proven successful in implementing tobacco-free workplace policies, training providers in tobacco cessation interventions and in integrating those interventions into regular clinical practice within substance use treatment clinics. This presentation will describe the program, participating clinics, data-based strategies used to tailor implementation within each setting, accomplishments to date (e.g., knowledge gained by staff and clinicians, tobacco-use assessments provided, pre-versus post-implementation changes in clinician behavior), and lessons learned during the implementation process that can guide program dissemination in other settings and states. Opioid dependence and overdose are serious public health concerns in the United States [1] . States have sought to identify and implement policy interventions to address these growing public health problems. One policy intervention identified has been to set prescribing limits such that physicians prescribe no more than five days' supply for post-surgical acute pain in an effort to reduce patient misuse and overdose [2] . As such in 2017 North Carolina passed the Strengthen Opioid Misuse Prevention (STOP) act which limits prescriptions to three to five-day supplies of opioids for acute postsurgical pain. The purpose of this study is to understand the barriers and facilitators in the passage and implementation of the STOP act in North Carolina. Three groups were identified as key figures in the passage and implementation of the STOP act: government officials, hospital administrators, and opioid prescribers. Using the Consolidated Framework for Implementation Science (CFIR) [3] we developed three separate interview guides to be administered in one-on-one interviews. Two researchers developed the guides by reviewing all constructs within the CFIR and identifying construct-derived questions that would be most salient for each interview group. Questions were adapted to fit a policy context as well as fitting the role of the individual in policy implementation. This research project is currently in the data collection stage. Interviews will be conducted from March to May 2019; analysis will begin in June 2019. In addition to using the CFIR to design the interview guides, the CFIR will inform our coding of interview data and the development of analytical themes. Interviews will be analyzed across groups in order to summarize the perspectives and identify unifying or diverging ideas that may inform how the law is being implemented in the state. Few studies have used the CFIR throughout the data collection process from development of interview guides to development of qualitative codebooks and conducting analysis. Given the growing number of States proposing laws to limit opioid prescribing, understanding the experience of North Carolina in implementing the STOP act will inform how states might support their key partners for more effective policy implementation. Background Patients with the combination of chronic pain and opioid use disorder have unique needs and may present a challenge for clinicians and health care systems. Primary care providers' (PCPs) capacity to deliver high quality, evidence-based care for this important subpopulation is unknown. This study's objective was to develop and test a survey of PCP capacity to treat co-occurring chronic pain and OUD. Capacity to Treat Co-Occurring Chronic Pain and Opioid Use Disorder (CAP-POD) questionnaire items were developed over a 2-year process including literature review, semi-structured interviews, expert panel review, and pilot testing. A national sample of PCPs (MD, DO, NP, PA) were recruited via email to complete an online survey that included the 44-item CAP-POD questionnaire. Response options ranged from 1 (strongly disagree) to 7 (strongly agree). CAP-POD items were analyzed for dimensionality and inter-item reliability. We compared mean scores across provider characteristics (education, setting, years' experience) to identify potential gaps in capacity. Results 509 PCPs from across the US completed the questionnaire. Principal component analysis resulted in a 22-item questionnaire. Twelve more items were removed because of their influence on coefficient alphas, resulting in a 10-item questionnaire with 4 domains: 1) Motivation to Treat patients with chronic pain and OUD (α =.87, M=3.49,SD=1.48); 2) Trust in Evidence (α =.87, M=5.67, SD=1.03); 3) Assessing Risk (α =.82, M=5.45, SD=1.19); and 4) Patient Access to therapies (α =.79; M=3.06, SD=1.47). Mean scores across the four scales differed significantly (p<.001). We developed a short, 10-item questionnaire that assesses the capacity of PCPs to implement best practice recommendations for the treatment of co-occurring chronic pain and OUD. The questionnaire and scales demonstrated adequate validity and good inter-item reliability. PCPs reported moderate trust in evidence of treatments for co-occurring chronic pain and OUD, and in their ability to identify patients at risk. Conversely, they had low desire to treat these patients, and see their patients' access to relevant services as suboptimum. These data imply a service shortfall that will likely require fixing with additional training, service design, and incentives. The questionnaire provides a brief, validated evaluation tool for such interventions. Background Unhealthy alcohol use exacerbates and complicates treatment of chronic liver disease [1] . Yet, evidence-based alcohol-related care is inconsistently delivered in hepatology clinics [2] . Informed by research supporting practice facilitation as an effective implementation strategy in primary care, we aim to tailor practice facilitation to implement evidence-based alcohol-related care in four Veterans Affairs (VA) hepatology clinics [3] . Here we describe barriers and facilitators garnered from qualitative interviews with key stakeholders at 2 of 4 clinics to inform intervention tailoring. We recruited key stakeholders (n=23) including clinicians (MD, NP), clinical staff (RN, LPN, MSW), and administrators responsible for caring for Veterans with liver conditions. Semi-structured qualitative interviews were developed using the Consolidated Framework on Implementation Research (CFIR) and specifically focused on understanding outer and inner setting and individual domains [4] . We elicited stakeholders': (1) context for, experiences with, and perspectives about providing care to Veterans with liver conditions and unhealthy alcohol use; and (2) feedback regarding a practice facilitation intervention. Rapid content analysis was used to extract relevant themes. Qualitative interviews highlighted barriers to and facilitators of providing alcohol-related care and tailoring practice facilitation. Barriers included lack of systematic alcohol screening procedures; variability in clinicians' knowledge, comfort, and interest in providing evidencebased treatments (e.g., medications for alcohol use disorder); perceived inadequate linkage with specialty addiction treatment and/or behavioral health; and challenges related to staffing time/availability. Facilitators included system-and clinic-level leadership support, histories of successful quality improvement efforts, staff who are wellprepared to serve as clinical champions, consensus regarding the importance of addressing alcohol use, enthusiasm for several planned practice facilitation elements, and cohesive teams. Consistent with the CFIR, findings from 23 liver clinic staff suggest that a practice facilitation intervention can capitalize and build on existing setting and individual characteristics. Conclusions Specifically, the intervention should build on existing leadership support, enthusiasm, team cohesiveness, and successful past quality improvement efforts and include: (1) assistance integrating standardized alcohol screening into clinic flow; (2) training and ongoing support regarding evidence-based care for unhealthy alcohol use; and (3) linkages with or internal capacity building for behavioral health or specialty addictions treatment. Implementation science and entrepreneurship: harnessing synergy for discovery uptake Enola Proctor 1 , Emre Toker 2 , Rachel Tabak Background Implementation science and social entrepreneurship share the goal of accelerating the uptake of medical discoveries for widespread use in clinical and community healthcare. This paper reports infrastructure and activities within a CTSA program to advance synergy between these two fields. This work is based on the assumptions that implementation science can benefit from entrepreneurship's emphasis on market demand, while entrepreneurship can benefit from implementation science's emphasis on data, models, and contextparticularly the policy, social, and organizational context of healthcare. Our CTSA conducted activities to identify challenges and areas of complementarity between implementation researchers and entrepreneurs. First, we held a series of meetings between implementation researchers and entrepreneurs, the purpose of which was to identify and map shared and distinctive approaches regarding criteria for roll-out readiness, metrics for assessing return on investment, roll-out processes, risk tolerance, and priority products. Second, we convened an IdeaBounce@ experience, an event in which implementation researchers "pitched" their innovations to an audience of entrepreneurs and received feedback. A qualitative researcher observed both activities, taking notes and synthesizing observations. This work revealed that implementation researchers and entrepreneurs had different perspectives on: criteria for rollout readiness, return on investment, risk tolerance, and product goals. Implementation researchers focus on empirical evidence of innovation benefit, minimizing risk and unanticipated consequences, and carefully sequenced steps in implementation. Entrepreneurs focused on market demand, innovation cost, numbers expected to benefit from the innovation, and infrastructure and payment required for sustainment. Harnessing the synergy between these disciplines can advance full realization of the benefits of biomedical research health care and population health. Both fields face the reality that the number of discoveries needing translational support greatly exceeds available funding and absorptive capacity. Innovative approaches, infrastructure development, and training are required to leverage the yet-untapped synergy between these fields. We identify a number of mechanisms for advancing synergy between these two fields-an exemplar of team science. Implementing across an integrated health care system and a state criminal justice systemlessons from a peer support intervention for veterans leaving incarceration Background Veterans just released from incarceration ("reentry veterans") experience barriers to housing and health services, which heightens risk for homelessness, recidivism, morbidity and mortality [1] . The Veterans Health Administration (VHA) employs peer support specialists, but does not have dedicated peers supporting the multi-faceted needs of reentry veterans. We developed and implemented the VHA's first peer-support [2] initiative for reentry veterans, the Post-Incarceration Engagement (PIE) program. We used a Facilitation strategy to implement PIE in Massachusetts. External facilitation included developing an intervention manual, worksheets, training curriculum, and hiring veteran peers. Peers met weekly with reentry veterans to address life priorities, and support community reintegration in 3 areas: linkage to services, skill building, and social support. External facilitation also involved stakeholder engagement with Massachusetts' Department of Correction (DOC), Mental Health, and Veterans Services; network development with community-based service providers; and marketing presentations to VHA regional homelessness programs and to veteran inmates in DOC facilities. Internal facilitation, led by a social worker champion, involved educating service line chiefs at Massachusetts' VHA medical centers about the benefits of the PIE program. High levels of collaboration were achieved between with the Department of Veterans affairs central office justice programs and a coalition of state agencies and community organizations. PIE served 30 reentry veterans released from 6 DOC prisons and 3 county jails. Peers had over 200 encounters with these veterans. PIE reentry veterans had a higher likelihood than comparison veterans of linkage to substance use treatment (80% versus 19%, respectively, P<0.001) and mental health care (87% versus 64%, respectively, borderline significant). They were more likely than comparison veterans to access VHA homelessness services, such as the domiciliary inpatient program (53.3% versus 2.7%, respectively, P<0.001) and short-term emergency beds (26.7% versus 5.4%, respectively, P=0.05). Though not statistically significant, trends suggested reentry veterans had greater access, than comparison veterans, to transitional grant and per diem housing (26.7% versus 25.4%, respectively) and to federal housing vouchers (6.7% versus 3.7%, respectively). Bridging the gap between rural and urban mental health services requires developing creative solutions to complex challenges that are unique to rural areas. Previous research has documented numerous mental health disparities in rural settings, including higher rates of depression and suicide [1] [2] , and limited resources and barriers to care restrict access to mental health services for rural residents [3] [4] . Despite the demonstrated need for intervention, there are significant challenges associated with implementing evidence-based interventions in rural community settings [5] . However, little is known about the current state of mental health implementation in rural settings. This scoping review thus aims to address this gap by providing a systematic overview of how evidence-based mental health interventions are being implemented within rural community settings. The scoping review is structured according to Peters et al's framework for conducting scoping studies [6] . We searched the following databases: PubMed, CINAHL, PsychINFO, EMBASE, SCOPUS, Web of Science, ClinicalTrials.gov, and the Cochrane Library. The three search strings used for this review included variations of "mental health," "implementation," and "rural." Inclusion criteria: 1) empirical study involving the implementation of a mental health intervention in a rural setting; 2) English language; and 3) peer-reviewed journal publication. No restrictions were placed on year of publication, sample size, or research design. Screening and review of articles will be carried out by two reviewers. A third reviewer will be involved as needed for consensus. We will assess and review findings through both tabular and thematic analyses. We are currently in the process of screening abstracts. In April-May 2019, we will review and extract full texts. We will present the yields, characteristics of included articles, and a description of evidencebased mental health interventions being implemented and tailored to the unique rural context. We will also describe the implementation strategies, adaptation methods, and outcomes associated with these studies. This project is intended to provide an overview of the current state of mental health implementation research in rural settings to identify gaps in previous research and identify areas for future work. Transition-age youth have elevated rates of mental disorders, and often do not receive services. Few mental health interventions have been developed for older youth in transition, and even fewer have been found to be effective over the transition to adulthood. Cornerstone, a theoretically-guided intervention has shown promise for addressing the mental health needs of this group as they emerge into adulthood [1] . Cornerstone provides case management, traumafocused cognitive behavioral therapy, mentoring/peer support, and community-based in-vivo practice to address stigma and mental health symptoms, and practical skill development to improve the transition to independence among TAY with mental health conditions [2] . Using the Consolidated Framework for Implementation Research (CFIR) [3] , this study examined determinants of implementation of Cornerstone with the goal of creating an implementation manual to guide real-world effectiveness trials and scalability efforts. Within a Hybrid Type 2 trial, investigators developed a semistructured interview protocol using implementation strategy domains as a framework [4] . Face-to-face interviews were conducted with clinic staff (n = 8) and state-level leadership (n = 3), and research staff (n = 1) on determinants of implementation for Cornerstone, such as planning, training, and supervision. Using grounded theory with sensitizing concepts, multiple coders analyzed the data using constant comparison. Iterative discussion(s) occurred over six months until saturation was met. Using the CFIR [3] , we created a comprehensive review of implementation determinants of the Cornerstone intervention, as well as a review of contextual information (e.g., state policy reforms) from statelevel stakeholders which may impact future scalability and sustainability of the intervention. Outer setting themes converged around the external policy context and incentives, with respondents discussing value-based payment and the importance of tracking nonbillable tasks of mentors. Process themes pointed to important areas of planning: integration of mentors within the clinic, regular team check-ins, and the increased use of technology by mentors. Participants qualitatively reported high acceptability and feasibility for the cornerstone intervention and its components. Results will be combined with user-centered design approaches, such as the simplification principle [5] , to develop a Cornerstone Implementation Manual that will assist us in moving toward testing effectiveness of a much-needed intervention for TAY. Trial Registration ClinicalTrials.gov NCT02696109 To reduce the gap between research and practice in community mental health services, there is a critical need to develop new methods for scaling up evidence-based practices [1] . To increase widespread access to effective practices, we are in the process of developing an Integrated Scaling Approach (ISA) for the efficient largescale implementation of empirically based interventions for people with psychiatric disabilities. We conducted a scoping review of the literature across various fields, including mental health, our own field of practice, as well as public health, business, and education, fields in which large scale implementation efforts are common. We then focused on examples of the implementation of employment initiatives, which have become an important focal point for change in practice and policies in mental health agencies and systems interested in the recovery of people with psychiatric disabilities [2] [3] . While interventions have proven effective in supporting employment for this population, the number of people benefiting from them remains limited [4] [5] [6] . The scoping review included interviews of a range of stakeholders, with experiences in implementing such employment initiatives in their state or region (whether successful or unsuccessful) and expertise in program leadership, employment services, mental health and vocational rehabilitation services administration and policy. Both literature and interviews were analyzed to identify recurring themes and critical components of large-scale implementation in community mental health services. Analyses currently in process will identify characteristics of these critical components drawn from the cross-field scoping review. A pilot test of the ISA and a final evaluation will be conducted in two states in 2020-2021.The analyses of the scoping review and the results of the pilot and evaluation studies will be used to create a handbook for intervention researchers, system and program administrators and knowledge translation specialists to use, when scaling up new interventions in mental health. In this presentation, we will share the data collection, analysis process, and preliminary characteristics of the ISA as identified through the comprehensive scoping review. Applying implementation science for real world impact: operationalized core practice components, feasibility testing, and next steps William Aldridge, Rebecca Roppolo, Julie Austen, Robin Jenkins University of North Carolina at Chapel Hill, Chapel Hill, NC, USA Correspondence: William Aldridge (will.aldridge@unc.edu) Implementation Science 2020, 15(Suppl 2):A183 Background Implementation science is at risk to suffer from the same challenge it was designed to address: a lack of translation into real world application. Complicating this challenge is that robust application of implementation science requires supporting behavior change at each of individual, organizational, and system levels. "Technical assistance," "facilitation," and "implementation support" are terms often used to describe the concept of "implementation practice." Regardless of these labels, what drives the effective application of implementation science within real world environments? Materials and Methods Drawing from a review of relevant literature and our experience facilitating the real-world application of implementation science, members of The Impact Center at FPG organized ten theoretically-and empirically-informed core practice components to strengthen implementation support processes. These ten proposed core practice components underwent initial feasibility testing within two projects involving implementation support for communities scaling an evidence-based system of parenting interventions. For more than two years, implementation specialists have tracked their utilization of the practice components across interactions with community sites. Implementation specialists working to build the capacity of intermediary partners also tracked their use of practice components. All community and intermediary sites received monthly surveys to report process and short-term outcomes. Intended long-term outcomes of implementation support (capacity to support implementation best practices at community and intermediary levels) were assessed every six months. Initial results suggest that the ten proposed practice components are an effective way to organize the work of implementation support. Supported sites reported favorable process outcomes, such as acceptability, feasibility, and appropriateness. Short-term outcomes, such as working alliance, have been useful markers for early successes or challenges. Long-term capacity outcomes have demonstrated improvement over time. Notwithstanding these strengths, Center implementation specialists voiced a need for greater clarity about operational activities related to the practice components. This recently led members of Center to re-operationalize the components to better support consistent application. Next steps include the development of a complete practice profile, stronger training and fidelity assessment materials, and formative evaluation methods to test statistical associations between the components and intended short-and long-term outcomes. If you want more research based practice, you need more practice based and early stage D&I trained researchers (borrowed and slightly changed from Larry Green) Rodger Kessler, Cady Berkel, Matthew Buman, Stephanie Brenhofern, Scott Leischow Arizona State University, Tempe, AZ, USA Correspondence: Rodger Kessler (rodger.kessler@asu.edu) Implementation Science 2020, 15(Suppl 2):A184 Background While training programs in D&I research have emerged over the last few years, they have generally been limited to single institutions or individuals traveling to national training sites. This has limited reach of training and opportunities for multi-institutional development of broad D&I capacity. In addition, investigators must effectively engage with other partners, from clinical trials centers to community partners and policymakers. Such engagement skills need to be embedded in the core D&I training. This includes assisting earlier stage translational scientists' participation in next stage activities, with designing for dissemination at the forefront. We designed a yearlong D&I training program for Arizona State University faculty and other researchers across the state, borrowing from the TIDIRH curriculum. Implementation began in February 2019. Participant expectations include: on-site attendance at presentations by local and national D&I scholars, completion of readings between sessions, and regularly working with an assigned mentor to generate a project to move their D&I effort ahead. We started the program recruiting the capacity of 25 trainees. After our kickoff event, seven participants withdrew (n=3 perceived relevance, n=2 distance/time, n=1 moved, n=1 unknown). We invited two trainees from the waitlist and now have 20 trainees who span the translational spectrum: Basic research (n=5); Pre-clinical (n=4); Efficacy/Adaptation (n=9); Implementation in clinical and community settings (n=12); Studying health outcomes at the population level (n=7) and career stage [graduate student/postdoc (n=4); assistant professor (n=9); associate professor (n=5); clinical professor (n=1); and adjunct professor (n=1)]. Total n is greater than 20 because we allowed trainees to select multiple areas. Each trainee was paired with one of nine mentors. We generated a multi institutional D&I training program. Recruitment was easily accomplished. Loss of participants due to absence of distance learning needs attention and lack of fit to earlier stage translational scientists suggests we need to refine the material presented at the first event to better include those individuals. Little D&I training has been developed for the basic end of the translational spectrum; we are attempting to fill that gap. We will report further on evaluation data and the projects that trainees generate. Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. 
