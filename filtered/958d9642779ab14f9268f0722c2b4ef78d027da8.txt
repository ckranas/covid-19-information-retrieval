958d9642779ab14f9268f0722c2b4ef78d027da8
ESICM LIVES 2016: part two NEUROMONITORING A391 Physiologic monitoring for neurocritically-ill patients: an international survey of intensivists
  Milan S  Sivakumar F S Taccone K A Desai C  Lazaridis M  Skarzynski M  Sekhon W  Henderson D  Griesdale 

Baylor College of Medicine Erasmus Hospital Baylor College of Medicine Baylor College of Medicine Baylor College of Medicine Erasmus Hospital Erasmus Hospital Erasmus Hospital 
Intensive Care Medicine Experimental 2016, 4(Suppl 1):A391 Introduction In addition to systemic hemodynamics, the management of neurocritically ill patients is often informed by neuromonitoring. In the absence of high-level evidence clinicians are often guided by personal and local expertise. Little is known about practices as they pertain to the use of such monitoring in patients with acute brain injury (ABI). Objectives To investigate practices in bedside monitoring for ABI patients. Particularly interested in differences among "neurointensivists" (NIs; defined here as intensivists whose clinical practice is comprised > 1/3 by neurocritical care) and other intensivists (OIs). Also, to explore patterns specific to traumatic brain injury (TBI) and subarachnoid hemorrhage (SAH), as well as preferences and availability of particular technologies/devices. Methods Electronic survey of 22 items including two case-based scenarios; endorsed by SCCM (9,000 recipients) and ESICM (on-line newsletter) in 2013. A sample size of 370 was calculated based on a population of 10,000 physician members, a 5 % margin error, and 95 % confidence interval. We summarized results using descriptive statistics (proportions with 95 % confidence intervals). A chi-square test was used to compare proportions of responses between NIs and OIs with a significance p < 0.05. There were 655 responders (66 % completion rate); 422(65 %) were classified as OIs and 226(35 %) as NIs. More NIs follow hemodynamic protocols for neurocritically-ill patients (56 % vs. 43 %, p 0.001), in TBI (44.5 % vs. 33.3 %, p 0.007), and in SAH (38.1 % vs. 21.3 %, p < 000.1). For delayed cerebral ischemia (DCI), more NIs target cardiac index (CI) (35 % vs. 21 %, p 0.0001), and fluid responsiveness (62 % vs. 53 %, p 0.03), use more bedside ultrasound (BUS) (42 % vs. 29 %, p 0.005) and arterial waveform analysis (40 % vs. 29 %, p 0.02). For DCI neuromonitoring, NIs use more angiography (57 % vs. 43 %, p 0.004), TCD (46 % vs. 38 %, p 0.0001), and CTP (32 % vs.16 %, p 0.0001). For CPP optimization in TBI, NIs use more arterial waveform analysis (45 % vs. 35 %, p 0.019), and BUS (37 % vs. 27.7 %, p 0.023), while more OIs monitor mixed venous oxygen saturation (54.1 % vs. 45 %, p 0.045). For TBI neuromonitoring, NIs use more PbtO 2 (28 % vs. 10 %, p 0.0001). In the case scenario of raised ICP/low PbtO 2 , most employ analgosedation (47 %) and osmotherapy (38 %). Fewer make use of preserved pressure reactivity, particularly OIs (vasopressor use 23 % vs. 34 %, p 0.014). Conclusions There is large heterogeneity in the use of monitoring protocols, variables, and technologies/devices. "Neurointensivists" not only employ more neuromonitoring but also more hemodynamic monitoring in patients with acute brain injury. ICP/CPP remain the most commonly followed neuro-variables in TBI patients, with low use of other brain-physiology parameters, suggesting that clinicians make limited efforts to individualize these goals. A prospective observational pilot study of cerebral autoregulation measured by near infrared spectroscopy (NIRS) in patients with septic shock Introduction Impairment of cerebral autoregulation has been proposed as a possible explanation of cognitive dysfunction in patients with septic shock. Although transcranial Doppler has previously been used to assess cerebral autoregulation, this technology can only evaluate at single points in time. In contrast, near-infrared spectroscopy offers continuous assessment of cerebral autoregulation. Objectives Assess cerebral autoregulation using NIRS in patients admitted to the intensive care unit with septic shock. Methods We included 20 patients admitted with septic shock admitted to the intensive care unit (ICU) at Vancouver General Hospital (VGH). The ICU is a 31-bed mixed medical-surgical unit affiliated with the University of British Columbia. We excluded patients with acute or chronic neurological disorders, end stage liver disease, long-term dialysis, and those admitted following a cardiac arrest. We measured regional cerebral oximetry (rSO2) by NIRS (INVOS®, Covidien, Ireland) for 24 hours. NIRS and mean arterial pressure (MAP) data were collected in real time using ICM + ® brain monitoring software (Cambridge University, UK). ICM+ calculates a moving Pearson correlation coefficient (COx) between 30 consecutive, 10 second average MAP and rSO2 values. Impaired cerebral autoregulation was defined as a COx greater than 0.3. We also defined the impaired autoregulation index (IARindex) as the percentage of monitoring time spent with an impaired autoregulation. The IARindex was calculated for each 6 Introduction Patients with a traumatic brain injury (TBI) remain in hospital for extended periods. It is likely that muscle mass in these patients diminishes over the hospital admission, yet this has not previously been quantified. Ultrasonography may provide a useful measure of changes in muscle size over the hospital stay. Objectives To quantify changes in ultrasound-derived quadriceps muscle layer thickness (QMLT) and establish the feasibility of repeated ultrasound examinations throughout the entire hospitalisation of patients with a TBI. Methods Adult patients with a moderate-severe TBI (Glasgow Coma Scale 3-12) consecutively admitted to the intensive care unit (ICU) at a single trauma referral centre over 12 months were eligible following informed consent. Ultrasounds of QMLT at the midpoint and two-thirds between the anterior superior iliac spine and top of the patella were conducted weekly during admission. Data were censored at 3-months and are mean (SD) unless otherwise stated. Results Thirty-three patients [45. 4 (16.6) years; 88 % male; 55 % severe TBI; Trauma Injury Severity Score 0.5 (0.3); median APACHE II 18 (IQR: 14-22); admission body mass index 27.2 (6.5) kg/m 2 ] were studied. Primary injury cause was vehicular (58 %) and 67 % of TBIs were multi-trauma. Median length of ICU and ward-based stay was 13.4 [IQR: 6.5-17.9] and 31. 8 [9.4-52.4 ] days, respectively. At 3-months all patients were alive and four remained in hospital. A total of 123 ultrasounds were taken; 30 (24 %) in ICU and 93 (76 %) on the acute ward, equal to 3.7 ultrasounds per patient. Ultrasounds were not possible at 21 % of time-points in hospital due to patient agitation and 61 % at 3-month follow-up due to inability to attend appointment in person. Twenty-eight (85 %) patients had >1 ultrasound taken during their admission, for which the mean baseline measure was 1.78 (0.72) cm and within patient standard deviation 0.3 cm. Nineteen patients (58 %) had >2 ultrasounds during the hospital admission with a baseline measure of 1.78 (0.68) and proximate measure to discharge of 1.53 (0.52) cm. There was a 6. Conclusions This is the first study to describe longitudinal change in muscle size over the hospital admission in patients with a moderatesevere TBI. Whilst technically feasible, issues with compliance and missing data and intra-individual variation between measurements are challenges when conducting regular ultrasound measures in this population. Muscle thickness reduced throughout hospitalisation, but improved towards baseline by 3-months. Acute impairment of saccadic eye movement is associated with cerebral infarction after aneurysmal subarachnoid haemorrhage M.J. Rowland 1,2 , P. Garry 1,2 , J. Westbrook 1,2 , R. Corkill 2 , C.A. Antoniades 1,2 , K.T. Pattinson 1, 2 Introduction Cerebral infarction due to delayed cerebral ischaemia (DCI) remains a significant cause of morbidity and mortality following aneurysmal subarachnoid haemorrhage (SAH). Damage to the brain in the first 72 hours ("early brain injury") is likely to play a key pathophysiological role but remains difficult to quantify objectively and noninvasively at the bedside-especially in those patients who do not require sedation or ventilation. Current diagnostic modalities used in routine clinical practice are either invasive, require ionising radiation or contrast or have a high learning curve and user variability. Objectives We sought to determine whether saccadic eye movements are impaired following SAH and whether measurement of saccadic latency (SL) in the acute period post-aneurysm rupture is associated with the likelihood of developing DCI in patients after SAH. Methods 24 male/female patients (mean age 53.32, range 31-70) with World Federation of Neurosurgeons (WFNS) grade I and II aneurysmal SAH, treated endovascularly within 72 hours of rupture were recruited. DCI and DCI-related cerebral infarction were defined as per consensus guidelines. 1 Saccadometry data was collected at three time points: in the first 72 hours, between days 5 and 10 and at three months post-SAH. Data from 10 healthy age/gender matched controls was collected on one occasion for comparison. Results Age-adjusted median SL in patients was significantly prolonged in the first 72 hours post-SAH when compared to controls (188.7, 95 % CI = (176.9, 202.2)ms v 160.7, 95 % CI = (145.6, 179.4)ms, p = 0.0054 t-test). By 3 months post-SAH, there was no significant difference in median SL compared to controls (188.7, 95 % CI = (176.9, 202.2)ms v 180.0, 95 % CI = (165. 1, 197.8) ms, p = 0.4175 t-test). Patients diagnosed with cerebral infarction due to DCI had a significantly higher age-adjusted median SL in the first 72 hours than those without infarction (240. 6 Introduction Spreading depolarisations (SD) occur spontaneously in ischaemic cortex and are implicated in the evolution of the ischaemic penumbra. Subsequent enlargement of the ischaemic lesion causes worse neurological outcomes. Monitoring for SDs is solely performed through invasive electrocorticography (ECoG) which is located when a patient requires emergency surgery. SDs can cause significant haemodynamic changes which may be amenable to non-invasive monitoring. Objectives This study seeks to develop such a technique using nearinfrared spectroscopy (NIRS). NIRS allows surrogate measure of cerebral blood flow by inferring changes in the concentration of oxyhaemoglobin and deoxyhaemoglobin. Methods 5 ischaemic brain injury patients requiring emergency neurosurgery (4 retrospective, 1 prospective) recruited to the COSBID study at King's College Hospital (and monitored with ECoG) underwent concomitant NIRS monitoring. The NIRS data was analysed for significant haemodynamic response to SDs. Results In total, three ECoG-confirmed SDs occurred during NIRS monitoring, each in a different patient. Two acute (one minute) hypoperfusion responses were seen after an SD in one patient. One acute (one minute) hyperperfusion response was seen after an SD in one patient. Three subacute (20 minute) hypoperfusion responses were seen across two patients. Conclusion This preliminary data is promising that NIRS can be used to assess the haemodynamic responses secondary to SDs. More data is required so that the responses can be characterised adequately which could lead to a novel non-invasive monitoring technique. Predicting intracranial pressure and brain tissue oxygen crises in patients with severe traumatic brain injury R.B. Myers 1 , C. Lazaridis 2 Introduction Two central physiologic targets in the management of severe traumatic brain injury (TBI) are the intracranial pressure (ICP) and the partial brain tissue oxygen tension (PbtO 2 ). Intracranial pressure and PbtO 2 thresholds are incorporated into step-tiered clinical protocols and guidelines however by the time treatment is provided, it may be too late. The ability to predict the onset of these "crisis" events would potentially provide clinicians with valuable time to attempt aborting the episode and/or to appropriately manage it. Combining statistical machine learning with physiologic and clinical insight allows the construction of robust quantitative models to predict future events such as elevated ICP or low PbtO 2. Such models provide targets for evidence-based individualized treatment in real time. Objectives Develop computer algorithms that can recognize physiologic patterns in TBI patients that occur in advance of intracranial pressure ICP and PbtO 2 crises. The automated early detection of crisis precursors can provide clinicians with time to intervene in order to prevent or mitigate secondary brain injury. Methods A retrospective study was conducted from prospectively collected physiologic data. Intracranial pressure and PbtO 2 crisis events were defined as ICP ≥ 20 mmHg lasting at least 15 minutes and PbtO 2 values < 10 mmHg for at least 10 minutes, respectively. The physiologic data preceding each crisis event were used to identify precursors associated with crisis onset. Multivariate classification models were applied to recorded data in 30-minute epochs of time to predict crises between 15 and 360 minutes in the future. Our cohort consisted of 817 severe TBI subjects admitted to the neurosurgical intensive care unit of Ben Taub General Hospital in Houston, Texas. Results Our algorithm can predict the onset of an ICP crisis with 30 minutes advance warning and an AUC of 0.86 using only ICP measurements and time since last crisis. An analogous algorithm can predict the start of PbtO 2 crises with 30 minutes advanced warning and an AUC of 0.91. Conclusions We report here novel algorithms that provide accurate and timely predictions of intracranial hypertension and tissue hypoxia crises in patients with severe TBI. Almost all of the information needed to predict the onset of these events is contained within the signal of interest and the time since last crisis. These predictive algorithms offer clinicians the opportunity to prepare and potentially prevent secondary brain injury insults. Supported by a training fellowship from the Keck Center of the Gulf Coast Consortia, on Rice University´s NLM Training Program in Biomedical Informatics (grant number T15LM007093) and by the NSF under grant number 0964526. Continuous EEG was measured during the first three days. EEGs were visually classified as unfavorable (isoelectric, low-voltage, burst-suppression-with-identical-bursts), intermediate, or favorable (continuous patterns), at 12, 24, 48, and 72 hours by two reviewers, independently. Outcome was dichotomized as good (CPC score 1 or 2) or poor (CPC score 3, 4, or 5) at six months. EEG parameters were related to outcome using logistic regression analysis. Costeffectiveness in the hospital is currently estimated by decision tree analysis. Results Poor outcome occurred 54 % of included patients. Single parameters unequivocally predicting poor outcome in the first 277 patients were an unfavorable EEG pattern at 24 hours, absent pupillary light responses at 48 hours, and absent SSEPs at 72 hours. Together, these had a specificity of 100 % and a sensitivity of 50 %. Favorable EEG patterns at 12 hours were strongly associated with good outcome. EEG beyond 24 hours had no additional predictive value. For the remaining 155 patients, EEG analyses are ongoing. Data on cost-effectiveness, based on the assumption of EEG based treatment discontinuation, will be presented. Conclusions EEG within 24 hours is a robust contributor to prediction of poor or good outcome and should be included in guidelines for treatment of comatose patients after cardiac arrest. Introduction Mechanisms of early brain injury (EBI) following aneurysmal subarachnoid hemorrhage (SAH) are poorly understood. Using brain perfusion CT (pCT) and cerebral microdialysis (CMD), we examined the relationship of cerebral energy metabolism with brain perfusion during the EBI phase after SAH in humans. Methods Prospective observational cohort of poor-grade SAH patients monitored with cerebral microdialysis (CMD) who were resuscitated according to current guidelines. Data from brain pCT (performed 44 ± 25 hrs from ictus) were matched to CMD epochs displaying cerebral energy dysfunction, defined by a CMD lactate/pyruvate ratio > 40 and/or lactate > 4 mmol/L. Results A total of 19 pCT and 127 hours of CMD samples (15 patients) were analyzed. The majority (14/19) of pCT were associated with cerebral energy dysfunction, despite main cerebral physiologic variables were within normal range (intracranial pressure 14.2 ± 7.2 mmHg, PbtO 2 25 ± 10 mmHg). Energy dysfunction was associated with simultaneous normal (n = 9; 28-65 mL/100 g/min) or hyperemic cerebral blood flow (n = 5; 69-85 mL/100 g/min). Energy dysfunction also correlated with concomitant pathological elevations of glutamate and glycerol, that were more pronounced in hyperemic than normal pCT (LPR 54 ± 12 vs. 42 ± 7 and glycerol 157 ± 76 vs. 95 ± 41 μmol/L, both p < 0.01; glutamate 38 ± 52 vs. 26 ± 24 μmol/L, p = 0.18, t-test for comparisons between groups). Conclusions EBI after SAH is associated with profound cerebral metabolic and cellular distress, despite normal-hyperemic brain perfusion. Our findings reveal alternative pathophysiological mechanisms to ischemia in the EBI phase of SAH in humans and support therapeutic strategies targeted to energy dysfunction in this setting. Introduction Raised intracranial pressure is a common manifestation of severe brain injury. Rapid diagnosis and timely intervention is required to prevent secondary brain damage and death.An accurate, reliable, noninvasive, point-of-care monitoring device to identify presence of intracranial hypertension would be helpful in situations where there is clinical suspicion for intracranial hypertension. Bedside ocular ultrasound is an emerging noninvasive technique to measure optic nerve sheath diameter. Knowledge of the normal range of optic nerve sheath diameter in a healthy population is essential to interpret this measurement as a marker of raised intracranial pressure in clinical practice. Objectives To evaluate normal optic nerve sheath diameter in healthy volunteers in Pakistan. Methods Hundred healthy volunteers of Pakistani origin, aged more than 18 years were recruited in the study. The ultrasound probe was placed on the superior and lateral aspect of the orbit against the upper eyelid with the eye closed. For each subject, the primary investigator performed three measurements on each eye. The measurements of each eye were then averaged to yield a mean optic nerve sheath diameter (ONSD). Results are presented as mean ± standard deviation (SD). Statistical analysis was performed with SPSS software version 19. Mann Whitney U test was used to compare unpaired variables between genders and Wilcoxon matched pairs signed rank test to compare left and right eyes. Results The median ONSD of right eye was 4.84 mm and 95 % of individuals had mean ONSD in the range 4.84-4.97 mm while the median ONSD of left eye was 4.86 mm and 95 % of individuals had mean ONSD in the range 4.85-4.96 mm. There was no difference among the 3 repeated measures of ONSD in each eye. There was no relationship between ONSD with age, gender and measurement taken between left and right eyes. Conclusions 95 % of healthy Pakistani adults have an ONSD less than 4.82 mm. ONSD more than 4.82 mm in this population should be considered abnormal and may reflect raised intracranial pressure. Note: This abstract has been previously published and is available at [3] . It is included here as a complete record of the abstracts from the conference. Introduction Autonomic control and cerebral autoregulation (CAR) may be disturbed after traumatic brain injury (TBI) and become severely impaired due to intracranial hypertension (IH). Decompressive craniectomy (DC) after TBI is a tiered therapy for patients with IH, but the links between autonomic derangement, intracranial pressure (ICP), impaired cerebral autoregulation and outcome remain poorly explored. Objectives We aimed to evaluate the relationship between heart rate variability (HRV), as a surrogate of autonomic control, ICP and CAR before and after DC. Methods We retrospectively studied 9 adult TBI patients, admitted to the Neurocritical Care Unit at Hospital São João, Porto that were submitted to primary or secondary DC and had completed monitoring records 12 h before and 24 h after surgery. Patients were monitored with continuous ECG, ICP, cerebral perfusion pressure, cerebral autoregulation with pressure reactivity and pressure-volume compensatory reserve index (RAP). Automatic delineation of ECG signal was performed using a wavelet-based approach and HRV analysis in time and frequency domain was done according to the guidelines for both periods selected. Results A total of 48 consecutive TBI patients submitted to DC were screened, but we had to exclude 39 patients because of incomplete monitoring data. The median age was 27 (IQR13), 7 were men, median GCS was 6 (IQR3), median GOS was 4 (IQR2) and hospital mortality was 22 %. DC led to a significantly decrease in ICP maximum value (p = 0.011), CPP (p = 0.038) and RAP (p = 0.008) after surgery. There were no significant differences between values of PRx and HRV variables both in time and frequency domain. However, we found statistically significant correlations between HRV nonparametric variables and multimodal brain monitoring variables (Fig. 2) . Before DC normalized low frequency (LFn), high frequency (HFn) and LF/HF ratio are positively correlated with ICP maximum (ICPmax) value, (respectively Rs = 0.5,p = 0.000; Rs = 0.3,p = 0.005;Rs = 0.4,p = 0.0001). After DC the correlation becomes negative but non-significant. Total power (Tp) has a positive and significant correlation with CPP before DC (Rs = 0.5,p = 0.000). RAP is negatively correlated with Tp and HF after DC (Rs = −0.4,p = 0.000;Rs = −0.5,p = 0.000). PRx increases after DC and we could not find any important correlation with HRV. Conclusions Further studies are warranted to better understand the brain changes and autonomic distress associated with high intracranial pressure and decompressive craniectomy. Introduction: The idea of a non-invasive method of measuring intracranial pressure (ICP) is captivating, as disadvantages seen in relation to the invasive methods of ICP measuring, that is, hemorrhage, infection, and costly expenses are avoidable. Objectives: Determine the value of ultrasonographic transcranial Doppler (TCD) and optic nerve sheath diameter(ONSD)in assessing increased ICP and outcome of moderate to severe traumatic brain injury patients. Methods: 40 patients with moderate to severe traumatic brain injury(GCS ≤ 13) admitted to a university teaching hospital were enrolled. ONSD and TCD measurements were performed daily for 7 days. TCD was performed on both middle cerebral arteries(MCA), recording peak systolic (sFV), end diastolic(dFV)and mean timeaveraged(mFV)blood flow velocities in cm/s. The Gosling and King's pulsatility index(PI) was calculated:PI = sFV-dFV/mFV. Marshall and Rotterdam head CT neuroimaging scales were recorded on admission, 48 hours and 5 to 7 days later. Glasgow Outcome Scale(GOS)was assessed six months after discharge for survivors. Results: The PI significantly increased in days 2 and 3 then it showed a non-significant decrease in day 4 and 5, all compared to baseline value. This was followed by a significant decrease in days 6 and 7. Comparing the PI's daily reading with the previous day was significant, increasing from day 1 to day 2, and from day 2 to day 3 then decreasing from day 3 till day 7(p < 0.001). The PI showed a significant direct correlation the Marshall and Rotterdam Scales on days 3 and 7, and Rotterdam Scale on day 7. A significant direct correlation was demonstrated between the ICU LOS and the PI determined on days 4 to7. No significant correlation was found between the mean ONSD and the PI measured on days 1 to 5, but a significant direct correlation was demonstrated between the two parameters on day 6 and day 7. The sFV, dFV and mFV were significantly higher on days 2 to 4 in survivors than in non-survivors. While the PI on day 2 and 3 was significantly lower in survivors than in non-survivors. On day 2, a mFV of ≤27.31 cm/sec was 94.44 % accurate in detecting non-survivors. On day 3, a mFV of ≤6.62 cm/sec was 100 % accurate in detecting non-survivors. On day 2, a PI of >1.26 was 89.47 % accurate in detecting nonsurvivors. On day 3, a PI of >1.87 was 100 % accurate in detecting non-survivors. Conclusions: There was a significant day-to-day changes in the ONSD and PI in TBI patients making serial estimation of clinically/ radiologically diagnosed raised ICP possible in the absence of invasive ICP measurement.The correlation between PI and CT imaging of the head together with its cost-effectiveness, safety to the patient and permanent availability makes the sonographic approach highly beneficial. TCD derived parameters predicted survival in TBI patients.TCD derived PI correlated directly with ICU length of stay. Introduction: Veno-arterial extracorporeal membrane oxygenation (VA-ECMO) is increasingly used to treat severe cardio-pulmonary failure. Among the possible complications, central nervous system (CNS) events, such as stroke or hemorrhage, are associated with long-term neurologic morbidity and increased mortality. Additionally, peripheral VA-ECMO can result in delivery of hypoxic blood to the brain. The use of cerebral near-infrared spectroscopy (NIRS) can detect cerebral hypoperfusion non-invasively. Methods: We reviewed our institutional VA-ECMO database (n = 159) from November 2008 to December 2015 and identified those patients who were monitored with cerebral NIRS. Sensors were placed on the patients´foreheads using the Foresight device (CAS Medical Systems, Inc, Branford, USA). Regional saturation (rSO2) was recorded and analysed by calculating the time below different thresholds (60 %, 55 % and 50 %). Results: A total of 39 patients (age: 54 [48-72] years) had cerebral NIRS monitoring during VA-ECMO for cardiogenic shock (n = 19), refractory cardiac arrest (n = 14) and post heart/lung transplantation (n = 6). ECMO was applied for 6 [3] [4] [5] [6] [7] [8] [9] [10] days and NIRS monitoring for 3 [2] [3] [4] days. Nine (23 %) patients developed an ischemic stroke (8/9 in the anterior circulation) and 6 (15 %) differential hypoxia -lower PaO2 in the upper body than in the lower body, because of normal cardiac output with severe impairment of pulmonary function-during the first 3 days of monitoring. Hospital mortality was 22/39 (56 %). Twenty-seven (69 %) patients had a drop of rSO2 < 60 % for at least 5 % of the NIRS monitoring period, resulting in hemodynamic interventions, which involved increasing pressure, oxygenation, and/or ECMO flow. In the 3/6 patients with differential hypoxia, these interventions were unsuccessful and a veno-arterial-venous ECMO was implemented. Patients developing ischemic stroke had a higher differential right-left rSO2 (11 [6] [7] [8] [9] [10] [11] [12] % vs. 6 [4] [5] [6] [7] %; p = 0.004) than others. Survivors had a shorter rSO2 time < 60 % than non-survivors (6.6[1.2-24.5]% vs. 43 [12-60]%; p = 0.007). Conclusions: Cerebral NIRS monitoring may be helpful in patients undergoing VA-ECMO to detect cerebrovascular events or brain hypoperfusion/reduced oxygen delivery. In these patients cerebral hypoperfusion is associated with a poor outcome. Introduction: Although it has been demonstrated previously that patients with aneurysmal subarachnoid hemorrhage (aSAH) may also experience neurocardiac injury, the impact of this complication on cerebral and peripheral tissue perfusion is not well understood. Objectives: We aimed to determine if neurocardiac injury as defined by increased levels of cardiac troponin I (cTnI) was associated with changes in regional cerebral (CrSO 2 ) and peripheral (PrSO 2 ) tissue oxygen saturation as measured with continuous near-infrared spectroscopy (NIRS) across days 1-3 after aSAH. Methods: Longitudinal prospective analysis of 13 patients with aSAH. Inclusion criteria: age 21-75 years, spontaneous aneurysm rupture, Fisher grade >1 and/or Hunt and Hess grade >2, and with NIRS data. Exclusion: traumatic SAH, and recent myocardial dysfunction. cTnI was measured at least daily. Continuous non-invasive CrSO 2 and PrSO 2 commenced immediately following study enrollment. CrSO 2 was acquired utilizing two separate sensors affixed to the left and right forehead, while PrSO 2 was obtained utilizing a single sensor attached to either the left or right thenar eminence. Continuous CrSO 2 and PrSO 2 values were recorded every 5 milliseconds and then averaged on hourly intervals for statistical analyses. The daily peak values of cTnI were used in the analysis as a time-varying variable. The hourly averaged CrSO 2 and PrSO 2 values were also treated as time varying variables. Generalized estimating equation (GEE) was used to evaluate the association between cTnI and both right and left CrSO2, as well as PrSO 2 , where cTnI was used as the independent variable and CrSO 2/ PrSO 2 as dependent variables, while controlling for age and gender. Results: The 13 patients in the analysis had a mean age of 56.6 years, SD = 8.9, and were predominantly female (85 %). The GEE modeling revealed that higher peak cTnI was significantly associated with lower PrSO 2 and higher left-sided CrSO 2 . Higher cTnI was also associated with a trend toward lower CrSO 2 on the right side, but that was not statistically significant (Fig. 7) . Conclusions: Neurocardiac injury after aSAH as defined by higher levels of cTnI is associated with impaired peripheral perfusion, but its impact on cerebral perfusion is variable. Further investigation in a larger sample is needed to see if site of the aneurysm, cerebral vascular autoregulation, or vasospasm may play a role. Grant acknowledgment NIH R01NR014221 Study of the incidence of convulsive and non-convulsive seizures in the acute phase of ischemic cerebrovascular stroke S.A. Abdelmonem 1 , S.A. Tahon 2 , T.A. Helmy 1 , H.S. Meligy 1 Introduction: Sepsis is associated with immune suppression, including depressed cellular immunity. A decrease in surveillance by immune cells could be one of the mechanisms explaining the growing perception that patients surviving sepsis are at increased risk of developing cancers. However, other mechanisms may be involved in this increased rate of tumors in sepsis survivors, involving humoral factors. Sepsis is also associated with marked up-or down-regulation of various soluble mediators affecting cell growth. We hypothesized that some of these mediators may promote the proliferation of tumors. Objective: To identify and isolate this (those) plasma factor(s) enhancing tumor cell growth. Methods: Heparinized human blood samples were collected from patients with septic shock and in healthy donors. Human adenocarcinoma epithelial cells from lung (A549), colon (SW620), breast (Hs578T), and liver (HepG2) and human monocytic leukemia cells (THP-1 and HL-60) were grown to 70 % confluence and incubated with 5 -15 % septic or healthy plasma, or control media. After 24 hours, cell proliferation was evaluated by MTT Cell Proliferation Assay. Septic and healthy plasma fractionation was performed using classical biochemical techniques. Results: Septic plasma supported significantly higher epithelial cell proliferation than plasma from healthy subjects (+48 % in A549, +59 % in SW620, +41 % in Hs578T, and +29 % in HepG2 cells with 15 % plasma). Interestingly, this effect was not observed in tumoral cells of monocytic origin. Adding healthy plasma to septic plasma decreased the tumor epithelial cell proliferation effect seen with septic plasma alone in a dose-dependent manner. Initial plasma fractionation studies suggest that the proliferation factor(s) in septic plasma remains in an immunoglobulin-and albumin-free plasma fraction, is(are) not precipitable by 50 % ammonium sulfate, and is(are) a trypsin-sensitive protein(s) > 50 kDa. The identification of such plasma protein(s) affecting tumor cell growth could be of great interest in the fields of sepsis and cancer biology. Introduction: In immunocompromised patients, acute respiratory failure (ARF) is associated with high mortality [1] and many studies have confirmed the utility of prolonged non invasive ventilation (NIV) in such condition. Lately High Flow Nasal Cannula (HFNC) has been used in ARF in various patient subsets but not specifically in post transplant patients. Objectives: To compare HFNC vs NIV as the modality to manage ARF in postoperative hypoxemia in post liver transplant patients. Methods: This was a pilot study conducted in a Liver Transplant intensive care unit (ICU) of a tertiary care hospital in India. We randomly assigned 20 consecutive post transplant patients who developed respiratory failure in the post-operative period to either HFNC group (n = 10) or to NIV group (n = 10). The HFNC was initiated at a flow rate of 60 l/min whereas NIV was set at EPAP of 5 cm and IPAP at 10 cm. Both the device setting and oxygen titration was done according to arterial blood gas (ABG) analysis. Apart from ABG analysis, we assessed the COMFORT scale as well as the RASS and CAM-ICU scale of the patient and also assessed the total nutritional deficit at the end of 48-hr therapy duration. The need for invasive mechanical ventilation (IMV) was also noted for both the groups. Results: None of the patients in the HFNC group required need for IMV whereas 2 patients in NIV group had to be intubated. Patients in the HFNC group had better average PaO2 as compared to NIV (98.2 vs 72.6 mm Hg) respectively. The patients in the NIV group received more sedation with dexmedetomidine as compared to HFNC group (22 vs 10 hrs) respectively. The patients in the HFNC group were more comfortable as compared to NIV group and two patients in the NIV group developed delirium for which they required IMV. The average RASS score was 0 to +1 in the HFNC group whereas it ranged from −2 to +2 in the NIV group. All patients were fed either orally or enterally but the NIV group consumed less feeding due to the inability to feed orally and apprehension of aspiration due to aerophagia when fed enterally. The NIV group received 52 % less calories as compared to HFNC group in 48-hr period. Conclusions: HFNC is may be an excellent armamentarium for managing hyperemic respiratory failure in immunocompromised patients with reduced risk of intubation, more comfortable to the patients and little interruption in providing adequate nutrition. Introduction: Intravenous glutamine can have beneficial effects on critically ill patients by preserving gut barrier and improving immune function. Objectives: We wanted to prove the benefit of intravenous glutamine in patients admitted to medical intensive care unit (MICU) with severe sepsis and receiving enteral nutrition. Methods: Randomized, single center, double -blind, placebo-controlled, pilot study on patients admitted to the MICU who met the criteria for severe sepsis. In the intervention arm, intravenous glutamine was given for 5 days at a dose of 0.5 g/kg body weight/day. All patients were fed enterally as per the MICU feeding protocol. The primary outcomes were 28-day mortality and the occurrence of new infections. We also looked at severity scores (SOFA), ICU length of stay (LOS), hospital LOS and duration of mechanical ventilation. Results: Thirty nine patients were randomized to receive glutamine (n = 19) or placebo (n = 20). The glutamine group had less disease severity than placebo (median SOFA score 8 versus 11, p =0.038). There was no difference in 28-day mortality between the glutamine and placebo groups (42 % vs 15 %, p = 0.06). When adjusted for disease severity, the glutamine arm had 5.6 times higher death rates ( Introduction: Central-Line-Associated Bloodstream Infections (CLABSI) have been studied extensively in ICU patients. There are no data in the literature regarding a potential association between obesity and CLABSI. Objectives: To test the hypothesis that CLABSI depends on the presence of obesity in critically ill patients. Methods: We conducted an 18-month observational study on 576 critically ill patients, in three general ICUs in Greece. All patients had inserted a triple-lumen catheter in a central vein (internal jugular, femoral or subclavian). Body Mass Index (BMI) was determined by a dietitian on ICU admission. BMI was categorized a priori as < 18.5 (underweight), 18.5-24.9 (normal weight), 25-29.9 (overweight), and >30 (obese). CLABSI was diagnosed by examining the catheter's tip and a blood sample. Multivariate logistic regression analysis was used to estimate the association between BMI groups and CLABSI. Conclusions: Obesity appears to be associated with the presence of CLABSI in critically ill patients. This could be partially attributed to the more efforts made by physicians to insert the catheter in the obese patients than the other patients. Introduction: Sepsis induces a hyperinflammatory phase with a concomitant immunosuppression that predominates after initial phase Introduction: The major reported causes of death within the first 30 days after lung transplantation (LT) are graft failure and non-CMV infections. Delay in starting effective antimicrobiological treatment in case of infections is associated with worse outcome. It is imperative to diagnose the presence of infectious complications after LT in a timely fashion. Biomarkers have been proposed as a tool to improve early diagnosis of infections in this population. Objectives: To determine how sequential measurements of PCT and CRP could improve the diagnosis of early infectious complications after LT. Methods: Multicentre prospective observational study between September 2014 and September 2015. The study included all 7 centres authorized to perform lung transplantation in Spain.Biomarker measurements were executed on ICU admission (day 1) and daily till 7th postoperative day. Patients were split into two groups depending on the presence of infectious complications. Results: Two hundred and thirty three consecutive patients (148 men, median age 56 [range 47 to 61] years) underwent single (n = 108, 46.4 %) or bilateral (n = 125, 53.6 %) LT. In the whole population, both biomarkers, PCT and CRP, presented similar kinetics during study period with an initial increase in their levels, a plasma peak recorded in the first 48 hours and a progressive decline over the next days. PCT plasma levels were similar for PGD grades 1 and 2 and increased significantly in the group of patients with PGD grade 3. CRP levels were similar in all groups. The median PCT levels were significantly lower in patients without infection than in patients with 'Infection' for all days of follow up ( Table 2 ). During the first 5 postoperative days (day 0 to day 4), PCT levels beyond median value were statistically associated with higher risk of infection. Thus, PCT levels beyond 0.50 ng/ml on ICU admission or 1.17 ng/ml on postoperative day 1 were associated with an increase in risk of infection of two-fold and three-fold respectively. Associations remain significant after adjusting by sex, age, need of postoperative ECMO, creatinine levels and type of lung transplant. However, after stratifying by primary graft dysfunction presentation these associations disappeared with respect to the group of patients with PGD 3 and increased in the NO PGD 3 group.Therefore, in the absence of PGD 3, previously described cut-off levels for day 0 and day 1 were significantly associated with an increase of three-fold and four-fold in the risk of infection development. Conclusions: In absence of severe PGD, PCT peak levels are predictor of infectious complications development during the first postoperative week. PGD grade 3 produce an important increase of PCT levels and interfere with PCT infectious diagnosis ability. PCT was superior to CRP in infections diagnosis during this period. Introduction: The development of neuropsychological dysfunction in survivors of critical care has been widely documented in the literature (1) . In contrast, the impact on patient outcomes of anxiety and depression at the time of critical care admission has been less well documented (2) . Objectives: We conducted a pilot study to determine the feasibility of assessing critical care patients' anxiety and depression during their admission and the potential impact of these morbidities on patient outcomes. Methods: Patients were recruited following admission to a general intensive care unit post surgical intervention. Patients had a Hospital Anxiety and Depression Scale (HADS) assessment on day 7 and day 15 post operatively, In addition demographic (gender, age, elective vs emergency surgery, cancer vs non-cancer surgery, prior antidepressant use), intervention and outcome (length of stay, infection, additional oxygen requirement, in-dwelling catheter in situ) data was collected. Results: One hundred and twenty two patients were recruited to the study and 69 (56.6 %) had a HADS assessment on day 7. Amongst the 52 patients that did not have a HADS assessment completed, 27 (52 %) were discharged prior to day 7 and 16 (31 %) either refused or were not appropriate for assessment. The completed HADS assessments indicated that 29 % and 30 % of patients had significant anxiety and depression scores respectively. Increased day 7 median anxiety scores were associated with female gender (6 vs 4, P = 0.04), anti-depressant use (8 vs 5, P = 0.01), oxygen requirement (9 vs 5, P = 0.049), infection (7 vs 4, P = 0.05) and urinary catheter use (8 vs 4, P = 0.04). Increased median depression scores were associated with female gender (7 vs 5, P = 0.04) and hospital stay longer than 14 days (7 vs 5, P = 0.007). Twenty-four patients had a further HADS assessment on day 15, with 35 patients having been discharged from hospital in the intervening period. Based on Wilcoxon Signed Ranks tests, anxiety but not depression scores appeared to decrease during the patient's hospital stay (z = 2.03, P = 0.04 and z = 0.25, P = 0.8, respectively). Conclusions: The assessment of anxiety and depression amongst peri-operative critical care patients is feasible. Increased anxiety levels appear associated with a number of interventions. Increased depression scores appear associated with increased hospital length of stay. Anxiety but not depression levels appear to decrease over time during patients' hospital stays. Introduction: In the last decades, several methods have been developed for the noninvasive assessment of the level of consciousness during general anesthesia by processing physiological signals. The performance of the developed indices depends on a large number of factors such as the choice of the signal, the selected parameters, the inter-individual variability, etc. However, it is not clear how the type of the model that is used for the index development and calculation can affect its performances. Objectives: The objective of the study was to compare two electroencephalographic (EEG) derived depth of anesthesia indexes that were developed with two different models: an adaptive neuro-fuzzy inference system (qCON ANFIS) and a quadratic equation model (qCON QE). The models have the same inputs based on the energy on four EEG frequency bands. Methods: After IRB approval, 71 patients scheduled for elective surgery were randomized in four groups. Anesthesia was induced using effectsite controlled, target controlled infusion with effect size concentration of propofol set to 8.6, 5.9, 3.6 or 2 μg/mL while the corresponding remifentanil was set to 1, 2, 4 and 8 ng/mL respectively. Data were used from 2.5 minutes before to 11 minutes after starting pumps. Patients enrolled were adults from both genders with age 53 ± 13 years, weight 79 ± 14 kg and height 174 ± 9 cm (mean ± standard deviation). The EEG was recorded with qCON 2000 monitor (Quantium Medical, Barcelona, Spain) at a sampling frequency of 1024 Hz. The qCON ANFIS and qCON QE indices were calculated on one-second EEG windows. The agreement between the two anesthesia indexes was evaluated with correlation (R 2 ), prediction probability (Pk) and Bland Altman analysis by calculating the bias and the standard deviation (SD) of the differences between the two indexes. Limits of agreement were defined as the bias ± 1.96SD in which 95 % of the differences between the two indexes are expected to lie. It is considered a clinically acceptable level of agreement when two indexes would differ by less than 10 units. Results: Fig. 9 shows the density plot of qCON QE vs. qCON ANFIS. Table 3 shows the values of the R 2 and Pk between qCON ANFIS and qCON QE. Figure. 10 shows the results of the Bland Altman analysis of qCON ANFIS versus qCON QE. Conclusions: The two indexes qCON ANFIS and qCON QE that were developed with two different models showed a strong correlation (R 2 > 0.95, Pk > 0.95) and a good agreement (Bias < 1 and limits of agreement < 10). In conclusions, changing the model of the qCON calculation from a fuzzy based model to a quadratic equation do not affect the index performances in depth of anesthesia assessment, with the advantage of working with a quadratic model structure that has less coefficients than the fuzzy model. Introduction: Delirium occurs frequently in ICU patients and is associated with numerous adverse effects. Apart from the hyperactive, hypoactive and mixed subtype, recently the 'rapid reversible sedationrelated delirium' was described which disappears after discontinuing of sedatives and is thought to have different outcomes then regular hypoactive delirium. Apart from a burden for the patient, the presence of delirium may also increase the workload for ICU professionals. Typically, workload in the ICU is measured using the Simplified Therapeutic Intervention Scoring System (TISS-28). Objectives: To determine the effect of delirium status on ICU workload. Methods: A retrospective cohort study was performed at the ICU of a university medical center. All ICU patients admitted between December 2011 and July 2013 were classified for their delirium subtype status, using the CAM-ICU. Peterson criteria were used to distinguish between the delirium subtypes, added with Patel's criterion for rapid reversible sedation-related delirium. Demographics and other relevant data relating to ICU workload were collected. Results: A total of 3,926 ICU patients were admitted during the study period ( Table 4 ). The age was 62 ± 15 (mean ± SD), of which 64.6 % were male. The APACHE II score was 17 ± 7, and hospital mortality was 11.6 %. Patients were ventilated for median 2 [IQR 2-3] days. The LOS-ICU was median 1 [IQR 1-3] day, and in-hospital LOS was median 5 [IQR [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] days. In total 881 (22 %) patients were classified as delirious of which the alternating subtype had the highest incidence. Delirium duration was median 1 [IQR 1-2] day, the dose of haloperidol administered was median 19 [IQR 9-42] mg. The overall TISS-28 score was 28 ± 7. After adjusting for APACHE II score the TISS-28 score did not differ between delirious patients and nondelirious patients, (28.4 ± 6 versus 27.2 ± 8, respectively). In addition, no differences in TISS-28 score were found between the delirium subgroups. Patients with delirium stayed significantly longer on the mechanical ventilator, in the ICU and in-hospital (all p < 0.001). Conclusions: Severity of illness but not delirium contributes in a higher workload in ICU patients. Furthermore, there were no differences in subgroups of delirium regarding workload. Importantly, however, delirium does burden ICU patients in the ICU. Introduction: Continuous infusions of sedative analgesia prolong the duration of mechanical ventilation and increase the risk of complications. Numerous scoring systems exist that assess depth of sedation, with current guidelines supporting the use of the RASS (Richmond Agitation-Sedation Scale) [1] . Studies highlight that caring for more awake patients is more demanding and increases workload for healthcare staff [2, 3] ). A preliminary audit was undertaken on our General Intensive Care Unt (GICU) in 2014-2015 to identify whether patients were optimal sedated, as determined by RASS. Objectives: As a result of the previous audit three main areas for improvement were identified. 1. To achieve optimum levels of sedation as determined by RASS. 2. To achieve a gradual reduction in sedation to achieve spontaneous breathing on the ventilator at the earliest opportunity. 3. To achieve predictable and timely sedation holds. Methods: A´targeted RASS´tool was developed, which was simple, colour coded and kept at the patient bed-side. A protocol for gathering data from audited sedation days was developed. The protocol was instigated over a 5 week period from 4/1/2016 to 5/2/2016. All sedated patients were included, except for those having treatment withdrawn. On each patient, data was collected at the beginning and end of each shift. Including baseline and target RASS, times of RASS allocation made and sedation drug usage. Data was collated on a spreadsheet within the ICU. Results: Total number of admissions were 156 patients, total number of sedated, ventilated days were 46. 38 out of the 46 patients had targets set during ward rounds (82 %) There was no difficulty allocating patients to groups. 11 patients were allocated to RED which achieved 100 % compliance. 13 patients were allocated to AMBER which achieved 63 % compliance. Reduction in sedation drugs and RASS at the end of each shift was, on average, reduced. 14 patients were allocated to GREEN which achieved a 32 % compliance. Sedation drugs were largely stopped or reduced. On average the RASS was lower. Successful extubation occurred in 5 patients. Agitation leading to re-sedation occurred in 8 patients. Conclusion: A simple, clear and effective tool for communication between medical and nursing staff can improve practice and be translated into a real reduction in sedation drug administration and lower levels of sedation. Introduction: Delirium is common in Intensive Care Unit (ICU) patients and negatively affects outcome. However, recognition of delirium by ICU physicians is poor [1] . To improve detection, delirium screening tools have been developed, but these are subjective and insensitive in routine, daily practice [2] . Previously, we showed that patients with and without delirium could very well be distinguished with one minute of bipolar electroencephalography (EEG) and relative delta power as an indicator of slowing of background activity [3] . Based on these findings, a prototype EEG-based delirium monitor was built, with real-time artefact removal and an improved detection algorithm. Objectives: To validate an EEG-based delirium monitor in patients at risk of delirium. Methods: In this ongoing multicentre study, we will include 154 frail, surgical patients aged ≥60 years. Preoperatively (T-1) and on postoperative day 1 to 3 an EEG recording is performed together with a standardized cognitive assessment that is a video-taped. Diagnosis of delirium is based on the video by two, or in case of disagreement, three delirium experts (psychiatrists, geriatricians or neurologists) independent of each other, and independent of the EEG recording. EEGs are automatically analysed after artefact removal using waveform analyses, as well as analysis of relative delta power, and compared with the classification of the delirium experts (gold standard), to obtain sensitivity, specificity and the predictive values. Preliminary results: Among 45 patients (75 % men, mean age 76 years, SD 7 years), 5 patients were diagnosed as delirious. The figure shows the development of delirium in an example patient and the findings of the waveform analysis on the consecutive days after surgery. Sensitivity and specificity of the waveform-and relative delta power analyses were promising, and final results will be presented at the ESICM meeting. Conclusions: Our findings suggest that EEG-based monitoring is promising for objective and reliable detection of delirium in routine daily practice. Introduction: Delirium is a frequently occurring syndrome in patients admitted to the Intensive Care Unit (ICU) or Medium Care Unit (MCU), yet the pathophysiology remains poorly understood. An excess of central serotonin can lead to an altered mental status, associated with autonomic hyperactivity, and neuromuscular excitation. Methods: During a 10-week prospective observational cohort study in the ICU and MCU, patients aged 18 or older, diagnosed with delirium in the ICU or MCU were included. Patients were considered as delirious in case of a positive CAM-ICU and/or at the start of haloperidol prescription on suspicion of delirium. Once included, patients were screened for recent administered serotonergic drugs and screened for physical signs associated with serotonin toxicity by a standardized physical examination by a specifically trained physician. Results: A total of 61 patients diagnosed with delirium were enrolled. In 44 out of 61 patients (72,1 %) the use of drugs potentially contributing to serotonergic toxicity was recorded. Out of 44 patients, 7 (16 %) patients showed physical signs of serotonin toxicity and in addition met the Hunter serotonin toxicity criteria, suggesting the presence of serotonergic toxicity. None of these patients were recognized as such by the treating physicians. CONCLUSIONS: A significant proportion of delirious patients in the ICU might in fact be classified as suffering from central serotonin toxicity. The awareness of potential serotonin toxicity is low among physicians. Introduction: Delirium is defined as an acute cognitive impairment, inattention and disorganized thoughts, may be associated with the use of benzodiazepines, opioid administration, mechanical ventilation duration and immobilization, the management of it depends on multidisciplinary team strategies. Objective: The purpose of this study was to compare the results of patients with and without Delirium that were submitted to an early mobilization protocol in the Intensive Care Unit (ICU). Methods: Cohort study in the general ICU of a University Hospital, Southern Brazil. The study was conducted between February and December 2013. Were excluded patients using mechanical ventilation for less than 24 hours, under 18 years old, patients submitted to passive exercises or who did not have early mobilization. Only patients that received active and active-assisted early mobilization were included. Patients were divided between Delirium and no-Delirium groups. Data were reported as mean and standard deviation. The variables were compared through of Mann-Whitney test, t-test parametric and the statistical significance level was 5 % (p ≤ 0.05). Results: In the period were admitted 474 patients of which 127 were included. The incidence of Delirium was 48 %. The main causes of admission in groups with delirium and without delirium were medical nonneurological (34 % vs. 33 %), medical neurological (22 % vs. 9 %) and Traumatic Brain Injury (22 % vs. 26 %). There were no significant. The data are demonstrated in Tables 5 and 6 . Conclusion: In this cohort study, we found no differences in the outcomes of patients with or without delirium submitted to early active mobilization. Most of patients had good response to an early mobilization protocol. Introduction: Addiction is one of the main problems in our society, Iran,about 3 % of the whole population. Many of critically ill patients needing intensive care units (ICU)admission suffer from underlying disease such as ischemic heart disease, hypertension, diabetes and so on, and are opium addicted too. Consequently, the control of pain and agitation in the intensive care unit plays an important role in early discharge and improving patient´s outcome. Objectives: Comparing opium tincture and methadone on the control of pain, agitation, and ICU outcomes in opium addicted ICU admitted patients. Methods: In this randomized pilot study, a total of 50 inhalant opium addicted patients aged 18-84 years, enrolled into the study and they were divided into two groups of 25, the opium tincture(T) and methadone group (M) . Patients received morphine infusion according to needs before allowing enteral drugs (at most one day). After that(as day one of study), in the T group, patients received 10 cc opium tincture in dark tea(total 50 cc) through nasogastric (NGT) tube and 10 cc normal saline intravenously (IV) every 8 hours. The M group received 50 cc dark tea via NGT plus 10 mg mehadone diluting to 10 cc IV every 8 hours.Then patient´s pain and agitation were measured and compared based on (BPS) behavioral pain scale and Richmond agitation sedation scale (RASS), and delirium by CAM-ICU. If BPS scale was desirable (−0, 1), the same dose continued, but if it was ≤ −1 or ≥ 2, the doses was decreased or increased by 2.5 (cc or mg) respectively at next interval. Rescue medications were IV morphine, midazolam and haloperidol. Results: Current study shows that the use of opium tincture in the pain management(by BPS) of opium addicted ICU patients had significant desirable impact and, (p-value = 0.041) compared with methadone especially after deleting confounding variables (morphine, midazolam and haloperidol) (P-value = 0.019).But considering agitation (RASS) there was no difference before (p-value = 0.684) and after the deleting confounding variables (p-value = 0.630) between the two groups. Extubation time, duration of ICU and hospital stay was not different between the two groups. Objectives: We assessed the efficacy and safety of prolonged use of SEVO in a cohort of hemodynamically unstable critically ill patients under ECMO. Methods: Patients initially sedated with IV MIDA and/or PROP and then switched to SEVO, were retrospectively reviewed. The liquid form of SEVO was infused via a modified heat-moisture exchanger (AnaConDa®, Sedana Medical AB, Uppsala, Sweden) placed between the Y-piece and the endotracheal tube. SEVO was given as an initial bolus of 1.2 mL followed by a continuous infusion started at 5 mL/h. Infusion rate was adjusted to reach a measured end-tidal SEVO (ETS) concentration between 0.8 and 1.4 %. Sedation level aimed to obtain a RASS score of −3 to −4. Mean blood pressure and norepinephrine requirement were evaluated before start of SEVO and after respectively 2 h and 6 h of treatment. ETS was measured after stabilization, and at 24 h and 72 h. Wilcoxon signed rank test was used to compare variables over time. Values were expressed as means ± SD. Results: Twenty-one patients (12 males, age 53 ± 15 years; 16 ARDS and 5 cardiogenic shock) were studied. Mean APACHE II score was 25 ± 5. MIDA and PROP dose before start of SEVO were respectively 2.1 ± 2.6 mg/min and 2.4 ± 0.9 μg/kg/min. Ten patients were curarized. Initiation of SEVO allowed immediate cessation of IV sedation and curarization. Opioid analgesia was continued unchanged. SEVO treatment was not associated with changes in MAP (73 ± 12 vs. 72 ± 10 mmHg; p = 0.56) or norepinephrine need ( Introduction: Patients admitted to the intensive care unit (ICU) usually require use of hypnotics and sedatives to ensure comfort and proper adaptation to mechanical ventilation. An important requirement for an adequate sedation is frequent and proper assessment of its depth. Inadequate sedation can lead to problems of oversedation, under-sedation and/or delirium in ICU, especially in elderly patients. Objective: To compare the total dose of sedative use and the rate of over-sedation in patients over 65 years admitted to the ICU, adjusting sedation by monitoring with BIS® versus monitoring with the exclusive use of sedation scales. Methods: A randomized, clinical trial including patients over 65 years who were admitted to the ICU affected with medical or surgical pathology of non neurological etiology who required sedation for more than 24 hours to maintain adaptation to mechanical ventilation. Patients were randomized into two groups: the intervention group using BIS monitoring to adjust sedation in order to maintain values between 50-60 and; the control group in which sedation was adjusted with the exclusive use of Richmond Agitation-Sedation Scale (RASS) to maintain RASS −2. The study was approved by the institution's Research Ethics Committee. Statistical analysis: We used the chi square test to compare categorical data and proportions, and the T-test, Mann-Whitney test or Kruskal-Wallis, as appropriate, to compare continuous variables. An alpha level of 0.05 was used to determine statistical significance. All data in the present study was analyzed using SPSS version 22.0 (SPSS Inc, Chicago, USA). Results: Until now 56 patients have been randomized. 27 (48 %) patients in the control group and 29 (52 %) in the intervention group. Related to the general characteristics, demographics (age, weight, height, gender), medical history (hypertension, diabetes, cognitive impairment, lung disease and chronic renal failure), pathology and admission severity scores (APACHE II and SOFA) there were not statistically significant differences between groups. Besides analgesia; midazolam, propofol or remifentanil were also used in both groups (without significant differences). There were not statistically significant differences in midazolam and propofol, total daily dose, days of mechanical ventilation, ventilator associated pneumonia, delirium, ICU mortality and ICU length of stay. Conclusions: No statistically significant differences were observed between the groups of this pilot study using BIS to adjust the sedation. We attribute these findings mainly to the lack of adherence to the protocol. Introduction: How much sedation is given, and for how long, is important in determining patient outcome as both over sedation and under sedation can have potentially deleterious consequences. Over sedation can increase time on ventilator support and prolong ICU duration of stay. Under sedation can cause hyper-catabolism, immunosupporession, hypercoagulability and increase sympathetic activity. Objectives: The aim of this audit was to look at our use of sedation in a large 18bed teaching unit in Glasgow. We aimed to look at propofol dosage, to particularly look if patients exceeded their maximum hourly dose, sedation scoring tools and whether it was regularly assessed, the addition of other sedative agents and when, and whether sedation load was associated with increased ventilator days. Methods: We looked at a snapshot of 40patients picked at random admitted to the Queen Elizabeth University hospital, Glasgow over the previous six months. The Richmond-Agitation Sedation scale was used as the sedation scoring tool. Results: Data was collected for 40patients. 57.5 % were male. The median age was 57 years. Weight and height were not documented for 21patients. 6 patients were given in excess of the recommended dose of propofol according to weight (mg/kg/hr). These were six of the patients in which weight was actually documented so exceeding maximum recommended daily dosing could have been more of an Intensive Care Medicine Experimental 2016, 4(Suppl 1):30 Page 223 of 607 issue than is described. All patients were sedated with propofol and an opiate, either remifentanil or alfentanil. Half of the patients were found to be over sedated in the time period, with RASS scores of −4 or −5. Six out of the forty patients did not have sedation scores documented daily as part of their care. When other agents were considered, they were considered relatively late in the patient stay (days [4] [5] . CK and triglycerides were never checked when propofol had been used in high doses for a significant length of time. Average length of ventilation was 4 days (12 hours -12 days) with unsurprisingly higher propofol use seen in the patients ventilated for longer periods of time. Excess sedation was more common in the younger patient with a past history of drug or alcohol dependence. Conclusions: Delirium and over sedation is associated with an increase in morbidity and mortality. As can be seen from our snapshot of data, we are poor at documenting daily sedation scores, with a significant proportion of our patients being documented as over sedated. Propofol use is excessive, and could perhaps lead to iatrogenic complications and morbidity. Patients who were heavily sedated were ventilated for longer. We are now working on a sedation protocol within our unit to improve our practice. Introduction: There is evidence that the type of intravenous fluid used in patients who are critically ill or who have undergone major surgery may have an impact on the progression and recovery of Acute Kidney Injury. Patients undergoing renal transplantation are not specifically included in this work. Our centre changed the general peri-operative fluid regimen from routine use of normal saline (NS) to Plasmalyte (balanced solution containing physiological sodium, chloride, potassium, magnesium with an acetate buffer), including all patients undergoing renal transplantation. We hypothesised that this change would reduce peri-operative hyperkalaemia and thus reduce the need for immediate renal replacement therapy (RRT). Methods: The peri-operative fluid management guidance was changed in March 2013. We performed a single centre retrospective observational study of consecutive renal transplant recipient's pre and post policy change to assess its impact on transplant patients. The local renal database, patient notes, a computer based pathology system and clinic letters were used to collect data. We excluded patients with incomplete data of the peri-operative period, who had not received the standard fluid regimen of the time and those with an immediate surgical complication that rendered dialysis inevitable. Results: There were 47 transplant recipients in the NS group and 29 in the Plasmalyte group. The percentage of patients not requiring RRT in the first 48 hours post operatively in the Plasmalyte group were significantly higher than in the NS group (D1 97 vs 81 % p 0.046, D2 94 vs. 72 %, p 0.025) (Fig. 12 ). There were no cases of hyperkalaemia in the immediate post operative period for patients who had received Plasmalyte (P < 0.0001) (Fig. 13) . A greater urine output in the first 24 hours after surgery was observed in the plasmalyte group, 2195mls (95 % CI:1423-2966) vs. 913.8mls (95 % CI:563.3-1264, P < 0.0001) which may indicate earlier onset of recovery from the post transplant AKI. Baseline characteristics were similar between each group except there were a higher proportion of DCD donors in the NS group compared to the Plasmalyte group (36 % vs. 17 %, p < 0.001). Conclusions: Renal transplant recipients who did not have an immediate surgical complication and received only Plasmalyte in the perioperative period, had a lower incidence of RRT in the first 48 hours following surgery than those who received normal saline. This may be attributed to the lower incidence of immediate hyperkalaemia in the Plasmalyte group. Introduction: Pulmonary complications after major surgery are common affecting up to 30 % of patients, increasing hospital length of stay, short and long-term mortality 1 . Despite this, very little specific action is taken to prevent post-operative pulmonary complications (PPC) within major surgery programmes. Even the Enhanced recovery after surgery [ERAS] programme, does not specifically address this. Objectives: Central Manchester Foundation Trust (CMFT) successfully implemented ERAS+ aimed at reducing PPC in 2014 and we now have results to show its sustained benefit. Methods: Using quality improvement methodology, a multidisciplinary team developed an innovative surgical pathway combined with elements of ERAS. Working with the Boston Medical Centre, we produced ICOUGH UK 2 consisting of -Incentive spirometry, Coughing and deep breathing, Oral care, Understanding (patient and family education), Getting out of bed and Head-of-bed elevation. Additional innovations within the ERAS+ include: Prehabilitation/Reablement tools; SURGERY SCHOOL -patient and family preparation session and ICOUGH UK multimedia resources including ICOUGH TV. Pathway innovation occurred during sponsored listening sessions with patients and relatives. We introduced ICOUGH prescriptions attached to drug charts to promote compliance and this was audited weekly. All elective surgical patients requiring critical care admission were screened for the development of PPC on days 1, 3, 5, 7 and 15 after surgery using standard definitions 3 . We prospectively measured baseline PPC between April 2013-4 and repeated PPC audit following introduction of ERAS+ in September 2014 through to Jan 2016. Results: ERAS+ has been successfully developed and embedded in a large NHS university teaching hospital. More than 200 critical care nurses have been trained in ERAS+. Surgery school has been embedded, with over 350 patients attending; qualitative feedback has been overwhelmingly positive. Since September 2014, utilising ERAS+ within critical care in greater than 500 patients has resulted in a sustained reduction of 40 % in PPCs. Conclusions: ERAS+ implementation into a large teaching hospital has successfully reduced PPCs in major surgery patients. ERAS+ can be rapidly adopted by European healthcare, with a significant reduction in patient morbidity and hospital length of stay. This innovation aligns with domains 1, 3-5 of the NHS Outcome Framework 4 . The use of inhaled nitric oxide (INO) in neonatal, pediatric and adult intensive care units, a franco belgian multicenter prospective survey from the positive study group C. Barbanti 1 , J. Amour 2 , P. Gaudard 3 Introduction: Inhaled NO is a well-known selective pulmonary vasodilator in Europe since 20 years nevertheless few study really described the daily ICU practice. The objective of this study was to determine the gap between guidelines and real life. Methods: This is a multicenter, prospective, observational study on iNO administered through an integrated delivery and monitoring device (EZ-Kinox) in 12 French and 1 Belgian centers for pulmonary arterial hypertension after cardiac surgery (PAH CS) and for persistent pulmonary hypertension of the newborn (PPHN). The following parameters were observed: dose, treatment duration, ventilation modes, monitoring procedures, weaning procedures and occurrence of a rebound effect. Concomitant pulmonary vasodilators treatments and safety data were also collected. Results: 236 patients were studied among 238 patients enrolled within one year period : 81 children and 117 adults with PAHCC and 38 neonates with PPHN. Echocardiography or pulmonary artery catheterization were performed to diagnose PAH respectively in 86 % and 31 % of the cardiac patients. In the neonatal group 97.4 % had an echocardiographic diagnosis. Inhaled NO was initiated before ICU admission in adult population (57 %) but rarely in cardiac pediatric patients (12.7 %), p < 0.01 and 38.9 % in neonates. The median initial dosage of iNO set was 20 ppm [18] [19] [20] in the cardiac pediatric group and 10 ppm [10-15] for adults and 16.7 ppm [11.2-20] for neonates with a median duration respectively 3.9 days [1.9-6.1], 3.8 days [1.8-6.8] and 3.07 days [1.04-5.74 ]. The NO therapy classically was delivered during controlled ventilation mode including high frequency oscillation and more and more via non invasive ventilation as high flow nasal cannula. The clinical effect of iNO was considered sufficient in 89 % of the cases and the dose was gradually decreased before definitive withdrawal in 86 % of the cases. Adverse effects (AE) occurred 75 times (80 % of the patients without AE) including rebound effect in 1.2 % of children, 3.4 % of adults and 2.6 % of neonates, methaemoglobinemia was observed on 7.9 % of neonates and 1.7 % of adults. The NO 2 generated by contact between NO and O2 was above 0.5 ppm value in 17 % of the pediatric cases, 1 % of the adult cases and never observed on neonates population. All these AE related to iNO recovered without sequelae. Pulmonary vasodilators (levosimendan, sildenafil, milrinone) were associated in 95 % of the cases in pediatrics, 23 % in adults (p < 0.01) and 23.7 % in neonates. ICU stay was 8 days [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] for children, 10 days [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] for adults and 3.7 days [1-5.7 ] for neonates. Discussion. This survey confirms the good efficacy and safety of NO therapy in the three populations. Occurrence of rebound effect is particularly rare with a large application of a gradually withdrawal of iNO and pulmonary vasodilators use. The usage of last generation of NO devices subject to prior training allows good compliance with recommendations. Introduction: Administration of normal saline has been associated with the development and exacerbation of acute kidney injury, [1] and this may be related to hyperchloraemia. Since recipients of kidney transplants often require large volumes of fluid replacement, we hypothesised improved post-operative biochemistry and quicker renal recovery following a switch from saline to Plasmalyte fluid therapy during the routine peri-operative period. Methods: The peri-operative fluid management guidance was changed in our centre in March 2013. We performed a single centre retrospective observational study of consecutive renal transplant recipients before and after the policy change to assess its impact on transplant patients. We used the local renal and pathology databases, paper and computerised patient notes and clinic letters to collect data. We excluded patients with incomplete data of the perioperative period or who had not received the standard fluid regimen of the time. Results: 47 patients received normal saline and 29 received plasmalyte. Demographics were similar between groups, except the saline group contained more patients receiving a kidney donated after cardiac death (36 % vs 17 %, p < 0.001). In both groups, fluid administration rates were matched to urine output and overall fluid balance was equal between the two groups. Electrolyte data for the two groups are shown in Fig. 15 and demonstrate significantly higher potassium and chloride and lower bicarbonate levels in the normal saline group (P < 0.0001). There was a higher proportion of hyperkalaemia (serum K + >6.0 mmol/L) immediately post-op (21 % vs 0 %), over the first 24 hours (32 % vs 21 %) and over the second 24 hours postoperatively (15 % vs 7 %) in the patients who received normal saline (P < 0.001). The saline group had a longer length of stay (11 days vs 7 days, p < 0.0001), and lower eGFR at 3 months post-op (43 vs 51 ml/min; P = 0.016), although by 1-year post-transplant, mean renal function was identical at 51 ml/min in both groups (Fig. 16) . Conclusions: The sole use of Plasmalyte fluid replacement in the peri-operative period is associated with improved potassium, chloride and acid base homeostasis after kidney transplantation when compared to normal saline. The use of Plasmalyte is safe (despite the concern that it contains potassium), and may be associated with improved early renal outcomes. Whilst evidence of benefit for balanced replacement fluids in the general population is conflicting, after transplantation the effects may be more pronounced as the volumes of fluid administered are greater. Methods: Patients were divided into a HR group (patients who returned home after discharge) and non-HR group (deceased or transferred to nursing facilities). Perioperative data and outcome were assessed and compared. Multivariate logistic regression analysis was conducted to identify independent predictors. Results: The average age of patients was 88 years. HR occurred in 61 % of patients, and mortality was 9 %. The HR group showed higher preoperative albumin level than the non-HR group. More patients in the non-HR group experienced hip surgery than in the HR group (51 % vs. 12 %, P < 0.001). APACHE II score was higher (P < 0.001) in the non-HR group. In multivariate analysis, preoperative albumin, hip surgery, and APACHE II score were identified as independent predictors of HR. Conclusions: Fluctuations of serum sodium, including in patients whose sodium remained within the normal range, were independently associated with an increase in 28-day mortality. Severity of dysnatraemia was associated with 28-day mortality. These findings are consistent with previous reports and suggest that minor fluctuations in sodium may be associated with mortality. Introduction: Cv-aCO 2 /Da-vO 2 has been suggested as a marker of adequacy of resuscitation in shock states. A ratio >1 reflects the metabolic tipping point at which CO 2 production exceeds oxygen consumption, akin to the anaerobic threshold in cardiopulmonary exercise testing, but with the advantage of measurement from paired arterial and central venous blood gas analysis. It is of prognostic value in critical care, and in sepsis when combined with lactate [1, 2] . We investigate the role of Cv-aCO 2 /Da-vO 2 in liver resection surgery. Our anaesthetic technique uses fluid restriction, diuresis and venodilation to decrease CVP, which improves outcome [3] . On completion of resection, goal-directed fluid therapy (GDFT) is initiated. This technique provides an ideal model of rapid haemodynamic changes in which to investigate Cv-aCO 2 /Da-vO 2 . Objectives: To establish: 1) Is there a relationship between perioperative Cv-aCO 2 /Da-vO 2 and outcome? 2) If Cv-aCO 2 /Da-vO 2 , inverse CO 2 gap or serum lactate correlate with cardiac output (CO) Methods: This is a subset of data from the prospective observational study MicroHepFlow, investigating microcirculation in liver resection surgery. All patients received general and thoracic epidural anaesthesia, fluid restriction, GTN, remifentanil and furosemide. Oesophageal Doppler (OD) was used at the anaesthetists' discretion. Prospective data was collected at pre-defined time points. The Clavien-Dindo (CD) Classification was used for post-operative complications. Statistical analysis was with linear regression and Fischers exact test. Results: In 31 patients, 17 with CO data, a Cv-aCO 2 /Da-vO 2 > 1 and lactate ≥2 was common (55 % at maximal desiccation and 52 % following GDFT). There was no consistent relationship between this and the incidence of complications. C-D complications ≥ Grade III were rare (6 %). Neither Cv-aCO 2 /Da-vO 2 , inverse CO2 gap nor serum lactate concentration significantly correlated with CO. Conclusions: The expected positive association between Cv-aCO 2 / Da-vO 2 > 1 and lactate ≥2 with post-operative complications was not observed, potentially due to a low incidence of serious complications. The lack of significant correlation between Cv-aCO2 / Da-vO2 and inverse CO2 gap with cardiac output is informative and suggests that these variables are poor surrogates of cardiac output in this setting. Hospital LOS in those who didn't require any vasopressors was 4.9d (3.9-6.1), in those who required some vasopressors was 5.8d (5.0-7.9), and in those with had vasoplegia was 7.0d (6.0-9.8), p < 0.0001 KWT. Introduction: Patients undergoing thoracic surgery commonly undergo a radial catheter placement to fulfill the need for continuous blood pressure monitoring, other than blood gas analyses 1. Objectives: In this prospective observational study, we recorded cardiac output and pressure measurements obtained by an uncalibrated pulse contour method in a totally non invasive manner (ClearSight system, Edwards Lifesciences) to assess hemodynamic variations during normal and one lung ventilation (OLV) in supine and lateral decubitus in thoracic surgery. Methods: After Ethical Committee approval was obtained, we enrolled patients with age > 18 years, scheduled for thoracic surgery and OLV with double-lumen tube in lateral decubitus. Exclusion criteria: ASA > III, severe baseline hemodynamic impairment which required invasive monitoring and amine infusion. Key hemodynamic parameters, including Stroke Volume Index (SVI), Stroke Volume Variation (SVV), Cardiac Index (CI) and Continuous Blood Pressure (cBP) were recorded at three time points: two lung ventilation in supine position (T1), two lung ventilation in lateral decubitus (T2) and one lung ventilation in lateral decubitus (T3). Results: 11 consecutive patients scheduled for thoracic surgery were included. Overall, our patients showed no hemodynamic impairment throughout the passage to lateral decubitus and OLV (CI 3,1 ± 0,9 l/min/m 2 at T1, 2.5 ± 0.6 l/min/m 2 at T2, 2.5 ± 0.7 l/ min/m 2 at T3; p = 0.09 T2 and T3 vs T1). Only in 3 patients a decrease in CI was detected after the position change (−37 %, −42 % and −43 %, respectively, T2 vs T1), which required prompt intervention. Conclusions: The lack of invasiveness and the simplicity of the system allowed satisfactory monitoring and, subsequently, appropriate therapy, without the need of arterial catheter placement for invasive monitoring, while an automatic, intermittent, noninvasive blood pressure measurement would have not readily detected the observed hemodynamic variations. Even if most studies underline the not-interchangeability of the finger cuff method with the currently used invasive devices 2 , in our low to moderate risk thoracic surgery patients not receiving an arterial line, ClearSight was able to track hemodynamic changes during the different phases of the surgical procedure, in particular those related to position changes and to the OLV. The global end-diastolic volume (GEDI) could be more appropiate to reduce the intraoperative bleeding than central venous pressure ( Conclusions: Volume depletion according to GEDI was found in more than half the patiens. The predictive values of CVP with regard to volume depletion were low GEDI and its changes significantly correlated to CI and its changes, which was not observed for CVP. Therefore, GEDI appears to be more appropiate for volume management during mayor liver resections with the aim to avoid intraoperative bleeding and transfusión. Note: This abstract has been previously published and is available at [4] . It is included here as a complete record of the abstracts from the conference. Results: 20 mechanically ventilated patients were included. Mechanical ventilation was set to guarantee constant minute ventilation (MV 10 ± 4 vs 10 ± 3 vs 10 ± 2 liters/minute for PCV, PSV and NAVA respectively). CRPS analysis showed a significant variation of SYNC index between the different modes ( Fig. 3 ), while RSA was not able to detect meaningful differences (23 ± 26 ms, 24 ± 24 ms and 22 ± 22 ms, p = 0.6, for PCV, PSV and NAVA respectively). Conclusions: Analysis of CRPS is possible in ventilated patients. Our results endorse the hypothesis that under ventilation with a fixed frequency, the interactions between cardiac and respiratory fluctuations were stronger than in the case of patient driven modes of mechanical ventilation, as PSV and NAVA (2) . The lack of variation of RSA may be due to sedation and mechanical ventilation. (ROSC) [1] . However, knowledge regarding a possible association between substance abuse and mortality is limited. Conclusions: Chronic substance abuse is common among patients with CA and is significantly associated with non-shockable ICR. As expected, in-hospitality mortality was significantly higher in the non-shockable group. Although chronic abuse was associated with non-shockable initial rhythm, it was not associated with in-hospital mortality. Introduction: Intravenous boluses of furosemide are commonly given to critically ill patients to modulate fluid balance 1-3 . However, their effect on urinary output (UO), fluid balance, electrolyte losses and hemodynamics has not been systematically studied. Therefore, we sought to compare UO, fluid balance, electrolyte losses, biochemical, and hemodynamic effects in the six hours before and after the administration of a 40 mg IV bolus of furosemide. Methods: We conducted a prospective observational study in critically ill patients where the attending clinician had decided to administer a 40 mg bolus of IV furosemide. We collected information on UO, fluid balance, urinary electrolyte losses, serum and urinary creatinine, serum biochemistry, and hemodynamics and compared the 6-hour pre-bolus period with the 6-hour post-bolus period. We performed linear regression analysis to identify predictors of the extent of urinary output response. Introduction: Inmune Heparin-induced thrombocytopenia (HIT) is a prothrombotic disorder caused by an immune-mediated complication that results from a platelet activating inmune response triggered by the interaction of heparin with a specific platelet protein, platelet factor 4 (PFA). Fondaparinux is a safety treatment of HIT, even though is not recommended in acute renal failure (ARF) because of it renal elimination and significant risk of accumulation. Objectives: Report the safety profile and efficacy of fondaparinux (thrombotic and major bleeding complications) in patients with HIT and ARF during continuous renal replacement therapy (CRRT). Methods: We reviewed consecutive elegible patients with HIT and ARF in one medical university center (Clínica Universidad de Navarra) over a 5 year period, who received fondaparinux for anticoagulation at the time of the HIT diagnosis. Results: -Of the 12 patients recorded that received fondaparinux as anticoagulation therapy, 5 of them shared the criteria of HIT and ARF with CRRT. We analyzed four of the five patients, excluding one because of loss of information. -The mean age of the patients was 67 yo, three men and one woman. All of them present acute renal failure with a mean basal creatinine of 2.57, meeting the criteria of CRRT. -All patients had cardiac surgery with heparin administration last more than 24 hrs with a mean of 4.5 days. -Platelets at admission were documented and in all cases they dropped more than 50 % of the original value. -After the administration of Fondaparinux, all the patients had a recovery of the platelet count until the basal value, with a mean of 28.25 days. -None of the patients developed new, recurrent or progressive thrombosis. No major bleeding complications were documented. Conclusions: Fondaparinux is a safety alternative of anticoagulation therapy in patients with HIT and ARF during continuos renal replacement therapy. There are more quantitative studies then qualitative studies [1] . Most studies conclude that more studies need to be conducted [2] . Other Dutch hospitals struggle with the same problem. Some hospitals enlarged pharmacy service to prepare more medication to decrease nurse's workload. Discussion: Evaluating double check workload, it was less time consuming then expected although the frequency of the check brings more interruptions. Every interruption brings a disturbance to nurse's concentration and work, this could potentially increase patient risk. Therefore the amount of interruptions should be reduced to a minimum. Meanwhile, technology makes giant leaps. This has the potential to replace the double check. BCMA is making progress and is more efficient and foul proof than human checks. Because of the wide spread variety in results its hard to draw further Conclusions: It is even doubtful whether further studies make sense, given the current advances in technology. If available, BCMA technique (combined with CPOE) should be implemented as soon as possible. If not available, than hospitals should focus on a select part of medication checking based on specific risks and workflow [3] . When we compare the pre and post treatment AST, ALT and CK values of the patients with multi drug intoxication there were significant decrease. But, there were no differences between troponin values. In the patients with CO intoxication there were no significant differences between the pre and post treatment carboxyhemoglobin (COHb) values (Table 8) . All patients were discharged with healing. Seventeen of the patients had no problem related with their pregnancy and they gave birth at term (37-38 weeks). All babies were healthy at birth and they did not have any problem associated with intoxication. One of the patients ended her pregnancy with her own decision in her early pregnancy. Conclusions: In conclusion, we did not observe any severe complication in clinically stable intoxication patients with normal laboratory findings in their pregnancy. Alcohol-related major traumatic brain injury: a province-wide retrospective analysis N. Kureshi 1,2 , L. Fenerty 1 , G. CONTROL underwent IIR without NAC. In the other groups, NAC was administered intraperitoneally with different regimens: 150 mg/kg before ischemia (NAC150), 300 mg/kg before ischemia (NAC300) and 150 mg/kg before ischemia plus 150 mg/kg 5 min before reperfusion (NAC150 + 150). Measurements in tissues and blood were conducted at 4 hours of reperfusion following exsanguination. Results: Histological score of the liver was significantly improved in NAC300 compared with control (1.7 ± 0.5 vs. 2.9 ± 1.1 respectively, p = 0.05). In addition, NAC treatment significantly reduced liver transaminases in all groups of treatment, mostly in group NAC300. Plasma malondialdehyde levels were lower with NAC treatment, although not statistically significantly. Lung glutathione peroxidase was significantly increased in group NAC300 (p = 0.04), while the other oxidation biomarkers showed no significant differences. Conclusions: NAC exerts a significant protective role in liver injury following IIR, which seems to be independent of an intestinal protective effect. Additional administration of NAC before reperfusion was of no further benefit. The most effective regimen among the compared regimens was that of 300 mg/kg before ischemia. Keywords: intestinal ischemia-reperfusion, n-acetylcysteine, oxidative stress, liver injury, rat model Introduction: Lactate supports brain energy metabolism and promotes cerebral vasodilation. Hypertonic lactate (HL) solutions are emerging as a therapeutic alternative after acute brain injury however their effect following aneurysmal subarachnoid hemorrhage (SAH) is unknown. Methods: We prospectively studied critically ill SAH patients (n = 7, age 64 ± 6 years) monitored with cerebral microdialysis (CMD) and transcranial Doppler (TCD) who were resuscitated according to current guidelines and had no intracranial hypertension (clinicaltrial.gov NCT01573507). Intervention consisted of a 3-h infusion of HL (30 μmol/kg/min, administered within 48 h from SAH, to achieve blood arterial lactate ≈ 4-5 mmol/L). Endpoints were the effect of HL on cerebral energy metabolism (using hourly CMD concentrations of lactate, pyruvate and glucose) and brain perfusion (using hourly TCD measurement of middle cerebral artery cerebral blood flow velocities, MCBFV Introduction: Intensive care unit acquired weakness (ICUAW) is a severe complication of critical illness. ICUAW is associated with muscle wasting, muscle weakness, respiratory failure as well as increased morbidity and mortality and features massive skeletal muscle atrophy by destruction of the contractile myosin elements. No specific treatment has been established. Objectives: Aim of the study was to investigate if protocol-based physiotherapy (pPT) or pPT with additional evoked muscle contraction by electrical muscle stimulation (EMS) are more effective to prevent skeletal muscle atrophy in critically ill patients when compared to standard physiotherapy (sPT). Methods: A randomized clinical trial was performed. Participants (inclusion criterion: SOFA score ≥ 9) were randomly split into 2 groups, either treated started at the day of admission with sole pPT or pPT with EMS daily. Data of patients treated with standard physiotherapy (sPT) were available from an earlier trial [1] . An open surgical muscle biopsy from the musculus vastus lateralis was obtained at median day 15 of critical illness. Histological examination of muscle biopsies and quantification of myocyte cross-sectional area (MCSA) for type I, IIa, and IIb fibers using ImageJ software (fiber count > 100 per patient) were performed after applying the toluidine blue ATPase Method: Non-parametric tests were performed. Ethic vote (Charité EA 2/041/10). Results: 39 critical ill patients were enrolled in this final analysis (19sPT, 11pPT, 9 pPT + EMS). There were no significant differences in baseline characteristics and fiber type distribution between the groups. The MCSA for all fiber types of patients with pPT with or without additional EMS were larger than the MCSA of patients with sPT. Compared to pPT alone, additional evoked muscle activation by EMS increases MCSA for type I,IIa and IIb muscle fibers. Data are shown as frequency-distribution histograms. Conclusions: For the first time we show that pPT is associated with reduced skeletal muscle atrophy when compared to sPT. EMS resulted in an additional reduction of muscle atrophy. The histological findings showed reduced muscle atrophy through preventive physiotherapy procedures. Further studies are needed to solidify our findings and to analyze if this reduction in atrophic response can be confirmed on molecular (i.e. analysis of myosin heavy chain, protein homeostasis) and functional levels and improves the long-term outcome of critical ill patients. Objective: Central venous-to-arterial carbon dioxide difference (P cva CO 2 ) has demonstrated its prognostic value in critically ill patients suffering from shock, and current expert recommendations advocate for further resuscitation interventions when P cva CO 2 is elevated. P cva CO 2 combination with arterial-venous oxygen content difference (P cva CO 2 /C av O 2 ) seems to enhance its performance when assessing anaerobic metabolism. However, the fact that PCO 2 values might be altered by changes in blood O 2 content (the Haldane effect), has been presented as a limitation of PCO 2 -derived variables. The present study aimed at exploring the impact of the Haldane effect on P cva CO 2 and P cva CO 2 Introduction: Transpulmonary thermodilution (TPTD) has been established to measure cardiac output CO, global end-diastolic volume GEDV and extravascular lung water EVLW. To facilitate interpretation of these data several ratios have been developed, including pulmonary vascular permeability index (defined as EVLW/(0.25*GEDV)) and global ejection fraction ((4*stroke volume)/GEDV). PVPI and GEF have been associated to the aetiology of pulmonary oedema and to systolic cardiac function, respectively. However, several studies showed that the use of femoral venous access results in a marked overestimation of GEDV which also falsely reduces PVPI and GEF. One of these studies suggested a correction formula for femoral venous access that markedly reduces the bias for GEDV (1) . Consequently, the last PiCCO-algorithm requires information about the CVC, and correction for femoral access has been shown. However, two recent studies demonstrated inconsistencies of this algorithm using incorrected GEDV for PVPI (2), but corrected GEDV for GEF. Nevertheless, these studies were based on mathematical analysis of data displayed by the PiCCO in a total of 15 patients equipped with only a femoral, but not with a jugular CVC. Objectives: To compare PVPI_fem and GEF_fem derived from femoral TPTD to values derived from jugular indicator injection in 25 patients with both jugular and femoral CVCs. Methods: 54 datasets in 25 patients CVC were recorded. Each dataset consisted of three triplicate TPTDs using the jugular venous access as the gold standard, while the the femoral access with (PVPI_fem_cor) and without (PVPI_fem_uncor) information about the femoral Introduction: Prediction of fluid responsiveness in hemodynamically unstable patients with spontaneous breathing activity has been a clinical challenge. It has been best assessed by passive leg raising test. Preejection period, the time from the onset of ventricular depolarization to the beginning of left ventricular ejection, is a systolic time interval found to decrease with greater preload 1 . The effect of passive leg raising test on the pre-ejection period has not been studied in this context. Objectives: Our objective was to test whether fluid responsiveness could be predicted by the response of pre-ejection period to passive leg raising test. We also examined whether baseline end expiratory inferior vena cava diameter could predict fluid responsiveness in this category of patients. Methods: Thirty patients with spontaneous breathing activity considered for fluid loading were included. We used transthoracic echocardiography to measure stroke volume, and pre-ejection period before and during passive leg raising test as well as before and after fluid loading (500 ml saline 0.9 % over 15 minutes). An increase in stroke volume of 15 % or more after volume expansion defined fluid responders. We also measured baseline end expiratory inferior vena cava diameter obtained from the subcostal window. Introduction: Persistent signs of skin hypoperfusion after resuscitation in patients with shock are associated with worse outcomes, but assessment is rather subjective. Skin laser Doppler (SLD) techniques allow skin blood flow (SBF) to be measured more objectively and non-invasively. Objective: To measure SBF at the extremities using a SLD technique in patients with shock and to determine if they are correlated to patients outcomes. Method: SBF was evaluated in the fingertip and toe (PU: perfusion units) using a SLD (PeriFlux System 5000, Perimed, Sweden) at basal skin temperature and after warming to 37°C in 28 consecutive patients admitted with circulatory shock (need for vasoactive agents to maintain MAP > 60 mmHg) on ICU admission and 10 healthy volunteers. Organ dysfunction was assessed using the sequential organ failure assessment (SOFA) score. Statistical analysis was performed using STATA 13.0. The area under the receiver operating curve (AUC) was calculated to identify the predictive performance of SBF. Results are presented as median (p25-75) values. Result: Global ICU mortality was 32 %. Demographic data and SBF are shown in Table 9 . The AUCs for prediction of mortality at basal temperature were 0.77 (0.58-0.97) and 0.65 (0.47-0.92) for the fingertip and toe respectively and 0.71 (0.51-0.93) for the SOFA score. Conclusion: Measurements of SLD at fingertip and toe may represent an interesting monitoring technique for shock patients. Their prognostic value is similar to SOFA score. Introduction: Investigating the use of dynamic haemodynamic parameters, such as pulse pressure variation (PPV) and stroke volume variation (SVV), for predicting fluid responsiveness prior to volume expansion has led many scientific discussions lately. Also, according to current consensus statements their use is increasingly recommended in suitable patients [1] . Extended hemodynamic monitoring (EHD) beyond measurement of cardiac filling pressures (central venous pressure, pulmonary artery occlusion pressure) is still rare. A recent study revealed that only a minor part of critical ill patients are supervised with specific monitoring to assess fluid responsiveness [2] . It remains unclear if this is due to lacking availability of the specialised devices or the limitations of the use of automated functional parameters of preload. Objectives: This analysis was designed to assess the availability of monitoring, the clinical suitability of using PPV or SVV, and if and how they are actually used in German, Swiss, and Austrian ICU´s. Methods: This is a sub-analysis of the ICU-CardioMan Trial. For this multicentre, one day cross-sectional study data regarding patients' hemodynamic monitoring was collected from 161 participating ICUs from Germany, Switzerland and Austria by means of a web-based case report form. The ICUs gave detailed information on availability of EHD in general and provided data from 1789 patients concerning monitoring, as well as information on the patients' specific characteristics that have impact on treatment suitability of PPV and SVV to predict fluid responsiveness. Results: EHD was widely available throughout the examined ICUs. Only a minority of patients was reported to be monitored with EHD during the study period (see Table 11 ). In the group of the patients that needed catecholamines and/or vasopressors (39.2 %) the share of patients monitored with EHD was significantly higher. In this subgroup, 66.8 % of those patients had sinus or pacer rhythm. Of this portion another 30.9 % were mechanically ventilated in a controlled mode. Conclusions: Though widely available EHD to predict fluid responsiveness is still not comprehensively implemented in daily clinical routine. Over one third of patients that required catecholamines/ vasopressors fulfilled the criteria for assessment of PPV or SVV. The high share of patients not fulfilling the criteria for using PPV and SVV stresses the need for further development of functional parameters of preload operating independently from the presence of controlled mechanical ventilation. Introduction: Weaning from mechanical ventilation remains a challenge in intensive care units (ICU); respiratory muscle fatigue may be important in difficult weaning. We evaluated whether reconnection to mechanical ventilation for one hour after the effort of a spontaneous breathing trial could reduce extubation failure in critically ill patients. Objectives: reconnection to mechanical ventilation for one hour after the effort of a spontaneous breathing trial could reduce extubation failure in critically ill patients. Methods: In this prospective, randomized, multicenter trial, patients who successfully completed a spontaneous breathing trial were randomized to direct extubation (Control group) or reconnection to the ventilator for a one-hour rest before extubation (Rest group). Statistical analysis included multivariable logistic regression models for extubation failure. Results: We randomized 243 patients to the Control group and 227 patients to the Rest group. The most common spontaneous breathing trial method was T-tube, and the median time from intubation to spontaneous breathing trial was similar between groups (5.7 days in the Control group and 5.5 days in the Rest group; p = 0.2). Extubation failure within 48 hours after extubation was more common in the Control than in the Rest group (58 (23.9 %) vs. 24 (10.6 %) patients; p < 0.001). Rescue noninvasive ventilation was administered in 47 (57 %) patients, 16 (34 %) of whom required reintubation. Reintubation was more common in the Control than in the Rest group (35 (14 %) vs. 12 (5 %) patients; p < 0.001) mainly due to inability to manage secretions in both groups. Hospital and ICU length of stay and mortality did not differ between groups. Conclusion: One-hour rest after a successful SBT reduced the rates of extubation failure within 48 h after extubation and reintubation. Driving pressure is a significant predictor of mortality in the Acurasys and Proseva randomized controlled trials in ARDS patients C. Guérin 1,2 , L. Papazian 3 Introduction: Driving pressure (ΔP) across the respiratory system has been shown to strongly predict hospital mortality in ARDS patients, with a threshold in the vicinity of 14-15 cm H2O above which the relative risk of mortality significantly increased (1). We wonder whether this result may be due to the wide range of tidal volume and PEEP used across the trials included (1). Objectives: Therefore, we investigated ΔP in two trials in which lung protective mechanical ventilation was applied to ARDS patients. Our working hypothesis is that ΔP is a risk factor just like compliance (Crs) or Plateau pressure (Pplat) of the respiratory system are. Methods: ARDS patients included in Acurasys (2) and Proseva (3) trials were used. The first trial compared the neuromuscular blocking agent (NMBA) cisatracurium vs. placebo and the second the prone vs. the supine position. Both had near inclusion criteria (notably PaO2/FIO2 < 150 mm Hg and PEEP ≥ 5 cm H2O) and similar lung protective mechanical ventilation (4) (in particular tidal volume 6 ml/kg predicted body weight and PEEP/FIO2  Are changes in diaphragm thickness during mechanical ventilation associated with clinical outcomes? A prospective multi-centre cohort study E.C. Goligher 1 , E. Introduction: Breathing is a cyclic activity that is not monotonous and is therefore variable. During mechanical ventilation (MV), breathing variability is reduced. Breathing variability has been mostly quantified with two indices: the coefficient of variation (CV) that is defined as the standard deviation to the mean ratio, and the amplitude ratio of the spectrum's first harmonic to its zero frequency (H1/ DC). Previous reports have suggested that low variability was associated with weaning failure and increased mortality. However, these studies have quantified variability either on very specific time points or on the contrary on the whole intensive care unit stay. Objectives: The aim of our study was to quantify breathing variability at the early phase of weaning according to those two indices. We further evaluated the factors associated with and the prognosis impact of low breathing variability. Methods: Ancillary study of a multicentre, randomized controlled trial comparing neurally ventilator adjusted assist to pressure support ventilation during the early phase of weaning. Airway flow and pressure were recorded during 20 minutes 12, 24, 36 and 48 hours following inclusion. Respiratory rate, tidal volume and mean inspiratory flow were measured. Variability was assessed according to CV and H1/DC. Impact of variability on clinical outcome was determined with a Receiver Operating Characteristic. Results: 108 patients mechanically ventilated for 5 days (3-9) were included, 72 men (68 %), aged 66 (37-86) years, SAPS II 44 (35-59), 62 % were mechanically ventilated for de novo hypoxemic respiratory failure. Sensitivity and specificity were plotted as functions of the ability of the CV of respiratory rate (RR), tidal volume (Vt) and mean inspiratory flow (Vt/Ti) to predict day-28 mortality. The curves intersected at a coefficient of variation of respectively 0.21 for respiratory rate, 0.16 for tidal volume and 0.14 for mean inspiratory flow (Fig. 26) . Conclusions: This preliminary report is the first study to evaluate the pharmacokinetics and the pharmacodynamic response of low-dose IVH when administered to critically ill adults to treat delirium. We observed low trough levels of IVH and lasting delirium (for the first three days after initiation of IVH). The IVH dose that should be used to treat delirium in the ICU requires further investigation. Intracranial pressure after antipyretic therapy in acute brain injury E. Introduction: Fever is a dangerous secondary insult for the injured brain (1). In a recent study (2) examining Paracetamol administration for fever control in acute brain injury (ABI) patients (pts), a reduction in intracranial pressure (ICP) was observed only in subjects with a baseline ICP > 15 mmHg. Objectives: 1) to analyze ICP trend after antipyretics administration, 2) to evaluate if ICP variations are influenced by ICP value before antipyretics administration. Methods: Adults pts with ABI admitted to our Intensive Care Unit (ICU) were prospectively evaluated after antipyretics administration [4 time points: baseline (t-0), 30 minutes (t-30), 60 minutes (t-60) and 120 minutes (t-120)]. Inclusion criteria were: 1) monitoring of intraarterial blood pressure, core temperature (Tc), and ICP and 2) a Tc ≥ 37.5°C. Exclusion criteria were: 1) hypovolemia, 2) administration of drugs with hemodynamic effects during the study period, 3) administration of antipyretics in the 6 hours before the start of the study, 4) acute heart failure and 5) cerebral vasospasm. 16.0 ± 4.4 mmHg at t-0, t-30, t-60 and t-120 respectively; P < 0.001) was observed in the group of pts with t-0 ICP > 15 mmHg. Conversely, a statistically significant increase in ICP (11.2 ± 2.7, 12.7 ± 3.4, 12.8 ± 3.5, 14.4 ± 4.1 mmHg at t-0, t-30, t-60 and t-120 respectively; P < 0.001) was observed in the group of pts with a t-0 ICP ≤ 15 mmHg. A statistically significant reduction in Tc, mean arterial pressure (MAP) and cerebral perfusion pressure (CPP) was observed in all groups of patients (overall population and pts with ICP > or ≤ 15 mmHg) after antipyretic therapy. Conclusions: ICP variations are influenced by ICP value before antipyretics administration. If these data are confirmed in future studies, the decision to start antipyretic therapy should take into account the baseline ICP value. Introduction: Intracranial hypertension (ICH) is one of the main cause of death, and of poor neurological recovery after traumatic brain injury (TBI). The use of a continuous osmotherapy has been described in retrospective single-center studies, but its effectiveness is discussed. Objectives: The first objective was to describe the association between the use of a continuous osmotherapy and mortality in patients developing a post-traumatic ICH. Secondary objectives were to investigate the impact of continuous osmotherapy on long-term neurological recovery and on tolerance. Methods: We pooled the data from three prospective multicenter studies: the corti-TC trial (ref 1), the BI-VILI study (NCT01885507) and the Atlanrea cohort (NCT02426255). We included all patients with traumatic brain-injury, hospitalized in ICU and receiving mechanical ventilation for more than 24 hours. ICH was defined as one or more episodes of intracranial pressure higher than 20 mmHg and that has required a specific therapeutic intervention. In one participating center, continuous osmotherapy (NaCL20% (ref 2)) was initiated as the first line treatment of intracranial hypertension, and its administration was pursued up to the end of the period at risk of ICH. The primary endpoint was the survival rate at day 90. The secondary endpoint was the Glasgow Outcome Scale (GOS) at day 90 (GOS = 1 death, GOS = 5 minor sequelae). A crude comparison of patients with ICH treated or not with continuous osmotherapy was first performed. To consider the biases related to this observational study, an adjustment on potential confounders (age, glasgow coma scale, pupil reactivity, Marshall score, hypotension and hypoxemia) was performed by both a propensity analysis and a multivariate analysis. The protocol for this study was approved by an ethics committee. Methods: Retrospective analysis of prospectively collected data of ICH patients with ICU length-of-stay >24 hours. We retrieved clinical data, CT scans, DNROs within 48 hours from admission, 30 days mortality and modified Rankin Scale (mRS) along with the ICH score and 6-months survival. Results: 100 consecutive patients (64 ± 14 years old, 57 % males, median GCS 7 at admission, median ICH volume 75 cm 3 ) were included. DNRO: 28 %, all died, 71 ± 11 years old, median GCS 4 at admission, median ICH volume 110 cm 3 . No DNRO: 72 %, 62 ± 15 years old, median GCS 9 at admission, median ICH volume 47 cm 3 (p < 0.05 vs. DNRO). Surgery was performed in 71 %. Overall, ICU mortality was lower than expected accordingly to the ICH score (see Fig. 27 ) (i.e. 33 %). mRS was ≤3 and >3 in 21 (30 %) and 46 (64 %) of the discharged patients, respectively. 180-days survival globally approached 60 % (95%CI 50-70). Considering the severity on admission: -ICH score < 3 (33 %), median length of stay in ICU of 3 days. 17 (51 %) patients underwent to neurosurgery. Mortality was nonsignificantly different between patients receiving neurosurgery and patients receiving medical treatment. -ICH score ≥ 3 (67 %) had a median length of stay of 5.5 days. Neurosurgery was performed in 34 (50 %), and observed short-and long-term mortality was significantly lower for patients that underwent to neurosurgery than in patients receiving medical treatment (see Figs. 28 and 29). Conclusions: We observed mortality to be lower than predicted by ICH score and functional outcome to be acceptable in one-third of patients. Full treatment including neurosurgery significantly improved short and long term survival for patients with ICH score ≥3. Prognosis estimation after an ICH remains a challenging subject and early DNROs and limitations of treatment should be carefully evaluated. Introduction: Influenza infection causes severe morbidity and mortality around the world. Pandemic influenza A(H1N1)pdm09 have been describe to increases disease severity comparing with seasonal flu viruses. There are limited data comparing clinical differences between influenza A (H1N1)pdm09 and influenza A(H3N2) infection in critically ill patients. Objectives: Our aim was to analyse the demographic and clinical differences between patients admitted to ICU due to pandemic influenza A(H1N1)pdm09 and seasonal influenza A(H3N2) infection. Methods: Prospective, observational, multicenter study conducted in 148 Spanish ICUs from 2009 to 2015. Individuals with Influenza A(H1N1)pdm09 were compared with those infected by influenza A (H3N2). All serotypes were confirmed using RT-PCR at ICU admission. Pa-tients´demographic, clinical, radiologic features, laboratory values, ICU and hospital length of stay (LOS) and outcomes were recorded. Discrete variables are expressed as percentage and continuous variables as medians with 25th to 75th interquartile range (IQR). Differences between groups were assessed using the x2 test and the Fisher exact test for categoric variables and Mann-Whitney U test for continuous variables. Results: Of 2898 patients with confirmed influenza infection at ICU admission, 110 were excluded due to influenza B (n = 56) or nonserotype A typification (n = 54). At all, 2421 patients with influenza A (H1N1) were compared to 367 patients with influenza A (H3N2). Patients with A(H1N1) were much younger (50 [38-61] vs 61 [50-73], P < 0.001), presented a higher multiorgan dysfunction (61,2 % vs 55,4 %, P = 0.038), and required more invasive mechanical ventilation (70,6 % vs 65.1 %, P = 0.046), and prone position(18.9 % vs 13.0 %, P = 0.007). Patients with A(H3N2) had more comorbidities: COPD (30.4 % vs 19.5 %, P < 0.001), heart failure(18,6 % vs 10.0 %, P < 0.001), chronic renal failure(14,5 % vs 7,6 %, P < 0.001), and diabetes(23,9 % vs 15,3 %, P < 0.001). Patients with A(H3N2) presented more bacterial coinfection pneumonia (26,5 % vs 14,4 %, P < 0.001) and a higher vaccination rate (23,5 % vs 5,7 %, P < 0.001). Influenza A(H1N1) group have an increased ICU length of stay (LOS) (11 [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] vs 8 [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] , P < 0.001) but there is no difference in hospital LOS. No statistically significant difference in overall mortality was observed (21.9 % H1N1 vs 24.2 % H3N2, P = 0337). Conclusions: Our data suggest than Infuenza A subtypes have different clinical presentation in critically ill patients. Influenza A(H1N1)pdm09 affect younger patients with less comorbidities suffering an acute and more severe respiratory disease. Influenza A (H3N2) is presented more frecuently with bacterial coinfection in older patients with more chronic illness and especially CPOD. The overall mortality was high without differences between groups. Introduction: During the past ten years the paradigm of a "healthy lung is a sterile lung" was challenged [1] [2] [3] [4] [5] . The healthy lung appeared to be populated by multiple resident bacterial species, that migrate to the distal airways from the oral cavity [2] . According to the adapted island model the respiratory microbiome represents a dynamic community, where the equilibrium point is achieved by the balance between immigration and elimination mechanisms [6] . Objectives: We hypothesized that mechanical ventilation and antibiotic administration decrease the diversity of the respiratory microbiome and that these changes are more profound in patients who develop ventilator-associated pneumonia (VAP). Methods: Intubated and mechanically ventilated ICU-patients were included. Tracheal aspirates were obtained three times a week. 16S RNA sequencing with the Roche 454 platform was used to measure the composition of the respiratory microbiome. Associations were tested with linear mixed model analysis. The relative changes were compared between patients that did and did not develop VAP. There was a statistically significant increase in abundance of Pseudomonadales and a decrease in abundance of Lactobacillales, Gemellales, Actinomycetales and Clostridiales between the moment of intubation and extubation. There were no statistically significant differences between patients that did and did not develop VAP. Conclusions: Mechanical ventilation, but not antibiotic administration, was associated with changes in the respiratory microbiome. Duration of mechanical ventilation was associated with increased abundances of Pseudomonadales. The dynamics in the respiratory microbiome were not different between patients that did and did not develop VAP. Impact of immunosuppression on the incidence, etiology, and outcome of ventilator-associated lower respiratory tract infections: a post-hoc analysis of the Introduction: Severe community-acquired pneumonia (CAP) remains a significant cause of morbidity and mortality [1] . In the Netherlands the guidelines recommends a duration of antibiotic therapy in severe CAP for at least five till seven days. Objectives: The purpose of this trial was to evaluate whether procalcitonin measurements were able to reduce antibiotic usage in patients with severe CAP in Dutch intensive care units by reducing the duration of antibiotic treatment without increasing mortality or recurrent infections. Methods: From 2009 until 2013 a randomized intervention trial was performed in three university medical centres and 12 teaching hospitals in the Netherlands [2] . In this Dutch multicentre trial all patients admitted to the intensive care unit and who received antibiotics for presumed infection were assigned to a PCT-guided or standard-ofcare antibiotic discontinuation. In this study a sub analysis for all patients with a severe community-acquired pneumonia was performed. Stopping advice for antibiotics was provided when PCT was ≤20 % of its peak value or ≤0.5 ug/L. Mortality and duration of antibiotic treatment (DOT) were the primary endpoints of this study. Results: In 15 ICUs 440 patients with severe community acquired pneumonia were randomized for PCT-guidance (n = 208) or standard-of-care (n = 232). The median DOT was 5.5 (3-8) and 7 days (4-10) respectively (P < 0 · 001). No difference in reinstitution of antibiotics or CRP-levels within 28 days after randomization was observed. Mortality at 28 days was 43/208 (20.7 %) and 58/232 (25 · 0 %) in the PCT and standard-of-care group respectively (P = 0.31). One-year mortality was 63/208 (30.3 %) and 90/232 (38.8 %) in the PCT and standard-of-care group respectively. In this prospective randomized trial, the addition of PCT-measurements to assist intensivists in duration of antibiotic therapy in severe community-acquired pneumonia, resulted in a clear reduction of antibiotic treatment from 7 days (IQR 4-10 days) in the control group to 5.5 days (IQR 3-8 days) in the PCT-guided patient group, without increase of mortality or subsequent antibiotic prescriptions. Type of stress-ulcer prophylaxis and incidence of ventilator-associated pneumonia . Giving that such patients show an increasing risk of important gastrointestinal (GI) bleeding, stress-ulcer prophylaxis (SUP) has been recommended for the prevention of upper GI hemorrhage. SUP strategy rely on drugs that block the secretion of gastric acid and increase the gastric pH (histamine-2-receptor antagonists -H2RA, and proton pump inhibitor -PPI) and those that does not alter gastric pH (sucralfate). The increase of gastric pH leads to bacterial overgrowth and potential colonization of trachea determining a higher risk of VAP. [2] . Such VAP rate associated with PPI would seem to be linked to a greater antacid power than ranitidine. This can lead to a more extensive gastric bacterial colonization in patients treated with these drugs. Randomized-Controlled Trial of Stress-ulcer prophylaxis are needed to assess which drug show the highest risk of VAP and the relationship with the incidence of major GI bleeding. Conclusions: Physicians may be aware about the degree of hypoalbuminemia in the postoperative of CS due to its influence in outcomes, even in long-term survival. Relationship between factors associated with nutritional and inflammatory status may be associated with the development of postoperative hypoalbuminemia. Introduction: Post-operative pulmonary complications (POPC) are common with a reported incidence ranging from 2 %-40 %. Adverse outcomes include death, longer hospital stays and lower long term survival, which is independent of pre-operative risk. The most widely recognised prediction tool for POPCs is ARISCAT. Interventions to reduce POPCs have been studied individually but the use of a care bundle (CB) has not been widely investigated. Enhanced recovery (ER) pathways are 'standard of care' for major surgery -however some patients may benefit from additional focused interventions. An example of a CB for POPCs is the´I COUGH´study, which demonstrated a trend towards reduction in POPCs. Results may be superior if the intervention is targeted to a high-risk group. Objectives: 1) To perform a survey of members of the ESICM POIC section: to choose international experts for the Delphi and to share their opinions on a POPC-CB. 2) To recruit a team of experts to participate in and complete an email-based Delphi consensus, leading to the formulation of a CB. Methods: A SurveyMonkey of members of the ESICM POIC section was conducted. International experts were identified from this survey. A Delphi consensus was conducted anonymously via email over 3 rounds, to 36 independently chosen experts. Each round comprised of a series of statements which experts were asked to respond to using a five-point Likert scale. There were free text spaces for comments and the possibility for papers to be circulated. After each round, anonymous feedback was circulated to the Delphi group and the previous results were used to create the statements for the subsequent round. At the end of the process, final feedback was sent to the group with the consensus and suggested care bundle. Results: Survey: 362 respondents. ·Routine screening for high-risk of POPC occurs in 50 % of centres. ·Information about current practice in relation to various pre-, intraand post-operative interventions was ascertained. ·Almost 80 % of respondents would be happy to assess the feasibility of implementing a POPC-CB. Delphi: The preferred number of components in the POPC care bundle was 7. Care bundle elements supported by the consensus process were: ·PRE-operatively: a supervised exercise programme and inspiratory muscle training. ·INTRA-operatively: low tidal volume ventilation with individualised PEEP, use of routine monitoring to avoid hyperoxia and efforts made to limit neuromuscular blockade. ·POST-operatively: deep breathing exercises and mandatory elevation of the head of the bed. Conclusions: A POPC care bundle has been suggested for use, in addition to enhanced recovery pathways, in major surgical patients at high-risk of POPC. Prospective evaluation of feasibility, before an evaluation of effectiveness, is now indicated. The development and impact of implementation of a quality improvement care pathway for patients undergoing an emergency laparotomy J. Doyle 1 , P. Introduction: 80 % of UK in-hospital surgical mortality occurs in those undergoing high-risk surgical intervention such as emergency laparotomy (EL) (1) these patients are among the largest consumers of hospital resources (2, 3) . Furthermore it was suggested that UK outcomes are worse than comparable countries (4). In the 2011 review of peri-operative care of high-risk patients NCE-POD reported care was good in less than half of patients leading to considerable health and financial costs (5). As such there was a clear need for a change in the approach to patients having an EL. Since this study the first national emergency laparotomy audit (NELA) has been published demonstrating a 30-day mortality of 11 % (6). Objectives: The aims were to create a focused, evidence-based Emergency Laparotomy Pathway (ELP) delivered by a multidisciplinary (MDT) team, utilising care bundles to improve delivery of care and assess the impact of the pathway on hospital mortality and length of stay (LOS). Pathway design: A Emergency Laparotomy Group (ELG) was convened and designed the ELP based on principles of best basic practice and the recommendations of the RCS (2) and NCEPOD (5) . The ELP covered the entire surgical stay of the patient in 4 stages. Study protocol: Data was collected for consecutive patients, 50 pre and 96 post-ELP during 2011/2012. The primary outcome measure was in hospital mortality. Secondary outcomes were ICU mortality, ICU and hospital LOS. Results: The in-hospital mortality fell from 21.7 % Pre-ELP to 9.6 % Post-ELP (p = 0.048). There is a strong trend towards significance in a survival analysis (p = 0.053). There was no significant difference in hospital LOS between Pre and Post cohorts. (Median 15.5 days vs 15 days, p = 0.875). There was no difference in the ICU LOS (3 vs 2 days, p = 0.3339), nor in the utilisation of high level beds. Conclusion: The introduction of an ELP reduced the in hospital mortality significantly, this has since been further evidenced with a 4centre (including our own) study demonstrating a case-mix adjusted decrease risk of death from 15.6 % to 9.6 %, p = 0.002 (7) . ELP is a useful tool reducing the risk of failure to deliver optimal care. Objectives: This study aimed to demonstrate whether a sedation strategy using dexmedetomidine was superior to that without dexmedetomidine in septic patients, in terms of 28-day mortality and ventilator-free days within a 28-day period. Methods: A multicenter randomized controlled trial was conducted to evaluate the dexmedetomidine-based strategy in septic patients in eight ICUs. We included adult septic patients who were expected to require mechanical ventilation for at least 24 hours. Patients were randomized to receive sedation strategy either with dexmedetomidine (DEX group) or without dexmedetomidine (non-DEX group). Additionally, fentanyl, propofol, and midazolam were used as required to achieve the sedation goal in both groups which was set to Richmond Agitation Sedation Scale 0 (calm) for daytime and −2 (light sedation) for nighttime. Results: We included 201 patients (mean age 68.8 years), of whom 127 (63 %) were men. Mean Acute Physiology And Chronic Health Evaluation (APACHE) II score was 23. The baseline characteristics were similar between groups. In the DEX group, well-controlled sedation rate was higher (p = 0.002) and delirium rate was lower (p = 0.03) during ventilation compared with those in the non-DEX group. At 28 days, 19 of 100 patients (19 %) in the DEX group and 28 of 101 patients (28 %) in the non-DEX group had died (p = 0.14). The ventilator-free days in a 28-day period did not differ between the groups, at 22 days (interquartile range [IQR], 17-25) and 21 days (IQR, 15.5-24.5) (p = 0.49). In a predefined subgroup analysis that included 104 patients with APACHE II score of 23 or more, 28-day mortality in the DEX group was significantly lower than that in the non-DEX group (odds ratio 0.40, 95 % confidential interval 0.17-0.93). Conclusions: A sedation strategy using dexmedetomidine compared with a strategy without dexmedetomidine induced well-controlled sedation in ventilated septic patients but did not significantly improve 28-day mortality and the number of ventilator-free days. Although more critically ill patients may benefit from a dexmedetomidine strategy, further studies are needed to confirm this result. Pandharipande PP et al. Crit Care 2010; 14: R38. The design of this study was supported in part by Hospira Japan who also provided a non-contractual research grant to Wakayama Medical University for start-up purposes. However, data collection, data management, statistical analyses, interpretation and manuscript preparation were conducted solely by the academic investigators without any support from pharmaceutical companies. The Institute for Clinical Effectiveness, a non-profit academic research organization, supported the implementation of this study. Lower versus higher haemoglobin threshold for blood transfusion in septic shock: exploratory subgroup analyses of a randomised trial S.L. Rygård 1 , L.B. Holst 1 , J. Wetterslev 2 , P.I. Johansson 3 , A. Perner 1 Introduction: Using a restrictive transfusion strategy appears to be safe in critically ill patients [1, 2] but there may be subgroups of patients benefiting from transfusion at a higher haemoglobin level [3] . Objectives: We explored if subgroups of patients with septic shock had worse outcome when transfused at a lower versus a higher haemoglobin threshold. Methods: By performing post-hoc analyses of the whole trial population of 998 patients from the Transfusion Requirements in Septic Shock (TRISS) trial [2] , we investigated the intervention effect in patients with severe co-morbidity (chronic lung disease, haematological malignancy or metastatic cancer), patients who had undergone surgery (either elective or acute) and patients with septic shock as defined by the new definition of septic shock: lactate above 2 mmol/l and treatment with vasopressors [4] . Results: The baseline characteristics were mostly similar between the 2 intervention groups in the different subgroups. There were no differences in the intervention effect on 90-day mortality in patients with chronic lung disease (test of interaction P = 0.31), haematological malignancy (P = 0.47), metastatic cancer (P = 0.51), septic shock by the new definition (P = 0.20) or in those who had undergone surgery (P = 0.99), see Table. Conclusions: In exploratory analyses of a randomised trial in patients with septic shock, we observed no mortality benefit in any subgroups of transfusion at a haemoglobin threshold of 90 g/dl vs. 70 g/dl. Introduction: At discharge from the Intensive Care Unit (ICU) physicians may integrate information of a patient's condition before ICU admission (medical history, functional status, quality of life) with the sequence of events during the ICU stay to estimate the prognosis of future well-being [1, 2] . In 2006, the Sabadell group developed a simple but subjective prognostic score which made this prognosis explicit [1, 2] . However, the Sabadell score has not been validated beyond hospital survival or for long-term health related quality of life (HRQoL). Objectives: To compare ICU physicians' subjective long-term prognosis with the observed long-term survival and HRQoL. Methods: The first admissions of all patients discharged alive from the ICU of the University Medical Center Utrecht between March 2012 and December 2014 were included in the study. The Sabadell score was determined and recorded by the treating physician at the time of ICU discharge ('0 -Good prognosis', '1 -Poor long-term prognosis (>6 months) with unlimited ICU readmission', '2 -Poor short-term prognosis (<6 months); ICU readmission debatable', or '3 -Death expected during hospitalisation, ICU readmission not recommended'). Survival status was verified using the municipal registry one year after ICU discharge. In one-year ICU survivors HRQoL was measured using the EuroQoL 5D-3L TM index score, dichotomized at 0.4 into high or low HRQoL. The analyses included agreement between Sabadell score and one-year outcome categories, and a description of correctly and incorrectly estimated prognosis groups. Results: Of the 4,874 eligible patients, 3,796 (77.9 %) had completed follow-up and were included into the study (see Fig. 32 ). In-hospital mortality was 3.1 %, 9.3 %, 39.1 % and 81.6 % for the Sabadell scores 0-3 respectively. In 2,849/3796 (75.1 %) the Sabadell score accurately predicted one-year outcome (Fig. 33) . Table 15 shows patient characteristics for the study population, and the groups where prognosis was over-and underestimated respectively. Compared to patients with a correct estimate of prognosis, both patient groups with over-or underestimated prognoses were more often admitted for non-surgical reasons, and more severely ill at admission and during ICU stay. Conclusions: In three out of four patients, the Sabadell score was in accordance with one-year prognosis. Only in less than 10 % of patients surviving ICU there was major disagreement between a physician's prediction and the observed long-term outcome. Introduction: Early and enhanced rehabilitation of patients in critical care is associated with improved patient outcomes (1). We have previously published the results of a quality improvement project promoting early and enhanced rehabilitation for patients mechanically ventilated for greater than 5 days, and shown an improvement in mobility levels at ICU discharge that was associated with a significant reduction in ICU and hospital length of stay, ventilator days and inhospital mortality (2) . The impact of such mobility programs on longer term outcomes is unknown. Objectives: To assess the 3 year mortality of patients mechanically ventilated for more than 5 days and who survived to ICU discharge pre and post a quality improvement project enhancing rehabilitation on critical care. Methods: The study took place within a large, tertiary referral ICU. A supportive rehabilitation team was created within the ICU in April 2012 with a focus on promoting early and enhanced rehabilitation for patients at high risk for prolonged ICU and hospital length of stays. The intervention has been described in detail in a previous publication, and was successful in improving mobility levels at ICU discharge. For all patients who survived to ICU discharge, mortality at 3 years was assessed. Introduction: Admission to the ICU deeply impacts on post-ICU mortality and quality of life, but the information on the issue is still scarce(1). Objectives: To analyze epidemiological data and evolution of patients on mechanical ventilation (MV) in the ICU and to define independent variables associated to long-term (1 year) mortality. Methods: National, prospective, multicenter cohort study sponsored by the Argentinian Society of Intensive Care Medicine, including patients receiving MV >72 hr (3/5-8/31/2014). Epidemiological and evolution variables were recorded, and after hospital discharge patients/their relatives were interviewed face-to-face or by telephone at 2, 6 and 12 months. Comparisons were made between survivors (S) and nonsurvivors (NS). Data are analyzed according to their nature; a p < .05 was considered significant. Independent predictors of post-ICU mortality were identified by logistic regression. Results: 320 patients from 26 hospitals across Argentina were included. The data are shown on Tables 16, 17 and 18. Global post-ICU mortality was 22 %; respectively 15 %, 5 % and 2 % at 2,6, and 12 months post hospital discharge. Independent predictors of mortality were: age (OR 1.07[.04-1.08;]; p 0.000) and SOFA 24hs (OR 1.12[1.02-.1.23];p 0.013). Calibration and discrimination of the model were adequate (GOF 0.407; AUROC 0.79, respectively). Conclusions: 1. Most patients were middle-aged men, admitted to public hospitals for medical causes, 60 % with ≥1 comorbidities and very acutely ill, according to APACHE II and SOFA scores. 2. Complications as ARDS, shock and infections were frequent, occurring in more than a half of patients. 3. 1-year mortality was 22 %. Most patients died within two months after hospital discharge. Yet no single ICU event was associated with post-ICU mortality; only age and organ failures were independent predictors of this outcomes. This study was supported by de Argentinian Society of Intensive Care (SATI). The outcomes of patients with severe dengue admitted to intensive care units Introduction: To survey the outcome of patients with dengue infection admitted to intensive care unit (ICU). Objectives: Because the outcome of adult patients with dengue infections requiring ICU admissions remains unclear, this study was conducted to assess the clinical manifestations and the prognostic factors of critical ill patients with severe dengue. Methods: This study was conducted in a tertiary referral hospital of 96 adult ICU beds. In this retrospective study, all of the patients with laboratory-confirmed severe dengue infections and admitted to ICU were enrolled between July 31 and November 31 in 2015 during the large outbreak period. The medical records of all the recruited patients were retrospectively reviewed and the following information was collected: age, gender, clinical manifestations, disease severity scores, underlying conditions, laboratory examinations, and outcome. The primary endpoint is to find the predictors of in-hospital mortality. Results: During study period, there were a total of 4787 patients with dengue infections, and 143 (2.99 %) patients with severe dengue infection required ICU admission. Among 143 critically ill patients, their mean age was 69.7 years. Hypertension (n = 90, 62.9 %) and diabetes mellitus (n = 70, 49.0 %) were the two most common underlying diseases. Eighty patients (55.9 %) had co-bacterial infections, and 33 patients had co-bacteremia. Hematologic system was the most common failure organ, followed by chest and cardiovascular systems. Fever was the most common presentation (n = 112, 78.3 %), followed by anorexia (n = 47, 32.9 %), and abdominal pain (n = 46, 32.2 %). Overall, a total of 33 patients had mortality, and the rate of mortality was 23.1 %. In multivariate analysis, we found that in-hospital mortality was significantly associated with lower Glasgow coma scale, lower platelet count before ICU discharge, and higher number of organ failures. Conclusions: The outcome of severe dengue patients requiring ICU admission remains high and the mortality was associated with lower Glasgow coma scale, lower platelet counts and more organ failures. Additionally, more than half of patients would have bacterial infections during severe dengue infections. Introduction: Critical illness is marked by hypermetabolism and increased protein catabolism. While studies suggest that protein delivery may be beneficial for critical illness outcomes, to date, limited information exists regarding the association between protein delivery during hospitalization and outcomes in ICU survivors following hospital discharge. Objectives: We hypothesized that higher protein intake might have a protective effect in patients with malnutrition. Methods: We performed a single center observational study of patients treated in medical intensive care units in Boston, Massachusetts. We studied 801 patients age ≥ 18 years, who received critical care following between 2004 and 2011 and survived to hospital discharge. All patients underwent a Registered Dietitian formal assessment within 48 hours of ICU admission. The exposure of interest, grams of protein per kilogram body weight delivered per day, was determined from all oral, enteral and parenteral sources for up to 28 days. Nutrition status was categorized as non-specific malnutrition, protein-energy malnutrition, or at risk for malnutrition via anthropometric measurements, clinical signs of malnutrition, malnutrition risk factors, and metabolic stress. The primary outcome was all cause 90-day post-discharge mortality. Adjusted odds ratios were estimated by mixed-effects logistic regression models to describe how 90-day post-discharge mortality differed with changes in protein delivery. Conclusions: In adult MICU patients who survive to hospital discharge, protein intake appears to be predictive of out of hospital outcomes. Patients with improvements in protein intake during hospitalization independent of energy intake have decreased mortality in the 3 months following hospital discharge. The achievement of ideal protein delivery may be an important factor in ICU survivorship, especially in malnutrition. Introduction: SMOFlipid 20 % is intravenous lipid emulsion (ILE) containing long-chain triglycerides (LCT), medium-chain triglycerides(MCT), olive oil, and fish oil as a mixed emulsion containing αtocopherol. The aim was to assess the efficacy of this new ILE in surgery compared with MCT/LCT,and it was tested for safety, tolerance, metabolic and clinical efficacy in surgical patients. Objectives: To assess the efficacy of this new ILE in gastrointestinal surgery compared with MCT/LCT. Methods: In this prospective study, 42 patients were randomized to SMOFlipid 20 % or MCT/LCT (Lipovenoes 20 %) group. Clinical and biochemistry data were collected. Inflammatory markers (CRP, IL-6) and liver function indicators (ALT,AST,TBIL)were measured. Results: 32 patients (17 males and 15 females) with a mean age of 51 years completed the study. The patients' baseline datas(age, gender, APACHE II) were similar in two groups(p > 0.05). The patients' baseline datas(age, gender, APACHE II)were similar in two groups.The increment of triglyceride on day 5 from baseline was significantly lower in SMOFlipid group than in Lipovenoes MCT/ LCT group(P < 0.05). The concentrations of alanine transaminase (ALT), aspartate transaminase (AST) and totalbilirubin on day 5 were significantly lower in SMOFlipid group than in control group(P < 0.05). Inflammatory markers (CRP, IL-6)were not different between groups(P > 0.05). Conclusions: SMOFlipid had a better triglyceride-lowering effectas compared with MCT/LCT and may be associated with a better liver tolerance in surgical critically ill. Dexmethasone-induced muscular atrophy is mediated by the expression of functional connexin based hemichannels Introduction: Muscle atrophy is one of the most important and frequent problems observed in patients in Intensive Care Units (ICU). Several mechanisms and risk factors have been described to explain this syndrome. Glucocorticoids, which are frequently used in ICU, induce muscle atrophy, but the mechanism still remains to be elucidated. Connexin based hemichannels (Cx HCs), are channels formed by six connexin proteins and communicates the intra with extra cellular space since they are permeable to ions and small molecules (e.g., ATP). Recently, CxHCs have been associated to denervationinduced skeletal muscle atrophy (1), and may also participate in the pathogenesis of corticoids induced muscle atrophy. Objectives: To evaluate the possible involvement of Cx HCs in dexamethasone-induced muscular atrophy. Methods: C57Bl/6 wild type (WT) mice and Cx HCs knock out (KO) mice (Cx43fl/flCx45fl/fl and Cx43fl/flCx45fl/fl:Myo-Cre) mice were used. KO mice were skeletal muscle deficient for connexin 43 and 45. Also, Lanthanum, a connexin blocker, was used in experiments. Presence and functionality of Cx HCs was evaluated acutely after 5 hours of dexamethasone exposure, by cellular Ethidium uptake, Evans blue permeability, intracellular free Ca2+, resting membrane potential, immunohistochemistry, and western blot. NFkb Phosphorylation and mRNA levels of TNF-alpha were also assessed. Finally, muscle atrophy was evaluated by cross sectional area (CSA) after 7 days of dexamethasone exposure. Also, atrogin-1 and MurF-1, which are two E3 ligases from ubiquitinproteasome system (intracellular degradation system), levels were evaluated. Results: Freshly isolated myofibers from mice treated with dexamethasone by 5 h showed de novo expression of functional connexins 39, 43, 45 and pannexins (P2X7R) which were mainly distributed on sarcolemma. Cx HCs expression was present only in WT myofibers, was blocked by La, and was absent in KO mice. Accordingly, a significant increase in basal intracellular free Ca2+ levels, and a decrease of resting membrane potential of about 10 mV, was observed in myofibers from WT mice treated with dexamethasone compared with mice injected with saline buffer or in KO mice. Moreover, dexamethasone induced the phosphorylation of NFkb and increased the mRNA levels of TNF-alpha. Finally, seven days treatment with dexamethasone drastically reduced the CSA of myofibers from WT mice but not KO animals. Both, atrogin-1 and MurF-1 were elevated in WT animals in comparison with KO mice. Conclusions: Dexamethasone induces the expression of Ca2+ permeable channels such as connexins, which leads to muscle atrophy. Connexins are upstream to the activation of the ubiquitinproteasome system. Connexins are a novel family of proteins which should be studied for prevention of corticoids-induced muscle atrophy. Comparison of two indirect calorimetry devices at varying levels of inspired oxygen M.K. Poulsen 1 , L.P. Thomsen Introduction: The administration of tranexamic acid to trauma patients with risk of haemorrhage is one of only seven treatments shown to improve mortality in critically ill patients in multi-centre randomized controlled trials [1, 2] . Nonetheless, four years on from CRASH-2, the implementation of this simple, low risk intervention, which has the potential to save 600 lives a year in the UK, remains suboptimal [3] . Objectives: To measure the proportion of trauma patients deemed to be at risk of haemorrhage (as evidenced by the administration of a first dose of tranexamic acid) that correctly received the second dose of tranexamic acid. We designed a quality improvement project to improve compliance with this measure, and here we report preliminary Results: Methods: All patients admitted under a 'trauma call' between January 2015 and January 2016 at the John Radcliffe Hospital in Oxford, a major trauma centre in the United Kingdom, were included in our study. Tranexamic acid administration information was collected for all patients. Interventions included disseminating tranexamic acid information to trauma doctors verbally and during departmental induction. We also added both doses of tranexamic acid into the electronic prescribing bundle for trauma patients in our hospital. Further interventions are ongoing. and an early focus on inter-specialty collaboration is our key recommendation to centres who intend to implement similar initiatives. Introduction: Emergency physicians are required to assess the severity of patient's illness and predict their prognosis with restricted situation at emergency department (ED). Trauma is one of the most severe injuries at ED and its outcome highly depends on initial appropriate management. Therefore, several scoring systems have been developed on the last decade. However, the environment on ED has changed and physicians have been still occasionally misled. Objectives: Vital signs are widely used in both emergency medical service and ED. It is a role of not only the static parameter but also the dynamic one to help emergency physicians classify trauma patients' severity. Thus, we aimed to analyze the association between changes in vital sings (ΔVS) and in-hospital mortality among trauma patients. Methods: This study was multicenter observational retrospective study from Japan Trauma Data Bank. It consisted of major emergency hospitals in Japan from January 2004 to December 2013. In this period, a total of 159,157 trauma patients were registered. Of these, 75,833 patients (48 %) were analyzed since all vital signs (systolic blood pressure, heart rate, and respiratory rate) were available both at site and at ED. We developed a new scoring system to predict in-hospital mortality for trauma patients using three ΔVS and age. The patients were judged on these 4 items with one point added for each positive one; when systolic blood pressure decreased more than 30 mmHg, heart rate increased more than 20/min, respiratory rate increased 10/min, or old (age ≧65). Results: Mean age (±SD) was 54 (±24) years old. 29,309 (39 %) were aged over 65 years old. 25,854 (34 %) were women. Overall, inhospital mortality rate was 5,834 (7.7 %). The in-hospital mortality rate increased from 6.4 % to 18.9 % when systolic blood pressure decreased more than 30 mmHg. In a similar way, it increased from 7.0 % to 16.5 % when heart rates increased 20/min. Also, it increased from 7.5 % to 10.7 % when respiratory rates increase 10/min. Old patients (> = 65 years old) had severe outcome than young adults (it increased from 5.1 % to 11.8 %). As using our scoring system, inhospital mortality rate increased: 0 point was 3.5 %; 1 point was 9.5 %; 2 points was 18.5 %; 3 points was 33.0 %; and 4 points was 48.6 %. The area under the ROC curve of this predictive model was 0.675 (95 % CI 0.668-0.683). Conclusions: Our new trauma scoring system, ΔVS scoring system, which focus on changing vital signs, predicts in-hospital mortality. It is useful to improve that emergency physician's decision and identification of patients who need critical care. Introduction: Systemic hypotension is a predictor of increased mortality in patients with traumatic brain injuries. Post-intubation hypotension (PIH) has been demonstrated to be common and associated with poor patient outcomes in other critically ill patient populations requiring emergent endotracheal intubation (ETI). The importance of PIH remains unclear in the trauma population. Objectives: To determine the incidence of PIH in adult trauma patients and assess the association of PIH with mortality. Methods: This study was a retrospective case series of adult (≥16 years) trauma patients requiring intubation after referral to a provincial trauma team located in a level 1 center in Halifax, Nova Scotia, Canada between 2000 and 2015. PIH was defined as (a) decrease in systolic blood pressure (SBP) to < 90 mmHg; (b) reduction in SBP of 20 % from baseline; (c) decrease in mean arterial pressure to < 60 mmHg; or (d) initiation of, or increased infusion dosage of, any vasopressor medication (bolus or infusion) during the 15-minute period after ETI. Data was collected from a provincial trauma registry and the patient chart, and included demographics, co-morbidities, trauma characteristics, intubation time, as well as all fluids, medications, adverse events, interventions, and vital signs during the 15 minutes before/after ETI. We evaluated the incidence of PIH and created a logistic regression model to determine the likelihood of mortality in the PIH and non-PIH groups after controlling for gender, age, intubator, mechanism of trauma, injury severity, traumatic brain injury and volume of fluid administered. Results: Overall, 477 patients arrived unintubated and required ETI by the trauma team over the study period, of which 444 patients met eligibility criteria and were included in the analysis. The incidence of PIH was 35.6 % (158/444) in our study population. In- Introduction: Recently, the population of elderly people has been increasing rapidly all over the world. Especially, Republic of Korea is now progressing to an aging society. The social activities of the aging population have increased, which has also increased the number of elderly patients injured. Objectives: The aim of this study is to analyze the clinical characteristics and injury pattern of geritaric patients involved in trauma. Methods: This study was conducted retrospectively from January 2015 to March 2016 among trauma patients who visited single trauma center in Seoul, Korea. The patients divided in two groups, a geriatrics group and an adult group on the basis of an age of 65. Patients under 18 years of age were excluded. The variables related with trauma were extracted and compared. Results: Total number of the included patients was 384, and the number of elderly patients was 74. There were no significant differences in Revised Trauma Score (RTS), intensive care unit (ICU) admission, hospital stay between the two groups. There were differences in the mechanism and the locations of the injury, gender, injury severity score (ISS), trauma and injury severity score (TRISS), mortality, drinking at admission between the two groups. Most common injury mechanism in the adult group was driver traffic accident (24.5 %) and in the geriatric group was pedestrian traffic accident (45.9 %). Injury of extremity (44.8 % vs 59.5 %) (p = 0.028) was more common in the geriatric group than in the adult group. And female patient was more common in the geriatric group (26.8 % vs 40.5 %) (p = 0.020). The average ISS of the geriatric group was higher than that of the adult group (17.8+/−11.52 vs. 14.0+/−12.06, p = 0.015). The mortality was higher in the geriatric group (14.9 %) than in the adult group (4.5 %) (p = 0.003). But drinking at admission was higher in the adult group (33.9 % vs 10.8 %) (p < 0.00). Conclusions: The mortality rate and the average ISS were greater within the geriatric group than the adult group despite there was no difference in the RTS, ICU admission. Also elderly people were prone to pedestrian traffic accident with the lower drinking rate compare than the adult group. Introduction: Sepsis is a dynamic medical condition where patientsć linical status can change rapidly in either direction. Different biomarkers and scores have been studied to assess sepsis severity and prognosis. Procalcitonin, C-reactive protein and interleukin-6 are biomarkers referred as helpful to follow evolution and outcomes. APA-CHE II model was developed to predict hospital outcomes, based on data from the first 24 hours. SOFA score describes the degree of organ dysfunction over time and evaluates morbidity, but has been used also for predicting mortality. Objective: Our aim was to study the ability of different biomarkers (procalcitonin, C-reactive protein and interleukin-6) and scores (APA-CHE II and SOFA), determined on day 1, to predict outcome in septic patients. Besides, we studied sequential SOFA score to find out its dynamics at early sepsis and its correlation with mortality. Methods: We assessed 48 consecutive septic patients admitted to our medico-surgical ICU. Procalcitonin, C-reactive protein and interleukin-6 were determined on day 1. APACHE II was calculated on day 1, and daily SOFA score was calculated for 5 consecutive days, determining also the maximum SOFA. Mann-Whitney U test and ROC curves were carried out to study association of these variables with 28-day mortality. Results: In our cohort of septic patients (mean age 69 ± 13) there were 43 survivors and 5 non-survivors. Procalcitonin, C-reactive protein and interleukin-6 did not show correlation with 28-day mortality. APACHE II, SOFA scores on days 1 and 2, and maximum SOFA, also showed no correlation with 28-day mortality. However, when analyzing SOFA scores on days 3, 4 and 5, we found significant lower scores in survivors compared to non-survivors: SOFA-3 (p = 0.048), SOFA-4 (p = 0.016), and SOFA-5 (p = 0.018). The ROC curve analysis also showed association with 28-day mortality: SOFA-3 (AUC 0.772, p = 0.048), and stronger for SOFA-4 (AUC 0.823, p = 0.019), and SOFA-5 (AUC 0.820, p = 0.021). Conclusion: Day 1 values for procalcitonin, C-reactive protein, interleukin-6, APACHE II and SOFA did not correlate with outcome. But, low SOFA scores on day 3, and specially in days 4 and 5, are good predictors of survival, meaning that after 48 hours of admission, regardless of the initial score, those patients with a low SOFA score have higher probability to survive. While SOFA scores at admission, and maximum SOFA, had bad performance in predicting mortality, sequential SOFA scores add information on the course of the disease, and improve the ability to predict the likelihood of survival. Larger studies are required to find out SOFA based prediction models with improved accuracy. Predictors of hospital mortality were identified by backwards binary logistic regression in a derivation cohorts separately for each severity group. Performance of models was tested in validation cohorts. Models were then fitted with the selected predictors for the different severities in all cases and predicted mortality risk was calculated. Combined model performance across all severities was assessed by discrimination using the "area under the curve" (AUC), by calibration plotting observed against predicted mortality over risk quantiles, and by explained variance. Results: 441 207 cases with sepsis without organ dysfunction (hospital mortality 13,5 %), 284 883 with severe sepsis (mortality 40,3 %) and 112 609 with septic shock (mortality 59,6 %) were identified. 41-43 of 53 assessed predictors remained in the final models. Overall discrimination (Fig. 36 ), explained variance (R 2 = 0.25), and calibration ( Fig. 37 ) were good. Strongest risk factors were age and advanced liver and hemato-oncologic disease. A urogenital focus and sepsis as main diagnosis were associated with lower hospital mortality. Mortality decreased from 2010 to 2013 for sepsis (p < 0.0001) and severe sepsis (p < 0.0001) but not for septic shock (p = 0.11). Conclusions: We developed a well performing risk adjustment model for sepsis mortality in German administrative data. This enables comparisons and benchmarks from administrative data in Germany. Hospital characteristics will be included into the model in the next development step. Methods: The review process followed guidelines consisting of 5 steps suggested for systematic reviews. Relevant studies from January 2000 to December 2015 were obtained from electronic databases. Standards for Reporting of Diagnostic accuracy (STARD) and Quality Assessment of Diagnostic Accuracy Studies instrument (QUA-DAS-2) were used to assess individual study quality and bias. Med-Calc statistic software was used to assess and combine the data and diagnostic accuracy across studies. Pooled diagnostic odds ratio and area under The ROC Curve (AUC) analysis was used to evaluate the prognostic accuracy of MEWS tool. Introduction: Recent guidelines on the definition of sepsis from the Sepsis 3 working group have suggested the use of a simplified version of the SOFA score as an initial way to screen for sepsis (1) . This score allocates a point each for new altered mentation (GCS < 15), respiratory rate greater than 22 and a systolic blood pressure < 100 mmHg. It has been given the term qSOFA based on the original SOFA (sepsis related organ failure assessment). The purpose of the score is to identify patients early with sepsis as dealy in recognition is associated with an increased mortality and increased length of stay. We decided to evaluate whether the qSOFA score when applied to ICU patients could be validated for use in our patient population. Methods: A historical patient cohort was identified by searching the WardWatcher CIS dataset for all patients admitted from 01/01/204 -31/12/2014 to a five bedded teaching hospital Intensive Care Unit in Glasgow. These patients demographic data was collected along with the parameters from qSOFA (as above) along with outcome data. After removal of patients with incomplete datasets, statistical analysis was performed. Results: There were 3357 patients included in the study, with analysis of 1353 due to incomplete qSOFA data. Baeline data for these patients was as follows: 58.9 % male, mean age 57.4 +/− 0.9 years, mean APACHE-II score 19.7 +/− 0.5, mean predicted mortality 37 +/− 1.5 %, mean length of stay 5.0 +/− 0. days and mortality of 33 %. Using the available data from Wardwatcher we generated qSOFA data as below. Conclusions: As can be seen from above there is a good correlation between the qSOFA and APACHE-II in terms of recognition of severity. There is a significant correlation between qSOFA and increased length of stay and mortality. This would suggest that qSOFA is a quick and useful tool that can be used on ICU admission to aid prognostication which can assist in discussions with patients, relatives and colleagues. Introduction: Hyperglycaemia occurs frequently in the critically ill and may be secondary to either diabetes (recognised or not), or stress induced hyperglycaemia. Stress induced hyperglycaemia occurs in patients who have normal glucose tolerance following resolution of their acute illness. Whether stress induced hyperglycaemia unmasks latent insulin resistance and/or impaired β-cell function has not been adequately explored. Objectives: To evaluate the association between stress induced hyperglycaemia, the development of diabetes and long-term mortality in survivors of critical illness. Methods: This is a retrospective, multi-centre observational study. All adult patients surviving admission to a tertiary intensive care unit (ICU) in South Australia between 2004 and 2011 were included. Stress induced hyperglycaemia was defined as a blood glucose ≥ 11.1 mmol/l within the first 24 hours of ICU admission. Prevalent diabetes was identified through ICD-10 coding or prior registration with the Australian National Diabetes Service Scheme (NDSS). Incident diabetes was identified as NDSS registration > 30 days after hospital discharge until July 2015. The predicted risk of developing diabetes was described as sub-hazard ratios using competing risk regression. Survival was assessed using Cox proportional hazards regression. Results: Stress induced hyperglycaemia was identified in 2,883 (17 %) of 17,074 patients without diabetes. The overall incidence of subsequent type 2 diabetes following critical illness was 4.8 % (821 of 17,074). The risk of diabetes in patients with stress induced hyperglycaemia was approximately double that of those without (HR 1.91 (95 % CI 1.62, 2.26), p < 0.001) and was sustained regardless of age or severity of illness. Subdividing age into approximate deciles the greatest risk was seen in the 50-59 year age group with over a seven-fold risk (HR 7.90 (5.38, 11.60), p < 0.001). Stress induced hyperglycaemia was not associated with increased long-term mortality in patients who survived their hospital admission. Conclusions: Stress induced hyperglycaemia within 24 hours of admission to the ICU identifies patients at greater risk of subsequent diabetes. This project was supported by grants from the Diabetes Australia Research Trust and a University of Adelaide, Discipline of Acute Care Medicine Maurice Sando Project Grant. Identifying an optimal target for blood glucose management among critically ill patients: a network meta-analysis T. Yatabe 1 , S. Introduction: Although several clinical guidelines recommend maintaining blood glucose between 144 and 180 mg/dL, these are insufficient evidences to assess the benefit and harm of this glycemic target. Objectives: We conducted a network meta-analysis to assess the impact of glycemic target 144-180 mg/dL on the incidence of hypoglycemia, the risk of infection and mortality in compared with other glycemic target as < 110 mg/dL, 110-144 mg/dL and >180 mg/dL. Methods: We considered all studies from three recent systematic reviews [1] [2] [3] and searched the PubMed database for studies that compared target blood glucose levels among critically ill patients. The primary outcomes were in-hospital mortality, and the secondary outcomes were the incidence of hypoglycemia, and risk of sepsis or bloodstream infection. Results: We identified 71 studies through the re-analysis of the three systematic reviews, and 431 studies through the PubMed search. Thirtynine potentially eligible studies were considered for inclusion, although 12 studies were excluded after screening the full texts. Thus, the network meta-analysis included 14,495 patients from 27 studies. The mean patient age was 61.6 years, and 21.7 % of the patients had diabetes. There was no significant difference of in-hospital mortality and risk of sepsis or bloodstream infection among 3 glycemic bands (<110 mg/dL, 110-144 mg/dL and 144-180 mg/dL). Target blood glucose levels of 144-180 mg/dL had significantly lower in-hospital mortality and risk of sepsis or bloodstream infection in compared with >180 mg/dL (odds ratio [OR]:0.82, 95 % credible intervals [CI]: 0.69-0.96; OR: 0.69, 95 % CI: 0.52-0.92, respectively). Our network meta-analysis revealed that target blood glucose levels of < 110 mg/dL and 110-144 mg/dL were associated with a 6-7 fold higher risk of hypoglycemia, compared to targets of 144-180 mg/dL and >180 mg/dL. There were no significant differences in the risk of hypoglycemia between < 110 mg/dL and 110-144 mg/dL (OR = 0.76 (95 % CI: 0.49-1.11). There were also no significant differences in the risk of hypoglycemia between and between 144-180 mg/dL and >180 mg/dL (OR = 1.0 (95 % CI: 0.30-2.70). The rank probability analysis indicated that a target blood glucose level of 144-180 mg/dL had the highest probability of being the best target blood glucose level for reducing hypoglycemia and hospital mortality rates and was the second best target level, following a target level of 110-144 mg/dL, for reducing sepsis or bloodstream infection rates. The results of our network meta-analysis indicate that target blood glucose levels of 144-180 mg/dL is an optimal target for balancing the risks and benefits of insulin therapy among critically ill patients. Introduction: Diabetes is a risk factor for the development and severity of critical illness, and the need for Intensive Care Unit (ICU) admission. Despite this, diabetes does not confer a greater risk of death for those with critical illness within the index hospital admission. However, long-term outcomes in patients with diabetes who survive ICU admission remain unknown. Objectives: Our objectives were to evaluate the effect of diabetes on both long-term survival rates and average years of life lost for patients admitted to ICU and who survived hospitalisation. Methods: We evaluated all adult patients in South Australia between 2004 and 2011 who survived hospitalisation requiring admission to a Public Hospital ICU. Demographic and admission data from the Australia and New Zealand Intensive Care Society Adult Patient Database were linked to population based datasets to match (i) International Classification of Disease (ICD-10) codes for diabetes through the Department of Health Integrated South Australian Activity Collection dataset, (ii) diabetes diagnosis in the national register (the National Diabetes Service Scheme), and (iii) mortality through the Australian National Death Index. Life years lost were calculated using age and sex specific life-tables from the Australian Bureau of Statistics. Data are presented as frequencies and proportions for categorical variables and mean (standard deviation) or median [interquartile range] for continuous variables. Between group comparisons were performed by t-test, Wilcoxon rank-sum or Chi-square tests. Longitudinal survival was analysed using Cox proportional hazards regression and average life years lost by linear regression. Results: 5451 patients with and 17022 patients without diabetes were included. Patients with diabetes were older (64.7 (14.9) vs 57.6 (19.7) years; p < 0.0001) and had higher illness severity on admission to ICU ( Introduction: Glycated hemoglobin A1c (HbA1c) is used to estimate chronic glycemic control. Recently, several studies suggested that the optimal glycemic control in acutely ill patients might be better being adjusted according to the premorbid chronic glycemic control (1-3). However, the majority of patients would not have been measured the HbA1c-level prior to the acute illness. As the HbA1c-level would be affected by the patients' conditions, HbA1c-levels during an acute illness may not reflect the actual premorbid glycemic status. Only limited research has been conducted so far to assess the value of HbA1c-levels during the state of an acute illness to estimate the premorbid glycemic control (4). Objectives: Assessment of the relationship between HbA1c during the state of an acute illness and HbA1c levels measured within 30 days before an acute illness. Methods: These are retrospective observational studies. The Ethics Committee of the Kobe University Hospital approved this investigation. The committee waived the need for informed consent concerning studies involving the use of databases. We screened patients' HbA1c levels that were measured within 30 days prior to an emergency surgery, requiring general anesthesia. Among them, we selected patients whose HbA1c levels were also measured on the day of the surgery. Thus we obtained HbA1c-levels measured within 30 days before the emergency surgery (preHbA1c) and on the day of the surgery (opeH-bA1c). Those HbA1c-levels were measured in the same laboratory. The correlations of the two HbA1c levels were assessed, using Pearson's correlation coefficient. Agreement between the two HbA1c-levels was assessed using the Bland-Altman approach. Results: We studied 100 HbA1c-levels in 50 patients. The patients were 66.8 years old in average. 31 of them were male patients (62 %). 38 out of 50 patients (76 %) were required emergency cardiovascular surgery. PreHbA1c was measured 11.4 days before the emergency operation. The average preHbA1c was 6.3 % and the opeHbA1c was 6.2 %. There is a significant correlation between preHbA1c and opeHbA1c (r = 0.83, p < 0.001). The mean difference between preHbA1c and opeHbA1c was −0.1 % (95 % confidential interval; −1.2 % to 0.9 %). This difference of the two HbA1c did not correlate with the time between the two measurements (r = 0.17, p = 0.29). The HbA1c-level on the day of surgery is a useful marker of premorbid glycemic control in patients requiring emergency surgery. Introduction: Hypoglycaemia during ICU admission is associated with adverse outcomes after discharge. In both health and patients with diabetes, acute hypoglycaemia triggers counter-regulatory responses increasing cardiac contractility and accelerating gastric emptying. However, antecedent hypoglycaemia attenuates endogenous catecholamine and vagal responses to subsequent hypoglycaemia 1 . Accordingly, patients who were hypoglycaemic during ICU may be unable to mount a physiological response to hypoglycaemia once discharged from ICU. Objectives: To determine the effects of antecedent hypoglycaemia on cardiac and gastric responses to subsequent hypoglycaemia in health. Methods: Ten healthy men (age 22.5 (1.0) years, BMI 23.8 (0.5) kg/m 2 ) were studied on two occasions, lasting 30 hours, separated by ≥ 6 weeks and randomised to either 'control' (Day 1 ( C1 ) -three euglycaemic clamps at a blood glucose of 6 mmol/L followed day 2 ( C2 ) -one hypoglycaemic clamp at 2.8 mmol/L), or 'antecedent hypoglycaemia' (Day 1 ( AH1 ) -three clamps at blood glucose of 2.8 mmol/L followed by day 2 ( AH2 ) -one clamp at 2.8 mmol/L). Cardiac contractility was measured using fractional shortening (FS) via 2D echocardiography on days 1 and 2 of the control (FS C1 and FS C2 ) and antecedent hypoglycaemia (FS AH1 and FS AH2 ) periods. Gastric emptying (GE) was measured on day 1 and day 2, for both control (GE C1 and GE C2 ) and antecedent hypoglycaemia (GE AH1 and GE AH2 ) study periods, using scintigraphy, following ingestion of a standardised meal consisting of 100 g of minced beef labelled with 20 MBq 99m technetium-sulphur colloid. Radioisotopic data were acquired for 180 minutes. Data are mean (SE). Results: Fractional shortening was greater (FS C2 vs. FS C1 , P < 0.01) and gastric emptying faster (GE C2 AUC vs. GE C1 AUC , P = 0.01) during acute, single episode hypoglycaemia compared to euglycaemia. When testing the effect of antecedent hypoglycaemia compared to a single episode of hypoglycaemia, fractional shortening may be attenuated (FS AH2 vs. FS C2 , P = 0.06), whereas gastric emptying was unaffected (GE AH2 AUC vs. GE C2 AUC , P = 0.74) (Figs. 40 and 41). Conclusions: In health, the increase in cardiac contractility during acute hypoglycaemia may be affected by antecedent hypoglycaemia whereas acceleration of gastric emptying during acute hypoglycaemia does not appear to be affected by antecedent was unaffected. These data suggest that antecedent hypoglycaemia during ICU may have "downstream" effects after discharge. Introduction: Plasmatic acid-base equilibrium remains a confusing area more than a century after the Henderson-Hasselbalch equation publication. However, a consensus exists concerning arterial carbon dioxide pressure (pCO 2 ) that would represent respiratory part of this equilibrium 1 . Stewart described this parameter as "independent", in contrast to "dependent" parameters, e.g. pH and HCO 3 − 2 . Objectives: The primary objective of this experimental trial is to demonstrate that lactic acid infusion increase pCO 2 . This would be inconsistent with Stewart approach. Methods: After local ethical committee approval, 9 anesthetized, curarized and mechanically ventilated piglets were studied. Lactic acid infusion (0.33 mmol.kg −1 .min −1 ) was administered. Each 3 minutes, an arterial gasometry was done. Each minute, the following parameters were collected: mean arterial pressure (MAP), cardiac output measured by transpulmonary thermodilution (CO), pulse oxymetry (SpO 2 ) and end-tidal CO 2 (EtCO 2 ). Bicarbonate (HCO 3 − ) was calculated like this: HCO 3 − = 0.03*pCO 2 *10 pH-6.1 . Total CO 2 (tCO 2 ) was calculated like this: tCO 2 = HCO 3 − + 0.03*pCO 2 The primary endpoints were pCO 2 increase and tCO 2 stability. To test the hypothesis of normal distribution, Shapiro Wilk test was applied. The p values were obtained from ANOVA analyses. p < 0.05 was considered as significant. Results: The results were: a decrease in pH (p < 0.001) (Fig. 42a) , an increase in pCO 2 (p = 0.002) (Fig. 42b) , a decrease in HCO 3 − (p = 0.015) (Fig. 42d ) without significant alteration in tCO 2 (p = 0.08) (Fig. 42c ). We also observed: an increase in EtCO 2 (p = 0.001) (Fig. 42e ) and lactatemia (p < 0.001) (Fig. 42f ). CO (p = 0.052), MAP (p = 0.506) and SpO2 (p = 0.905) were not significantly altered. Conclusions: This in vivo metabolic acidosis model with stable minute ventilation shows an increase in pCO 2 without significant alteration in tCO 2 . Although these results were biochemically predictable, they question one of the basements of Stewart approach, that considered pCO 2 as an independent parameter. In our study, pCO 2 seems a dependent parameter. tCO 2 , too often neglected parameter, seems an independent parameter. The role of bicarbonate precursors in balanced fluids during haemorrhagic shock with and without compromised liver function P. Objectives: This study investigated the role of the liver in the efficacy of balanced and unbalanced solutions to correct acidbase alterations and renal haemodynamics and microvascular oxygenation in a rat model of resuscitated hemorrhagic shock (HS). Methods: Ringer's Lactate (RL), Ringer's Acetate (RA), Plasma-Lyte (PL) or normal saline (NS) were administered following HS in the presence or absence of a 70 % partial liver resection (PLR). Renal haemodynamics and microvascular oxygenation (by oxygendependent quenching of phosphorescence) were measured as well as levels of lactate, gluconate and acetate in plasma and urine. Kidney wet and dry weighing was also assessed. Results: PLR resulted in increased liver enzymes compared in control and HS groups (p < 0.01). HS decreased systemic and renal haemodynamics and reduced microvascular kidney oxygenation to 20 and 14 mmHg for cortex and medulla respectively, associated with lactic acidosis (p < 0.01). Resuscitation with balanced fluids did not fully restore renal oxygenation (p < 0.01). RA and PL increased bicarbonate levels (15.5 ± 1.1 and 16.4 ± 1.6 vs 13.4 ± 2.0 and 11.5 ± 2.5 mmol/L) and restored pH better than RL or NS (7.29 ± 0.09 and 7.30 ± 0.04 vs 7.22 ± 0.12 and 7.14 ± 0.09) respectively in the PLR experiment (p < 0.01). PLR caused an increase in plasma gluconate after PL resuscitation (10.4 ± 2.8 vs 13.8 ± 5.1 g/L p < 0.05). Conclusions: Acetate buffered balanced fluids show superior buffering effects than RL and NS. Gluconate is partially metabolized by the liver although it does not contribute to acid-base control because of large excretion in urine. Acetate is metabolized regardless of liver function and may be the most efficient bicarbonate precursor. Lactate infusion tends to overwhelm the metabolism capacities of the residual liver. NS seemed to be the most unsuitable fluid when compared to balanced fluids, even in cases of liver failure. Introduction: Recent evidence suggests that a more liberal glycemic control (target blood glucose level between 10 and 14 mmol/l) may be beneficial in patients with diabetes adapted to chronic hyperglycemia (glycated hemoglobin A1c [HbA1c] >7 %) 1 . However, whether such liberal strategies leads to relative insulin deficiency, accelerated ketone body production and ketoacidosis is uncertain. Accordingly, we conducted a prospective observational study to explore the incidence of ketosis, ketonuria and ketoacidosis during liberal glucose management of critically ill diabetic patients. Methods: We studied 60 critically ill diabetic patients treated according to a liberal glucose protocol targeting a blood glucose level (BGL) between 10-14 mmol/l. We performed daily measurement of bedside blood 3-beta-hydroxybutyrate (β-OHB) and semi-quantitative urine ketones on ICU admission and on the following mornings during the ICU stay, for a maximum of 10 consecutive days. Results: Median (IQR) blood ketone level on admission was 0.3 (0.1, 0.8) mmol/l. Ketoacidosis was rare (3 %), but some level of ketosis (β-OHB ≥ 0.6 mmol/l) was found in 38 patients (63 %) at some stage during their ICU stay. However, there was no significant difference in severity or prevalence of ketonemia and ketonuria among patients with BGL above (permissive hyperglycemia) or below 10 mmol/l. On multivariate linear regression there was no association between blood ketone levels and BGL, HbA1c, lactate levels or APACHE III score. Conclusions: Liberal glycemic control in critically ill, predominantly type 2, diabetic patients itself does not appear to lead to increased ketogenesis. We found no difference in prevalence and severity of ketonemia between patients with or without permissive hyperglycemia. Furthermore, severity of ketosis was unrelated to blood glucose levels. Introduction: It is well known that poor preoperative blood glucose control is associated with poor postoperative blood glucose control and postoperative complications. Postoperative hyperglycemia is common in patients underwent cardiac surgery, especially in those with a preoperative elevated HbA1c. The STG-55 (Nikkiso CO., Ltd., Tokyo, Japan) is a newly developed and commercialized computer regulated continuous blood glucose management apparatus. Objectives: To compare the usefulness and the workload of ICU nurses of the STG-55 with the conventional sliding scale method in diabetic patients underwent cardiac surgery. Methods: The study was approved by the Institutional Review Board, and written, informed consent was obtained from all participants. This study included 28 patients underwent elective cardiac surgery with preoperative HbA1c > 6.0 %. The management of blood glucose was performed from immediately after admission to the ICU for two research days. The patients were randomly assigned to control blood glucose levels with the STG-55 group (n = 16) or sliding scale method, SS group (n = 12). The usefulness of blood glucose management defined the incidence of hyperglycemia (blood glucose > 180 mg/dL), hypoglycemia (<80 mg/dL), and the maximum glycemic variability (maximum blood glucose level minus minimum blood glucose level). The workload of ICU nurses defined the number of blood samplings for the management of blood glucose and the number of calls made to the physician. Results: The two groups were comparable with respect to age, gender, height, weight, duration of surgery, the amount of blood loss during surgery and the preoperative HbA1c. The blood glucose levels determined STG-55 and ABL3 acid-base laboratory analyzer were strongly correlated (R2 = 0.936), with nearly identical values. The incidence of hyperglycemia and hypoglycemia was significantly lower in the STG-55 group (1.9 ± 1.3 vs 6.7 ± 4.9 times/day, p < 0.001; 0.2 ± 0.1 vs 5.8 ± 6.0 times/day, p < 0.001) than SS group. The maximum glycemic variability was also significantly lower in the STG-55 group (46 ± 32 vs 283 ± 165 mg/dL, p < 0.01). The frequency of blood samplings (4.2 ± 3.7 vs 21.5 ± 14.1 times/day, p < 0.01), and the number of calls made to physician (2.1 ± 2.2 vs 6.9 ± 5.4 times/day, p < 0.05) were significantly lower in the STG-55 group than SS group. Conclusions: Use of the STG-55 in the ICU contributed to improved blood glucose management and reduced workload of ICU nurses compared to using the sliding scale method. Results: A total of 615 patients were studied, 142 of these patients had underlying liver cirrhosis. One hundred twenty-eight patients fulfilled criteria of ACLF. Median SOFA score of the total cohort was 10 (IQR 6-13), median SAPS II score 53 (IQR 38-70) and median age 60 (IQR 49-69) years. Patients with liver cirrhosis showed a marked metabolic acidosis compared to critically ill patients without (Base excess (BE) -6.8 (IQR −12.3 to 0.8) mmol/l vs. -1.5 (IQR −5.2 to 2.7) mmol/l, p < 0.001). Analysis of the BE subcomponents revealed that this acidosis was primarily attributable to hyperchloremia (BE Cl = −4.6 (IQR −7.5 to 0.8) mmol/ l), lactate (BE Lactate = −2.7 (IQR −6.1 to −1.0) mmol/l), and unmeasured anions (BE UMA = −1.6 (IQR −6.2 to 1.8) mmol/l). Interestingly, hyperchloremic acidosis antagonized by hypoalbuminemic alkalosis was found in critically ill patients with and without liver disease. In patients with cirrhosis, we observed respiratory alkalosis (partial pressure of arterial carbon dioxide (PaCO 2 ) = 36.4 (IQR 28.5 -44.5) mmHg) counteracting metabolic acidosis. With progression to ACLF, the compensatory mechanisms (hyperventilation and hypoalbuminemia) became insufficient resulting in progression of metabolic acidosis. Accordingly, BE in patients with ACLF grade 3 was −10.1 (IQR −17.4 to −3.6) mmol/l with a resulting pH of 7.29 (IQR 7.14 to 7.41). Lactate (BE Lactate = −3.6 (IQR −8.3 to −1.5) mmol/l) and unmeasured anions (BE UMA = −3.9 (IQR −8.9 to 0.9) mmol/l) were main contributors to metabolic acidosis in ACLF grade 3. The extent of metabolic derangement attributable to lactate and unmeasured anions, respectively, in patients with cirrhosis was associated with 28-day-mortality (Fig. 44) . Conclusions: Metabolic acidosis is a common feature of cirrhosis and ACLF at the ICU and is more severe compared to patients without cirrhosis. Acidosis in ACLF is primarily attributable to lactate and unmeasured anions. Although hyperchloremic acidosis did contribute to metabolic acidosis in critically ill patients, we found no clinically relevant difference in chloride-related acidosis between patients with and without liver disease. Unmeasured anions in deceased donor: can they predict liver transplantation outcome? Introduction: Complex elective surgery is increasingly provided to an aging population with heightened risk for prolonged ICU stay or death. While risks of surgical and anaesthetic procedures are routinely discussed preoperatively in the process of obtaining informed consent, the patients' preferences in case of unfavourable ICU outcomes are rarely discussed and most critically ill patients do not have advance directives. If patients at risk of a prolonged ICU stay or death could be identified preoperatively, this would provide an opportunity to make their preferences known in a timely and adequate manner. Objectives: To identify the predictive validity of routine pre-operative risk assessment for an unfavourable ICU course (ICU stay > 24 hours or death), and to assess the prevalence of advance directives in these patients. Introduction: This study assessed opinion of healthcare workers about consent and acceptable outcome in the context of decompressive hemicraniectomy for 'malignant cerebral artery infarction" Method: Seven Hundred and seventy three healthcare workers at the two major public neurosurgical centres in Western Australia participated in this study. Participants were asked to record their opinion regarding consent and acceptable outcome based on the Modified Rankin Score (mRS). They were then given a detailed analysis of the evidence for clinical efficacy of the procedure and an explanation of the "disability paradox". They were then asked to reconsider their initial responses. Results: Of the 773 participants included in the study 407 (52.7 %) initially felt that they would provide consent for a decompressive craniectomy as a life-saving procedure but only a minority of them considered mRS 4 or 5 as an acceptable outcome (for mRS Table 20 . The majority of deaths in the hospitals were expected and hence not preceded by a cardiopulmonary resuscitation. The mention of a poor prognosis was documented in a majority of cases, the DNR and DNI being the most frequent type of treatment limitation both in ICU and wards. The treatment limitation was communicated with the family fare more often than to the patient (81 % and 31 %, respectively). Patients did not have an advance directives document, nor were their treatment preferences documented during the last hospitalization (0,5 and 1,62 %, respectively). The various aspects of treatment limitations in the ICU vs. wards are presented in Table 21 . Conclusions: This is the first large prospective study comparing the decision making process and the perceptions of clinicians and family members of patients dying in a tertiary care hospital. The study shows an insufficient interdisciplinary and intra-team communication with discrepancies between the documented and the agreed treatment limitations. Furthermore, a difficult communication with patients and their families in final phases of patients´lives suggests a gap between the care provided and the patients preferences regarding the end-of-life, although these are known to be key aspects of good end-of-life care. Methods: Retrospective study (January 2012 -March 2016) in a Spanish tertiary hospital. We studied all patients that underwent LLST thru TE. Demographic factors, general patient characteristics (comorbidities, diagnosis upon ICU admission, APACHE II on admission and SOFA in the previous 24 h before TE), ICU length of stay and timing from TE to cardiac arrest together with their donor/non-donor condition were recorded. We also analyzed the different types and doses of analgesic and sedation drugs (morphine, fentanyl, remifentanyl, propofol and midazolam) and the different strategies used (bolus administration, increase of the infusion rate or both). In order to simplify dosage analysis we used the intervals previously described by other authors 1 . Statistical analysis with c 2 and Mann-Whitney U test. Statistical significance p < 0,05. Results: During the period studied we recovered a total of 68 patients with LLST thru TE that were divided in two groups: DCD (group A, n = 26) and non-donors (group B, n = 42). Demographic data and general characteristic are described in Table 22 . There were no statistical differences regarding the different types and doses of analgesia and sedation, and the different strategies used in group A vs group B (Table 23 and Fig. 46 ). Although none of the following reached statistical significance we found that the number of patients receiving doses described as superior to standard accounted for an important percentage in both groups, and that there was a higher rate of bolus administration followed by an increase in infusion rate un group B (53,3 %) when compared to group A (29,4 %). Conclusion: In our study we found no differences in dose, type and strategy applied for analgesia and sedation after TE regardless of whether the patient was a potential organ donor or not. Introduction: Advance care planning (ACP) is the process in which the patient makes decisions in consultation with health care givers about future health care once they become incapable of deliberate medical treatment decisions. ACP is increasingly recognized as area of concern respecting quality of care in the ICU and other wards in the hospital. However, research shows that ACP discussions (ACPd) are still rare in hospital settings: clinicians underestimate the number of patients willing to discuss ACP and the feeling being unskilled, inadequately trained or inexperienced may hamper a meaningful patient-doctor discussion. Objectives: To develop and evaluate an e-module preparing residents to perform effective and timely ACPd. Methods: Development of an e-module aiming to equip residents with knowledge, skills and appropriate attitudes for ACPd, preferably in a simulated situation before real life practice in the workplace. The design of this e-module is inspired by the 4C/ID-model. First, experts explain the ethical, legal and social issues concerning ACP that constitute the learning goals of the e-module. Subsequently, five cases are presented in videos illustrating appropriate performance. Each case is provided with comments from experts and residents and their advice based on personal experience. Cases are presented in increasing complexity sequence. Roles of patients are performed by trained simulation patients. Residents, senior staff and nurses demonstrate lifelike ACPd designed to illustrate preset educational goals. Documenting ACP agreements in the electronic health record is shown using screen shots. Finally, background information by experts and useful links are offered. Learners work through the e-module at their own pace with the option to interrupt and looking back. The e-module was piloted in a group of residents purposefully sampled from a variety of specialties with a web-based 5 point Likert scale survey with room for narrative explanation to evaluate satisfaction of participants. Results: In this pilot 18 residents participated, mean age 30.4 (+/− SD 2.6) year, 33 % male, in training for neurology (n = 5), internal medicine (n = 5), surgery (n = 3), anesthesiology (n = 2), cardiology (n = 1) and undisclosed (n = 2), ranging from 1 st to 6 th year of training (median 3 rd ). 83 % of participants (strongly) agreed with the statement that the e-module is well-arranged. 89 % (n = 16) review the emodule as giving sufficient insight in the necessity of ACPd. Ten residents (55 %) appraise the e-module offering guidance for performing ACPd themselves in clinical practice. Overall satisfaction was 7/10 points (median, range 6-8). Conclusions: This pilot suggests s that an e-module showing appropriate behaviors based on clarified skills and attitudes by role models in lifelike situations may help to engage residents in learning activities and actual practice to master ACPd, thus contributing to quality of care. Limitation of life sustaining therapy in patients died early in ICU As a result of this audit we proposed the following actions To formulate a template in ACUBASE with essential elements of EOL which will be filled by the relevant CCU consultant and copy of it will be handed over to the bed side nurse for further care. The time of withdrawal will be documented by the bed side nurse after family gathering and fulfilment of spiritual aspects in the monitoring chart and the doctor who certifies the death will document it on the ACUBASE. Conclusions: Substantial variation exists in the terminology and definitional criteria for cohorts of patients receiving mechanical ventilation. Standardization of terminology and definitional criteria is required for study data to be maximally informative. Introduction and objectives: The use of continuous waveform capnography is well established within the theatre environment, and is now considered a standard of care within intensive care by UK national bodies 1 2 3 . University Hospital Birmingham is a large UK teaching hospital. Historically within this unit the use of capnography has not always been routine on all invasively ventilated patients. This quality improvement project aimed to implement national guidelines in our unit. Methods: To assess the usage, availability and attitudes towards using capnography, a baseline audit of the use of capnography on ventilated patients, during airway interventions and patient transfers was performed. Concurrently a staff questionnaire was circulated to the multidisciplinary ICU team to complete, in order to assess their knowledge and attitudes towards capnography and promote awareness of national guidelines. A business case was developed to purchase sufficient modules and consumables to allow for use on every invasively ventilated patient. Teaching of critical care staff was carried out by the trusts practice development team in conjunction with volunteers from within the critical care team. This covered the system set up and interpretation of the capnography waveform. Mandatory use of capnography was then introduced into local guidelines and its use was then re-audited. Results: The audit results are shown in Table 25 . Conclusions: The routine use of capnography for invasively ventilated patients has risen by 62 %. The use for airway interventions and patient transfers appears to have remained at the same level or fallen though both these area had much higher baseline rates of use. This highlights an area for further improvement and the wider dissemination of this work will contribute to further improvement in local practice. Introduction: Disturbances of external respiratory function (ERF) are in a leading position among extracranial complications after severe traumatic brain injury (STBI). According to the opinion of the most specialists, disturbances of ERF belong to the complications resulted from aspiration and damage of mucous tunic of tracheobronchial tree. Aspiration of gastric contents usually occurs owing to consciousness depression accompanied by STBI. Objectives: To determine the development periods and to study the development rate of acute respiratory distress syndrome (ARDS) in isolated STBI complicated with aspiration of gastric contents and blood. Methods: The study was conducted in neurosurgery intensive care unit at Republic Research Center of Emergency Medicine. 33 of 165 patients with STBI admitted between 2013 and 2014 had aspiration. 28 were male and 5 were female. Mean age was 35 ± 3. Glasgow coma score after admission was 5-9. All patients were intubated and mechanically ventilated. Patients were divided into 2 groups according to the etiology of aspiration agent. First group (n = 33) -patients with aspiration of gastric contents or blood. Second group (n = 33)control group, i.e. with isolated STBI without aspiration. Aspiration was confirmed with fiberoptic bronchoscopy. Results: We conducted analysis of extravascular fluid in the lungs. In 21 patients with aspiration of gastric contents (first group) the amount of extravascular water in lungs (EVWL) 3-6 hours after the trauma was 7.8 ± 3.0 mL/kg (normal value is 3-7 mL/kg), PaO2/FiO2 ratio was 275.0 ± 127.2, after 24 hours EVWL was 7.3 ± 2.9 mL/kg, PaO2/FiO2 ratio was 291.8 ± 94.1. Fifteen patients were with ARDS criteria and their EVWL was 9.6 ± 1.6 mL/kg, PaO2/FiO2 ratio was 218.0 ± 72.9. In 12 patients with aspiration of blood, EVWL 3-6 hours after the trauma was 9.3 ± 2.9 mL/kg, PaO2/FiO2 ratio was 336.2 ± 20.7. Nine of them had ARDS criteria and their EVWL was 10.2 ± 2.2 mL/kg, after 24 hours it was 10.5 ± 4.9 mL/kg. In the second group after 3-6 hours, EVWL was 6.8 ± 1.5 mL/kg, PaO2/FiO2 ratio was 330.5 ± 183.2 and none of the patients had ARDS criteria. After 24 hours EVWL was 6.6 ± 0.8 mL/kg, PaO2/FiO2 ratio was 323.9 ± 122.4, and three of them had ARDS criteria, EVWL was 9.6 ± 1.4 mL/ kg, PaO2/FiO2 ratio was 234.0 ± 17.2. Conclusions: Hence in patients with STBI and aspiration of gastric contents we observed significant increase in EVWL (p = 0.05) and decrease in PaO2/FiO2 ratio in the first hours after trauma in comparison with the patients without aspiration. Accumulation of EVWL can be considered as one of ARDS criteria, but only with other signs of damage. ARDS is registered in the first hours after trauma roughly in 50 % of cases in patients with aspiration of both gastric contents and blood. Introduction: Acute respiratory failure (ARF) can be divided in hypoxemic or hypercapnic, depending on the leading modification in blood gas analysis, being the first one the most common. Mechanical Ventilatory Support is one of the treatment mainstays of patients in the Intensive Care Units (ICU), either as management for a primary respiratory imbalance or to protect the airway. Non-invasive mechanical ventilation (NIMV) is defined as any method in which positive pressure is delivered by a face mask or any other interphase without the use of an endotracheal tube. Objetives: It is well established in which pathologies NIMV can be useful, but an inadequate patient selection may cause an increment in morbidity and mortality as well as a delay in endotracheal intubation. While the aim in most studies is to determine which pathologies NIMV will have a better outcome, the main objective in our study was to define whether the blood gas values (pH, paCO 2 and paO 2 ) are the ones that may indicate which patients are better suited for NIMV. Methods: Retrospective observational study of all adult patients admitted to the ICU (mixed ICU) between March 2014 and April 2016 but data presented in this abstract is a preliminary report as we pretend to add more patients in the ongoing months. Patients with DNR order were excluded as well as patients that required endotracheal intubation in the first 2 hours after the beginning of NIMV. Patient's data was analyzed with the purpose of finding cutoff points in blood gas values that could suggest which patients had a better outcome. Patients divided in two groups (survivors or non-survivors) and mean values were compared using Student's t test. A p value of less than 0.05 was considered to be statistically significant. Results: 52 patients were included and their data analyzed: n = 22 (42.3 %) were female and n = 30 (57.7 %) male, with a mean age of 74 ± 12 (36-94). Of all, n = 15 (29 %) required endotracheal intubation; overall mortality rate was 23.1 % (n = 12). Patients who survived had higher PaO 2 /FiO 2 ratio than those who did not (p = 0.04) and tend towards higher PaCO 2 levels although p values were not statistically significant (p = 0.07). ARF cause with the highest mortality was cardiogenic acute pulmonary edema in n = 5 patients (41.7 %). Conclusion: The use of NIMV can be considered as an alternative to endotracheal intubation in hypercapnic patients while the benefit of its use has not been proven in severe hypoxemia (PaO 2 /FiO 2 ratio less than 100) at least in our group of patients and it actually may lead to a worst outcome. Methods: We prospectively conducted this pilot study of 28 PCT in coagulopathic patients. We defined the neck anatomy in three categories depending on the presence of blood vessels in the track of needle even at the lowest visible inter-tracheal space on ultrasound. The unsatisfactory category was defined as presence of multiple vessels in the centre of the field, good category had one blood vessel in the centre of the field, excellent category had clean procedure field with no blood vessels. The technique that we adopted in PCT in unsatisfactory category was liberal instillation of 2 % Xylocaine in the skin and subcutaneous tissue between the vessels and creating a potential space for the needle. We also avoided putting any predetermined incision on the skin during the procedure and followed an entire seldinger technique by dilating the skin and subcutaneous tissue using the 5Fr tracheal dilator provided in Portex® ULTRAperc®. The entire procedure was done under real time ultrasound guidance. Blood loss was estimated by the number of gauze pieces soaked with blood with one gauze piece soaking 5 ml. Results: The average local anesthesia requirement was around 10 ml for instillation. The INR ranged from 2.1 to 2.9 and the platelet count ranged from 20,000 to 75,000. None of the patients required any blood product transfusion. The maximum blood loss was 15 ml and none of the patients required abandoning of the procedure. Conclusions: This modification of the classical technique of PCT in patients having unfavorable neck anatomy resulted in increased safety with minimal blood loss. Ultrasound guidance is a very useful modality to define such unfavorable neck anatomy which are non amenable by just palpation of neck. Correction of coagulopathy may not be mandatory if real-time ultrasound is used during this modified technique of PCT. None. The usefulness of delta neutrophil index for predicting superimposed pneumonia in patients with acute decompensated heart failure at the emergency department Y. Conclusions: Initial DNI was significantly higher in the superimposed pneumonia group than in the ADHF group and the prediction ability for ADHF with superimposed pneumonia of initial DNI in the ED was as good as those of serum CRP. Survival benefit of prone ventilation and feasibility of prolonged (>20 hours) prone positioning in severe Complications: 10 patients needed to stop enteral feeding transiently during prone session due to increased residual gastric aspirate. 9 patients had Grade 1 pressure sores on the face. 1 patient in prolonged proning had sudden cardiac arrest during the prone session. Conclusions: Easy feasibility & rapid response assessment make prone ventilation an ideal choice for the initial treatment of patients with severe H1N1-ARDS. For who can not be put on ECMO for various reasons, prolonged proning is an option as rescue therapy and should be evaluated by RCTs. Introduction: Use of generic drugs, which are bioequivalent to brand-name drugs, is now a common practice. However, there is still concern among patients and physicians that brand-name drugs are more efficient than generic drugs (1 Objectives: The objectives of this audit were to assess the median level of sedation in ventilated patients, record any variation in score at different times of day or night and measure the frequency of recorded score. This audit was then repeated to measure any improvement in practice. Methods: All patients sedated and ventilated during July 2015 were audited and then re-audited in November 2015. Patients were excluded if it was felt that reducing the level of sedation was inappropriate. Results: 300 scores were obtained during July 2015 and 672 in November 2015. The median sedation score was −2 in July and −3 in November. 41.5 % were too heavily sedated at −3 or below in July and 53.3 % in November. The majority of scores were recorded frequently with 84 % of patients in July having a score recorded at least every 2 hours and 91 % in November. Conclusions: Sedation scores are being recorded frequently, with few long gaps for either month. Sedation protocols should be used in order to target the lowest possible levels of sedation. There should be discussion around whether targets should be different at night compared with daytime. There has been no improvement in sedation practice in November compared with July 2015. Fewer than half (45.5 %) of patients were sedated to optimum levels in July and this fell to 38.2 % in November. There may be merit in maintaining an infusion of the opioid, whilst reducing or stopping the hypnotic, rather than stopping both completely. Maintaining staff awareness of the benefits of optimising sedation is prudent. Introduction: The management of severe Legionella pneumonia can include extracorporeal membrane oxygenation (ECMO) to rescue those patients which develop refractory hypoxemia or extreme respiratory acidosis. However, some physicians remain skeptical about this approach, considering that evidence is very weak and only derived from case series from single ECMO centers. We believe that reporting experience from diverse centers is important to expand the knowledge and the predictors of benefit from ECMO support in patients with Legionella pneumonia. Objectives: Clinical, physiological, functional and biomechanical characterization of a population with severe Legionella pneumonia treated with extracorporeal life support in a ELSO recognized ECMO centre. Methods: Protocol-driven prospective registration and analysis of data from a population of 9 patients diagnosed with severe acute respiratory distress syndrome (ARDS) secondary to Legionella infection, with additional respiratory physiology evaluation and characterization during the ECMO run treatment. Results: From 2013 to 2015, nine patients with Legionella pneumonia and severe ARDS have failed conventional mechanical ventilation and were treated with extracorporeal oxygenation (Quadrox HLS or PLS Oxygenator System from Maquet). Median age was 46.6 ± 12.3 and all patients were male. ECMO criteria admission were hypoxemia (median pre-ECMO PaO2:FiO 2 of 73.5 ± 22.9 mmHg) associated with respiratory acidosis (median pre-ECMO PaCO 2 of 69,6 ± 12,5 mmHg and pH of 7.22 ± 0,08). Murray score was 3.17 ± 0,16 and SAPS II was 43.7 ± 9.8. Symptoms to cannulation was 4.4 ± 2.2 days, which represented a very early strategy to ECMO implementation. Initial static compliance was 25.9 ± 7.6 ml/cmH 2 O, did not changed significantly by day four (27.7 ± 13,4), and improved to 38.1 ± 13.4 by day seven. Six patients were smokers, six had acute kidney injury AKIN 3 and three had circulatory shock. During ECMO run, all patients were additionally conventionally ventilated with a lung rest strategy (Vt 2.0 ml/kg, driving pressure below 15 cmH 2 O and PEEP of 10 to 14 mmHg). Seven patients were treated with azithromycin and two patients with levofloxacin. We did not prescribed corticosteroids in any patient. All patients survived ECMO run (median time of 9.8 ± 4.5 days) and hospital discharge. We showed excellent results derived from a strategy of extracorporeal oxygenation in patients with the most severe forms of Legionella pneumonia. We believe that early referral and early implementation of a protocol-driven ECMO technique, with better understanding of its physiological and management principles, might improve the outcomes of patients with severe Legionella pneumonia. Introduction: Percutaneous Tracheostomy is a procedure commonly performed in the intensive care unit 1 , being considered as first choice in patients in critical condition due to the lower rate of complications associated with this procedure 2 , reports of perioperative complications ranging from 2 to 6 % 3 such as bleeding, death, false passage, extubating, pneumothorax, emphysema, hypertension and inability to perform the technique; Postoperative complications were reported from 9 to 17 % 3 , including bleeding, displaced tube, pneumothorax, infection and death. In our intensive care unit we have one year experience of performing percutaneous tracheostomy, with very low rate of complications so far. Objectives: To determine the incidence of complications related to percutaneous tracheostomy in critical ill patients in our intensive care unit. Methods: A retrospective study was conducted in our intensive care unit during March of 2015 to February of 2016, counting 23 patients who underwent percutaneous tracheostomy for any indication, and the complications observed in each procedure were recorded in a data collection sheet. Results: We obtained a population of 23 patients, 11 females and 12 males, all diagnoses of these patients were divided into groups, including 9 patients with lung disease (39.2 %), 7 patients with neurological disease (30.4 %), and 7 patients with abdominal disease (30.4 %), with an average of 8.47 days of mechanical ventilation, and an average of 15.4 minutes duration of the percutaneous tracheostomy, in which 2 episodes of extubating without clinical repercussion as perioperative complications were reported (8.9 %), and a tube displacement which required endotracheal intubation as a postoperative complication (2.3 %). Conclusions: We observed a low incidence of perioperative complications in our patient population, as well as a very low incidence of postoperative complications compared with that reported in the reviewed articles, no serious complications in any patient who perform percutaneous tracheostomy were observed. We strongly recommend percutaneous tracheostomy as a safe method to the bedside of most patients in critical condition, regardless of their disease. Three-year mortality in 30-day survivors of critical care with acute kidney injury -data from prospective Finnaki study H. Introduction: Acute Kidney Injury (AKI) is a frequently encountered syndrome in the critically ill. While the role of AKI in increasing shortterm mortality is evident, results regarding its role in long-term mortality are conflicting. Advanced age and pre-existing co-morbidities are known risk factors for AKI and also the main determinants for the long term-mortality of initial survivors of intensive care (1). Objectives: To determine whether AKI is an independent risk factor for increased three-year mortality among 30-day survivors of critical care. Methods: This prospective study enrolled 2901 patients from 17 Finnish intensive care units (ICU) in 2011-2012. In this analysis, we included 30-day survivors of the cohort. We compared the crude three-year mortality of AKI and non-AKI patients and adjusted for confounders using Cox proportional hazard model. We performed sensitivity analyses by excluding patients with 1) chronic kidney disease (CKD), 2) stage 1 AKI, or 3) CKD, stage 1 AKI only, or an estimated pre-admission creatinine. and poor premorbid functional performance were. Pre-existing arteriosclerosis, diabetes, hypertension, systolic heart failure, thrombophilia and characteristics of the ICU admission and treatment (operative admission, higher SAPS II score without age and renal points, use of vasoactives and severe sepsis) did not independently associate with an increased hazard for three-year mortality. In the sensitivity analyses, AKI was not associated with an increased hazard for three-year mortality. Conclusions: Our findings imply that increased long-term mortality among patients with AKI who survive critical illness is not related to AKI per se, but rather to increased age and pre-existing comorbidities. Introduction: After years of negligence, a kidney-brain crosstalk has become an issue [1] .The link between cognitive impairment and chronic kidney disease is widely acknowledged. Less is known about the influence of AKI. Recently, an increase of serum beta-2 microglobulin (B2M), an uremic toxin, was proved to be associated with cognitive decline (CD) in mice [2] . Methods: A prospective, single-center and observational study was carried out in urine samples from patients undergone to cardiac surgery obtained at arrival to Critical Care Unit. Urine samples were centrifugated 10 minutes at 1000 g and supernatants (S1) were centrifugated 15 minutes at 17000 g to remove cellular fragments and other debris. Supernatants were subjected to ultracentrifugation 60 minutes at 200.000 g to obtain exosomic fraction and a final supernatant (S2). Glutamyl aminopeptidase (GluAp) and alanyl Introduction: ADVOS® (Hepa Wash GmbH, Munich, Germany) is a new advanced dialysis device that is approved in the European Union for treatment of kidney and liver failure. Apart from removing water soluble and albumin bound substances it is able to counteract severe acid-base-disequilibrium on an individualized basis. Objectives: Aim of this study is to quantify the ADVOS®´efficacy in improving respiratory acidosis in hypercapnic patients at the intensive care unit. Methods: Retrospective analysis of patients with acute kidney failure and respiratory acidosis that were treated with the ADVOS®-device via a conventional dialysis catheter at an interdisciplinary intensive care unit. Results: 10 patients were included in the analysis, 6 (60 %) were male, the mean age was 58 ± 16 years. All patients were mechanically ventilated and suffered from severe multiorgan failure. Mean SAPS II was 50 ± 12 and mean SOFA-Score was 16 ± 3. Parameters of mechanical ventilation did not change significantly during treatment with the ADVOS® device (PEEP pre 11 ± 4 mbar versus PEEP post 11 ± 4 mbar, p = ns, FiO 2pre 66 ± 21 versus FiO 2post 64 ± 24, p = ns, tidal volume pre 371 ± 106 ml versus tidal volume post 372 ± 109 ml, p = ns, respiratory rate pre 28 ± 5 /min versus respiratory rate post 29 ± 6 /min, p = ns). PaO2/FiO2 prior to treatment was 143 ± 77 mmHg versus 154 ± 70 mmHg at the end of treatment(p = ns).Mean blood flow rate of the ADVOS® device was 148 ± 68 ml/min, median flow rate of the concentrate was 160 ml/h and mean dialysate-pH-setting was 8,4 ± 0,5. Unfractioned heparin was used as anticoagulant in 6 patients and 4 patients had regional citrate anticoagulation. Mean duration of each treatment session was 16 ± 8 hours.pH and HCO 3− increased significantly during treatment with ADVOS® (pH pre 7,28 ± 0,12 versus pH post 7,38 ± 0,1, p < 0,001, HCO 3-pre 28 ± 8 mmHg versus HCO 3-post 32 ± 9 mmHg, p < 0,01) and P a CO 2 decreased significantly (P a CO 2pre 66 ± 12 mmHg versus P a CO 2post 53 ± 10 mmHg, p < 0,001). We observed significant differences of the acid-base-status pre and post the ADVOS® device: P v CO 2preMem 67 ± 18 mmHg versus P v CO 2postMem 24 ± 15 mmHg, p < 0,001, pH preMem 7,26 ± 0,14 versus pH postMem 7,74 ± 0,23, p < 0,001, HCO 3-preMem 27 ± 7 mmHg versus HCO 3-postMem 32 ± 6 mmHg, p < 0,001). We could not observe any device related side effects during treatment. 28-survival-rate of the patients was 70 %. Conclusions: ADVOS® is a new advanced dialysis device that is approved in the European Union. ADVOS® is able to remove CO 2 without an extracorporeal membrane oxygenator and to support patients with respiratory acidosis. Conclusions: There are numerous barriers to the provision of renal replacement therapy in neurointensive care patients. This survey has not explored the physiological problems encountered with RRT in these patients, but has highlighted that the maintenance of training, competency and logistical problems sometimes affects the consistent, direct availability of RRT to NICU patients. This is especially true of units without traumatic brain injury patients, where medical staff may become deskilled in the practice of RRT over time. It also highlights the logistical challenges in providing renal replacement therapy in patients who are at high risk of intracranial bleeding without point of care testing immediately available to monitor the anticoagulation of the circuit. Introduction: Septic shock is associated with a severe cardiovascular stress response. Beta-blockade represents a novel way of addressing this; esmolol titrated to keep heart rate < 95 bpm in critically ill patients receiving high-dose noradrenaline resulted in improved outcomes [1] . We measured a series of biomarkers of cardiac stress and injury in an observational study of critically ill patients with septic shock. We then used a long-term fluid-resuscitated rat model of sepsis to assess the same cardiac markers. Objectives. To measure the degree of cardiac stress in critical illness using the biomarkers of cardiac injury, troponin T (cTnT) and of ventricular dysfunction, B-natriuretic peptide (BNP). Methods: Study 1: Observational study of 27 critically ill patients with septic shock from faecal peritonitis or community-acquired pneumonia. Daily measurements of cTnT and BNP were performed on days 0 to 3 (measured by ELISA). Study 2: Awake, instrumented yet fully mobile male Wistar rats (350 ± 50 g) received an intraperitoneal injection of faecal slurry to induce sepsis. Fluid resuscitation (crystalloid 10 ml/kg/h) was commenced at 2 h. At 6 h, an echo-measured stroke volume rate cut-off of 0.20 ml was used to classify animals into predicted survivors (S) or nonsurvivors (NS) (n = 6 per group). Blood was sampled at 6 h and 24 h for cTnT and BNP (ELISA). Control animals were treated identically except for faecal slurry injection. Results were analysed using two-way ANOVA and post-hoc testing and considered statistically significant when p < 0.05. Results: cTNT was significantly elevated in critically ill patients on the day of ICU admission, and was significantly higher in NS (Fig. 55) . BNP was significantly elevated in NS patients only. Likewise, in the experimental model of sepsis (Fig. 56) , non-surviving rats had an early elevation of the same cardiac biomarkers. (p < 0.05 for both cTnT and BNP compared to survivors). Conclusions: Sepsis is associated with excess cardiac stress, as demonstrated in both a critically ill patient population and in a rat model of faecal peritonitis. Whether beta-blockade can be used to ameliorate this cardiac stress is the subject of further studies. We performed 2 sensitivity analyses: 1) using only septic shock subgroups and 2) double blinded trials with intention to treat analysis. We performed 45 comparisons. There was no significant betweengroup difference in the rate of death. In sensitivity analyses, the results were qualitatively similar to the results obtained with 23 studies. Conclusions: There were no significant differences in the rate of death between patients with shock who were treated with any vasopressor agent. Introduction: Hyperglycemia is a feature of septic patient and has been associated with poor outcome and higher mortality. In contrast insulin has been shown to decrease mortality and to prevent the incidence of multi-organ failure but is often associated with deleterious hypoglycemia. Protein Tyrosine Phosphatase 1B (PTP1B) is a negative regulator of insulin signaling and NO production. We found that PTP1B inhibition or gene deletion improved mesenteric endothelial function, reduced cardiac and vascular inflammatory markers, leading to reduced cardiac dysfunction. Objectives: The purpose of the present study was to assess the potential therapeutic effect of total PTP1B invalidation on glucose metabolism and cardiovascular insulin resistance using experimental model of sepsis. Methods: Thus, in order to address this question, we developed a Cecal Ligation and Puncture (CLP) model of sepsis. CLP is followed by subcutaneous fluid resuscitation. To evaluate the potential therapeutic effect of PTP1B invalidation, we used PTP1B −/− mice. Results: Indirect calorimetry study showed that CLP induced a significative diminution of VO2 inspired, VCO2 expired, physical activity with food and water consumption. This study characterizes a severity of our CLP model without difference between WT vs PTP1B − Moreover, we showed that PI3k/Akt molecular pathway is functional in CLP mice suggesting a GLUT4 expression or translocation alteration. In fact, GLUT4 expression study showed that in plasma membrane fraction and endosome fraction, GLUT4 expression is abolished in WT CLP mice. We also found that PTP1B −/− mice subjected to CLP had a higher survival rate compared to WT. Conclusions: CLP-induced sepsis changes the carbohydrate mechanistic by abolishing GLUT4 expression and PTP1B inhibition restores GLUT4 expression and improves metabolic function, cardiovascular function and survival. This suggests that, PTP1B inhibition may be an attractive target for the treatment of sepsis. Note: This abstract has been previously published and is available at [1] . It is included here as a complete record of the abstracts from the conference. Introduction: Septic shock is a condition of extreme physiological stress associated with significant haemodynamic, immune and hormonal abnormalities. Beta-blocker therapy is associated with improved organ dysfunction and survival in patients with severe, prolonged septic shock [1] . Precise mechanisms of putative benefit however remain uncertain. Objective: To investigate the impact of esmolol on the inflammatory and catecholamine stress response during sepsis. Methods: We used an awake, fluid-resuscitated rat model of faecal peritonitis in which 72 h mortality can be accurately predicted at 6 h post-insult by stroke volume (<0.20 ml) [2] and interleukin(IL)-6 [3] . After the 6 h echocardiogram, rats were randomised to receive either esmolol (75 mcg/kg/min, preceded by a loading dose of 500 mcg/kg for one minute) or equivalent volume of placebo for the next 18 hours. Rats (n = 12) then underwent repeat echocardiography, followed by terminal blood and tissue sampling. This included plasma levels of IL-6 (pro-inflammatory cytokine) and IL-10 (anti-inflammatory cytokine) (ELISA, BD Biosciences) and catecholamine levels (ELISA, Cusabio). Comparison was made against non-septic control rats (n = 6). Results were analysed using two-way ANOVA with post-hoc testing, and considered statistically significant when p < 0.05. Results: Septic animals had increased levels of IL-6 and IL-10 at 24 h that were greater in predicted non-survivors (Table 30) . Esmolol significantly decreased IL-6 levels in both predicted survivors and nonsurvivors compared to placebo-treated rats, whereas IL-10 levels were increased by esmolol. However, no change was seen in catecholamine levels. Conclusions: Treatment with esmolol altered plasma cytokine balance towards a more anti-inflammatory profile in both predicted survivors and non-survivors in this model of faecal peritonitis. However, circulating catecholamines were unaffected. Introduction: Hospitalized patients often receive oxygen supplementation, which may lead to a supraphysiological oxygen tension (hyperoxia). Hyperoxia has hemodynamic effects, including an increase in systemic vascular resistance suggesting arteriolar vasoconstriction. Despite several in-vivo, ex-vivo and in-vitro studies involving humans and various types of animals, the mechanism behind hyperoxia-induced vasoconstriction remains unclear. To enhance our understanding of this phenomenon, we set out to develop an experimental model of hyperoxia-induced vasoconstriction in murine vessels. Objectives: To develop an ex-vivo mouse model to study the underlying mechanisms of hyperoxic vasoconstriction. Methods: Femoral arteries (conduit vessel) and gracilis-and mesenteric arterioles (resistance vessels) were isolated from 10-12 week old C57BL/6 mice. Vessels were pre-constricted with noradrenaline to approximately 50 % of their maximal diameter for vasodilation studies. Mesenteric arteries developed spontaneous myogenic tone. Agonist induced endothelium-dependent (acetylcholine, arachidonic acid) and -independent (nitroprusside, noradrenaline) dilation and constriction were examined under normoxic (PO 2~8 0 mmHg) and several hyperoxic conditions (PO 2~2 20,~350 and~660 mmHg) using no-flow pressure myography. Results: Oxygen tension did not influence the endotheliumdependent dilation of femoral arteries (Fig. 58, left) or gracilis arterioles (Fig. 58, right) . Endothelium independent dilation was not affected either. Comparably, oxygen tensions also did not influence the degree of spontaneous myogenic tone of mesenteric arteries or the response to arachidonic acid or noradrenaline. Conclusions: In this study, the isolated femoral artery and gracilis and mesenteric resistance arterioles from mice did not show altered vascular tone responses under hyperoxic conditions. We therefore discourage researchers to use these vessels for mechanistic research of hyperoxic vasoconstriction. Introduction: The mechanisms of persistent hyperlactemia during endotoxic shock are probably multifactorial. Both hypoperfusionrelated anaerobic production and adrenergicdriven aerobic generation have been implicated. More recently an early and severe impairment in exogenous lactate clearance has also been described [1] . Theoretically, an excessive adrenergic response could influence all these mechanisms and thus aggravate the problem. Some small experimental and clinical studies have shown favorable effects on heart rate and hemodynamic or perfusion parameters, and also in inflammatory and metabolic parameters with beta-blockers. Esmolol (ESM) a short-acting selective beta-blocker has demonstrated to improve cardiac contractibility and vascular reactivity probably in relation to an anti-inflammatory effect. In a randomized-controlled study in stable septic shock patients, esmolol reduced heart rate (HR), decreased fluid requirements and lactate levels, and surprisingly showed a significant effect on mortality. Objectives: To assess the effects of ESM on lactate production and exogenous lactate clearance in an endotoxic shock model. Methods: Twelve anesthetized sheep were subjected to a multimodal hemodynamic/perfusion assessment including hepatic and portal vein catheterizations, total hepatic blood flow, sublingual microcirculation, and muscle microdialysis. After the monitoring phase, all received a 5 mcg/kg LPS bolus (E coli O127:B8®) and then 4 mcg•kg1•hr1 for the rest of the experiment. After 1 hr they were volume resuscitated, and then randomized to LPS-control or LPS-ESM. Sampling and exogenous lactate clearances at different timepoints (Fig. 59) [3] . We calculated dynEl as SVV/PPV. We performed measurements prior to (T0) and after 20 ml/kg fluid challenges (T1). In a subgroup of 6 patients vasopressor support was also given between T0 and T1. Results: In a multivariate analysis VAC was found to improve significantly in the fluid responder group (p = 0.005) after fluid resuscitation. Arterial elastance, which is a determinant of VAC was significantly reduced in those patients (p = 0.01) and dynEl, although not significantly, decreased. Not surprisingly we found a high correlation between dynEl and Ea.In those also receiving vasopressor therapy similar changes occurred. Introduction: Persistent hyperlactatemia after initial septic shock resuscitation is associated with bad prognosis. However, at least three mechanisms are involved: anaerobic glycolysis in hypoperfused tissues, adrenergic-driven aerobic glycolysis and impaired lactate clearance. Only the first mechanism is sensitive to further resuscitation. Thus pursuing lactate normalization with additional fluids while confronted to non-hypoxic causes could lead to the toxicity of overresuscitation with no clinical benefit. To develop clinical algorithms aimed at differentiating hypoxic vs non-hypoxic profiles could have relevant clinical consequences. We hypothetized that a multimodal perfusion monitoring will aid in this purpose, since the presence of low ScvO 2 , or increased central venous-arterial pCO 2 gradient, or an impaired peripheral perfusion together with hyperlactatemia might identify a hypoxic-related phenotype. This phenotype could be associated with worse outcomes as compared with a non-hypoxic profile. Objectives: To address this subject we perfomed a proof-of-concept retrospective study to assess if this approach can effectively differentiate two clinical phenotypes among hyperlactatemic septic shock patients. Methods: Retrospective analysis of a prospective database of patients with septic shock admitted to our ICU during the calendar year of 2014. Patients with persistent hyperlactatemia committed to full resuscitation and with complete multimodal perfusion monitoring and follow up after initial resuscitation were included. Statistical analysis included t-test and chi-square. Results: 44 patients (age 64 ± 16y, APACHE II 21 ± 7, SOFA 9.9 ± 3.5, abdominal and pulmonary main sepsis sources, hospital mortality 13.6 %) were included. No difference in basal severity, hospital mortality, first 24 h fluids, cardiac index or NE requirements between patients with an hypoxic (36) compared to anon-hypoxic (8) lactate profile was observed. Other results are shown in Table 32 . Conclusions: Patients with a hypoxic-lactate profile required more days in the ICU, and tended to receive more MV. They also received more rescue therapies and inodilators. A multimodal perfusion monitoring might be useful to recognize a hypoxic profile among septic shock patients with persistent hyperlactatemia that appears to be associated with worse outcomes and a more complex management. Our findings should be validated in prospective studies. The clinical characteristics and influence of vasopressors-induced peripheral ischemia in shock patients S. Introduction: As a potent vasoconstrictor, vasopressors play a critical role in the management of fluid resistant hypotension in septic shock for maintain the mean arterial pressure more than 65 mm Hg. Because of the wide variability in individual vasopressor requirement, the absolute maximum dose of vasopressor is difficult to determine. In general, when starting vasopressors, their doses should be titrated to the desired effect by closely monitoring the adverse effects such as hypoperfusion (particularly affecting the extremities, mesentery or kidneys), dysrhythmias, myocardial ischemia, local effects, and hyperglycemia. Objectives: We conducted the present study to assess the risk factors of inadequate perfusion of extremities during the vasopressors treatment in patients with severe septic shock. Methods: In this cross-sectional study, we evaluated the medical records of 73 patients who received vasopressors such as norepinephrine (NE), epinephrine, dopamine, vasopressin and dobutamine more than 48 hours in patients with severe septic shock in the medical intensive care unit at a tertiary university-affiliated hospital, from April 2014 to December 2015. The patients were stratified into ischemia or non-ischemia (control) groups according to whether peripheral ischemia developed or not. Results: A total 73 patients with septic shock were introduced vasopressors more than 48 hours. Basically, NE introduced in all patients but more than 2 vasopressors were 28, and 3 more than vasopressors were 14. Peripheral ischemic insults including color changes occurred in 43 patients (60 %). The median onset time for peripheral Introduction: There are currently over 120,000 people awaiting for a lifesaving organ transplant in the US with 22 patients per day dying on the waiting list. 1 An organ shortage is also the case for most European countries. Furthermore, the demand is rising due to increasing burden of certain types of organ failure, and widening eligibility criteria for transplants. In regards to procurement policies the debate is often exhausted between opt-in and opt-out, and not enough attention has been devoted to a "non-opt" policy. Such a policy, in the literature, is better known as organ conscription. 2, 3 Conscription entails the routine procurement of organs from the dead, making consent and family veto irrelevant. The policy tends to be uncritically rejected as being an extreme utilitarian position that violates core deontological side-constraints such as autonomy and personal sovereignty. Objectives: To examine the permissibility of conscription via normative ethics and formal justice analyses. Methods: Systematic review of the literature on the arguments for and against conscription to describe the current state of the debate. Subsequently and from a moral theory standpoint the policy is examined under the light of major normative theories such as consequentialism, deontology, and "mixed" views such as Parfit's triple theory. From a formal justice perspective, I employ Rawls's liberal principle of legitimacy and Sen's capabilities approach. Results: There are three strands of arguments for and against conscription. These are based on normative ethics, justice and metaphysics. Contrary to main-stream views, conscription is not only defensible in consequentialist terms but obtains an even stronger force when examined under a deontological and mixedtheory lights, as well as formal justice theory. Potential conscription from patients who have been declared dead by neurologic criteria has been estimated to increase organ supply by many thousands per year. Conclusions: We ought to reconsider our procurement policy in order to face organ shortage in ways that are ethical, just and maximally efficient. Organ conscription is such a policy. Introduction: Early mobility is defined as any activity capable of providing benefits to the patient from adequate positioning and passive movement to exercises and functional postures as orthostatism and ambulation. For early mobility success it is necessary a multiprofessional team working. Objective: To collect multiprofessional team perspective in order to verify their involvement in early mobility process. Methods: During a three days period we performed small groups dynamics with clinical examples to elucidate early mobility process. At the end, we evaluated the teams' perspective asking them to respond to one of each questions: 1) What do you consider important to the patient/family? 2) How can we contribute due to this experience? Results: 474 professionals were approached (cleaning assistant, nursing assistant, nurses, speech therapists, physiotherapists, and clinicians). 155 professionals (33 %) chose to answer the first question. The most frequent responses were: learn to listen (11 %), put yourself in the others point of view (10 %), team work (6 %), care with respect and love as if your own family member (6 %). The other 319 professional (67 %) chose to answer the second question. We separated the answers in regards to attitude, consequence and feeling of this experience. Attitude: motivation (13 %), willpower (105), commitment (7 %), focus (7 %), attention (6 %). Consequence: dedication (17 %), safeness (14 %), humanization (14 %), communication (105). Feelings: empathy (12 %), affection (11 %), love (10 %), fulfillment (9 %), patience (8 %), understanding (7 %). Conclusion: There is an emotional involvement of health care professional due to patients' assistance performance incentive. Introduction: Therapeutic hypothermia is indicated for refractory intracranial hypertension [1] and post cardiac arrest [2] . It may have effects on controlling secondary brain injury, which may occur after traumatic brain injury or brain ischemia. Objectives: To compare the range of motion (ROM) of immobilized joints to that of the other joints, which were passively mobilized. Methods: All patients requiring veno-venous or veno-arterial ECMO with one femoral cannula in situ were included. Joints not affected by ECMO were mobilized every day and evaluated by goniometry every 3 days until ECMO withdrawal. After ECMO withdrawal, all joints were mobilized daily and evaluated every 3 days until ICU discharge. ROM was compared before and after mobilization (Student's t test) and in immobilized and mobilized joints (ANOVA). Results: Ten patients (age 49 ± 15 years, 8 male, ICU mortality 40 %) with veno-venous (n = 5) or veno-arterial (n = 5) ECMO were included. Passive mobilization was well tolerated by all patients. The duration of sedation and ECMO was 6 ± 3 days. ROM was assessed until day 21 Introduction: Although the Spanish transplant network is regarded as one of the best in the world due to its high rate of donors (approximately 40 per million), nowadays the number of organs needed exceeds the demands. Objectives: To describe the end of the life care practices in patients suffering from severe non-reversible brain injury in order to evaluate their suitability as potential organ donors and to introduce a pathway for their identification and transformation into real donors. Methods: Multicentre, observational and prospective study (ACCORD project) in Spanish hospitals. Two period study: -First period (data collection): review of all the deceased patients in our hospital due to severe non-reversible brain injury and identification of potential organ donors. -Second (intervention period): creation of a pathway to overcome obstacles for the identification of potentials donors and convert them into real donors. Results: During the data collection phase we identified 24 patients with severe non-reversible brain injury. Thirteen of them (52.4 %) were males and 6 (25 %) were between 60 and 69 years old. The principal cause of death was stroke (haemorrhagic or ischemic). Fifteen patients (62.5 %) were admitted to the Intensive Care Unit (ICU) and the other nine (37,5 %) were not considerer by their primary care team as subsidiary of ICU care or as potential donors. Of the 13 patients admitted to the ICU, six died in brain dead and nine after circulatory dead. Four of the deceased patients in brain dead were real donors and five in the circulatory death group [37,5 % (n = 9) absolute donation rate]. Of the nine patients not admitted, only one had medical contraindications for donation (33,3 % of potential donors). In order to prepare for the intervention period, the data were analysed and shared with the different medical teams involved in the care of these patients and an algorithm was elaborated in order to identify the potential donors. Recollection of data for this second period is now underway. Conclusions: Hospitalized patients with severe non-reversible brain injury could contribute to the increase in the number of real donors. Programs aimed to spread the knowledge regarding the role of these patients as potential donors, and the creations of pathways and protocols to activate the transplant coordination team could be fundamental to increase the number of available organs. The participation of the intensivist in this kind of projects is essential as conditional ICU admission plays an important role. Introduction: In recent years there have been major advances in renal transplantation, including postoperative management, reflected in decreased in-hospital mortality. However, it remains a complex procedure in a group of patients with high comorbidity. Acute graft failure is one of the most common complications, increased in recent years due to non-heart beating donors (NHBD). Bedside ultrasound and radioisotope imaging tests are routinely used during postoperative management in ICU. Objectives: To analyze the concordance of renal doppler ultrasound (RDU) performed at bedside and radioisotopes tests after renal transplantation. Evaluate delayment in renal function in NHBD. Methods: Retrospective, observational study from 2013 to 2014. Inclusion criteria: patients admitted in the ICU in the postoperative of renal transplantation. Variables: Demographic information, type of donation, analytical values, diuresis and bleeding during the ICU stay, results of the imaging tests (ultrasound resistance index less than 0.7 and good perfusion in scintigraphy), transfusion, creatinine levels at discharge, days of hospitalization in the ICU and mortality. Descriptive statistical analysis using U of Mann-Whitney test for differences between groups and Kappa test for the agreement between flow tests. Results: 172 patients were included in our study. 62 % were male. The median age was 52 (RI 41-61) years old. Characteristics of the patients are shown in Table 34 . The median time of ICU stay was 1 day (RI 1-2). No deaths were registered. Agreement between imaging tests reached a Kappa Index of 0.5 (p < 0.001) (Table 35) . Conclusions: Kidney transplantation postoperative has a short length of stay at the ICU. Renal grafts from un-controlled NHBD showed a delay in the improvement of kidney function compared with other types of donors. A medium agreement between RDU and scintigraphy was observed. Introduction: Survival following critical illness is improving and the focus is moving towards optimisation of recovery. However, rehabilitation is poorly understood and national guidance recommends the need for information to be delivered to patients and their carers in an appropriate way (NICE CG83, 2009). In order to demonstrate adherence to national guidance and improve the patients' and their carers' awareness about rehabilitation in the acute phase of recovery following critical illness, this project aimed to develop, implement and evaluate an information booklet on rehabilitation after critical illness. Objectives: To evaluate the impact of introducing an information booklet on compliance with CG83 standards. Methods: A three stage approach was used. Firstly, current evidence was critiqued to identify the important and required informational needs. This information was then used to design and develop the information booklet by the author. This was then introduced and evaluated for a period of 8 weeks. Compliance with NICE CG83 was analysed using the guideline specific audit tool. A locally produced service evaluation questionnaire and a booklet feedback form were used to generate qualitative and quantitative outcomes. Results: Over the evaluation period the booklet was issued on n = 29 occasions, with n = 13 completing analysis. Following the implementation of the booklet, compliance with NICE guidance (see Table 36 ) improved from 0 % to 100 %. Improvements were made in all but two areas of the service evaluation questionnaire. Out of 53 feedback comments received, 45 were positive. Conclusions: Production of the critical illness information booklet was an effective method in meeting national guidelines for Objectives: The department's existing system and equipment for transfers were perceived to be inadequate. This project was to assess the current system and implement any necessary change. Methods: The contents of three existing bags were audited to assess uniformity. Users' perception and experience of the bags were audited. The results were poor. Following this, a standardised kit list and Standard Operating Procedure (SOP), compliant with ICS guidelines (3), were agreed by all members of the anaesthetic, theatre and ICU departments. New bags and protocols were introduced. Users' perception of the bags was then re-audited. Results: The audit of the old bags showed that only 27 % of items were present in all 3 bags, that there was no standardised kit list, and that some items were out of date. Overall rating of the bags increased from 3.5 to 8.4 following the introduction of these changes. Conclusions: Introduction of a standardised kit list and a robust system for checking the bags has improved consistency, safety and user satisfaction. Following further use, the kit list will be reviewed and revised as necessary. Consideration should be given to the Surrey Critical Care Network adopting these bags and procedures. Introduction: Delirium and Intensive Care Unit Acquired Weakness are two of the most common sequelae in patients recovered in Intensive Care Unit (ICU) [1, 2] . The ABCDE bundle (Awakening and Breathing trials, Choice of sedative and analgesics, Delirium monitoring and Early mobility) is a multicomponent approach effective in preventing these complications [4] . Despite a large amount of literature about the ABCDE bundle is available, a previous attempt of implementation in an Italian environment has never been reported. Objectives: The aim of this study was to implement the ABCDE bundle in a general ICU of a large university hospital in northern Italy. Methods: A multidisciplinary team, consisting of critical care physicians and nurses, reviewed the literature and developed a protocol tailored on the Italian environment. Before the ABCDE bundle was part of the routine practice, education of nurses and physicians has been provided through meetings, reminders and poster that summarized the key steps of the protocol was posted by the patients´bedside. After the ABCDE bundle was part of the routine practice a quality improvement (QI) program to strengthen the bundle knowledge has been realized: every nurse and physician attended a training course while data about facilitators and obstacles to the bundle implementation was collected. Data about adherence to the protocol has been collected to evaluate the effect of QI program. Results: The ABCDE bundle has been implemented in November 2014. The Early mobility protocol became standard care from March 2015. During the QI program, some hindering factors to the implementation were identified, such as communication issues between team members, lack of resources and low confidence with the protocol. In the first quarter post-implementation 27 % of total patients were mobilized, in the second quarter post-implementation 67 % of total patients were mobilized dangling or out-of-bed. Adverse events related to the bundle were not observed. A year after the initial implementation, the "F" phase has begun to be incorporated into everyday practice, with a wider opening hours to relatives and a project of live musicians. Conclusions: Although there is no available data about a previous implementation of the ABCDE bundle in an Italian setting, our experience demonstrate that it is feasible and safe. Further efforts are needed to spread the knowledge of the ABCDE bundle and improve adherence to protocol. Introduction: Myocardial injury, as reflected by elevated plasma cardiac troponin levels, has repeatedly been reported in patients with community-acquired pneumonia (CAP), but its temporal dynamics have not been systematically studied. Furthermore, although troponin release has been associated with increased mortality, its etiology still remains unknown. Objectives: Our aim was to determine the incidence of troponin release in CAP patients and provide a detailed description of the clinical and pathophysiological setting during which it occurs. Methods: We enrolled consecutive patients admitted with CAP to the intensive care units (ICU) of two tertiary care centers in the Netherlands between January 2011 and May 2015. Patients transferred from another hospital, patients after cardiac arrest, and patients not meeting criteria for organ failure were excluded. Highsensitivity cardiac troponin I (hs-cTnI, Abbott ARCHITECT STAT High Sensitive Troponin-I) was measured daily during the first week. ICU days were categorized into days with troponin release (days followed by a 40 % increase in hs-cTnI on the next day and an absolute rise >26 ng/L), days without troponin release (days followed by a >40 % and >26 ng/L decrease in hs-cTnI, or a value beneath the upper reference limit (URL) of 26 ng/L), and days with possible troponin release (if fulfilling none of these conditions (Table 37) . Furthermore, several extrinsic factors (e.g., acute kidney injury and cardiotoxic medication use) were also associated with troponin release. Conclusions: Troponin release occurs in a majority of CAP patients. Increased myocardial workload (resulting in supply-demand mismatch) and an activated coagulation system could be potential causes of this injury. This study was performed within the Molecular diagnosis And Risk stratification of Sepsis (MARS) project (grant-04 l-201). Evolution & impact of thrombocytopenia in septic shock C. Introduction: Autonomic dysfunction is associated with increased mortality in septic shock (SS) [1] but little is known about the mechanisms behind this relation. Objective: To analyze the association between changes in cardiovascular indices extracted from arterial blood pressure (ABP) and heart rate (HR) waveforms and progression of organ failure in SS. Methods: This is a preliminary analysis of patients recruited in Geneva University Hospitals for the prospective observational study Shockomics, from 10.2014 to 12.2015. Twenty SS patients followed during the first 3 ICU days were stratified according to change in SOFA score from day 3 vs. day 1 into "Recovery (R)" (ΔSOFA < −1, n = 13) and "Non-recovery (NR)" (ΔSOFA ≥ 0, n = 7) groups. Time series of systolic (SAP) and diastolic (DAP) AP and heart period (HP) were  Hypotension (hours MAP<60 mm Hg) Shock index (hours HR/SBP > 1) 0 (0-6.0) 0 (0-5. . Baroreflex sensitivity (BRS) was computed by the spectral analysis and transfer function methods. Wilcoxon Ranksum and Friedman tests were used to assess differences between groups in each day and differences within the same group over the 3 days, respectively. Significance is for p < 0.05. Results: There were no significant differences between groups in demographic characteristics or comorbidities. For the HP series, there was a significant increasing trend in total power from day 1 to 3 in the R group (p = 0.0249); LF% also increased in the R group only (p = 0.0125). Mean DAP values increased significantly in the R group from day 1 to 3 (p < 0.01). LF power (mmHg 2 ), LF% and LF/HF in the DAP series increased significantly in the R group (p = 0.0183, p < 0.01 and p = 0,0498 respectively). In the 2 nd and 3 rd ICU days LF power (mmHg 2 ), and LF% were higher in R compared NR patients (p = 0.0394 and p = 0.0476 respectively). There were no significant differences in the SAP series. Baroreflex indices showed an increasing trend in both groups without statistically significant results. Conclusions: Variability of HR significantly increased in SS patients presenting organ function improvement over the first 3 ICU days. This may be driven by increased sympathetic autonomic activity. The mean value of DAP, considered to reflect vascular resistance driven by sympathetic vasomotor tone, raised only in the Recovery group. The ability to increase DAP could be a sign of responsiveness to vasoconstrictors. Interestingly SAP was not different between the 2 groups; this could be due to the fact that it is used as target for therapy. Further investigations are required to find specific associations with drug dosage, namely symphatotonic drugs, and clinically relevant outcomes. Introduction: Mortality in severe sepsis and septic shock is predicted independently by a variety of factors, such as, hyperbilirubinemia, since there is evidence that it can induce inflammation, and apoptosis. 1-3 However, animal data suggested that bilirubin has antioxidant properties that might be cytoprotective. 1, 3 To date, evidence of the discriminative power of bilirubin on survival due to its alleged antioxidant effects are lacking. Objectives: We hypothesized that milder elevations of bilirubin might be protective and associated to better outcomes. Our secondary outcome is to identify a level of bilirubin with discriminative power either for survival or mortality. Materials and methods: We conducted a retrospective study using our unit database, collecting data from 2008 to 2015, including patients >18 years-old, meeting the criteria for severe sepsis and septic shock according to the American College of Chest Physicians/Society of Critical Care Medicine Consensus Conference. 4 We identified the highest serum bilirubin levels within 72 hours of ICU admission and then stratified into 4 cohorts based on hepatic SOFA cut-off values. SOFA and APACHE II scores were recorded. Results: We analyzed 642 patients. The highest bilirubin level was 25,1 mg/dL. Stratifying in the four cohorts, we found a significant decrease in survival from a bilirubin ≥1,2 (OR from 2 to 7,2 (p < 0,001)) with the highest impact from moderate increases (Wald score of 26) (graphic 1). Patients with >11,9 mg/dL had a mean survival of 3 days. There was also a significant difference in severity scores, renal function, liver enzymes and lactate values between the groups, which was analyzed in a Logistic regression. There was no significant difference for UCI-days and length of mechanical ventilation. Discussion: We found hyperbilirubinemia to be independently associated with increased risk of death but no difference in other outcomes, in this population. Despite a lower mortality rate, moderate elevations were not protective but were found to have a higher predictive weight to ICU mortality. We ponder if the protective role of mild elevations, might be true only for patients with hyperbilirubinemia over a much longer time frame that critical patients, which should be studied in future prospective studies. Conclusion: Elevated bilirubin levels in patients with severe sepsis and septic shock were significantly associated with an increased risk of ICU mortality, but not longer ICU stay and length of mechanical ventilation. The protective role of the stress-induced rise of bilirubin in septic shock, was not proven. Conclusions: Diastolic dysfunction was seen in 90 % of patients. fever, HR, WBC counts still good early indicators for diagnosis of sepsis.Vasopressors withdrawal on 7th day was good predictor for survival. Admission serums IL-6, IL-10 & CRP from PV were better indicators for Sepsis than IL-1, Pro-BNP & Troponin I.admission TNF-α & 7th day IL-6 levels were highly prognostic to mortality.CS samples proved that NT Pro-BNP is a good indicator for sepsis diagnosis & a good predictor for survival,TNF-α from CS samples was also a good predictor for mortality. SAPS II .A slower E`d/t on admission was good predictor to mortality. Note: This abstract has been previously published and is available at [2] . It is included here as a complete record of the abstracts from the conference. Introduction: Sepsis-associated encephalopathy (SAE) is associated with increased morbidity and mortality in septic patients. The pathophysiology of SAE is incompletely elucidated. It has been hypothesized that impairment of cerebral autoregulation (CAR) would result in brain hypoperfusion and neuronal damage (1), but previous studies showed conflicting results (2,3). Objectives: The aim of the study is to evaluate CAR in septic shock patients and test the hypothesis that its alteration is associated with clinical encephalopathy or brain perfusion. Methods: Adult patients diagnosed with septic shock and admitted to the ICU stay were included (July 2015 -March 2016). Exclusion criteria were: intracranial disease; arrythmias; extra-corporeal membrane oxygenation; intra/extra-cranial arteriopathy. Transcranial Doppler (DWL, Germany) was performed insonating left middle cerebral artery (LMCA) with a 2-MHz probe. LMCA blood flow velocity (FV) and arterial blood pressure (BP) signals were simultaneously recorded; Pear-son´s correlation coefficient between BP and FV (Mxa) was calculated using MATLAB (MathWorks, USA). Impaired CAR was defined as Mxa > 0.3 (4) . 3), PaCO2 level < vs ≥ 40 mmHg (p = 0.9) and presence of encephalopathy (e.g. GCS < 15 on admission) (p = 0.5). Also, no association between Mxa and mean BP or dose of vasopressors was noted. Conclusions: CAR was altered in almost half of the patients with septic shock. No association between autoregulation and clinical encephalopathy or determinants of brain perfusion was found (Table 38) . ICU LOS (days) 8 [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] Introduction: Septic shock is a life threatening condition associated with high mortality. Poor outcome is mainly related to the inadequacy between oxygen delivery and cellular demand leading to the onset of multiorgan dysfunction. Whether this multiorgan failure affect the pancreas is not fully investigated [1] . Objective: To assess the prognostic value of increased pancreatic enzymes in patients with septic shock. Methods: We conducted a prospective study in a 12-bed medical surgical intensive care unit. All patients admitted with septic shock were included. Demographic, clinical and biological data were recorded on admission. Serum amylase and lipase levels were checked on day 1 and day 2. All the patients with increased amylase and/or lipase serum level underwent imaging investigations. Quantitative variables were expressed as median [ Conclusion: The increase of pancreatic enzyme is common in patients with septic shock. However, pancreatic injury does not affect the prognosis of these patients. In our center, although promoting the standardization and individualization of sepsis treatment, some patients die. We examined some factors of the patients with sepsis. Objectives: We searched the worse factor of the prognosis of septic patients. Methods: This study was a retrospective observational study in a single center. We studied the patients with sepsis who admitted from the emergency department to the ICU in our hospital. We defined sepsis as patients with SOFA score 2 points worse than sepsis onset before (Sepsis-3 Definition) (3). The study period was from Jan. 2014 to Jun. 2015. Gender, age, APACHE2, SOFA, and KDIGO classification of AKI were checked. Results: The number of patients was 60: non-survivor 18(30 %), and survivor 42(70 %). Table 39 showed the characteristics of each group. Table 40 showed the correlation between KDIGO classification and the prognosis. As APACHE2, SOFA, and KDIGO classification of AKI were bad, life prognosis was bad. Among SOFA score, renal function and respiratory function were well correlated with patients mortality. Conclusions: The acute kidney injury and acute respiratory failure were especially worse prognostic factor among septic patients. is over-activated,causing a consumption of clotting factors until DIC.This extreme condition is associated to a higher mortality.RO-TEM®, a point-of-care assay based on viscoelastic measurements of coagulation changes in whole blood,could be useful to study the coagulative profiles in patients at risk of DIC [1] . However, the use of ROTEM®for the management of SS has not been validated,yet. Objectives: The aim of this study was to evaluate the possible role of ROTEM®as a diagnostic and prognostic tool in SS.In particular,we assessed its ability to identify critically ill-patients at high risk of DIC. Methods: 21patients(43%M,57%F)admitted to our ICU with a diagnosis of SS [2] were enrolled.Exclusion criteria were:end-stage heart failure and liver disease,severe cancer, age < 18y, pre-existent hematological disorders,ongoing anticoagulation and antiplatelet therapy. 21 Hepatic dysfunction represents a common manifestation during the sepsis process, involving portal inflammation, centrilobular necrosis, lobular inflammation, hepatocellular apoptosis, steatosis and cholangitis. The splanchnic hypoperfusion and the subsequent microcirculation injuries are causative factors among other multiple factors leading to the hepatic dysfunction in sepsis. However, how much of the liver dysfunction is recovered after discharge from hospital is still little known. Herein we evaluated the impact of sepsis on liver structures in sepsis survivals. Methods: Adult Wistar rats (200 g) (n = 12) were submitted to sepsis [iv. 2 mL E. coli 10 9 CFU/ mL (S9), DL80 in 26 hours]. After 2 h, 6 h, 24 h and 30 days, (T2h, T6h, T24h and T30d), the animals were sacrificed, and samples of liver were collected and stained with H&E, PAS and Sudan-Black. The T30d animals were considered survivors since the mortality of sepsis S9 is 80 % from 26 hours after induction Results: The histological results show that S-9 sepsis model determines a rapid and progressive liver damage. In the period of T2h, although predominant hepatic aspect of normality was observed, there was the onset of a sinusoidal congestion of focal occurrence, presence of polymorphonuclear cells in the lumen of the vein hepatic centrilobular and by PAS staining was observed the glycogen accumulation in cytoplasm of hepatocytes, except around centrilobular vein. At T6H, there was a generalized sinusoidal congestion, significant polymorphonuclear cells infiltration in the portal area and presence of leukocytes adhering to the endothelium of the centrilobular vein. Besides, was also observed some hepatocytes with shrunken nucleus suggesting apoptotic cell death in progress. PAS showed a overall decrease of glycogen in hepatocytes, suggesting a high consumption of energy due to the exacerbated inflammatory process of sepsis. Twenty four hours post sepsis, the liver was congested, mainly in centrilobular veins, suggestive of increased vascular resistance in the liver. The infiltration of polymorphonuclear cells, predominantly in centrilobular and periportal areas suggested the leucocyte invasion into the liver parenchyma and subsequent proinflammatory reaction. PAS staining showed the presence of multiple small vesicles inside the hepatocytes, suggestive of initial degenerative process in progress and this proved to be fat vesicles by Sudan Black staining. In 30 days after sepsis recovery, the sinusoidal spaces were compressed and some congestions were located in the centrilobular vein, moreover, there were liver cell degeneration with pycnosis and hyaline degeneration, suggesting a chronic phase of liver dysfunction. The overall findings demonstrated a multiple liver parenchymal abnormalities in post-sepsis period, suggesting the fragility of the liver physiology to fight against a new infectious challenge. Introduction: The splanchnic reticulo-endothelial system is fundamentally involved in bacterial clearance both via innate and adaptive immune responses. It has e.g. been reported that hyposplenism is associated with an unfavorable outcome in sepsis. We hypothesized that systemic inflammatory response (SIR) induced immunosuppression leads to decreased trans-splanchnic microbial clearance. Objectives: To investigate if pre-existing systemic inflammation affects the splanchnic bacterial clearance. Methods: Fifteen anesthetized pigs were subjected to an infusion of E. coli in a cervical vein for 3 hours. To induce a systemic inflammatory response, group "EtxPreExp" (n = 6) received a continuous intravenous endotoxin infusion starting 24 h prior to the E. coli infusion. Group "UnExp" (n = 6) received the bacterial infusion without prior endotoxin exposure. To understand the effects of 24 h anesthesia alone, three animals received saline instead of endotoxin for 24 h prior to the bacterial infusion ("Controls"). According to the predefined statistical plan, "Controls" were not included in the primary analysis. Bacterial counts in arterial and portal venous blood were analyzed hourly during the E. coli infusion, and were corrected for the bacterial dose administered per body weight. Blood samples were analyzed and physiologic parameters were recorded throughout the experiment. Results: All animals receiving endotoxin developed SIR prior to the E. coli infusion. The amounts of administered bacteria were comparable between the groups. There were no differences between EtxPreExp and UnExp groups in log arterial (2.47 (±0.49) vs. 2.38 (±0.57) CFU x mL −1 corr ; mean ± SD) or portal (2.40 (±0.36) vs. 2.11 (±0.77)) bacterial counts at 3 h, just before the end of the bacterial infusion. Furthermore, there was no difference in the ratio of portal vein to arterial bacterial counts between the EtxPreExp and UnExp groups (Fig. 65 ). White blood cell counts (p < 0.001), mean arterial pressure (p < 0.01), base excess (p < 0.05) and pH (p < 0.001) were lower, while arterial lactate levels (p < 0.001) were higher in UnExp vs. EtxPreExp group during and after the E. coli infusion. Conclusions: Our preliminary results show that despite diminished immunologic and physiologic response, induced by pre-existing inflammatory response, the splanchnic bacterial clearance is not affected in E. coli septic shock. Objective: To investigate the effect of biliary tract external drainage (BTED) on liver of severe acute pancreatitis (SAP) rats and the relationship with heme oxygenase-1 (HO-1) pathway. Methods: SD rats weighing 250-300 g were randomly assigned into five groups (n = 6): sham surgery (SS) group, SAP group, SAP + BTED group, SAP+ zinc protoporphyrin IX (ZnPP) group, SAP + BTED + ZnPP group. The SAP model was induced via retrograde injection of 4 % sodium taurocholate (1 mL/kg) into biliopancreatic duct through duodenalwall. BTED was performed by inserting a cannula into the bile duct of SAP rats. Tissue and blood samples were collected 24 hours after surgery. Pathological changes in organs were scored. The level of amylase, alanine transaminase(ALT), aspartate aminotransferase (AST) in serum were measured. The expression of hemeoxygenase-1 (HO-1), tumor necrosis factor-α (TNF-α), and interleukin-6 (IL-6) in tissues were analyzed by real-time PCR and western-blot. Results: Liver damage in SAP rats was significantly alleviated by BTED (p < 0.05). Compared to the SAP group, the serum level of amylase, ALT, AST, were significantly lower in the BTED group (p < 0.05). The BETD treatment led to a significant reduction of TNF-α, IL-6 level and a significant increase of HO-1 level in tissues than in SAP rat (p < 0.05). ZnPP significantly inhibited all mentioned effects. Conclusions: BTED protected liver against SAP related injuries via the HO-1 pathway. Objectives: The aim of our observation retrospective study was to test the hypothesis that a correlation exists between percentage of ventilated patients developed VAP (% VP) and the main nursing, severity and outcome indexes in our both medical and surgical ICU served in community hospital. Methods: From January 2006 to June 2014 admitted to our ICU 620 patients, mean age 64.8 years, mean length of ICU stay (LOS) 14.2 days, mean mechanical ventilation duration per ventilated patient (V. Days) 12.23 days, mean APACHE II score on addition 21.2, predicted mortality 38.9 %, actual mortality 31.45 %, Standardized Mortality Ratio (SMR) 0.80. From our database we looked for between percentage of ventilated patients developed VAP (% PV VAP) as well as the above nursing and severity indexes per year from 2006 to 2013 and per six months period for the latest year 2014. Using linear correlation method, we looked for linear slope, correlation coefficient (r), and coefficient of determination (r 2 ), and by linear regression method using ANOVA test we looked for p value, according % PV VAP and nursing (LOS, VD), severity (age, APACHE, Predicted mortality) and outcome (Actual mortality, SMR) indexes. Conclusions: According to our data, there was no statistically significant correlation detected between percentage of ventilated patients developed VAP and Age, LOS, APACHE II score, Predicted Mortality, Actual Mortality and Standardized Mortality Ratio. On the other hand, we detected statistical significant positive, moderate correlation between percentage of ventilated patients developed VAP and Ventilation Days. Our data suggest that the more the ventilation days, the more the percentage of ventilated patients developed VAP increases. Introduction: Metered dose bronchodilator inhalation through ventilator circuit has long been used in intubated patients of chronic obstructive pulmonary disease (COPD). However, fixed drug dosage now commonly used has not been endorsed by manufacturers nor proved clinically effective [1] . Evidences suggest drug delivered this way has suboptimal lung deposition [2] . Also, great individual variations among patients make them imprecise and unreliable [3] . Objectives: We proposed an experimental bronchodilator dosing schedule based on each individual's airway resistance (R aw ) monitored periodically. This study tests its efficacy in R aw reduction. Methods: Fifty-one just-admitted, invasively ventilated COPD patients were randomly assigned to receive either personalized or fixed bronchodilator dosing. Personal target R aw was defined by measuring each one's R aw after maximally broncho-dilated by consecutive 4, 8 and 16 puffs of fenoterol metered dose inhaler (100 mcg). Thereafter, R aw was measured every 8 hours until the 28th day. Patients of the fixed dose group received only predetermined dose. Additional doses of bronchodilator were given to patients of the personalized dosing group when measured R aw exceeded patient's target R aw . Both groups received rescue short-acting bronchodilator when dyspnea exacerbated. Results: The relative deviation of R aw from its personal target was expressed as (measured R aw -target R aw )/target R aw . Experimental group has a smaller relative R aw deviation than control group (0.09 ± 0.10 vs 0.44 ± 0.11, P = 0.022). In a multivariate linear regression model analysis, R aw of experimental group tended to become closer to its personal target over time (−0.031 point of relative deviation every day). Whereas that tendency was deviation away from its target over time in control group (0.004 point of relative deviation every day) (Fig) . The two groups did not differ significantly in ventilator-free days from day 1 to 28, percentage of breathing without assistance by day 28, episode of nosocomial pneumonia, total puffs of rescue bronchodilator, number of drug-related adverse effect or mortality rate at day 180. Conclusions: Personalized dosing of bronchodilator inhalation to invasively ventilated COPD patients produce a better R aw reduction profile than fixed dosing. The conclusions of this pilot study need consolidation by further investigations. Objective: Review our experience in the management and evolution of patients with Severe ARDS during 3 years in a second level hospital. In our analysis we took into account the treatment approach, mode of ventilation, PEEPs, the resistance and compliance values reported by the ventilator and recorded automatically. Methods: A retrospective study of ICU patients requiring mechanical ventilation between 2013-2015 at Hospital Virgen de la Concha(Zamora, Spain) due to severe ARDS. 23 patients admitted during this period have a deterioration of PaO2/FiO2 to levels lower than or equal to 100 during a 24 hours period and requiring at least 5 days of ICU admission. Epidemiological data, presumed cause of ARDS, management (steroids, neuromuscular blocking agents, inhaled beta-agonists), mechanical ventilation parameters (maximum PEEP,resistance,compliance,driving pressure) were analysed. We divided arbitrarily between HOR (high concentration of oxygen required, greater than or equal to 60 %) and LOR period (low oxygen concentration required, less than 60 %). Results: The overall severe ARDS mortality was of 56.52 %. The pronation strategy was carried out in 39.13 % of the patients. The median ICU stay, mechanical ventilation and high oxygen requirement (HOR) duration was of 24.47; 16.6 and 8.43 days. The maximum PEEP used in this group of patients was 17 cmH20; with a median value of 13.2 cmH20. The pulmonary resistance, compliance and driving pressure (DP) in the non-surviving group were (19.21 cmH20/l/sec; 45.39 ml/cmH20; 14.20 cmH20), in the surviving group were (15.38 cmH20/l/sec; 47.82 ml/cmH20; 12.10 cmH20). The mortality in the group with DP higher than 15 during HOR was 100 %, being 33.3 % in the group with lower DP values (p < 0.05). Conclusions: We found that non-surviving patients have higher resistance and lower compliance values in their respiratory system and the improvement of its values were associated with better clinical outcome.The driving pressure was the variable that best stratified the surviving and non-surviving patients. (Table 42) . Conclusions: Incidence and outcome of VAC and IVAC were similar in COPD and non COPD patients. Agreement between VAC or IVAC and VAP episodes was poor in the two groups. We found no significant changes in C rs (from 37 ± 7 to 40 ± 13 ml/mbar, p = 0.48), ΔP (from 10.8 ± 1.6 to 9.8 ± 1.5 mbar, p = 0.14) and SDRVD40 (from 11.2 ± 4.1 to 8.6 ± 2.5 %, p = 0.07). Conclusions: Our preliminary results indicate that adjustment of mechanical ventilation according to the EIT-based algorithm is feasible and leads to ventilator settings that are associated with improved oxygenation. Introduction: PEEP is a key element of protective mechanical ventilation. Nevertheless, the identification of feasible bedside methods for "optimal" PEEP selection is still controversial. EIT allows real time monitoring of changes in End Expiratory Lung Impedance (ΔEELI), which corresponds to end-expiratory volume. We reasoned that ΔEELI decrease after a Recruitment Maneuver (RM) might indicate alveolar de-recruitment and inadequate PEEP. Thus, we aimed at identifying PEEP level able to minimize decrease of ΔEELI. Methods: We enrolled 15 intubated sedated paralyzed hypoxemic patients undergoing controlled ventilation. The study consisted of 3 steps during which protective tidal volume and FiO 2 were kept constant and ΔEELI was continuously monitored: -Step 1: PEEP was selected according to the ARDSnet protocol 1 . -Step 2: a) a RM was performed, applying pressure of 40 cmH 2 O for 40 seconds; b) ΔEELI was measured within 30 seconds (ΔEELI 30sec ) and after 10 minutes (ΔEELI 10min ); c) if we observed that (ΔEELI 30sec -ΔEELI 10min ) ≥10 % of ΔEELI 30sec , a new RM was performed followed by PEEP increase by 2 cmH 2 O. Steps b) and c) were repeated until PEEP level associated with (ΔEELI 30sec -ΔEELI 10min ) < 10 % of ΔEELI 30sec (EIT-PEEP) (Fig. 66 ). . Donor/recipient lung size mismatch was calculated according to the ratio between donor and recipient predicted total lung capacity (pTLC ratio). Tidal volume set according to recipient PBW was 6.6 mL/kg ± 0.7 in undersized grafts (pTLC ratio < 1) compared to 6.7 ml/kg ± 0.7 in non-undersized grafts (pTLC ratio ≥ 1). When tidal volume was computed according to donor PBW, it was significantly higher in patients with undersized grafts (pTLC ratio < 1) compared to non-undersized grafts (pTLC ratio ≥ 1) (7.2 ml/kg ± 0.9 vs 5.9 ± 0.7, p < 0.001). The incidence of PGD3-72 h was higher in undersized compared to non-undersized grafts (12 % vs 6 %, p = 0.052), but not statistically significant. Objectives: To compare the changes between the baseline ventilator settings and the "Express" strategy in terms of respiratory system mechanics and gas exchange. Methods: Patients with early (<48 hours) moderate ARDS were included (Berlin definition). Baseline settings were adjusted according to our routine clinical practice and thereafter PEEP level was titrated to reach a Plat 28-30 cmH 2 O ("Express" strategy). FiO 2 , respiratory rate (RR) and tidal volume (Vt) were kept unchanged. Measurements of respiratory system mechanics and gas exchange were done at baseline and after 2 hours of "Express" settings. Patients were classified as responders or non responders according to their change in PaO 2 /FiO 2 (>25 mmHg) as described 2 . Results: We prospectively analysed 12 consecutive patients (9 males, aged 56 ± 19 years). A comparison of respiratory system mechanics and gas exchange between baseline and "Express" is detailed in Table 44 As expected, the overall comparisons showed significant changes in PEEP and Pplat and a significant improvement in oxygenation. The main differences between PEEP responders (n = 6) and PEEP non responders (n = 6) are shown in Table 45 . Conclusions: Overall, patients with moderate ARDS significantly improved oxygenation when the PEEP "Express" strategy was implemented. However, half of our patients did not improve oxygenation and parameters of respiratory mechanics also worsened. The (3). EIT can visualize this, enhancing the decision on the best compromise between alveolar overdistension and collapse. Whether EIT guided PEEP is better than Cdyn guided PEEP remains to be determined. Introduction: LPV is the gold standard for mechanically ventilated patients with features of, or at risk of ARDS 1 . Uptake of ARDSnet guidelines into clinical practice has been variable 3 ; this service improvement project identifies some of the barriers to changing practice and demonstrates that improvement is possible. Objectives: We identified the variation in practice in mechanical ventilation across an 78 bedded mixed Intensive Care Unit (ICU) in a tertiary referral centre and implemented a strategy to promote LPV. We aimed to identify and address the barriers to the use of LPV through an ongoing education program. Methods: Audits have been performed comparing unit practice to the guidelines for LPV issued by ARDSnet. All staff on the unit were invited to respond to an electronic survey regarding the use of LPV in our unit, Unit guidelines have been written to guide all staff in the use of LPV and bedside laminates supporting LPV decision making have been attached to all the ventilators in our unit. Results: There has been an improvement in the percentage of patients compliant with lung protective ventilation from 14.9 % to 29.0 %, a decrease in peak airway pressures greater than 30 cmH20 and an increase in those ventilated with tidal volumes less than 6 ml/kg (26 % to 64 %). There is an ongoing downward trend in tidal volumes with 64 % of the final cohort ventilated at < 6 ml/kg compared with a majority of 6-8 mls/kg in the previous two cohorts. Key barriers to the use of LPV were identified. Conclusions: We have demonstrated that with guideline implementation, education, promotion and decision support tools LPV performance can be improved. Whilst the tide is changing, there is still a significant performance gap; the implementation of change into healthcare practice faces challenges of information dissemination, unit culture, perceived role understanding, authority hierarchy and variation between multiple autonomous practitioners. Introduction: Inappropriate mechanical ventilation can lead to dynamic hyperinflation and autoPEEP. In the absence of an esophageal catheter, dynamic hyperinflation is typically evaluated from the expiratory flow profile with the absence of zero flow at end expiration illustrating incomplete expiration. In patients with spontaneous breathing, expiratory profiles can vary breath to breath, making interpretation of flow profiles difficult. Additional information may be present in the capnography signal. As incomplete expirations will result in early termination of the expiratory CO2 signal and low endtidal CO2 (ETCO2), a combination of complete and incomplete expirations will result in variability in ETCO2. Objectives: This study investigates whether systematic patterns of expiratory flow and ETCO2 exist in mechanically ventilated patients with spontaneous breathing. Methods: Respiratory flow and capnography signals were analysed in eleven patients on pressure support ventilation, each ventilated at 3-5 pressure support levels. Part of these data have been published previously (1) . Flow signals were analysed to calculate the average number of incomplete expirations over a 20 breath window. CO2 signals were analysed to calculate the variability (2*SD) in ETCO2 over the same window. Data including 2350 sets of 20 breaths were categorized according to the analysis of flow into 3 groups, few incomplete expirations (<2 in 20), some incomplete expirations (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) (18) in 20) and many incomplete expirations (>18 in 20); and the variability of ETCO2 was calculated for each of these groups. A Wilcoxon rank sum test was used to compare median ETCO2 variability between groups. Results: Significant differences were found for median ETCO2 variability between the three groups. For few (<2) and many (>18) incomplete expirations, ETCO2 variability was low ( (Table 47 ). There was no obvious relationship between TEG values and the risk of thrombosis. All baseline TEG variables were poor predictors of both bleeding within 5 days of inclusion and during the ICU admission (Table 48) . Conclusion Baseline TEG did not predict bleeding in our heterogeneous cohort of haematological ICU patients with severe sepsis. Thrombotic events were few. Introduction: Undiagnosed HIV infection poses a significant public health burden in the UK; a fifth of infected individuals remain unaware. 1 Our ICU is situated in Milton Keynes, a city with an unexpectedly high HIV prevalence and one of the highest late diagnosis rates in the UK. 2 This is relevant to critical care as HIV infection may influence a patient's outcome and since ICU admission provides a unique opportunity to offer testing. UK Guidelines for HIV testing 3 do not specifically address ICU patients. However, consideration of universal testing is recommended for medical inpatients when local prevalence exceeds 2 per 1000, as in Milton Keynes. Our previous practice of HIV testing was based on informal assessment of risk, with correspondingly low testing rates. Evidence shows that testing rates increase when opt-out policies are adopted in other settings 3 and we elected to implement this in our ICU. In patients with capacity, we sought consent prior to testing. In those lacking capacity, testing was performed in their best interests. There is limited UK data on the cost-effectiveness of expanded HIV testing but US data suggests it is cost-effective if 1 new diagnosis is made per 1,000 tests. 4 We report our experiences following a year of opt-out testing. Introduction: Over the last decade, survival rates in critically ill cancer patients have improved dramatically. [1] Earlier admission to the intensive care unit (ICU) has resulted in better survival rates for critically ill cancer patients. [2] Selecting patients likely to benefit from ICU admission is based on complex criteria, and some ICU specific therapies such as mechanical ventilation; have been associated with an increase in mortality. [3] Objectives: To identify clinical characteristics of oncological patients admitted to our ICU and to identify risk factors associated with 14 day mortality in this specific population. Methods: Five -year retrospective observational analysis was performed including all patients with a personal history of active oncological malignancies admitted to the ICU of a tertiary care University Hospital in Spain. Patients´demographic, clinical features and outcome were recorded. Data were expressed as frequency (percentage) and median (interquartile range IQR). Multivariate logistic regression with significant covariables at 0,05 was performed to identify specific risk factors for 14 day mortality. Results: One hundred and thirty six patients were registered in this period. Age (median 60,IQR 2575: 5270), ICU Length of stay (LOS) (median 5 (IQR 2575:28) Principal reason to admission to ICU was respiratory failure (41,9 %), followed by septic shock (33,8 %) and low conscious level (8,1 %). Top three solid malignancies were lung (27.2 %), followed by breast (12.5 %) and Bowel (11.8 %) . No differences in co morbidities between Survivors and nonsurvivors at 14 day were assessed. APACHE II score was higher in non survivors median 25 (IQR 2575:18,731,5; p = 0,002) versus survivors and this group had more frequently mechanical ventilation and vasopressors. Multivariate logistic regression for 14 day mortality assessed mechanical ventilation OR:3.59 (CI95%:1.438.97, p = 0,006) and APACHE II increases in 1score OR 1.06 (CI95%:1.011.23, p = 0,021) as independent risk factors for 14 day mortality in ICU. Conclusions: Oncological critically ill patients remain as a high mortality population. Mechanical ventilation and increases in one point in APACHE II score at admission to ICU are independent risk factor for 14 day mortality. Introduction: Although hematopoietic stem cell transplantation recipients (HSCTR) admitted to an ICU have a high mortality (52 %-83 % 1 ), limited data exists regarding six-month mortality rates. The aim of our study was to investigate the outcomes and explore nonrespiratory predictors of ICU and six-month mortality, and to compare our result with a previous publication 2 done in our center, in order to learn if outcome has improved. Methods: Retrospective study. We analyzed all HSCTR who were admitted to our ICU from January 2009 to March 2015. We recovered demographic data, reason for ICU admission and all the possible variables related with mortality. Statistical analysis was done using the Chi-square test for categorical variables and the Mann-Whitney test for continuous non-parametric variables. Results: During the study period a total of 25 HSCTR required ICU care, and this accounted for 33 admissions (7 of them were readmitted). General patient characteristics are shown in Table 49 . The most frequent cause for ICU admission was acute respiratory failure (56 %) followed by non-respiratory sepsis (7 patients; 28 %) and by acute coronary syndrome, brain stroke, hemophagocytic syndrome and veno-occlusive disease (one case each; 4 %). Twenty patients had 2 or more organ failures: respiratory (64 %), hemodynamic (64 %) and renal (72 %; use of renal replacement techniques in 32 %). All patients received antibiotic treatment, and 9 of them (36 %) had positive microbiological results. Mean ICU stay was 9 days (2-35). In our study, ICU mortality was 48 % (12 of 25 patients), inhospital mortality 60 % (15/25) and six-month mortality was 72 % (18 of 25 patients). Compared to mortalities reported 30 years ago for our center the rates that we found were lower (ICU-mortality 48 vs 76 %; in-hospital mortality 60 vs 88 %) 2 . Factors related to ICU and six-month mortality are listed in Table 50 . Non-respiratory laboratory parameters (lactic, hemoglobin, INR, aPTT, fibrinogen) and isolated respiratory (p = 0,053) and hemodynamic (p = 0,386) failures together with the use of vasoactive drugs (p = 0,819) renal replacement therapies (p = 0,236) or positive cultures (p = 0,656) did not reach statistical significance. Conclusions: Pre-ICU hospital days, 24 h SOFA, number of organ failures and isolated renal failure are factors associated with ICU mortality. The presence of lower counts in the first 24 h of platelets, leukocytes and neutrophils together with pre-ICU hospital days were related with six-month mortality. Although mortality rates in HSCTR admitted to ICU have decreased, ICU, in-hospital and six-month survival rates are still low. Introduction: Sepsis is a common complication in cancer patients and it is associated with high mortality rates. Clinical approach in critically ill cancer patients should take into account the disease course and cancer-related determinants. Objectives: To characterise cancer patients admitted to an oncological intensive care unit with sepsis/septic shock and to determine baseline predictors of in-hospital mortality. Methods: This is a retrospective cohort study of all the adult cancer patients admitted to a 6-bed Oncological Intensive Care Unit (ICU) with the diagnosis of severe sepsis or septic shock, between 1 January 2012 and 31 December 2015. Solid and haematological conditions were analysed separately. The analysis was performed with multivariate logistic regression models, using a stepwise backward elimination with complete case analysis. All the analysis was performed with the software Stata 12.1®. P-value was considered significant at < 0.05. Results: We identified 210 patients: the mean age was 60.8 (CI 58.8-62.8) and 65 % were male (n = 136). About 19 % (n = 40) were postoperative and the remaining 81 % (n = 170) were medical septic complications; 61 % were admitted with septic shock (n = 129). The majority of cancer conditions were solid tumours -71 %(n = 149)and among the haematological cancers -29 %(n = 61) -16 % (n = 10) were admitted after bone marrow transplantation. The median ECOG performance status score was 2. Only 6 % (n = 12) were in complete response and 65 % (n = 137) were at an initial phase of the treatment. Data regarding comorbidities, tumour staging, site of infection, culture-positive sepsis and organ support at admission were included in the multivariate analysis. ICU mortality and in-hospital mortality were 34 % (n = 71) and 50 % (n = 104), respectively. Among solid tumour patients, higher scores of Simplified Acute Physiology Score II (SAPS II) and Eastern Cooperative Oncology Group (ECOG) Performance Status showed a statistically significant association with inhospital mortality, as expected; postoperative admission, septic shock at admission tend to be associated with worst prognosis. Regarding haematological conditions, only Acute Physiology and Chronic Health Evaluation (APACHE) II score was a statistically significant predictor of in-hospital mortality. Conclusions: This study highlights ECOG as a predictor of in-hospital sepsis-related mortality in patients with solid tumours and raises the awareness around the search of oncological baseline characteristics that may be determinants of sepsis-related mortality. This Oncological ICU mortality and respective in-hospital mortality rates are similar to mortality rates of sepsis/septic shock in general population. These results suggest SAPS II and APACHE II as a good predictor of in-hospital sepsis-related mortality in patients with solid tumours and haematological patients, respectively. Larger retrospective cohorts or prospective studies might strengthen these conclusions. None. Introduction: Sepsis and SS are one of the most serious complications in neutropenic pts. MSCs reprogram of monocytes and macrophages by releasing prostaglandin E2, IL-10 and decrease the production of TNF-α and IL-6. Injection of MSCs to septic animals reduced mortality and improved organ function [2] . No study has investigated the efficacy of MSC therapy in pts with SS, especially neutropenic pts. , respectively) were similar in both groups. During the study period, total SOFA score did not differ between the groups. However, since second day cardiovascular SOFA score and respiratory SOFA score were lower (p < 0.05) in MSCs-CT group, than in CT-group. 28-days survival rates were 20 % (3 out of 15 pts) in CT group and 60 % (9 out of 15 pts) in CT + MSCs group (P < 0.05). Despite higher 28-days survival rates in MSCs + CT group only 4 of 9 pts survived 28 days remained alive in 3 months, 5 pts died due to sepsis related organ dysfunctions. In 3 months there were no differences in survival between the groups. Conclusions: Administration of MSCs in first hours of SS improves organ dysfunction and short-term survival in neutropenic pts, but doesn´t prevent death from sepsis related organ dysfunctions in long term period. Perhaps, it is required repeated administration of MSCs. Introduction: Patients with acute respiratory failure on ventilators constitute the majorities of patients in intensive care units (ICU). Early extubation has always been one goal that medical teams want to achieve. Objectives: Rehabilitation invention has already been administered in ICUs in other countries and has successfully helped achieve the goal of early extubation. It is therefore hoped that physical therapy as intervention can help create a safe environment that facilitates early extubation for patients. Methods: The participating patients with acute respiratory failure were all in the conditions of stable hemodynamics, normal nutritional status and no infectious complications and first underwent joint assessment by the medical teams based on their progresses in recovery after treatment for their diseases before receiving rehabilitation consultation, which directed them to cardiopulmonary rehabilitation that included T-tube training. Upon the confirmation of their ventilator weaning indications, their endotracheal tubes were removed. They were then engaged in early ambulation activities ranging from Level II to Level IV according to their abilities. During this period, the medical teams conducted 3 sessions of education training led by physical therapists, followed by exercises and group testing. Results: Days of ventilator use were reduced from 6.3 (days) previously to 4.1 (days) after improvement. The secondary goal, i.e. days in ICUs, were reduced from 10 (days) to 6.1 (days). Hospitalization costs were also reduced from NT$329,000 before improvement to NT$241,000 during improvement and NT$186,000 after improvement. During the improvement, no tube slippage or patient falls occurred. This shows that this innovative proposal has achieved its purpose and also ensured patient safety. Conclusions: It is suggested that medical teams for ventilation in severe cases can develop weaning protocols that have shared goals and integrate multiple technologies and find weaning solutions for ventilator dependent patients by exploring literature and relevance of content in protocols. This provides possible indicators for assessing healthcare for ventilator dependent patients and serves as a reference for healthcare facilities in developing patient care plans. Results: 159 (21.4 %) of 740 patients who were monitored in GICU belonged to a Syrian nationality who were the victims of the Syrian civil war. A total of 795 patients were requested for hospitalization in GICU, while GICU stay of 55 (6.9 %) patients were rejected because of full bed occupancy. Mean age (34.3 ± 12.4 years), gender distribution (women, n = 36; 22.6 %), and men, n = 123; 77.4 %), and the mean APACHE II score (24.2 ± 13.7) of the patients were recorded as indicated. The most common indications for hospitalization were multisitel shrapnel injuries (42.7 %), subarachnoidal bleeding (SAK) (42.1 %) caused by firearm injuries, and chest gunshot wounds (5.6 %). Total number of days of GICU hospitalization were 4300 days, while patients with Syrian nationality stayed in the GICU a total of 1558 (36.2 %) days. Mean duration of hospitalization was 9.7 days. Average mortality rate among all GICU patients in 2013 (26 %) was lower than that of Syrian citizens (n = 49 deaths, mortality rate 30.8 %; n = 12 women; 24.4 %). The standardized mortality ratio [observed mortality (49/159), according to the APACHE II score of expected mortality rate (48 /159) ratio] was 1.02 Conclusions: Because of higher APACHE II score, increased incidence of gunshot hwounds, and transportation of the patients from a distance of over 100 kilometer under unfavourable conditions increased mortality rates were observed. Introduction: The massively increasing knowledge of recent years about the importance of circadian rhythms is orientating the researchers from laboratories towards the bedside (1). Objectives: The daily pattern of MT production is the main regulator of circadian rhythms, with the strongest known signal of its release being the daily change of light and darkness. The aim of this prospective study was to determine the MT production in septic and non-septic groups of ICU patients suffering from severe night light pollution. Methods: Mechanically ventilated patients over 18 years, without CNS damage were enrolled in the study. Illuminance levels (IL) were measured by a lux meter. Serum MT levels were determined from arterial blood samples. Sampling and IL measurements were performed after admission at 01:00, 07:00, 13:00 and 19:00 constitutively for 96 hours. Blood samples were kept in total darkness before being centrifuged, then serum samples were placed into −80°C until MT measurement was performed. Repeated correlation analysis was performed to investigate the correlation between illuminance and MT levels. The equality of MT variances was tested by fitting two nested models and comparing their likelihoods. Results: Out of the 28 enrolled patients 15 were able to take over the study. 8 patients proved to be septic and 7 non-septic, which was sufficient to form subgroups. Out of the 16 measurements/patient, 240 MT samples were analysed. Although IL were the lowest at 01:00 [19(3-101) lux], estimated MT peaks were missing, the median (IQR) was 30(24-51) pg/ml at this time point. Although repeated correlation analysis between MT and IL showed a non-significant between-subject correlation (r = 0.438, P = 0.103), the MT variances of septic subgroup were 70 % of the non-septic variances. In spite of the low sample size the fixed effect of subgroup was statistically highly significant (P < 0.0001), in general higher MT levels were observed in the septic subgroup. Conclusions: Our results indicate that circadian rhythm is desynchronized in ICU patients, as indicated by the missing MT peaks during the night, the absence of the normal 24 h rhythm of MT release and by the poor correlation between illumination and MT levels. This first observation suggests that absence of darkness at night and the missing contrast of day and night light levels can rapidly destruct the rhythm of MT release. The cause(s) of our second observation, namely that patients in septic subgroup showed lower MT variances and higher MT levels in general needs to be elucidated by studies focusing on this phenomenon, conducted in larger patient population. Based on these observations, future trials on light/dark conditions and patient outcomes could lead to redesigned healthcare environments, which may help restore circadian rhythmicity and reach health benefits. Objectives: Aim of this study was to assess burnout in ICU physicians and nurses in a national level and to identify possible contributing factors. Methods: A cross-sectional, multicenter study in 18 Greek ICUs was conducted between June and December 2015. Scores of Exhaustion, Depersonalization and Personal Accomplishment from the Maslash Burnout Inventory Questionnaire 2 were recorded in the 469 study participants. Univariate and multivariate logistic regression analysis was performed in order to identify predicting factors for burnout. Results: A high participation rate was recorded (65.7 %). Baseline participant characteristics, scores of burnout, as well as statistical comparisons between the medical and nursing staff are shown in (Table 51 and 52) . ICU nurses compared to doctor participants were mainly females (80.8 % vs. 55.6 %, chi-square test, p < 0.001), almost a decade younger (p < 0.001), had less working experience (p < 0.001), and declared lower job satisfaction (p = 0.001). Exhaustion scores were relatively low but statistically different between doctors and nurses (22.8 % and 37.5 % respectively, Mann-Whitney U test, p < 0.001), while differences in scores of depersonalization and personal accomplishment did not reach statistical significant levels. Multivariate logistic regression analysis (Table 53) identified two independent predicting factors for high exhaustion: to be a nurse (Odds ratio 1.6, 95 % CI 1.1-2.7, p = 0.05) and to have low job satisfaction (Odds Ratio 0.2, 95 % CI 0.1-0.4, p < 0.001). Other factors like gender, age, working experience, working in university hospitals or having personal experience of losing a close family member were found not to be associated with burnout. Conclusions: Our results demonstrate low burnout levels in Greek ICU personnel. Nurses are more exhausted compared to doctors. The major contributing factor for burnout is job satisfaction. Introduction: Despite their importance in informing care interventions, significant barriers exist in Critical Care in regards to the measurement of height and weight. Common interventions based on weight include lung-protective ventilation in ARDS management [1] , renal replacement therapy, and antibiotic dosing. Studies have investigated the use of a calibrated ulnar length (UL) tape in tidal volume (VT) measurements [2] , whilst our institution uses a formula converting actual height (AH) to ideal body weight. We have demonstrated in previous audits poor compliance with measurement of actual height and wished to investigate the performance of UL to improve compliance. Objectives: We performed a three-way comparison comprising height derived from UL versus AH, and clinician estimation (CE) versus AH. We sought to simulate the clinical effects of applying measured and derived values into the common clinical parameter of 6 ml/kg VT lung-protective ventilation. Methods: We sampled 16 Critical Care patients and 4 healthy volunteers. Participants were measured supine, semi-recumbent or sitting. UL was measured between olecranon process and ulnar styloid. AH was measured in the position the participant was approached in, using a summation of heel to knee, knee to greater trochanter (GT), and GT to vertex lengths. CE was estimated by a Consultant Intensivist, blinded to actual measurements. Results were analysed using Excel, with correlation of results performed using Bland-Altman plots and regression analysis. Results: A significant correlation between performance of UL and AH was obtained (P < 0.01). There was no significant correlation between CE and either UL or AH. Similarly, when converted to 6 ml/kg VT, a statistically significant correlation was obtained between UL and AH and (P < 0.01) but not CE. Estimates of height ranged between -16 cm and +5 cm, most commonly underestimating height. VT extrapolated from CE gave a range between −41.4 ml and +68.4 ml. Conclusions: Significant barriers to measuring height in Critical Care exist, including lack of pre-morbid measurement, immobility, and lack of suitable equipment. Anecdotally there may have been a tendency for clinicians to rely on estimation of height and weight which can erroneously form the basis for regimes in a range of interventions. Our study confirms UL validity as a proxy of formal height measurement, and the poor performance of estimation compared to AH and UL. We propose UL measurement as an acceptable standard of care. Development of an automated data extraction process for use in retrospective pharmacokinetic analyses: initial application to vancomycin dose and concentration data in patients using citrate and heparin CVVHDF anticoagulation modalities Introduction: Critically ill patients have altered antibiotic pharmacokinetic (PK) characteristics, which are further affected by continuous venovenous haemodiafiltration (CVVHDF) (1). Regional citrate anticoagulation (RCA) use is increasing and effects of RCA-CVVHDF settings on antibiotic PK parameters need quantification for dose individualisation. Electronic prescribing and recording systems have potential to improve data availability and accuracy for PK analyses. Data extraction and amalgamation from multiple sources requires a systematic approach, considering data quality assurance and research objectives. Objectives: The aim was to develop a reliable methodology to extract and amalgamate retrospective data from dialysis machines (Prismaflex), the clinical information system (ICIP) in the intensive care unit, and electronic laboratory systems, for use in future PK studies. Using this methodology, we compared vancomycin doses and levels in patients receiving heparin anticoagulation or RCA on CVVHDF. Methods: All patients on vancomycin and CVVHDF in 2014 were included. Vancomycin data were extracted from the laboratory information system; timing of dialysis and anticoagulation mode from ICIP (Philips); and dialysis flow data from the Prismaflex (Gambro) machines. Extracted data reliability was categorised as high or low risk in terms of time-sensitivity and patient-specificity for internal validation of data extraction and amalgamation. High risk data had a two part validation system to match variables across databases. Risk assessment was undertaken by a multidisciplinary team. Open source technologies were utilised including Perl (perl.org), REDCap (projectredcap.org) and MySQL (mysql.com); and SPSS V17 (IBM Corp.) was used for data analysis. Ethical approval was obtained. Results: A fully coded-anonymised database for retrospective analysis was created. 58 patients were included, representing 323 patient days with an average of 5.57 (SD 2.14) days per patient. This resulted in 255, 56, 8 and 4 dialysis days on heparin, citrate, both and no anticoagulation, respectively. The average vancomycin dose was 1162.22 mg (+/−437 mg) and 1306.12 mg (+/−343 mg) on heparin and RCA respectively (p = 0.032). Trough vancomycin levels were within range in 37.9 % of levels in heparinised patients and 29.72 % of levels in patients on RCA. There was no significant association between anticoagulation and vancomycin trough levels in target range, χ2(1) = 1.563, p = .668. Conclusions: This methodology represents a promising approach for retrospective data analysis. Our initial results indicate that anticoagulation modality used is associated with vancomycin dose, but not the proportion of trough levels in target range. Work is ongoing to further validate data amalgamation processes and explore vancomycin PK in these patients. Introduction: The impact of clinical pharmacist on preventing drug related problems in critically ill patient has been well reported in several randomized control trials. The critical care pharmacist impact is greatly essential in therapeutic drug monitoring, renal dosing, drug-drug interaction, and de-escalation of antibiotic therapy and others in this setting. Objective: The aim of this study was to evaluate the types of interventions, clinical significance and cost saving involved with each intervention. Methods: A prospective observational study was conducted in a 13 bed critical care unit at tertiary care teaching hospital in AL-Khobar, Saudi Arabia. All Patient greater or equal to 18 yrs of age, who were admitted to our intensive care units were included in the study. Pharmacist interventions were recorded electronically on daily bases. The electronic documentation system collected the following information, patient demographics and (age, gender, and weight, past medical history, home medication, allergies, type of intervention, and outcome. The study group consisted of 181 patients. Three hundred and three interventions were recorded during a period of 12 months. Therapeutic drug monitoring accounted for 66 (36 %) of total pharmacist interventions, while 65 (35 %) was related to review & reconciling of medication history. Furthermore (17 %) of these interventions were related to unnecessary medications mostly antibiotics. Interventions related to renal dosing adjustment accounted for 50 (28 %) of interventions. Conclusions: The overall interventions identified in this study well demonstrate the impact of critical care pharmacist in improving patient outcome and preventing drug related problems. Are daily blood tests on icu necessary? How can we reduce them? Introduction: Daily blood tests are a long running feature of ICU care, and are regarded as an essential diagnostic tool by medical staff, however they aren't without their drawbacks. The risk of iatrogenic anaemia is a very real one and there are significant costs involved in both equipment and staff time.1 With this in mind guidelines were drawn up to limit excessive blood tests in otherwise stable patients. Objectives: We audited adherence to these guidelines in 2015 finding 292 unnecessary vials of blood taken in a 20 bed unit. Guidelines were clarified and advertised on posters and then we re-audited. Methods: In order to establish trends and to exclude stable post surgical patients we limited eligible patients to those who were on the unit for 3 days or more. A simple proforma was designed to record which common blood tests had been performed, daily haematocrit and haemoglobin (if tested), and any major change in overall condition or events such as transfusions or surgery. On six randomly assigned days over a 2 month period, all eligible patients on the unit had a proforma filled retrospectively for all days up until their admission to the unit, or up to seven days previously, whichever sooner. We also recorded if the patient had arterial or central access, as these facilitate obtaining samples for testing. Results: 70 patient days were audited across 10 individuals, with 339 tests ordered, 41 % of which were unnecessary, down from 46 % before our intervention. Conclusions: While the bedspace posters had a modest effect, we are now enforcing the guidelines through the weekly medical and nursing teaching sessions, and also ensuring all requests for clinical reasons are agreed with the registrar or nurse in charge. We are also recommending removal or alteration of the "Critical Care" test set that is currently available from our electronic requesting system in the hope that it will encourage more critical thinking about which tests are appropriate for the patient they are caring for. We aim to re-audit our practice within the next 6 months to ascertain the impact of these changes. Introduction: Hospital Antimicrobial Stewardship (AMS) programs have achieved savings and more rational use of antimicrobial treatments. However, intervention over antimicrobial treatment of critical patients with hematologic disease is highly complicated Objectives: To evaluate a two years experience of an AMS program intervention in patients with hematologic disease admitted in an intensive care unit (ICU). Methods: We designed a quasi-experimental study. AMS strategies were put into practice during three years (January 2014-January 2016) in collaboration with the ICU nosocomial infection control team. Antimicrobial treatment was revised twice a week. If any antimicrobial treatment modification was recommended in the AMS meeting, a face-to-face interview was held between AMS team and the attending physician. ICU length of stay and ICU mortality rate were compared with the same time period previous to AMS implementation. Continuous and categorical variables were compared using T-student and Fischer exact test (Stata v.13.0). (1) . However, the opinions of health care professionals on this subject remain unknown. Moreover, communication with ICU patients is becoming increasingly important since ICU guidelines aim to reduce the use of sedatives, thus it is expected that more patients will be awake and able to communicate (2) . Objectives: To investigate communication issues with MV patients as experienced by ICU health care professionals. The primary aim was to quantify the extent of the problem and to determine its effect on patient care and job satisfaction. The secondary aim was to identify patient and health care factors associated with communication difficulties and to evaluate the preference and effectiveness of currently available communication methods. Introduction: ICU is a high demand area in the hospital, with a large demand supply gap especially in limited resource countries. In addition, it requires a higher staffing ratio than rest of the hospital. Objectives: To explore the impact of multiple factors for increasing bed turnover during expanding newly developed ICU. Methods: Observation study during gradual opening of 18 beds medical/surgical ICU from June 2014 till March 2016. It is a part of Alexandria University (primary and tertiary) hospitals covering 2 governorates receiving a lot of emergency patients. In September 2015, outreach critical care services were provided for early discharge of ICU patients but was inactive since April 2015 due to financial problem. In September 2015 post-operative ICU was opened but the nursing staff was recruited from general ICU. In January 2016, proactive ICU project was implemented which included reducing the time of delay of investigation for ICU patients, daily care plan for rapid stabilization, implementing end of life care decisions, and avoiding inappropriate antibiotic or medication use. In Feburary 2016, administration increased ICU capacity with same number of nursing staff. Results: 347 patients were admitted to Smouha University ICU, from which 147 patients died (42.4 %). The mean mortality rate was 43.9 % (28-84.6 %), with mean APACHE II score of 23 (16) (17) (18) (19) (20) (21) (22) (23) (24) (25) (26) (27) (28) (29) (30) , and mean expected mortality 46.5 % (23.5-70.3). The relative mortality (actual/expected) ranged from 0.35 to 1.25 with mean 0.88 %. Mean Bed occupancy ranged from 4 till 13 beds. After failure of outreach service, bed turnover was similar (2.29 to 2.3). Before and after opening of post-operative ICU, The mortality rate of post-operative cases was higher in post-operative ICU than in general ICU (9.5 vs 2 %, p = 0.019), with lower occupancy rate (4.5 vs 10 patients per month, p = 0.277), and higher mean ICU stay (3.5 vs 1.2 days, p = 0.02). Before and after implementation of proactive ICU, the number of admissions significantly increased from 18 to 33 (p = 0.003), insignificantly higher occupancy rate from 1.8 to 2.8 (p = 0.345), and significantly decreased waiting time for ICU admission from 38 to 6 hours (p < 0.001). However ICU complication increased; unexpected cardiac arrest from 7.5 to 18.5/1000 patient days (p = 0.002), unplanned extubation from 21 to 35/1000 ventilator days (p = 0.305), deep vein thrombosis from 0 to 4.7 % (p = 0.259) and pneumothorax from 3 to 2 % together with increased mortality and relative mortality insignificantly (45.7 to 59 % and 0.89 to 1.13 respectively) Conclusions: From multiple efforts to increase ICU turnover, end of life care decisions and proactive ICU seems most effective, however the expense of increasing nursing and doctor load must be weighted to avoid iatrogenic complications. Also diverting post-operative patients to specialized ICU needed more nurses without better patients outcome. Better "guesstimates" -defining, standardising and documenting safe, accurate and consistent values for actual and ideal body weight in a uk university teaching hospital critical care service Introduction: Knowledge of the critically ill patient's Actual Body Weight (ABW) and Ideal Body Weight (IBW) guide safe treatment in Critical Care (1, 2) . When it is not safe or practical to measure these at admission it is necessary to estimate. Our dietician service attends within working hours and uses a systematic method to estimate values if these are unknown. We suspected that ABW and height was inconsistently estimated and documented by various teams. Objectives: We present data from the first project chosen by the NUHCC Better Collaboration, a multi-disciplinary team (MDT) set up to measure and improve the care we offer (3). We aim to define, standardise and improve documentation of safe, accurate and consistent values of ABW and IBW. Phase 1: Survey current documentation of ABW, IBW and height. Phase 2: Survey our MDT for opinion and feedback on a proposed standardised approach to better systematic documentation and estimation of ABW and IBW. Phase 3: Reflect on this feedback to present a definition for optimal standard practice in sourcing and documenting safe values. Phase 4: Survey performance against the approved standards regularly with planned interventions to improve performance. The initial notes review showed that 32 % of heights and 24 % weights were documented. The majority of respondents to our internal survey agreed that using accurate values was important, that we should define and standardise how we do this and that there was a definite need to improve performance (4) . A small MDT group collaborated to define best practice and it was agreed that a standard protocol for measurement and documentation of ABW and IBW would be implemented. Conclusion There is an evident problem with consistency of documentation for safe values of ABW and IBW within NUHCC. We have defined our standard and are excited about implementing and embedding excellent practice as a collaborative effort. We look forward to sharing the data from the first steps of our journey to the ESICM conference. Sabadell score as a predictor of outcome after discharge from the intensive care: a prospective observational study L.U. Taniguchi Introduction: Despite initial recovery, many critically ill patients discharged from the intensive care unit (ICU) may experience deterioration 1 . Early identification of patients at risk might facilitate improvements in quality of care. Objective: To determine risk factors associated with short-term hospital outcome (unplanned ICU readmission and unexpected death on the ward). Methods: Prospective cohort study from August 2014 to May 2015 performed at Hospital Sírio Libanês (São Paulo, Brazil). During this period, we analyzed 527 patients who were admitted in our ICU and discharged alive. We used univariate and multivariate analysis to identify risk factors associated with latter ICU readmission or unexpected ward death in the same hospitalization period. Results: Forty seven patients (8.9 %) were readmitted after ICU discharge and further forty seven died in the ward. Patients who had unexpected outcomes were older compared to those with successful outcomes ( Introduction: Survivors of ICU admission can develop several complications, such as physical impairment, weight loss, psychological and social disorders, with potential impact on quality of life. Little has been described on this evaluation in low-income countries. Objectives: To describe the results of six years from a follow-up outpatient Clinic evaluating adult patients that survived to admission to ICU, three months after discharge. Methods: Prospective cohort study evaluating adult patients that survived after admission to a general ICU of a University Hospital in Southern Brazil. It was included patients that stayed > 24 h in ICU and > 18 years old. All survivors were contacted by Clinic, and only were excluded that patients that did not attend to the Clinic. Sociodemographic and medical data were collected by searching the medical record. For the psychological evaluation it was used the Hospital Anxiety and Depression Scale -(HADS) and the Impact of Event Scale-Revised -(IES-R). It was analyzed weight and height on hospital admission and discharge, as well as at the office visit. Muscle strength was measured by Medical Research Council (MRC) scale. Spirometry was performed by using One-flow device, with standard procedures. Results: During the period of the study (jul-2008 to dec-2014), 2615 patients were admitted to adult ICU, and 1845 were discharged alive from hospital. Of them, 696 were evaluated at the outpatient multiprofessional Post-ICU Clinic three months after discharge. 62.9 % of the patients were male, mean age 43.1 years, mean APACHE 20.4. The ICU admission was due to trauma (42.1 %), medical conditions (26.2 %) and postoperative (31.7 %). Mean ICU length of stay was 10.3 days. The most of the patients (83.3 %) required mechanical ventilation. In outpatient evaluation, 94.6 % were on oral feeding, mean weight loss of 11.7 % during hospital length of stay, and a mean weight gain of 9.1 % after discharge. 31.8 % had reduced muscle strength, with 4.9 % hemiparesis/hemiplegia and 5.7 % moderate/severe tetraparesia or tetraplegia. Spirometry was abnormal in 49 %, being more common obstructive disorders (37.8 %). At psychological evaluation, 45.2 % showed emotional disorders: anxiety (30.6 %); depression (21.4 %) and PTSD (19.5 %). 47,7 % had a family income lesser than US$550.00/month. It was found significant social and economical consequences for the most of the survivors and their families. Conclusions: A large proportion of patients had physical, social and psychological complications three months after ICU discharge. Thus, early identification and appropriate treatment of these complications may be beneficial. The social and economical impact of ICU stay is to be determined in low-income populations. Examining Introduction: A recent survey on the long-term complications reported by the General Practitioners of 1-year ICU survivors showed that chronic fatigue was among the complications most often reported [1] . One of the instruments proposed to assess fatigue is the Functional Assessment Chronic Illness Therapy-Fatigue (FACIT-F), a 13-item scale that has been validated in a sample of the general USA population [2] . Al-shair et al. [3] who used FACIT-F (13-FACIT-F) questionnaire in 2107 COPD patients, recently proposed a modified 9-item FACIT-F (9-FACIT-F) for these patients. Objectives: The aim of this study was to compare reliability and validity of 13-FACIT-F and 9-FACIT-F in a group of ICU survivors assessed one year after hospital discharge. The study was performed in 56 consecutive adult ICU patients staying in ICU for at least 72 hours, and able to co-operate at the time of ICU discharge. We excluded patients with pre-existing cognitive deficits, or resident more than 30 km from the hospital. One year after hospital discharge, the patients who consented came to the hospital. An investigator administered by direct interview the following instruments to the patients who consented: 13-FACIT-F, modified Medical Research Council (mMRC) Dyspnea scale and the Medical Outcomes Survey Short Form-36 (SF-36). An additional question asked whether the patient's fatigue was the same, improved, or worsened in comparison with the pre-ICU time. Statistical analysis was performed using Cronbach alpha for reliability, Spearman correlation between FACIT-F scales and both mMRC and Vitality of SF-36 for validity, and Mann-Whitney test in patients with same/improved, or worsened fatigue for discriminative ability of both 13-FACIT-F and 9-FACIT-F scales. Results: 13-FACIT-F had higher internal consistency (α = 0.813) compared to 9-FACIT-F (α = 0.654). The correlation between the original and the modified scales was excellent (Table 54 ). The correlations between both scales and mMRC, and Vitality of SF-36 were all statistically significant (p < 0.001) (Table 54 ). Both 13-FACIT-F and 9-FACIT-F values were statistically significantly different in patients with improved/not changed and worsened fatigue in comparison with one year before (Table 55) . Conclusions: Both 13-item and 9-item FACIT-F scales demonstrate convergence with other conceptually relevant patient-reported outcomes, namely mMRC and Vitality of SF-36. The present study demonstrates that 13-FACIT-F and 9-FACIT-F have a similar ability in discriminating between ICU survivors with improved/not changed and worsened fatigue at one year. However, the original 13-item FACIT-F scale may have the advantage to allow comparison with the general population. Results: During the study period 1482 patients were admitted into the ICU and 566 were observed at the outpatient clinic. 555 patients were able to answer to the screening questionnaires and are analyzed. Of these 50 % (277) reported new complains and 30 % (168) had to be oriented for specific interventions and 6 % (33) to more than one. Of these 168 patients: 29 % (n = 48) were oriented to Psychiatry; 15 % (n = 26) to Internal Medicine; 10 % (n = 16) to the Primary Care Physician; 8 % (n = 14) to General Surgery; 8 % (n = 13) to Cardiology; 7 % (n = 12) to Physiotherapy, and 23 % (39) others. When observed at the outpatient clinic only 230 (44 %) had resumed previous normal activity (34 did not answer the question). Of the 291 that did not, 197 (71 %) assumed to be related to the ICU. No significant differences were observed concerning the timing of the outpatient clinic observation (<2 months, 2-6 months and > 6 months after hospital discharge, p = 0.147) and resuming previous activity. Of those that were still not able to return to previous activity (n = 291), 194 (67 %) reported new complain and 85 (44 %) needed referral for specific therapeutic approaches. Conclusions: The importance of the ICU follow up clinic is reinforced by the significant proportion of patients in whom new problems are identified requiring specific referral for treatment. The impact of the outpatient clinic in the subsequent quality of life of those patients remains to be determined. We propose for those in whom new clinical problems are addressed a second observation to evaluate its efficacy and impact. Introduction: Patients who survive an episode of post admission to intensive care for sepsis syndromes have been found to have poor quality of life, physical and psychological problems and a high rate of recurring illness or mortality in the first year. Follow-up clinics have been instituted for general intensive care patients but the evidence as to efficacy is sparse at present and there has been no clinic specifically for survivors of sepsis. Objectives: The aim of this trial is to investigate if targeted screening and appropriate intervention to these subjects post hospital discharge can result in an improved quality of life, decreased mortality, decreased readmission to hospital and/or decreased use of health resources. Methods: Patients post sepsis syndrome in intensive care and receiving respiratory support for greater than 48 hours will be randomized to one of two groups. The intervention group will attend an outpatient clinic two monthly for six months and receive screening and targeted intervention. Screening will include physical measures (strength, balance) psychosocial measures (depression, anxiety, PTSD), cognitive measures, pain, nutrition or sleep problems. The usual care group will remain under the care of their physician. The primary outcome will be short form (36) health survey (SF36v2Ô), readmission to hospital, mortality in the first 12 months, and use of health resources in the first year. A sub group in a rural setting will be assessed by telemedicine. Results: Twenty patients (9 intervention, 11 usual care) have been randomized. Patients randomised to the intervention group report a Introduction: Surviving the ICU is only the beginning of getting life back. The majority of ICU survivors experience immediate and frequently persistent physical, mental and cognitive impairments that compose post-intensive care syndrome (PICS) [1] [2] [3] . The exact prevalence of PICS is unrevealed, but it is estimated that more than half of critical care survivors develop at least one symptom throughout their recovery. Understanding who are the patients more likely to develop PICS is a key issue. Objectives: This study intends to determine the prevalence of PICS in one Portuguese ICU, to characterise this population and identify risk factors to the development of this syndrome. Methods: We performed a prospective cohort study from January 2013 to February 2015. All ICU survivors that were admitted to our unit during two or more days were included. In the first 24 hours of admission patients were screened for the risk to develop physical and non-physical components of PICS. The presence of PICS was assessed at four time points: at ICU discharge, one week after, at hospital discharge and three months after ICU discharge. Additionally, we recorded clinical data on: patients' demographics, type of admission, simplified acute physiology score (SAPS II), length of ICU and total hospital stay, length of sedation and mechanical ventilation. Results: We enrolled 355 patients with a median age of 63 years and a predominance of males (62 %). At ICU admission 87.6 % of the patients had some risk factor for PICS. Throughout time PICS was identified in 186 (54 %) patients at ICU discharge, 148 (58 %) one week after discharge, 78 (55 %) at hospital discharge and on 106 (43 %) patients three months after ICU. At ICU discharge, physical components of PICS were more frequent, and at three month follow up non-physical components were more common. Patients with higher SAPS score, longer length of ICU and hospital stay and more ventilation and sedation days were more prone to have PICS at ICU discharge. These variables were independent risk actors to the development of PICS. At three months follow-up, these same variables, except SAPS II score, were still risk factors of PICS. Conclusions: PICS is a major concern in nowadays intensive care units (ICU), reflecting a drift from the original focus on organ support to patient support. Interventions in reducing the absolute number of ventilation and sedation days might contribute to reduce the burden of PICS. Depression after intensive care: who to blame?depression after intensive care: who to blame? Introduction: Depression has been associated to ICU stay in a fair proportion of patients. But most studies rely solely on the outpatient clinic screening after ICU discharge, without considering previous psychopathology of the patients or specific risk factors, like ICU memories. Objectives: To determine the prevalence of depression after ICU discharge in patients with and without a previous diagnosis of psychopathology and its association with memories from the ICU admission. Methods: Prospective cohort study of all patients seen at the outpatient clinic, discharged between January 2011 and December 2014, from a 12-bed, mixed ICU, at a tertiary care university affiliated hospital. The ICU memory questionnaire and Beck Depression Inventory (BDI) were the tools used, depression was assumed if the BDI score was higher than 16. With depression has the dependent variable: age, sex, previous psychopathy, acute psychiatric event, previous neurologic disorder, acute neurologic event and the presence of memories were studied as risk factors, through logistic regression. Results: During the study period 1482 patients were discharged from the ICU, 635(43 %) died before the outpatient clinic appointment and 566(67 %) attended the clinic, of these 555 filled the BDI and 530 the ICU memory questionnaire. These patients (n = 555) had a mean ± SD age of 58 ± 17 years; 341(61 %) were male; 157(28 %) had a previous diagnose of a psychopathology disorder : 79(14 %) alcoholism, 55(35 %) depression, 16(10 %) psychosis and 7(4 %) drug abuse were the more frequent, 13(8 %) had more than one; 32(6 %) were admitted to ICU due to an acute psychiatric event, only 2 patients without a previous diagnose were admitted with an acute psychiatric event. The prevalence of depression in the group with a previous history of psychopathology was significantly higher than in the group without: 26 %(n = 40) vs 16 %(n = 63), p = 0.008. In the univariate analysis variables significantly associated with depression after ICU were: previous psychopathology ( Conclusions: Depression after ICU is more prevalent among patients that have previous psychopathology, recalling that the ICU stay is associated with a reduced risk for after ICU depression. We suggest that when patients are admitted to ICU the relatives fill in a questionnaire about the previous cognitive, psychologic and functional status of the patient in order to allow clinicians to determine the true impact of ICU care. The elaboration of a diary to decrease posttraumatic stress disorder following ICU has already been study, but it would be interesting to see if that would have a positive impact in the prevalence of depression after ICU care. Introduction: Many intensive care unit (ICU) patients experience symptoms of depression, anxiety, and posttraumatic stress along with cognitive impairment and physical debility. This combination of symptoms has been classified as post-intensive care syndrome (PICS). Over half of ICU survivors are reported to have significant psychiatric symptoms which appear to diminish little over time. Post-ICU intervention efforts may fail due to delayed initiation, i.e., following hospital discharge after patients' perceptions of their ICU experience has potentially solidified. Currently work is being done to prevent physical aspects of PICS via early physical rehabilitation while still in the ICU. However, there are no evidence based practical interventions to prevent or treat the psychological and cognitive consequences of the ICU stay. It is also not known if there may be categories of patients who are more susceptible to PICS, and would therefore benefit most from tailored treatments. Objectives: The aim of this study was to assess the prevalence of psychocognitive morbidity among patients across six adult ICUs. Table 56 illustrates prevalence of psychocognitive symptoms by the ICU type. Conclusions: There was a high prevalence of symptoms of depression (range 17-69 %), anxiety (range 18-58 %) and PTSD (range 18-58 %). In terms of predictors of distress, patients in the heme-onc/transplant ICU had a much lower prevalence of symptoms of depression, anxiety and PTSD compared to patients in the other ICU units. Whether these patients experience the ICU differently by virtue of the chronicity of their diseases and the contextual circumstances of their ICU admissions invites further study. There was also a high level of cognitive impairment across the ICUs (range 45-83 %). Clearly more needs to be learned about patient and unit factors that are related to psychological difficulties, and tailored interventions will need to be appropriate for individuals with cognitive impairments. Introduction: Prolonged ICU admission is associated with high mortality. Provent score at day 21 has been proven effective as a prognostic index of mortality one year after prolonged admission in ICU in patients requiring prolonged mechanical ventilation (over 20 days). Objective: Assesment of Provent Score as prognostic score in ICU mortality in patients with prolonged ICU stay (over 20 days). Methods: Prospective descriptive study. During two years, we included all patients with more than 20 days of stay in a medicalsurgical ICU. Previous informed consent, we collected demographics data, diagnosis, severity index (APACHE II and SOFA scores), Provent score variables at day 21 of ICU admission (age, platelets < 150.000/ mm 3, , need of vasoactive support and renal replacement therapy), PaO2/FiO2 at day 21, mortality and ICU stay. Data is expressed as number and percentage; statistical analysis was performed with Chi-square test. Results: A total of 58 patients with prolonged ICU admission were included. We did not find differences in age, sex, comorbidity or severity of illness at admission between survivors and deceased in ICU. Introduction: Patients surviving the acute phases of critical illness, complications as polyneuropathy and prolonged mechanical ventilation can appear. A high level of uncertainty exists regarding to prognostication of outcomes in these patients. Chronical critical illness is usually considered when invasive mechanical ventilation is prolonged for at least 21 days after acute illness. Objectives: To study the ability of Acute Physiology and Chronic Health Evaluation (APACHE) II and Simplified Acute Physiology Score (SAPS) II to predict outcome in our chronically critically ill patients. Methods: We performed a retrospective analysis of patients admitted to our medical-surgical ICU in the last 5 years. Differences in basal characteristics and outcomes and data regarding APACHE II and SAPS II predictive value were studied in two cohort of patients according to the need for more than 21 days of mechanical. For univariate analysis Chi-square test, t-Student and U-Mann-Whitney test was used. Receiver Operating Characteristic (COR) curves was used to study predictive ability of scores. Results: A total of 2671 patients were admitted. Of them, 85 required more than 21 days of mechanical ventilation (chronic). Results: Record files of 119 liver transplant patients admitted to ICU during study period were evaluated. Postoperative early ICU mortality was 15.1 %. Mean MV duration, APACHE II score, SOFA score, MELD score were found 5 hours (1-168), 9(3-29), 6(2-16) and 18(5-31), respectively. APACHE and SOFA scores of the patients whose ICU stay were longer than 35 hours were significantly higher (p < 0.05). APACHE and SOFA scores were inversely correlated with early ICU mortality (p < 0.001). MELD score did not have significant prognostic value on ICU stay and early ICU mortality. Independent risk factors effective on mortality were evaluated by logistic regression test indicating APACHE and blood urea nitrogen(BUN) value as independent risk factors in terms of mortality. Conclusions: There are conflicting results in terms of availability of generally used physiological scoring systems for predicting the prognosis after liver transplantation(3). Significant number of studies has results confirming the prognostic value of SOFA, APACHE II and MELD scores in ICU stay, MV duration and mortality. In our study, early mortality and ICU stay were higher in the liver transplant patients who have higher APACHE and SOFA scores obtained at first day of ICU admission, postoperatively (2, 3) . APACHE II and SOFA scoring systems were found to have prognostic efficacy on ICU stay and early mortality after liver transplantation(3). However, we found no correlation between MELD score and mortality(1). The discrepancy may result from the quality of liver graft as 70 % of the donation was performed from live organ donors in our study. Comparison of apache IV with other scoring systems in the ICU in predicting in-hospital mortality after liver transplantation Introduction: Several prognostic systems have been tested to predict early in-hospital mortality after liver transplantation, showing moderate performance. The recently developed Acute Physiology and Chronic Health Evaluation (APACHE) IV score and Simplified Acute Physiology Score (SAPS) 3 now include liver transplantation as a diagnostic category. Objectives: The aim of this study was to compare the performance of APACHE IV, SAPS 3, APACHEII, MELD, MELD-Na, and CTP scores in predicting early in-hospital mortality in liver transplant patients. Methods: We studied 590 adult (age ≥ 18 years) patients who had undergone living donor or deceased donor liver transplantation between October 2010 and September 2014. APACHE II, APACHE IV and SAPS 3 were recorded on ICU admission after liver transplantation. MELD, MELD-Na, and CTP scores were calculated using values before liver transplantation. Results: The overall in-hospital mortality rate was 2.9 %. Hosmer-Lemeshow statistics showed good calibration for all 6 prognostic models. The AUC was 0.83 for APACHE IV, 0.78 for SAPS 3, 0.81 for APA-CHE II, 0.72 for MELD-Na, 0.76 for MELD, and 0.68 for CTP score. Conclusions: The APACHE IV score and SAPS 3 in predicting inhospital mortality after liver transplantation showed revealed generally good discrimination and calibration. The overall discrimination and calibration of APACHE IV were similar to those of all other models except CTP score for predicting hospital mortality. Objectives: To compare, in mortality calibration terms, a general ICU severity index (Saps 3) with a specific one (Grace) designed for coronary patients in a population of acute coronary syndromes (ACS) admitted in our ICU. In addition to build a correlation equation between both scores. Methods: During the period 1/1/2015 to 30/9/2015 a total of 287 patients with ACS were admitted in our ICU. Predicted Saps 3 mortality is systematically recorded in our electronic clinical record. Grace score was obtained by retrospective carefully revision of medical records according to their authors recommendations. Saps 3 death risk was derived by Mediterranean country index equation while Grace death risk was obtained from original score variables by using Granger's regression coefficients. We compared in-hospital observed mortality with theoretical predicted mortality for both scores. We have used a goodness of fit test. We used Pearson's R analysis for correlation purposes. Introduction: The use of temporary tracheostomies to avoid complications of prolonged intubation and facilitate respiratory weaning is a well recognised cornerstone of critical care medicine, but their insertion and subsequent management is not without risk. Tracheostomy displacement is one of the most serious and frequent of all airway events in critical care and is associated with 50 % of airway related deaths in this setting 1,2 . As such a timely emergency action plan is a necessity for critical care areas 1,2,3 . Objectives: We aimed to carry out a service improvement project to improve timely escalation of patients with dislodged tracheostomies to senior airway trained doctors. The project was carried out at two sites: Queen´s Medical Centre (QMC) and Nottingham City Hospital (NCH) of Nottingham University Hospitals NHS Trust, UK. Methods: A rapid cycle audit was undertaken by the authors whereby staff awareness of the local emergency airway protocol was audited on a shift-by-shift basis. All non-airway trained clinical staff were asked how best to get an airway expert to urgently attend a patient with a dislodged tracheostomy. Answers were recorded and at the same time staff were reminded of the local protocol. Other education measures undertaken concurrently included departmental emails, posters and reminders during resuscitation training. A Statistical Process Control chart of percentage correct answers per shift was plotted. Results: Over both sites an improvement in compliance was observed over a 4 month period. Mean compliance for the first 3 audit cycles at QMC and NCH was 38.47 % and 24.2 % respectively versus mean compliance for the final 3 audit cycles of 97.23 % and 50.53 % respectively. At QMC, use of posters after 3 months saw a marked improvement in compliance with all 8 audit cycles undertaken after distribution of the posters exceeding the upper control limit of the preceding 3 months' worth of data and 4 of those 8 cycles seeing greater than 90 % compliance. Conclusions: Improved awareness of the escalation protocol over the 4 month audit period was reflected in its increased utilisation. Use of various educational tools achieved varying results, the most effective being distribution of posters. There is ongoing scope for staff education in order to consistently achieve greater than 90 % compliance at both sites and we would recommend re-audit within 6 months. Introduction: The length of oral ETT in males and females has been recommended as 23 cm and 21 cm respectively from corner of mouth to above carina, standards described for Western population. Caucasian population tends to be taller than Asian population. We, thus retrospectively analysed whether it is true in Asian population of smaller stature and whether there is any correlation between height of the patient to the ideal length of oral ETT. Objectives: To validate the ideal length of oral ETT in Asian Population compared to Western standards. This plays an important role while securing ETTs especially in Intensive care patients, as they tend to be intubated for an average of 3-5 days and require lot of movements during day to day care. Either securing the tube too low or too high can cause either right sided endo-bronchial intubation or high risk of accidental extubation respectively. These inadvertent impediments predispose already critically ill patients to significant risks and complications. We suggest that females and males in Asian population especially in South East Asia should have their endo-tracheal tubes secured at corner of mouth by at least one cm less in comparison to western population. Evans administered with a spoon in middle third of the tongue), then we observed wheather aspiration signs appear (early/late cough, symptoms of asphyxia, or more than 3 percentage points basal pulse oximetry desaturations), and the posible blue stained secretions suctioned through the tracheostomy tube. Simultaneously the FEES was performed, watching directely all the posibilities of penetration and or blue Evans aspiration (Fig. 77) . The validity and performance enhancement were calculated, and the ROC curve was made with 95 % CI. The study was approved by the hospital ethics committee. Results: 26 patients underwent FEES + EEBD: 7 had FEES without aspiration and a negative EEBD. 19 had FEES with aspiration, 16 were positive and 3 negative EEBD. The validity and performance enhancement indexes are described in Fig. 78 , with an area under curve of 0.92 ± 0.54 (95%CI: 0.82-1.00) and p = 0.006 (Fig. 79) . Conclusions 1-The EEBD is a significant and simple diagnostic screening tool in dysphagia secondarily to artificial airway. 2-In our opinion if the EEBD is negative and there is high clinic suspicion, FEES should be considered to confirm, or not, dysphagia. Introduction: Supraglottic airway devices are used with increasing frequency following routine anesthesia and for emergency airway management. Unfortunately, not all devices allow a possibility to perform a secondary endotracheal intubation (ETI) through the device. A new promising device, the Spritztube (ST), has been developed combining the ability to perform both supraglottic ventilation and orotracheal fibreoptic intubation using the same device. Particularly, it is able to perform a supraglottic ventilation during positioning as tracheal cannula during fibroscopy. Objectives: To compare the ease, the time of insertion, and the success rates of use between the intubating laryngeal mask (Fastrach™) and the novel tracheal tube (Spritztube ®). Methods: We evaluated the novel Spritztube and compared it to the Fastrach using a manikin-based study. Each partecipant received a verbal instruction and practical demonstration of technique of insertion for both devices on patient simulation manikins. Each participants used both devices in a randomised order. Time of placement (T1), time of inflation (T2), the elapsed procedural time (T3), ease of insertion, time of exchange maneouver for intubation (T4), success rates and number of attempts were recorded for each supraglottic device. After a maximum of 3 attempts airway-management was defined as a failure. Results: A total of 47 participants were enrolled: 36 % without previous experience with Fibroscopy and 17 % without previous experiences with ETI. There was no difference in number of attempts for insertion between both devices(p = 0.68).Fastrach was applied 11 s faster than the Spritztube (median T3 Fastrach:13 s.,Spritztube:24 s., p = 0.000). The exchange manoevrue for ETI was 11 s faster for Fastrach than the Spritztube (median T3 Fastrach:13 s.,Spritztube:24 s., p = 0.000). Number of attempts for exchange to ETI were significantly more for Fastrach (p = 0.000). Participants judged Spritztube as easier insertion than Fastrach (p = 0.000). Spritztube had a significant higher success rate than Fastrach (p = 0.000). However the success rate did not depend on previous experience in ETI or in fibroscopy. The Spritztube performed similarly to the Fastrach in insertion and intubation times in a manikin setting. Introduction: Available data shows that dysphagia and swallowing disorder rate secondary to artificial airway and prolonged mechanical ventilation in critical tracheostomized patients is high (50-83 %), nevertheless it real incidence is not yet well established. Dysphagia is directly related to bronchial aspirations and respiratory infections. The rate of respiratory infections on tracheostomized patients is also very high (Some series next 100 %). The re-establishment of airway using speaking valves allow the rehabilitation and post-recovery of those disorders, as well as deglutition and phonatory system rehabilitation. Introduction: Available data shows that dysphagia rate, secondary to artificial airway and prolonged mechanical ventilation, in critical tracheostomized patients is high (50-83 %). Dysphagia is directly related to bronchial aspirations and respiratory infections. The rate of respiratory infections on tracheostomized patients is also very high (Some series next 100 %). The re-establishment of airway using speaking valves allow the rehabilitation and post-recovery of those disorders, as well as deglutition and phonatory system rehabilitation. Introduction: High endotracheal tube(ETT) cuff pressure could damage tracheal mucosa and result in significant airway complications. We hypothesized that high cuff pressure on intensive care unit (ICU) admission is very common. So we designed this study as a quality measurement audit to gauge ETT cuff pressure on ICU arrival. In this prospective observational study we included all intubated who were admitted from different clinical area to ICU. We measured ETT cuff pressure on ICU admission using an aneroid cuff pressure gauge during a 6 month period. Results: We measured ETT cuff pressure in 159 patients on their arrival to ICU. The Mean cuff pressure on ICU admission was 63.94 (SD 31.52) cm H2O. There was no statistically significant difference in ETT cuff pressure between the patients admitted from different clinical areas. Duration between tracheal intubation and patient handover to ICU was 9.5 (SD 8.0) hours. Conclusion High ETT cuff pressure is very common on ICU admission and this can set the stage for airway complications. Using cuff pressure gauge is a simple and effective way to measure and readjust ETT cuff pressure immediately after intubation. Efficacy of conduction anaesthesia of nervus mandibularis and videolaryngoscope "tepro" in patients with inflammatory lockjaw V. Artemenko 1 , A. Introduction: In most cases, endotracheal intubation in patients with the neck phlegmon may not be feasible due to inflammatory lockjaw and mouth opening limitation [1, 3] . Conductive anaesthesia of nervus mandibularis can improve condition for intubations in patients with inflammatory lockjaw [2] . The goal of work: to study the efficacy of conductive anaesthesia nervus mandibularis with videolaryngoscopy "Tepro" and to provide optimal conditions for intubation in patients with inflammatory lockjaw. Materials and methods: We analysed medical cases of 47 pts. with the surgical treatment of the neck phlegmon and inflammatory lockjaw. The control group (n = 23) tracheal intubation was proved by conventional laryngoscope Macintosh. In the main group (n = 24) patients have limitation of mouth opening. In those patients conduction anesthesia of nervus mandibularis was performed and trachea intubation by videolaryngoscope "Tepro"; (Table 64) . Results: In control group, rate of difficult laryngoscopy and failed tracheal intubation was 91.3 % due to limitation of mouth opening by lockjaw. In main group we performed conduction anesthesia of nervus mandibulus and videolaryngoscopy, that significantly reduced the rate of difficult and failed intubation to 3.3 % in comparison with patients in the control group (χ2 = 32.36; p = 0.0000). Conclusions. Conduction anaesthesia of nervus mandibulus with videolaryngoscopy "Tepro" increased the amplitude of mouth opening, reduced the rate of difficult laryngoscopy and failed intubation, improved the larynx visualization, therefore provided the best conditions for intubation in patients with inflammatory lockjaw. Preliminary evaluation of a novel strategy to aspirate subglottic secretions following intubation with standard endotracheal tubes G. Introduction: Endotracheal tubes (ETTs) that allow subglottic secretions aspiration (SSA) reduce ventilator-associated pneumonia (1). An innovative device has been recently developed to insert an aspiration catheter into the subglottic region, post intubation with standard ETTs. Objectives: In animals on mechanical ventilation up to 76 hours, we evaluated safety and efficacy of the novel SSA strategy, in comparison with standard ETTs comprising SSA. Methods: Thirteen pigs (31.7 ± 2.6 Kg) on mechanical ventilation (MV) for 76 hours. Pigs were randomized to be intubated with a standard SSA ETT (Control). Upon aspiration, the patency of the suction lumen was tested; then, secretions were aspirated and the volume quantified. Whereas, in the treatment group, a novel delivery device was employed to advance a 12-Fr suction catheter into the subglottic space and perform SSA as reported above (Fig. 81) . A: 1, Subglottic secretions aspiration catheter; 2, Delivery device to place the aspiration catheter into the subglottic region. B: 3, ETT. Upon insertion, the delivery device was placed along the concave surface of the endotracheal tube and advanced up to the larynx. 4, Then, the catheter was inserted into the internal channel of the delivery device and advanced up to the subglottic region. Upon autopsy, lesions of the 1) epiglottis, 2) corniculate cartilages, 3) true vocal cords, and 5) subglottic region were grossly scored: 0: no injury; 1: mucosal erythema and/or edema; 2: mucosal erosion; 3: exposed cartilage. Results: Six animals (4 controls and 2 treatment) were kept in the lateral-Trendelenburg position and aspiration was performed every 4 hours. Whereas, 7 animals (2 controls and 5 treatments) were kept in semi-recumbent position and SSA was performed every 8 hours. Among animals in lateral-Trendelenburg position, SSA was performed 18.2 ± 0.9 and 18.5 ± 0.7 times in the control and treatment groups, respectively (p = 0.972). Overall, the mean volume of aspiration was 0.05 ± 0.07 (range 0-0.25 mL) and 0.03 ± 0.07 mL (0-0.25 mL) of secretions/hour in the control and treatment group, respectively (p = 1.000). The median [IR] level of injury was 1 [0] and 1 [0] in the control and treatment group, respectively (p = 0.258). Whereas, among animals in semi-recumbent position, SSA was performed 5.5 ± 0.7 and 7.6 ± 2.7 times in the control and treatment groups, respectively (p = 0.378). Overall, the median [IR] volume of aspiration was 0.14 ± 0.12 (range 0-0.41 mL) and 0.17 ± 0.30 mL (0-1.33 mL) of secretions/ hour in the control and treatment group, respectively (p = 0.324). The median [IR] level of injury was 1 [0] and 1 [0] in the control and treatment group, respectively (p = 0.734). Conclusions: In preliminary in-vivo evaluations, the novel SSA strategy is safe and not inferior to standard ETTs comprising SSA. Introduction: Endotracheal intubation is a common procedure in the treatment of respiratory failure in the Intesive Care Unit (ICU). Sometimes generates local complications that might difficult or even make it imposible to remove the artificial airway (AA). If this complications are not detected before the AA removal, stridor, laryngeal dyspnea or spasms might apear requiring emergency reintubation/recannulation in rather difficult circumstances with severe increase in morbimortality. Therefore is essential to follow a clinical guideline in the removal of the AA once overcome weaning and espontaneous breathing test. Objetive: To describe the incidence of treatable causes for negative cuff-leak test in our critical care unit. Methods: We prospectively registered all patients admitted in our ICU (18 beds) who underwent artificial airway procedure (endotracheal tube or tracheotomy) during 24 months (from January 2014 to December 2015). In every patient who overcome the weaning guideline process (including spontaneous breathing test), we implemented also an aritificial airway removal guideline, containing the cuff-leak test, in Volume Controlled Ventilation (CMV) and with the cuff deflated. If leak rate was greater than 20 % of tidal volumen, "positive test", we could safely remove the artificial airway. If leak rate was less than 20 %, "negative test", an upper airway revision by direct laryngoscopy was performed to evaluate treatable causes. Results: We registered 407 patients in ICU with artificial airway procedures (endotracheal tuve, tracheotomy) during the study period. Mean age was 62 years (48-76 CI 95 %), 67,8 % were male and the mean APACHE was 23 (33-13 CI 95 %). Before extubation/decanulation, cuff-leak test was performed. 374 (91.9 %) had "positive test" and 33 (8.1 %) "negative test". In these negative test a direct laryngoscopy was performed and the following treatable causes were found: 23 laryngeal edema, 2 dental bridge impacted in the pharynx, 1 supraostial laryngeal edema plus granuloma, 1 edema plus decubitus, 1 laryngeal granuloma, 1 distal tube obstruction, 1 laryngeal granuloma in intercricotiroidea tracheotomy, 1 with a bloodclot in the larynx and finally 1 with a tumor in vocal cordv (Fig. 82) . The inclusion of an upper airway direct laryngoscopy exam after negative cuff-leak test, ensures specific diagnosis and manage of the treatable causes. In all our patients, the artificial airway was safely removed after treating the cause, avoiding the increase of morbimortality due to reintubation/recanulation. How do we deal with the airway: assessment in the emergency department (ED) and intensive care unit (ICU) C. Sepsis is frequently complicated by organ dysfunction and the lungs seem to be particularly vulnerable to the inflammatory response. The disabling fatigue and the higher susceptibility to developing a viral respiratory infection that many survivors experience in post-sepsis syndrome cannot yet be explained. Herein, we sought to evaluate the impact of sepsis on lung structures of the post-sepsis survivors. Methods: Adult Wistar rats (200 g) were submitted to sepsis [iv. 2 mL E. coli 10 8 (S8) or 10 9 CFU/ mL (S9), DL60 and DL80, respectively, in 26 hours].Under general anesthesia, the lung architecture was monitored by histology at 6 hours after sepsis (T6h, n = 3/group) and 30 th day survivals (T30d, n = 3/group). The lungtissue wasexaminedafter staining with H.E. Results: The S8-6 h group showed a vascular congestion of the alveolar wall, alveolar wall thickening and neutrophils infiltration.It was also observed an increase in cellularity in the bronchial lumen and BALT hyperplasia (Fig. 86) . After 30 days was observed a reduction of the alveolar wall thickening, complete reduction of alveoli vascular congestion in the entire lung, however, there was a persistence of the hyperplasia of BALT. In animals submitted to more severe sepsis (S9-30d), the alveolar wall thickening remained more intense, there was decreased of inflammatory cells infiltrates, but persisted the alveoli wall congestion and BALT hyperplasia and hypertrophy (Fig. 2) . These findings showed that depending on the severity of sepsis, the parenchyma and pulmonary microcirculation injuries may have significant recovery (S8) or minimal (S9), even 30 days after the clinical recovery from sepsis. In addition, presence of histological signs suggestive of persistence of a state of the activated BALT, even in less aggressive sepsis (S8-30d), shows that still exist a continuous stimulating inflammatory factor even in the absence of clinical signs of infection. Thus, the overall data demonstrate that clinical recovery is not synonymous of a normal physiological state, on the contrary, histology showed an ongoing severe lung disease process at post-sepsis period. How long last these eventsis unknown, but the data suggest that post-sepsis physiological state is far from the standard health. Introduction: Eph-Ephrin signaling mediates various cellular processes, including vascular permeability, inflammation, angiogenesis, cell migration, axon guidance, fluid homeostasis, and repair after injury. The detailed mechanisms of EphA2 signaling in lung injury are unknown. Objectives: To evaluate the role of EphA2 signaling, as well as related signaling pathways, in the lipopolysaccharide (LPS)-induced lung injury model. Methods: Three experimental mouse groups were formed: PBS + IgG (IgG instillation after PBS exposure), LPS + IgG (IgG instillation after LPS exposure), and LPS+ EphA2 mAb (EphA2 monoclonal antibody instillation posttreatment after LPS exposure). Cell numbers and protein concentration in the bronchoalveolar lavage fluid (BALF), changes in histopathology and the expression of several signaling pathway proteins-including PI3K-Akt-NF-kB, Src, Erk, E-cadherin and mTOR-were compared among the three groups. Results: Acute LPS exposure significantly upregulated EphA2 and EphrinA1 expression. Inhibition of the EphA2 receptor by intranasal EphA2 mAb administration attenuated lung injury and reduced BALF cell counts and protein concentration (all, P < 0.05). EphA2 mAb posttreatment downregulated the expression of PI3K 110γ, phospho-Akt, phospho-NF-kB, Erk1/Erk2, phospho-Src, and phospho-S6K. In addition, inhibiting the EphA2 receptor augmented the expression of E-cadherin, which is involved in cell-cell adhesion. Conclusions: The present data suggest that the EphA2 receptor may be an unrecognized modulator of several signaling pathways-including PI3K-Akt-NF-kB, Src-NF-kB, E-cadherin, and mTOR-in LPS-induced lung injury. Further studies are needed to verify the potential of EphA2 receptor inhibitors as novel therapeutic agents for LPS-induced lung injury. Introduction: One of the therapeutic ventilation goals of the ARDS Network protocol is to control blood pH in a certain range (7.30-7.45) [1] . Only a strict and frequent schedule of arterial blood gas analysis can result in a good performance for such control, which mainly relies on personal efforts. Objective: This preliminary work was to analyze the possibility to control blood pH via the average carbon dioxide elimination (VCO 2 ) that can be noninvasively measured from the exhaled air during the closed-loop ventilation therapy [2] . METHOD. Approved by the local animal ethical committee, a male pig (45.4 kg) was anesthetized, intubated and ventilated in supine position for 1 h. After induction of ARDS by repetitive lung lavages, automatic ventilation therapy was continued for 3 h. All vital parameters including the CO 2 data from a capnography (CO 2 SMO+) were continuously recorded by a medical panel PC. Based on the ARDSNet protocol, higher PEEP/lower FiO 2 settings [1] were automatically applied to the pig. After the onset of the automatic ventilation, the average VCO 2 was computed for every 30 min. Results: All goals of the ARDSNet protocol were satisfied in terms of oxygenation, pH value and plateau pressure. The figure shows the experimental results of the pH value compared to the computed average VCO 2 during the ventilation therapy. It should also be noted that a new setting of PEEP value influences the dynamics of VCO 2 . Conclusions: The carbon dioxide elimination is a possible intermediate parameter for the use of noninvasive indirect control of blood pH that could fulfil a fully closed-loop ventilation therapy based on the ARDSNet protocol. Sepsis is a leading cause of acute respiratory distress syndrome (ARDS), characterized by diffuse injury of the alveoli-capillary wall, increased pulmonary vascular permeability, and alveolar and interstitial edema. The aggressive fluid therapy is a controversial procedure by the possibility of increment the lung edema. Besides, due to the difficulties to study the lung, the consequences in the tissue injuries in sepsis patients in the post-sepsis phases are little known. The present study investigated the effects of aggressive-fluid therapy in lung tissues of the sepsis survivors. Methods: Adult Wistar rats (200 g) were submitted to sepsis (S8) (iv. 2 mL E. coli 10 8 CFU/mL −1 , DL60 in 26 hours), or sepsis and Ringer Lactate (S8HH) (iv. 30 mL/kg/20 min), 30 minutes after sepsis challenge. The tissue samples were evaluated by histology (T6h,T30d), using HE dyes.The S8-6 h group showed a vascular congestion on the alveoli walls, withintense thickening and infiltration of neutrophils, and increased cellular invasioninto the bronchus lumen. BALT showed intense hyperplasia. InS8-30d animals,there was a reduction in thickening of the alveoli wall, the absence of thecapillary congestion throughout the lung, but with cellular debris in the bronchial lumenand a persistent BALT hyperplasia (Fig. 88) . The aggressive fluid therapy in S8HH-6 h group resulted in lesser vascular congestion in the peripheral alveolar walls. More pronounced lesions were seenin the central part of the organ (hilo); with venous congestion and thickening of the alveoli-wall, infiltration of mononuclearcells and neutrophils in intra epithelia's spaces of the bronchi; BALT hyperplasia was highly evident. The aggressive fluid didnot recovered the injuries of the S8HH-30d group. the vascular congestion and thickened parenchyma were observed in whole lung, although without inflammatory infiltrate. BALT showed less hypertrophy and hyperplasia. In summary, although there was a worsening of the alveoli injuries, the signs of non-activated BALT suggested low immune activation under aggressive-fluid therapy but with high pulmonary edema due to their high permeability characteristics. The overall data suggested that lung not have adequate physiology and anatomy to support a fluid aggressive therapy demanding a more careful maneuver in terms of volume and perfusion velocity. These results reinforce the doubts that inadequate management of sepsis may cause consequences in the future. Introduction: During weaning from invasive mechanical ventilation (IMV), pulmonary oedema may develop due to cardiac failure, and it is a cause of failure in weaning from IMV. Cardiogenic pulmonary oedema produces hemoconcentration and haematocrit (Ht) is a good marker of hemoconcentration. It is not determined if the increase of Ht during weaning protocol may predict failure in weaning from IMV. Objective: To determine if the increase of Ht during spontaneous breathing trial (SBT) is a predictor of failure in weaning from IMV. Methods: We prospectively included patients with IMV >72 hours. A SBT was performed with a T-piece for two hours. Ht value at the start and at the end (or failure) of the SBT was measured and the delta was calculated. Logistic regression analysis was performed to determine the association between the increase of Ht and failure in weaning from IMV. Its performance as a predictor of failure was assessed by its discriminative capacity and calibration. A p value < 0.05 was considered statistically significant. Results: Fifty-five patients were analysed, 58.2 % female, mean age 49.9 years. Thirty-two (58. Conclusions: Patients who failed in weaning from IMV has significantly increased the value of Ht at the end of the SBT. The increase of Ht is a risk factor and has adequate discriminative capacity and calibration to predict failure in weaning from IMV. Key words: Failure of weaning from mechanical ventilation, spontaneous breathing trial, haematocrit. Introduction: With a high prevalence in Intensive Care Units (ICU), the Ventilator-Associated pneumonia (VAP) has been responsible for increased mortality and morbidity rates, hospital stay, duration of mechanical ventilation (MV), costs and a set of other complications. Usually, VAP develops 48 h after the beginning of mechanical ventilation (MV) and can be classified as of early-or late-onset. Objectives: This study aims to evaluate the incidence, length of hospital stay, number of days of MV, and treatment and prevention methods (bundles) of VAP during the year of 2015, in the ICU of CHA-Faro, as well as to compare these results with those from 2014. Methods: Patients were evaluated according to their age, sex, type of VAP (early-/late-onset), identified microorganism, antibiotic treatment, admission type and severity scores (APACHE II and SAPS II), as well as the assessment of the likelihood of lung infection (CPIS). Results: Of the 473 patients admitted to the ICU, 24 developed VAP. The incidence rate was 5.07 %, and the incidence density rate was 9.74 per 1000 ventilation days. The mean value of CPIS was 1.35 ± 7.5. Five cases were classified as early-onset (20.83 %) and 19 as lateonset (79.17 %). The mean values of both, hospital stay (7.12 ± 9.97 and 29.83 ± 21.35) and MV (5.21 ± 9.26 and 26.17 ± 23.05), were significantly different (p < 0.01) between patients without and with VAP, respectively. The most common isolated microorganism was P. aeruginosa (57.9 %) in late-onset VAP, with no microorganisms isolated (60 %) in the early-onset VAP. The adherence to VAP prevention bundles from January to October 2015 was 14,91 %. Conclusions: Our data indicate that the incidence of VAP was reduced from 2014 to 2015. The increase on adherence to VAP bundles might explain this signigficant reduction. Decrease on VAP incidence was significantly asociated with reduction on days of mechanical ventilation and length of hospital stay. Introduction: Driving airway pressure, the difference between plateau (end of an inspiratory pause) and end-expiratory airway pressure, can be an independent predictor of ventilator-induced lung injury (VILI) [1] . However, during ongoing mechanical ventilation, (dynamic) end-inspiratory airway pressure exceeds (static) plateau airway pressure, especially when inspiratory flows are very high [2] . Thus, for the same static driving airway pressure, different dynamic driving airway pressures can be reached. Objectives: To compare the role of static and dynamic driving airway pressures in the development of VILI. Methods: Sixteen healthy piglets were anesthetized, paralyzed and mechanically ventilated for 54 hours with no positive end-expiratory pressure. Animals were divided into two groups that were matched for static driving airway pressure (ΔP AW , stat ), defined as above, but not for dynamic driving airway pressure (ΔP AW , dyn ), defined as the difference between airway pressure recorded when flow zeroed immediately after an end-inspiratory occlusion (P1) and end-expiratory airway pressure. Lower and higher dynamic driving airway pressures were obtained by using lower or higher inspiratory flows. Respiratory rate was always 15 breath-per-minute. VILI was diagnosed if final lung weight (measured with a balance) exceeded initial lung weight (measured with computed tomography), as for edema. Data were compared between the two groups with Student's t and Fisher's Exact tests. Results: The two groups of animals were ventilated with similar static but different dynamic driving airway pressures (Table 66 ). Incidence of VILI was 25 % among animals ventilated with lower and 75 % among those ventilated with higher dynamic driving airway pressure (p = 0.13). On average, lung weight decreased over time (−56 ± 60 g) in the former group whereas it increased (98 ± 166 g) in the latter group (p = 0.04). Mortality at 54 hours was 13 % among animals ventilated with lower and 63 % among those ventilated with higher dynamic driving airway pressure (p = 0.12). Conclusions: For the same static driving airway pressure, higher dynamic driving airway pressures may increase the incidence of (fatal) ventilator-induced lung injury. Introduction: The sequence of events that at alveolar level determine lung inflation are only partially known. Methods that can provide simultaneously high-resolution, in-vivo conditions and information about the core region of the lungs are lacking. Ventilatory strategies to support lung function rely upon the idea that lung alveoli are isotropic balloons that accommodate gas progressively and that pressure/volume curves derive by the interplay of opening pressures and position of alveoli inside the lung. This simplistic idea has been challenged by subpleural microscopy 1 , magnetic resonance imaging 2 and computed tomography (CT) studies 3, 4 . Images of in-vivo lungs can be obtained from Synchrotron Radiation Computed Tomography (SRCT) at resolutions higher than conventional CT. Objective: To evaluate kinetics of airspaces in healthy (HC) and Acute Respiratory Distress Syndrome (ARDS) conditions. Methods: The study was conducted in seven anesthetized New Zealand rabbits. They underwent SRCT scans (resolution of 47.6 μm)of the lung at decreasing PEEP levels of 12, 9, 6, 3 and 0 cmH 2 O during end-expiratory holds. Pulmonary imaging was executed during HC and after induction of ARDS by repeated lung lavages and injurious ventilation (inspiratory pressure of 35 and PEEP = 0 cmH 2 O). Three concentric regions-of-interest (ROI) were studied: subpleural (SP), peripheral (PE) and core (CO). Images were enhanced by phase contrast algorithms. Airspaces Number (AN), covered area (AA) and dimensions (AD) were computed by using the Image Processing Toolbox for MatLab (Mathworks, Natick, USA). Student's T-test was used to assess any statistically significant difference produced by PEEP or ROI position. Results: AN and AA decreased with decreasing PEEP, however in ARDS at PEEP lower than 6 cmH 2 O they remained stable. The three ROIs had similar courses but with different magnitudes. AD during HC showed a tendency to reduce progressively after 9 cmH 2 O; during ARDS this tendency was observed sharply after 6 cmH 2 O. Conclusions: Alveolar kinetics is different between healthy and ARDS conditions. In HC and ARDS de-recruitment and isotropic deflation are both present, however their entity and proportion depend on the applied pressure. In HC, alveolar dimensions in the studied range support the idea of a continuous derecruitment simultaneous with isotropic deflation. In ARDS, passage from PEEP 12 to 6 cmH 2 O is characterized by a sharp derecruitment (alveoli do not change appreciably dimensions but can be either open or closed). In ARDS lungs this may be consequence of their high critical closing pressures and elastance. Introduction: We have previously found that during spontaneous breathing (SB) the diaphragm exerts an expiratory breaking effect, maintaining lung volume. In this experimental study in a porcine mild acute respiratory distress (ARDS) model we compared the effect on lung aeration between full mechanical ventilation (MV) and SB and our hypothesis was that SB, due to the breaking activity by the diaphragm, would improve intraparenchymal distribution of gas during expiration and reduce atelectasis formation. Methods: A mild acute respiratory distress syndrome was induced in five anesthetized, tracheostomized pigs by repeated lung lavages, targeting a PaO 2 /FiO 2 of 250 mmHg. After stabilization, the animals were allowed to breathe spontaneously and underwent a decremental continuous positive end-expiratory pressure (CPAP/PEEP) trial at 15, 12, 9, 6, 3 and 0 cmH 2 O. Then the same sequence was repeated during MV after muscle relaxation. Para-diaphragmatic expiratory dynamic CT-scans were collected four (L1) and one (L2) cm cranial to the diaphragm. The amount of gas (Vgas, [mL]) for each CT-image at half and end expiration was calculated in all the compartments from +100 to −1000 Hounsfield Units (HU). The amount of atelectasis (between −100 and +100 HU) for each selected CT-image was also measured. Paired samples Student t-test was applied to assess any statistically significant difference between study conditions. Results: At CPAP/PEEP levels equal or lower than 6 cmH 2 O, Vgas was higher during SB than during MV at all distances from the diaphragmatic dome and, in addition, at both half and end-expiration. The increase in atelectasis with decreasing CPAP/PEEP was in all animals larger during MV than SB. Only during SB, and not during MV conditions, the lung near the diaphragmatic dome (L2) was less atelectatic than the lung further away from it (L1). More atelectasis during MV than SB was observed already at half-expiration. Conclusions: SB maintains the amount of lung aeration significantly better than MV in a collapse-prone mild ARDS model. Furthermore, SB protected against atelectasis formation: this effect was visible already at half expiration. Therefore we deduce that the improved redistribution of gas and the decreased atelectasis formation depend on the preserved diaphragmatic contraction. These findings have potential implications for the design of new ventilatory strategies. The Swedish Heart Lung Fund; The School of Anesthesia of Bari University. Cerebral availability and usage of oxygen in pigs with sepsis: can lung protective ventilation protect the brain? Introduction: Sepsis is a common cause for admission to the ICU and more than a quarter who suffer from septic shock dies (1) . Severe sepsis and septic shock leads to failure of one or more organs. The brain can get affected by septic induced organ failure, a condition known as sepsis-associated encephalopathy (SAE). Protective ventilation (PV), with tidal volumes (TV) of 6 ml/kg, have showed a decrease in mortality in patients with sepsis and acute respiratory distress syndrome, in comparison to routine ventilation (RV), TV of 10 ml/kg, and is the recommended approach for intensivists worldwide (2) . However, it's not yet shown whether PV can affect hemodynamic adverse effects and impaired usage of oxygen in the brain of a septic patient. Objectives: The purpose of this study is to examine brain oxygenation and hemodynamic changes in a sepsis porcine model and to investigate whether PV may affect cerebral usage and availability of oxygen, in comparison to RV. Methods: Data was collected in an ongoing project concerning neuroinflammation in septic pigs, at the Hedenstierna Laboratory in Uppsala, Sweden. Fourteen healthy pigs were randomized to two groups and anaesthetized. The groups were given an infusion of lipopolysaccharide to induce a septic like condition and was ventilated with RV (n = 6) respectively PV (n = 8). The animals received vascular catheters in order to draw arterial and venous blood gases before and after the blood has passed through the brain (sagittal sinus), and to monitor hemodynamic changes. A flow meter was applied to the left internal carotid artery. Hemodynamic data and blood samples were collected every hour for 6 hours. Results: No difference in mean arterial pressure or arterial oxygen content was seen between the two groups. Protective ventilation enhanced oxygen delivery index to the brain (44.5 ± 14.1 to 30,3 ± 5.9 mlO2/min/m2, p = 0.018). Increased blood flow to the brain due to reduced brain vascular resistance was seen in the PV-group in comparison to the RV-group (19046.2 ± 7270.4 to 26637.3 ± 5678.5 dyn · s · cm − 5, p = 0.018). Conclusions: Protective ventilation induces hemodynamic changes in cerebral blood vessels in the septic pig which reduces brain vascular resistance. These changes leads to improved oxygen delivery to the brain. Further studies will take place in order to clarify the cause behind these changes, with an emphasis on the role of inflammatory biomarkers and neuronal nitric oxide synthase. (1) improve lung function in a stable lung injury model; (2) attenuate ventilator-induced lung injury in a model of progressive lung injury. Methods: An established model of ventilator-induced lung injury (VILI) was used (anesthetized pig) and all animals were monitored using esophageal manometry (P es , pleural pressure), Electrical Impedance Tomography (EIT, regional ventilation) and pulmonary artery catheter. 2 series of experiments were performed. Series 1 -Stable Lung Injury. 7 pigs were subject to maximal lung recruitment using PEEP (20 cmH 2 O) followed with progressive derecruitment by lowering PEEP in serial increments of 2 cmH 2 O; full physiologic assessment was performed at each decrement of PEEP. This series of assessments was performed twice in each animal: once with CNAP (−5 cmH 2 O) and once with no CNAP (the order was randomized). Series 2 -Progressive Lung Injury. Animals were randomized to 'CNAP' or 'no CNAP' (5 per group) and both groups were exposed to standardized injurious ventilation: V T 20 mL/kg, low PEEP, and the same expiratory transpulmonary pressure (P L , −3 cmH 2 O) for 4 h. Results: Series 1 -Stable Lung Injury. CNAP considerably reduced the vertical gradient of P pl (measured by direct instrumentation): at PEEP = 4: 11.3 ± 3.5 vs. 6.6 ± 2.5 cmH 2 O, PEEP vs. PEEP + CNAP (P < 0.01). Application of CNAP consistently resulted in better oxygenation, respiratory system compliance, and more homogeneous ventilation at descending PEEP values from 12 to 4 cmH 2 O. At PEEP = 4, the P/F ratio (mmHg) was 67 ± 5 (no CNAP) vs. 263 ± 36 (with CNAP, P < 0.01). At most levels of PEEP, oxygenation with added CNAP was greater despite a lower global P L (Fig. 92) . . Dynamic CT demonstrated that addition of CNAP (−5 cmH2O) to a PEEP level of 10 cmH2O yielded the same amount of aeration as a PEEP of 18 cmH2O. haemodynamics of HRS and these therapeutic approaches have been thoroughly investigated using advanced haemodynamic monitoring, this technology is not yet recommended in recent guidelines. Objectives: Therefore, it was the aim of our randomized controlled trial to compare the outcome of patients with HRS treated according to a pre-defined algorithm based on transpulmonary thermodilution (TPTD) to standard treatment. Methods: 25 patients were randomized with a ratio of 1:2 to standard care or to the RACEHORSE-protocol (Early goal-directed volume resuscitation in hepato-renal syndrome). This protocol was based on three sequential algorithms including global enddiastolic volume index GEDVI, extravascular lung water index EVLWI, cell count in the ascites and pO2/FiO2. In summary these algorithms aimed at GEDVI-guided volume expansion within the first 48 h, followed by a TPTD-guided strategy for fluid support using the PiCCO-2-device (Pulsion Medical Systems SE, Feldkirchen, Germany). Conclusions: Goal-directed therapy based on TPTD-guided substitution of albumin and crystalloids improves short term outcome of patients with HRS. Due to the limited statistical power of this mono-centric study larger multi-centric trials also including targets for vasopressor therapy are required to confirm these data. Can we predict early liver failure with indocyanine green liver clearance? Introduction: A non-invasive liver function monitoring system, the LIMON®, has been developed to measure indocyanine green (ICG) elimination by pulse spectrophotometry. The aim is to assess the relationship between pre and post-operative ICG plasma disappearance rate (ICG PDR %/min) values and the onset of post-hepatectomy liver dysfunction. Postoperative liver failure after hepatectomy has been identified by the association of prothrombin time < 50 % and serum bilirubin >50 umol/L (the "50-50" criteria). Methods: We collected 30 patients scheduled for major liver resections. Nine had chronic liver disease. Prothrombin time and serum bilirubin was determined on day 3 and day 5 in critical care unit after hepatectomy. IGC PDR was measured preoperatively and 24 hours postoperative. Results: We submit the values obtained for the variables of the ICG PDR pre and postoperative to an analysis of ROC curves, we found a very good predictive capacity for postoperative PDR showing an area under the curve of 0.96 but not well for preoperative PDR AUC = 0,667 for determined early diagnosis of postoperative liver failure. Bilirrubin and prothrombin time show an area under the curve of 0,922 and 1. Significant correlation was found between ICG PDRpost measurement taken on postoperative day 1 and bilirubin level on day 5 (p < 0,001) and prothrombin time on day 5 (p,001). The most sensible and specific value calculated for PDR post was 7.8. Discussion: LiMON ICG PDR measured by pulse spectrophotometry is a non-invasive and reliable liver function test for patients undergoing liver resection that aids in the prediction and early detection of postoperative liver failure. Introduction: Post-operative liver failure (PLF) is a major complication after extended liver resection with a high mortality rate. Early identification of patients at risk for PLF could improve prognosis. Objectives: To determine the time course of lactate, lactate clearance and the relationship of lactate with other markers of liver function and mortality. Methods: All consecutive patients (2008-2014) who were postoperatively admitted to the intensive care unit (ICU) after liver resection were included. Patients were classified as "minor" or "major" liver resection based on a functional liver remnant (FLR) of ≥70 % and < 70 % respectively. Lactate clearance (%) was defined as: (lactate at ICU admission -lactate at 6 h) / lactate at ICU admission *100. The 50-50 criteria, a validated predictor of liver failure and death after liver resection, was defined as PT >21'' and serum bilirubin >50 umol/L on postoperative day 3 [1] . Numbers are expressed as median (interquartile range). Results: A total of 382 patients admitted to the ICU after liver resections were included (80 % major resection). The main indication was colorectal liver metastasis (63 %). At ICU admission lactate was 2.4 (1.7-3.4) mmol/L. Maximum lactate level was 2.7 (2-4) mmol/L and occurred at 1.2 (0.3-7.9) hours after ICU admission. There was a significant difference between the lactate clearance at 6 h between the minor and major resections (25 % versus 14 %, P = 0.005). Highest PT was observed 30 hours after ICU admission. Only 3 patients met the "50-50 criteria" at day 3 and mortality at 30-days was 3.1 %. After multivariate analysis, lactate at ICU admission and perioperative blood loss, but not FLR, lactate clearance at 6 h or the "50-50 criteria", were independent predictors of 30-day mortality. Conclusions: Lactate levels at ICU admission, but not lactate clearance during the first 6 hours, is a strong independent predictor for 30-day mortality. In addition, lactate at ICU admission is of more prognostic value than the often used "50-50 criteria" (day 3) and also available much earlier. Introduction: Sudden cardiac arrest (CA) is one of the leading causes of death in adults in many parts of the world. Every year estimated 350.000 to 700.000 people in Europe are suffering CA and receive cardiopulmonary resuscitation (CPR). Hypoxic hepatitis (HH) can be found in up to 10 % of critically ill patients. To date, data on incidence and outcome of HH after out-of-hospital CA and CPR is scarce. Objectives: Aim of the study was to determine incidence and outcome of HH in patients after out-of-hospital CA. Methods: Assessment of incidence of HH in a cohort of 798 consecutive patients with out-of-hospital CA and successful CPR that were treated at the Medical University Vienna, 168 (21 %) patients with HH could be identified. Patient characteristics, admission diagnosis, severity of disease, course of the disease and 28d mortality were assessed. Results: Overall, 168 patients representing 21 % of the total cohort (128 male, age 56 (47-66) years) developed HH after CA with successful CPR were assessed. CA was witnessed in 136 (81 %) cases. Initial rhythm was shockable (VT/VF) in 90 (54 %), non-shockable (PEA/ Asystole) in 75 (44 %) and unknown in 3 (2 %) patients. Time to ROSC was 27 (13,25 -46,50) minutes. Cardiac events leading to CA were observed in 108 (64 %) of patients. SOFA-Score on admission was 11 (9-12), SAPS II was 80 (75-86).149 (89 %) patients needed mechanical ventilation on admission and 123 (73 %) needed vasopressor support. Mild therapeutic hypothermia was applied in 125 (74 %) patients. 28d-survival was 45 % in patients with HH and 60 % in the total cohort (p < 0,05). 107 (64 %) patients with HH were dead or had bad neurological outcome (CPC III/IV) after 28d. Conclusions: New onset of HH is a frequent finding in patients following successful CPR out-of-hospital and is associated with worse outcome. Introduction: Acetaminophen (APAP) overdose is the most frequent cause of acute liver failure in many countries. Following cell necrosis, the release of intracellular damage-associated molecular patterns, like high-mobility group-box protein-1 or DNA fragments, induces a sterile inflammation mediated through interleukin-(IL) 1, IL-6 and tumor necrosis factor-α (TNF-α), amongst others 1 . Procalcitonin (PCT) that is frequently used to monitor the course of systemic infections and inflammation is also up-regulated through these pro-inflammatory mediators 2 . Therefore, PCT could be a potential biomarker to monitor the course of APAP overdose patients. Objectives: This pilot study sought to assess whether APAP administration induced PCT synthesis in an in vitro model of human hepatoma cells (HepaRG©) and to explore possible dose-dependent relationships. Methods: Human hepatoma cells (HepaRG©, Biopredic International, Rennes, France) were cultured according to the instructions of the manufacturer. Cells were exposed to increasing concentrations of APAP (20 μg/ ml; 200 μg/ml, 500 μg/ml). Cell supernatants were collected after 24 hr (time/concentration: 24/20, 24/200, 24/500) and after 48 hr (48/20, 48/ 200, 48/500). To assess if HepaRG cells are capable of producing PCT, lipopolysaccharide stimulated cells were used as positive controls (24/LPS and 48/LPS). PCT was measured using the BRAHMS PCT LIA-Test (Thermo Fisher Scientific, Waltham, USA). Lactate dehydrogenase (LDH), gammalactate dehydrogenase (GLDH), aspartate aminotransferase (AST), and alanine aminotransferase (ALT) were measured as markers of hepatocellular injury. All analyses were carried out in duplicate. Applying a Chi square test the score "LiFe" is significant in order to assess the mortality of patients both in ICU and at 30 days (p < 0.002 and p < 0.003 respectively). The Pearson correlation coefficient between the different scores and the score "LiFe" is: APACHE II 0.51, SAPS II 0.41, SOFA 0.52 and MELD 0.74. Conclusions: The score "LiFe" is a quick and useful tool in our environment for assessing the prognosis of patients with liver disease admitted to ICU. The score "LiFe" is correlated with MELD values. Introduction: Hypoxic hepatitis (HH) is a frequent found condition in critically ill patients and is associated with a high morbidity and mortality. Up to 10 % of critically ill patients suffer from HH during their stay at the ICU. Literature of HH after cardiac arrest is scarce and only available in out-of-hospital cardiac arrest (CA). To date no study evaluated the incidence and outcome of HH in patients after in-hospital CA. Objectives: Aim of the study was to determine incidence and outcome of HH in patients after in-hospital CA. Methods: Assessment of incidence of HH in a cohort of 270 consecutive patients with in-hospital CA and successful CPR that were treated at the Medical University Vienna. Patient characteristics, admission diagnosis, severity of disease, course of the disease and 28d mortality were assessed. Results: Overall, 51 patients representing 19 % of the total cohort (33 male, age 67 (54,5 -76,5) years) developed HH after CA with successful CPR. CA was witnessed in 48 (94 %) cases. Initial rhythm was shockable (VT/VF) in 16 (31 %), non-shockable (PEA/Asystole) in 35 (69 %). Time to ROSC was 8,5 (2-18,5) minutes. Cardiac events leading to CA were observed in 34 (67 %) of patients. SOFA-Score on admission was 11 (8) (9) (10) (11) (12) (13) 5) , SAPS II was 88 (78,5 -97). Mild therapeutic hypothermia was applied in 24 (47 %) patients. In 6 (12 %) of patients with HH was a cardiac re-arrest observed. 28d-survival was 37 % in patients who developed HH compared to 63 % in patients without HH (p < 0,05). 19 patients, who developed HH, survived longer than one month, of these 16 (84 %) had good neurological outcome (CPC I/II). Conclusions: New onset of HH is a frequent finding in patients following successful CPR in-hospital and is associated with worse outcome. Circulating bile acids predicting hepatic decompensation and acute-on-chronic liver failure T. Horvatits 1 , A. Drolz 1 , K. Roedl 1 , K. Rutter 1 , A. Ferlitsch 2 , G. Objectives: Aim of this study was to evaluate the impact of circulating serum BAs on clinical complications in patients with liver cirrhosis. Methods: 143 patients with liver cirrhosis were included in this prospective observational study. Total serum BAs and individual BA composition were assessed in all patients on admission. BAs were analyzed via high performance liquid chromatography. Clinical complications such as AD, ACLF and transplant-free survival were recorded. Results: Circulating total and individual BAs were significantly higher in patients with bacterial infection, AD and ACLF (p < 0.001). BAs furthermore correlated significantly with model of endstage liver disease (MELD) and hepatic venous pressure gradient (p < 0.001). Total serum BAs were identified as independent predictor of decompensation on admission (independently of sex, age and severity of liver disease assessed via MELD score) (OR 1.017, 95%CI: 1.01-1.025, p < 0.001) and furthermore predicted new onset of decompensation/ ACLF during follow-up (OR1.025, 95%CI:1.012-1.038, p < 0.001). Best cut-off predicting new onset of AD/ACLF and survival during course of time was total BAs ≥36.9 μmol/l. Conclusions: Circulating total and individual BAs are associated with AD and ACLF in patients with liver cirrhosis. Measurement of serum BAs could represent an additional marker for risk stratification in cirrhotic patients with respect to new onset of decompensation and ACLF. (Table 67) , with a minimal Alb loss. We could not demonstrate any release of the adsorbed Bil. For the in vivo study, we enrolled until today, 3 patients (Table 68) . Bil Mass Balance (MB) in vivo was higher than in vitro and showed the system's capacity of Bil removal, whereas removal rate (RR) is not significant for that purpose, being affected by many factors, first at all Bil production. In patient 3, Cytosorb was continuously used for 4 days and it would seemed to favour reduction of inflammation, help the recovery of hepatic function, and the hemodynamic stabilization, with inotropic support interrupted already after 2 nd treatment. Conclusions: The in vitro study shows the effectiveness in removing Bil, also Alb-bound, for 24 h, without significant Alb loss. In vivo, Cytosorb is able to remove Bil in combination with cytokine removal, as reported in literature. Clinical effects suggest to be linked to the precocity of treatment and the adequate dose. Its use might help in restoring organs function. Cytosorb might represent a simple aid in organ dysfunctions, that may work alone or in combination with CRRT. Other experiences are ongoing to confirm these data. In the critically ill patient adequate PICC is even more important in the presence of neuro-muscular or cardio-vascular disfunction, coagulopathy, bleeding and massive transfusion. In adult critically ill patients calcium supplementation has been reported to improve 28-day survival [1] . Conversely, it has been shown that in septic patients calcium administration increases inflamatory signaling, multiorgan dysfunction and mortality [2] . The critical post liver transplant patient admitted in ICU can present with these conditions leading to altered PICC. Objectives: We analysed PICC of liver transplant patients and its association with ICU outcomes. Methods: Retrospective single-center study in liver transplant patients admitted in ICU at a reference liver transplant center. PICC was analysed at admission and its trend in percentual diference from baseline (deltaPICC) reflected the initial 12 hours evolution period. Univariable analysis was performed to explore association with ICU lenght of stay (ILOS) and UCI vital outcome. Results: 140 cases were included in this study. In the ICU survivor group (n = 166) the mean PICC was 1.11 mmol/L (SD 0.12) and deltaPICC −3.04 % (SD 15.2 %). While in non-survivor the mean PICC (n = 9) was 1.17 mmol/L (SD 0.09) and deltaPICC (n = 7) was −16.1 % (SD 10.1 %). The diference between survivor and non-survivor was non significative for PICC (p = 0.15; IC95% 0.021-0.14) and significative for deltaPICC (p = 0.03; IC95% -24.5; −1.49). In the 3 or less days ILOS group (n = 60) the mean PICC was 1.10 mmol/L (SD 0.09); in the 4 or more days ILOS group (n = 67) the PICC was 1.15 mmol/L (SD 0.15). There was a significant PICC difference between ILOS groups (p = 0.03; IC95% 0.003-0.09). Differences between deltaPICC between 3 or less days ILOS group (mean −1.15 %, SD 14.4 %) and 4 or more days ILOS (mean −1.16 %, SD 10.0 %) were not significative (p = 0.99; 0.-4.31; 4.33). Conclusions: Univariable analysis in liver transplant post-surgical patients revealed longer ILOS significantly associated with higher PICC at ICU admission and a negative deltaPICC significantly associated with higher ICU mortality. Multivariate analysis will assess the independent value of calcemia as a risk factor in this ICU population. Introduction: Liver transplant (OLT) is the only definitive therapy for patients with cirrhosis and also for those patients on acute liver failure that do not regain liver function. It is a highly demanding procedure that carries a high number of complications, but outcome is regarded nowadays as excellent. We analyzed prospectively ten years ago the complications in our patients and wanted to evaluate if management and results have changes in this ten years. Objective: To define the profile of early complications after OLT and its related variables and to compare them with our population from ten years ago. Introduction: Adrenomedullin and endothelin-1 are hormones with opposing effects on the cardiovascular system. Adrenomedullin acts as a vasodilator and seems to be important for the initiation and continuation of the hyperdynamic circulatory response in sepsis. Endothelin-1 is a vasoconstrictor and has been linked to decreased cardiac performance. Few studies have studied the relationship between adrenomedullin and endothelin-1 and morbidity and mortality in septic shock patients. High-sensitivity troponin T (hsTNT) is normally used to diagnose acute cardiac injury but is also prognostic for outcome in intensive care. Objectives: We investigated the relationship between mid-regional pro-adrenomedullin (MR-proADM), c-terminal pro-endothelin-1 (CT-proET-1) and myocardial injury, measured using transthoracic echocardiography and hsTNT in septic shock patients. We were also interested in the development of different biomarkers throughout the ICU stay, and how early measurements were related to mortality. Further, we assessed if a positive biomarker panel, consisting of MR-proADM, CT-proET-1 and hsTNT changed the odds for mortality. Methods: A cohort of 53 consecutive patients with septic shock had their levels of MR-proADM, CT-proET-1, hsTNT and left ventricular systolic functions prospectively measured over 7 days. The relationship between day 1 levels of MR-proADM/CT-proET-1 and myocardial injury was studied. We also investigated the relationship between biomarkers and early (7 day) as well as later (28 day) mortality. Likelihood ratios, pre-and posttest odds for mortality were calculated. Results: Levels of MR-proADM and CT-proET-1 were significantly higher among patients with myocardial injury and were correlated with left ventricular systolic dysfunction. MR-proADM and hsTNT were significantly higher among 7 and 28 day non-survivors. CT-proET-1 was also significantly higher among 28 but not 7 day nonsurvivors. A positive biomarker panel consisting of the three biomarkers increased the odds for mortality 13-20-fold. Conclusions: MR-proADM and CT-proET-1 are associated with myocardial injury. A biomarker panel combining MR-proADM, CT-proET-1 and hsTNT increases the odds ratio for death, and may improve currently available scoring systems in critical care. Circulating levels of advanced glycation end products (AGES) are associated with 28-day mortality in septic patients E. Introduction: The usefulness of lactate levels and ScvO2 is well known in treating patients with sepsis. We have encountered discrepancies between lactate levels and ScvO2, but the reason for this discrepancy is unknown. Objectives: Our hospital joined the transpulmonary thermodilution (TPTD) study, which is a multicenter, prospective, randomized controlled trial. Inclusion criteria were ICU patients with sepsis undergoing mechanical ventilation. Various data were collected using TPTD and compared with CVP for transfusion. Primary outcome was ventilator-free days and secondary outcomes were ICU length of stay, 28-day mortality, and length of hospital stay. We used these study data to determine factors associated with the discrepancy between lactate clearance and ScvO2. Methods: Based on TPTD study data, we subdivided patients into the following four groups: ScvO2 ≥ 70 % and lactate level ≥ 4 mmol/L (HH group), ScvO2 ≥ 70 % and lactate level < 4 mmol/L (HL group), ScvO2 < 70 % and lactate level ≥ 4 mmol/L (LH group), and ScvO2 < 70 % and lactate level < 4 mmol/L (LL group). Evaluations included the SOFA score, SAPS II score, lactate level, ScvO2, BNP, etc. We also analyzed mortality at 28 days, duration of mechanical ventilation, use of renal replacement therapy, duration of catecholamine use, and ICU length of stay. Results: In total, 57 patients were included: HH group (n = 11), HL group (n = 24), LH group (n = 6), and LL group (n = 16 Methods: Twenty-one pigs were intubated and on mechanical ventilation (MV) for 72 hours. Following surgical preparation, pigs were randomized to be positioned: 1) in semirecumbent/prone position, ventilated with a duty cycle (T I T TOT ) of 0.33 and without PEEP (control); 2) as in the control group, PEEP of 5 cm H 2 O, and T I T TOT to achieve a mean expiratory-inspiratory flow bias of 10 L/min (treatment); 3) in Trendelenburg/prone position and ventilated as in the control group (Trendelenburg). Following randomization, P. aeruginosa was instilled into the oropharynx. Prior to bacterial challenge, and every 24 hours thereafter, blood was drawn for quantification of serum interferon (INF)-Gamma; interleukin (IL)-1α; IL-1β; IL-1 receptor antagonist (RA); IL-2; IL-4; IL-6; IL-8; IL-10; IL-12; IL-18, tumor necrosis factor (TNF)-α, tissue factor; angiotensin-2; adrenomedullin and protein C reactive. VAP and VAT were clinically suspected and confirmed by histological/microbiological studies. Results: Overall, ten animals developed VAP (4 controls, 6 treatments and 0 Trendelenburg), four animals VAT (1 control, 0 treatments, 3 Trendelenburg) and 6 did not develop any pulmonary infection ( Objectives: The aim of this study is to analyse the relationship between tissue hypoxia, levels of hypoxia-inducible factor 1α (HIF-1α, a factor that activates gene expression in response to inflammatory and hypoxaemic conditions) and the innate immune response in patients with septic shock, and its relationship with mortality. Method: Prospective observational study in patients with septic shock and healthy volunteers (controls) to analyse normal values of non-standard determinations (pyruvate, HIF-1α, and HLA-DR on circulating monocytes). Individuals signed an informed consent and the study was approved by the Ethics Committee. Tissue hypoxia was monitored by non-invasive transcutaneous spectroscopy (NIRS). At inclusion, 3rd and 7th day, venous blood samples were obtained for determinations above were obtained. Lactate was determined at baseline, every 6 hours the first day and daily until day 3. Quantitative variables expressed as median [ , and SOFA 9 [7.5-11.5]. All patients had elevated levels of leukocytes, CRP, serum lactate and pyruvate. Pyruvate levels were higher in patients than in controls. HIF-1α was higher in patients, reaching peak levels on day 3rd (2.06 times the inclusion day). In patients: a) levels of HLA-DR on monocytes circulating inclusion day were 2.86 times lower than in controls; b) IL-6 and IL-10 levels in patients were higher than in controls on the day of inclusion, with marked reduction at day 3rd (26.25 and 6.98 times respectively), IL6 was 1088.49 pg/ml and 0.17 pg/ml, respectively. IL10 values were 121.66 pg/ml in patients being undetectable in controls; c) there were no differences in HIF-1α, IL-6, IL-10 and tissue hypoxia between dead and survivors. In the follow up, an inverse relationship between pyruvate and HIF-1α levels was observed. Conclusions: Patients with septic shock show peripheral tissue hypoxia. HIF-1α appears high and rising until the third day of monitoring, which despite a decrease in the levels of IL-6 and IL-10 in those days was observed. Introduction: The high inter-and intra-patient variability and confounding factors during early sepsis has made it difficult to diagnose and characterize. Despite this variability, serum cytokine levels such as interleukin-6 (IL-6) during sepsis appear to follow consistent and distinctive trajectories across patients. Objectives: To classify septic patients into groups defining endotypes of sepsis using longitudinal IL-6 trajectories and to estimate time of sepsis onset. Methods: The multicenter, randomized Protocol-Based Care for Early Septic Shock (ProCESS) trial enrolled 1341 patients with septic shock and showed a 16.3 % 14-day mortality. Patients with IL-6 measured at 0, 6, 24, and 72 hours after enrollment were selected for this analysis. Those with IL-6 values below the lower limit of detection or with missing measurements were excluded, leaving 164 patients for analysis. Each IL-6 trajectory was modeled as a differential equation evolving in response to inflammation. 3 classes of differential equations were used to enforce classification into specific dynamic behaviors: overdamped response, under-damped response, and overshoot-type response. Patient classification was performed based on best data fit to one of the 3 possible responses. Within each class of response, a Gaussian Mixture model on differential equation parameters was used to further classify each patient. The centers of each cluster generated a characteristic IL-6 response to sepsis (a master curve) for that sub-population. Aligning each patient along with their category master curve provided an estimate for disease time-zero with respect to onset of sepsis. Results: Subgroup analysis revealed a total of 5 distinct IL-6 responses: 1-high response and fast decline; 2-slow and protracted response; 3-fast response and protracted decline; 4-small response and fast decline; 5-sustained response. Statistical testing of clinical biomarkers between clusters revealed significant differences across 12 hour bins following disease onset. There were notable differences in vital signs, bilirubin, lactate, and urine output, establishing a correspondence between trajectory endotypes and physiological variables. This suggests that endotypes can be informed from easy and minimally-invasive measurements. Finally, endotypes were associated with distinct low and high mortality outcome. Endotype 5 exhibited particularly high mortality. Conclusions: A novel data-driven approach is proposed to generate sepsis endotypes and disease time-zero. The clusters provided physiological characterization of phenotypes. The knowledge of disease time as well as endotype risk can be used to guide treatments in order to shift sepsis patients towards better outcomes. Introduction: Acute cardiac events are common after subarachnoid hemorrhage (SAH) and are associated with an increased risk of poor outcome (1-3). However, the impact of cardiac events on long term mortality after SAH are barely studied (4). Objectives: The aim was to evaluate the impact on acute cardiac events on long-term mortality after SAH. Our hypothesis was that these events are associated with an increased long-term mortality. Methods: This is a retrospective study. Medical records from all patients admitted to our NICU from 2010 to 2015 with the diagnosis SAH were analysed. Admission variables obtained were age, medical history, WFNS score, modified fischer grade. Cardiac varibales obtained were troponin and NTproBNP levels, ECG, echocardiograpic evaluation. Kaplan-Meier curves and Cox-regression were used in the statistical analyses. Results: A total of 708 patients were admitted with suspected/ verified SAH during the study period. 118 patients did not fulfill SAH-diagnosis, 33 patients were not included due to long time to admission (>4 days). Cardiac variables were found in the following number of patients; troponin levels n = 428, NTproBNP levels n = 342, ECG n = 454, echocardiography n = 235. In 28 patients no ECG/echo/cardiac biomarkers were found. Of the 529 patients analysed, 109 patients had died at the time mortalily data was obtained (April 2016). In a univariate cox-regression analysis, WFNS grade 4-5, Fisher grade, age, history of hypertension, cardiovascular disease (CVD) or renal disease, levels of troponin and NTproBNP and ST-elevations or negative T-waves had a significant higher risk (hazard ratio) for death. Stresscardiomyopathy was not significantly associated with an inreased risk of death. Fig. 96 shows a Kaplan Meier curve of cumulative survival in patients with troponin release, divided in upper or lower quartiles. In a multivariable cox-regression analysis, both troponin levels (Table 70) and NTproBNP levels were significantly associated with an increased risk for death when adjusting for the most important admission variables; WNFS grade 4-5, age and history of CVD or renal disease. However, these differences were only significant the first year after the hemorrhage. Conclusions: Acute realease of the cardiac biomarkers troponin and NTproBNP after SAH is an omnious clinical sign which is associated with an increased risk of death, especially the first year after the hemorrhage. Further research is needed to address whether measures to optimize cardiac treatment after SAH might improve survival. Introduction: The concept of brain-heart interaction (1) has been described in several brain injuries. Traumatic brain injury (TBI) may also lead to cardiac dysfunction but evidences are mainly based upon experimental (2) and clinical retrospective studies (3) . Objectives: The present study aimed at evaluating myocardial function at the early phase of TBI using conventional 2D echocardiography and complementary STE analysis. We hypothesized that patients with TBI had altered cardiac function compared to the control group. Methods: We conducted a prospective case-control study in a level I trauma center. Twenty consecutive adult patients with severe TBI were matched according to age and gender with twenty control patients. Control group included adult patients undergoing general anesthesia for peripheral trauma surgery. Conventional and Speckle Tracking Echocardiography (STE) was performed within the first 24 post-traumatic hours in the TBI group and PRE/PER-operative in the control group. Primary endpoint was left ventricle ejection fraction (LVEF) measured by the Simpson's method. Secondary endpoints included diastolic function and STE analysis. Results: We found similar LVEF between the TBI group and the PER-operative control group (61 % [56-76]) vs. 62 % [52-70]). LV morphological parameters and systolic function were also similar between the two groups. Regarding diastolic function, isovolumic relaxation time was significantly higher in the TBI cohort (125 s [84-178] versus 107 s [83-141], p = 0.04), suggesting subclinical diastolic dysfunction. Using STE parameters, we observed a trend toward higher strains in the TBI group but only apical circumferential strain and basal rotation reached statistical significance. STE-derived parameters of diastolic function tended to be lower in TBI patients. Conclusions: No systematic myocardial depression was found in a cohort of severe TBI patients. STE rather revealed correct adaptation of left systolic function, while diastolic function slightly impaired. Introduction: The immediate events associated with aneurysmal subarachnoid haemorrhage (SAH) result in early brain injury (EBI). Delayed cerebral ischemia (DCI) may also develop between 1-2 weeks after bleeding caused by vasospasm and other mechanisms. Characterizing both type of brain injury and standardising the diagnostic modalities is key to predicting and potentially modifying the outcome of SAH. Objectives: Use serial MR imaging to determine the characteristics of early and late brain injury and investigate their role in determining outcome after SAH. Methods: Patients' demographic and clinical data were collected. 6months outcome was evaluated using the extended GOS (GOS-E). Serial MRI scans were performed on days 0-5 (early), and 7-14 (late) following the acute bleeding. The MRI protocol included 3D-T1, T2, T2*-weighted sequences, 3D-FLAIR, diffusion-weighted imaging (DWI) and apparent diffusion coefficient maps (ADC) were calculated. FLAIR, DWI/ ADC and T2 sequences were co-registered and volumes measured using the SPM and Analyze software. Early cerebral ischemia (ECI) and DCI were identified as hyper/hypointense lesions on the correspondent DWI/ADC maps. DWI were classified on the basis of the whole lesion volume: none (N), spotty (SP), ≤10 ml (S = small), and > 10 ml (L = large). Early cerebral haematomas (ECH) were identified on FLAIR and T2 and similarly classified as none (N), small (S) and large (L). All early lesions (excluding SP lesions) were named as EBI (ECI + ECH). Chi square test and logistic regression were used for univariable and multivariable analysis. Introduction: Acute stroke is the second leading cause of death and disability in western world 1 . An early risk assessment with estimate of the severity of disease and prognosis is pivotal for optimized care and allocation of healthcare resources. Novel biomarkers have emerged to assist clinicians with decision making. Copeptin is a novel neuroendocrine peptide that is a strong and independent prognostic marker for functional outcome and death in patients with acute stroke 3 Background and purpose: Stroke is an important cause of death worldwide, and the majority of stroke survivors suffer from some form of residual disability. This study aimed to investigate the association of blood biomarkers with stroke scales and their predictive value after acute stroke at the time of admission until hospital discharge. Design and methods: We investigated 60 patients with acute stroke who were admitted within 24 h of event onset at the intensive care unit or neurovascular emergency unit of Clínicas Hospital. All patients provided venous blood samples for the measurement of neuron-specific enolase (NSE), S100ß protein (S100ß), interleukin-6 (IL-6), C-reactive protein (CRP) and brain-derived neurotrophic factor (BDNF) within 24 h of the acute event, on the third day and on the fifth day after the stroke. Neurological stroke severity and global disability were determined with the National Institutes of Health Stroke Scale (NIHSS) and modified Rankin Scale (mRS) at the same three times of blood collection and at the time of hospital discharge. Results: The serum levels of the S100ß protein, IL-6 and CRP seem to constitute the best panel of biomarkers after acute stroke in this study. When patients were subdivided into two groups according to the NIHSS (NIHSS ≤ 6 and NIHSS > 6) and mRS (mRS ≤ 3 and mRS > 3) scores, which were used as neurological outcome measures, both neurologic scores for good outcome (NIHSS ≤ 6 and mRS ≤ 3) at hospital discharge were significantly related to the S100ß protein and IL-6 levels at all of the measured time points. Among the analyzed blood markers, S100ß, IL-6 and PCR levels significanttly correlated with the stroke scales and prognostic value. Conclusion: Blood biomarkers may be useful in acute stroke either by suggesting stroke severity or providing a prognostic value. The addition of the S100ß protein, IL-6 and CRP to previously validated stroke scales slightly improves the ability of these scales to predict outcome. Introduction: In patients with traumatic brain injury (TBI), monitoring of brain metabolism using micro dialysis revealed that a decrease in brain glucose concentrations and an increase in lactate levels were markers of cellular alterations. However, such catheters are not used routinely. Few data are available on glucose and lactate concentrations in the cerebrospinal fluid (CSF) of these patients. Objectives: Determine the relationship between glucose and lactate concentrations in CSF and arterial blood and the CSF glucose/lactate ratio and its correlation with outcome in severe TBI. Methods: We reviewed data from all patients admitted to a 35bed medico-surgical ICU following TBI over a 4-year period Introduction: To prevent delayed cerebal ischaemia (DCI), patients with spontaneous SAH (s-SAH) are frequently given supra-normal blood pressure targets. 1 If patients with DCI do not improve with hypertensive therapy (achieved using fluids and vasopressor drugs, e.g. noradrenaline), a trial of inotropic therapy (e.g. dobutamine) may be considered. 2 Consequently, vasopressor and/or inotropic therapy is frequently required in s-SAH patients. Central venous catheters (CVCs) are required for the safe administration of many vasopressors and inotropes, 3,4 but carry potentially serious morbidity and mortality risks, 5,6 particularly as the femoral insertion site is frequently chosen to avoid the theoretical risk of impaired venous drainage from the head in association with internal jugular vein CVC placement. 7 The authors observed that there was a difference in practice between consultants within the Department of Anaesthesia regarding the routine placement of CVCs in patients with s-SAH, prompting the study. Introduction: Secondary insults such as hypoxia-hypotension (HH) provide secondary brain damages and worsen neurologic outcome in patients with severe traumatic brain injury (TBI). Early identification of secondary insults with biomarkers could improve the characterization of TBI severity to better individualize treatment. Several biomarkers have been investigated in severe TBI; However, they have been poorly studied after secondary brain insults. Two of them appear to be particularly of interest 1 : Glial fibrillary acidic protein (GFAP) and Ubiquitin carboxyterminal hydrolase L1 (UCH-L1). Objective: Our objective was to describe the effects of a standardized secondary insult including hypoxia and hypotension on GFAP and UCH-L1 expression in rat brain in a model of severe diffuse TBI. Methods: Rats were randomly allocated to the following 4 groups: Control (C), in which the entire procedure was performed except TBI and HH; TBI, in which TBI was performed alone; HH, in which HH phase was performed alone; TBI + HH, in which TBI was followed by HH. The TBI model was realized according to the adapted model of Marmarou and Foda reproducing diffuse TBI with accelerationdeceleration damage. Hypoxia was performed by mechanical ventilation with O 2 /N 2 mixture of 10 %/90 % (decrease in arterial PaO 2 to about 40 mmHg). Hypotension was obtained with a controlled hemorrhagic shock (mean arterial pressure (MAP) at 40 mmHg) during 15 minutes. Brains were collected after 4 hours of mechanical ventilation for immunohistochemistry of GFAP and UCH-L1 in 6 regions known as particular sensitive to hypoxic insults 2 (neocortex, striatum, thalamus, hippocampus (CA-1 and dentate gyrus) and corpus callosum). Non-parametric data were compared using Kruskall-Wallis test (p < 0.05). Results: Twenty-four rats were included (C, n = 9; TBI, n = 9; HH, n = 3; TBI + HH, n = 3). For GFAP, immunostaining revealed a decrease of strong staining (p < 0.001) in the neocortex for TBI + HH group compared to TBI group (Fig. 101) Introduction: The study hypothesis was hypoglycaemia is an independent outcome prognosticator in severe traumatic brain injured cases. Objectives: The study aimed to see the role of glucose monitoring in the brain parenchyma region as independent outcome prognosticator and its association with plasma glucose . The aim of the study was to analyse the relationship of intracerebral glucose measured by intraparenchymal cerebral microdialysis and it's relationship to blood glucose. We also evaluated the relationship of these values to the outcome. Methods: Prospective nonrandomised study conducted at a tertiary care trauma centre in India.Twenty-five patients with severe TBI who underwent decompressive craniectomy were prospectively monitored with intracerebral microdialysis catheters (MD). Results: Fifteen patients (60 %) had a good outcome in terms of GOS at 3 months while the rest (10 patients) had poor GOS at 3 months. There was significant difference in the incidence of hyperglycemia (RBS > 10 mmol/L) between the two groups (p < 0.0001). The difference between the two groups while comparing episodes of hypoglycemia was significant (p = 0.0026). Good outcome group had fewer episodes of brain hypoglycemia during systemic hypoglycemia (p = 0.0026). Neither mean blood glucose values nor mean cerebral glucose values predicted outcome at 3 months. Conclusions: After decompressive craniectomy in severe TBI, there was a poor correlation between plasma and MD glucose concentration. A high degree of variation was seen in the correlations for patients individually. Neither mean blood glucose values nor mean cerebral glucose values predicted outcome at 3 months. Good outcome group had fewer episodes of both hyperglycemia and hypoglycemia. Education, training, staff Introduction: Simulation is increasingly recognised as a useful modality in post-graduate education in Intensive Care Medicine (ICM) but is often perceived as expensive and difficult to deliver. It is used for recruitment to ICM training posts and also forms part of assessment for the Faculty of Intensive Care Medicine exam, however its use in ICM education training lags behind anaesthesia. Objectives: We aimed to establish and evaluate a programme of regular, integrated, curriculum-mapped point-of-care simulation training in a United Kingdom University Hospital Intensive Care Unit. Methods: A 6 month pilot project was undertaken delivering dedicated, weekly inter-professional simulation sessions as part of the existing trainee education programme. This consists of weekly, 2hour curriculum-mapped small group sessions attended by stage 1, 2 and 3 ICM trainees. During the pilot programme, 1 hour of each session was transferred to a simulation-based session, with scenario objectives designed to complement the teaching topic. At least 1 member of nursing staff was released from clinical duties to participate in the session. Other allied professionals were encouraged to attend. Each session required 1 confederate, 1 debriefer and 1 person to run the manikin. Scenarios were designed to explore both technical and non-technical aspects of the topic and were delivered in an ICU side-room that is permanently set up with a manikin. Debriefing was provided using the´good judgement´model. Quantitative and qualitative feedback was sought after each session 1 . After 6 sessions, interim feedback was analysed and changes were implemented for the remaining pilot sessions. Results: Several common themes emerged from the initial feedback. Whilst broadly positive, participants and faculty all stated that the room was very crowded, with many feeling that it detracted from the learning experience. In an attempt to address this, we employed the low-cost iOS application Airbeam®. This allows live audio and video to be streamed over a secure wireless network between iOS devices (iPhones and a MacBook). This allowed observers to view the scenario from an adjacent room. Final feedback was almost universally positive. Participants reported greater willingness to speak up in future and highlighted specific issues such as the accessibility of emergency guidelines. Quantitative feedback demonstrated statistically significantly higher scores in all areas for simulation versus didactic teaching. Conclusions: We were able to provide a curriculum-mapped, in situ simulation-based training programme within our ICU that was highly rated by participants using low-cost, medium fidelity technology. We present our experiences as potential template for other programmes. Introduction: A recent article written by The Faculty of Intensive Care Medicine Workforce Advisory Group (FICM WAG) highlighted the looming staffing crisis for ICM within the UK due to the increasing need for critical care related to the increasing age of the population. The Intensive Care National Audit and Research Centre (ICNARC) Simulation 9.161 (9-10) 9.352 (9-10) 9.397 (9-10) 9.353 (9-10) p value <0.001 0.004 <0.001 0.004 have advised FICM WAG to expect a 4 % rise per year in the demand for intensive care beds and the Centre for Workforce Intelligence (CfWI) is predicting a required increase in the number of WTE in anaesthesia and ICM from 6,100 to 11,800 by 2033. 1, 2 This, in conjunction with contract reforms and a change in workforce demographic, means that we need a multifaceted approach to increasing the number of intensivists over the coming years. Objectives: Less than full time (LTFT) trainees are still very few in number within ICM and we wanted to assess how the experiences LTFT anaesthetic trainees had within the ICU setting affected their future career choices and whether this group could be a source of increasing the number of applicants to ICM dual training. Methods: We used an anonymous web based survey distributed nationwide to LTFT anaesthetic trainees. Results: We received 115 responses. The vast majority were LTFT due to childcare responsibilities (96.4 %). 7.2 % had been asked to complete their ICM training full time despite approval for LTFT training from their parent specialty. 40 % had considered dual training with ICM but ultimately decided against it. Only 3.5 % were planning to apply in the future. 78.3 % had encountered difficulties with ICM training related to their LTFT status. The most common issues were engaging in extra-curricular activities, negative attitudes to LTFT training and working patterns. 45.2 % felt they were perceived more negatively than their FT peers. 53.1 % felt they would consider applying for dual training if there was a more structured pathway for LTFT trainees. LTFT trainees expressed a wish to connect with others in order to allow peer support and mentorship. Conclusions: Very low numbers of LTFT anaesthetic trainees are pursuing a career within ICM due to difficulties encountered with their training. Some of the highlighted issues may be due to the nature of ICM but the negative attitudes experienced by LTFTs can and should be addressed and more structured guidance for navigating LTFT training within ICM could be developed. Innovative approaches to allow equity of access to training opportunities would be welcomed. We propose that although ICM and LTFT training have not been the most natural bedfellows, there is a pressing need for this relationship to improve. LTFT trainees may be a relatively untapped resource which could contribute towards the necessitated expansion of the ICM workforce. Introduction: Oral part of EDIC diploma examinations has changed in 2013 into objective-structured clinical examination (OSCE) type exam [1] . All candidates face identical questions with pre-defined correct answers simultaneously in 7 high-throughput exam centres. Objectives: To identify factors associated with success in part 2 EDIC exam. Methods: We prospectively collected self-reported data from all candidates sitting EDIC Part 2 in 2015, namely demographics, professional background and attendance to an EDIC part 2 or generic OSCE exam preparatory courses. After testing association with success (with cut-off at p < 0.10) and co-linearity of these factors as independent variables, we performed a multivariate logistical analysis, with binary exam outcome (pass/fail) as the dependent variable. and 20 % of missing candidates' data are the main limitations of this study. The ESICM examination committee and Executive Committee have taken a series of measures in order to optimise fairness and reproducibility of the exam, which will be meticulously monitored in upcoming series of exams. Conclusions: Younger age, English as native language, working at a European country and the use of PACT for preparation were factors associated with success in oral part of EDIC exam. Despite the limitations of this study, the signal of differences in outcomes among the 7 exam centres will need further investigation. Introduction: National guidelines state that critically ill women should receive the same standard of care for their pregnancyrelated and critical care needs. With changes to midwife training focusing on normal labour and delivery, nursing competences are reduced. A recent national audit identified that 43 % staff in maternity high dependency unit (HDU) areas had no specific critical care training (1). Objectives: -To identify the need to cerate a HDU on the labour ward to meet these national standards through local audit. -Development of a training course for midwives. Methods: A retrospective audit including all cases admitted to HDU over a one-year period was conducted. Information regarding demographics, diagnosis, maternal and neonatal morbidity and mortality and length of critical care stay was collected. Secondly, a prospective audit over a 2week period surveyed all obstetric in-patients including demographics, physiology scoring, level of care required and staff providing this care. Results: The retrospective phase identified 18 patients transferred to HDU, all post-partum. 6 of these patients could have been accommodated on a HDU on labour ward, had one existed. The prospective phase identified 17 women required HDU according to physiology scoring. 88 % of these women were cared for by Band 6/7 midwives, and the remainder by band 5 midwives. None of the midwives had recent critical care training. Only 26 % of patients were reviewed by an anaesthetist and 37 % by a consultant obstetrician. 42 % did not receive the correct review prompted by their MMEOWS score. MECU development: A 2-day course was created using a mixedmethods teaching program including theoretical, practical and simulation based sessions. The curriculum is designed to improve midwivesć onfidence and skills in detecting, treating and stabilizing emerging or established critical illness. The midwives who participated in the MMEC course highlighted that the practical elements, demonstrations and simulation-based teaching facilitated their learning were particularly effective. Feedback identified increased confidence in clinical management, increased awareness of when to escalate and recognition of their own limitations. Conclusions: The MECU course, as part of a larger quality improvement project to create a labour ward HDU environment was created in response to local audit. This identified that such a unit could reduce admissions to HDU provide appropriate care for in-patients in need of a higher level of care. The course created has a curriculum designed to increase confidence and awareness of the issues surrounding the sick parturient and has received excellent feedback. Future plans include development of a regional training network. The aim of this audit was to demonstrate any significant improvement in our inter-hospital transfer practice following the introduction of a new simulated all day training provided to junior doctors in the view of auditing our transfer data from 2014-2015. A single centre retrospective audit in 21 bed mixed ICU of a nontertiary university hospital. During the audit period (2014-15) 29 critical care transfers were made. We audited data of referring team, location, receiving team, transfer reason, decision-departure time, intubation details, arterial blood gases (ABG), comments of the teams, time of transfer, documentation and transferring doctor grade. Our primary aim was to analyse any effect of our newly introduced complex transfer training program. Records of the doctor performing the transfer were well kept but those of the receiving team were generally absent but thanks to the new transfer form 24 out of 29 comments from the receiving team were documented (82.7 %) and were consistent with the expectations with one comment saying (Excellent handover). The transfer of the critically ill patients remains a big challenge to juniors of all grades. A complex and holistic approach needed with a broad spectrum of knowledge regarding the possible complications. Our all day transfer course introduced in 2015 gave the opportunity to learn and hands on simulate with a live ambulance what is it like to be on a hot transfer. Our data shows significant improvement in the documentation, organization and quality of transfer without adverse events affecting patient´s safety with lack of incident reports. The positive feed backs from trainees and the overall improvement of our transfer service proves that simulated training of this difficult and grey area is fruitful and worth carry on. Introduction: Delirium is one of the most common complications resulting in ICU morbidity and mortality. Despite its well-known condition, delirium is frequently unrecognized by critical care teams. Additionally, assessment of delirium in critically ill patients is not routinely performed in our country. The Confusion Assessment Method for the ICU (CAM-ICU) 1,2 is a well-validated tool for delirium evaluation, however, it is the new tool for our team. Objectives: We aimed to assess nurse competence in using the CAM-ICU for delirium evaluation. Methods: Our hospital had implemented the CAM-ICU for delirium evaluation in 2 medical ICUs for a 4-month period and we subsequently assessed nurse competence in using the CAM-ICU by a paper-based examination. All medical ICU nurses were enrolled to perform the test which was composed of 5 case-scenarios. The nurses were allowed to use CAM-ICU sheets for Richmind Agitation Sedation Scale (RASS) scoring 3 and delirium evaluation. Results: Sixty-nine medical ICU nurses did the paper-based test. Approximately, 31 % of the examinees scored RASS inaccurately. Interestingly, 60 % of them did not understand how to interpret the mental status domain of the CAM-ICU, especially the fluctuating course of consciousness. In addition, only 29 % of them detected hypoactive delirium correctly. Furthermore, 80 % of the examinees got confused to make a diagnosis of delirium in partially sedated patients. The study demonstrated the limited skill and knowledge of our intensive care nurses in detecting delirium by the CAM-ICU. According to these results, a structural training program would be provided to increase the nurse competence in delirium assessment. Introduction: In 2007, Martin Bromiley established the first clinical human factors group, which has both clinical and NTS specialists involved in safety in intensive care and anaesthesia. Human factors and NTS contribute up to 40 % of the critical incidents as per the NAP 4 anaesthesia audit which was a UK based national level audit on the adverse incidents in airway management during anaesthesia. The causes for critical incidents included lack of situation awareness, judgement and poor decision making with poor communication and teamwork. A mortality rate of 5.6 per million general anaesthetics (1:180 000) in a period of over a year in anaesthesia, ICU and the emergency department, was reported. The project findings suggest avoidable deaths due to airway complications occur in ICU and the emergency department. Objectives: To analyse the rationale of a full-scale simulator called the Comprehensive Anesthesia Simulation Environment (CASE) to specifically study decision-making processes of anaesthetists during that were a take off from aviation Crew Resource Management (CRM)in difficult Airway & Resuscitation situation. Critical analysis of simulation as a valid and reliable tool to assess the competency based training (CBT). Methods: This study conducts a systematic literature search and an analytical review from the Cochrane database of reviews and other online sites such as Medline, Embase and Pubmed. Results-Simulator enables faculty to provide structured simulation lab experiences instead of trying to find appropriate and/or rare patient care opportunities in a health care settingAny kind of environment can be created to train multi professional teams in primary and secondary care. Currently simulators are used much more for educational purposes (undergraduate: 77 %, postgraduate: 85 %) than for evaluation purposes (undergraduate: 14 %, postgraduate: 7 % (Girard, Ely 2008) and that proportion needs to change with the current needs of using simulation for evaluation of competency. Conclusions: Human factor training develops leadership, coordination and shared understanding of roles leading to improved performance in anaesthesia, trauma and intensive care. Simulation is vital to validate CBT and it can be accepted as a comprehensive way to assess procedural skill. Behaviour and personality testing should be considered in the selection process to identify the prospective trainees in the subject along with the just use of NTS training to achieve that end. Simulation centres require important financial and human resources and hence the need for communication and collaboration among centres using simulation technology to improve quality of training. Introduction: The professional activity in the ICU departments has inherent a particularly high level of stress, which is a risk factor for development of burnout. Studies carried out in this area have revealed high levels of burnout and how these were related with labor absents with its consequences for the functioning of units. Objectives: To identify the possible existence of burnout and its risk and protective factors in health professionals of the ICU Department of Algarve Hospital Center -Faro. Methods: Quantitative, cross-sectional, descriptive study in which we applied a self-fulfilled questionnaire containing three items: sociodemographic characterization of the study population, experiences lived in the workplace based on Embriaco questionnaire and Maslash Burnout Inventory (MBI). Results: Out of 77 professionals, 75 agreed to answer to the questionnaire (response rate 97.4 %). 60 returned the complete questionnaire, 8 physicians and 52 nurses. 43.3 % of the professionals had less than 10 years of work experience and 29.3 % said that if they could they would change profession. We considered burn out if the professional presented high level on Emotional Exhaustion and Depersonalization and low level of Personal Accomplishment; high risk of developing burnout if high level was presented in Emotional Exhaustion or Depersonalization and low level in Personal Accomplishment; and moderate risk if Emotional Exhaustion or Depersonalization presented high level or Personal Accomplishment presented low level. Of the 60 professionals, 48.3 % presented moderate or high risk of developing burnout or were in burnout. Burn out levels were higher in women (26.7 %) versus men (13.3 %) and in physicians (25 %) versus nurses (23.1 %). Conclusions: Burn out or high risk of developing burnout was presented in a high rate of health professionals of our unit. Being woman and physician is associated with a higher risk of developing burnout. Strategies aiming to reduce burnout should include coping strategies and specific training in this field. developing them may help determine interventions to avoid these adverse psychological states. Objectives: The aim of the study was twofold. The first aim was to quantify the number of relatives with clinically detectable anxiety and depression using a verified scoring system. The second aim was to see how access to information correlated with anxiety and depression scores. Methods: A questionnaire of patients' relatives on the ICU over a six month period (February -August 2015) was carried out. Local ethical approval was granted. Relatives were selected at random to be part of the study and elective admissions and admissions of less than 48 hrs were excluded from the study. The questionnaire collated data on the 'hospital anxiety and depression score' (HADS), the perceived quality of communication delivered and the external support outside the ICU that was sought. Results: The questionnaire was completed by 50 relatives. Clinically significant anxiety was found in 38 (76 %) relatives and 20 (40 %) had clinically significant depression. There was no correlation between length of stay and HADS. There was a correlation between high HADS and perceived high quality of communication on the ICU. This possibly indicates that these relatives sought or required more information to help allay anxieties. External information sources relating to the ICU and patients medical conditions was actively sought in 20 (40 %) of relatives, with the internet and friends being the most popular sources. Many individuals said they felt isolated when they were at home and relied on friends for support. The results demonstrate that a large proportion of our patients relatives suffer significant acute psychological symptoms. Relatives with higher HADS sought more information from ICU staff and 40 % of relatives also sought external support and information. Following the results of this we have developed a website specific for our ICU with general information, useful links and a contact email address for the ICU consultants. We plan to re audit relatives HADS 6 months after the introduction of the website. period of 3 months, the admitting physician and coordinating nurse were asked to fill in a survey covering the 4 domains of teamwork (Leadership, communication, stress and situational awareness) on all acute admissions in the ICU. Items were scored on a scale of 0 (not important or worst level) to 10 (very important or highest level). The second part of the study consisted of structural trainings of all physician-and nursing staff in the ICU divided in groups of 3 nurses and 1 physician, using high fidelity MTW/CRM based simulation with a prefixed scenario. The groups had each to fill in surveys before and after training, and were debriefed by an experienced instructor using video analysis. Scenario trainings were scheduled to be repeated after 6 months. Results: During 133 acute ICU admissions physicians and nurses had the perception that handing over information and communication was above average, however summaries were used poorly (median scores 4 and 6 for physicians and nurses). After 2 structural trainings, physician and nurses felt they were more competent leaders (P = 0.001). Especially nurses became more confident in a leadership role (P = 0.001). Feedback loops, briefings and summaries were used more systematically (p = < 0.001) and everyone was more accustomed to standard terminology. Furthermore, nurses dared to speak up more (P < 0.001). Overall, stress levels were reduced (P = 0.015). Conclusions: The entire team in the ICU has the perception that structural training in CRM improves confidence and performance. Future research is warranted to compare these results with behavioural observations of the entire team in the ICU. This study was partially funded by Gelre Hospitals. Introduction: The number of intensive care unit (ICU) beds in the UK per capita is proportionally one of the lowest in Europe 1 ; the Royal Berkshire Hospital (RBH) has one of the lowest proportions compared to the rest of UK. Access to this resource is therefore limited and increasingly intensivists are being asked to bring intensive care to the wards 2 . Objectives: To describe the work carried out by intensive care doctors outside the 17 bed ICU in the 745 bed Royal Berkshire Hospital serving a population of 600,000 people and identify any impact this has on patient outcome. Methods: Contemporaneously recorded requests for intensivists to review patients on inpatient wards and in the emergency department during 1 st August 2014 -31 st July 2015 were retrieved from the electronic ICU database. Hospital admission and discharge data were analysed for comparison of outcomes. Results: 1108 patients were referred; paediatric patients (n = 108) and referrals with incomplete details (n = 105) were excluded from analysis. 895 patients were included in analysis, median age 66 years (interquartile range = 48-77 years). 26.6 % were admitted to ICU (n = 238), of which 76.1 % survived to discharge from RBH. 45.6 % referred patients were suitable for but not requiring an ICU admission at the time of referral (96.1 % survived), 17.6 % were at their ceiling of care (ward based care maximum; 19 % survived). 60.7 % of all referred patients not admitted to ICU survived to hospital discharge. Conclusions: Intensivists spend considerable clinical time reviewing patients on general wards, however only a proportion (26.6 %) require admission to an intensive care unit. The outcome for patients in whom escalation in care was felt inappropriate was widely poor. Whereas those reviewed by intensivists and considered eligible for but not requiring of admission to ICU experienced good outcomes (survival rate 96.1 %). Any potential effect of an increased bed capacity on admission and survival is unknown. Introduction: Since the advent of Focussed Assessment with Sonography for Trauma (FAST), focussed sonography has become integral to clinical assessment in the early phase of critical illness with wide adoption in Emergency Departments and Critical Care. Bedside ultrasound (US) guided assessment has been demonstrated to be superior to clinical assessment alone in examination of the chest, abdomen, renal and musculoskeletal systems as well as a fundamental patient safety tool for invasive procedures [1] . While focussed US can be considered an extension of basic clinical skills, most undergraduate programs globally are yet to address this deficit with some uptake in Europe and the United States and none in the UK at present. This descriptive paper outlines our institutional experience integrating focussed ultrasound training into a 3-month Resuscitation Medicine module. Objective: Explore feasibility, engagement, self perceived and objectively assessed competence following integration of US into undergraduate clinical education. Methods: An elective program on Resuscitation medicine was designed covering undergraduate learning outcomes spanning early identification of critical illness to the concepts of organ support. Nationally adopted ultrasound competencies designed for senior trainees in Emergency Medicine and Critical Care were edited and aligned to each component of the undergraduate module. Students received an average of 2 hours of formal US training weekly for an 8 week period and were each allocated a handheld device (GE VScan) and this was integrated into their routine clinical assessment. The following themes were prioritised: .71 +/− 11.9 days; p < 0.0001) and duration of MV (15.2 +/− 11.3 vs. 6.9 +/− 9.5 days; p < 0.0001). There was no difference in APACHE II scores and mortality between VAP and non-VAP groups (p = 0.27 and p = 0.16 respectively). Predominant pathogens were H.Influenza, S.Aureus, enterobacter and klebsiella. Trauma patients had increased infection with H.Influenza (28 % vs. 12 %) and S.Aureus (36 % vs. 19 %). Trauma patients who developed VAP had higher mean injury severity scores (ISS) (34 vs. 27; p = 0.0004) and lower mean pre hospital Glasgow Coma Scores (GCS) (7 vs. 9; p = 0.03) compared to trauma patients without VAP. Trauma patients with VAP had a higher incidence of significant head injury compared to those trauma patients who did not get VAP (41/61 (67 %) vs. 134/254 (52 %); p = 0.04). Chest trauma rates were similar between patients who developed VAP and those who did not (18 % v. 14 %; p = 0.43). Conclusion: The trauma population are at high risk for developing VAP. Traumatic brain injury (TBI) patients are the highest risk in this group. The ISS is a better predictor for developing VAP than traditional ICU scoring systems (APACHE II). Amongst the TBI population, ones with lower pre-hospital GCS are at higher risk, and this may reflect loss of protective airway reflexes and higher risk of aspiration. VAP is associated with longer LOS and MV, but crude mortality is unaffected. Further research should ascertain other risk factors for VAP with focussed preventative strategies for high-risk subgroups. Increased risk of psychiatric diseases in patients with mild traumatic brain injury: a nationwide cohort study Background: It is known that psychiatric disorders after traumatic brain injury are frequent. However, the relationship between mild traumatic brain injury and psychiatric diseases has never been established. We conducted a study of patients with mild traumatic brain injury to evaluate if they had a higher risk of psychiatric diseases compared with the general population. Methods: We utilized a sampled National Health Insurance claims database containing one million beneficiaries. We followed all beneficiaries from January 1, 2005 to December 31, 2013 to determine if they were diagnosed with psychiatric diseases. The definitions of psychiatric diseases in our study are schizophrenia, bipolar disorders and major depression. We further identified patients with mild traumatic brain injury and compared their risk of psychiatric diseases with the general population. Results: We identified 76,991 patients with mild traumatic brain injury and 881,511 patients without mild traumatic brain injury. After controlling for age, gender, urbanization level, socioeconomic status, liver cirrhosis, chronic obstructive pulmonary disease, diabetes, hypertension, coronary artery disease, hyperlipidemia, history of alcohol intoxication, malignancies, smoking, obesity, chronic renal insufficiency and Charlson Comorbidity Index score, the adjusted hazard ratio for psychiatric diseases was 1.46 (95 % confidence interval, 1.29-1.64). Conclusion: Mild traumatic brain injury may be associated with diagnoses of psychiatric diseases. Acute respiratory distress syndrome (ARDS) in children with pulmonary contusion S. Objective: To evaluate the incidence and prevalence of PC in children with chest trauma and the association between PC and ARDS. Methods: This is a retrospective single center cohort study. Our institutional Trauma registry was queried for patients 0-18 years of age who were admitted between 5/2008 and 10/2015 with a diagnosis of PC. PC at our center was defined using radiological and clinical criteria. We included patients with trauma with a chest Abbreviated Injury Score (AIS) of 2 or greater. Patient demographic, clinical data including age-adjusted hypotension, initial Glasgow Coma Scale score (GCS) and injury of severity score (ISS) was collected. ARDS was defined using the Berlin Criteria (1) and Pediatric ARDS PALICC criteria (2). We excluded patients who were discharged home from the emergency department or were dead on arrival. Conclusions: Our experience demonstrated that over a quarter of patients with PC will require ventilatory support and more than half of patients with PC requiring ventilatory support will develop ARDS. The need for IMV, higher ISS score and lower GCS are risk factors significantly associated with morbidity and thus help to identify high risk patients. (1), but the relationship with clinical severity is unclear, due potentially to the complex dynamics of acute inflammation. Burn injury is a unique form of trauma with very well defined aetiology, onset of insults and early clinical course, producing acute sterile SIRS in virtually all patients with a moderate to severe degree of injury. Severe burns may therefore represent an optimal study population to evaluate acute MV release and its relationship to the development of SIRS. In this pilot investigation, we measured circulating MV levels following severe burns, with severe sepsis patients as a comparator group. Objectives: To determine the relationship between circulating MVs and early onset SIRS following severe burns injury. Methods: Patients with acute thermal injury admitted to the burns Intensive Care Unit (ICU) were prospectively studied. Baseline demographic data collected included age, sex, Abbreviated Burn Score Index (ABSI) and Belgian Outcome in Burn Injury (BOBI). Blood was sampled within 24 hours of admission and centrifuged to remove cells. MVs derived from leukocytes (CD45+), granulocytes (CD11b+/CD66b+), monocytes (CD45+/CD14+), and endothelial cells (CD105+) were quantified in plasma by flow cytometry. MV levels were compared to samples taken from healthy volunteers and patients with severe sepsis recruited from the general ICU. Sepsis and burns patients that died while on the ICU were classified as non-survivors. Results: All circulating MV subpopulations were elevated in burns patients on day of admission (day 0) compared to healthy volunteers (leukocyte-MVs: 3.5-fold, p = 0.005; granulocyte-MVs: 12.8-fold, p < 0.0001; monocyte-MVs: 20.4-fold, p < 0.0001; endothelial-MVs: 9.6-fold, p = 0.01), but decreased significantly by day 2. MV levels were increased with severe sepsis, but less consistently between patients. Leukocyteand granulocyte-derived MVs on day 0 correlated with clinical assessment scores and were significantly higher in burns ICU non-survivors compared to survivors (leukocyte MVs 4.6 fold, p = 0.002; granulocyte MVs 4.8 fold, p = 0.003). Mortality prediction analysis of area under receiver operating characteristic curve was 0.92 (p = 0.01) for total leukocyte MVs and 0.85 (p = 0.04) for granulocyte MVs. Conclusions: These findings demonstrate, for the first time, acute increases in circulating MVs following major burns injury and point to their potential role in propagation of sterile SIRS-related pathophysiology. Mortality rate was 10.4 %. According to multivariate logistic regression analysis, the surgical specialty, revised trauma score < 9, injury severity core >15, the need for ventilatory support and the use of vasopressors significantly influenced mortality (P < 0.05). Conclusions: The impact of trauma on our icu has not been previously documented. This study assesses the pattern, profile, frequency, and outcome of trauma cases admitted to the multidisciplinary ten-bed ICU. The characteristics and evolution of trauma admission of this series of patients are similar to those described abroad. Mortality was in agreement with ISS and RTS scores. Hyperoxia during porcine hemorrhage and resuscitation with pre-existing coronary artery disease -part i: effects on kidney function and injury E. Antonucci 1 , T. Merz 2 , C. Introduction: Hemorrhagic shock is characterised by a mismatch of O 2 demand and supply resulting in tissue hypoxia, inflammation and subsequent multi-organ failure (MOF) 1 . Hyperoxia reduced inflammation and attenuated kidney dysfunction in hemorrhagic shock in healthy swine 2 . However, pre-existing cardiac disease increases mortality after trauma and hemorrhage 3 . Objectives: To investigate the effect of hyperoxia on kidney function during porcine hemorrhage and resuscitation with pre-existing coronary artery disease (CAD). Methods: Hemorrhagic shock was induced by removal of 30 % of the calculated blood volume (mean arterial pressure (MAP) 43 (40-45) mmHg) and maintained for 3 h in anesthetized and instrumented LDLreceptor −/− pigs with high fat diet-induced hypercholesterolemia and CAD 4 . Post-shock resuscitation comprised re-transfusion of shed blood, crystalloids and infusion of noradrenaline (NA) titrated to maintain MAP at pre-shock values for 48 h. So far, n = 7 animals were subjected to hyperoxia (FiO 2 1.0) during the initial 24 h of resuscitation, n = 8 pigs received standard treatment (FiO 2 0.3, SaO 2 ≥ 90 %). Before, at the end of, and every 12 hours after hemorrhage, we assessed systemic and renal hemodynamics (renal artery ultrasound flow probe), kidney function (creatinine clearance, urinary output, renal venous blood gas analysis) as well as mitochondrial activity (high resolution respirometry) of kidney specimens collected at the end of the experiment. Data are median (range). Results: Survival time, NA requirements as well as systemic and renal hemodynamics were comparable in both groups. However, plasma creatinine levels were significantly lower after 36 (p < 0.01) and 48 h (p < 0.02) and creatinine clearance was significantly higher at day 2 of resuscitation (115 (100-132) ml/min vs. 64 (33-97) ml/min; p < 0.02) in the hyperoxic group. Moreover, maximal oxidative phosphorylation (OxPhos) (hyperoxia: 241 (227-286), control: 189 (164-231) pmol*mg −1 *s −1 ; p < 0.03) and O 2 flux related to ATP production (178 (171-201) vs. 128 (95-147) pmol*mg −1 *s −1 ; p < 0.03) of renal mitochondria were significantly higher in the hyperoxic animals. Conclusion: In our model of porcine, resuscitated hemorrhagic shock with pre-existing CAD, hyperoxia significantly improved kidney function due to increased mitochondrial respiratory capacity which is in good agreement with previous results from healthy swine 2 . Hyperoxia during porcine hemorrhage and resuscitation with preexisting coronary artery disease - Introduction: Multi-organ failure after hemorrhagic shock is triggered by tissue hypoxia and inflammation resulting from the mismatch between O 2 demand and supply 1 . In healthy swine, hyperoxia (increased FiO 2 ) reduced inflammation and organ dysfunction 2 after hemorrhagic shock and did not adversely affect myocardial function upon critical hemodilution 3 . Pre-existing coronary artery disease (CAD) might increase the risk of cardiac injury during low flow states. However, the use of increased FiO 2 is restricted in acute coronary syndrome due to vasoconstriction and subsequent myocardial damage 4 . Objectives: To investigate the influence of hyperoxia on left ventricular (LV) function during hemorrhage and resuscitation in swine with pre-existing CAD. Methods: Hemorrhagic shock was induced by removal of 30 % of the calculated blood volume (target mean arterial pressure (MAP) 40 mmHg) and maintained for 3 h in anesthetized LDL-receptor −/− pigs with high fat diet-induced hypercholesterolemia and CAD 5 . Post-shock resuscitation comprised re-transfusion of shed blood, crystalloids and noradrenaline (NA) to maintain MAP at pre-shock values for 48 h. Amiodarone was used if needed to treat arrhythmia. So far, n = 7 pigs were subjected to hyperoxia (FiO 2 1.0) for the initial 24 h of resuscitation, n = 8 pigs received standard treatment (FiO 2 0.3, SaO2 ≥ 90 %). Before, at the end of, and every 12 hours after hemorrhage, we assessed hemodynamics and LV function (pressure-conductance catheter) and cardiac mitochondrial activity at the end of the experiment. Data are median (IQR). Results: Survival time, hemodynamics and total doses of NA and amiodarone did not significantly differ between groups. Dp/dt max transiently increased after resuscitation and decreased again in both groups, whereas dp/dt min and the isovolumic relaxation constant tau remained largely unaffected throughout the experiment despite high doses of NA and tachycardia. Together with the mostly unchanged ejection fraction, the fall in stroke volume and the rise in filling pressure (pulmonary artery occlusion pressure) after re-transfusion indicate increased LV stiffness and dysfunction in both groups. However, all cardiac parameters and mitochondrial respiratory capacity of the heart did not show any significant differences between hyperoxic and control animals. Conclusion: In our porcine model of resuscitated hemorrhagic shock with pre-existing CAD, hyperoxia did not exert detrimental effects with respect to LV function. Therefore, hyperoxic treatment appears to be a safe approach for the treatment of O 2 deficiency in hemorrhagic shock even under conditions with preexisting cardiac comorbidity. Conclusions: The pathways associated most strongly with the post-operative response to surgery, are related to innate immune response. Interestingly, we detected genes/pathways not conventionally associated with the host response to cardiac surgery such as cell proliferation, cell differentiation and cell signalling. Proinflammatory and anti-inflammatory genes operate simultaneously rather than sequentially after cardiac surgery and CPB. Association between perioperative intravenous fluid administration strategy and renal outcomes in patients undergoing cardiovascular surgery: an observational study Method: This retrospective study investigated 2613 patients undergoing cardiovascular surgery. A group of patients undergoing cardiovascular surgery from January 1, 2010 to July 4, 2012 were included in the control group and were given intravenous fluids with saline-based solutions and hydroxyethyl starch perioperatively. The other group of patients undergoing cardiovascular surgery from July 23, 2012 to December 31, 2013 formed the RPF group and were given balanced solution and a limited volume of hydroxyethyl starch solution. The primary outcome was the incidence of postoperative acute kidney injury (AKI) using serum creatinine. Secondary outcomes included the incidence of severe AKI, requirement for renal replacement therapy, renal outcome at the time of discharge. Propensity score and multivariable regression analyses were performed to assess the association of fluid management strategy with renal outcomes. Result: In the entire cohorts, postoperative AKI, severe AKI, inhospital renal replacement therapy, and persistent AKI at discharge occurred in 213 (21.2 %), 54 (5.4 %), 29 (2.9 %), and 52 (5.2 %) patients of RPF group compared to 696 (43.2 %), 254 (15.8 %), 79 (4.9 %), and 194 (12.1 %) patients of control group, respectively. In the propensity score matched cohort, the incidence of AKI, severe AKI, in-hospital RRT, and persistent AKI at discharge were also lower in the RPF group than in the control group. After adjusting by the multivariable analyses, the RPF group was independently associated with a lower risk of postoperative AKI, severe AKI, use of renal replacement therapy, shorter postoperative extubation time and intensive care unit and hospital stay. Conclusion: The RPF strategy was associated with improved acute renal and clinical outcomes after cardiovascular surgery. These findings support the need for definitive clinical studies on RPF strategy. Introduction: Diaphragmatic dysfunction is a known complication of cardiac surgery associated with delayed weaning from mechanical ventilation. Its incidence and evolution has not been established in detail. Echographic evaluation of diaphragmatic excursion is a simple, non-invasive technique that can be used at the bedside to monitor diaphragmatic function. Objectives: To evaluate the incidence and evolution of diaphragmatic dysfunction in patients undergoing cardiac surgery. Methods: This prospective observational study was conducted from 16/10 to 23/12/2015 at a tertiary cardiac surgical center in France. Consecutive elective adult patients operated via a median sternotomy with cardiopulmonary bypass were enrolled. Demographic data was collected. Echographic measurements of right and left hemidiaphragm excursions were obtained using anatomical M-Mode and averaged over 3 respiratory cycles before surgery (E1), within 48 h following extubation (E2) and between 96 and 144 h after extubation (E3). Values were compared using Friedman's analysis for repeated measures and Wilcoxon test for paired samples. Diaphragmatic dysfunction was defined as an excursion < 1 cm, as previously reported 1,2 . An inter-observer reproducibility evaluation was performed using Bland-Altman analysis. Results: 143 patients were submitted to cardiac surgery during the study period, of which 106 fulfilled inclusion criteria. 26 patients were not included: 8 did not consent, machine or operator were unavailable in 19 patients at E1. 80 patients were included and 79 were analysed (1 patient withdrew consent). The evolution of right and left hemi-diaphragmatic excursion is shown in graph 1. After establishing pre-op baseline values (E1), we observed a shorter excursion after surgery (E2) with partial recovery at E3 (Table 78 ). Patients that did not develop dysfunction followed a similar pattern. At E2, unilateral dysfunction was observed in 25 patients (37 %) and bilateral dysfunction in 4 (5 %). At E3, unilateral dysfunction remained in 9 patients (13 %). Conclusions: Diaphragmatic excursion was reduced after surgery but returned mostly to normal by day 5. 30 % of patients developed a diaphragmatic dysfunction but this was not associated with clinically relevant complications in this small cohort. Introduction: Red blood cell (RBC) transfusion has been associated with increased in-hospital morbidity and mortality after cardiac surgery. However, the impact on quality of life has not been fully clarified. Objectives: The aim of this study is to analyze whether transfusion of RBC has an impact on health-related quality of life (HRQOL). Methods: Prospective observational study of 205 patients undergoing cardiac surgery (valve replacement and / or coronary revascularization) between January and April of 2015 at a University Hospital. Clinical data relating to patient comorbidities, surgery and postoperative course were collected, including hemoglobin pre and postsurgery and the number of blood products transfused perioperatively. At 6 months after discharge, was applied EUROQUOL-5D questionnaire for assessing the HRQOL through telephone interview. Significant variables in the univariate analysis were entered into a multivariate logistic regression model to calculate the Odds Ratio (OR) with confidence interval 95 %. Results: Questionnaire response 178 patients (61.2 % males, age 70.7 ± 9.8). They were divided into two groups: group 1: problems in some dimension of HRQOL of EUROQOL 5D and group 2: without problems. In the Univariate analysis,group 2 patients (with problems) presented the following characteristics: were older (p < 0.01); were mostly males (p < 0.01); lower preoperative hemoglobin (p < 0.05), received more RBC (p < 0.01) as well as a higher Hospitality stay (p < 0.01 Introduction: Enteral nutrition (EN) is currently the route of choice for feeding critically ill patients (1); however, due to the unpredictable nature of critical illness, the delivery is frequently disrupted. Common reasons for inadequate delivery are gastrointestinal intolerance, fasting for diagnostic procedures, surgery and airway management (2) . Cumulative calorie deficits contribute to malnutrition (3) and poor outcome including increased infections, length of ICU /hospital stay and mortality (4) . There is no recognised guidance on the length of time that should elapse between stopping EN and commencing anaesthetic procedures. We developed and implemented our own fasting guidelines to address the EN interruptions on our units. In our trust, only radiologists or ICU consultants are allowed to confirm placement. We believe that this is negatively influencing tube confirmation times and contributing to EN under delivery. Objectives: To compare specific interruptions to EN in 3 different adult intensive care units (ICU), assessing impact on nutrition delivery· To examine compliance with ICU fasting guidelines on stopping and restarting enteral nutrition prior to operative and non-operative procedures Methods: An audit over 1 month in 3 adult different ICU's in a large London trust, each with its own unique specialities. Results: Data was collected on 59 patients. See Table 81 for demographic details. The most frequent reasons for stopping EN were removal and confirmation of nasogastric tubes, extubation and cancelations. Each was associated with an average deficit of 800kcals and 35 g protein per episode. The nutritional deficits relating to each episode of fasting are detailed in Tables 82 and 83. Conclusions: Although the case mix was different, each unit experienced frequent fasting impacting on enteral nutrition delivery. The reasons were similar for all units. Each fasting period was associated with considerable calorie and protein deficit. Despite having ICU specific fasting guidelines in place, violations were observed for all procedures especially extubation and tracheostomy, where the fast far exceeded 4 hours. Restarting EN was also extended waiting on NGT confirmation after the procedure. Prolonged fasting and delays in restarting EN suggests limited appreciation of nutritional deficits and associated negative impact of fasting by ICU staff.Further education to our ICU staff is recommended on fasting guidance to increase awareness and compliance. In addition, the current practice for NGT confirmation should be reviewed with the view to allowing ICU trainees to confirm position following appropriate training. chain triglycerides) lipid emulsion on liver dysfunction, infectious complications and other clinical outcomes in a cohort of critically ill patients with Apache II > 17 and length of ICU stay of at least 5 days. Methods: Observational retrospective single-centre cohort study in a general ICU from September 2014 to July 2015. Patients in the fish oil cohort (n 14) received n-3 PUFAs-enriched PN and patients in the standard PN cohort (n 10), a MCT/LCT lipid emulsion. Baseline characteristics of patients, energy and fat intake, laboratory parameters (including liver function tests), new infections, insulin requirements, days on mechanical ventilation, length of ICU and hospital stay and mortality were recorded. Significance level was defined at a p value of less than 0.05. Results: Both groups had similar baseline characteristics : age (63 ± 17 vs 63 ± 12), Apache II (18 ± 6 vs 18 ± 7), SAPS 3 (66 ± 12 vs 61 ± 15), prealbumin at admission (11 mg/dl ± 10 vs 9 ± 6). The variable results are shown in Tables 84 and 85 . Conclusions: The use of a fish oil based emulsion in PN had no effect on new infections, insulin requirements, hospital length of stay and hospital mortality when compared with MCT/LCT based emulsion in ICU patients with Apache II score > 17. Bilirubin concentrations and ICU length of stay were lower in the MCT/LCT group. There is also a non-significant trend toward less ventilatordays per patient in the MCT/LCT group. More strong evidence is required before giving a recommendation on lipid emulsions in critically ill patients requiring PN. Objectives: The ICU admission of patients over 80 years of age has been questioned because of the high mortality and low life expectancy of these patients. However, with the growing increase of the life expectancy of the population together with the improvement of diagnostic and therapeutic techniques, more and more, age is not a limiting factor for ICU admission. Our goal is to analyze the short and long term the morbidity and mortality of octogenarian patients admitted to the ICU, as well as functional status after ICU discharge. Materials and methods: Retrospective observational study in which all patients over 80 years old admitted to a polyvalent ICU of a tertiary hospital during the years 2012-2014 were included. Demographic variables, severity indices (APACHE II), initial lactate, mortality and length of stay were registered. Patients were followed during one year after ICU discharge. 6 months and one year mortality as well as the value of the Conclusions: The number of octogenarian patients admitted to ICUs has been increasing in recent years. Mortality in patients over 80 years of age admitted to our ICU is higher than the overall mortality of our ICU. However, it varies significantly depending on the diagnosis. The initial lactate and APACHE II are also prognostic in this group of patients. The mortality of octogenarians patients admitted to our ICU reaches the 50 % after one year of discharge, and those who survive cannot perform a normal daily activity. Outcomes Background: Acute variceal haemorrhage (AVH) presenting to Intensive Care Unit (ICU) is associated with significant mortality. [1] Objectives: To compare outcomes and factors associated with hospital mortality (HM) in patients admitted with AVH to a busy district general hospital ICU. Methods: A retrospective study of adult patients (N = 82) admitted to ICU with a primary admission diagnosis of AVH from 1993-2016 was performed by searching the electronic medical records database. We applied statistical analysis (Pearson chi-square) to assess the differences in outcomes for patients receiving different interventions. Results: The median age of our patient population was 56.3 years, 62 % were male, and there were 8 transfers to tertiary centres. The percentage HM for patients admitted to ICU with a variceal bleed was found to be 43 %, with mortality rising to 59 % if that patient was intubated and ventilated, and 92 % if that patient received inotropic support during their admission. Inotropic support (OR, 11.9; 95 % CI, 1.5 to 97.3; chi-square 7.9 P = 0.0048) and an APACHEII score above 40 (OR, 3.98; 95 % CI, 1.0-15.5; chi-square 4.4 P = 0.0459) were both significant independent predictors for mortality. Intubation and ventilation alone was not a significant mortality predictor. Conclusions: A patient presenting to ICU with an AVH is predicted to have a significantly worse outcome if they are commenced on inotropic support, with mortality rising to 92 % from 43 %. Intubation and ventilation alone was not a significant predictor of a worse outcome. This result should prompt a consideration of outcomes when starting inotropic support in a patient on ICU who presents with a variceal bleed. and five secondary hospitals in the capital city of Ulaanbaatar as well as nine secondary province hospitals were collected during a six month period in 2014/15. The study protocol was approved by the Ethics Committee of the Mongolian Medical University. Results: During the observation period, 2,032 patients (53.6 % male) with a median age of 49 years (interquartile range, 36-62 years) were admitted to the study ICUs. The ten most frequent ICU admission diagnoses were stroke (ischemic and hemorrhagic) (n = 354; 17.4 %), decompensated liver cirrhosis (n = 187; 9.2 %), acute or acute-onchronic heart failure (n = 182; 9 %), infection (n = 169; 8.3 %), trauma (n = 153; 7.5 %), traumatic brain injury (n = 145; 7.1 %), acute abdomen (n = 143; 7 %), pre-eclampsia/eclampsia (n = 117; 5.8 %), acute or acute-on-chronic renal failure (n = 80; 3.9 %) and postoperative care following elective and emergency surgery (n = 66; 3.2 %). 100 %, 31.7 % and 13 % of patients had access to mechanical ventilation, renal replacement therapy and invasive hemodynamic monitoring, respectively. ICU mortality was 23.5 % in the total population and 26.6 % when maternal cases were excluded. Multiple organ dysfunction syndrome (38.1 %), coma (36.6 %) and shock (15.6 %) were the three most common causes of death. The five ICU admission diagnoses with the highest case fatality rate were lung tuberculosis (51.9 %), traumatic brain injury (42.1 %), decompensated liver cirrhosis (33.7 %), stroke (31.9 %) and infection (30.8 %). The five ICU admission diagnoses causing most death cases were stroke (n = 113), decompensated liver cirrhosis (n = 63), traumatic brain injury (n = 61), infection (n = 52) and acute abdomen (n = 38). Conclusions: Critical illness in Mongolia affects younger patients than reported from high-income countries. ICU admission diagnoses are similar with a particularly high incidence of stroke and decompensated liver cirrhosis. Total ICU mortality is approximately 25 % with most ICU deaths caused by stroke, decompensated liver cirrhosis and traumatic brain injury. (OR = 2.00, 95 % CI = 1.46-2.76, P = 0.001) after adjusting to APACHE II score, vasopressor requirements, mechanical ventilation, and lactate levels. Conclusions: In this large series of critically ill patients, the presence of hypochloremia at ICU admission was an independent predictor of mortality. In contrast, hyperchloremia was not associated with increased mortality. Introduction: Continuous renal replacement therapy (CRRT) is commonly employed in ICU for patients with acute kidney injury and is associated with increased morbidity and mortality. However, renal outcomes at in the longer term are not widely described in the literature and have never been described in Ireland. Objectives: We analysed all patients admitted to our tertiary ICU who were commenced on CRRT over a 2 year period. Our primary aim was to calculate the mortality of this cohort and estimate the likelihood of survivors requiring long-term dialysis. Our secondary aim was to analyse the characteristics of those requiring long-term dialysis. Method: We conducted a retrospective cohort study of all patients requiring CRRT admitted to our ICU between 2013 and 2015. From the Clinical Information System, we analysed patient age, sex, diagnosis, illness severity scores, pre-CRRT creatinine levels, AKIN scores, length of CRRT and ICU admission. Survivors with new onset renal failure were followed up at 6 and 12 months to determine survival, dialysis dependency and serum creatinine level. This study received ethical committee waiver. Results: Of 686 ICU admissions, 202 patients (29.4 %) received CRRT. 50 % of these patients died prior to hospital discharge. 85 patients had new onset renal failure and survived to hospital discharge. The 5 patients dialysed for toxin removal were excluded from further analysis. 11 patients (13.8 %) required ongoing CRRT at hospital discharge whereas 69 patients (86.2 %) did not. Of those requiring ongoing CRRT, 1 patient had died at 6 months, 2 further patients had died at 12 months, and 1 patient was lost to follow-up. Of the remaining 7 patients, 4 (57 %) were dialysis dependent at 12 months. Of the 69 patients who did not require RRT at hospital discharge, 12 had died at 6 months and 3 further patients had died at 12 month follow-up. 4 patients were lost to follow-up and a further 5 patients did not have blood results available. Of the remaining 45 patients, 100 % were not dialysis dependent at 12 months. Conclusions: The mortality rate for patients admitted to ICU and commenced on CRRT in our cohort was consistent with that in the international literature. The likelihood of requiring long-term dialysis for survivors was similarly consistent. This novel information is of value in the management and prognostication of patients requiring CRRT in an Irish ICU setting. group S (P < 0.05). The median length of ICU stay was significantly longer in group SHS than in group S (P < 0.05). The occurrence of pneumonia in this population was also similar between the three groups of patients. there were no significant differences between the groups with regard to postoperative side effects. Conclusions: We found that SHS was associated with increased length of ICU stay compared to nonsmokers among scoliosis surgery patient. We concluded that it is important to avoid SHS before at ICU admission when possible. Differences in critical care and hospital length of stay between two cohorts of patients admitted with traumatic brain injury (TBI) and hypoxic brain injury (HBI) Analysis of care provision for these patients identified a clear structure and pathway for patients with TBI, supported by a multiprofessional team with structured, frequent patient reviews. In comparison, patients with HBI had no clear pathway or review frequency, although were supported by several therapeutic disciplines. Conclusion: It is clear that patients experiencing severe Brain Injury (regardless of type) do experience prolonged hospital stays and uncertain recovery pathways. Although larger in number, patients with HBI tend to occupy both Critical Care and Ward Beds for lengthier periods than patients with TBI. This may lead to delays in accessing appropriate ongoing care and/or inappropriate use of resources in specialised hospital beds. Further work is needed to unpick the layers of consistency in service provision for both groups.  
