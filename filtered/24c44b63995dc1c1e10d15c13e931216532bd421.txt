24c44b63995dc1c1e10d15c13e931216532bd421
EFFECTS OF A FLUID CHALLENGE ON REGIONAL TISSUE PERFUSION IN ICU PATIENTS DOPAMINE AND NOREPINEPHRINE FOR THE TREATMENT OF SHOCK: A PER PROTOCOL ANALYSIS MICROCIRCULATION DENSITY AND PERFUSION IN A LOWER BODY NEGA- TIVE PRESSURE (LBNP) MODEL OF CENTRAL HYPOVOLEMIA THE EFFECTS OF NON-LEUKOREDUCED RED BLOOD CELL TRANSFUSIONS ON MICROCIRCULATION IN MIXED SURGICAL PATIENTS 0005 NITROGLYCERIN FAILS TO RECRUIT THE MICROCIRCULATION OF THE INTESTINAL VILLI IN SHEEP ENDOTOXEMIA
E  Klijn M  Van Velzen C  Ince J  Bakker J  Van Bommel D  De Backer P  Biston J  Devriendt C  Madl D  Chochrad C  Aldecoa J.-L  Vincent D M J Milstein S A Bartels R  Bezemer F J Wallis De Vries B  Ayhan K  Yürük S  Koene A  Sahin U  Aypar V S Kanoore Edul G  Ferrara M O Pozo G  Murias E  Martins C  Canullán H S Canales E  Estenssoro A  Dubin 

Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Brugmann University Hospital Medical University of Vienna Rio Hortega University Hospital Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Brugmann University Hospital Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care Intensive Care 
INTRODUCTION. Fluid therapy is one of the cornerstones of hemodynamic management in critically ill patients. Although the aim of fluid therapy is to improve regional tissue perfusion, its adequacy is judged by the effect on cardiac stroke volume (SV). It is as yet unknown whether an increase in SV through a fluid challenge (FC) can also improve common parameters of regional perfusion. And if so, whether it is possible to predict the effect of a FC on regional perfusion parameters by performing a passive leg raising. METHODS. Critically ill patients, receiving invasive hemodynamic monitoring and requiring fluid therapy, were eligible for enrollment. They underwent a 30°passive leg raising (PLR) followed by a fluid challenge of 250 ml colloids. During the PLR and FC, stroke volume and cardiac output (CO) were measured as well as sublingual microcirculatory perfusion (sidestream dark field imaging), peripheral flow index (photoplethysmography of the finger) and tissue blood flow of the skin (laser Doppler flowmetry). RESULTS. 35 patients were included in our study, of which 15 (43%) were fluid responsive (FR; more than 10% increase in SV). Baseline SV and CO were significantly lower in responders than in non responders, as well as the sublingual perfusion. In the responsive patients sublingual vessel density and skin tissue blood flow increased following FC (Fig. 1) , whereas PFI on the finger remained low. During the PLR no changes in any parameter were observed. Fluid responsiveness was best predicted by SV response to PLR (AUC 0.88 ± 0.08, p \ 0.01) and baseline SV (AUC 0.79 ± 0.08, p \ 0.01), followed by baseline sublingual vessel density (AUC 0.76 ± 0.09, p \ 0.05). It was not possible to predict the response effect of FC on regional perfusion by performing a PLR. CONCLUSIONS. In septic patients, parameters of regional perfusion are not related to systemic hemodynamic parameters and do not respond uniformly to fluid administration. In fact, it is questionable whether regional perfusion does benefit from fluid therapy at all following initial resuscitation. As such, the PLR has no value in optimizing regional perfusion. INTRODUCTION. We recently demonstrated that, compared to norepinephrine, dopamine was associated with a non significant increase in 28 day mortality ]) (1). However, arrhythmia resulted in discontinuation of the study drug in some patients, which was converted to open label norepinephrine in all cases. We conducted a per-protocol analysis limited to patients in whom the study drug was not discontinued. OBJECTIVES. To evaluate in a per protocol analysis the impact on outcome of dopamine and norepinephrine for the treatment of shock. METHODS. In a prospective, randomized study (NCT00314704), 858 patients received dopamine and 821 norepinephrine, according to a protocol described in detail elsewhere (1). Briefly, patients were randomized within 4 h max of the onset of shock to receive either dopamine (max dose 20 mcg/kg min) or norepinephrine (max dose 0.19 mcg/kg min). When the desired mean arterial pressure (MAP) could not be reached with these max doses, an open label norepinephrine was added. In the presence of problematic arrhythmias, physicians were allowed to discontinue study drug and to replace it by any vasopressor agent while blinding of initial allocation was maintained. According to our predefined analytical plan, we analyzed patients in whom study drug was not discontinued. Kaplan-Meier curves for estimated survival were compared using a log-rank test. RESULTS. The study drug was discontinued in 65 of the 1,679 patients enrolled, leaving 1,614 patients in the per-protocol analysis. Discontinuation occurred more frequently in dopamine than in norepinephrine-treated patients (52 vs. 13 patients, p \ 0.05), so that 806 patients in the dopamine group and 808 patients in the norepinephrine group were exposed to study drug during the entire shock episode. Kaplan-Meier curves for estimated survival showed a increased mortality rate in dopamine treated patients (p = 0.031, Fig. 1 ). Kaplan-Meier curves for 28 day survival CONCLUSIONS. In patients effectively exposed to dopamine or norepinephrine during the entire shock period, dopamine was associated with an increased mortality rate. REFERENCE(S). (1) De Backer et al. Comparison of dopamine and norepinephrine in the treatment of shock NEJM 362:779-789;2010 AIMS. Hypovolemia and hemorrhagic shock are common life threatening complications and early reliable detection would be a great advantage for on-time corrective therapeutic interventions. The aim of this study was to investigate the effects of imminent hypovolemia on sublingual microcirculation perfusion and vessel density during a lower body negative pressure (LBNP) model of progressive central hypovolemia. AIMS. The impact of the storage process on oxygen-carrying properties of red blood cells and the efficacy of red blood cell transfusions (BTX) concerning tissue oxygenation remain an issue of debate in transfusion medicine. Storage time and leukocyte content probably interact since longer storage duration would be expected to cause greater accumulation of leukocytederived cytokines and red blood cell injury. The aim of this study was to investigate the effects of storage and efficacy of fresh (stored for less than 1 week) versus aged (stored for more than 3 weeks) non-leukoreduced BTX on sublingual microvascular density and microvascular flow in mixed surgical patients. METHODS. 18 surgical patients were included in this study. Patients were randomly assigned into two groups as patients receiving fresh BTX (Group A) and patients receiving aged BTX (Group B). Sublingual microcirculatory functional capillary density (FCD) and microvascular flow index (MFI) were assessed using orthogonal polarization spectral (OPS) imaging. Measurements and collection of blood samples were performed after induction of general anesthesia, before BTX and 30 min after the BTX ended. (Fig. 1) . BTX increased FCD in group A, while FCD remained unaffected in group B (Fig. 2) . Changes in MFI following BTX in both groups are depicted in Fig. 3 . RESULTS. In both groups BTX caused an increase in systemic hemoglobin concentration Figures Fresh non-leukoreduced BTX in surgical patients were effective in improving microcirculatory perfusion by elevating the number of perfused microvessels. However, stored BTX did not have the capacity to maintain effective microcirculatory function. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9 INTRODUCTION. Hypoperfusion of intestinal villi still persists after fluid resuscitation of endotoxemic shock (1). To show that nitroglycerin improves the microcirculation of the villi. METHODS. Twenty sheep were anesthetized and mechanically ventilated. Endotoxemic shock was produced by the infusion of 5 lg/kg of endotoxin followed by 4 lg/kg/h for 150 0 . After 60 0 of shock, hydroxyethyl starch resuscitation was given to normalize oxygen transport, and sheep were randomized to control (n = 10) or nitroglycerin (n = 10) groups. Nitroglycerin was infused at a rate of 0.2 lg/kg/min during 90 0 . Mean arterial blood pressure (MAP), cardiac output (CO), intestinal blood flow (Q gut ), intramucosal-arterial PCO 2 (DPCO 2 ), and lactate were measured at baseline (0 0 ), during shock and after resuscitation. The microcirculation was evaluated by sidestream darkfield (SDF) imaging. Villi perfused capillary density (PCD) and microvascular flow index (MFI) were calculated. RESULTS. Hemodynamic and perfusion variables were similarly compromised during shock in both groups. Hyperlactatemia, intramucosal acidosis and villi hypoperfusion that developed during shock were not affected by the resuscitation with nitroglycerin. INTRODUCTION. Microcirculatory failure may be involved in the development of sepsisrelated acute kidney injury. OBJECTIVES. We conducted this study to determine the role of initial renal hypoperfusion in the endotoxemia-induced renal microcirculatory failure. METHODS. 24 Wistar rats were randomized in 4 groups: sham group; LPS group; LPS group with early fluid resuscitation preventing drop of renal blood flow (EARLY group); LPS group with a delayed (i.e. 2 h) fluid resuscitation (LATE group). Cortical microvascular blood flow was measured using speckle laser imaging techniques with assessment of microvascular blood flow distribution. Renal function was assessed with creatinine clearance. Serum levels of IL-6, IL-10 and TNF-a were measured. RESULTS. LPS infusion resulted in 80% drop of renal blood flow with marked fall of cortical microcirculatory blood flow. Fluid resuscitation could only partially restored microcirculatory blood flow in the LATE and EARLY group despite preservation of renal blood flow and increase aortic blood flow in the later group. Microvascular blood flow heterogeneity with a left shift on histograms persisted in both resuscitated groups (Fig. 1) . All rats in the control group were anuric. Fluid resuscitation in both the LATE and EARLY groups partially prevented decrease of creatinine clearance which still remained lower than the sham-operated group. Serum cytokines levels decreased in the resuscitated groups with no difference between the EARLY and LATE group. Cortical microcirculatory blood flow distribution CONCLUSIONS. Our study shows that endotoxaemia induces intrarenal alterations of the cortical microcirculation and oxygenation which appear to be poorly dependant on the macrohemodynamics. This may explain why renal failure yet progresses after correction of shock due to intrarenal microvascular oxygen supply heterogeneity. GRANT ACKNOWLEDGMENT. M. Legrand was partially supported by a grant from the French minister of foreign affairs (EGIDE-LAVOISIER). INTRODUCTION. Sepsis is the leading cause of acute kidney injury (AKI) in intensive care units but debate remains concerning its prognosis. To determine whether AKI is an independent factor of prognosis related or not to the severity of shock. METHODS. This multi-centre study was approved by the local Committee (# CCPPRB 2061) and involved patients from four medical-surgical Intensive Care Units in Paris, France. Patients with criteria of severe sepsis or septic shock (ACCP/SCCM consensus conference) (1) having at least two organ failures defined by the SOFA score were included between 01/2004 and 1/2006. After excluding patients with chronic renal failure (n = 23) 3 groups were identified based on AKIN and SOFA renal scores: (1) patients with no early (within 48 h) AKI (serum creatinine B 110 lmol/L; i.e. SOFA renal 0), (2) patients with mild AKI (serum creatinine [110 lmol/ L and B 300 lmol/L; i.e. SOFA renal 1, 2) and (3) patients with severe AKI (serum creatinine [ 300 lmol/L or urine output \ 500 ml/day or requiring renal replacement therapy; i.e. SOFA renal 3, 4). To assess the role of shock in the development of early AKI patients were stratified on the vasopressor dependency index (2) to treat cardiovascular failure. This index was calculated as the ratio of catecholamine index to the MAP. The catecholamine index was calculated as: (dopamine dose 9 1) + (dobutamine dose 9 1) + (adrenaline dose 9 100) + (noradrenaline dose 9 100) + (phenylephrine dose 9 100). A multivariate analysis with a competitive risk model was used for mortality risk. p \ 0.05 was considered as statistically significant. RESULTS. 43 had no AKI, and 132 had AKI, 73 with mild AKI and 59 with severe AKI. During the first 48 h, 29 patients had severe sepsis and 146 were in shock. Severe early AKI patients had a significantly higher rate of mortality at day 28 (42%) compared to patients with mild AKI (23%) or no AKI (11%, p \ 0.05). In multivariate analysis using a competitive risk model, severe AKI was found to be an independent factor of mortality after adjusting for age, gender, presence of diabetes or cancer, and the SOFA score with exclusion of the renal item ], p = 0.005). The severity of cardiovascular failure (based on vasopressor dependency index) did not differ between groups of AKI. Only early severe sepsis-related AKI appears to be an independent factor of mortality as part of multiple organ failure syndrome. Furthermore, occurrence of AKI does not seem to be driven by the severity of cardiovascular failure. INTRODUCTION. The optimal dialysis dose in patients with acute kidney injury (AKI) is unknown. Whereas, Schiffl et al. previously suggested that daily dialysis should be provided, the recent VA/NIH Acute Renal Failure Trial Network (ATN) concluded that intensive renal support in ICU patients did not improve the outcome (1, 2). Despite differences in the mean delivered Kt/V urea per session, the delivered dialysis dose per week in the trice weekly group of ATN study were comparable with those of Schiffl daily dialysis group. These results provide evidence of the importance of the weekly dose of dialysis. To test the efficiency of on line adjustments of dialysis parameters in order to decrease the number of dialysis sessions in patients with septic shock or severe sepsis and AKI by targeting a Kt/V C 1.2 per session. All patients (pts) with AKI requiring renal support and hemodynamically stable were prospectively enrolled during a 18 months period. Each session was performed thru a triple lumen catheter (12 Fr 20 cm length, medial and proximal blood flow rate respectively 285 and 305 ml/ min, Arrow USA) with an AK 200 hemodialysis monitor (Gambro Sweden) equipped with a Diascan module for automatic measurement of ionic dialysance. Dialysate flow was set at 500 ml/ min, blood pump speed and duration of the session being adjusted on line to reach the targeted Kt/V. Forty pts of 69 year-old (median, IQR: 58.5-81) with a SAPS II of 65 (50-70) were included; 32 of them requiring vasopressor and 28 mechanical ventilation. ICU length of stay was 15 days (5-27.5), hospital mortality: 57.5%. Among the 206 dialysis delivered, 178 sessions were analyzed. Management of 178 renal support sessions Session/pt Duration (min) Blood flow (ml/min) Pre-dial. Urea Post-dial Urea Urea reduction ratio Kt/V Median: 3 250 243 25.3 10.2 0.59 1.13 IQR: 2-6 240-300 224-265 19.6-33.1 7-14 0.5-0.68 0.84-1.27 The targeted Kt/V was obtained in 43% of the dialysis sessions, in which median duration were increased at 390 min (277-303) and blood flow were increased at 260 ml/min (249-270). An urea reduction ratio of more than 0.65 occurred in 36% of the cases. During these sessions, catecholamine infusion rate needed to be increased 42 times, volume expansion was performed 35 times and catheter dysfunction was reported 37 times Despite online management of dialysis sessions and increment of duration, the main factor (AUC: 0.718-95% CI: 0.633-0.797), and blood flow, the targeted Kt/V was obtained in less than 50% of the sessions. A procedure improvement such as dialysate flow rate increment, should be implemented prior to the reduction of weekly sessions. A Kt/V of at least 1.2 per session is difficult to obtain. To avoid inadequate dialysis, before improvement of our dialysis management, daily dialysis remains indicated. ). (1) Schiffl et al. N Engl J Med 2002;346:305-10 (2) The VA/NIH acute Renal Failure Trial Network. N Engl J Med 2008;359:7-20. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9 INTRODUCTION. After cardiopulmonary bypass, acute kidney injury (AKI), is estimated to occur in 15% of patients with normal pre-operative renal function. Even mild peri-operative AKI has been independently associated with increased mortality (1). Cardiopulmonary bypass has been shown to induce oxidative stress, leucocyte and endothelial activation and release of inflammatory mediators. Such inflammatory states have been associated with AKI in animal models. HMG-CoA reductase inhibitors (statins) have been shown to have antioxidant and anti-inflammatory activity and their use has been associated with improved outcomes after cardiac surgery in small studies (2). To assess the effect of peri-operative initiation or continuation of statin therapy (Atorvastatin 40 mg once daily for 4 days) on post-operative AKI in the first 5 days after surgery. We conducted prospective, double blinded, randomized, placebo-controlled trial of 100 patients undergoing cardiopulmonary bypass with a higher risk of peri-operative AKI. Randomization was stratified by presence or absence of pre-operative statin therapy and data was analyzed on an intention to treat basis. Primary outcome was defined by the RIFLE consensus classification of AKI (RIFLE R or greater). Additionally, serum and urine neutrophil gelatinase-associated lipocalin (NGAL), a biomarker of renal tubular injury, was assessed as a secondary outcome (3). . Study groups were well matched. Median maximal rise in creatinine after surgery was 28 lmol/L with Atorvastatin and 29.5 lmol/L with Placebo (p = 0.62), with RIFLE R or greater occurring in 26 and 32% of patients respectively (p = 0.65). Post-operatively urine and serum NGAL rose significantly, but these changes were similar in treatment group and placebo. Treatment was well tolerated and reports of adverse event were similar between groups. CONCLUSIONS. In our study peri-operative statin use was not associated with a reduced incidence of subsequent AKI or smaller post-operative elevations in NGAL. This study was too small examine any wider potential benefits of statin therapy. ). (1) Zanardo G, Michielon P, Paccagnella A, et al. Acute renal failure in the patient undergoing cardiac operation. Prevalence, mortality rate, and main risk factors. J Thorac Cardiovasc Surg. 1994;107:1489-95. (2) Kulik A, Ruel M. Statins and coronary artery bypass graft surgery: preoperative and postoperative efficacy and safety. Expert Opin Drug Saf. 2009;8:559-71. (3) Haase M, Bellomo R, Devarajan P, Schlattmann P, Haase-Fielitz A; NGAL Meta-analysis Investigator Group. Accuracy of neutrophil gelatinaseassociated lipocalin (NGAL) in diagnosis and prognosis in acute kidney injury: a systematic review and meta-analysis. Am J Kidney Alkaline phosphatase (AP) is an endogenous detoxifying enzyme that is depleted in the kidney during an ischemic or inflammatory insult. Administration of AP improves outcomes in animal models and decreases urinary excretion of markers of tubular damage in a previous sepsis trial. To evaluate whether AP treatment improves renal function in sepsis patients with acute kidney injury (AKI). Thirty-six sepsis patients (27 m/9f, age 66 ± 13 years) with evidence for kidney injury (AKIN stage 1) were included in a double-blind, randomized, placebo-controlled study on the safety and efficacy of AP. Patients on dialysis were excluded and during the study renal replacement therapy (RRT) was started according to the Acute Dialysis Quality Initiative (ADQI) criteria. AP was administered intravenously as a bolus injection of 67.5 U/kg followed by continuous infusion of 132.5 U/kg for 48 h and followed up for 28 days. RESULTS. Progress in renal parameters was the primary endpoint, namely combined creatinine clearance, requirement and duration of RRT, and serum creatinine. The results confirmed that AP treatment is well-tolerated by patients with sepsis and AKI. Creatinine clearance was restored to normal in the AP group within 7 days and remained impaired in the placebo group (p = 0.02) and this improvement was sustained during the follow-up period (p \ 0.05). Fewer patients in the AP group required RRT (19 vs. 36%, p = 0.29) and the relative duration of RRT was shorter (12 vs. 34% total time in study, p = 0.04). Overall benefit of AP treatment on renal endpoints was clinically important (p = 0.02). In addition, AP treatment reduced mean length of ICU stay (10.9 vs. 24.5 days, p = 0.02). CONCLUSIONS. Alkaline phosphatase treatment improves renal function in sepsis patients with AKI. Advances in sepsis therapies: 0011-0015 METHODS. For the present investigation, 8 healthy male volunteers with a mean age of 29 ± 3.6 years were recruited for a cardiovascular screening exercise stress test prior to inclusion for the study. During the LBNP protocol, the subjects were exposed to sequential increasing negative pressures of -20, -40, and -60 mmHg while resting in a supine position with their legs sealed in the LBNP chamber at the level of the iliac crest. In addition to continuous registration of cardiac output (CO) and mean arterial pressure (MAP), sublingual perfused vessel density (PVD) (1) and microvascular flow indices (MFI) (2) were measured using sidestream dark-field (SDF) imaging before (T0), during (T1; -60 mmHg), and after (T2) LBNP. RESULTS. There were no significant differences in mean CO and MAP in our subjects. INTRODUCTION. Fever management remains controversial in sepsis. Control of thermal balance might improve vascular tone but fever could play a role in host defence. OBJECTIVES. The aim of this multicentre randomised controlled trial was to determine primarily whether external cooling might accelerate the weaning of vasopressors in patients with septic shock. Patients with septic shock treated with epi/norepinephrine infusion and fever over 38.3°C were enrolled in 7 centres when also requiring mechanical ventilation and sedation. Patients received external cooling to reach normothermia (36.5-37°C) during 48 h (n = 101) or had fever respected (n = 99). A goal of 65 mmHg for mean arterial pressure was used in the two groups. A similar algorithm was used for weaning of vasopressors. The main end point was the number of patients achieving a 50% decrease in the initial dose of vasopressor in the two groups. Shock reversal was defined by vasopressor withdrawal for at least 24 h. At inclusion the two groups (cooling/respect of fever) were similar for age 61 ± 14 versus 59 ± 15 years, SAPS III (68 ± 12 vs. 70 ± 13), SOFA score (11 ± 3 vs. 11 ± 3), and body core temperature (39.0 ± 0.6 vs. 39.0 ± 0.6°C). A similar number of patients received steroids and a PC before enrolment. Body temperature became significantly lower in the cooling group within the 48 h of treatment: 36.8 ± 0.7 vs. 38.4 ± 1.1 at H12 and 36.8 ± 0.5 vs. 37.6 ± 1.17°C at H48 (p \ 0.001). The decrease in vasopressor was more rapid in the cooling group (Fig. 1 ). Shock reversal was 84 vs. 73%, p = 0.07 and in-Hospital mortality was 45 vs. 48% in the cooling and the respect of fever groups respectively. CONCLUSIONS. These preliminary results show that treating fever using external cooling in septic shock patients allows a more rapid decrease in the dose of vasopressor without apparent adverse effect. GRANT ACKNOWLEDGMENT. APHP-SCR 06012. We set up to describe the antibiotic treatment regimens prescribed for patients with severe sepsis in Spanish ICUs and to analyze the potential therapeutic benefit of combination therapy. METHODS. Edusepsis subanalysis, including all patients with severe sepsis admitted to the 77 participating ICUs during 8 months, in three periods between November 2005 and June 2007. There was analyzed the time between the presentation of sepsis and the initiation of antibiotic treatment and empirical antibiotic used in terms of focus and origin of sepsis (community/nosocomial). We also studied the combination therapy compared to monotherapy, assessing the impact on outcomes of combination therapy in particular. The results are presented as frequencies (percentage) or mean ± standard deviation. RESULTS. There were included 2,782 patients with severe sepsis (age 62. CONCLUSIONS. Combination therapy is not associated with a better outcome in this large cohort of patients with severe sepsis. Nevertheless, there is room for improvement since 61% of patients did not receive antibiotic therapy within the first 3 h from admission, as recommended by the SSC. INTRODUCTION. Tracheostomies are increasingly common in hospital wards and can lead to significant patient harm. This is partly due to bed pressures in UK critical care units and the increasing use of percutaneous and surgical tracheostomies for critical care patients. Commonly, hospital wards lack the infrastructure to care for tracheostomies safely. OBJECTIVES. Analyse tracheostomy-related critical incidents reported in the UK over a 2 year period. We wished to identify themes and make recommendations to improve patient safety. METHODS. The search was conducted from 1st October 2005 to 30th September 2007 and was conducted in February 2008 to allow time for incidents to be submitted. The selected incidents were then incorporated into an Access database (Microsoft Office 2007) and the description of each incident was read and reviewed. We analysed 968 tracheostomy-related critical incidents reported to the UK National Patient Safety Agency over a 2 year period, identified by key letter searches. We categorized the records to identify recurring themes and then performed root cause analysis where possible. RESULTS. We identified 1,541 incidents from the NPSA incident database originating from hospital wards during the study period having the defined letter sequences. Of these incidents, 968 were associated with tracheostomies; 453 directly affecting patients with the remaining 515 not directly affecting individual patients. In the 453 incidents where patients were directly affected 338 (75%) were associated with some identifiable patient harm of which 83 (18%) were associated with more than temporary harm. In 29 incidents (6%) some intervention was required to maintain life and in 15 cases the incident may have contributed to the patient's death. There were 15 cardiac arrests and 26 respiratory arrests described in these incidents. Of the 453 incidents, 126 involved equipment and there were 276 blocked or displaced tracheostomy tubes described. Note: An individual incident could be classified in multiple fields CONCLUSIONS. We were able to identify themes in incident reports associated with tracheostomies and identify areas where care could be improved to reduce risks to patients. There were a number of recurrent problems that contributed to incident evolution or severity that would be potentially avoidable. These include: INTRODUCTION. The study of computerized thoracic tomography patterns can be of great help in the diagnosis of the causes of acute respiratory failure in the ICU patients. We hypothesized that the consecutive analysis of a series of thoracic CTs will contribute to the management of these critically ill patients. OBJECTIVES. To study, over a three-month period, the thoracic CTs performed in the Adult ICU in the Albert Einstein Hospital in São Paulo, Brazil. METHODS. From May 1st to August 31st, 2009, all the thoracic CTs were analyzed by two radiologists from the Albert Einstein Hospital staff according to a pre-established protocol: (1) presence of parenchymal consolidations; (2) ground-glass opacities; (3) septal thickening; (4) atelectasis (5) pleural effusions; (6) pneumothorax (7) pneumomediastinum; (8) subcutaneous emphysema; (9) presence of nodules; (10) presence of masses; (11) presence of cysts; (12) emphysema; (13) bronchial thickening. RESULTS. Hundred and sixteen thoracic CTs were performed and analyzed over the study period, from 64 (55.1%) males and 52 (44.9%) females. The mean age of the patients was 65.30 ± 19.03 years. Thoracic CT analysis revealed: (1) parenchyma consolidations: 59 (50.8%); (2) ground-glass opacities: 72 (62%); (3) septal thickening: 41 (35.2%); (4) atelectasis: 78 (67.2%); (5) pleural effusions: 94 (81%) (6) presence of pneumothorax: 10 (8.6%); (7) pneumomediastinum: 3 (2.5%); (8) subcutaneous emphysema: 11 (9.4%); (9) nodules: 30 (25.8%); (10) presence of masses: 2 (1.7%); (11) presence of cysts: 2 (1.7%); (12) emphysema: 21 (18.1%); (13) bronchial thickening: 51 (43.9%). CONCLUSIONS. Thoracic CT is a useful tool for a detailed analysis of the lung parenchyma, specially in the detection of ground-glass opacities, consolidations and atelectasis, improving the diagnostic possibilities and management of acute respiratory failure.  S. Wolf 1,2 , A. Rieß 3 , J.F. Landscheidt 2 , C.B. Lumenta 2 , L. Schürer 2 , P. Friederich 3 1 Charite Campus Virchow, Department of Neurosurgery, Berlin, Germany, 2 Klinikum Bogenhausen, Neurosurgery, Muenchen, Germany, 3 Klinikum Bogenhausen, Anesthesiology, Muenchen, Germany INTRODUCTION. Extravascular lung water index (EVLWI) may present a valuable marker for the severity and treatment of acute lung injury and acute respiratory distress syndrome. Measured by single indicator transpulmonary thermodilution and indexed to predicted body weight, a threshold of 10 ml/kg is currently regarded as the upper limit of normality. However, so far only critically ill patients were studied and data from subjects with normal cardiovascular function is lacking. OBJECTIVES. To prospectively investigate EVLWI in patients without cardiopulmonary compromise. METHODS. Patients requiring elective brain tumor surgery were equipped with a transpulmonary thermodilution device (PiCCO 7.0, Pulsion Medical Systems AG, Munich, Germany). Triplicate EVLWI measurements were performed after induction of anesthesia (time point 1), before (time point 2), during (time points 3 and 4) and after surgery (time point 5) as well as after extubation (time point 6) and before discharge from the neurosurgical ICU (time point 7) . Data were recorded electronically and investigated with a random effect model to cope for multiple measurements per individual. RESULTS. 641 valid measurements were performed in 101 patients (60 female/41 male, Fig. 1 ). No patient showed clinical signs of over-hydration or cardiopulmonary failure and all were discharged regularly from the ICU on postoperative day one. Indexed to predicted body weight, females had a mean EVLWI of 9.1 (SD 3.0, range 5-23) ml/kg and males had a mean EVLWI of 8.0 (SD 1.9, range 4-19) ml/kg (p \ 0.001). 26% of the measurements in females and 11% in males exceeded the threshold of 10 ml/kg. No significant differences were between the different time points of measurement (p = 0.28) or during anesthesia and after extubation (p = 0.86). CONCLUSIONS. Measured with single indicator transpulmonary thermodilution and indexed to predicted body weight, EVLWI frequently shows values above the previously established normality threshold of 10 ml/kg in patients without cardiopulmonary compromise. Females present significantly higher values than male patients. As we are not aware of any abnormal hemodynamic profile for brain tumor patients, we propose our findings as a close approximation to normal values for EVLWI. INTRODUCTION. Cardiovascular dysfunction is though to be common during weaning from mechanical ventilation. However, its precise incidence is unknown in this setting. In addition, the respective impact of systolic and diastolic dysfunctions on the weaning process have not been studied. OBJECTIVES AND METHODS. This is an ancillary study of the ''BNP for the Management of Weaning'' clinical trial. Patients were ventilated with an automated weaning system as soon as they tolerated pressure support ventilation with an FiO 2 B 50%, a PEEP level B 8 cmH 2 O, and a total inspiratory pressure B 30 cmH 2 O. A total of 67 patients underwent transthoracic echocardiography (TTE) at Day1 (initiation of weaning). In addition, serial TTE were performed in a subgroup of 31 patients to explore left ventricle filling pressures variations during daily weaning trials (low-pressure support with zero end-expiratory pressure). Filling pressures were assessed using the ratio of early transmitral peak velocity (E) over early diastolic mitral annular velocity (e 0 ). RESULTS. Day 1 TTE revealed a systolic (ejection fraction \ 50%) or diastolic dysfunction (defined as e 0 \ 8.5 cm/s) in half of patients. Treatment during weaning included diuretics (84% of patients), vasodilators (45%) , dobutamine (28%), amiodarone (28%) and betablockers (3%). Diastolic dysfunction was more prevalent in patients with difficult or prolonged weaning as compared to those with simple weaning (weaning duration \ 3 days). Serial TTE revealed a greater increase in E/e 0 ratio during failed weaning trials as compared to successful trials. CONCLUSIONS. When treated, systolic dysfunction does not seem to jeopardize weaning. In contrast, diastolic dysfunction is associated with difficult/prolonged weaning. During failed weaning trials, there is a more pronounced increase in filling pressures as compared to successful trials. INTRODUCTION. Monitoring and determination of fluid responsiveness in a critically ill patient who presents with circulatory compromise and septic shock is essential but often, challenging and difficult. Continuous haemodynamic monitoring using arterial pulse contour analysis is less invasive compared to the thermodilution method using the pulmonary artery catheter. OBJECTIVES. We aim to assess the utility of stroke volume variation as measured by the FloTrac Ò device (Edwards Lifesciences, Irwine, USA) as a predictor of fluid responsiveness in patients with septic shock. We studied 11 mechanically ventilated adult patients with septic shock in the medical intensive care unit (ICU) of a university hospital. Haemodynamic parameters including stroke volume variation (SVV) and stroke volume (SV) were recorded using radial arterial pulse contour analysis (FloTrac Ò pressure sensor versions 1.10 and 1.14) before and after a crystalloid fluid challenge. Fluid responsiveness was defined as an increase of C 10% in SV after the fluid challenge. RESULTS. The sensitivity, specificity, positive predictive value and negative predictive value of a SVV of C 10% to predict fluid responsiveness were respectively 50.0, 33.3, 33.3 and 50.0%. The area under the receiver operator characteristic curve for the prediction of fluid responsiveness using SVV (pre) was only 0.583 . Similarly, there was no correlation between SVV (pre) and the absolute change in stroke volume (Spearman's rho -0.192, p = 0.60). CONCLUSIONS. Our study's findings call for caution with the use of SVV measured via versions 1.10 and 1.14 of the FloTrac Ò device to predict fluid responsiveness in patients with septic shock. Further studies are now required to assess if recent software upgrades may provide more accurate SVV measurements in severely septic patients. OBJECTIVE. Our objective was to assess the recent literature with respect to CCO monitor validation. In particular we wished to determine if study protocols reflected the dimension of time. We looked at four different CCO monitors: Vigileo TM , PiCCO TM , PulseCo TM , and Oesophageal Doppler (ODM). Human validation studies of CCO monitors were sought through the Ovid interface, generating over 3,000 hits. Manufacturers' websites were also searched. Case reports were excluded, as were abstract-only publications, letters, and studies over 10 years old. Ultimately, 99 studies were included. A full reference list and search strategy is available from the authors. A recent article provided suggested criteria for assessment of CCO monitors [1] : this was used to generate a proforma. To check for interobserver bias, a subselection of five studies was assessed by the three authors independently; no differences were found. The authors summarised the remaining studies individually. RESULTS. Results are summarised in Table 1 . W Rows do not add up because some studies evaluated more than one monitor Researchers have yet to address the necessity of validating CCO monitors with respect to their realtime functionality. While most studies give an assessment of bias based on essentially static measurements, fewer than half document sampling time or directional change reliability. Response time and response amplitude to a step change in cardiac output are important variables which may influence patient treatment; in the vast majority of studies, these have not been assessed. In this respect, all four monitors have yet to be validated. This study offers two perspectives: one, for clinicians to realise that the CCO monitor in their intensive care unit may not have been as extensively validated as they think; another, for researchers, to realise that work is still to be done.  INITIAL DISTRIBUTION VOLUME OF GLUCOSE RATHER THAN RIGHT VENTRICULAR END-DIASTOLIC VOLUME IS CORRELATED WITH CARDIAC OUTPUT FOLLOWING CARDIAC SURGERY J. Saito 1 , H. Ishihara 1 , E. Hashiba 2 , H. Okawa 1 , T. Tsubo 2 , K. Hirota 1 1 Hirosaki University Graduate School of Medicine, Anesthesiology, Hirosaki, Japan, 2 Hirosaki University Graduate School of Medicine, Division of Intensive Care, Hirosaki, Japan INTRODUCTION AND OBJECTIVES. Rational decision making for cardiovascular and fluid management in critically ill patients requires reliable assessment of cardiac preload. We have reported that initial distribution volume of glucose (IDVG) measures the central extracellular fluid volume and has potential as an alternative preload variable 1) . IDVG can be approximated rapidly and simply in any ICU using a conventional blood glucose analyzer 2) . Right ventricular end-diastolic volume (RVEDV) has been shown to be a better indicator of cardiac preload than cardiac filling pressure 3) . This study was intended to determine whether IDVG, RVEDV, pulmonary artery wedge pressure (PAWP) or central venous pressure (CVP) are correlated with cardiac output (CO) during the early postoperative days following cardiac surgery in the absence of apparent congestive heart failure. METHODS. Twenty-nine consecutive patients who underwent cardiac surgery such as coronary artery bypass grafting (either off-pump or on-pump: n = 6), valve surgery (n = 10) and aortic arch replacement (either hemi or total: n = 13) were studied. Patients associated with excess hyperglycemia ([ 14 mmol/L), arrhythmias or mechanical cardiovascular support were excluded from the study. A volumetric thermodilution pulmonary artery catheter for continuous monitoring of CO and RVEDV was placed in the operating room. Immediately after cardiovascular variables were recorded, IDVG was determined using the incremental plasma concentration at 3 min after administration of glucose (5 g) as described previously 2) . Three sets of measurements were performed; on admission to the ICU and daily at 10 a.m. on the first 2 postoperative days. The relationship between either volumetric or static variables and cardiac index (CI) was evaluated throughout the study period. A P value\0.05 was considered statistically significant. RESULTS. All but one patients required vasoactive drugs during study period. Indexed IDVG (IDVGI) had a moderate correlation with CI (r = 0.56, n = 87, p \ 0.001), even though indexed RVEDV (RVEDVI) had a slight correlation with CI (r = 0.29, n = 87, p = 0.007). A Linear correlation was also obtained between changes in IDVGI and those in CI (r = 0.47, n = 58, p \ 0.001). However, changes in RVEDVI had not a correlation with those in CI (r = 0.10, n = 58, p = 0.47). Neither PAWP nor CVP had a correlation with CI (r = -0.02, n = 65 and r = -0.06, n = 87, respectively). Although cardiac dysfunction has a significant impact on determining CO early after cardiac surgery, our results demonstrate that IDVG rather than RVEDV is correlated with CO. IDVG has potential as being an alternative indicator of cardiac preload following cardiac surgery. (SPV) are reliable predictors of fluid responsiveness in controlled mechanically ventilated patients [1] . PPV and SPV are calculated using an intra-arterial catheter. It is unknown whether an arterial pressure signal obtained with the Nexfin TM system [2] using only a finger cuff can be used to calculate PPV and SPV. OBJECTIVES. To validate PPV and SPV measured with a finger cuff. METHODS. After their arrival on the ICU, sedated and mechanically ventilated patients after Coronary Artery Bypass Graft surgery (CABG) were included. Intra arterial pressure (IAP) was measured using an arterial catheter inserted in the radial artery, and non-invasively, using the finger cuff of the Nexfin TM monitor (BMEYE, The Netherlands). We took the mean value of PPV and SVV in a 1-min time interval before and after the administration of a fluid challenge. Agreement of the PPV and SPV measured by the finger cuff and from the IAP signal were assessed using the method described by Bland and Altman. RESULTS. Nineteen patients were included and twenty-eight volume challenges were analyzed, resulting in 56 simultaneous measurements. PPV and SPV measured by the finger cuff correlated with PPV and SPV from IAP (r 2 = 0.92, P \ .0001 and r 2 = 0.93, P \ .0001, respectively), see Figure 1 . The mean bias was -0.95 and -0.22% for PPV and SPV respectively, and limits of agreement were -4.3 and 2.4% for PPV and -2.2 and 1.7% for SPV (see Figure 2 ). There was no correlation between the bias and the mean value of the two measurement methods. The correlation between changes in PPV and SPV measured by the two different methods was r 2 = 0.82 (p \ .0001) for PPV and r 2 = 0.83 (p \ .0001) for SPV. CONCLUSIONS. In ventilated ICU patients, PPV and SPV can be reliably calculated using the Nexfin TM monitor. REFERENCE(S). (1) Kramer, A., et al., Chest, 2004. 126(5) . (2) Eeftinck Schattenkerk, D.W., et al., Am J Hypertens, 2009. 22(4) . INTRODUCTION. The transpulmonary thermodilution (TPTD) technique with integrated pulse contour analysis (PiCCO Ò -system) enables continuous monitoring of cardiac index (CI) after calibration by TPTD [1] . This monitoring technique is applied in patients with lung failure who undergo prone positioning (PP) which has been shown to potentially improve pulmonary gas exchange [2] . OBJECTIVE. We sought to determine the influence of a modified PP (135°) on the accuracy of pulse contour derived CI (PCCI) without recalibration by TPTD. PATIENTS: After approval by our institutional review board and written informed consent by a legal surrogate we studied 16 critically ill patients (11#, 5$, age 20-71 years) who were mechanically ventilated due to acute lung injury following lung contusions or acute respiratory distress syndrome. METHODS. All patients were prone positioned and had received an extended haemodynamic monitoring (PiCCO Ò , Pulsion Medical Systems AG, Munich, Germany). Before turning from supine position (SP) to PP, CI was measured by TPTD (TPTDCI) and PCCI was calibrated. Ten minutes after positioning, PCCI was read from the monitor and then recalibrated by TPTD. After 8-10 h, PP was ended and measurements were performed analogously to prone positioning. Volume management between the respective time points remained unchanged. Linear regression analysis and Bland-Altman plots were used for statistical analysis. All data are given as mean ± standard deviation, range in brackets. RESULTS. The TPTDCI in SP was 3.29 ± 0.88 (1.50-4.51 ) l/min/m 2 . After proning, a PCCI of 3.51 ± 0.79 (2.15-4.63 ) l/min/m 2 and a TPTDCI of 3.56 ± 0.75 (2.33-4.63 ) l/min/m 2 were measured. Linear regression analysis revealed a correlation coefficient of r = 0.87 (p \ 0.0001). Mean bias (TPTDCI-PCCI) was 0.05 ± 0.40 l/min/m 2 . Immediately prior to turning back to SP, TPTDCI was 3.46 ± 0.67 (2.06-4.75 ) l/min/m 2 . After re-positioning, the PCCI was 3.28 ± 0.70 (2.00-4.48 ) l/min/m 2 and TPTDCI was 3.10 ± 0.74 (1.47-4.28) l/min/m 2 , with a mean bias of 0.18 ± 0.37 l/min/m 2 . The correlation coefficient was r = 0.84 (p \ 0.0001). CONCLUSION. PCCI is only marginally influenced by prone positioning and is reliable without recalibration by TPTD. However, in case of greater differences a recalibration by TPTD is nevertheless recommended. OBJECTIVES. The aim of this study was to analyze the clinical agreement between the intermittent bolus thermodilution technique (TDCO) and APCO in patients with non-traumatic intracranial hemorrhage requiring intensive care. METHODS. This was a prospective observational clinical study in a university level ICU. We studied 16 adult patients with non-traumatic intracranial hemorrhage, who for clinical indication underwent CO monitoring by the TDCO (PAC, 7.5 Fr, CritiCath TM SP5507H TD Catheter, Becton-Dickinson, Singapore). In parallel, arterial pressure waveform was applied using the radial arterial pressure curve (FloTrac/Vigileo TM , version 1.10 and 1.14, Edwards Lifesciences, CA, USA). TDCO measurements were done approximately every 4 h and when needed. The length of data recording was depending on the need for TDCO monitoring and ICU stays but was no longer than 6 days. Every TDCO measurements and the simultaneous APCO values were recorded and included into the analysis. RESULTS. 407 data pairs were obtained. Overall, mean CO was 7.5 (SD 2.0) L/min for TDCO and 6.0 (SD 1.9) L/min for APCO. Mean bias between TDCO and APCO was 1.6 L/min ( Fig. 1 ), 95% limits of agreement 1.4 to 1.7 L/min and the percentage error 45%. There was a large interindividual variation in mean bias and percentage error (minimum to maximum, -0.7 to 4.8 L/min and 13-51%, respectively). The bias was significantly greater if patient received norepinephrine (0.8 vs. 1.7 L/min, P = 0.04) but not if patient received dobutamine (1.5 vs. 1.9 L/min, P = 0. 28) . Only a small correlation between the bias and the rate of norepinephrine infusion was detected (q = 0.16). When cardiac index of 2.5 (L/min/m2) was used as a cut off value for need for intervention, the sensitivity and specificity for APCO were 0.50 (95% CI 0.24 to 0.76) and 0.94 (95% CI 0.87-0.93), respectively. CONCLUSIONS. According to our results the second generation of FloTrac Ò /Vigileo Ò monitoring system underestimates the TPCO and the sensitivity is poor. There is also a large interindividual variation in bias. The use of norepinephrine may provoke the error. OBJECTIVES. To compare 5 cardiac output techniques to the reference TTE method, which allows accurate measurement of the aortic flow section and of velocity time integral of aortic pulsed wave Doppler signal to measure CO. METHODS. Monocentric prospective study included patients requiring invasive blood pressure and hemodynamic therapeutic intervention. TTE CO measurement was performed with aortic diameter measured in parasternal long axis view at the the aortic leflets, and velocity time integral measured using five apical view averaged on 5 cardiac cycles. TOD CO was measured only when the PAC insertion was decided. TTE, USCOM Ò , Mostcare Ò and VIGILEO Ò were performed in all patients. Each value was the average of 5 successive cardiac cycles with 3 consecutive measurements. Each patient could have several measures. RESULTS. 24 mechanically ventilated patients (60 ± 20 years; SOFA 8 ± 3.5) were investigated allowing to obtain 252 measurements (117 under norephinephrine). Diagnostics: brain injury (n = 9), sepsis(n = 9) and others (n = 5).1 patient had the 6 methods (9 measurements), 13 patients had 5 techniques (115 measurements), 9 patients had 4 techniques (69 measurements), 6 CONCLUSIONS. All methods correlated more or less with TTE CO, with a slope close to identity, and a low intercept. The best correlation was obtained between Mostcare Ò and TOD. Agreement for almost all methods was large, within an acceptable range. For the pulse contour method, Mostcare is correlated better than Vigileo with TTE CO. The arterial signal has to be accurate as possible and requires a high quality chain for measurement avoiding overdamping or underdamping to allow effective signal digitalization. INTRODUCTION. The lithium indicator dilution technique is attractive in paediatric intensive care because it is non-invasive. However, it requires calibration. The reliability of cardiac output measurement data rests on the reproducibility of the calibration factor (CF). OBJECTIVES. To establish the number of calibrations (= x) that are required in a paediatric patient material, if the coefficient of variation for the calibration factor does not increase by 10% or more by (x + 1) calibrations. To establish x it is also required that 80% of the patients do not show an increase in CV by 10% or more and that 0% of the patients show an increase in CV by 20% or more at (x + 1). Hemodynamically stable sedated and ventilator treated children under intensive care with a body weight of 3-15 kg were included. To perform calibration, 0.007 mmol/kg of lithium chloride was injected intravenously and the concentration of lithium ions in arterial blood was analyzed by a lithium selective electrode. The calibration process was repeated 5 times and the CF as well as lithium indicator cardiac output (LidCO) were calculated. RESULTS. Results from 6 children with a mean body weight of 7.7 kg are presented below. CV was below 1% throughout the investigation. INTRODUCTION. Stroke volume variation has been shown to be a better indicator of fluid responsiveness than static indices such as CVP or PAOP. A limitation of dynamic parameters is arrhythmias which produces abnormal SVV. Beat-to-beat variations reflect altered cardiac filling times not the effects of mechanical ventilation in fluid responsive conditions. A recently developed enhanced algorithm (NewSVV) helps eliminate this limitation. NewSVV rejects ectopic beats using multi-parameter signal recognition and restores the respiratory variation of the signal using spline-based interpolation. OBJECTIVES. To evaluate the performance of the new arrhythmia rejection SVV algorithm to predict fluid responsive from patient data with frequent arrhythmias. METHODS. NewSVV was developed from data collected in a porcine model to limit the impact arrhythmias had on SVV. Comparing the current standard SVV (SVVstd) algorithm (FloTrac-Vigileo System Edwards Lifesciences, USA) with the NewSVV showed a significantly improved sensitivity and specificity. (1) In this preliminary study 3 sets of patient data with frequent PVCs and atrial fibrillation (Afib) were ran through the new algorithm and compared to the data from SVVstd. In one patient 13 fluid boluses (195-440 cc platelets and packed red blood) during a period of Afib caused NewSVV to decrease from 25 to 10% and CO to increase from 4.5 to 6.2 l/min, while SVVstd algorithm did not show a significant change (varying randomly between 10 and 30%). A second patient had non-paroxysmal Afib. SVVstd showed abnormally high values ranging between 25 and 35%. Patient was a non-responder to fluid and had a CO ranging between 10 and 12 l/min. NewSVV showed more realistic value of 11% depicting a non-responder range. The third patient had periods of Afib followed by normal sinus rhythm (NSR). SVVstd algorithm had abnormally high SVV values ([ 35%) during the Afib. During NSR, both algorithms correlated well with SVV of 7%. (Fig. 1.) CONCLUSIONS. The NewSVV algorithm improved SVV with ectopics and Afib and shows promise in eliminating a limitation of SVV in those conditions. Further studies are needed to fully evaluate the performance in patients with arrhythmia receiving fluid challenges. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 S97 METHODS. 14 mechanically ventilated pigs (median weight 37 kg) under general anesthesia were investigated. After instrumentation, baseline values were obtained after at least 2 h of stabilization. ''Shock'' phase (simulation of AAA rupture): 26 (24-28) ml/kg of blood was gradually withdrawn and hemorrhagic shock maintained for 4 h. Abdominal cavity was filled with warmed saline to abdominal pressure of 20 mmHg. ''Clamp'' phase: infrarenal aorta was cross clamped for 90 min and hemodynamics was resuscitated with shed blood and fluids. ''Post-surgery'' phase lasted 11 h and pigs were subsequently sacrificed. Hemodynamics was obtained at baseline, every 30 min for first 2 h of hemorrhage, every 1 h until postoperative phase and every 2 h till the end of the study. Data are presented as median (IQR), appropriate non-parametric tests were used for statistical analysis. RESULTS. Baseline CO measured by PAC was 145 (122-161) ml/kg/min. Both Vigileo 214 (185-263) ml/kg/min (p = 0.029) and LiDCO 77 (60-100) ml/kg/min (p = 0.004) differed significantly. The course of CO is shown in Fig. 1 , all values are presented as a difference to baseline. The median difference between PAC and Vigileo was 34 (12-60)% and for LiDCO 106 (36-171)%. Study limitations: Both devices were designed for CO estimation in humans but we do not expect huge differences in arterial system properties in pigs. Young pigs reacted to hemorrhage by severe sinus tachycardia which caused failure in some CO measurements but at least 10 pigs are presented at every timepoint. CONCLUSIONS. Absolute CO values obtained by both Vigileo and LiDCO differ significantly from PAC. Unlike LiDCO Rapid, FloTrac/Vigileo was able to track changes in CO during severe hemorrhage. GRANT ACKNOWLEDGMENT. IGA MZCR NS 10109-4 and VZ MSM 0021620819. INTRODUCTION. Most important role of postoperative sedation is suppressing stress of the patients in ICU. Urinary 8-hydroxy-2-deoxyguanosine (8-OHdG) can be a good biomarker for oxidative stress in clinical research. The aim of this study is to assess the free radical production under sedation in ICU and compare the production between with midazolam and dexmedetomidine. SUBJECTS AND METHODS. Subjects were twenty-five patients with sedation after neck malignant tumor operation and ventilated for 48 h in ICU. Patients with renal failure were excluded from this study. All patients received fentanyl (2 lg/kg/day), fifteen patients were with midazolam (0.1 mg/kg/h: M-Group) and ten patients were with dexmedetomidine (0.2-0.7 lg/kg/h: D-Group) We examined the concentration of urinary 8-OHdG by high performance liquid chromatography (HPLC) method with coolaray system every morning in ICU. RESULTS. The average value of urinary 8-OHdG of healthy human volunteer is 4 ng/ml. The values of urinary 8-OHdG were less than 2 ng/ml in the both groups and no significant differences were observed between the groups in this study. CONCLUSIONS. Postoperative sedation with both midazolam and dexmedetomidine were effective in suppressing oxidative stress in ICU patients. Poorly controlled pain in the postoperative period can lead to slow recovery and life threatening complications, especially in elderly patients. It has also been suggested that the quality of postoperative analgesia could decrease delirium incidence and reduce duration of hospital stay in the elderly patients. However, the ideal postoperative analgesia management of elderly surgical patients in intensive care units remains to be determined. Since, continuous epidural analgesia provides the required level of analgesia to support early mobilization and significant reduction in pulmonary and cardiovascular morbidity in the early postoperative period, we postulated that the use of low dose of continuous epidural morphine might improve postoperative analgesia and reduce undesirable side effects in elderly patientsTherefore, the present study was designed to evaluate the effects of morphine administered via epidural patients controlled analgesia and intravenous tramadol + metamizol on postoperative pain control and side effects in elderly patients after major abdominal surgery. OBJECTIVES. The purpose of this study was to compare the analgesic efficacy of morphine administered via epidural patients controlled analgesia (EPCA) with our standard analgesic for postoperative pain treatment, intravenous tramadol + metamizol in eldery patients undergoing major abdominal surgery. METHODS. Forty patients older than 70 years undergoing major abdominal surgery were randomly assigned to two groups. Group I received epidural morphine 1 mg at the end of surgery and used a patients controlled analgesia device programmed to deliver morphine 0.2 mg/h, 0.2 mg per bolus. Group II received intravenous infusion of 400 mg tramadol plus 5 mg metamizol in 500 ml electrolyte infusion. The patients in group II received 125 ml of the infusion solution as a loading dose over 20 min (corresponding to 100 mg tramadol plus 1.25 mg metamizol) Postoperative analgesia was tested at rest on a visual analogue pain scale (0 = no pain, 10 = worst possible pain) at 1, 2, 6, 12 and 24 h after surgery. Patients' satisfaction, arterial oxygen saturation, respiratory rate, episodes of nausea, vomiting, pruritus and dizziness were also noted. RESULTS. Both groups obtained adequate pain relief, and there were no between-group differences in pain scores. There were no significant respiratory differences but the patients in the epidural group were more sedated. In the tramadol metamizol group 10 patients were treated for PONV while 5 of the patients in the morphine group showed PONV. We conclude that combination of tramadol and metamizole provided postoperative analgesia equivalent to that provided by epidural morphine in early postoperative period. The both analgesic regimens were safe and suitable for the management of postoperative pain in elderly patients. H. Poon 1 , J. Hulme 2 1 Sandwell and West Birmingham Hospitals NHS Trust, Birmingham, UK, 2 Sandwell and West Birmingham Hospitals NHS Trust, Intensive Care Medicine and Anaesthesia, Birmingham, UK A substantial amount of patients in intensive care units (ITU) receive an inappropriate level of sedation with a tendency for over-sedation. Although the ideal ITU sedation practice is not known, many units use a protocol-based approach incorporating best practice consensus. The use of daily interruption of sedation infusions can reduce oversedation and is included in our current guidelines. OBJECTIVES. The audit assesses compliance to our current protocols for sedation scoring and adjustment of sedation infusions. Provision of sedation breaks in patients sedated more than 1-day is evaluated. METHODS. Retrospective review of ITU inpatients' daily record charts during June and July 2009 at Sandwell and West Birmingham Hospitals NHS Trust in two 16-bedded ITU. 184 charts were reviewed. RESULTS. Our guidelines recommend hourly sedation scoring from 0600 h to midnight and 3 hourly scoring from midnight till 0600 h; at 0000, 0300 and 0600 h. 86% of the reviewed charts did not have a recorded hourly score. 81% did not have 3 hourly scores overnight. 75% of the charts contain Ramsay score -2 or -3; 29% of the charts contain Ramsay score 2 or 3. Per protocol, sedation infusion is stopped at Ramsay score -2 or -3 but in 71% of cases this did not occur. A sedation bolus should be given at a score of 2 or 3. 56% did not receive a recorded bolus. Our guidelines advocate restarting a sedation infusion at a lower rate after it has stopped and the patient is less sedated and increasing the rate after a bolus is given. However, correct infusion rate adjustments were only performed in 46% of cases. Often, rates were changed but without first stopping, or administering a drug bolus. Out of 184 sedation days, there were only 62 true daily breaks. CONCLUSIONS. There is a tendency to over-sedation in our ITU; less so under-sedation. Common practice deviates from protocol and there is poor documentation. Scores are recorded less often than protocol: there may continuous assessment by nursing staff that is not recorded. Boluses are given more often than documented on patient charts. Review of the current guidance is required to address appropriate frequency of formal scoring, nurse-led compulsory sedation breaks and pharmacokinetic education about the necessity to stop or bolus before infusion rate alterations. INTRODUCTION. Daily interruption of sedation has been shown to decrease length of stay in ICU 1 . Recent national guidance in Scotland 2 promotes DIS as part of a care bundle to decrease ventilator associated pneumonia. A 6 week retrospective first round audit was completed prior to the introduction of DIS and demonstrated 30% of patient hours where sedation could be improved. A second round audit of current practice was therefore undertaken to assess the impact of DIS on sedation levels. Our aim was to identify the frequency of periods where sedation levels were undesirable and investigate any clinical reason behind these. OBJECTIVES. To assess whether DIS would improve sedations levels of our patients already managed with a simple sedation algorithm (SA) aiming at a Ramsay sedation score level 3-4 3 . METHODS. Six months following the introduction of DIS, a second period of 6 weeks was studied retrospectively where the ICU daily charts were examined to look at: demographic data, sedation score, and whether DIS had been successfully carried out. RESULTS. 21 cases were identified: 13 males and 8 females with an average age 61 years and similar illness severity scores to the first group. DIS was carried out on 44 patient days, omitted on 3 days and contraindicated on a further 36. 1,395 patient hours were examined. 419 (30%) were excluded due to contraindications such as refractory hypoxia, drug overdose, and end of life care. The remaining patient hours were compared to the first round group [1,540 patient hours with 308 contraindications (20%)] using the Mann-Whitney test as shown in Fig. 1 . CONCLUSIONS. We could not demonstrate any difference in sedation levels following introduction of DIS on our unit. We found a large proportion of patients where DIS was unsuitable. INTRODUCTION. Delirium, an acute and fluctuating disturbance of consciousness and cognition, is a common manifestation of acute brain dysfunction in critically ill patients, occurring in up to 69% of ventilated patients in the United Kingdom 1 . Delirium is independently associated with more deaths, longer hospital stay, and higher overall cost 2 . Hypoactive delirium is much more common, is easily missed and is associated with a worse prognosis than hyperactive delirium 3 . OBJECTIVES. The aim of our project was to quantify the presence of delirium on our critical care unit and to survey the practice of delirium assessment within our region. We conducted a prospective audit at the Critical Care Unit, Birmingham City Hospital, UK. We used the Confusion Assessment Method for the Intensive Care Unit (CAM-ICU) to assess for delirium daily on all our patients for a period of 2 weeks. Simultaneously, we conducted a telephone survey to elicit the delirium assessment practice of the other units within the West Midlands region of the Unite Kingdom. RESULTS. We carried out our assessment on 24 patients over a 2-week period, which resulted in 68 assessments (55 were on non ventilated patients and 13 on ventilated patients). 12 assessments could not be completed because of deep sedation or language barrier. In total we had 17 assessments positive for delirium giving an incidence of 30% for those patients we could fully assess. All of the patients with a positive assessment had hypoactive delirium. The telephone survey revealed only three of the twenty units in our region routinely assessed for delirium. None of the units had a formal management protocol/guideline for delirium. CONCLUSIONS. Delirium is a significant problem on our critical care unit. The incidence was lower than that reported in the literature this might be because firstly we were unable to assess a number of patients due to the patients being deeply sedated, and secondly we noted many of the patients during the assessment period were high dependency patients with minimal organ dysfunction. Despite a large number of recent publications on delirium and increasing awareness amongst critical care professionals most of the units in our region do not routinely assess for delirium. Without regular assessment most delirium will go unrecognised and thus opportunities to instigate preventative measures and early management will be missed. METHODS. Six patients aged 20-45 years old (4 females) who all sustained brain injury with cerebral oedema alongside other traumatic damage (i.e., fractures, abdominal trauma) are hereby presented. Upon admission to the ICU all patients received large propofol doses (25-30 ml/h of propofol infusion 2%), in an attempt to lower cerebral metabolic demand along with vasopressors to maintain a normal mean arterial pressure. Three to 5 days following admission all patients developed metabolic acidosis (base deficit ranged from -6 to -12 mmol/L), hyperkalemia (potassium concentration ranged from 5.8 to 6.9 mmol/L), evidence of muscle cell degradation (creatine kinase and myoglobin concentrations ranged from 30,000 to 49,000 U/L and from 1,900 to 2,700 lg/L, respectively) and lipaemia (triglyceride concentrations ranged from 4 to 4.4 mmol/L). At that time all patients were clinically stable and usual laboratory tests as well as cultures were inconclusive, hence a diagnosis of PRIS was suggested. RESULTS. Three out of six patients developed global left ventricular dysfunction, which was documented by echocardiographic evaluation, with normal cardiac enzymes, while all patients developed acute renal failure. Cardiac and renal failure were observed within 24-48 h following the manifestation of the above abnormal laboratory findings. Continuous hemofiltration was initiated promptly on a daily basis in all cases, while the administration of propofol was discontinued. Abnormal laboratory findings normalized within 2-4 days, while cardiac and renal function gradually ameliorated within a week, following therapy in all cases. No deaths were recorded. CONCLUSIONS. The initiation of continuous hemofiltration therapy is a crucial therapeutic tool for the elimination of propofol and its potentially toxic metabolites in cases of PRIS and may have a beneficial effect upon survival in these cases. L. Zurong 1 , W. Yichun 1 1 Intensive Care Unit of Hunan Province Tumor Hospital, Changsha, China OBJECTIVES. Our purpose was to compare the analgesic properties, effect, and side effects of intravenous butorphanol and fentanyl during chest tube removal in cardiac surgery patients. Seventy-four patients with cardiac surgery were enrolled before chest tube removal. Each patient received standard doses of either fentanyl (50 lg) or butorphanol (1 mg) before chest tube removal in a double-blind manner. Pain intensity and pain distress were measured before analgesic administration, immediately after chest tube removal, and 20 min later Pain quality was measured immediately after chest tube removal. Level of sedation was measured before and 20 min after chest tube removal. RESULTS. The fentanyl (n = 37) and butorphanol (n = 37) groups were identical with respect to age, race, sex, and weight. Pain intensity, pain distress, and sedation levels did not differ significantly between groups. However, procedural pain intensity (mean 3.26, SD 3.00) and pain distress (mean 2.98, SD 3.18 ) scores for all were low. Patients remained alert, regardless of which analgesic was administered. CONCLUSIONS. If used correctly, either fentanyl or butorphanol can substantially reduce pain during chest tube removal without causing adverse sedative effects. Thus, clinicians may choose either safe and effective analgesic interventions during chest tube removal. INTRODUCTION. Delirium is defined as an acute alteration of mental status, with either a disturbance of consciousness or a change in cognition which develops over a short period of time and fluctuates during the course of the day. Reported prevalence of delirium in critical care varies widely from 20 to 80%. Despite this, delirium remains grossly under-recognised and is often thought to be temporary and of little consequence in critical care. It is however one of the most frequent complications and, after adjusting for age, gender and severity of illness is an independent risk factor for prolonged length of stay and mortality (1) . Current recommendations are for the assessment and diagnosis of delirium using simple validated tools (2) . Pharmacological intervention should be considered when reversible precipitating factors have been corrected. Haloperidol is considered the drug of choice. OBJECTIVES. The purpose of this study was to detect knowledge and awareness of delirium, attitudes and behaviours towards its assessment and pharmacological management in critical care units of two large UK teaching hospitals A 15-point survey was distributed to all senior medical and nursing staff employed in Critical Care at the Leeds General Infirmary and The James Cook University Hospital, Middlesbrough. A total of 114 questionnaires were collected after four follow up rounds via web-based survey tool ''Survey Monkey''. RESULTS. The survey detected a significant awareness of the problem delirium poses in ICU. The vast majority (84%) of practitioners did not screen for delirium routinely. Of the16% who screened only 1 in 10 used screening tools that were appropriate, the majority lacked the knowledge of suitable methods to do so. 82% of respondents felt that they required tools to aid diagnosis of delirium in their unit. The pharmacological management of delirium varied significantly, with a wide range of drugs used, suggesting the need for guidance. The majority of respondents (95%) felt that they needed guidelines for treatment of delirium, 90% felt that guidelines would change their practice. Despite an awareness of the problem delirium poses in ICU, data from this survey shows a lack of knowledge of assessment and treatment. Given that most respondents needed guidelines, we have developed a delirium treatment protocol and implemented the Confusion Assessment Method for ICU (CAM-ICU) training package for all staff in the James Cook ICU. Following its implementation we plan to re-evaluate in the hope that the awareness of delirium can be met with the appropriate knowledge to implement a sustained change in practice. RESULTS. 50 patients were included, 35 male (70%), mean APACHE II score 21 ± 5. Midazolam was suspended in 77% after 6 h. Maximum dose of Sufentanyl was 3 mcg/kg/h. Bilirrubin and creatinin did not change from initial values and there was no effect in enteral nutrition tolerance. BIS values improved 22% from 50 ± 10 to 39 ± 9 (p = NS) and there were less hemodynamic effects as well as less necessity of amines and sedatives. Results are shown in Table 1 . CONCLUSIONS. Sufentanyl is an efficient and safe sedative that reduces necessity of more sedatives, amines and generates adequate sedation without renal or hepatic effects. A.S. Puxty 1 , J. Kinsella 1 , K. Anderson 1 1 Glasgow Royal Infirmary, Department of Anaesthetics, Glasgow, UK Etomidate is a sedative agent often used for the induction of critically ill patients. It is, however, a controversial drug with effects on the steroid axis that have been suggested may lead to a poor outcome. So far this has only been proven in infusions of the drug. Despite this some have called for its withdrawal altogether OBJECTIVES. To determine the attitude of anaesthetists and ICU consultants in five hospitals in a major UK city towards the use of etomidate. METHODS. An online questionnaire was constructed using SurveyMonkey (Portland, Oregon, USA). This was then sent out to all anaesthetists in Glasgow via an E-mail link. A reminder was sent after 2 weeks. Trainees from one of the hospitals were unable to be contacted via E-mail and so hard copies of the questionnaire were sent to them. Of a total of 243 anaesthetists in Glasgow (trainees and consultants), 175(72%) completed the questionnaire successfully. Of those answering the questionnaire, 18.2% were SHO level, 23.9% SpR, 57.4% consultants and 0.6% SAS grade. These respondents sub-specialities/specialist interest were: general (46%), pain (8%), ICU (22.2%), obstetrics (14.8%) and cardiac (9.1%). Overall 64(95% CI 57-71)% of respondents were concerned about etomidate's effect on steroid synthesis, although when asked about induction of an emergency laparotomy 53 (46-60)% would still use it [with 34 (27-41 )% avoiding it and 12 (7) (8) (9) (10) (11) (12) (13) (14) (15) (16) (17) % responding that they were never involved in emergency laparotomies]. Of those using etomidate, 27 (18-36)% would avoid it in a septic patient, and a further 33(23-43)% would give steroid cover. The most common reason for using etomidate was cardiovascular stability [98 (96-100)%]. Other reasons given were simple dosing (6 [1-11] )% and habit (13 [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] )%. More than one reason was allowed. Looking for differences between groups the following was found: while ICU consultants reported more concern over etomidate (75 vs. 50%, p = 0.044), there was no difference in etomidate usage in emergency laparotomy (65% of general vs. 50% of ICU consultants, p = 0.31). Trainees were more likely to have their habit changed by the recent literature on etomidate (56 vs. 41%, p = 0.035). CONCLUSIONS. There is concern among anaesthetists and ICU consultants regarding the use of etomidate but usage has not changed markedly by most. Further evidence of harm would likely need to be demonstrated before abandonment of the drug. INTRODUCTION. Nociception and requirement of additional analgesia before painful procedures in ICU are difficult to anticipate. Under anaesthesia, the direct pupil light reflex reflects the sympatho-vagal balance and remains altered by pain and sedative drugs. The pupillometry is a reproductive, non invasive method based on automated flash light device assessing pupillary variations [1] . To study pupillometric parameters to anticipate the tolerance to painful stimuli (surgical debridement). METHODS. Eligibility criteria: sedated patients (morphinomimetics + benzodiazepines, BPS = 3) in days after invasive surgery for cervical necrotizing fasciitis (CNF), complicated or not with mediastinitis, requiring a surgical debridement three times a day. Clinical evaluation performed before and during debridement: heart rate (HR), mean arterial pressure (MAP) and Behavioral Pain Score (BPS) [2] . Pupillometric test before debridement (calibrated bright flash of one-second at 150 Lux, (Neurolight, ID MED) with recording of pupillary parameters: minimum and maximum diameter, variation rate, latency, velocity. Noxious procedure was defined as an increase of at least one point of the BPS (change in facial expression, upper limb movement or ventilator synchrony). The additional analgesia was decided blindly from pupillometric values. Analysis compared two groups defined on BPS variation induced by the procedure: Group 1 with DBPS C 1 and Group 2 with DBPS = 0. Comparison of pupillometric parameters before procedure between the 2 groups. Results expressed as median (interquartile range, IQR), Mann-Whitney test, significance at p \ 0.05. . 24 patients with cervical cellulitis of which 5 complicated by mediastinitis, H/ Fratio = 15/9, age 49 years (40), IGS 33 (17). In this population, during the procedure, HR and MAP were unchanged, the BPS increased significantly [from 3(0) to 5 (2) , p = 0.0004] but remained unchanged in 8 patients (33%) (group 2 = high tolerance). Pupillometric parameters before procedure Before procedure Group 1 (n = 16) Group 2 (n = 8) p CONCLUSIONS. All pupillometric parameters, except latency, were discriminant for subsequent debridement tolerance with significantly lower values in the group without pain experience. The pupillometric test seemed adapted to this clinical practice for evaluation of nociception status and may help for rationalizing analgesia for short noxious procedures. INTRODUCTION. Delirium is an acute and fluctuating change in mental status, with inattention and altered levels of consciousness. The incidence of delirium in orthopedic patients was ranges from 5.1 to 61%. Delirium may present before or after the patient undergoing surgical procedure and has demonstrate increasing risk, including mortality. OBJECTIVES. The purpose of this study was to compare the effectiveness and tolerability of intravenous propofol versus midazolam infusions in postoperative agitation/delirium therapy with using an epidural infusion for postoperative analgesia after major orthopedic surgeries in high-risk patients with chronic renal failure. With the institutional ethic committee approval; eighty-two high-risk chronic renal failure patients (ASA III, BUN [ 40 mg/dl and serum creatinin value [ 2) after a major hip or knee operations with a diagnosis of agitation/delirium were eligible for the study in the postoperative period. Richmond agitation sedation scale (RASS) or Confusion Assessment Method for the ICU (CAM-ICU) were used for sedation/orientation levels. All agitated patients had an lumbar epidural catheter was inserted preoperatively in combination with spinal anesthesia intraoperatively. After the surgery the catheter was loaded with 0.25% 25 mg bupivacaine at the T12 to L1 sensory levels and a continuous infusion of 0.125% bupivacaine was commenced at 2-4 mL/h in combination with patient controlled analgesia of meperidine (2 mg/bolus). For agitation/delirium therapy in group P (n = 40) propofol was used with intravenous loading dose of 1-2 mg/kg in a bolus and followed by continuous infusion at 1-3 mg/kg/h and group M (n = 42) midazolam was used with intravenous loading dose of 0.05-0.2 mg/kg in a bolus and followed by continuous infusion at 0.05-0.3 mg/kg/h to ensure a target of RASS in +1 and -1 values. Hemodynamic parameters (heart rates, systolic and diastolic blood pressures), oxygen saturation with sedation-agitation scales were monitored periodically for 24 h. Adverse events were recorded. p \ 0.05 showed statistically significant. RESULTS. The groups were demographical comparable (p [ 0.05). Group P patients reached the target RASS scores earlier in group p (p \ 0.05). Hemodynamic values were significantly higher in group M (p \ 0.05). The epidural bupivacaine consumption was significantly lower in group P with a limited analgesic requirement (p \ 0.05) and n treatment required adverse events was seen in group P (p [ 0.05). CONCLUSIONS. Intravenous propofol infusion may be an effective and safe approach adjunct to epidural analgesia for possible postoperative agitation/delirium treatment after major orthopedic surgeries in high-risk patients with chronic renal failure. INTRODUCTION. Ventilator-associated pneumonia (VAP) is the most common nosocomial infection among the critically ill patients admitted in the intensive care units (ICUs). Implementation of the available international evidence-based guidelines and recommendations to prevent and manage VAP into the clinical setting may not be adequate leading to suboptimal patient care and increased VAP rates. OBJECTIVES. To assess the implementation of selected VAP prevention strategies, and to learn how VAP is managed by the intensivists practicing in the Indian Subcontinent. METHODS. Three hundred 10-point questionnaires were distributed during an international critical care conference. 131 (43.7%) were returned and 126 (42%) questionnaires of delegates from India, Nepal and Sri Lanka were analyzed. Most of the intensivists (96.8%), reported using VAP bundles in their ICUs with a high proportion including head elevation (98.4%), chlorhexidine mouthcare (83.3%), stress ulcer prophylaxis (96.8%), heat and moisture exchangers (HME, 92.9%), early weaning (94.4%), and hand washing (97.6%) as part of their VAP bundle. Use of subglottic secretion drainage (SSD, 45.2%) and closed suction systems (CSS, 74.6%) was also reported by many intensivists, whereas, use of selective gut decontamination was reported by only 22.2% of respondents. Most common method for sampling used for diagnosis of VAP was endotracheal suction by 86 (68.3%) intensivists, and only 0.8% intensivists reported using protectedsample brush. Gram negative organisms (pseudomonas, acinetobacter) were reported to be the most commonly isolated organisms. Majority of respondents (39.7%) reported using proton pump inhibitors for stress ulcer prophylaxis. Majority (84.1%) believed that VAP contributed to increased mortality in their ICUs with 47.6% treating VAP with an antibiotic course lasting for 7-14 days. De-escalating therapy was considered, in patients responding to treatment, by 57.9 and 65.9% considered adding empirical MRSA coverage and 63.5% considered adding nebulised antibiotics in certain high risk patients. Overall there was good concordance regarding VAP prophylaxis among the intensivists with a majority adhering to evidence based recommendations and guidelines. Even though the gap between recommended guidelines and the actual clinical practice is closing, we could identify certain issues like the choice of agent for stress ulcer prophylaxis, use of HME, SSD and CSS, where there still exists some practice variability and opportunities for improvement to provide better patient care. OBJECTIVES. To reassess the value of individual levels and dynamic alteration of procalcitonin (PCT) in predicting the outcome of ventilator-associated pneumonia(VAP) patient. METHODS. Forty adult patients with VAP were studied and divided into two groups according to their outcome at day 28 after diagnosis of VAP: death and survival. Serum PCT levels were measured on Days 1, 4 and 7 (D1, D4, and D7, respectively) and their alteration between different days (kinetics, 4PCT) were calculated. To control the study, Acute Physiology and Chronic Health Evaluation II (APACHE II), Sequential Organ Failure Assessment (SOFA), and Clinical Pulmonary Infection Score (CPIS) and C-reactive protein (CRP) were also recorded and analyzed. All parameters have been investigated as independent variables in relation to 28-day death as dependent variable. RESULTS. The increase of PCT levels on day 1, 4 and 7 were significantly predictive of death in univariate analysis with area under curve (AUC) and 95% CI of 0.732 (0.568, 0.896), 0.741 (0.546, 0.937) and 0.797 (0.606, 0.989), respectively. However, kinetics of PCT levels among day 1, 4 and 7 did not show a significant difference between favorable and unfavorable outcomes (p [ 0.05). Multivariate analysis revealed that only SOFA (7) CONCLUSIONS. Neither PCT individual levels nor their kinetics during VAP course can predict patient outcome. Comprehensive evaluation of patients with multiple methods, in combination with PCT levels, may increase predictive accuracy in the future. GRANT ACKNOWLEDGMENT. We have no competing interests. INTRODUCTION. The presence of new or progressive radiological infiltrates, pyrexia, leukopenia or leukocytosis, and the presence of purulent tracheal aspirates are key features defining the presence or absence of VAP. The incidence of VAP is dependent upon the number of diagnostic criteria applied, and the demographics of the critical care population to which it refers. A UK government directed ''patient safety first'' campaign in the UK, has highlighted VAP as a complication related to mechanical ventilation that can be reduced through the introduction of a ''care bundle''. However, benchmarking between different units has practical limitations. OBJECTIVES. Selective data presentation can distort the perceived occurrence of critical events in order to deliver performance targets. We compared the incidence of VAP between a neurosurgical and general intensive care unit in the same hospital. A variety of denominators were applied to explore the potential for data manipulation to realise performance targets A local database of neurosurgical and general intensive care admissions, covering a 6 month period, was analysed retrospectively RESULTS. 322 and 96 subjects were admitted to GITU and NITU respectively in the 6 month period. 165 (51%) and 59 (61%) subjects were ventilated for more than 2 days. Table 1 summarises the demographics and measures of performance between the two units. A P value \0.05 was considered significant. Parametric and Non-Parametric tests were applied as appropriate. 1 . VAP is associated with not only mortality but also considerable morbidity, prolonged duration of ventilation and increased cost of hospitalisation. To determine the incidence of VAP in patients ventilated at the QENSIU, to calculate MV resource utilisation, and to ascertain whether VAP relates to outcome in acute SCI. We undertook a retrospective case note review of all patients ventilated at the QENSIU during a 5 year period. Patients were identified using a local computerised database. The QENSIU receives referral of patients with SCI from the whole country (pop * 5.1 m). VAP was defined pragmatically as deteriorating gas exchange more than 48 h following MV, coupled with a raised CRP or WCC, together with either a positive sputum sample or new infiltrates on CXR. Statistics: descriptive, median (range); analytical, Mann-Whitney U and Fisher's exact test as appropriate. Death occurred in 22% of patients, and was significantly greater in the group who were retrospectively assigned to the VAP cohort: VAP vs Survival Of the 13 deaths, 8 occurred following discharge from the unit (6 of whom developed a subsequent VAP). CONCLUSIONS. VAP incidence was apparently high in this patient population (56%), particularly in comparison to the reported general ICU population incidence (8-20%) 2 . This may partially reflect our pragmatic diagnostic criteria, applied retrospectively. VAP was also associated with an increase in mortality following discharge in patients with SCI. A modified VAP bundle adapted to SCI patients is being developed locally, based on recent recommendations 3 . INTRODUCTION. The implementation of a prevention programme with feedback to nurses and healthcare workers (HCW) was associated with better outcomes and increased compliance [1] . To assess the effects of feed-back in a study based on implementing a 5variables care bundle to prevent VAP. A multicenter and prospective study was carried out in 5 ICUs. The 5 element care bundle consisted in hands hygiene, oral hygiene, monitoring cuff pressure, sedation vacation/adjustment and avoid ventilator circuits changing. Beweekly feed-back displaying posters with information was carried out to update HCW in the compliance of the prevention measures and VAP incidence. A 6 questions with open answer questionnaire was performed 6 months after the implementation of the feed-back in all ICUs to assess the knowledge of the compliance measures, VAP incidence, opinion of the study and improvement suggestions. RESULTS. 82 questionnaires were obtained. The median experience in intensive care was 10.7 years (SD 7.9-15.2). 100% of the staff was aware of the study: 95.8% agree that was useful, 3.1% disagree and 1.0% didn't know. Regarding if they thought that in their units they had a high VAP incidence, 22.2% answered that they did, 71.6% answered negatively and 1.7% didn't know. Asking about the knowledge of the prevention measures' compliance 41.4% answered right, 4.2% said they knew but didn't specify the percentage, 51.1% didn't know and 3.3% didn't answer the question. Finally, about the VAP incidence, 37.0% answered right, 6.7% said they knew but didn't specify it, 50.8% didn't know and 5.5% didn't answer the question. 14.1% added comments, the most relevant was: 73.3% of the respondents wanted more verbal information. CONCLUSIONS. Poster Feed-back failed to improve compliance on VAP care bundle due to lack of information. Our survey suggests to implement other communication strategies based on direct verbal interaction to improve implementation. OBJECTIVES. To compare the effectiveness of two different methods of oral dental hygiene on ventilator-associated pneumonia (VAP) prevention using the CPIS (Clinical Pulmonary Infection Score). METHODS. Twenty-seven critically ill patients, aged 21-79 years were studied. Patients were randomly separated in 2 groups: Group 1 (n = 14) received oral care with tooth brushing using the Bass technique followed by lavage with chlorhexidine 0.12% (CHX) solution in NaCl 0.9% (CHX:NaCl 0.9% = 3:1). Hexetidine 0.1% (HEX) was used for oral lavage alone in group 2 (n = 13). Demographics, SOFA, APACHE II, GCS and CPIS scores were recorded upon patient admission. On days 2, 5, 8 and 15, BAL and tongue surface cultures were obtained. The endpoints taken into account were the CPIS on days 2, 5, 8, and 15 as well as the number and species of bacteria cultivated. A CPIS C 6 was considered positive for VAP. Two-way ANOVA, t test for independent samples, Mann-Whitney U, Pearson correlation and Kruskal-Wallis tests were used for statistical analysis. P \ 0.05 was considered statistically significant. Patient data analysis showed that both groups were homogeneous. On days 5, 8 and 15 there were more negative tongue surface cultures in the CHX group than in the HEX group (p = 0.03). Even though the CPIS did not differ significantly between the 2 groups, a strong tendency of faster and greater reduction in the CHX group was observed. Moreover, a continuous gradual improvement of the CPIS score was recorded in both groups on days 5, 8 and 15. The overall incidence of VAP was similar in both groups: group 1, 14.4% (n = 2) and group 2, 15.4% (n = 2). The same bacteria (p \ 0.001) developed in both BAL and tongue cultures on days 8 (p \ 0.001) and 15 (p \ 0.001). Nevertheless, the CPIS was positive for VAP only in the above 4 patients on day 8, while day 15 was totally free of VAP. CONCLUSIONS. Even though the CPIS improvement was more remarkable in group 1, both group scores showed parallel improvement overtime, the CHX group being in a slightly more propitious position. Diligence in patient oral care seems to be an additional effective practice for VAP prevention, independently of the method used. INTRODUCTION. Specific patterns of cytokine gene expression are reported to be associated with the occurrence of infection in humans [1, 2] . It is unclear whether these characteristic profiles are a consequence of an established disease process or precede the infective process. OBJECTIVES. Our primary endpoint was to determine whether hospital acquired pneumonia was associated with differential gene expression of IFN-c, TNF a and IL-12 family of cytokines. Secondary endpoint was to identify whether alteration in gene expression preceded the clinical onset of infection. METHODS. 60 consecutive patients undergoing elective thoracic surgery were recruited. Hospital acquired pneumonia was diagnosed as per NNIS guidelines, independent of study investigators. mRNA and protein levels were analysed pre operatively, 24 h and 5 days post operatively. . 41 patients had an uncomplicated recovery. 19 patients developed hospital acquired pneumonia. IL-6, IL-10, IL12-p35, IL-23-p19, IL-27-p28, TNF-a, and IFN-c mRNA and protein levels of IL-6, IL-23, and IFN-c in peripheral blood were analysed before surgery, 24 h and day 5 post surgery. IL-23p19 mRNA levels were reduced in the pneumonia group (15,465; 8,071-51,614) compared to non pneumonia group (31,420; 7,101-206,943 ) day 1 post surgery (P = 0.02). IFN-c mRNA levels were reduced in the pneumonia group (305; 102-1,522) compared to non pneumonia group (640; 144-1,820) (P = 0.03) day 5 post surgery. Absolute copy numbers of mRNA per 10 million copy numbers of b-Actin are quoted. All values are quotes as median and 10th to 90th centile range. Patients with postoperative hospital acquired pneumonia exhibit distinct patterns of cytokine gene expression. These distinctive patterns manifest before the clinical onset of pneumonia. OBJECTIVES. The aim of this study was to evaluate the impact of the implementation of a ventilator bundle on the incidence of VAP in our Intensive Care Unit (ICU). METHODS. Prospective, observational study. During a 1 year period (January 09-10) a ventilator care bundle based on the CDC and Canadian Guidelines 1,2 was applied to each patient requiring more than 48 h of mechanical ventilation (MV). The ventilator care bundle consisted in:Hand hygiene. Use of barrier precautions. Preference of noninvasive ventilation (NIV). Orotracheal intubation. Semirecumbent position. Continuous aspiration of subglottic secretions. Manteinance of the endotracheal cuff pressure. Oral care with chlorhexidine. Daily sedation vacation and assessment of readiness for weaning. No scheduled ventilator circuit changes. Ventilation circuit maintenance. Stress bleeding profilaxis. We followed general measures for infection control:Single patient room. Microbiologic surveillance. Monitoring and early removal of invasive devices. Program to reduce antimicrobial prescriptions. For each ventilated patient the following data was registered:Age, APACHE II, the reason of admission, risk factors, use NIV, MV duration, timing of tracheostomy, time of diagnosis of VAP, microbiological data, length of stay and mortality in ICU. The compliance with the bundle was registered in a check list. The application of the ventilator care bundle impact was compared with historical data. . 67 ventilated patients were included. The median age was 73 years. The mean APACHE II was 22.5 ± 8.4. The reason of admission was in a 87% medical and 13% surgical. The most frequent risk factors were: age [65 years, emergency surgery, pulmonary disease and immunosuppression. NIV was used in 23%. The median duration of MV was 8 days. Tracheostomy was done in 19.5% patients with a delay of 15 ± 7 days. There were 3 late-onset VAP episodes and the rate of VAP per 1,000 ventilator days was 4.57. The VAP were caused by Candida albicans, Enterobacter aerogenes and Pseudomona aeruginosa. The length of ICU stay was 17.6 days. Mortality was 26% (only one patient with VAP). The rate of compliance with ventilator care bundle was 100%. The rate of VAP per 1,000 ventilator days after implementation of the bundle decreased significantly (Table 1) . There is currently no consensus on the diagnostic criteria for ventilator associated pneumonia (VAP) which has led to significant variation in the reported incidence (9-28%) 1 . ICUs need a reliable and accurate diagnostic system so that the efficacy of measures to reduce the incidence of VAP can be assessed, and if VAP is to be considered as a quality indicator of performance. OBJECTIVE. To establish a process to diagnose VAP that can be used for continuous surveillance and to assess the effect of new therapeutic interventions. METHOD. Potential diagnoses of VAP were identified prospectively by a senior intensive care doctor and clinical data was collected to calculate a modified clinical pulmonary infection score (CPIS) 2 . Each case was subsequently reviewed at a multidisciplinary team (MDT) review forum with intensive care and microbiology clinicians. The case details, modified CPIS and semiquantitative microbiological culture results were used to reach a consensus view on the diagnosis. A pilot audit performed over a 6 week period in 2009, gave a VAP incidence of 5% (6 VAPs; 118 ventilated patients; 483 ventilator days) . A change to our ventilator care bundle was subsequently instigated, with the addition of chlorhexidine paste to daily mouth care before repeat surveillance. RESULT: 366 patients were admitted to the critical care unit over 112 days. 199 patients were ventilated during a total 759 ventilator days. 12 patient episodes were identified as potential VAP and discussed at the MDT forum. 3 cases were diagnosed as VAP (incidence 1.5%) and 1 patient diagnosed as tube associated pneumonia. The other cases were excluded either due to clinical circumstances (n = 5) or absence of positive microbiology (n = 3). CONCLUSION. We have developed a process for identifying and diagnosing VAP within our critical care unit that continues to be used for ongoing surveillance. Collaboration between the intensive care team and the microbiology department, along with a MDT forum, has been fundamental to this process. Our data highlights the difficulty in diagnosing VAP and the need for multidisciplinary expertise. Of the 12 patient episodes prospectively identified as potential VAP, 9 were deemed not to be VAP when clinical data and results were available for review at the MDT forum. The reduction of VAP incidence between the pilot study and subsequent screening suggests benefit from the introduction of oral chlorhexidine, however we recognise other contributing factors. Controversially, ICUs in the UK are increasingly being asked to provide data on VAP incidence as a quality indicator. We believe that we have a process that is robust and allows us to accurately monitor the incidence of VAP. INTRODUCTION. Bacterial biofilm within the internal surface of the endotracheal tube (ETT) may contribute to ventilator-associated pneumonia. The gene expression pattern of those bacteria, embedded within biofilm matrix, greatly differs from their planktonic counterpart and allows survival benefits and increased virulence. To compare biofilm production capability of planktonic versus sessile methicillin-resistant Staphylococcus aureus (MRSA) retrieved from within ETTs, and to assess whether antimicrobials can hinder those processes. Ultimately, to study any change in planktonic versus sessile bacterial DNA. We previously developed a model of pneumonia in pigs mechanically ventilated up to 84 h and challenged into both lungs with MRSA. From those studies, 35 ETTs of pigs, treated with placebo (n = 10), Linezolid (n = 9) or Vancomycin (n = 16) were retrieved. Distal and medial parts of each ETT were processed (70 samples). The planktonic MRSA strain, inoculated to the pigs, was compared with sessile MRSA strains, retrieved from the internal surface of the ETTs, in capability to form biofilm, assessed through the adhesion-to-aplaque method for gram-positive bacteria. The optical density of biofilm was measured using a Microplate Reader at wave length k = 450 nm and results are proportional to the planktonic control strain (value = 1). Pulsed-field Gel Electrophoresis (PFGE) was used to determine potential bacterial DNA recombination. INTRODUCTION. Ventilator-associated pneumonia (VAP) is a common complication in mechanically ventilated patients and is associated with increased morbidity, mortality and costs. Treatment-related risk factors associated with VAP, include prolonged duration of mechanical ventilation, lack of antiseptic techniques, improper patient's position, inappropriate cuff pressure, peptic ulcer prophylaxis, and deep sedation. OBJECTIVES. The aim of this study is to evaluate the presence of these risk factors and their association with VAP development in a multidisciplinary ICU. One hundred and fifty-seven critically ill patients consecutively admitted to a multidisciplinary ICU, were prospectively studied. Forty-one of them, developed VAP (32M/9F age: 51 ± 22 years, APACHE II score on admission 14 ± 6, SOFA score on admission 8 ± 3). Inclusion criteria were intubation \12 h prior to ICU admission or after 48 h of admission. Exclusion criteria included: prior hospitalization in another ICU, ICU stay\48 h, brain death, age \18 years old and pregnancy. Bronchial secretions, samples from the pharynx and gastric secretions were collected from each patient 3 times weekly (on days 1, 3 and 7). We also documented the known risk factors for VAP; sedation depth (using the RAMSAY scale), cuff pressure, head-bed elevation, reintubation, ventilator circuit changes, tracheostomy, the presence of levin, deep venous thrombosis and stress ulcer prophylaxis, three times weekly per patient RESULTS. In this selected sample of patients, the incidence of VAP was 26 per 1,000 ventilation days. Out of this sample, 15% underwent at least one endotracheal tube change, 24% had at least once their ventilator circuit changed, 19% underwent a tracheostomy, 93% had levin, 14% did not have head-bed elevation above 30°, 87% had Ramsay scale 5 or 6, 19% had cuff pressure B15 cmH 2 O, 58% did not received deep venous thrombosis prophylaxis and all of them received H 2 -receptors antagonists, as gastric ulcer prophylaxis. These results indicate that several risk factors for VAP, do indeed apply for the cases under study and that the incidence of VAP is relatively high. Therefore, the implementation of preventive strategies and the reinforcement of VAP bundles can result in beneficial effects on the appearance of VAP, in the monitored ICU. INTRODUCTION. Pulmonary inflammatory response and progressive ARDS may complicate posttraumatic ALI. CLRT by a motor-driven bed is used in trauma patients to improve gas exchange and to prevent from ventilation-associated complications. We investigated the effect of CLRT on the inflammatory response in the posttraumatic course. To assess systemic and pulmonary cytokines (Interleukin (IL-6, IL-8), Intercellular Adhesion Molecule-1 (ICAM-1) before and 5 days after begin of CLRT. Conventionally positioned patients served as a control group. After approval by our Institutional Review Board 27 trauma patients presenting with ALI (PaO 2 /FiO 2 \ 300) were prospectively randomized in CLRT (n = 13) and control group (n = 14). Cytokines were assessed from serum (S) and broncho-alveolar lavage (BAL) after admission at the ICU and on day 5, respectively. RESULTS. The mean age was 44 ± 11 years and mean Injury Severity Score was 48 ± 7. Pulmonary gas exchange improved significantly in CLRT in comparison with conventional positioning on day 5. Changes in cytokine levels are presented in Table 1 (median and 25/75percentile values, * = p \ 0.05 within groups and $ = p \ 0.05 between groups, Wilcoxon and Mann-Whitney-U test). Serum IL-6 and IL-8 levels were reduced statistically significant on day 5 in both groups, but this effect was significantly more pronounced in CLRT-group. In BAL cytokines tended to be increased in CLRT and control group on day 5. ICAM-1 levels were increased in S and BAL after 5 days treatment. CONCLUSIONS. The early use of CLRT reduces the systemic inflammatory response (IL-6, IL-8), but has no influence on regional pulmonary cytokine expression. CLRT might be a helpful tool for stabilization in trauma patients with ALI. OBJECTIVES. The aim of this study was to compare the performance of Adaptive Support Ventilation (ASV) with and without closed loop control by end tidal CO 2 (ETCO 2 ) (ASVCO 2 ) to that of pressure control ventilation (PCV) and volume control ventilation (VCV) during simulated ARDS and to compare the ability of all modes to manage ETCO 2 , tidal volume (V T ), and plateau pressure (PP) as respiratory mechanics, PEEP and minute volume changed. METHODS. ASV and ASVCO 2 were compared to a V T of 6 ml/kg in VCV and PCV using the Michigan Instruments test lung set up with CO 2 titrated into one of the test lung chambers. The compliance of the system was set at 35 and 15 ml/cmH 2 O and resistance at 7.7 cmH 2 O/L/min. At baseline ventilation CO 2 was titrated to establish a CO 2 production of 3 ml/kg PBW/min (70 kg) or 210 ml/min. After stabilization and data collection CO 2 production was increased to 280 ml/ min and then to 350 ml/min then decreased to 140 ml/min. After each CO 2 adjustment and stabilization period data was collected. Statistical analyses were performed by ANOVA or Kruskal-Wallis tests where appropriate, a p value\0.05 was considered significant. Overall ETCO 2 level in ASVCO 2 (45.3 ± 6.8 mmHg) was higher than in other modes (ASV 35.6 ± 13.5, VCV 29.4 ± 9.5, PCV 31.7 ± 9.7 mmHg) (p \ 0.001). At the lowest compliance ETCO 2 in ASVCO 2 (48.6 ± 6.8 mmHg) was higher than in VCV (29.8 ± 9.8 mmHg) and PCV (33.4 ± 10.1 mmHg). Overall V T was similar in all modes except that V T in ASVCO 2 (5.3 ± 1.7 ml/kg) was lower than in VCV (6.3 ± 0.2 ml/kg) (p = 0.033). At the lowest compliance V T in ASV (3.9 ± 0.5 ml/kg) and ASVCO 2 (3.7 ± 0.5 ml/kg) were lower than in VCV (6.4 ± 0.1 ml/ kg) and PCV (5.9 ± 0.1 ml/kg) (p \ 0.001). Overall, PP in ASV (29 ± 1.9 cmH 2 O) and ASVCO 2 (28.6 ± 2 cmH 2 O) were lower than in VCV ( CONCLUSIONS. Our high mortality in this group of patients despite improved oxygenation concurs with published data. However, potential improvements with adherence to pH and oxygenation targets could be made to ensure optimal use of HFOV as a lung protective strategy. OBJECTIVES. This randomized cross-over controlled study was designed to assess safety, gas exchanges, and ventilator outputs obtained with Intellivent Ò as compared to Adaptive Support Ventilation (ASV) (2) in ICU ventilated patients with acute respiratory failure. METHODS. The study was approved by ethic committee and inform consents were obtained by next-of-kin. 50 intubated, sedated and ventilated patients were included (age = 67 ± 15 years, SAPS II = 50 ± 18, 31 and 19 ALI/ARDS and normal lungs patients, respectively). Patients were ventilated using a G5 (Hamilton Medical, Switzerland) with a dedicated software. ASV and Intellivent Ò were delivered in random order for two periods of 2 h with half an hour of washout in between. Tidal volume (V T ), peak pressure (Ppeak), SpO 2 , and EtCO 2 were continuously recorded. Blood gas analysis and plateau pressure (Pplat) were measured at the end of each period. A paired t test was used to compare ventilation and oxygenation parameters between ASV and Intellivent Ò period. No patient was removed from Intellivent Ò for major safety issue. Intellivent Ò delivered a lower MV (7.1 ± 1.8 vs. 7.9 ± 1.7 L/min, p = 0.003), PEEP (9 ± 5 vs. 10 ± 4 cmH 2 O, p = 0.01), FiO 2 (35 ± 13 vs. 45 ± 18%, p \ 0.001), Vt/PBW (8.1 ± 0.8 vs. 8.4 ± 0.8 mL/Kg PBW, p = 0.003), and Pplat (22 ± 6 vs. 24 ± 6 cmH 2 O, p = 0.01) than ASV. Static compliance, PaO 2 /FiO 2 ratio and PaCO 2 were not different between ASV and Intellivent Ò . With both ASV and Intellivent Ò , V T was between 6 and 10 mL/Kg PBW in all the patients. Figure 1 is showing the distribution of mean of individual breath by breath peak pressure during the two recording periods. CONCLUSIONS. Intellivent Ò delivered lower volumes and pressures than ASV for equivalent results on gas exchange suggesting more efficient ventilation. INTRODUCTION. During neurally adjusted ventilatory assist (NAVA) pressure applied to the airways by the ventilator is moment-by-moment proportional (according to a proportionality factor called ''NAVA gain'', unit: cmH 2 O/lV) to the electrical activity of the diaphragm (EAdi, unit: lV), as measured through a modified nasogastric tube with a multiple array of esophageal electrodes. Independently from its physiological correlation with real diaphragm activity, EAdi and its variations are the only variables through which different NAVA gains may affect patient respiratory pattern. OBJECTIVES. We explored how EAdi influence the effect of varying the NAVA gain on tidal volume and peak airway pressure. We included twelve patients recovering from acute respiratory failure. All patients, connected to a Servo-i ventilator (Maquet Critical Care, Solna, Sweden) able of delivering both PSV and NAVA, underwent to a random application of 7 increasing gains (0.5-1-1.5-2-2.5-3-4 cmH 2 O/lV) during NAVA and 4 increasing pressure support (4-8-12-16 cmH 2 O) during PSV. Each level was maintained at least 10 min. All changes in EAdi, tidal volume (Vt), and peak airway pressure (Paw peak ) were referenced respect to their respective values at NAVA gain 0.5. INTRODUCTION. Lung protective ventilation strategies is considered 'gold standard' for patients with acute respiratory distress syndrome (ARDS). High-frequency oscillation (HFO) has been used as a rescue measure and claimed to protect the lungs from ventilator induced lung injury (1) . Theoretically HFO should be considered early in the course of ARDS. OBJECTIVES. We were interested to determine the time course to achieve optimal gas exchange with early HFO and its impact on the use of other adjunctive therapies; inhaled nitric oxide, prone positioning and extracorporeal oxygenation or carbon dioxide removal. After Ethical approval, a total of 79 adult patients with ARDS were enrolled in this prospective observational study. The oscillation (Metran Co. Ltd, 12-18, 2-Chome, Kawaguchi, Saitama, Japan) was started when FiO 2 [ 0.7 or level of PEEP [ 15 cmH 2 O were required on a conventional ventilator. HFO frequencies, cycle volume and bias flow were altered until optimal gas exchange achieved. The pattern of gas exchange was observed for the first 24 h and other adjunctive therapies were used when required. The following parameters were recorded: duration of HFO, arterial blood gases during the first 24 h, frequency of need for other therapies, incidence of barotraumas, and re-requirement of HFO once weaned from. A total of 79 patients (age between 18-74 years, male:female ratio = 43:26) were ventilated 1-3 days with conventional ventilator before start of HFO. Duration of HFO varied from 2 to 13 days (4 median). There was a significant improvement in PaO 2 at 8-12 h (p = 0.001) following the onset of HFO (Fig. 1) . The number of patients requiring other therapies are very low; Inhaled nitric oxide n = 4, prone positioning n = 2, both prone positioning and nitric oxide n = 1, ECMO/Novalung n = 0. Seven patients required re-HFO once weaned and another two developed pneumothoraces requiring chest drainage. CONCLUSIONS. The data of this study demonstrates that significant improvement in gas exchange occurs in patients with ARDS following 8-12 h of HFO. Early oscillation also appears to reduce the need for other adjunctive therapies. Further studies of early HFO strategy are warranted. INTRODUCTION. Neurally adjusted ventilatory assist (NAVA) is a novel method for patient triggering of pressure support. Instead of relying on conventional pressure or flow triggering, the peak diaphragmatic EMG signal (Edi) is used to precisely synchronise patient demand with ventilatory assist. Although, the physiology and science underpinning NAVA has been described, less is known about its clinical application and efficacy (1) . In particular, clinical superiority over conventional pressure support has not been established. OBJECTIVES. Here, we describe the clinical, nursing and operational lessons learnt from the introduction of 10 NAVA platforms (Servo-i, Maquet) into a 32-bedded central London intensive care unit over 2 years. In parallel we present some novel data from an observational cohort study examining the effect of NAVA on sedation use and ventilator days. A protocol for the safe measurement of Edi in critically ill ventilated patients was developed through multidisciplinary review and discussion. A 2 year registry of clinical lessons and adverse events from the introduction of NAVA was kept. In a parallel observational cohort study we examined three populations of ventilated patients (n = 27) matched for APACHE II, oxygenation index and compliance. Group 1 had no NAVA catheter; group 2 had Edi signal measured during conventional pressure support; and group 3 utilised the Edi signal to act as a neural trigger to drive ventilatory support. RESULTS. The measurement of Edi was not associated with a difference in hospital mortality. There was a significant reduction in sedation use, muscle relaxation, ventilator days and ICU days in patients with a NAVA catheter (Fig. 1) . However, there was no significant difference in any of these parameters with Edi measurement guiding conventional pressure support versus NAVA. Ventilator days in NAVA versus pressure support CONCLUSIONS. In this study we show that neurally adjusted ventilatory assist can be safely and effectively be introduced into a 'non-expert' intensive care unit. We further show that reductions in sedation use and ventilator days appear to be related to the earlier introduction of sedation holds and reductions in ventilatory assist (with consequent earlier spontaneous breathing trials) in order to acquire an Edi signal rather than due to an intrinsic advantage gained by improved patient-ventilator synchronisation with NAVA. The causes of the respiratory failure were: infections n = 8; 47.05% (immunodeficiency n = 3, tuberculosis n = 1, aplastic anemia n = 1, congenital cardiomyopathy n = 2, sepsis n = 1), RSV infection-bronchiolitis n = 3; 17.64%, bronchopulmonary dysplasias n = 3; 17.64%, leukemias n = 2; 11.76%, burn-ARDS n = 1; 5.88%. The mean duration of HFOV was 3.2 days (12 h to 10 days). The parameters of ventillation ranged: FiO 2 : 100-50%, mean pressure: 22-29 cmH 2 O, DP:45-75 cmH 2 O. The I time and Hertzs ranged within the acceptable for age limits. Closed suction circuit was used. We didn't notice any side effects from cardiovascular system or distension of the thorax. EAdi and respiratory effort indices decrease when assistance increases in NAVA. NAVA should also theoretically allow perfect synchronization between the patient and the ventilator, and no asynchrony has been described with this mode. NAVA level adjustment at bedside, however, is still a matter of research. We assessed breathing pattern, respiratory effort indices, and patient-ventilator synchronization throughout a titration of NAVA and of pressure support ventilation (PSV). We assessed breathing pattern, respiratory effort indices, and patient-ventilator synchronization throughout a titration of NAVA and of pressure support ventilation (PSV). METHODS. Physiological study conducted in seven patients (preliminary results) during the weaning. Airway pressure (Paw) and flow, esophageal and gastric pressures and the EAdi were continuously recorded. For each patient, the following levels of assistance were consecutively applied: in PSV: 7-10-15-20-25 cmH 2 O; in NAVA: 0.5-1-1.5-2-2.5-3-4-5-7 cmH 2 O/mvolt. Results are given as median and [25th-75th percentiles], and tidal volume (Vt) in ml/kg of predicted body weight. RESULTS. The increase from the lower to the higher level of assistance was associated with an increase in Vt from 6.7 [5.8-7 .0] to 9. 4 [8.4-11.3] ml/kg in PSV and from 6.7 [6.2-8.7 ] to 8.7 [7.7-11.8] OBJECTIVES. We describe technical possibilities, tolerance and gas exchange with combination of oscillation device with NIMV. A specific Oscillator device (Sensor Medics, Vyasis) was selected to change conventional airflow to oscillatory airflow. Connected by ''T'' piece with oscillatory devicerespiratory circuit-face mask. We selected BiPAP ventilator (Vision Resp Inc), facial mask. BiPAP mode (IAP/EPAP cmH 2 O) to achieve stable mechanical ventilation (T1). A progressive increment in rate of oscillation (HZ) and power oscillation to achieve airflow change (T2).  To evaluate the differences of PEEPi during the release phase, referred to mechanical pressure release from P high to P low , and the inspiratory work of breathing (WOB) during P high among currently available APRV ventilators, using a lung model (TTl1600, MI). METHODS. The six APRV ventilators were evaluated in this study: 1) Nellcor Puritan-Bennett 840 (Puritan-Bennett), 2) Evita XL (Drager), 3) Servo I (MAQUET), 4) Avea (VIASYS), 5) G5 (Hamilton) and 6) Engstrom (GE healthcare). Ventilator settings in APRV ventilators were set as follows: P high /P low 25 cmH 2 O/0 cmH 2 O, T high /T low 4.5 s/0.5 s. When evaluated PEEPi during the release phase, T low was diminished by steps of 0.1 s from 1.0 to 0.2 s. The inspiratory pressure-time product (PTP), as an index of WOB, was directly measured under with tidal volume/respiratory rate of 300 ml and 30/min. Measurement for each setting was performed in a random order. Three breaths were analyzed and averaged for each measurement. The results are shown in Fig. 1 OBJECTIVES. To perform bench study to test the hypothesis that ETT or TRACH can reduce the insufflated (VTI) and/or exsufflated (VTE) volume as provided by Coflator Ò . METHODS. Coflator Ò is connected to a pneumatic model (TTL, Michigan Instruments) via ETT Mallinckrodt 6.5, 7.0, 7.5, 8.0, 8.5) or TRACH (Mallinckrodt 6.0, 7.0, 8.0) . The set up is tested in 4 conditions of compliance (C ml/cmH 2 O) and resistance (R cmH 2 O/L/s): C30R0, C30R5, C60R0, C60R5. The device is set in manual mode, at the highest inspiratory flow, inspiratory/expiratory time 3/1, 1 s pause after expiration. Three pressures are used, 30, 40 and 50 cmH 2 O in both inflation and deflation. A baseline condition without any tracheal prothesis nor R served as reference. Airflow and pressure upstream ETT or TRACH are measured (BioPac MP150). Five insufflations followed each by an exsufflation are performed in each condition. The data are analyzed by using a linear mixed effects model where ETT or TRACH, and pressure have fixed effects and C or R a random effect. The dependent variable is VTI and VTE. The main end-point is the slope of the relationships between VTI or VTE and pressure. RESULTS. The VTI-pressure slope was significantly lower with any ETT than baseline at both C ( Fig. 1A and B). The same was true for TRACH. Even though these differences were statistically significant the reduction in VTI from the baseline averaged 160 ml with ETTs as a whole. The VTE-pressure relationships were similar for ETT and TRACH and showed no difference from baseline at C 30 ( Figure 1D ). However, at C60, the relationships are scattered ( Figure 1C ). Moreover, expiratory pressure of -40 and -50 cmH 2 O were not reached for ETT 6.0, 8.0 and 8.5 and TRACH 7.0 and 8.0. CONCLUSIONS. ETT and TRACH slightly but significantly change the performance of the device. However, small sized ETT or TRACH in C60 condition substantially modify the efficacy of the exsufflation. These findings desserves assessment in patients for relevance. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 S109 Though humidified high flow nasal canula oxygen (HFNC) has been widely studied in pediatric population, few data in adult is available and its and its precise indications and actual benefits in these patients remains unknown. Two studies have shown that HFNC generates a low level of positive airway pressure contributing to decrease the work of breathing. One study has reported a favourable effect on comfort and oxygenation of HFNC as compared to Venturi mask and in another preliminary one, fewer patients using HFNC went on requiring non invasive ventilation. OBJECTIVES. To evaluate the efficiency of HFNC (Optiflow, Fisher and Paykel, Auckland) in critical care patients with acute respiratory failure. METHODS. Prospective single centre study in a university hospital intensive care unit. All patients exhibiting acute respiratory failure (ARF) as defined by clinical signs and/or failure of haematosis, regardless of the aetiology, were eligible. HFNC was used at a mean output of 48 ± 9 L/min and a mean FiO 2 of 80 ± 20% throughout the study period. RESULTS. Thirty-five patients were included. The mean age was 50.4 ± 16.5 years old and mean SAPS II is 35 ± 11. Pulmonary infection was the most common aetiology of ARF. HFNC was used 2 ± 2 days. All but one patient were discharged alive from ICU. Optiflow significantly reduced respiratory rate (p \ 0.0001), heart rate (p \ 0.0001), dyspnea score (p = 0.015), sus clavicular recession and thoraco abdominal asynchrony, and improved pulse oxymetry (p = 0.009). There was no significant difference in pH, PaO 2 , PaCO 2 on arterial blood gazes performed before and 1, 12 and 24 h after HFNC use. The PaO 2 /FiO 2 ratio at 1 and 12 h after HFNC initiation was higher than before use of HFNC (p = 0.03). Patients ultimately intubated exhibited a higher respiratory rate 30 min (29.9 ± 3.4 vs. 23.5 ± 5 bpm, p = 0.004) and 45 min (  With an incidence of up to 60% in routine sonography [1] , pleural effusion is one of the most common complications in intensive care patients. The use of bedside 2D ultra-sound to detect pleural effusion is fast, practicable and minimises radiation exposure [2] . However, sonographical volumetry tends to be imprecise, and CT imagingbased volumetry is the more accurate method to quantify pleural fluid in intensive care patients [3] . OBJECTIVES. The aim of this study was to compare the accuracy of 3D and 2D ultra-sound volumetry of pleural effusion in intensive care patients. METHODS. 16 ICU patients designated for thoracentesis because of radiological support for pleural effusion were examined both with 2D and 3D ultra-sound \6 h before and after the intervention. Effusion volume was calculated with the formula ''Volume [ml] = Sep [mm] 9 20'' [4] for 2D measurements and compared to the 3D volumetry by the GE 4D View software. The difference of volumetry before and after intervention was compared to punctured volume (gold standard). The device used for u-sound measurements was the GE Voluson I. . Within the group under survey (n = 16), eight patients were on the respirator. Mean punctured volume was 605 ml (350 ml; 850 ml). Mean absolute value of deviation from punctured volume (gold standard) was 191 ml (28.1%) for the 2D measurements and 18 ml (6%) for 3D measurements. Biggest difference between methods was found between 500 ml and 700 ml punctured volume. None of the methods generally measures higher volumes than the other. CONCLUSIONS. The size of deviations from gold standard in both directions in 2D measurements suggests that the method is not reliable in predicting pleural effusion volume. 3D measurements are more likely to predict the right effusion volume, making the method a better diagnostic tool than 2D u-sound measurements. Although thoracocentesis was found to be safe for mechanically ventilated patients [1] and 3D volumetry may not change the therapeutic decision, which depends on high-risk patients' overall clinical condition, it could nevertheless help to avoid unnecessary interventions and thus improve patient safety. Ongoing work analyses results for a group of patients with CT imaging-based volumetry of pleural effusion as gold standard.  We study the utility of deltaCVP changes during pressure support ventilation (PSV) as an indication of respiratory effort. Patients after several T-trials failures were on PSV. The level of ventilatory assistance was changed in order to set the PSV. No aditional interventión was used in the management of these patients. We registered data from the ventilator and beside monitor (Vt, RR, P01, deltaCVP) in two levels of PS. Optimal-PS, as the lowest support without respiratory distress and with the middle of this level 50-PSV. The inspiratory trigger was used with the highest sensibility without autotrigger, the inspiratory ramp was changed in every patient and expiratory was flow-cycled at 25% of the peak inspiratory flow. RESULTS. 14 patients n, 2 acute on chronic respiratory failure, n, 6 heart failure, n, 6 recovery of acute respiratory failure. Age 67 ± 14 years, admission APACHE II 24 ± 6 and they needed weaning with PS after 10 ± 8 days with control mechanical ventilation. The respiratory mechanics in this time were Cst.rs 35 ± 11 ml/cmH 2 O and Raw.rs 12 ± 7 cmH 2 O/l/s. The Ramsay score was 3 ± 1 (2) (3) (4) (5) (6) . When the optimal level of PS was decreased from 12 ± 4 to 6 ± 2 cmH 2 O, all patients showed respiratory distress, and the variables studied changed significantly: P01: 1.5 ± 0.8 to 2.6 ± 0.9 cmH 2 O, deltaCVP 6.2 ± 2.2 to 9.8 ± 3.8 cmH 2 O, Vt decreased from 0.534 ± 0.181 to 0.419 ± 0.148 l and RR increased from 19 ± 4 to 22 ± 5 bpm (p \ 0.001). The correlation between P01 and del-taCVP was 0.6 (p = 0.02). Central venous pressure swing provided information about the respiratory effort and may be useful during pressure support ventilation. INTRODUCTION. The use of a tidal volume of 6 ml/kg of predicted body weight is part of the management of patients presenting with ARDS (1) and prevents ventilator induced lung injury in ICU patients undergoing mechanical ventilation (2) . The setting of tidal volume is based on patient height. Height seems to be more often estimated by the ICU staff than actually measured (3). OBJECTIVES. Our study aimed to assess the accuracy of the visual estimation of patient height and its impact on ventilator settings. Thirty-two patients admitted to a surgical ICU were prospectively included in this observational study. Patients had their height visually estimated by 18 ICU staff members (6 doctors, 6 nurses and 6 nurse-assistants) and then measured. We also measured the knee height from which height can be extrapolated. We then compared the mean estimated height for each patient to the actual measured height with the use of Bland and Altman plots and the consequences of the measurement error on the tidal volume setting. In most patients visual estimation overestimates the actual height. The measurement errors result in an increase in the tidal volume up to +2 ml/kg. This remains true whatever the subgroup studied: all patients (bias: 4.5 ± 5.52, 95% CI: -6.32;15.32), male patients (bias: 4.02 ±6.29, 95% CI -8.3;16.35), female patients (bias: 5.5 ± 2.29, 95% CI 1.01-9.99) and whatever the type of assessor. Extrapolated height from knee height results invariably in an underestimation of actual height (bias -1 ± 4.5, 95% CI -11.68; 9.68). Our results prove that neither visual estimation nor knee height measurement are reliable surrogates for measured height. Therefore, measuring patient height should be mandatory in critically ill patients in order to minimise ventilator-induced lung injury. METHODS. 3,016 respiratory acts were recorded in 4 ICU patients selected because of severe asynchrony with the ventilator (G5, Hamilton Medical) during PSV. By visual analysis (VA) of airway pressure and flow trajectory, ineffective efforts and inspiratory/expiratory delays were detected. The results of VA were compared with those provided by a new algorithm based on the automatic analysis (AA) of flow trajectory. RESULTS. VA identified 773 ineffective efforts (26% of patients acts). Among 2,243 assisted acts, average inspiratory and expiratory delay was 380 ± 214 ms and 134 ± 215 ms, respectively. Significant inspiratory and expiratory delay ([300 ms) occurred in 1,255 (56%) and in 422 acts (19%), respectively. Automatic analysis was able to identify 2,994 of 3,016 patients acts (99%). In 2,656 cases (88%), both inspiratory muscles contraction and relaxation were detected. In 338 acts (11%) only relaxation was identified. Compared with VA, inspiratory and expiratory delay of AA was 138 ± 134 and 29 ± 208 ms, respectively. AA recognized the start and the end of patient's effort before the ventilator in 2,142 (95%) and 1,477 (66%) of assisted acts. Sensitivity and Specificity of AA in detecting ineffective efforts, inspiratory delays [300 ms, expiratory delays [300 ms were 99 and 98%, 78 and 85%, 81 and 87% respectively. The new algorithm proved to be efficient as a real-time, continuous monitoring system of patient-ventilator interaction. The advantage over traditional flow and pressure based triggers has to be tested. INTRODUCTION. Mechanical ventilation remains as one of the most difficult safety issues in the ICU, but parameters commonly monitored by ventilators only depict the most extreme risks for patients. New computerized approaches may manage exhaustive data and may include ''intelligent'' software that mirrors expert decision making. To test the clinical usefulness of a new computerized system as a herald for clinically significant alarms and its possible impact in outcome. METHODS. Twenty-five mechanically ventilated patients were continuously monitored in a single mixed ICU in a university-affiliated hospital. We recorded age, diagnosis, PaO 2 /FiO 2 , APACHE II and SOFA on admission. The computerized system grabs and process data from different devices, usually a monitor and a respirator, and evaluates the most relevant events in a ventilated patient. All the algorithms were designed and validated with the clinical staff. Data of ventilated patients were recorded at the ICU during 8 months and a total of 4,615,589 breaths from 25 different patients, each of them with a register of at least 50% of total ventilation time, were collected. Data include biomedical signals (waves and trends) as well as all the clinical events detected by the system, including trapped gas at end-expiration, presence of secretions, double-cycling, asynchronies during expiration, pulse pressure variation in patients not triggering the ventilator and stress index ([1.2 or \0.8) in those ventilated with square airflow. Outcome variables were ICU length of stay, hospital stay and mortality. Statistical analysis included multiple regression models for length of stay and mortality. [4] [5] [6] [7] [8] [9] [10] , ICU length of stay 11.5 days [7.5-18] , hospital length of stay 21 days . The frequency of alarms were: trapped gas at end-expiration: 20.7%, presence of secretions 1.3%, double-cycling 1.1%, asynchronies during expiration 5.2%, stress index [1.2 1.1%, stress index \0.8 2.5%, and pulse pressure variation 5.1%. Multiple regression analysis found PaO 2 /FiO 2 associated with length of MV and close to significance with hospital stay and mortality, but any of the computerized alarms reached yet the level of significance. CONCLUSIONS. The computerized system is able to detect and review more clinically significant problems than clinical routine. However, its impact to define patient outcomes warrants further investigation. OBJECTIVES. We have assessed the ability of the ventilator T-bird VS02 and LTV-1000 to deliver to a lung model with ARDS a set tidal volume (Vt) at different simulated altitudes. We used a decompression chamber to mimic the hypobaric environment at a range of simulated cabin altitudes of 1,500, 2,500 and 3,000 m (4,000, 6,670, 8,000 feet). Ventilators were tested with realistic parameters. Vt was set at 400 and 250 ml in an ARDS lung model. The positive end expiratory pressures (PEEP) were set at 10 and 15 cmH 2 O. Pressure drop across the pneumotachograph was measured by a differential pressure transducer (Enertec TM ). The spirometer was checked at each altitude using a calibration syringe. The inspired oxygen content (FiO 2 ) was 100%. Respiratory rate was 20 breaths/min. The ratio inspiratory time/expiratory time was 1/1. The protocol included three measurements for each simulated altitude. Comparisons of preset to actual measured values were accomplished using a t test for each altitude. A significant difference was defined by p \ 0.05. The standard deviation for the three measurements obtained at each altitude was consistently less than 10 ml. Respiratory rate delivered was 20 breaths/min in all cases. Variation of PEEP did not change the volume delivered. The T-bird VS02 showed a decrease in volume delivered. Comparisons of actual delivered Vt and set Vt demonstrated a significant difference starting at 1,500 m for a Vt set of 400 ml, at 2,500 m for Vt set of 250 ml. At these altitudes, the variations between Vt set and delivered were more than 10%. With decreasing barometric pressure, the LTV-1000 showed mostly an increase in volume delivered. Comparisons of actual delivered Vt and set Vt demonstrated a significant difference at 2,500 m for a Vt set of 400 ml, at 3,000 m for Vt set of 250 ml. The delivered tidal volume remained within 10% of the set Vt. Assuming that the patient is ventilated at sea level and gas exchange is normal, the movement to altitude would result in an increase in tidal volume which might in fact represent a clinical event. CONCLUSIONS. The LTV-1000 met the trial targets in all settings, whereas the T-bird-VSO2 did not compensate well for altitude and progressively delivered lower volumes as barometric pressure decreased. Such variations between delivered and set Vt suggest lack of efficacy of altimetric correction in hypobaric conditions in some devices. The LTV1000 showed a moderate increase in volume delivered for ARDS lung model with increasing altitude, but maintained the delivered volume within 10% of the set Vt up to 3,000 m. The accuracy of the Vt delivery was superior with the LTV-1000 than with the T-birdVSO2.  Oxygen therapy is commonly used to correct residual oxygenation impairment in the post-extubation period. This is usually done through a Venturi mask which allows to deliver predetermined fractions of oxygen humidified with bubble humidifiers. The low humidity delivered by such devices and the use of an oro-nasal mask may, however, reduce patient's comfort, possibly resulting in mask displacement or removal and consequent oxygen desaturations. Nasal high-flow (NHF) oxygen therapy allows to deliver high-flow oxygen, humidified with heated humidifiers and delivered through nasal cannulae, with the potential to improve comfort and efficacy. OBJECTIVES. In patients requiring oxygen therapy after extubation, we compared NHF vs. Venturi mask in terms of oxygenation and comfort. Patients who were mechanically ventilated for more than 24 h, passed a spontaneous breathing trial, and had PaO 2 /FiO 2 \ 300 at the end of the trial were randomized to receive oxygen with NHF or Venturi mask after extubation. Exclusion criteria were: tracheostomy, age \18, pregnancy, or anticipated need for noninvasive ventilation after extubation. In both groups, FiO 2 was set to obtain SpO 2 between 92 and 98% (88-95% in COPD patients). With NHF, flow rate was set at 50 L/min. Arterial blood gases, respiratory rate, and discomfort were assessed at 1, 3, 6, 12, 24, 36, and 48 h. Discomfort was assessed by asking patients to rate their discomfort with the used device by using a numerical scale from 0 (no discomfort) to 10 (maximum imaginable discomfort). Discomfort symptoms were also assessed for the dryness of the delivered oxygen (dryness of the mouth, throat, nose, difficulty to swallow and throat pain). Incidence of desaturations and interface displacement was also assessed. OBJECTIVES. To evaluate the optimal humidifier water temperature when using a helmet for noninvasive positive pressure ventilation. oxygen. Each was sequentially tested in the following order: using the helmet without humidification at ambient temperature, with humidification with unheated chamber water, and with humidification with the chamber water at 31, 34, and 37°C. At each setting, after a 20 min stabilization period, measurements were taken. Comfort level at each setting was evaluated using a visual analog scale (VAS) rated zero (most comfortable) to ten (least comfortable). Temperature and relative and absolute humidity inside the helmet, and VAS scores statistically significantly increased as the humidification chamber water temperature increased. The lowest VAS, 1.6 ± 0.8, was obtained when water in the humidifier chamber was at ambient temperature. CONCLUSIONS. For patient comfort during CPAP using a helmet, the most desirable conditions are likely to obtained by humidifying without heating, that is by leaving the water in the humidifier chamber at room temperature. INTRODUCTION. The physiological and clinical effects of non-invasive ventilation (NIV) on acute post-operative respiratory failure are relatively unknown. The aim of this study was to determine the prediction factors for failure in the use of NIV with a helmet in this context. The use of NIV was assessed for a period of 2 years, in a post-operative intensive care unit (ICU). Demographic data was collected, as well as ARF and arterial gas readings. Haemodynamic changes were assessed using PiCCO TM technology and the clinical development of patients was recorded. All patients who developed acute respiratory failure (ARF) were treated using NIV as their primary care, and the two groups for the study were determined in this way, depending on whether the technique was successful, or the patients required intubation. The risk factors that determined failure in the application of NIV were subsequently determined. Of the 56 patients presenting with post-operative ARF treated with NIV using a helmet, 41 did not require intubation (73.2%). Following a multivariate analysis using logistic regression, we determined that there are four independent risk factors for the failure of NIV. The primary causes of respiratory failure are as follows: acute respiratory distress syndrome (ARDS) and PNEUMONIA, and in second place, the high initial EVLWI (extravascular lung water index) value, as a protective factor, is the increase in the pO 2 /FiO 2 ratio after the first hour of NIV application. CONCLUSIONS. NIV using a helmet could provide an effective alternative to conventional ventilation in selected patients with post-operative ARF. -Jaber S, Delay OBJECTIVES. Analyze NIV practice in emergency departments. We have development an international epidemiology survey (March 2009) by electronic questionnaire to know NIV organization, equipment and training in emergency departments (Phase I). DESIGN. International multicenter prospective. We have enrolled information from 57 hospitals: Spain (42); Italy (2); India (1); USA (3); Slovakia (1); Turkey (1); Germany (2); Australia(2); Chile (1); Singapore (1); Finland (1) during to analyze noninvasive practice in prehospital and emergency medicine, equipment, interfase, ventilatory modes and common clinical applications. Major results during 1 month period analysis were: noninvasive mechanical ventilation were applied in prehospital: 3 (57) (5.2%). NIMV commonly was applied follow a objective pprotocol of NIMV: (54) (57) (94.7%). Global rate indication of NIV were COPD exacerbation (90%) and cardiac pulmonary edema (10-60%). All NIV applications were successful applications in emergency departments (avoid ETI 80%) with minor complications (12.2%) (skin nose lesion). Equipment more relavant were (CPAP devices (60%) and facial mask (90%) was more frequent, follow total face(5%); nasal mask (3%); helmet (2%); type ventilary mode: cpap ventilatory mode was frequent used as first line (60% (1) suggest NIV should be started within 1 h of not responding to the maximal medical therapy for acute type 2 respiratory failure patients. Following an earlier audit presented as an abstract at ESICM 2008 (2) , which looked at possible delays in starting NIV, protocols were implemented to start NIV earlier at Russells Hall hospital acute admissions unit. OBJECTIVE. The aim was to assess the delays in starting the appropriate patients on NIV at admission looking at impact on adverse outcomes. METHOD. Data was collected retrospectively using BTS NIV audit tool. 54 cases admitted with type 2 respiratory failure in our hospital between January and March 2010 who needed NIV were included in the audit. Delay was subdivided into a) door to first arterial blood gas (ABG) sampling b) ABG to decision for NIV and c) from decision to actual starting of NIV. RESULTS. The mean time to get an ABG from admission was 180 min. 6 cases with delay more than 10 h skewed the data. The median time, which was more representative of the usual delay between admission and first ABG, was 51 min. Our audit showed that 28 out of 54 (52%) patients had ABG within an hour compared to 11 out of 19 (58%) in the last audit.  Although noninvasive ventilation (NIV) has been widely used in patients with acute on chronic respiratory failure (ACRF) due to chronic obstructive pulmonary disease (COPD), series studying patients with pulmonary restriction due to morbid obesity (MO) are rare (1) , despite the disease is highly prevalent in our environment. OBJECTIVES. The aim of our study is to analyze and compare the effectiveness of NIV in patients with COPD and OM. We analyzed all patients admitted to ICU for a period of 14 years with diagnosis of ACRF due to COPD or MO and treated with noninvasive ventilation. NIV success was defined as the avoidance of endotracheal intubation, survival in ICU and at least 24 h on a medical ward with no signs or symptoms of respiratory failure. Variables are expressed as means ± standard deviation and percentages. Comparison between variables by Pearson's v 2 test and Student t. We analyzed survival and hospital readmission per year (log Rank test). During the study period, 475 patients were admitted with exacerbation of COPD and 160 with MO. All patients were treated with two levels of pressure. Age differs between COPD and OM, 70 ± 10 and 73 ± 11 years, respectively (p = 0.003), as well as the percentage of men, 87. 6 Adaptive support Ventilation (ASV) Ò (Hamilton Galileo) has been shown to result in better patient synchrony, reduced weaning times and reduced work load for the ICU staff (1, 2) . But, data is lacking on its efficacy, especially as Non invasive ventilation (NIV) due to the concern of being closed loop ventilation. Also, little is known about the risk factors of late NIV failure in patients who improve initially ( OBJECTIVES. To assess end tidal CO 2 monitoring in patients with hypercapnic exacerbations of COPD requiring NIV METHODS. Simultaneous measurement of PaCO 2 and PETCO 2 was performed in 3 groups of patients. PaCO 2 was measured using arterial blood gas analysis and PETCO 2 was measured using non-invasive capnography. The groups were; Phase 1a: 20 mechanically ventilated patients post coronary artery bypass graft, used to establish the reliability of the end tidal carbon dioxide monitor in a homogenous group of previously well patients. Phase 1b: 5 patients with COPD who did not have symptoms associated with an exacerbation, used to assess the use of a non invasive sampling device and assess the sampling method in stable COPD patients. Phase 2: 28 patients with a hypercapnic exacerbation of COPD requiring NIV. Capnography was monitored continuously in this group and PETCO 2 values were calculated based on a mean value 1 min before and after the arterial blood gas sample. This was to avoid any sampling error as it was impossible to isolate the exact moment of arterial puncture. Agreement between the sampling methods was assessed using the Bland-Altman method. Phase 1a OBJECTIVES. We aimed to evaluate the possible harm of NIV failure in routine practice among Spanish ICUs. METHODS. We extracted patients with acute respiratory failure requiring either invasive or noninvasive mechanical ventilation in 32 Spanish ICUs during the 3-month period of the validation of the Sabadell Score (1). We recorded demographic parameters and treatments received during the ICU stay. Patients were followed until hospital discharge or death. RESULTS. We analyzed 4,132 patients, of whom 1,602 (39%) received only invasive mechanical ventilation (IMV) and 529 (13%) received NIV. NIV succeeded in 50% of patients, but the other 50% required intubation. NIV failure was more common in neurologic (70%) and post operatory (13%) and less frequent in coronary patients (11%). Mortality was lower than predicted in NIV patients (22 vs. 33%) and similar to predicted in IMV patients (27 vs. 29%). Mortality was lower than predicted in patients in whom NIV was successful (12 vs. 28%) and (similar or slightly lower than to predicted) in those in whom NIV failed (32 vs. 38%). CONCLUSIONS. Routine use of NIV seems to confer a benefit, even when it fails and intubation is needed. REFERENCE(S Tables 1 and 2 shows the parameters on respiratory muscles. INTRODUCTION. The effectiveness of non-invasive ventilation (NIV) in the setting of hypoxemia de novo remains controversial. It has been detected that patients in whom NIV fails and intubation is required have a high mortality. Otherwise, in patients in whom NIV avoids intubation, survival rate is also high. To identify the factors involved in success or failure of NIV in critically ill patients with hypoxemia de novo. We retrospectively studied all the patients admitted in our 26-bed intensive care unit (ICU) from January 2008 to December 2009 with the diagnosis of hypoxemia de novo. Do-notintubate patients were excluded. The indication of NIV was at medical discretion, as well as intubation criteria. We defined the hypoxemia de novo as acute non hypercapnic respiratory failure due to a different cause from cardiogenic pulmonary edema. We defined two groups of patients: 1) NIV failure, patients who required intubation, and 2) NIV success, patients who did not require intubation. We collected demographical variables (age and gender), etiology of the hypoxemia, severity scores on admission (SAPS II and SOFA), Glasgow Coma Scale (GCS), respiratory rate (RR), pulsioximetry (SpO 2 ), pH and FiO 2 , before and 2 h after starting NIV, episodes of nosocomial respiratory infection, length of stay (LOS) in ICU and ICU mortality. We compared both groups using the Mann-Whitney non-parametric test. P \ 0.05 was statistically significant. We studied 35 patients (12 women and 23 men) with a mean age of 65 ± 18 years. The etiology of respiratory failure was: ARDS (n = 12), pneumonia (n = 13) and others (n = 10). There were 20 patients in the NIV failure group (57%), and 15 in the NIV success group (43%). NIV failure rate was higher when hypoxemia was due to ARDS (P = \ 0.05). OBJECTIVES. This retrospective analysis aimed to assess outcomes following instigations of NIV in a variety of clinical conditions. Outcome data for COPD/APO and non-COPD/APO groups were compared. We assessed whether outcomes differed between these groups. In addition we wished to assess how outcomes varied across non-COPD, non-APO conditions. OBJECTIVES. The aim of this study was to compare patient's respiratory effort with three different noninvasive ventilators currently used on critical care patients and selected from a bench study. Six patients treated by NIV to prevent respiratory failure after extubation were included. Each subject was successively submitted to a randomly assigned 15 min-period of PS-NIV with three different ventilators: BiPAP Vision (Respironics), Elisée 250 (Resmed) and Oxylog 3000 (Dräger Medical). These ventilators have different performances in a bench comparison. Ventilatory settings were adjusted for the first ventilator and maintained for the followings. PS level was increased in order to obtain a tidal volume of 6-8 ml/kg of body weight (PS 9 ± 2 cmH 2 O). Flow, airway and oesophageal pressures were recorded. The oesophageal pressure time product (PTPoes) and tidal oesophageal swing (DPoes) were measured to evaluate patient's respiratory effort. RESULTS. No significant differences in tidal volume, respiratory rate and autoPEEP were found between ventilators. The DPoes and PTPoes, however, were significantly higher with Oxylog 3000 as compared to BiPAP Vision and Elisée 250, as expected from the bench comparison. There are limited data on NIV 0 s efficacy in hypoxic respiratory failure. OBJECTIVE. To investigate the epidemiology and outcomes of patients administered NIV as first line respiratory support in a mixed medical-surgical ICU over a 2 year period (Jan 2008-Dec 2009), in an academic medical center. METHODOLOGY. Data abstraction from ICU database, clinical care manager and chart review. RESULTS. 64 surgical patients (SP) and 260 medical patients (MP) were administered NIV. The SP were 58% male, and had a median age of 73 years. The MP were 56% male, and had a median age of 69 years. 42% of SP were admitted with type 1 respiratory failure (T1RF PaO 2 \ 9 kPa), 22% were admitted with type 2 respiratory failure (T2RF PaCO 2 [ 6 kPa) and the remainder were admitted with respiratory distress (RD). 34% of MP were admitted with T1RF (PaO 2 \ 9 kPa), 48% were admitted with T2RF (PaCO 2 [ 6 kPa) and the remainder were admitted with RD. The median length of stay (MLOS) was 3 days for SP (range 0-50); the MLOS for MP was 3 days (range 0-46). SP were commenced on NIV on average 1.52 h after admission (range 0-6 h), and remained on NIV for a median of 19.5 (range 1-304) h. 22% of surgical patients required intubation, and the mortality rate was 9.4%. MP were commenced on NIV on average 1 h after admission (range 0-6 h), and remained on NIV for a median of 20 (range 1-356) h. 30% of medical patients required intubation, and the mortality rate was 22%. Logistic regression was applied to all datasets. Among medical and surgical patients there was no correlation between the type of respiratory failure, initial blood gas or pH and the need for subsequent intubation, or risk of death. Hematology patients had a mortality rate of 65% and accounted for 16% of overall deaths. Oncology patients also had a 65% mortality rate, and accounted for 45% of overall deaths. Amongst the MP that presented with hypoxemia, the intubation rate was 29% and the mortality rate was 29% (although not all patients that died were intubated). Amongst the MP that presented with hypercarbia, the intubation rate was 24% and the mortality rate 13%. SUMMARY. NIV successfully prevented intubation in more than 70% of patients. Patients presenting with hypoxic respiratory failure were no more likely to be intubated than those presenting with hypercarbia. Two-thirds of hematology and oncology patients treated initially with NIV subsequently died.  A microdialysis system was composed and the time delay of the system, recovery time, was introduced and tested with a fluids switching method. Twelve SD rats were divided into IR or control group. Myocardial IR was induced by ligating (20 min) or releasing (60 min) the suture underlying LAD. Mycrodialyisis probe was implanted into the left ventricular myocardium perfusion area to be occluded. Dialysate samples were collected every 10 min. Blood samples were drawn at the beginning and at the end of the procedures. Dialysate calcium concentration ([Ca++]i) was detected with an atomic absorption spectrophotometer. Serum calcium and cTnT were detected. Recovery time for the microdialysis system was 20 min, recovery rate was 16%. [Ca++]i showed no changes during ischemia and descended immediately after reperfusion,reached the lowest level at 20 min after reperfusion, then escalated slowly while keeping lower than control with significant difference. There was no difference in serum calcium at the beginning ( OBJECTIVES. To evaluate the causes, incidence and impact on outcome of admission hyperlactatemia in patients admitted to a general MICU. METHODS. Data were retrospectively collected from the patient records for all adult patients admitted in the MICU during the 15-months period. Data regarding patient demographics, probable cause of hyperlactatemia, presence of shock on admission, need for organ support and ICU outcome were recorded. Patients were divided into two groups based on admission lactate levels: high lactate, with levels of 2 mmol/l or more and normal lactate, with levels less than 2 mmol/l. Patients in these two groups were compared in terms of need for organ support and ICU mortality. The efficacy to discriminate between survivors and non-survivors was assessed by Area Under the Receiver Operating Characteristic Curve (AUROC). INTRODUCTION. During critical illness alterations in blood flow are thought to predispose to organ dysfunction and hemodynamic therapy is often targeted at maintaining organ perfusion. However, abnormal blood flow distribution during critical illness may cause regional blood flows to correlate poorly with systemic haemodynamics (1) . Currently, our understanding of blood flow distribution during critical illness in humans has been limited by the invasiveness of established techniques for its measurement. OBJECTIVES. Phase-contrast MRI (PC MRI) represents an entirely non-invasive, contrastfree, method of measuring blood flow in major blood vessels (2, 3) . We sought to apply this technique to technique to the measurement of organ blood flow in the critically ill. In a pilot proof of concept study, we measured renal and portal blood flow by PC MRI critically ill humans with sepsis, multi-organ dysfunction and acute kidney injury (AKI). In 5 individuals cardiac output was measured by thermo-dilution in the ICU, in the remaining patients we measured cardiac output (ascending aortic flow) and also descending thoracic aortic blood flow using PC MRI techniques. We studied 10 critically ill individuals with severe sepsis and AKI. When studied, 8 were mechanically ventilated, 9 were on continuous haemofiltration and 5 required vasopressors. Transport and MRI examinations were carried out without complication. In these patients, median cardiac index was 3.5 L/min/m 2 (range 1.6-8.7), median renal blood flow 482 ml/min (335-1,137) and median renal fraction of cardiac output 7.1% (4.4-10.8). Median portal blood flow was 881 ml/min (550-1,800). Descending aortic blood flow (measured in 5 patients) ranged between 65 and 85% of cardiac output (median 75%). CONCLUSIONS. Phase-contrast MRI can efficiently and safely assess organ perfusion during critical illness in man. Near simultaneous measurement of cardiac output enables organ blood flow to be assessed in the context of the global circulation. Preliminary observations suggest renal blood flow is consistently reduced as a fraction of cardiac output in established AKI. PC MRI may be valuable to future investigation of organ dysfunction and vasoactive therapies in sepsis and critical illness. OBJECTIVES. We were interested in the effects of the higher pCO 2 -levels on the microcirculation of infants with birh weights \1,000 g. Data were collected from 12 infants, who were randomized either to treatment with permissive hypercapnia or normocapnia. Inclusion criteria were a birth weight between 400 and 1,000 g, a gestational age from 23rd to 28th+6 weeks, intubation during the first 24 h of life and no malformations. The pCO 2 target range was increased stepwise and was 15 mmHg higher in the intervention group. Skin microvascular parameters were assessed noninvasively with SDF on the right arm every 24 h during the first week of life and on the 14th day. RESULTS. pCO 2 (AUC: 639 ± 62 vs. 744 ± 62) differed significantly between the two groups (p = 0.004). Functional vessel density (FVD) was significantly lower in the intervention group on the 14th day of life (395 ± 43 vs. 281 ± 67 cm/cm 2 ; p = 0.04). The proportion of small vessels increased in the control group whereas they decreased slightly in the intervention group, but did not reach stat. sig. Increasing target pCO 2 lead to a temporary hyperdynamic flow in both groups. CONCLUSIONS. pCO 2 -levels influence significantly the microcirculation in preterm infants. Elevation of pCO 2 -levels leads to a decrease in FVD, presumably due to shunting and vasoconstriction and might cause temporarily hyperdynamic flow. METHODS. Blood from 6 healthy volunteers were diluted with HES, albumin 4%, RL or autologous plasma to obtain a final hematocrit of 30%. In vitro WBV measurements were made by the Rheolog TM device (Rheologics, Exton, PA), a new viscometer with a U-formed capillary. The flow rate (determined by the rate of change in height of the columns of blood) is directly related to the pressure drop across the capillary tube. The shear rate (from 1,000 to 1 s -1 ) and viscosity of the sample can be mathematically derived. Results were expressed as median values (with 25-75% intervals) and compared by ANOVA with Bonferroni correction. A p value \0.05 was considered as statistically significant. Hemodilution with RL and albumin decreased significantly the WBV for all shear rate compared with autologous plasma and HES ( Fig. 1 ). CONCLUSIONS. In contrast to albumin and Ringer's lactate, HES and autologous plasma increased the whole blood viscosity, suggesting that these solutions may be preferred in severe hemorrhagic shock to better preserve plasma viscosity and microcirculation.  We divided into two groups the randomly selected sample from the scope of patients come through open-heart operation assisted with extracorporeal support at the University of Pécs: therapeutic (continuous blood gas monitoring/CDI-500) and control (intermittent sampling) group. After the retrospective data collection we carry out the analysis with (prevalence) frequency and confidence interval calculation and Khi square test. RESULTS. The following accompanying diseases occurred significantly higher rate in the therapeutic group: AMI (p = 0.007), kidney disease (p = 0.009), chronic pulmonary disease (p = 0.001), and the aggregation of the accompanying diseases showed also significantly high degree (p = 0.001). The long interval operations occurred significantly higher rate (p = 0.036) in the therapeutic group, and the times of the aorta clinch (p = 0.025) and the perfusion (p = 0.001) was also significantly longer. Despite of that during the perfusion in a significantly more cases remained the rates in the normal range concerning to the therapeutic group (pH: p \ 0.001; BE: p \ 0.001; pCO 2 : p \ 0.001), and the prevalence of the restart of the heart showed also significantly higher rate (p = 0.005). The continuous blood gas analyses assure reliable and the postoperative recovery assisted ECC circulation support. This assists considerably for keeping the parameters in the physiological limits even in the higher rate of the incidences of complex operations and accompanying diseases. This could contribute to lower incidence of side effects, preventing the causeless elevation of the postoperative hospital charges. OBJECTIVES. Describe the changes in capillary perfusion after erythrocytapheresis during severe falciparum malaria. We report two cases of severe falciparum malaria and describe the evolution of the sublingual capillary perfusion after erytrocytapheresis. The sublingual microcirculation has been studied with Sidestream dark-field imaging (MicroScan; MicrovisonMedical TM , Amsterdam). The device was applied on the lateral side of the tongue and the video images (2-3 captures of 5-12 s.) of capillary perfusion were recorded. The microcirculatory scores were analysed offline: small vessels (\20 lm) density (number of vessels/mm), percent of continuously perfused small vessels (PPV%) and Mean Flow Index (MFI). 2 mmol/l. The capillary perfusion has improved: capillary density increased (13.6/mm), the proportion of perfused vessel increased (87%) and flow was continuous in most vessels (MFI: 3). Clinical evolution was rapidly favourable and the patient was discharged from the intensive care unit. Case 2. Severe falciparum malaria with high parasitemia (24%) and acute renal failure. Before erythracytapheresis: Macrohemodynamic parameters were normal but microcirculation was reduced: vessels density (14.6/mm) with 71% of small vessels perfused and the flow was slow in most vessels (MFI: 2.16). After erythracytapheresis: Parasitemia decreased (7.9%). Sublingual microcirculation has improved with an increase in small vessels density (18.1/mm) among which 93.6% were perfused with a continuous flow (MFI: 3). The patient had a good outcome. CONCLUSIONS. Microcirculation monitoring should be assessed specifically in some critically ill patients, even if macrocirculatory parameters are in the normal range. During severe Plasmodium falciparum malaria, this monitoring could be specifically important to assess the effect of erytrocytapheresis therapy on tissue perfusion. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 S117 OBJECTIVE. Perioperative Myocardial Infarction (poMI) is associated with significant mortality and morbidity in cardiac surgery. The primary objective of this prospective multicenter study is to investigate whether monitoring of coronary sinus metabolic markers can reliably predict ischemia and poMI faster than conventional monitoring. METHOD. 50 Patients undergoing cardiac surgery were monitored perioperatively using a transjugular implanted microdialysis catheter (CMA Microdialysis) to study the metabolic changes of the heart. Coronary sinus (SC) samples of Lactate, Pyruvate and Glycerol were obtained continuously through 24-h post-operatively. poMI was defined by CKMB C 100 U/ L and Troponin T C 1.0 lg/L. A total of 5 patients met the criteria for poMI. 14 patients showed at least one adverse event during the postoperative course. Lactate, Lactate-Pyruvate-ratio and glycerol levels in the SC sharply increased up to 12 h before rise of cardiac enzymes. Analyses of regression and discriminate analyses showed statistically significant (p \ 0.05) relationships between elevated metabolite values and the occurence of poMI. ROC analysis revealed that Lactate, LP-ratio and Glycerol from the SC are sensitive markers to predict poMI and postoperative clinical events. CONCLUSIONS. Coronary sinus metabolic markers are sensitive and early predictors for the detection of perioperative myocardial infarction and severe complications in patients undergoing cardiac surgery. Beginning disorder can be detected far earlier than with any existing monitoring device.  Perioperative red blood cell transfusions (BTX) are commonly used in patients undergoing cardiac surgery to correct for anemic conditions caused by blood loss and hemodilution associated with cardiopulmonary bypass circulation and anesthesiological procedures. However, several studies have shown BTX might have adverse effects on patient outcome. The goal of BTX is to correct anemia and to ensure an improvement in the oxygen delivery to the parenchymal cells by the increased presence of red blood cells in the microcirculation. The aim of this investigation was to test the hypothesis that BTX during onpump cardiac surgery have a beneficial effect on sublingual microcirculatory perfused vessel density, and oxygenation. METHODS. 24 adult patients undergoing on-pump cardiac surgery were selected for this study. Sublingual microvascular flow index (MFI), detected vessel length (DVL), and functional capillary density (FCD) were assessed using sidestream dark-field (SDF) imaging in 12 patients. Sublingual reflectance spectrophotometry was applied in 12 patients to monitor sublingual tissue oxygen saturation. In group A, BTX resulted in increased FCD and DVL as depicted in Fig. 1 . MFI for small and medium microvessels was not affected by BTX (Fig. 2 ). In group B, reflectance spectrophotometry demonstrated increases in microcirculatory hemoglobin and oxygen saturation ( Fig. 3 ). The main findings suggest that leukoreduced BTX improves the systemic circulation and oxygen carrying capacity of the microcirculation by increasing FCD and thereby reducing diffusion distances without increasing significantly the convection of red blood cells. This reduction in diffusion distances causes an increase in microcirculatory oxygen saturation. D.M.J. Milstein 1 , K. Yürük 1 , R. Bezemer 1 , C. Ince 1 1 Academic Medical Center at the University of Amsterdam, Translational Physiology, Amsterdam, Netherlands AIMS. Anemia is a common adverse effect of oncologic diseases as is the therapeutic options required for their treatment. However, as blood transfusions are directed at correcting for anemia and intrinsic hypoxic conditions, little evidence exists claiming that blood transfusions have successfully resolved anemic challenges as storage can significantly deteriorate RBC function. The aim of this study was to investigate the influence of RBC transfusions on sublingual microcirculatory perfusion and tissue oxygenation in anemic oncology patients. METHODS. Eight consecutive ambulatory patients scheduled to receive 3 packed RBC transfusion bags were selected for this study. Baseline sublingual microcirculation functional capillary density (FCD) was measured using sidestream dark-field (SDF) imaging prior to and after 30 min of the completion of the last infused blood bag. Sublingual mucosal oxygen saturation (StO 2 ) was measured at the same anatomical location and time points using near-infrared spectroscopy (NIRS). RESULTS. Figures 1 and 2 Capillary refill time (CRT) is a generally accepted method of assessing the circulatory status of a patient. We have previously showed that using 4.5 s as the upper limit of normality in critically ill patients could discriminate patients with a more unfavourable outcome 1 . However, this upper limit of normality was defined based on variation of CRT in an adult healthy population 2 . The best CRT in critically ill patients, therefore, should still be redefined. OBJECTIVES. We aimed to define the best CRT as predictor of organic and metabolic dysfunction in an intensive care unit (ICU) population. METHODS. Capillary refill time was measured by applying firm pressure to the distal phalanx of the index finger for 15 s, and a chronometer recorded the time of returning to normal colour. We performed receiver operating characteristic curve (AUC) to detect the best CRT consistent with severe organ and metabolic dysfunction, as evaluated by Sequential Organ Failure Assessment (SOFA) [11 and acidosis (lactate [2 mmol/L and BE\ -3 mEq/ L), respectively. In addition, we performed logistic regression analysis using the cutoff CRT as binary to investigate its estimated odds ratio (Exp(B)). Of 170 patients included in the study (age 55±16; 125 male), 115 had circulatory shock, of whom 62 had septic shock. Mean CRT in all patients was 4.6 ± 2.2. Figures 1 and 2 show the ROC curve for SOFA score[11 and metabolic acidosis, respectively. Using the best CRT value, logistic analysis revelled the following estimated odds ratio: for SOFA score[11: Exp(B) = 6.8; P = 0.004); for metabolic acidosis (Exp(B) = 5.3; P = 0.001). ROC curve for CRT relative to SOFA score [11 ROC curve for CRT relative to acidosis CONCLUSIONS. We found that 5.5 s is the best time to define prolonged CRT in critically ill patients, and that using this CRT cutoff value could discriminate patients with a more severe organ and metabolic dysfunction. 1 INTRODUCTION. Impairment of microcirculation in acute situations is associated with organ failure and depends on macrocirculation but also on specific factors (1) . Micro-perfusion, assessed by tissue hemoglobin saturation (StO 2 measurement) or micro-blood flow (laser Doppler, LD) are easy to use and non invasive methods. The obtained data could be an end point in critical care resuscitation or optimization. OBJECTIVES. To assess the impact on microcirculation of cardiovascular (CV) support on the basis of mean arterial pressure (MAP) and cardiac output (CO), to evaluate when microcirculatory parameters improved or not the modifications observed in MAP and CO. METHODS. Observational study: measure of CO, MAP, SVCO 2 , and lactate, thenar NIRS (InSpectra 650; Hutchinson Technology) baseline StO 2 , with performance of an arterial occlusion test (3 mn, 300 mmHg) so calculate occlusion-OS and reperfusion slopes-RS (1). Similarly, forearm skin blood flow velocity (LD, BLF21D, Transonic Systems) basal LD, and post-ischemic peak velocity LDmax) (1) were measured. Data were collected before and after CV optimization (fluid loading, vasoactive or inotropic drugs). Patients were defined: macrocirculatory responders (R) when CO increased more than 10% versus nonresponders (NR); microcirculatory responders (RS+) when RS increased more than 10% versus nonresponders (RS-). Statistical analysis: nonparametric tests (Wilcoxon and Mann-Whitney test). RESULTS. 32 patients (86% in shock) were studied. 20 had sepsis (63%), 5 hemorrhage (16%), 4 pulmonary oedema (12%), or other (9%). 50 therapeutic optimization challenges were performed:40 fluid challenges (500 ml, 0.9% NaCl), 4 dobutamine 5c/kg/min, 3 nitrates, 1 diuretic, 1 electric shock and an increase in dosage of norepinephrine. In R group (n=28, 56%), CO was increased associated with MAP (p \ .0001), SVCO 2 (p = .001) and decreased lactate (p = .02). The micro-oxygenation improved with an increase of RS (2.55 [1.3-4.25] vs. 2.7 [1.6-3.9 ]%/s, p = .002) as microperfusion did: increase in LDmax (7.5[4.8-16.3] vs. 8.7 [6.9-16.3 ] TPU, p = .01). In the NR group, both the macro or the microcirculation did not change. Since no microcirculatory differences between R and NR were observed, patients with good or poor microcirculation could not be detected. The study based on microcirculatory responses showed 50% of responders (RS+). In this group, baseline StO 2 (p = .002), basal LD (p = .04) and LDmax (p = .01) increased in a large amount in association with an improved CO and MAP (p = .0076 and p = .0008). In the RS-group, CO and MAP were also improved (p = .0002 and p = .006). CONCLUSIONS. Improvement of macrocirculatory parameters can improve microcirculation but not in all patients. Improvement in microcirculation may also be a target, regardless the effects on macrocirculatory parameters. This concept has to be tested prospectively. INTRODUCTION. Hypothermia is regularly used for brain protection after resuscitation from cardiac arrest but its impact on cardiovascular function, however, is not well defined. OBJECTIVES. The aim of this study was to evaluate the cardiovascular response to mild therapeutic hypothermia and rewarming in a large animal model. Seven anesthetized, mechanically ventilated and invasively monitored sheep were cooled with a cold intravenous saline infusion, ice packs and nasal cooling (RhinoChill System, Benechill, CA) to achieve a core temperature of 34-35°C (the basal temperature in sheep is around 40°C). After maintenance of this temperature for 6 h, sheep were progressively rewarmed to baseline temperature. A positive fluid balance was maintained during the entire study period to avoid any hypovolemia. The sublingual microcirculation was observed using sidestream dark-field (SDF) videomicroscopy and the proportion of perfused vessels (PPV) and perfused vessel density (PVD) evaluated using a semi-quantitative method. RESULTS. During cooling, systemic and pulmonary artery pressures did not change, but cardiac output decreased significantly along with the increase in vascular resistance. Left and right ventricular stroke work index decreased reflecting altered ventricular function. Nevertheless, there was an increase in mixed venous oxygen saturation (SvO 2 ), reflecting a decrease in oxygen extraction. Sublingual microcirculation analysis showed a significant decrease in PPV and PVD. All the variables returned gradually to baseline during the rewarming phase. CONCLUSIONS. In this intact healthy large animal model, the alteration in cardiac function during hypothermia was well tolerated because of the simultaneous decrease in oxygen requirements. Arterial pressure was maintained by an increase in systemic vascular resistance associated with a reduction in peripheral microcirculatory density. GRANT ACKNOWLEDGMENT. *RhinoChill System was supplied by Benechill, Inc. OBJECTIVES. To evaluate consequences of hypoxemia occurence on intestinal microcirculatory perfusion in mice submitted to controlled hemorrhage. Tracheotomized and ventilated Balb/c mice were submitted to systemic hypoxemia (PaO 2 = 40 mmHg) during 1 h. Controlled hemorrhage to mean arterial pressure of 40 mmHg was associated (from 30th to 60th min). 4 groups were constituted: HH = hypoxia and hemorrhage, Hr = hemorrhage, Hx = hypoxia, CL = control (neither hypoxia nor hemorrhage). A segment of ileon was exteriorized through an abdominal midline incision. It was opened along the antimesenteric border and placed on a specially designed piedestal to facilitate observation of the villi with transilluminating and epifluorescent microscopy. The bowel segment was superfused with Krebs solution maintained at 37°C. Villous perfused density (Dvp), red blood cell velocity in villous tip arteriole (Vart) and villous capillaries (Vcap) were observed after FITC-labeled erythrocytes were intravenously administered. 6 mice were included in each group. Leucocytes adhesion to intestinal wall venules (20-40 lm) was observed in a separated set of experiments including also 6 mice per group. Number of adherent leucocytes (L adh ) and leucocytes flux (L fl ) were observed in each group. Measurements and arterial blood gases were collected at 0, 30, 60 min (T 60 ). Data were expressed as mean ± SEM and were compared by analysis of variance (ANOVA). INTRODUCTION. Despite remarkable progress in hemodynamic monitoring, clinical examination, assessment of peripheral perfusion and comparison of surface and body core temperature still are diagnostic cornerstones of critical care. Infrared non contact thermometers provide accurate measurement of body surface temperatures. The PiCCO device using an arterial line with a thermistor tip in the distal aorta-in addition to transpulmonary thermodilution (TPTD)-provides continuous body core temperature. OBJECTIVES. Therefore, it was the aim of our study to evaluate the predictive capabilities of surface temperatures and their differences to body core temperature regarding CI, SVRI and parameters of microcirculation. In 46 ICU-patients body core temperature was measured four times per day using a PiCCO-catheter (TP), a thermistor-tipped urinary catheter (TU) and an ear thermometer (TE) (Thermoscan; Braun). Additionally, surface temperatures were determined on the great toe, finger pad, forearm and forehead using an infrared non contact thermometer (Thermofocus; Tecnimed). Furthermore capillary refill time (CRT), lactate and ScVO 2 were measured and peripheral perfusion was clinically assessed (normal, pale, mottled). Immediately afterwards TPTD was performed to obtain CI and SVRI. Statistics: SPSS 18.0. Spearman correlation. Compared to TP, T forehead (-0.4 ± 0.89°), T forearm (-2.95 ± 1.42°), T finger pad (-5.66 ± 3.13°) and T toe (-7.02 ± 4.49°) were significantly lower (p \ 0.001 for all comparisons). In multivariate analysis TPTD-derived CI (4.09 ± 1.2 L/min sqm) was significantly correlated (R = 0.552) to the difference ''TP-T forearm '' (p \ 0.001), ''TP-T finger pad '' (p = 0.001), CRT (p = 0.004), ScVO 2 (p = 0.008) and MAP (p = 0.012). TPTD-derived SVRI was multivariately associated (R = 0.631) with ''TP-T forearm '' (p \ 0.001) and MAP (p \ 0.001). ScVO 2 was independently correlated to the difference ''TP-T finger pad '' (R = 0.429; p \ 0.001). Lactate was independently correlated (R = 0.302) to CRT (p \ 0.001). The ROC areas were 0.740 and 0.725 for (TP-T forearm ) and (TP-T finger pad ) to predict ''CI \ 2.5'' and ''ScVO 2 \ 70'', respectively. The sensitivity, specificity and negative predictive value of ''TP-T forearm [ 2.7°'' were 92, 52 and 98% regarding a CI \ 2.5 L/min/sqm. 1.) Measurement of surface temperatures using non contact infrared thermometers and comparison to body core temperature provides useful data on macro-and microcirculation. 2.) The differences (TP-T forearm ) and (TP-T finger pad ) were independently associated to TPTD-derived CI and SVRI, and CI and ScVO 2 , respectively. 3.) CRT was independently associated to lactate level. V. Shilov 1 , A. Astakhov 1 1 Ural State Postgraduate Medical Academy, Chelyabinsk, Russian Federation INTRODUCTION. Actuality of this problem consists of different disturbances of heart rhythm and heart conductivity (from sinual bradycardia and ventricular extrasystolia till sinuatrial arrest and fibrillation of ventricles) provoked by traction of oculomotorial muscles and pressure on eyeball. This reaction is called oculocardial reflex (OCR). It is necessary to note there is no definite strategy of OCR prevention. OBJECTIVES. This study was conducted to estimate the possibility of the control of haemodynamic effects of OCR. The haemodynamics and hydrobalance were investigated with electric current probe (28 and 115 kHz) using monitoring complex of cardiorespiratory system and hydratation of tissues -KM-AR-01 «Diamant». Data documentation was carried out at 6 stages of evisceroenucleation: 1. Before anesthesia and surgery; 2. at induction; 3. during the intubation; 4. at eyeball mobilization and oculomotorial muscles traction; 5. while deepening of endotracheal anesthesia by inhalative anesthetics during 5-10 min after preceding stage; 6. at the end of surgery, after the extubation. RESULTS. The study confirmed OCR reflex, to appear at eyeball extraction and to manifest as bradycardia, cardiac output decreasing heart productivity, but peripheric vessel resistansce does not change. Monitoring-controlled gradual deepening of inhalative anesthesia during 5-10 min has restored the haemodynamic data to normal eliminated OCR vessel reactions. Hydrostatic changes took place only at the end of the operation, after the extubation. It manifested ad increasing of extracellular liquid confirmed by decreasing of low-frequent impedance. Intracellular liquid remained intact. It seems the most possible, hydrostatic changes of extracellular liquid to depend on crystalloid infusion in blood vessels up to 1,000 ml during anesthesia and they eliminate with hypovolemia. CONCLUSIONS. Thus we can conclude that vascular manifestations of hemodynamics in OCR at eyeball extraction or active oculomotorial tractions may be eliminated with gradual deepening of inhalative anesthesia and monitoring of registed date of haemodynamic and hydrobalance. Probably it's necessary to optimige the anesthesia using of pterygopalatal and pterygoorbital blockade to prevent OCR before the induction as retrobulbal anesthesia may be an OCR trigger. F. Corradi 1 , C. Brusasco 1 , A. Vezzani 2 , F. Altomonte 3 , P. Moscatelli 3 1 University of Genoa, Anesthesia and Intensive Care, Genoa, Italy, 2 Ospedale Maggiore di Parma, Anesthesia and Intensive Care, Parma, Italy, 3 Azienda Ospedaliera Universitaria San Martino, Emergency Medicine, Genoa, Italy INTRODUCTION. Despite improvements in trauma care, uncontrolled bleeding is the leading cause of potentially preventable early in-hospital deaths contributing to 30 to 40% of trauma-related deaths (1) (2) . About 30% more deaths occur within the second/third hour after injury due to occult major internal haemorrhage. Failure to recognize this situation may in part be due to lack of sensitivity of Hb/Hct levels, arterial blood pressure, heart rate, respiratory rate, injury severity score and markers of hypoperfusion (lactate and base excess) in initial assessment of blood loss. To study if early changes in spleno-vascular resistance index predict the development of hypovolemic shock after trauma. A prospective observational study conducted in 40 adult haemodinamically stable patients admitted to the emergency department because of suspected or definite severe trauma and retrospectively divided into 2 groups depending on whether or not they developed haemorragic shock requiring blood transfusion. Doppler ultrasound measurements of splenic arterial branches at ilum were obtained and Splenic Doppler Resistance Index (SDRI) was recorded at admittance (within 1 h from trauma) and related to arterial blood gas analysis (haemoglobin, base deficit, lactate, CO 2 , pH), heart rate, and outcome in the first 24 h (intensive care unit admittance, blood transfusion, sepsis, mortality). RESULTS. Statistically significant differences between patients who developed shock within 24 h and those who did not were the following: higher SDRI (0.67 ± 0.12 vs. 0.52 ± 0.05, p \ 0.001), lower base deficit (-4.0 ± 4 vs. 0.1 ± 3 mEq/L, p = 0.001) and higher lactate (2.7 ± 1.2 mMol/L vs. 2 ± 1 mMol/L p = 0.015). AUC's of ROC analysis were significant for SDRI (AUC = 0.89, CI 0.73-1.05, p \ 0.001) and lactate (AUC = 0.76, CI = 0.55-0.96, p = 0.04), and borderline for BD, Hr, Hb, and pH. By multivariate analysis, SDRI at admittance resulted to be the only good independent predictor of hypovolemic shock and bleeding (p \ 0.001), whereas haemoglobin, base deficit, heart rate, lactate and pH were not significant. In trauma patients with stable haemodynamic conditions at admittance spleen constriction occurs very early under heavy adrenergic stimulation in response to occult bleeding and can be non-invasively detected by SDRI. The present study proposes SDRI as a non-invasive measurement of changes in splanchnic circulation to detect blood loss and occult hypovolemia, which may help activate early surgical or radiological intervention for patients with major trauma and guide therapy to optimize splanchnic perfusion. INTRODUCTION. Approximately 1% of patients require temporary circulatory support due to cardiogenic shock following cardiac surgery. These patients are at risk of a mismatch between oxygen delivery and demand and carry a substantial mortality and morbidity risk. Mixed venous oxygen saturation (SvO 2 ) is the still the ''gold standard'' for the determination of the ratio between systemic oxygen delivery and consumption (DO 2 /VO 2 ratio) in cardiac surgery patients. A nonivasive technique is thought to be cerebral near-infrared spectroscopy determining cerebral oxygen saturation (rSO 2 ). PURPOSE. The present analysis aims to compare rSO 2 and SvO 2 levels in adult patients undergoing ECMO therapy for postoperative cardiogenic shock. METHODS. Data were collected hourly for the first 24 h post operatively. Each patient was equipped with a pulmonary artery catheter (PAC) for continuous determination of SvO 2 connected to a Vigilance II-monitor (Edwards Lifesciences, Irvine, USA) and an INVOS 5100 monitoring system (Somanetics, Troy, USA) to determine rSO 2 . Data were analyzed by parametric testing and Bland-Altman analysis. A total of 10 patients were enclosed. All SvO 2 values were in a range between 47 and 86%. In this range, the linear correlation coefficient between SvO 2 and rSO 2 was r = 0.983 (p \ 0.0001). The correlation coefficient for SvO 2 values below 70% was r = 0.841 (p \ 0.0001) and r = 0.708 (p \ 0.0001) for SvO 2 levels equal or higher than 70%. Bland-Altmann analyses of all collected oxygenation data (n = 250) revealed a bias of 3.4% (mean 95% CI: 2.73 to 4.03) and limits of agreement (1.96 standard derivation) of 13.6 to -6.8% (upper 95% CI: 12.48 to 14.70; lower 95% CI -7.93 to -5.71) for the raw data of the whole group ( Figure 1 ). Bland-Altmann analyses of SvO 2 values below 70% (n = 105) showed a bias of 3.5% (mean 95% CI: 2.30 to 4.60) and limits of agreement (1.96 standard derivation) of 15.1 to -8.2% (upper 95% CI: 13.14 to 17.09; lower 95% CI -10.18 to -6.23). Bland-Altmann analyses of SvO 2 values equal or higher than 70% (n = 145) revealed a bias of -3.3% (mean 95% CI: 2.57 to 4.09) and limits of agreement (1.96 standard derivation) of 12.4 to -5.7% (upper 95% CI: 11.09 to 13.68; lower 95% CI -7.03 to -4.42). Interestingly, despite SvO 2 values [ 70%, we noticed 19 events in 4 patients with rSO 2 values less than 50% for more than 5 min. All events had been associated with arterial CO 2 levels below 30 mmHg, whereas no other changes in hemodynamic or oxygenation parameters could be determined. CONCLUSIONS. This pilot study suggest for the first time that rSO 2 highly correlates with SvO 2 in patients undergoing ECMO therapy due to refractory cardiac and/or pulmonary dysfunction. Therefore determining rSO 2 may be a noninvasive alternative to monitor global tissue oxygenation under this condition. Additionally, it was noted that cerebral hypoxia may be present despite a SvO 2 C 70 mmHg. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 RESULTS 1 : During severe hypothermia (25°C) cardiac index (CI), stroke index, mean arterial pressure and indexes of LV contractility (PRSW 2 and dP/dTmax) were reduced. After rewarming all variables remained reduced, except for CI that returned to prehypothermic values due to increased heart rate. Systemic vascular resistance (SVR), LV isovolumetric relaxation time (Tau) and oxygen content in arterial and mixed venous blood increased during 25°C, while LV end diastolic pressure (LVEDP) was constant. After rewarming SVR and LVEDP were reduced, while Tau and the blood oxygen contents normalized. Troponin-T and TNF-a were constant during 25°C but increased after rewarming. Albumine plasma concentration was reduced during 25°C and remained so after rewarming. CONCLUSIONS. Surface cooling to 25°C followed by rewarming caused reduction of systolic, but not diastolic LV function. There were no signs of inadequate global oxygenation throughout experiments. The posthypothermic increase in troponin-T may reflect degradation of myocyte troponins secondary to a hypothermia-induced calcium overload. The increase in tumour necrosis factor alpha together with a posthypothermic reduction of plasma albumin concentration may indicate that the cooling and rewarming initiated an inflammatory response.  We studied 41 patients, mean age 51.6 ± 10.2 years, 68% male. The etiology of cardiogenic shock was: 44% (n = 18) dilated cardiomyopathy, 37% (n = 15) acute myocardial infarction, 12% (n = 5) acute cardiac allograft rejection and 7% (n = 3) acute myocarditis. The duration of ECMO support was 118.8 ± 89.8 h. Weaning was possible in 22% (n = 9) and the ECMO was used as a bridge to transplantation in 51% (n = 21). 30-day survival was 60 and 58.5% of our serie were discharged from the hospital. In 7 cases the ECMO was withdrown as a result of a limiting treatment decision. OBJECTIVES. To describe the characteristics of patients with CA and its management with moderate hypothermia using Arctic Sun Ò device with hydrogel patches. Descriptive, observational and retrospective study of patients who suffered CA and received moderate therapeutic hypothermia (33°C) according to the protocol implemented in a coronary intensive care unit of a tertiary hospital. We collected patients from June 2009 to April 2010, first months of this therapy in our hospital. Moderate therapeutic hypothermia is applied using the Arctic Sun Ò device consisting of hydrogel patches applied to the skin covering 40% of the body surface. The device is connected to a temperature control console, measuring core temperature with an urinary catheter. We analyzed demographic characteristics, cardiovascular risk factors and other relevant comorbidities. We collected data about the CA, its initial treatment and its ICU management with moderate hypothermia, analyzing length of events and systemic and neurological outcome at discharge from ICU. We also collected data about the infectious complications during the ICU stay. RESULTS. During this period, moderate therapeutic hypothermia was applied to 14 patients with a mean age of 56 ± 14 years. 78.6% were male. The most frequent cardiovascular risk factor was cigarette smoking, present in 50% of individuals. The CA cause was an AMI by 70% of cases; however, myocardial infarction or angina was documented before the event only in 14.3% of patients. The CA event was outside the hospital in 78.6% of cases and the initial heart rate recorded was ventricular fibrillation in 64.3% of cases. The average CA length was 18.6 ± 8 min. Obtaining a temperature of 33°C took between 3 and 6 h from the CA in most cases; and this temperature was maintained for an average of 31 ± 6 h. The average time of induction of hypothermia was 2.5 h. The re-heating was performed between 0.3 to 0.5°C per hour, averaging 9 h to reach temperatures of 36.5°C. Midazolam sedation was performed in all patients and severe chills required muscle relaxation with cisatracurium in 71.4% of patients. Infectious complications occurred in 64.3% of patients, the most common site of infection was respiratory. The average stay was 18 days. At the time of ICU discharge, average GCS was 14 and the average GOS was 4. Mortality was 14.3% (2 patients). 1-Implementation of a therapeutic hypothermia protocol is feasible. 2-Infectious complications are common, being respiratory ones the most observed. 3-The Arctic Sun Ò device is quick and safe for induction of moderate therapeutic hypothermia. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 S121 OBJECTIVES. Up to now, it is not clear, however, whether mild hypothermia influences also markers of oxidative stress and nitric oxide production. METHODS. Eleven patients after out-of-hospital cardiac arrest were included into this study, all were treated with mild hypothermia using endovascular system Thermodard XP. Target core temperature 33°C was maintained for 12 h, re-warming rate was set at 0.15°C per hour, followed by normothermia of 36.8°C. Blood samples for measurement of nitrotyrosine and nitrates/nitrites were taken at admission and then every 6 h for 2 days. During hypothermia the levels of nitrotyrosine and nitrates/nitrites were comparable with baseline values. In re-warming period serum levels of both parameters gradually increased and in normothermia the levels were significantly higher as compared with hypothermia: nitrotyrosine 14.87 ± 2.01 vs. 8.03 ± 1.68 lM/L, p = 0.027; nitrates/nitrites 105.47 ± 30.65 vs. 55.62 ± 10.74 lM/L, p = 0.04. Our results revealed that during mild hypothermia in cardiac arrest survivors the levels of nitrotyrosine and nitrates/nitrites are significantly lower. These data indicate that the reduction of oxidative stress and suppressed nitric oxide production may be involved in the protective effect of hypothermia. GRANT ACKNOWLEDGMENT. This study was supported by the grant of the Czech Ministry of Health, Nr. 00000064203.  New volumetric variables of preload, such as total end-diastolic volume index (TEDVI) and active circulation volume index (ACVI) and central blood volume index (CBVI), have been shown to be good predictors of fluid responsiveness. During acute changes of intravascular volume, such as hemorrhagic shock, these variables allow a more accurate intervention. OBJECTIVES. The aim of our study was to investigate the changes in TEDVI, ACVI, CBVI in a juvenile model of hemorrhagic shock. Seven anesthetized ponies (1-4 months of age) were studied at normovolemia (Base), after blood withdrawal to mean arterial pressure (MAP) of 40 mmHg (Hemo), after infusion of norepinephrine to a MAP of 75 mmHg (NE), and after retransfusion (Resu). TEDVI, ACVI, CBVI were measured by Ultrasound Dilution (UD) technology with CoStatus device. Data were analyzed using Kruskal-Wallis analysis and Dunn's t test. Comparison of fluid load agreement by Blant Altman. RESULTS. TEDVI and ACVI had significant change during Hemo and Resu status. Percentage of TEDVI and ACVI changes agreed with percentage of blood volume removed/ infused with bias and limits of agreement (LOA) 4% (-21.4, 29. 3) and -10.6 (-29.5 8.2%) respectively. NE administration induced MAP and CVP significant changes, whereas TEDVI and ACVI remained unchanged. CBVI showed high variability and seemed to be inconsistent on the identification of the volume status. CONCLUSIONS. In this animal model, TEDVI and ACVI were superior to CBVI in accurately reflecting hemorrhage and were also suitable to predict fluid responsiveness. NE administration did not affect the volumetric variables TEDVI and ACVI. (1). OBJECTIVES. We sought to identify independent predictors of post-arrest neurological recovery, and of survival to hospital discharge with neurological recovery. In the course of a pre-planned interim analysis, we analyzed the data from 220 participants of NCT00729794. This three-center, double blind, placebo-controlled, clinical trial is ongoing (estimated enrollment = 350 patients) and aims to asses the efficacy of combined vasopressin and epinephrine during cardiopulmonary resuscitation (CPR) and of steroid administration during and after CPR. Post-arrest neurological recovery was defined as Glasgow Coma Scale Score[9 documented at least once by 2 study-independent physicians in patients not receiving sedation for at least 24 h. We identified a total of 65 patients who were subjected to at least one post-arrest assessment of their neurological status. Subsequently, we used backward stepwise logistic regression, and assessed the following potential predictors: cause of cardiac arrest (cardiac vs. non-cardiac); area of cardiac arrest occurrence (monitored vs. non-monitored); use of therapeutic hypothermia; number of CPR cycles; mean arterial pressure and serum lactate at 15 min following resuscitation; and patient group allocation. RESULTS. The sole independent predictor of post-arrest neurological recovery was the occurrence of the cardiac arrest in an area of monitored patient care (i.e., intensive or coronary care unit, and operating or emergency room): odds ratio: 3.83, 95% confidence interval = 1.26-11.63; P = 0.018. The sole independent predictor of survival to hospital discharge with neurological recovery was the serum lactate concentration at 15 min after resuscitation: odds ratio: 1.22; 95% confidence interval = 1.02-1.46. CONCLUSIONS. The results of this preliminary analysis suggest that post-arrest neurological recovery seems to depend more on the use of pre-arrest patient monitoring rather than the employed CPR protocol. Also, patients with lower, early post-arrest serum lactate concentration seem to have a better chance of surviving to hospital discharge without concurrent, severe neurological deficits. REFERENCE(S). To quantify the attribution of intra-operative defibrillation on markers of myocardial injury (CK, CK-MB, TnT and hFABP). METHODS. Single centre prospective study in which 50 elective CABG patients were included in a 2 month period in 2007. Patients with valve, emergency, off-pump surgery or rethoracotomies were excluded. Patients were grouped as having had defibrillation or no defibrillation during surgery. Serum levels of CK, CK-MB, TnT and hFABP were analyzed in blood samples taken at arrival on the ICU and at 4, 8 and 16 h after admission to the ICU. Levels of these biochemical markers were compared using a paired t test. RESULTS. All data presented as mean ± standrad deviation CONCLUSIONS. Atrial fibrillation is a common problem associated with morbidity and mortality in critically ill patients; however, evidence-based recommendations are lacking leading to variability in treatment. Our audit confirmed variability and low compliance to NICE in treating new AF. Inconsistency in using appropriate first line drugs for rate control and inadequate thromboprophylaxis reflects lack of familiarity with NICE guidelines. Educating ITU medical staff and promoting the use of well validated, easy to remember CHADS 2 scoring system 2 might improve compliance with NICE guidance. Also,promoting HEMORR 2 HAGES scoring system 3 for assessing risk of bleeding and CARAT tool to guide prescribing antithrombotics may allow ITU physicians to anticoagulate more patients with AF with less fear of bleeding complications.  In patients with acute coronary syndromes (ACS) combined antiplatelet and anticoagulant therapy is recommended in addition to percutaneous coronary revascularization. Heparins and glycoprotein IIb/IIIa receptor inhibition can be associated with immune-mediated thrombocytopenia of clinical significance in less than 2%, resulting in major bleedings and increased mortality rate. To evaluate the incidence of thrombocytopenia and its impact on in-hospital complications-bleedings, reinfarctions, in-hospital heart failure and mortality in patients with ACS. Retrospective evaluation of patients admitted during 3 months, fulfilling the criteria for ACS: rest chest pain up to 36 h, changes in standard ECG with or without ST-elevation with or without elevated serum troponin I. Serum Troponin I was estimated by immunochemical method (Boehringer, Mannheim, Germany, normal levels \0.15 lg/L). Patients were treated by combined antiplatelet therapy, heparins and percutaneous coronary revascularization. Platelets were estimated by automatic analyzer Sysmex XE2100, Kobe, Japan (normal levels 140-340 9 10 9 /L). Thrombocytopenia was defined as platelet count less than 140 9 10 9 /L or a drop in platelet count of more than 50% during inhospital stay. We registered demographic, laboratory, clinical data and in-hospital mortality. We included 78 ACS patients, 82.1% (64/78) with and 17.9 (14/78) without STelevation (64.1% men, mean age 63.8 ± 13.3 years). Mean admission troponin I was 11.7 ± 24.9 lg/L, platelet count 212.6 ± 68.8 9 10 9 /L. In-hospital thrombocytopenia was observed in 24.4% of patients. In thrombocytopenic patients in comparison to non-thrombocytopenic ones we observed significantly increased mean age (70.2 ± 10.9 vs. 61.8 ± 13.4 years, p = 0.016) and admission serum creatinine (172.7 ± 142.1 vs. 102.3 ± 37.7 lmol/L, p = 0.001), significantly decreased admission systolic blood pressure (123.8 ± 28.9 vs. 139.8 ± 27.6 mmHg, p = 0.034) and HDL-cholesterol (1.1 ± 0.3 mmol/L vs. 1.3 ± 0.4 mmol/L, p = 0.048), significantly increased bleedings (26.3 vs. 6.8%, p = 0.028), in-hospital heart failure (57.9 vs. 22%, p = 0.003), but nonsignificantly increased reinfarctions (5.3 vs. 3 .4%), arrhythmias (36.8 vs. 32.2%) and in in-hospital mortality (21 vs. 6.7%). Thrombocytopenic patients were less likely treated by percutaneous coronary revascularization (63.2 vs. 88.1%, p = 0.044). Admission thrombocytopenia in comparison to normal admission platelet count was associated with significant increase in inhospital mortality (60 vs. 5%, p = 0.0209) and ICU-mortality (42.9 vs. 5.6%, p = 0.0094). CONCLUSIONS. Thrombocytopenia, observed in more than 20% of ACS patients, was associated with in-hospital complications and mortality, especially thrombocytopenia on admission. INTRODUCTION. Stress cardiomyopathy, also known Apical Ballooning or Takotsubo cardiomyopathy (TTS), has been recognized for several years. This syndrome is characterized by transient systolic dysfunction of the apex or mid segments of the left ventricle (LV) in the absence of coronary artery disease. Several forms of mostly physical stress may evoke this syndrome. In this case we describe a very uncommon cause for TTS in an unusual situation. A 69-year-old woman without cardiovascular history found her husband non-responsive in bed. After resuscitation he was admitted to ICU. Visiting her husband, she complained of chest pains, shortness of breath and hyperventilation. Physical examination revealed no abnormalities but her ECG showed deep negative T-waves in leads I, II, III, AVF, V3-V6. Her Troponin T level was 0.789 lg/l (ref \ 0.03), NT-pro-BNP was 7,812 ng/l (ref \ 301). CK was 226 ng/l with CKMB of 27 ng/l. Echocardiography showed very poor LV function with the typical apical ballooning of the LV along with hyperkinesis of the basal ring ( Fig. 1 ). There was no coronary artery disease. She was admitted and treated with beta-blockers. Within days, the enzymatic changes normalized and echocardiography showed improved LV function with and normalization of the apical segments. She made full recovery within 2 weeks. DISCUSSION. ICU admittance has significant impact on family members. In the acute phase of the illness, most medical attention goes to the admitted patient. Especially when prognosis is poor, stress to the family may be considerable. Mostly spouses and relatives with female gender are at the highest risk for depression and anxiety disorders 1 . In contrast, little is known about the occurrence in relatives of broader physical symptoms like pain and nausea 2 or even acute onset severe medical conditions requiring treatment. In our case the wife experienced pain, anxiety and nausea along with hyperventilation. However, the underlying disease was a severe cardiomyopathy requiring admittance and treatment. The TTS cardiomyopathy is known to ICU physicians in relation to subarachnoid hemorrhage, but most likely not in the context of severe emotional stress. In summary, we stress the importance for intensive care physicians to be alert to the fact that despite many diverse symptoms related to stress and anxiety, relatives can develop acute medical conditions as well. 2001 2  A retrospective observation study. Demographic profiles, operative data and short term outcomes in the ICU were reviewed in the 22 patients who underwent beating-heart (B-H) operation. We also compared B-H operation group (2003-2010) and conventional cardiac arrest (C-A) operation group (before 2003). Both groups of patients were similar with respect to preoperative demographics (age, co-morbidities, LV function). In the B-H operation group, mean age was 70 years (55-78). Preoperative mean NYHA functional class was 3.5. and the mean LVEF was 28.7%. 15 patients underwent single valve operation, and the rests needed combined valve operation or CABG. 17 patients were included in the C-A operation group, with mean age of 63 years (23-82), NYHA functional class of 3.5 and mean LVEF of 29.3%. In the B-H operation group, no DC shock was needed, whereas 53% of the patient with C-A operation needed DC shock after aortic unclamp. In the single aortic valve replacement, B-H operation group had a tendency of shorter assist perfusion time after intracardiac procedure (38.5 vs. 45.1 min). In the ICU, inotropic support (maximum dose of dopamine) was much less (4.6 vs. 7.3 r) than conventional C-A operation (P = 0.002) and additional IABP support was not required (0 vs. 53% in C-A operation). Low cardiac output syndrome was not encountered in the B-H operation group (0 vs. 6% in C-A operation). No major postoperative complication was encountered except ventricular tachycardia in one patient. There was no 30 day mortality (0 vs. 6% in C-A operation). CONCLUSIONS. In our series, valve surgery on the beating-heart had a superior postoperative hemodynamics and lower associated morbidity compared to conventional cardiac-arrest operation. This procedure is recommended especially in the patients with impaired LV function. (2003) OBJECTIVES. Does HRT measured during daytime or nighttime predict: One-year all-cause mortality in ACS?; Hospital readmission within one-year? METHODS. Secondary analysis of the IMMEDIATE AIM study, prospective clinical trial of patients presenting to the emergency department (ED) with symptoms of ACS (N = 1,308): Holter recordings of 303 patients, positive for ACS and admitted to the hospital, started 45 min (median time) after arrival in the ED; 1-year follow up after hospital discharge in 70% of the sample; Recordings scanned to exclude artifact and non-sinus rhythm. HRT analysis performed using research software at the Washington University Heart Rate Variability Lab; HRT parameters measured: 1) turbulence onset (TO), which characterizes the initial rate acceleration after a ventricular premature contraction (VPCs); and 2) turbulence slope (TS), which characterizes the subsequent oscillation in heart rate. RESULTS. 187 Holter recordings eligible for HRT analysis; 116 eliminated due to unanalyzable rhythm, \5 VPCs needed to calculate HRT, or recording time \12-h. 121 patients were diagnosed with UA, 46 with NSTEMI, and 20 with STEMI. 17 patients died and 84 were re-hospitalized during follow up. HRT measures were dichotomized into low and high-risk groups based on previously reported cutpoints: TO \ 0% normal, TO C 0% abnormal; TS [ 2.5 ms/beat = normal, TS B 2.5 abnormal. Chi square statistics calculated. Findings include: abnormal 24-h TS significantly associated with 1-year mortality [odds ratio (OR) 3.7 (p = 0.008)]; re-hospitalization significantly associated with both abnormal 24-h TO (OR 1.83, p = 0.046), and 24-h TS (OR 2.1, p = 0.018); abnormal Night (0000-0600) TO and Day (0800-2000) TS also significantly associated with 1-year mortality (OR 3.8, p \ 0.05 for both); abnormal daytime TO (OR 2.4, p = 0.007) and TS (OR 2.4, p = 0.012) each significantly associated with re-hospitalization. CONCLUSIONS. Patients with ACS who have a TS \ 2.5 measured over 24 h or during the daytime are at higher risk of dying within 1 year after hospitalization. Those who either have TO C 0% or TS B 2.5 have a greater risk of re-hospitalization. Assessment during the daytime only might provide sufficient information for risk stratification. HRT measured close to ACS symptom onset may aid in risk stratification. OBJECTIVES. We tried to find a correlation between TRS and the severity of coronary artery disease (CAD) found in coronary angiography. We analyzed all consecutive patients with NSTEACS admitted to intensive care unit from June 2008 to December 2009. All patients were stratified at admission with TRS. PCI were performed when it were indicated. For the study we grouped patients according to TRS and the severity and extend of CAD. Considering the TRS the patients were classified into three categories: TRS 0-2, TRS 3-4 and TRS 5-7 and considering the results of the coronary angiography were grouped into three categories: normal angiogram, one or two vessel disease and three vessel or left main disease. We excluded patients without PCI. Qualitative variables are expressed as absolute value and percentage and quantitative variables are expressed as means ± standard deviation or median ± interquartile range when correspond. Comparisons between groups were made with the v 2 or Fisher's exact test for categorical variables and Mann-Whitney test for quantitative variables. A total of 51 patients were admitted with NSTEACS during the period of the study and 41 underwent to PCI. Age median were higher in patients with TRS 5-7 than other groups (71.1 years ± 7.5 p \ .01). Men percentage and in-hospital mortality were similar in all groups (pNS). Between groups there weren't significant differences in prevalence of diabetes, hypertension, dyslipidemia, smoking, mean first troponin I and mean highest troponin I (pNS). The v 2 for all comparisons were 17.1 (p \ .01). Normal angiogram were most likely found in patients with TRS 0-2 than in those with TRS [2 (p \ .05 OR 10, 95% CI 1.61-62). One or two vessel disease were found more often in those with TRS 3-4 than in those with TRS\3 o [4 (p \ .01 OR 5.83, . Three vessel or left main disease were found more often in those with TRS 5-7 (p \ .01 OR 10.4, 95% CI 2.3-47.5). CONCLUSIONS. The relationship between TRS and clinical outcomes (recurrent angina, acute myocardial infarction and death) is well known but its relation with the extent and the severity of CAD is not well determined. In our study we found a correlation of TRS with the number of vessels affected in coronary angiography, making the TRS as a good predictor of the extent and the severity of CAD. A.B. Ratnaparkhi 1 , J. Walton 1 1 Freeman Hospital, Anaesthetics, Newcastle upon Tyne, UK INTRODUCTION. Acute onset atrial fibrillation (AF) is common phenomenon in the intensive care unit. Atrial fibrillation poses risk for thromboembolism. Practice of commencing anticoagulation after acute onset AF varies in different intensive care units. Anticoagulation comes with its own side effects in the already compromised patients in the intensive care unit. This regional audit was carried out in intensive care units of the north east region of the UK. To assess the practice of use of anticoagulation after acute onset of atrial fibrillation in the intensive care units. Postal questionnaire were sent to the 15 intensive care units of the north east region of the UK including two cardiac surgical intensive care units. The questions asked were; is there a protocol in your unit? Are you aware of any guidelines? If yes, which guidelines? Do you commence anticoagulation for acute onset AF? What do you use for anticoagulation and in what dose? After what duration of onset of AF you consider starting anticoagulation? How long do you continue anticoagulation? Do you commence anti platelet therapy? We also put six clinical scenarios with acute onset atrial fibrillation. The aim was to assess if the units consider stroke risk stratification for commencing the anticoagulation. One example is; how would you manage anticoagulation for a 73 year old patient with hypertension and diabetes, presented with sepsis following pneumonia. RESULTS. We received responses from 14 out of 15 intensive care units. The management of anticoagulation strategy was different in different unit. Two units were aware of the NICE guidelines, one unit was aware of the ACCP guidelines and two units were aware of the other guidelines. Ten units responded that they commence anticoagulation for acute onset AF. Commonly used anticoagulation was low molecular weight heparin. Four units use anticoagulation within less than 48 h of the onset of AF. There was no fixed duration for the continuation of the anticoagulation. Different units consider various factors before commencing anticoagulation. CONCLUSIONS. Use of anticoagulation in acute onset AF varies in the different units. Each unit takes into account different factors for the commencement of anticoagulation. This audit highlights the possible need for the evidence based protocol for the use of anticoagulation in acute onset AF in intensive care units. OBJECTIVES. To study of the clinical features and analytical features of those patients with dilated cardiomyopathy treated with ECMO as a bridge to cardiac transplantation in order to determine which parameters are useful to predict the outcome METHODS. A retrospective study from December 2006 to December 2009. All patients were divided into two groups: the A group: patients who died before transplantation; the B group patients who got transplantation. Several clinical and analytical characteristics are compared before starting ECMO, at 12 and 24 h after the onset and immediately before withdrawing (''end time'') ECMO treatment (either for transplantation or for death). Qualitative variables are expressed as % and quantitative ones a mean and standard deviation (SD). Chi square and T student test are used as appropriated. A p \ 0.05 denotes statics significance.  There are statistically significant differences between patients who died and patients who survived to be transplantated. The presence of multiorgan failure and severe tissue oxygen hypoperfusion, and its persistence after initiated treatment, denotes a worse prognose. The study of this differences could be useful to decide which patients benefit of ECMO treatment. OBJECTIVES. To measure the diagnostic contributions of routinely used (NT B type Natriuretic Peptide (NT proBNP), cardiac troponin I (T), DDimeres (DD), C-reactive protein (CRP) and procalcitonin (PCT)) and new biomarkers(Mid-regional Pro-Atrial natriuretic peptide-(MR-proANP), Pro Adrenomedullin (Pro ADM), Pro Endothelin (Pro ET) and Copeptin [Pro vasopressin (CP)] for diagnosing infection in patients with severe acute dyspnea. We designed a prospective study of patients admitted in the Emergency Department and in Medical Intensive Care Unit in a University Hospital. Inclusion criteria were acute dyspnea with SpO 2 B 92% and/or respiratory rate (RR) C 25 b/min. Patients with obvious myocardial infarction or pneumothorax were excluded. Clinical-biological data were recorded and biomarkers sampled. An independent blinded expert panel classified the patients according to all the data including response to treatment and outcomes blindly to biomarkers' results. The roles of biomarkers were assessed quantitatively and then using terciles of the distribution. The contribution of the biomarkers in the diagnosis was assessed using AUC-ROC curves and by multiple logistic regression taking into account other clinical and biological explanatory variables. OBJECTIVES. To compare differences between a group of patients with LMCA treated with percutaneous coronary intervention (PCI) and others with CABG. To evaluate direct results and make a long term prognosis analyzing mayor cardiovascular complications (MCC) rate. Observational retrospective study that includes a total of 130 patients with LMCA submitted to CA between January 2005 and December 2009: 39 patients (30%) were treated with PCI and compared to 90 patients (70%) treated with CABG. In the total of the PCI cases drug-eluting stents were used. We exclude patients in cardiogenic shock and those with protected left main coronary artery. RESULTS. Average age of the patients was 68.3 ± 9.7. In the PCI group most of the patients were older than 75 years. In the CABG group there was a majority of male patients (64.5 vs. 35.5%, p = 0.02) without significant differences in the rest of demographic information. In the PCI group (p = 0.05) there were more previous record of acute myocardial infarction (AMI) and PCI found, and also a greater percentage of patients with LVEF\50% (p = 0.03). Average euroscore of patients from the PCI group were greater than those from the CABG group. Complete revascularization was obtained more frequently in the CABG group. In the CABG group (p = 0.001) the number of days between diagnosis and therapeutic strategy as well as the days hospitalized were greater. In the multivariate analysis, the type of therapeutic strategy wasn 0 t associated to mortality when hospitalize. The median follow-up period was 21 months. According to the classification CCS (p = 0.001), there was no significant difference in the grade of angina. Tendency to a greater restenosis of stent, greater mortality during follow-up and greater MCC without statistically significant. In the multivariate analysis surgical strategy was associated to a lower mortality during follow-up (OR 0. OBJECTIVES. Our objectives were to analyze the characteristics of the patients who were done a cardiac catheterization, the differences of the procedure and the incidence of complications. METHODS. We randomized 380 consecutive patients referred to the hospital for cardiac catheterization since August until October 2009. RESULTS. Among 380 patients, the age (mean ± SD) was 65 ± 10.8 years and more frequently male (65.3%). 34.7% were angioplasty. The radial approach was used in 203 patients (53.4%; 64.8% with 5F arterial sheaths and 35.2% with 6F), and the femoral approach in 177 patients (46.6%). There was no difference in the baseline characteristics of the patients. The time required for the procedure and the fluoroscopy time were longer in the radial group (p = 0.06). A cross over was more often necessary in the radial group (10 patients, 2.6%) due to radial artery spasm, deviousness, loop, unstable catheter or artery dissection. Only one patient required cross over from femoral to radial approach (0.26%) due to serious deviousness in iliac artery. The intravascular ultrasound (IVUS) and Rotablator always were done by femoral approach. The incidence of complications was higher in the femoral approach group (20.9 vs. 12.8%, p = 0.015). In the radial approach group, the most important complication was wrist haematoma (0% radial artery occlusion checked with Allen test), however the femoral approach complications were: inguinal haematomas (13.5%), big haematomas required blood transfusions (2.8%), femoral artery pseudoaneurysms (2.8%), arteriovenous fistulas (0.6%), retroperitoneal haemorrhages (0.6%), strokes (0.6%). These complications increased the hospital stay (5.5 ± 2 vs. 1.2 ± 0.4 days, p = 0.001). CONCLUSIONS. The radial approach reduces peripheral arterial complication rates and allowed earlier ambulation, so also reduces the hospital stay. However, needs higher learned time, and the size of the artery can limit several procedures (IVUS/rotablator On the other hand, the development of bundle branch block after that procedure has been associated with higher rates of complete AV block, syncope, and sudden cardiac arrest at long term. OBJECTIVES: Our aim is to describe the incidence of cardiac conduction problems after PAVI and to identify possible risk factors associated with these conduction problems. PATIENTS AND METHODS. A total of 57 consecutive patients who underwent a PAVI were included in our analysis. The indication for PAVI was a severe symptomatic aortic valve stenosis in patients who were rejected or had a high risk for conventional SAVR. Permanent pacemaker implantation was performed in case of the presence of complete heart block or symptomatic bradycardia, persisting after at least the second postprocedural day. Data are expressed as mean value ± SD for continuous variables and as numbers with percentage for categorical variables. Between the variables selected for predicting AV block after PAVI (basal valvular area, annulus diameter, Valsalva sinus diameter, left and right bundle branch block), the only independent predictor was the last one (OR 11.3, 95% CI 1. (1). Implementation of care bundles have been advocated to reduce the infection rate (2). OBJECTIVES. The aim of the study was to identify the effect of the introduction of the Central Venous Catheter (CVC) bundle on CRBSI rate on our Critical Care Unit over a threeyear period. Retrospective audit on the rate of CRBSI for a 3 months period before the implementation of the CVC bundle provided baseline data. Prospective audits for the corresponding 3 months were carried out after the CVC bundle was firmly embedded in clinical practice. The data was collected based on the information recorded in our clinical information system (CIS). The CVC bundle consisted hand hygiene, barrier precautions on insertion, 2% chlorhexidine skin preparation, using femoral site as last resort, daily review of necessity of central access, daily inspection of insertion site, use of TPN on a dedicated port and maintaining asepsis when accessing the line. Robust educational program was rolled out during the implementation phase for medical and nursing staff. Compulsory elements of the care bundle were recorded in our CIS. We collected data on overall compliance with the bundle, mean dwell time, number of CRBSIs, site of infection and whether the patient left the unit with a CVC line in situ. For statistical analysis Chi-square test and Wilcoxon test were used. Our main results are summarised in Table 1 . Lines removed prior to transfer (n) 33 52 76 We have seen a significant increase in the compliance with the bundle and it resulted a significant and sustained reduction in mean dwell time, CVC related infection rate and number of patients transferred to the ward with CVC lines (all p \ 0.05). The bundle resulted in bigger scrutiny for CVCs, hence the reduction in the number of lines inserted. CONCLUSIONS. Our data shows that implementation of care bundles can significantly and sustainably reduce the rate of CRBSI on the ICU in a real life setting. Our previously unacceptable infection rates were reduced and now are comparable with the recently published data (1) . Evidence-based catheter-care procedures, guided by healthcare workers 0 perceptions and including bedside teaching, reduce significantly the CRBSI rate and demonstrate that improving catheter care has a major impact on its prevention.  To evaluate the incidence of catheter-related bloodstream infection (CR-BSI) and of the use of central venous catheters (CVC) after an intensive improvement program aimed at reducing CR-BSI. Before-and-after study in patients admitted to a 12-bed medical-surgical ICU from January 2007 through December 2009. In 2008 we implemented an improvement program (analysis of barriers, creation of a working group, review of protocols, and implementation of an educational program and checklist) and a set of measures to reduce CR-BSI during CVC insertion and maintenance based on Provonost et al.'s model (1) . In the postintervention period, we suspended the use of the checklist and evaluated the degree of completion of the online training module ''Bacteremia Zero program'' and analyzed the staff turnover rate. We have monitored CR-BSI using the ''Estudio Nacional de Vigilancia de Infección Nosocomial en UCI'' (ENVIN-UCI) criteria since 2002. We calculated the incidence rate ratio of CR-BSI and CVC utilization ratio for 2007, 2008, and 2009 . We compared the incidence rate ratios using the Epitab module from the STATA program and utilization ratios using Chi-square tests. RESULTS. Nine CR-BSI were diagnosed in 2007, one in 2008, and five in 2009. The incidence rate ratio of CR-BSI in these periods was 3.11, 0.32, and 1.52%, respectively. The incidence rate ratio in the postintervention period (0.94%) was significantly lower than in the preintervention period (3.11%) (3.31: 95% CI 1.05-11.32, p = 0.025.) The increase in incidence rate ratio between 2008 and 2009 was not statistically significant (0.32 vs. 1.52%, p = 0.14). The pre-and post-intervention CVC utilization ratios were 0.83 and 0.86, respectively (no significant differences). During the year 2009, and for existing staff in 2008, 6 rotating residents, 19 nurses (turnover rate 52%), and 5 nurse's aides (turnover rate 50%) joined the ICU. The training module was completed by 32% of the new nurses and none of the physicians or nurse's aides. CONCLUSIONS. The program was effective; its effectiveness may be related to the intensity of the measures. A low preintervention incidence rate ratio does not preclude the usefulness of an improvement program. INTRODUCTION. In the intensive care unit (ICU) the bloodstream infections (BSI) related to the central venous catheters (CVCs) represent a serious clinical complication and are a substantial economic burden. Although the data are still somewhat controversial, the use of antibiotic impregnated CVCs is one of the generally accepted approaches in reducing the risk of BSI [1, 2] . OBJECTIVES. In order to determine the efficacy of antibiotic impregnated CVCs in our clinic we evaluated retrospectively the data of the cultures of CVCs and blood obtained from patients during their stay at ICU within the last 2 years (January 2008 till August 2009). CONCLUSIONS. Surprisingly, there was no difference in the incidence of the CVC and bloodstream infections in both groups. We can conclude that the strategy of using MRimpregnated CVCs did not reduce the incidence of catheter related BSI. Although earlier studies have indicated that MR-impregnated CVCs are cost saving [3] , our data add further proof to the suggestion that the cost effectiveness of these catheters is at least uncertain. RESULTS. From all patients, 27 (42.1%) developed infection from any reason during the ICU stay. 8 patients developed CRBSI, 12.5% of the total patient number and 29.62% of the patients who developed any infection. We recorded 9 episodes of bacteremia due to CVC during 735 days of CVC placement stay, 12.24% while the standard limit is four episodes of CRBSI per 1,000 days CVC placement. During the year 2009, we chanced our practice in order to avoid as risk factors as we can, using only antimicrobial/antiseptic impregnated catheters, improving our hand hygiene and aseptic technique, using only chlorhexidine and semipermeable polyurethane dressings and making catheter replacement at scheduled time intervals as a method to reduce CRBSI. The previous year the recorded CRBSI incidence was 18.7% respectively. CONCLUSIONS. The incidence of intravascular catheter related infection is recorded above the standard limits for second consecutive year assuming that we have to improve further our surveillance policy. On the other hand, the incidence is recorded smaller than the incidence of the previous year according to the change to our practice, assuming that our reforming policy, although not fully effective, still is better for the prevention of intravascular catheter related infections. INTRODUCTION. Intravenous catheter related blood stream infection is a major factor contributing to in hospital morbidity and mortality and extending hospital stay by 10 days and expenditure by 10,000 to 30,000 lb 1 . The incidence of central line associated blood stream infections (CR-BSI) in our unit was audited in 2008 and a comprehensive infection prevention program that included staff education, hand hygiene, maximal sterile barrier precautions and daily assessment of the need for a central line was introduced. We are also taking part in the national audit project Matching Michigan. OBJECTIVES. Assess the effectiveness of the infection prevention programme and re-audit the incidence of CR-BSI METHODS. Data was collected daily for a period of 4 months. This included the number of patients with central venous catheters in the unit, the number of lines removed or re-sited, the indications for line change, the site of line insertion and incidence of line infection. The lines were reviewed daily and removed if indicated clinically (pyrexia or raised white cell count) or if not required. RESULTS. Over a period of 4 months 206 central lines were used amounting to 716 line days. The lines inserted were subclavian (SC)-13 (6.31%), femoral (F)-108 (52.4%) and internal jugular (IJ)-85 (41.26%). The percentage of lines removed for clinically suspected CR-BSI reduced in this period from 30 to 15.04%. The average duration of stay for the lines were SC 4.4 days, IJ 5.8 days and F 4 days which was shorter than our previous audit showed. The percentage of microbiologically proven CR-BSI also dropped from 12.5 to 2.5% (4 from internal jugular lines and one from a femoral line). CONCLUSIONS. Introduction of simple and cost effective practices decreased the prevalence of CR-BSI in our unit by a factor of five. Daily review of lines led to earlier removal of central lines once they were no longer required. The unit being a neurointensive care unit has a greater proportion of patients in whom femoral lines are often the only option. Our survey proves that with strict adherence to guidelines and following infection control protocols diligently the risk of CR-BSI from all line types can be reduced. CONCLUSION. This study implies that the scale of CRBSI may be higher than is currently recognised and that the blood culture positivity rate for CRBSI is 79%(152/192). As concurrent antibiotic therapy may reduce blood culture and CVC tip positivity, the blood culture rate of 79% suggests that CRBSI has an inherently high blood culture positivity rate despite concurrent antimicrobial therapy. (1). In this context, we tested the introduction of chlorhexidine(CHX)-impregnated sponges (2) (8), Acinetobacter baumannii 11.8% (6), Serratia marcescens 3.9% (2), Stenotrophomonas maltophilia 3.9% (2), Escherichia coli 1.9% (1) jai Salmonella enteritidis 1.9% (1) . Production of extended-spectrum beta-lactamases (ESBLs) was detected in 50% of Klebsiella spp. and E. coli strains, overproduction of AmpC beta-lactamases was recognized in 44.5% of Enterobacter spp., while only one K. pneumoniae strain was found to produce metalloenzyme. All eight strains of P. aeruginosa were susceptible to aminoglycosides, ciprofloxacin and carbapenemaces, both strains of S. maltophilia were susceptible to ticarcillin/clavulanate and trimethoprim/sulfamethoxazole. Among A. baumannii isolates, 33.3% were susceptible only to colistin. In total, 90.2% of isolates were susceptible to imipenem and ciprofloxacin. CONCLUSIONS. Gram-negative bacteremia, in particular in the critically ill, is associated with significant morbidity and mortality. Significant susceptibility to ciprofloxacin and imipenem was demonstrated. Empiric treatment regimens should be based on unit-specific data. Ben OBJECTIVE. To assess whether implementation of a national safety program to prevent CVC-related bacteremia had an impact on rates of devices-associated infections acquired in ICU. METHODS. Prospective, multicenter, incidence, surveillance study of VAP, CRB and UTI carried out from 01-04-2009 to 31-06-2009. Simultaneously, a bundle for prevention of CVCrelated bacteremia and a comprehensive safety program were introduced at the national level. Infections were diagnosed according HELICS definitions. The follow-up was carried out until discharge from the ICU or to a maximum of 60 days. The severity was assessed by the APACHE II score. The rates are expressed as incidence density (ID) per 1,000 days of risk factor. Rates are compared with those of previous years (2007) (2008) . INTRODUCTION. Acute kidney injury (AKI) is one of the most dreaded complications of severe malaria. Occurs as a complication of Plasmodium falciparum malaria in less than 1% of cases, but the mortality rate in these cases may be up to 45% [1] . To evaluate the incidence of AKI and compare AKIN and RIFLE classification systems with regard to hospital mortality. A retrospective analysis based on medical records of adult patients with severe Plasmodium falciparum malaria admitted in the general ICU of Clínica Sagrada Esperança, in Luanda, Angola, from January 2006 to December 2008. Criteria for diagnosis included the standard WHO definition for severe malaria. Only changes in serum creatinine were used to define the presence of AKI by both criteria. Logistic regression was used to access the association of each RIFLE and AKIN with hospital mortality. Data are presented as odds ratios with 95% confidence intervals (CI). We enrolled 51 patients. Thirty-nine (76.5%) were males. The mean age recorded was 42.9 ± 13.3. The mean APACHE II score was 14.0 ± 7.0, with a mean predicted dead rate of 22.2%. The mean SOFA score on admission was 7.2 ± 3.4. The mean length of stay in the ICU was 5.7 ± 3.5 days. RIFLE allowed the identification of more patents than AKIN as having AKI (68.9 vs. 58.8% There was no statistic association between corticosteroids therapy and length of ICU stay less than 6 days (p = 0.945), duration of mechanical ventilation less than 5 days (p = 0.945), severe infection (p = 0.057), re-intubation (p = 0.448), tracheotomy (p = 0.896), nosocomial infections (p = 0.697), myopathy (p = 0.448) or mortality (p = 0.448). Although there is a tendency for a higher prescription of corticosteroids in DNI patients with severe infection, the difference did not reach statistical significance. The use of steroids is neither associated with a better outcome nor with a higher frequency of adverse events or side effects, namely critically illness myopathy or nosocomial infections. Ozbek INTRODUCTION. Q fever, a zoonosis due to Coxiella burnetii, is more frequent and severe in men than women, despite a similar exposure. Here we explore whether the severity of C. burnetii infection in mice is related to sex differences in gene expression profiles. METHODS. Experimental study analyzing the transcriptome of 40 C57Bl/6 J mice. Ten females and 10 males were sterilized at 7 weeks of age. After 3 weeks, 10 males and 10 females (5 intact and 5 castrated animals of each gender) were killed. The other series of mice were injected intraperitoneally with 10 5 C. burnetii organisms and sacrificed at day one after infection. Organs were aseptically excised and stabilized in RNAlater. Total liver RNA was retrotranscribed and labelled with Cy3. Labelled cDNA were hybridized onto Whole Mouse Genome Oligo Microarray 4 9 44 K (Agilent). Raw signal data were normalized with the quantile method. The Significance Analysis of Microarrays test was used to study the gene expression in uninfected and infected mice. Supervised analyses were carried out with R with the library Bioconductor. PCA was used to visually explore global effects for genome wide trends, unexpected effects and outliers in the expression data (library made4). In another set of experiments, 64 mice (4 intact males, 4 castrated males, 4 intact females and 4 castrated females) were killed at 0, 1, 4 and 7 days after C. burnetii infection (same protocol). Liver RNA was analyzed by RT-PCR to confirm microarray results. RESULTS. Multiclass analysis (sex and infection) identified 2,777 modulated genes (FDR = 5%, |fold change| [ 1.75) . We found that 86% of the genes are specifically modulated in males or females. Only 14% of the genes are sexindependent. Castration showed that sexual hormones are responsible for more than 60% of this sex-specific differential expression. The reduction of gene expression modulation upon castration is seen almost exclusively in males. Functional annotation of male specific signature identified 4 groups of keywords linked to cellular adhesion, signal transduction, defensins and cytokines and Jak/Stat pathway. Functional annotation of female specific signature identified two group of keywords linked to intracellular metabolism and circadian rhythm. These results were confirmed by RT-PCR. The increased susceptibility to infection in males may be related to the overexpression of IL10 and STAT3. The modulation of the circadian rhythm in female is linked to a more efficient bacterial clearance. CONCLUSIONS. This study showed for the first time that the sexual dimorphism observed in Q fever is reflected by sex related gene modulation, and is under the control of sexual hormones. This study also showed that the circadian rhythm seems to play an important role in infection in mice. This work open the way for deciphering the role of sex and circadian rhythm in human infections. The author's report a P.aeruginosa sepsis with skin and heart involvement in a previous healthy woman. A 30 years old woman without a pertinent medical history came to the hospital after 3 days with high fever ([38.5°C), vomiting and diarrhea. At admission she was in septic shock with multiple organ disfunction (hemodynamic, cardio respiratory and renal) and presented genital skin lesions (round, ulcerated, painless lesions with necrotic black eschar and erythematous margin-ecthyma gangrenosum). The laboratory tests showed bicytopenia (leucocytes and platelets), hepatic necrolysis and elevated troponin T, associated with T wave inversion in anterior leads in the ECG. The ecocardiogram showed apical dyskinesis with normal systolic function suggesting Tako-Tsubo cardiomyopathy. Hemocultures (3) were positive to Pseudomonas aeruginosa and skin lesions biopsy showed vascular ulcers with local P. aeruginosa inflamation. RESULTS. Besides the fluid challenge and supportive therapy she began empirically Piperaciline-Tazobactam with rapid improvement of the clinical picture. She needed vasopressors (norephynefrine and dopamine) for 48 h. The skin lesions have resolved in 7 days and cardiac treatment was conservative and symptomatic. The patient was discharged from the intensive care after 8 days. CONCLUSIONS. Ecthyma gangrenosum although relatively uncommon, was first considered a pathognomonic sign of P. aeruginosa sepsis, but now we known that other bacterias can have the same presentation. Tako-Tsubo cardiomiopathy or broken heart syndrome is a stress-induced cardiomiopathy characterized by transient systolic dysfunction that mimics myocardial infarction but without coronary disease. Although the unusual P. aeruginosa clinical presentation sepsis should be treated with prompt supportive measures and the most adequate antibiotic. OBJECTIVE. We undertook this study to determine the relative frequency of meningitis and sepsis in a paediatric intensive care and to define the clinical and laboratory features at the time of admission and the outcome of these children. We reviewed the medical records of 19 patients with sepsis and meningitis, in our paediatric intensive care, from 2007 to 2010. RESULTS. Among these patients 42% had meningitis, 37% had sepsis, 16% patients had bacteraemia, and 5% had meningitis and sepsisAge ranged from 1 month to 14 years old (37% were 2-6 years old. Boys 68%, girls 32%. Temperature at the moment of admission was in 53% patients greater than 39°C. Leucocytosis was noted in 42% (from 10,000 to 20,000/ mm 3 ) and leucopenia 10% (3,000-5,000/mm 3 ) 74% of the patients had petechiaes, 58% had a positive lumbar puncture and 42% who did not have lumbar punctures had diffuse intravascular coagulationThe species of microorganism were in 58% meningococcus group B, in 21% no organism was found, in 11% were pneumococcus, and meninococcus group D in 5%. On admission, 21% of our patients had seizures. The duration of hospitalization in our picu was 84% (average length of stay from 1 to 3 days) 37% had hemodynamic instability, and 63% had a normal arterial pressure. From the patients who had hemodynamic instability, needed only fluids 14%, and 86% needed fluids and inotropes100% of the patients received intravenous ceftriaxoneWe had no mortality. CONCLUSION. Meningitis and sepsis remain a serious problem in picu. With the existing guidelines of therapy and prognostic signs at the moment of admission in picu we have a better outcome. Howitz INTRODUCTION. Community acute bacterial meningitis is a relatively common disease. Three bacteria are responsible in most cases: Streptococcus pneumoniae (adults), Neisseria meningitidis (older children and young adults) and Listeria monocytogenes (in the elderly, alcoholics and immunosuppressed). The mortality rate ranges between 11 and 21% and is higher in case of pneumococcal meningitis (30%) due mainly to increased intracranial pressure and the intense inflammatory reaction that produces pneumococcus in the cerebrospinal fluid. OBJECTIVES. To study epidemiology, aetiology, clinical and evolution in acute meningitis in the adult community in our ICU. METHODS. Retrospective and descriptive study of patients admitted to a tertiary ICU with 34 beds from 1 January 2006 to 31 December 2009. A total of 26 patients of whom 14 were males (53.84%) and 12 women (46.15%). The mean age was 45.65 years (range: 17-75). The APACHE II at admission was determined in 19 of the 26 patients with an average of 10 points, which is associated initially with a good prognosis. The Glasgow Coma Scale was found in 100% of the cases the majority ranging between 12 and 15 with a range: 4-15. The average stay in ICU was 5.69 days. 3 patients died (11.5%). Risk factors include: Infections in Otolaryngology: 3 cases (11.5%) Alcohol: 1 case (3.8%) and states of immunosuppression: 8 (30.76%) of which: There were two diabetic patients (7.69%); HIV: 2 (7.69%) were chronic treatment with corticosteroids in one case (3.8%); ADVP: 1 case (3.8%) liver transplantation: one case (3.8%) and other case cerebrospinal fluid leak (3.8%). In 14 patients (% 53.84) found no risk factor. The most common complication was the need for endotracheal intubation and mechanical ventilation in a 34.61% of patients, hydrocephalus followed by 3.8%. Hearing sequelae were found in 3 patients (11.5%) and persistent vegetative state in 1 case (3.8%). The outcome was favorable and without sequelae in 18 cases (69.23%). The etiology was bacterial germs and virus in 20 cases in 6. Bacteria, not unknown in 6 cases (23%). Filiated of the causative agent in the majority (34.61%) were Streptococcus pneumoniae, followed by Neisseria meningitidis in 2 cases (7.69%), Listeria, Staphylococcus aureus, E. Coli and Mycobacterium tuberculosis were isolated in one case each (3.8%) . In relation to the VHS virus was found in one case (3.8%) and unable to filial the rest. CONCLUSIONS. Community acute meningitis is a disease with low prevalence and mortality in our environment. The agent most commonly Streptococcus pneumoniae, clearly associated with increased morbidity. The most frequent complication was the need for endotracheal intubation and secondly hydrocephalus. Mortality was associated with longer hospital stays and lower Glasgow at the beginning, but not with age. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 S131 Evaluated factors: patient characteristics, signs, symptoms, abscess location, time between symptoms and hospital admission and surgery, lab results, microbiology, antibiotic therapy, APACHE2, SAPS2, SOFA, length of ICU stay, surgical re-intervention, duration of mechanical ventilation, infectious complications, critical illness myopathy (CIM), renal replacement therapy (RRT), re-intubation, tracheotomy, mortality. Descriptive statistics were used to analyze data. OBJECTIVES. To assess ventriculitis (VG) and to study outcome and disability indices in patients admitted in ICU due to cerebral hemorrhage (spontaneous or traumatic). We prospectively studied patients hospitalized due to cerebral hemorrhage in the ICU of University Hospital of Thessaly, between 2006 and 2009. Patients were followed for median follow up of 290 (120-690) days. On admission, the neurological status of patients was described by the Glasgow Coma Scale; disability was evaluated at 6 months by the Rapid Disability Rating Scale (RDRS). RESULTS. One hundred twenty-one patients (85 male) were studied; median (IQR) age was 53(37-66) years, GCS before intubation 8 (5) (6) (7) (8) (9) (10) OBJECTIVES. To analyze characteristics of patients diagnosed with infective endocarditis in a third-level hospital from January 1996 until December 2008, evaluating the echocardiography findings, the therapeutic strategy used, and both morbidity and mortality rates in hospital and during long term follow-up. Observational retrospective study of 107 consecutive patients with following Duke criteria with a mean follow-up of 16 ± 2 months. CONCLUSIONS. This study showed a low mortality of sepsis and its sequential stages in children with meningococcal disease admitted to the PICU, which was probably associated with the early use of antibiotics (up to the sixth hour) and aggressive fluid esuscitation. Diagnosis and treatment of infections in critically ill patients: 0190-0200 BACKGROUND. About one-third of hospital mortality in critically ill patients occurs after Intensive Care Unit (ICU) discharge. Post ICU deaths may arise from incomplete resolution of the primary condition or from the development of new complications. Some authors have recently hypothesized that unresolved or latent inflammation and sepsis may be an important factor that contributes to death following successful discharge from the ICU. AIM. The aim of our study was to determine the ability of the clinical and inflammatory markers at ICU discharge to predict post-ICU mortality. A prospective observational cohort study was conducted during a 14-month period in an 8 bed polyvalent ICU. Acute Physiology and Chronic Health Evaluation (APACHE) II score, Simplified Acute Physiology Score (SAPS) II, Sequential Organ Failure Assessment (SOFA) score, C-reactive protein (CRP), body temperature and white cell count (WCC) of the day of ICU discharge were collected from patients who survived their first ICU admission. RESULTS. During this period 156 patients were discharged alive from the ICU. A total of 29 patients (18.6%) died in hospital after ICU discharge. There were no differences in clinical and demographic characteristics between survivors and nonsurvivors. C-reactive protein levels at ICU discharge were not associated with hospital mortality (mean CRP concentration of survivors = 8. INTRODUCTION. Early diagnosis of bacterial infection can be challenging in critically ill patients, however prompt recognition and initiation of antibiotics improves outcome. 1 Serum procalcitonin (PCT) has been proposed as a more reliable marker of bacterial sepsis than white cell count (WCC) or C-reactive protein (CRP), however there is no consensus in how it should be used and PCT measurement has not disseminated widely into critical care practice in the UK. 2 To identify if clinical recommendations based on procalcitonin levels are being followed. We retrospectively studied PCT use between October and December 2008. Assay results were interpreted as: \0.5 ng/ml, possible local bacterial infection 0.5-2.0 ng/ml, possible bacterial systemic infection, moderate risk of severe sepsis 2.0-10 ng/ml, likely systemic bacterial infection, high risk of severe sepsis \10 ng/ml, almost exclusively severe bacterial sepsis or septic shock. 3, 4 This was compared to changes in antibiotic prescribing which were identified from our local audit database and used as a surrogate marker for clinical suspicion of sepsis. To provide context we also compared this to CRP and WCC trends in a larger sample from June to December 2008. RESULTS. Forty-four episodes had matched antibiotic prescribing data and PCT results. A further 102 episodes provided synchronous WCC and CRP data. PCT assays were typically requested on day 6 (median, interquartile range 4-11). Distribution of PCT results PCT Value (ng/ml) \0.5 0.5-2.0 2-10 [10 Number (%) 76 (55) 22 (16) 14 (10) 27 (19) There was poor concordance between PCT and both WCC and CRP trends and also when WCC and CRP trends were compared. PCT assays did not have significant correlation with antibiotic prescribing. PCT CONCLUSIONS. Our study suggests PCT results did not influence clinical practice. PCT testing may be of greater benefit if used with a protocol with guidance for clinicians based on assay levels. 5 Routine and serial quantitative PCT testing protocols may also be useful to guide antibiotic initiation and duration, particularly in cases of greater diagnostic uncertainty, for example traumatic brain injury. 5, 6 REFERENCES. INTRODUCTION. Procalcitonin (PCT) is a reliable marker for diagnosis of infection after cardiac surgery, except in patients who previously received antibiotics, but its diagnostic role in patients with post-sternotomy pre-sternal wound infection and mediastinitis has not been studied in detail. (1) . OBJECTIVES. This retrospective study focused on the role of PCT in the differentiation between poststernotomy pre-sternal wound infection and mediastinitis. METHODS. All patients (n = 19; age: median 80, 49-87 years) who underwent surgical treatment due to poststernotomy superficial pre-sternal wound infection and mediastinitis between January and September 2009 were included in the study. Procalcitonin (PCT), C-reactive protein (CRP) and leukocyte counts were routinely measured within the last 24 h before surgical wound revision. Body temperature and hemodynamic parameters were evaluated immediately before operation. Bacteriologic samples were also routinely taken intraoperatively. RESULTS. The primary cardiac operation was CABG (n = 12), CABG and valve procedure (n = 6) and others (n = 1). Time between primary operation and wound revision was in median 15 days (range Sensitivity, specificity, positive and negative predictive value for diagnosing sepsis are presented in Table 2 . ROC curves and AUC are presented in Figure 1 . ROC curves and AUC CONCLUSIONS. Patients with sepsis have significantly higher levels of CRP, PCT, IL-6 and LBP on admission to the ICU as compared to patients with SIRS. PCT is more usefull in differentiating between sepsis and SIRS than CRP, IL-6 and LBP. B. Ergan Arsava 1 , S. Bilekli 1 , N. Alayvaz Aslan 1 , E. Er 1 , A. Topeli 1 1 Hacettepe University, Ankara, Turkey INTRODUCTION AND OBJECTIVE. The incidence and mortality of bacterial infections significantly increase with age. Aging is associated with an impaired immune response, which causes not only an increased susceptibility for infections, but also a poor inflammatory response against them. Procalcitonin (PCT) is an inflammatory biomarker used as a diagnostic and prognostic tool in bacterial infections. There is no data regarding the diagnostic yield of PCT in elderly patient populations. In this study we sought to identify the relationship between age and the magnitude of PCT response in patients admitted to the intensive care unit (ICU). METHODS. Patients, who were admitted to ICU between January 2008 and December 2009, with the diagnoses of severe sepsis, pneumonia and chronic obstructive pulmonary disease exacerbation (COPDE) were included into the study. Patients' demographics, APACHE-2 scores, admission PCT values, intensive care and hospital outcomes were extracted from a database of prospectively collected clinical data. RESULTS. We studied a total of 189 admissions (92 female/97 male, mean age ± standart deviation 60.6 ± 18.7 years). Median (interquartile range-IQR) APACHE 2 score was 23 (18-31); the ICU and hospital mortalities were 32.8 and 41.8%, respectively. Median (IQR) admission PCT levels were 7.9 (1.7-24.7) ng/ml in patients with severe sepsis (n = 91), 0.6 (0.2-3.4) ng/ml in patients with pneumonia (n = 60) and 0.2 (0.1-0.3) ng/ml in patients with COPDE (n = 38). There was a negative correlation between age and PCT levels (Spearman correlation coefficient: r = -0.21, p = 0.004); the median (IQR) PCT levels were 3.8 (0.4-22.5) ng/ml in patients\60 years-old and 1.1 (0.2-6.6) ng/ ml in patients C60 years-old (p = 0.005). In subgroup analyses it was found that the inverse correlation between age and PCT levels mainly arised from patients with severe sepsis (r = -0.23, OBJECTIVES. We intend to define the role of PCT in the initial evaluation of the patient with a suspected sepsis admitted to the ICU. Preliminary data from a prospective observational single centre study (polyvalent ICU in a third level University Hospital). The Ethics Committee of the centre has approved this study. We included all patients admitted to our Unit with diagnosis of sepsis since June-2009. We measured PCT (lgr/mL) at admission and at the second and third day of stay beside the routine screening for the source of infection. Then we analyzed the relation of PCT with culture results. Chi-square and ANOVA have been used for the analysis. (Fig. 1 ). PCT at admission showed an Auc of 0.53 (0.38-0.69) for discriminating bacterial infection. We detected higher mortality in those patients with bacterial infections and sustained high levels of PCT the third day ( Fig. 2) (p \ 0.05). Figure 1, 2 CONCLUSIONS. In the initial approach to the septic patient, PCT does not seem in our experience useful as an aid in decision-making but an early decrement of serum levels can be a marker for response and for a better outcome of patients with bacterial infections. ( 1-3) b-D-glucan (BG) assay in early detecting ICI in critically ill pts and assess its reliability on arterial blood specimens compared to venous blood specimens. METHODS. All pts admitted to the 18-bed ICU of our university hospital, between 15th of February and 31th of March 2010, harboring an arterial line for more than 4 days and suspected to have an ICI, were prospectively enrolled. From all the pts, two blood samples drawn from the arterial line and direct femoral site were simultaneously obtained and subjected to both conventional cultures and BG assay determinations. Candida Colonization Index (CCI) and Candida Score (CS) were also calculated. RESULTS. During the study period, from 62 admissions, 50 pts were enrolled. 98 BG assays, 144 cutaneous and mucosal swabs and 48 urine cultures were collected. In 40 pts BG assays resulted negative from either arterial line and femoral site. All but one did not develop ICI. In 10 pts BG assays resulted positive. Four of these pts did not develop ICI, whereas the other six developed ICI (5 fungemias and 1 mediastinitis). The positive and negative predictive values (PPV, NPV), sensitivity (Se) and specificity (Sp) of BG assay, CCI, and CS are shown in Table 1 . Among 7 pts with ICI, 3 (median SOFA score value 11 ± 3.5; median SAPS II value 63.7 ± 13.8) had at the diagnosis BG levels C500 pg/ml and developed septic shock; two of them died within few days. In contrast, the clinical course of pts with BG assay below 500 pg/ml was not complicated by septic shock (median SOFA score 7.5 ± 5; median SAPS II value 52 ± 14.7) and a rapid clearance of BG levels was observed. In addition, we observed a 100% agreement between arterial line and femoral site BG assays (positive and negative). In particular, we detected BG levels from arterial site specimens that did not significantly differ by those obtained from femoral site specimens (p = 0.5). CONCLUSIONS. Although conventional mycological culture remains the gold standard for ICI diagnosis, we showed that BG assay seems to be a diagnostic tool that may help physicians in early detecting ICI. Sampling blood from the arterial line was shown to give a simple and adequate specimen to be used for BG assay. Further studies are in progress in order to define the role of BG as a surrogate marker for an early diagnosis of ICI. OBJECTIVES. To assess which marker, if any, and at which cut-off value could add diagnostic information to enhance clinical assessment in the difficult context of long-term ICU-patients. METHODS. Long-term ([6 days) critically ill patients prospectively enrolled in the general ICU of a University-hospital. All patients were daily assessed by the attending physician for the ACCP-SCCM classification. C-reactive protein (CRP, mg/dL), procalcitonin (PCT, ng/ mL), and Interleukin-6 (IL-6, pg/mL) were measured after patient's discharge on daily stored sera. An independent overall clinical evaluation after patient's discharge, aware of the clinical course but blinded against biomarker's measurement, an ''a posteriori'' ACCP-SCCM classification, was chosen as reference standard for all comparisons. RESULTS. We studied clinical variables and biomarkers in 592 patient-days (26 patients). The day by day ACCP-SCCM classification of the attending physician overestimated the severity of the inflammatory response to infection. Discriminative ability of each biomarker for diagnosis of sepsis is shown in Table 1 . METHODS. 48 ICU patients (31 males and 17 females) with new onset of fever and leukocytosis within the first 3 days of ICU admission were prospectively included in the study. Exclusion criteria: age \18 or [75 years old, heart or renal failure, hypertension, COPD, pregnancy and head trauma. Serial plasma samples were taken on days 1, 2 and 4 after the onset of fever for Procalcitonin and BNP levels measurement. Procalcitonin and BNP values were correlated with severity scores (APACHE II and SOFA), progression to Septic Shock and final outcome. Statistical analysis was performed. RESULTS. Patients included in the study were divided in three groups according to clinical and laboratory findings: SIRS, Sepsis and Septic Shock. Procalcitonin value on Days 1 and 4 and BNP value on Days 1, 2 and 4 was significantly associated with SOFA Max value and with SOFA value at the first day of fever, but not with APACHE II. There was found no correlation between Procalcitonin value on Days 1, 2 and 4 and final outcome. BNP value on Days 1 and 2 was significantly associated with final outcome (p = 0.01 and 0.017 respectively). The optimal cut-off BNP value on Day 1 was estimated to be 215 pg/ml (sensitivity = 86%, specificity = 58%). The optimal cut-off BNP value on Day 2 was estimated to be 212 pg/ml (sensitivity = 86%, specificity = 75%). Procalcitonin value on Days 1, 2 and 4 was not able to differentiate between patients with SIRS and those with Sepsis. Also Procalcitonin value on Days 1, 2 and 4 was not significantly associated with progression to Septic Shock. BNP value on Day 1 was useful in differentiating between patients with SIRS and those with Sepsis (p =0.026). The optimal cut-off BNP value was estimated to be 159 pg/ml (sensitivity = 74%, specificity = 78%). BNP value on Days 1 and 2 was significantly associated with progression to Septic Shock (p = 0.001). The optimal cut-off BNP value on Day 1 was estimated to be 301 pg/ml (sensitivity = 86%, specificity = 81%). The optimal cut-off BNP value on Day 2 was estimated to be 213 pg/ml (sensitivity = 86%, specificity = 75%). CONCLUSIONS. In ICU patients with new onset of fever during the first 3 days of ICU hospitalization, BNP value on days 1 and 2 seems to be a good predictor of ICU mortality and progression to Septic Shock. Also BNP value on Day 1 may be useful in differentiating between patients with SIRS and those with Sepsis. In our study Procalcitonin value on Days 1, 2 and 4 was not found useful in predicting progression to Septic Shock nor the final outcome. Due to the small number of patients included in our research, further studies are needed to confirm these findings. OBJECTIVES. As C-reactive protein (CRP) is regarded a marker for both inflammation and infection we decided to analyse the PCT and Eo status next to every CRP request of critically ill patients, during 1 month. A two-side immunoassay (sandwich principle) for procalcitonin, using both anti-katacalcin and anti-calcitonin (see Fig. 4A ) was used for quantitative analysis of procalcitonin with the Roche Modular E170. PCT concentrations [0.5 lg/L were regarded as positive. CRP was measured by immunoturbidimetric analysis using the Roche Modular P. A positive blood culture was regarded as infection, with exclusion of the coagulase negative Staphylococcus aureus since this organism doesn't induce PCT expression. Every CRP request of the ICU during 1 month was accompanied by a PCT, WBC, and eosinophil count. CONCLUSIONS. PCT at randomly measured at the ICU doesn't seem to contribute to an earlier diagnosis of sepsis. PCT measurement seems to be useful only when sepsis is suspected and a blood culture request has been summoned. However, its non-specificity for infection, as demonstrated by the high number of PCT-positive, no blood-culture requested patients (concerning mostly post-cardiac arrest and post-heart surgery patients), makes it difficult to apply routinely. The recently displayed effort of various companies to market PCT in combination with CD64 and neopterin (other potential markers of infection) supports the conclusion that not one marker by itself can substitute the golden standard of blood culture today. OBJECTIVES. In this prospective observational study we sought to investigate the role of serum C-reactive protein (CRP) and procalcitonin (PCT) in the diagnosis and prognosis of patients admitted to the ICU with suspected 2009 H1N1 infection. All patients older than 14 year-old, presenting with severe acute respiratory disease (cough, fever and respiratory distress) admitted to the ICUs of an university hospital in southeast Brazil were included in this study. Serum levels of CRP and PCT were measured at inclusion and at day 3, 5 and 7. were also were also significantly higher (p \ 0.001 and p = 0.001, respectively) independently from the presence or not of a co-infection. CONCLUSIONS. As a conclusion, in our experience, some severe forms of influenza A/ H1N1with respiratory failure had elevated levels of PCT and/or CRP in the absence of proven bacterial co-infection. Low values were unusual in the presence of co-infection but high values are not synonymous of co-infection and may be related to the severity of the disease. A large prospective randomized study is needed to assess the clinical interest of these biomarkers during the next pandemic of influenza. METHODS. Descriptive study of pregnant with influenza A admitted in the obstetric section ICU. The study period runs from September 2009 to January 2010. During this period 55 patients were admitted. Entry criteria (%): gestosis 31%, complicated postoperative gynecology and obstetrics 27, postpartum hemorrhage 9, acute respiratory failure in influenza pneumonia: 7.2, sepsis and others respiratory failure 5 respectively, others (pregnant myocardial infarction, trauma, renal failure, arrhythmias and heart failure) 14. Acute respiratory failure due to influenza pneumonia was assessed using severity criteria the ATS/IDSA (major criteria (1)  Were admitted in ICU 13 cases of severe influenza pneumonia, nasopharyngeal specimens confirmed with RT-PCR positive for influenza A (H1N1): 4 pregnant in ICU OG, and 6 women and 3 men general ICU. The average age of pregnant was 34 ± 5 years, average stay 18 days. 75% were in the 3rd trimester and one in the 2nd trimester (week 24). Two-third pregnancy and two primiparous. The APACHE II on admission ranged between 13 and 22. Only one patient with pre-existing disease (diabetes type 2). Admission due: Acute respiratory failure complicating pneumonia multilobar in 100%, with more than 6 days of typical symptoms (fever [38°C, malaise, myalgia, headache and respiratory symptoms), no starting oseltamivir within 48 h symptoms. Caesarean was performed at 100%; 75% in the first 24 h of admission and one after 15 days (week 26) intraUCI, posterior cerebral hemorrhage fetal death. All newborns free of viral disease. Invasive mechanical ventilation (MV) in the first 24 h in 3 patients and 1 did not require. Required aggressive parameters 100%: BIPAP, alveolar recruitment and prone. A percutaneous tracheostomy for weaning. The average duration of mechanical ventilation: 19 ± 9 days Complications: barotrauma (pneumothorax and a pneumomediastinum 1). 75% required vasoactive drugs. One patient with acute renal failure that required extracorporeal clearance techniques (HDFVVC), recovering renal function, deep vein thrombosis complicated with Shaldon catheter. One brain death by massive subarachnoid hemorrhage. Nosocomial infections in 2 patients, most common germ Staphylococcus epidermidis catheter and Candida sp in urine. Initial empiric coverage with ceftriaxone and clarithromycin, as well as oseltamivir. CONCLUSIONS. During pregnancy, especially in the second and third quarters, there is an increased risk of complications associated with infection by influenza A virus H1N1, highlighting pneumonia, with more rapid progression to severe respiratory complications. OBJECTIVES. The aim of this study was to describe baseline characteristics, management and outcomes of critically ill patients with influenza A (H1N1) infection who were treated at ICU. We performed a retrospective observational study which included 20 critically ill patients with influenza A (H1N1) infection admitted to ICU between 23rd November 2009 and 15th March 2010. The primary outcome measure was mortality. Secondary outcomes included the rate of 2009 influenza A (H1N1)-related critical illness and introduction of mechanical ventilation as well as intensive care unit (ICU) length of stay and hospital length of stay. In the early 20th century, burns patients were dying of multi-organ failure due to dehydration and hypovolaemia [1, 2] . The Parklands formula was devised to guide fluid resuscitation and prevent multi-organ failure from occurring. However, over enthusiastic fluid resuscitation will lead to other complications [2] . OBJECTIVES. We aimed to assess the adequacy and complications of fluid resuscitation in the 1st 24 h of a burns patient admitted to our ICU, a tertiary centre for burns intensive care. • A retrospective medical case notes audit on all patients admitted to our ICU in 2008 with [15% TBSA (Total burns surface area). • 1st 24 h of burns resuscitation initiated by the referring hospital and our ICU compared to the Parkland's Formula. • Statistical analysis by SPSS 17. RESULTS. 13 patients audited. • Mean duration of transfer from burn injury to our Unit = 6.5 h • Mean age = 41 years, burn area 44%, length of stay 3.9 days • 28 day mortality = 54% • 61% had an inhalational injury • No statistical difference between the Emergency Department (ED) estimation of TBSA and Whiston ICU. • Mean IV fluids given 6.5L but the actual predicted requirement is 4.7 L, therefore an excess of 1.8 L (p \ 0.01) • Average urine output during this period was 0.99 ml/kg/h suggesting that this amount was adequate. IV Fluids in the 1st 24 h CONCLUSIONS. Excessive amount of IV fluids in the 1st 24 h is associated with prolonged ventilation and length of stay but is not associated with increased 28 day mortality. The mean amount of fluid required in the 1st 24 h is approximately 6 ml/kg/h which is consistent with other studies [3] . Urine output is still an accurate marker of resuscitation. There was no statistical difference between the determination of TBSA by the ED and burns surgeons, contrary to other studies [3] . INTRODUCTION. ICU-acquired hypernatremia appears to be associated with mortality in the ICU 1 . To reduce iatrogenic rise of serum sodium the use of balanced colloids has been advocated. OBJECTIVES. Aim of this study was to establish the incidence of clinically relevant hypernatremia on our ICU and to evaluate the change in incidence of hypernatremia due to the introduction of a Natriumacetate based colloid solution. We performed a single centre retrospective study in a 22-bed mixed ICU with all available medical specialities except neurosurgery. Sodium measurements of all patients were analyzed during a 3-month period prior to and after a switch from Sodium-based (S) to Natriumacetate -based (NA) colloids. S contains a 6% 130 kDa polystarch with a 154 mmol/L Na and 154 mmol/L Cl concentrations (Voluven Ò ). NA contains a 6% 130 kDa hydroxyeethylstarch with a 137 mmol/L Na and 110 mmol/L Cl concentrations (Volulyt Ò ). Serum sodium measurements were routinely performed 6-hourly. By protocol colloids were provided to a maximum of 2 L/day, independent of bodyweight. Patients with hypernatremia at ICU admission were excluded. Data are expressed as mean ± SD. Comparison of Na concentrations between groups was performed with a t test for independent samples and comparison of incidence of hypernatremia with a Pearson Chi-square test. RESULTS. Patient characteristics and number of samples are summarized in Table 1 . After the introduction of NA mean serum sodium concentration in the total ICU population decreased significantly from 138.8 ± 4.4 to 137.8 ± 4.5, p = 0.000. The incidence of serum Na[145 mmol/ L decreased from 8.0 to 6.6%, p = 0.000. The percentage of patients with at least one Na measurement[145 mmol/L did not change significantly: 5.6% (S) versus 4.4% (NA), p = 0.31. Introduction of a Natriumacetate based colloid solution in stead of a sodium-based colloid solution reduces the overall incidence of clinically relevant hypernatremia; however, the number of patients with such hypernatremia did not change significantly.  Patients admitted to intensive care frequently have a metabolic acidosis with previous studies demonstrating an association between the degree of acidosis and outcome. Hyperchloraemia is a significant cause of metabolic acidosis and there is increasing interest in the adverse consequences associated with it, which include hypotension, renal dysfunction, impaired gut perfusion and increases in inflammatory cytokines. Previous studies, however, have failed to show that hyperchloraemic metabolic acidosis (HClA) has a significant effect on survival. To assess whether patients with HClA had a worse prognosis than our general intensive care unit (ICU) population, and the factors associated with the development of HClA. Consecutive admissions to the intensive care unit over a 13 month period were studied. Patients with a base deficit[5 mmol/L and a serum chloride[110 mmol/L on the same arterial blood sample during their ICU admission were classified as having an episode of HClA. APACHE II scores on admission, length of stay on the unit, mortality rates and reason for admission were collected. Hospital survival was investigated by logistic regression analysis, controlling for illness severity (APACHE II) and admission category, and displayed as a Kaplan-Meier curve. Of 743 patients entering the unit during the retrospective study period, 116 had an episode of HClA, with an odds ratio of death of 3.71 (95% CI 2.39, 5.75) compared with those without HClA. After controlling for APACHE II score on admission, and admission category the odds ratio reduced to 2.31 but was still statistically significant (p = 0.001, 95% CI 1.37, 3.89). The development of HClA was significantly more associated with medical than surgical admissions with an odds ratio of 3.63 (95% CI 2.19, 6.02). Within the surgical admissions, the occurrence of HClA differed significantly with the urgency of surgery, with an odds ratio of 2.59 (95% CI 1.34, 5.00) for emergency surgery versus elective surgery. Those with HClA had a longer median duration of stay and were overrepresented in the group of patients whose length of stay was C7 days. Kaplan-Meier graph showing survival to 14 days CONCLUSIONS. The results demonstrate that HClA occurs frequently in a general ICU population and is associated with a significantly worse outcome. This is in contrast to previous studies which have demonstrated acidosis secondary to lactate and an elevated strong ion gap are associated with poorer outcomes, but not hyperchloraemia. A. Dumoulin 1 , A. Janssen 1 , J.J. De Waele 1 , J. Decruyenaere 1 , E.A. Hoste 1 1 Universitair Ziekenhuis Gent, Gent, Belgium Increased creatinine clearance or hyperfiltration has been reported in ICU patients. Enhanced renal clearance of antibiotics in patients with hyperfiltration may result in suboptimal antibiotic serum concentrations, and so affect patient outcomes. There are only limited data on the incidence of hyperfiltration in ICU patients. OBJECTIVES. Assess the epidemiology of hyperfiltration in a cohort of ICU patients. Single center retrospective cohort study, including adult patients hospitalized during the period 12/2008-2/2010 in the 50 bed ICU of the Ghent University Hospital, a tertiary care center. Data were retrieved by a specially designed electronic alert from the electronic ICU database. Urinary creatinine clearance (Ccr) was calculated as (24 h urine volume) 9 (urinary creatinine)/([creatinine day -1 + day 0]/2)/time. We retrieved the initial Ccr, and the minimum and the maximum Ccr. Hyperfiltration was defined as a Ccr C 120 mL/min. Patient days with anuria were excluded from the analysis. Data are reported as median (interquatile range).  patients with neurological disease. Several factors may interfere with water and sodium homeostasis in these patients, including factors that are also present in other ICU patients. In addition, these patients may develop a syndrome of antidiuresis (SIAD), or salt wasting syndrome (SW). The latter by secretion of brain natriuretic peptide (cerebral salt wasting syndrome (CSW)), release of atrial natriuretic peptide in volume overload, or renal salt wasting. OBJECTIVES. Assess the epidemiology of hypoNa in ICU patients with neurological disease. METHODS. Retrospective single center study. Data were retrieved from electronic ICU databases. Inclusion criteria were age C15 years, HypoNa (\135 mmol/L), and neurological disease. Only the first episode of HypoNa was considered. SIAD and SW was assessed with tonicity balance on data of the preceding 24 h in patients with urinary sodium[20 mmol/l, in whom other etiologies were excluded. SW was defined as negative salt balance and negative fluid balance, and SIAD as positive fluid balance.  To evaluate the prevalence of anaemia among patients attended at the Emergency Room (ER) and to estimate the need of an early diagnose and efficient treatment. Observational transversal trial in which 3 days in June were randomly chosen. All patient attending to the ER is included. Paediatric, gynaecologic and traumatic cases fall out of this research. Anaemia was diagnosed according to WHO criteria. Comparison means statistics methods for quantitative variables and Chi square for categorical variables were used. Prevalence data for the entire cohort, for men and women separately and for different age bands, medical history, anaemia related medication and red blood cells data were extracted. RESULTS. 861 patients were interned through the ER channel. 44% men, mean age 51.4 ± 22.2 years old (median 49), and 44,6% were subject of blood analysis using classification proceedings. From the 384 analysed 17.7% were anaemic. 8.5% of them were under 65 years old, 23% aged from 65 to 74 and 30.6% elderly patients (over 74 years old). Most frequent co-morbidity was Chronic Obstructive Pulmonary Disease (COPD) (n = 46, 5.3%) and most related drug aspirin (n = 71, 8.2%). 5% of the sample had a bleed but only 0.7% needed red blood cell transfusion. We found statistic difference in mean age, antiplatelets therapy use, bleeding episode, need for transfusion, creatinin value and hospitalisation. Anaemia classification according to VCM: microcytic 41.7%, normocytic 48%, macrocytic 10.3%. CONCLUSION. Unknown anaemia detection in the ER and its following treatment could be a strategy to further reduce allogeneic blood transfusion. The presence of disorders of sodium balance on ICU admission could be independently associated with mortality. We decided to study if the existence of dysnatremias at the time of ICU admission could be related to mortality in critically ill patients. We conducted a retrospective study in a mixed ICU with a database of 3,569 adults admitted consecutively over a period of 7 years (2001-2007) . Most patients (72.4%) had normal sodium levels (135 B Na B 145 mmol/L) on ICU admission. The frequencies of borderline (130 B Na B 135 mmol/L), mild (125 B Na \ 130 mmol/L), and severe hyponatremia (Na \ 125 mmol/L) were 14.3, 3.7%, and 1.8%, respectively. The frequencies of borderline (145 \ Na B 150 mmol/L), mild (150 \ Na B 155 mmol/L), and severe hypernatremia (Na [ 155 mmol/L) were 5.7, 1.3, and 0.8%, respectively. All types and grades of dysnatremia were associated with increased raw and risk-adjusted hospital mortality ratios. Multiple logistic regression analysis showed an independent mortality risk rising with increasing severity of both hyponatremia and hypernatremia. Odds ratios and 95% confidence interval (CI) for borderline, mild, and severe hyponatremia were 1.34, 1.78 and 1.79, respectively. Odds ratios and 95% CI for borderline, mild, and severe hypernatremia were 1.45, 2.23, and 3.45 respectively. CONCLUSIONS. This observation suggests the possible correlation of natremia on ICU admission with hospital mortality and confirms that both hypo-and hypernatremia present on admission to the ICU could be independent risk factors for poor prognosis in ICU populations. (1) . A relationship between mortality and delay from time of PARS trigger to critical care admission for patients not requiring surgery has recently been described (2) . OBJECTIVES. This study was to test the hypothesis that in cases of emergency laparotomy, prolonged physiological deterioration pre-operatively is associated with higher hospital mortality. We reviewed notes of patients that underwent emergency laparotomy between July 2007 and February 2009 at the Northern General Hospital, Sheffield, UK. Time at which patients triggered (PARS C 3), time of arrival in theatre and hospital mortality were recorded. Two-tailed Fisher's exact test was used to test null hypotheses that a delay of more than 10 h after PARS trigger does not affect hospital mortality. . 502 patients had an emergency laparotomy during this period. Of 108 notes retrieved by our patient record service, 3 were incomplete. Of 105 remaining patients 73 patients did not trigger, 6 of whom died (8.2% mortality). 32 patients triggered, 9 died (28.1%). Amongst 32 patients that triggered, 17 arrived in theatre within 10 h, 4 of whom died (23.5% mortality); 5 of the 15 patients that arrived in theatre after 10 h died (33.3% mortality). The odds ratio of death for those with a prolonged pre-operative deterioration (n = 15) compared to those without (n = 90) was 4.0 (95% CI 1.14-14.1, p = 0.038). The number needed to treat early to save one life was 5. CONCLUSIONS. Our data suggest that in cases of emergency laparotomy, those who trigger PARS pre-operatively have higher hospital mortality than those who do not. Specifically, our data indicate that patients triggering PARS C 3 should arrive in theatre within 10 h of first triggering.  Nothing is known about the effect of the duration of ICU-related therapies on acute outcome. To identify the importance of the duration of invasive ventilation and of renal replacement therapy for acute prognosis of surgical patients treated in an intensive care unit (ICU). We performed a retrospective analysis of prospectively collected data of an ICU patient cohort linked to a local database. Adult patients (n = 1,462) admitted to a 12-bed ICU at a university hospital in Munich, Germany, between 1993 and 2005 who had an ICU length of stay of more than 4 days and who were followed-up until the end of the acute phase after ICU admission. Cox-type additive hazard regression models were used to analyse linear, nonlinear or time-varying associations of therapeutic variables with survival time. Duration of different invasive therapies was evaluated by constructing specific vectors, which tested potential effects of time-dependant variables on outcome after a lag time of 7 days. . 808 patients (56.6%) were still alive at the end of the acute phase after ICU admission. During the acute phase, 85.3% of the patients required invasive ventilation, and 16.1% a continuous renal replacement therapy. Besides the underlying disease and disease severity at ICU admission, the need for invasive ventilation or renal replacement therapy was associated with poorer outcome. Duration of invasive ventilation shortened survival (with a lag of 1 week), if treatment lasted for more than 11 days (non-linear association). In contrast, duration of renal replacement therapy was unimportant for acute prognosis. CONCLUSION. Prolonged duration of invasive ventilation, but not of renal replacement therapy is inversely related to acute survival. OBJECTIVES. To identify the prognostic importance of preceding invasive ventilation, renal replacement therapy and catecholamine therapy for long-term survivors after surgical critical illness. We performed a retrospective analysis of prospectively collected data of an ICU patient cohort linked to a local database. Adult patients (n = 1,462) admitted to a 12-bed ICU between 1993 and 2005, who had an ICU length of stay of more than 4 days, were followedup until the end of the second year after ICU admission. Hazard function was explored by Weibull modelling and likelihood ratio tests. Cox-type structured hazard regression models were used to analyse linear, non-linear or time-varying associations of therapeutic variables with 2-year survival time of a patient subgroup, which had survived the period of high hazard. Hazard rate declined exponentially up to day 195 after ICU admission, and became constant thereafter. 808 patients reached this stable stage of their disease forming the study population. 648 of these patients (80.2%) were still alive at the end of the second year after ICU admission. Underlying diseases were major determinants for long-term outcome. Long-term mortality was significantly associated with the acute extent of physiological derangement during ICU stay (maximum Apache II score), but was independent from the duration of preceding invasive organ support. In surgical patients with a prolonged ICU length of stay, an exorbitant mortality exists for about half a year after ICU admission. Later on, life expectancy of surviving patients is largely determined by the underlying disease and, to a minor degree, by the acute extent of homeostatic disturbance during ICU stay. The duration of preceding invasive therapies does not limit long-term survival. B. Rozec 1 , A. Desdoits 2 , K. Asehnoune 2 , C. Lejus 2 , Y. Blanloeil 1 1 CHU Nantes, Hôpital Laënnec, Anesthesia and Intensive Care, Nantes, France, 2 CHU Nantes, Hotel-Dieu, Anesthesia and Intensive Care, Nantes, France Postoperative stroke could be an endpoint in non-cardiac surgery morbidity studies [1] . Therefore, its frequency established in old studies and considered higher than in the non surgical population remains to be estimated more precisely. OBJECTIVES. The aim of this evaluation was to calculate the frequency of stroke, firstly in a prospective study, and secondly in a review of the literature. Strokes diagnosed in the prospective follow-up (30 days) of surgery for hip fracture was confirmed by a neurologist and a CT-scan. Retro and prospective studies (except abstract) published in journals (PubMed, Ovid) from 1961 to 2009 were included in the analysis. Statistics:% IC95, multivariate analysis (effects of population size, date of publication, type of surgery, patient age, prospective vs. retrospective studies were evaluated). RESULTS. Mean pre-operative POSSUM scores between the two groups showed no significant differences. Continuous measurements taken by the ODM showed a mean stroke volume increase of 20 mls at the end of surgery (Paired t test, p-value = \0.001). 91 (40.6%) patients following implementation compared to 121 (52.2%) prior to implementation required post-operative critical care admission. Following ODM implementation, critical care LOS was reduced from 3.7 to 2.1 days and post-operative length of stay within hospital was also significantly reduced by 6.5 days. INTRODUCTION. Local (skeletal muscle necrosis) and remote (lung neutrophil infiltration) ischemia-reperfusion injury (IR) have been described in animals [1] and humans after aortic surgery. Postconditioning with cyclosporinA (CsA) was recently shown to prevent skeletal muscle infarction in pig latissimus dorsi muscle flaps [2] . OBJECTIVES. The aim of this study was to investigate local (gastrocnemius muscle, GC) and remote (lung and liver) IR in rats exposed to aortic cross-clamping with special focus on mitochondrial respiratory chain complexes activities and reactive oxygen species (ROS) production. We also investigated whether pharmacological post-conditioning with CsA would be protective in this setting. METHODS. Anaesthetized (isoflurane) and mechanically ventilated Wistar rats underwent laparotomy and were randomly assigned to one of the 3 following groups: Sham (n = 8), IR (n = 10, clamping of the infrarenal aorta for 3 h followed by 2 h of reperfusion), IR+CsA (n = 7, 10 mg/kg CsA administered intraperitoneally 90 and 30 min prior to reperfusion). Maximal oxidative capacities (Vmax) and complexes I, II and IV of the mitochondrial respiratory chain were determined using glutamate-malate (Vmax) and succinate (Vsucc) as substrates in the GC permeabilized fibers and freshly harvested liver and lungs isolated mitochondria. Tissue superoxide anion production was assessed with dihydroethidium (DHE) in thin sections of frozen GC. Data are expressed as mean±SEM and analyzed with ANOVA followed by Newman-Keuls post-hoc test; a p value\0.05 was considered significant. Esophagectomy with gastric tube reconstruction is associated with frequent postoperative complications due to a (surgery induced) systemic stress response, provoked by the overproduction of proinflammatory cytokines. In elective postoperative esophagectomy patients, we previously showed that levels of serum CRP are associated with the occurrence of postoperative complications and reduced survival. Plasma NGAL (pNGAL) and urine NGAL (uNGAL) are early predictors of acute kidney injury, however sepsis/sirs seems to accelerate their production even in the absence of AKI. OBJECTIVES. We examined the role of pNGAL and uNGAL as early indicators of postoperative complications at the ICU in patients undergoing elective esophagectomy surgery METHODS. In a prospective follow-up cohort study, data of a total of 49 patients admitted to the ICU following elective esophagectomy with gastric tube reconstruction were collected in the period from September 2007 to April 2008. Patients who developed AKI at the ICU were not included in this study. Postoperative pNGAL and uNGAL levels were determined at consecutive time points and the relation between the course of postoperative serum pNGAL and uNGAL, development of complications and outcome of the patients was investigated.  In our experience, assisted by DV robot radical prostatectomy, despite requiring longer surgery time, was shown to be safer than conventional radical prostatectomy, with a significant less blood loss during surgery, less need for blood transfusion, fewer postoperative complications, included need to reoperate, and also a shorter length of hospital stay than conventional radical prostatectomy. OBJECTIVES. The aim of the study was to evaluate safety and effectiveness of M infusion, impact on fluid balance and urine output (UO) and also whether we can avoid CVC line insertion. We conducted a prospective analysis of patients (pts) treated with M who were admitted to the SHDU between Oct 2008 and Aug 2009. Demographic data and vital parameters were collected through the individual questionnaires before (0) INTRODUCTION. An ever increasing number of patients over the age of 80 year are being admitted to critical care units [1] . With no marked expansion in the number of critical care beds in our hospital and in the health region as a whole, this may lead to a huge strain on the service provision, with less availability of beds to treat elective and other emergency admissions. To determine the factors that affect outcome following admission to critical care of patients aged 80 years and above(medical and surgical). METHODS. Ethical approval was sought but deemed unnecessary as our study was observational (non-interventional). We prospectively looked at the number of patients (age 80 year and above) who were admitted to ICU/Warrington General Hospital over the period of 1 year. Our unit is a modern, 18-bedded general ICU with an annual admission rate of approximately 800 (340 level 3 and 460 level 2 care). We examined data that was related to the source of admission, gender, APACHE 2 scores, the use of vasopressors (including inotropes) and the need for IPPV in the first 48 h of admission. We analysed the effect that each factor had on patient mortality (applying Chi-square and Z tests). We followed the patients up for 6 months post-discharge from ICU. The final report produced results that showed ICU, hospital and 6-month mortality. RESULTS. There were 53 admissions during the period 1st May 2008-30th April 2009. Last set of mortality data was obtained in September 2009. Female: Male ratio was 30:23. The overall 6-month mortality was 64%. In our study, patients admitted through A&E, theatre and ward had mortality rates of 83, 73 and 65% respectively. Patients who received vasopressors (including inotropes) in the first 48 h had a significantly lower mortality than patients who did not receive any vasopressor support (27 vs. 31%). Invasive ventilation in the first 48 h of admission was associated with significantly higher mortality rates (31 vs. 25%). In this patient cohort, the overall 6-month mortality is higher than the general ICU population. Factors that determine mortality include the source of admission to ICU, the need for vasopressor support and invasive ventilation in the first 48 h of admission. INTRODUCTION. The optimization of oxygen delivery (DO 2 ) is an intervention with fluids and inotropics to achieve supranormal goals of DO 2 during surgery, before disturbances of perfusion occur and oxygen debt accumulates. Oxygen debt is directly linked to multiple organ failure and death. We aimed to evaluate the temporal pattern of oxygen debt in the intraoperative period in patients included in two studies of goal directed therapy to supranormal values of DO 2 . Oxygen debt was calculated from data obtained from 87 high risk surgical patients included in two randomized controlled trials were analysed. 1, 2 The oxygen deficit was calculated by subtraction of the basal VO 2 value from subsequential values of VO 2 obtained during surgery and after the ICU admission. The oxygen debt was calculated by the product of oxygen deficit and time (minutes) between measurements. Patients treated with supranormal goals of DO 2 ([600 ml/min/m 2 ) using fluids and dobutamine showed lower levels of oxygen debt during ICU stay. The peak of oxygen debt was 4,440 ml/m 2 at 390 min of surgery in the control group in comparison to 2,040 ml/ m 2 in the protocol group. 1 In the second study, the peak of oxygen debt occurred at 240 min in the volume group (14,670 ml/m 2 ) which was significantly higher than in the dobutamine group (2,720 ml/m 2 ). 2 Higher oxygen debt during peroperative period correlated with poor outcome as shown on the original studies. CONCLUSION. The use of supranormal goals of DO 2 with dobutamine and fluids in the peroperative period results in lower oxygen debt.  Post-operative nausea and vomiting (PONV) is a common problem in the patients undergoing laparoscopic surgery. The release of serotonin during surgical procedure may induce PONV. We investigated if postoperative increase in plasma serotonin metabolite was associated with PONV after gynecologic laparoscopic surgery. OBJECTIVES. The patients who experienced nausea after gynecologic laparoscopic surgery (PONV group, n = 20) and patients who had no or mild nausea (control group, n = 20) were enrolled into this study. Postoperative nausea was assessed during 1 h in Post-Anesthetic Care Unit and ondansetron was administered if needed. Blood samples were obtained before anesthesia and 1 h after surgery. Plasma serotonin metabolite (5-hydroxy indole acetic acid, 5-HIAA) was analyzed using high performance liquid chromatography (HPLC) assay. Perioperative change of plasma 5-HIAA and the degree of nausea were compared between groups. RESULTS. The degree of post-operative nausea varied from 0 to 100 (100 mm visual analogue scale, VAS) and median value was 0 (0-20) in control group and 60 (40-100) in PONV group (P \ 0.001). Average 5-HIAA concentration of all patients increased after surgery (3.65 ± 0.90 to 4.36 ± 1.17 ng/ml, P \ 0.001). Baseline plasma 5-HIAA concentrations were similar between groups, however, 5-HIAA of PONV group increased higher after laparoscopic surgery compared with control group (3.69 ± 0.89 to 4.62 ± 1.12 ng/ml vs. 3.61 ± 0.93 to 4.10 ± 1.20 ng/ml, P = 0.03). CONCLUSIONS. The patients who experienced post-operative nausea showed more increase in 5-HIAA concentration. PONV after gynecologic laparoscopic surgery may be associated with a peripheral release of serotonin. INTRODUCTION. The intracavitary ECG method is an easy, accurate and inexpensive methodology for real time positioning of the tip of central venous catheters. In particular, when the ECG method is performed using not the guidewire but the saline-filled catheter as electrode, the methodology is completely safe and can be applied to any central venous access device (VAD). We have tested a new specific device (Sapiens TLS, Romedex) which simplifies and standardizes the ECG method; it consists of a hardware (a small box with cables connecting it to a PC and to ECG electrodes) plus a software (which can be used on any PC). We tested the Sapiens TLS in 334 patients who underwent positioning of central VADs (182 totally implantable ports, 114 PICCs and 36 tunnelled catheters, all inserted by ultrasound guided venipuncture). Our goal was to position the tip of the catheter at the cavoatrial junction: the length of the catheter was estimated by anthropometric measurements and the correct positioning was achieved by the intracavitary ECG method during the procedure. The final position was checked by a post-procedural chest x-ray. There was no insertion-related complication. The intracavitary ECG method was easily performed in all cases. At the final x-ray control, 97% of all tips were correctly positioned at the cavo-atrial junction (±1 cm), confirming the accuracy of the intracavitary ECG method. The anthropometric measurement tended to overestimate the length of the catheter both in port insertions ([1 cm in 30% of cases) and in PICC insertions ([1 cm in 35% and [2 cm in 15% of cases). CONCLUSIONS. The intracavitary ECG method as performed with the Sapiens TLS was more accurate than the anthropometric measurement in terms of correct positioning the tip of the catheter during the procedure. The Sapiens TLS simplified the method, by standardizing the ECG tracking, and making it easy (no need of ECG monitor, no need of ECG commuter since the Sapiens TLS displays simultaneously the surface ECG and the intracavitary ECG). Also, the Sapiens TLS allows the print-out of the intracavitary ECG reading for documentation, as well as the storing of the ECG reading in a computer-based database.  Previous studies have shown that hypernatremia impact graft function after orthotopic liver transplant (OLT). The purpose of this retrospective investigation was to determine whether differences in serum sodium values after OLT influenced postoperative short-term patient outcomes. OBJECTIVES. The study was aimed at exploring the incidence of hypernatremia after orthotopic liver transplantation (OLT) in order to provide critical monitoring and intensive care services. Clinical and SICU laboratory data were collected; serum sodium was assessed an average of three times per day. Hypernatremia was defined as two daily values of serum sodium above 145 mmol/L. From 2004 to 2005, we analyzed 111 patients with hypernatremia after OLT. The major outcome was death in the ICU after 14 days. CONCLUSIONS. In SICU, OLT patients are easy to suffer from hypernatremia (42.3%) and have high mortality (34.0%). Hypernatremia is associated with an increased risk of death in patients with OLT. Early active fluid infusion is crucial, besides optional continue venovenous hemofiltration (CVVH). Cywinski OBJECTIVES. The aim of this study was to determine the value of blood lactate sequential dosages during the first 24 postoperative hours for the diagnosis of GD. We conducted a retrospective study on consecutive patients admitted in ICU after LT, between July 2006 and June 2008. LT with auxiliary or splited grafts were excluded so were patients with septic or cardiogenic shock occurring during the first 48 h after LT. Criteria for GD diagnosis were: SGOT [ 2,000 U/L with PT \ 50% between D2 and D7, or re transplantation or death between D1 and D7. Demographics and biological data (transaminases, PT, serum bilirubin) were recorded between D0 and D7. Hopital Bicêtre, Kremlin-Bicêtre, France, 3 Hôpital Saint-Louis, Paris Diderot University, Biostatistics, Paris, France, 4 Hôpital Hôtel-Dieu, Medical Intensive Care Unit, Nantes, France, 5 Hôpital Gabriel Montpied, Nephrology and Transplantation, Clermont-Ferrand, France, 6 Hôpital Edouard Herriot, Medical Intensive Care Unit, Lyon, France, 7 CONCLUSIONS. In kidney transplant recipients, ARF is associated with high mortality and graft loss rates. Increased Pneumocystis and bacterial prophylaxis might improve these outcomes. Early ICU admission might prevent graft loss.  A. Umgelter 1 , K. Lange 2 , P. Büchler 2 , H. Friess 2 , R.M. Schmid 1 1 Technical University of Munich, Transplantationszentrum München rechts der Isar, II. Medizinische Klinik, München, Germany, 2 Technical University of Munich, Transplantationszentrum München rechts der Isar, Chirurgische Klinik, München, Germany INTRODUCTION. The shortage of donor organs in the Eurotransplant region results in late allocation at a time when liver disease is already very advanced. The severe condition of patients at that stage negatively affects outcomes of orthotopic liver transplantation (OLT). To support decision-making in these situations, clinical data are urgently needed. OBJECTIVES. To evaluate outcomes of liver transplantation (OLT) in ICU-patients with multi-organ failure due to advanced Acute on Chronic Liver Failure (ACLF). METHODS. In our centre, patients on the waiting list for OLT are not automatically excluded from the procedure, if their condition deteriorates to multi-organ failure. A consensus of the team in each individual case is based on criteria such as the previously manifested will of the patient, exclusion of current infection, absence of neurologic damage or other organ damage expected to impair the possibility of rehabilitation. We retrospectively analyzed a database comprising data from evaluation for the waiting list of all patients transplanted in our center since implementation of the MELD-score for allocation. Only cirrhotic patients treated on our intensive care unit before transplantation were included. Patients treated on the ICU before retransplant for primary graft failure were excluded from analysis. Data are presented as median (25 th -75th percentile). Wilcoxon or Mann-Whitney U tests were used for comparisons of paired and unpaired data, respectively. RESULTS. From January 2007 until September 2009 15 patients (7 m, 7f; age 58 (52-65) years) fulfilled inclusion criteria. Cirrhosis was due to alcohol (n = 7), HCV (n = 3), alcohol+HCV (n = 2), alpha-1-antitrypsin deficiency (n = 1), budd-chiari-syndrome (n = 1) or cryptogenic (n = 1). Upon ICU admission ICU, APACHE II scores were 26 (22-31), SOFA scores 11 (8-14); MELD 25 (21-34). After 14 (3-21) days on the ICU, directly before transplantation, SOFA scores had deteriorated in all patients to 18 (17-21) and MELD scores to 35 (25-38). 7 patients had renal replacement therapy and 4 patients were on single-pass albumin dialysis. The 30-day-mortality was 27%, hospital mortality 47% and 1-year mortality 60%. In hospital survivors, surprisingly, SOFA scores (14 (11-16) vs. 8 (8-11); p = 0.029) and INR (3.1 (2.5-3.5) vs. 1.9 (1.3-2.1); p = 0.006) upon admission to the ICU were significantly higher than in non-survivors. There were no significant differences in age, gender, MELD scores or use of extracorporeal treatment in survivors vs. non-survivors. CONCLUSIONS. Liver transplantation in selected cirrhotic ICU-patients with multi-organ failure is not medically futile. Outcome, however, is much worse than usually considered acceptable. OBJECTIVES. This work tries to study the clinical profile and the results with the immediate postoperative outcome of patients suffered from pancreas-kidney transplantation (PKT) and only pancreas transplantation (PT) admitted in our Intensive Care Unit (ICU) setting. METHODS. Prospective study during 4 years (from 2006 to 2009). We recorded epidemiological, demographical and clinical data, surgical and postsurgical complications, therapy, morbidity and mortality rate, length of stay in ICU, organs survival, etc. The data were expressed in mean±typical deviation, median and percentages. RESULTS. We recorded 47 patients. Table 1 expresses some of the data. The mean age was 41.8 ± 7.7 years old male 74.5%. PKT from unic deceased donor: 83%. PT: 17%. The mean ischemia time was 12.4 ± 2.4 h for the kidney and 10.27 ± 3.4 for the pancreas. The most frequent surgical complications were bleeding (4.3%), technical difficulties (12.8%) and anesthetic complications (4.3%). Postoperative immunosuppression consists in methyl-prednisolone, tacrolimus, mycophenolate mofetil and thymoglobulin (as our protocol recommends) and was administered to the 100% of the patients. Prophylactic antibiotic and antiviral therapy (ampicillin, ceftriaxone, fluconazole and gancyclovir) was given to almost the 95% of the patients. Table 2 expresses the blood test results. The mean insulin requirements per day during the stay in ICU was 0 (0-8.5) IU. Table 3 represents the complications in the ICU. The first leading cause of reoperation was vascular thrombosis (50%) followed by intraabdominal bleeding (20%). CONCLUSION. The clinical profile of this patient in our setting is a 42 years old man, with high blood pressure, retinopathy, dialysis, pancreas-kidney transplant recipient, with unic decesed-donor. He needs no insulin or minimal requirements. The principal complication is pancreatic vascular thrombosis that frecuently leads to removal of the graft. (1) . In a clinical practice, a specific marker to evaluate and predict ischemic-reperfusion injury in liver transplantation (OLT) is not available. Poor organ perfusion and high PCT levels appeared to predict early graft failure only in the cardiac donor (2) . OBJECTIVES. We evaluated PCT as a predictor of ischemic-reperfusion injury in liver transplantation and PDR, as a predictor of complication and graft outcome. METHODS. Prospective study. 16 patients (age, Child-Pugh score, aetiology of liver cirrhosis) undergo liver transplant. Bilirubin levels and PDR (0.5 mg/kg of IG in a central catheter with LIMON System Ò , Pulsion Medical System, Munchen, Germany) was measured once a day for 3 postoperative days (POD). On the same day, Aspartate AminoTransferase (AST/GPT) and Alanine AminoTransferase (ALT/GOT) were measured. SOFA score was as a patient severity score. Serum level of PCT, C-Reactive Protein (CRP) was collected at the liver reperfusion time and from the 1st to the 3rd POD. Warm and cold ischemia time was collected. Statistical analysis was performed with Wilcoxon, Spearman tests (P \ 0.05). Linear correlation was performed too. A small rise on PCT levels were observed early after OLT, with a peak in the 1st day 1 after OLT. It was associated neither with hepatic post-OLT dysfunction nor with other non infective complications. PCT increased significantly after liver reperfusion (p \ 0.01) and correlate with PDR on the 2nd POD, but not correlation were found with CRP, white blood cells, or liver enzymes after OLT. CRP levels increased rapidly after OLT. PCT increasing after liver reperfusion correlated with Child-Pugh OLT (R = 0.4 at 2nd POD) in the recipients. The cold ischemia time did not correlate with PCT serum levels after liver reperfusion as well as the warm ischemia time. A negative correlation was found between PDR and liver function in the recipient. PDR did not correlate with Child-Pugh score. The cold ischemia time well correlated with AST and ALT on the first day after transplant (R = 0.4). It negatively correlate with PDR (R = -0.6) at the same time. The warm ischemia time did not correlate with PDR, AST and ALT. The same results were found between PDR and liver enzymes and lactates. No correlation was found between PDR and SOFA score. CONCLUSIONS. PCT peak in the recipient at reperfusion and early post operative was not predictive of graft dysfunction or other non infective complication. It may represent a marker of ischemia-reperfusion injury. CRP levels increased rapidly after OLT and it could be an expression of surgical procedure, and it doesn't correlate with PCT. OBJECTIVES. The aim of this prospective observational study was to describe the kinetics of NGAL following renal transplantation and to assess its ability to predict delayed graft function. INTRODUCTION. Lung transplantation is the recognized therapy for end-stage respiratory failure. Many serious medical complications have been described occurring from months to years after lung transplantation, often necessitating admission to an intensive care unit (ICU), which has been associated with a high mortality. We examined the factors associated with mortality. METHODS. All patients admitted to the general intensive care unit between 2000 and 2009 following lung transplantation were included in this retrospective study. Data was collected regarding demographic parameters, intensive care unit stay and outcome. Over the study period, Forty patients were admitted to the ICU. The main pretransplant diagnosis was idiopathic pulmonary fibrosis followed by chronic obstructive pulmonary disease. The majority (93%) of patients required mechanical ventilation during their ICU stay. The main reason for ICU admission was septic shock in 22 patients (55%) of cases. An organism was isolated from 19 of these patients; in 11 cases, the organism was shown to be multi-drug resistant. The ICU mortality was 62.5%. Non-survivors were characterized by a higher admission SOFA score (P = 0.02), an admission diagnosis of sepsis (87.5 vs. 37.5% for all other diagnoses, P \ 0.001), and a requirement for mechanical ventilation (P = 0.02). In addition, the incidence of chronic rejection was significantly higher in the non-survivors (P = 0.02). CONCLUSIONS. Severe sepsis remains the most important factor associated with a poor outcome. New strategies are required to alter the course of this common complication of lung transplantation. (the 80% of the infections were respiratory) and 13 (10%) patients presented pulmonary allograft rejection. According to our immunosuppressive protocol, we started with methylprednisolone and tacrolimus and we added mycophenolate later. The CCD length of stay was 9 (2-102) days and the median days of mechanical ventilation were 4 (1-92). Thirteen (10%) patients died, basically due to refractory respiratory failure, multiple organ dysfunction syndrome and haemorragic shock. CONCLUSIONS. In our large series of lung transplantation a remarkable incidence of complications has been observed. Despite this complications, lung transplanted patients presented an excellent short term outcomes. INTRODUCTION. Acute kidney injury (AKI) poses a massive challenge after kidney transplantation, especially when kidneys from brain dead adult donors are transplanted into small paediatric recipients. Inflammation mediated by cytokines is a key event in experimental models of ischaemic AKI. OBJECTIVES. The aim of this study was to investigate whether remote ischaemic preconditioning (rIPC) reduced the inflammatory cytokine load and apoptosis in the kidney after transplantation. METHODS. Kidneys were harvested from eight 65-kg brain dead donor pigs and transplanted into two groups of 15-kg recipient pigs after 21 h of cold ischaemia. In one group (+rIPC, n = 8) rIPC was performed before the 10-h reperfusion period, while no rIPC was performed in the other group (-rIPC, n = 6). Non transplanted kidneys from 7 brain dead pigs served as controls. Concentrations of TNF-a, IL-6, IL-8, and IL-10 in renal tissue were determined by an immuofluorometric assay. Renal apoptosis was quantified by immunohistochemistry for activated caspase-3. High concentrations of TNF-a, IL-6, IL-8, and IL-10 were detected in renal cortex in all three groups. No statistical differences between the two transplanted groups were found for any of the cytokines. Compared to controls higher cortical levels of IL-10 (control vs. -rIPC, p = 0.02, control vs. +rIPC, p = 0.006) and lower levels of IL-6 (control vs. -rIPC, p = 0.03, control vs. +rIPC, p = 0.01) were found in transplanted kidneys. No differences were detected for TNF-a or IL-8. Transplantation significantly increased the number of apoptotic cells in both glomeruli and tubuli (control vs. -rIPC, p = 0.0005, control vs. +rIPC, p = 0.0001). No difference was found between recipients, (p = 0.26). CONCLUSIONS. In transplanted kidneys from brain dead donors exposed to 21 h of cold ischemia and ±rIPC, we found increased tubular and glomerular apoptosis, but no increase in pro-inflammatory cytokines. The levels of IL-10 were higher in transplanted kidneys compared to controls. Remote ischaemic preconditioning did not modify cytokine load or apoptosis in the kidney graft. OBJECTIVES. We present the case of a patient with confirmed HIT and the management of its status during the perioperative period of the cardiac transplantation. A 45 years old patient with a cardiac myxoma was operated under heparin anticoagulation. Thrombocytopenia is noted at day 5 after surgery. An enzymelinked immunosorbent assay (ELISA) was performed and since the result was positive, the treatment was changed to Lepirudin. The HIT was confirmed by a heparin-induced platelet activation (HIPA) test. The internal jugular vein thrombosis was observed. The post operative evolution was marked by the necessity of the implantation of a ventricular assisted device. The patient was submitted to two sessions of plasmapheresis which turned the antibodies negative. The patient underwent heparin anticoagulation during the surgery time and Bivalirudin as the post operative treatment. The antibodies remained negative. Two months later, the cardiac transplantation was performed; heparin was used for anticoagulation during surgery. Due to a restored renal function, Danaparoid was used postoperatively. CONCLUSIONS. HIT is a serious complication of heparin therapy. The diagnosis is difficult. When HIT is strongly suspected, a non-heparin anticoagulant is recommended. The choice of the anticoagulant depends on the hepatic and renal function. Plasmapheresis is a solution for the antibody purging prior to cardiac surgery. OBJECTIVES AND METHODS. A nationwide qualitative study investigating their perception of the meaning of professionalism, and how they learn to behave professionally was performed. All eight Dutch ICM training centres participated. The moderator asked participants to clarify the terms professionalism and professional behaviour. Next, participants were asked to explore the questions 'How do you learn the mentioned items?' and 'What ways of learning do you find useful or superfluous?' Qualitative data analysis software (MAXQDA2007) facilitated analysis: an inductive approach applying open, axial and selective coding principles was used. RESULTS. 35 fellows across eight groups participated. Results relating to the subtopics 'Elements of professionalism' and 'Teaching and learning of professionalism' are described consecutively. Elements of professionalism relevant to intensivists: The elements most frequently addressed were communication, keeping distance and boundaries, medical knowledge and expertise, respect, teamwork, leadership and organization and management. Medical knowledge, expertise and technical skills seem to become more tacit when training progresses, and relate to ethical, cultural and legal dilemmas originating in the specific ICU context, and working as a multidisciplinary ICU team member. Teaching and learning professionalism: Topics can be categorised into the themes workplacebased learning, by gathering practical experience, by following examples and receiving feedback on their actions, including learning from own and others' mistakes. Formal teaching courses (e.g. communication) and scheduled sessions addressing professionalism aspects were also valued. CONCLUSIONS. The emerging elements considered most relevant for intensivists were adequate communication skills, and keeping boundaries with patients and relatives. The specific ICM context, and working as multidisciplinary ICU team member substantially influenced the ICM fellows' perception of professionalism. Whereas medical knowledge, expertise and technical skills seem to become more tacit when training progresses, professionalism issues continue to be learned during ICM training. Professionalism is herein mainly learned 'on the job' from role models. Formal teaching courses and sessions addressing professionalism aspects were nevertheless valued, and learning from own and others' mistakes was considered especially useful. Selfreflection as a starting point for learning professionalism was stressed. The latter can e.g. be stimulated by means of assessment, structured feedback and use of portfolios, for which guidelines are now being developed within the CoBaTrICE project. Introduction: During the past decades there has been an increase in mass casualty events with changing geopolitical and climate situations. In a mass casualty event comprehensive care for the individual is expected [4] . To meet these obligations further education in disaster medicine seems obligate [1] . Therefore the German Home Department responsible for mass casualties passed a concept for student education in disaster medicine [2] . OBJECTIVES. The introduction of a Summer Academy ''Disaster Medicine'' (SADM) is a first approach at Charité University of Berlin to establish a curriculum for disaster medicine. The SADM is sponsored by the German Academic Exchange Service (DAAD) for 3 years. The enhancement of student education in disaster medicine is supposed to raise the level of skills and knowledge of future physicians in the face of mass casualties [5] . International participants and an interdisciplinary approach are keystones of the SADM concepts. In a globalized world international networking should enable students to exchange knowledge about the handling of mass casualties in different parts of the world. Disaster medicine needs an interdisciplinary approach [3, 4] . Psychological aspects are always a key factor in the successful handling of mass casualties. The teaching concept of SADM consists of four parts: e-learning ahead of a 2 week training session, emergency medicine training, disaster medicine training and excursions to evaluate already existing disaster concepts. The concept will be evaluated [3] using a knowledge test, a skills test and a structured written interview concerning motivation and satisfaction of the students. CONCLUSION. The support of the DAAD for three consecutive years allows a further evolution of this concept by integrating the evaluation results. The SADM should enable future physicians to meet the challenges of mass casualties with greater confidence and skills. Educational programs are being set up to provide training and skills in these core subjects for dental care professionals. OBJECTIVES. To evaluate dental practitioner (DP) skills and knowledge prior to a 1 day continuous medical education (CME) training session, and assess training efficacy at the end of the session. METHODS. Nine (9) multiple choice questions concerning medical emergencies and pain treatment were handed out to DPs at the beginning of CME training sessions over a 1 year period in metropolitan France. After the 1 day training session, the same multiple choice was taken again and collected for statistical analysis (Kruskall-Wallis test). EXAMINATION BEFORE AND AFTER CME, P \ 0. We evaluated 494 DPs and obtained a 100% answering rate. Before the CME session, the correct answer rate was below 50% for several items, like the 112 european emergency telephone number or performing back blows before the Heimlich manoeuver for severe choking, and below 75% for identifying vasovagal malaise by bradycardia, giving insulin for diabetic malaise or treating anaphylactic shock by epinephrine. More worrisome still is the fact that nearly 1out of 4 DPs would prescribe non steroidal anti inflammatory drugs (NSAIDs) during late pregnancy. The overall impact of CME was highly significant (p \ 0.001), showing real efficacy but correct answering rates after CME still remained between 82 and 94%, which leaves room for improvement. Further studies are under way to evaluate long term memorization of CME sessions in order to determine their optimal frequency. CONCLUSIONS. Medical skill and proficiency evaluation before CME training sessions for DPs allows to target the training sessions and to evaluate their efficacy in the short run. INTRODUCTION. The positive impact of immediate bedside echocardiography for rapid diagnosis and management of acute hemodynamic disturbances in the critically ill patient is well established. It is advocated that peri-resuscitation echocardiography should be an integral part of training for all intensivists. However, a major challenge for the intensive care clinician is access to appropriate echocardiography training outside of specific fellowship programmes. OBJECTIVES. One suggestion to meet this training need is to combine supervised practical instruction with self-learning through the use of on-line educational tools. The internet is ideally suited to studying echocardiography as e-tutorials serve to convey theoretical principles whilst stills/video clips aid image recognition and interpretation. Here we review currently available web based learning resources. METHODS. An online search was performed using Google Ò and Yahoo Ò search engines with the following key words: echocardiography, TTE, TOE, education, training, programme, courses, on-line, web-based, critical care. The resulting hits were screened to identify relevant sites and these were then evaluated independently by each author before an overall consensus was reached. One author had no previous echocardiography training whilst the other had passed the American National Board of Echocardiography Perioperative Transesophageal Echocardiography examination. A total of 16 sites were identified for evaluation (see Table 1 ); these are listed below with a brief description. CONCLUSIONS. Our search demonstrated a number of sites dedicated to facilitating echocardiography training. These varied from those which were essentially atlases, to those with a modular learning programme supported by interactive discussions and self assessment. Some were targeted at the beginner seeking a basic understanding of echo whilst others were aimed at the enthusiast preparing for examinations. With growing interest in critical care ultrasound it is likely that we will see the use of such resources increasing. However echocardiography is a practical skill and it is essential that on-line learning is conducted in parallel with supervised bedside training in a process of 'blended learning'. 2. To determine level of supervision for trainees in the elective MRI setting as compared with critical care transfers to MRI. 3. To gain insight into the learning resources used by medical staff on MRI to allow existing training to be improved. METHODS. Two online surveys were conducted in February 2010, with invitations to participate via e-mail. The survey population included all anaesthesia and intensive care medicine consultants in the local tertiary neurosciences centre and all trainees for these specialties in the Northern Ireland Deanery. First year trainees were excluded. RESULTS. The response rate was 61% for consultants and 50% for trainees. In total, 35 consultants responded with over 50% having no experience of MRI at consultant level, even though 70% worked in areas where MRI skills could be required. 54 trainees completed the survey, with 70% having experience of MRI in the elective setting, all of whom had been directly supervised by a consultant. 65% of trainees had experience of critical care transfers for MRI, but this was in an unsupervised capacity more than 50% of the time. Despite this, 44% of trainees did not feel competent to work in MRI unsupervised. Web based learning was found to be a poorly utilised MRI training tool, particularly among consultants. CONCLUSION. We have demonstrated a need to formalize training for MRI in our institution and for trainees in the local deanery. We propose to meet this need by a combination of e-learning and experiential sessions with defined competencies. This should increase the cohort of physicians who can provide optimal care 3, 4 in this unique environment and subsequently improve both service delivery and patient safety. was not a priority in health systems. Following the 1999 report: ''To err is human. Building a safer health system'', by the Institute of Medicine, which had a great impact on the media, ''patient safety'' is included as an strategic line in most health systems. Training in patient safety is essential to implement safety culture and as a result improve it. For that reason we developed a training program (3 courses) in 2009 for 15 physicians and 30 nurses from our ICU. OBJETIVE. Patient safety training program assessment. METHODS. We designed a 17 h course (70% practical), using simulated scenarios common in ICU clinical practice. We pointed out the relevance of human factors such as teamwork and communication, and its leading role in the genesis of error. We discussed a ''sentinel case'', using the root-cause analysis method, and analysed an ICU process through failure mode and effects technique. Adverse events reported to the Department website were reviewed. Participants and instructors discussed specific aspects about insertion of central venous catheter, prevention of nosocomial infection and improvement of security in the different groups of ICU patients, highlighting the need for fidelity to the established protocols for this purpose. Finally, participants completed a survey that assessed various aspects in a score from 1 to 5. Results indicated the most and least interesting aspects and suggestions for improvement were included. RESULTS. 45 assessment surveys were analysed. Participation rate was 100%. Overall results: appropriate and clear targets, accomplished goals and utility (4.4) , appropriate content objectives and organization (4.3) , time invested in development activity and oral presentations (4.1), faculty competence (4.6) , interest and faculty adaptability to the group needs (4.7), degree of satisfaction and practices (4.5) . Most interesting comments: practice of root-cause analysis (33.3%), continued participation and motivation (25.7%), practices with HPS and group discussions (22.2%), importance of human factors (20%), theory and practice good balance (15.6%). Least interesting comments: too condensed contents (13.3%), few scenarios (6.7%)Suggestions: do it again(33.3%), enhance preventive medicine sessions (15.6%), increase course duration (13.3%). CONCLUSIONS. Overall assessment was positive. Adaptability and competence of teaching staff have been the most valued aspects; too condensed contents and oral presentations were the least valued. Practice of root-cause analysis ease of participation, ongoing motivation, HPS scenarios and group discussions are the most appreciated activities. Final Comment: good acceptance has encouraged us to continue in 2010 to complete participation of all interested professionals. INTRODUCTION. Our intensive care unit (ICU) was one of the first to initiate a humanization program in daily routine in 1996. Since then, the program suffered changes, the ICU grew up in number of beds and complexity and had great renewal of the members of our interdisciplinary group. OBJECTIVES. To improve our knowledge we continually re-evaluated the stress factors for the patients from our staff members' perspective, putting them in the patients place. METHODS. Between January and March of 2010, a research form was used with the interdisciplinary ICU team. The following items were analyzed: profile of the interviewed, evaluation of the environment of the ICU and the stress factors for the patients. The results were compared with the questionnaire form filled by the patients after ICU discharge, as a part of our quality improvement program. RESULTS. About 84.41% of our ICU team answered the research (n = 65). The mean age is 32.61 years (SD 6.74), 58.50% of female, 58.50% married, 50.85% Protestants and 38.50% Catholics and ICU professional experience of 6.75 years (SD 4.65 ). Our ICU is noisy for 70.80%, very illuminated for 70.80%, easy-going for 53.80%, organized for 44.61%. In a 2005 preview research we found closed results. According to the team, factors that bother the patients are: noise (60.0%), bed bath (58.46%), loneliness (55.38%), lack of privacy (55.38%), anxiety (53.84%), distortion of time perceptions (35.38%) and fear (27.69%). The patients (n = 95) described as main complaints after ICU discharged: distortion of perceptions of time (50.70%), anxiety (41.74%), sleeplessness (29.24%), noise (29.24%), loneliness (20.83%), fear (8.32%), pain (4.35%)bed bath (4.35%) and lack of privacy (4.35%). The study showed differences of ICU team opinions and the patients' complaints. When the team is placed in the patient's perspective they may experience a better view of how harmful is an ICU and how much we can do to improve it. This is our daily challenge: take care with quality, respect, affection and always search for improvement. INTRODUCTION. Endotracheal intubation is a routine procedure to protect the airway in critical care, that is performed by a wide variety of clinicians from different specialities with different levels of experience in airway management. Serious complications can result from misplacement of an endotracheal tube (ETT) in a main stem bronchus. A widely recommended method for the prevention of this complication is bilateral auscultation of the lungs; but this method frequently provides only inconclusive results (1) . Other routinely used tests to verify correct endotracheal tube placement include observation of symmetric chest movements, and inserting the ETT to a specific depth, but it remains unclear which of these tests detects endobronchial intubation best. OBJECTIVES. We therefore designed this study to determine which bedside method has the highest sensitivity and specificity for detecting endobronchial intubation in adults and whether sensitivity and specificity increases as a function of the anesthesiologist's experience. METHODS. Surgical patients were randomized to two study groups. In the first, the ETT was fiberoptically positioned 2.5-4-cm above the carina, whereas in the second group the tube was positioned in the right main stem bronchus. First year residents and experienced anesthesiologists randomly performed only one of the following tests to verify the position of the tube: 1) bilateral auscultation of the chest (Auscultation); 2) observation and palpation of symmetric chest movements (Observation); 3) estimating the position of the ETT by the insertion depth (Tube Depth); and, 4) a combination of all three mentioned tests (All Three). RESULTS. 160 patients (118 female/42 male) with 320 observations by 32 experienced and 22 inexperienced anesthesiologists were included in the study. Tube Depth and All Three had a higher sensitivity (0.88 and 1) in detecting endobronchial intubation than Auscultation (0.65) and Observation (0.45) (p \ 0.05). Experience increased the sensitivity only for auscultation, with 45% of first year residents versus 90% of experienced anesthesiologists detecting endobronchial intubation by auscultation correctly. The optimal ETT insertion depth was found to be 20 cm in women and 22 cm in men. We conclude that auscultation alone is inadequate for assessment of correct ETT insertion depth, and that checking for symmetric chest movements is of little use. Our results suggest that the hierarchy of the methods used to assess the correct ETT insertion depth should be changed and that clinicians should rely more on depth of ETT insertion than on auscultation. This is especially true for physicians with less experience in airway management and in situations where auscultation is difficult or impossible. Min USA) , uses a new probe measuring hemoglobin saturation at a lesser depth (15 vs. 25 mm before), with more data output (1value/2 s vs. 1value/3.5 s). The new device contains automated software to compute parameters such as occlusion and reperfusion slopes of StO 2 obtained during and after a vascular occlusion test (VOT). OBJECTIVES. To compare NIRS parameters obtained with the 2 devices used simultaneously in healthy volunteers and critical care patients to test if the new device gave similar results than the older one. METHODS. Micro-oxygenation parameters were collected simultaneously with the 2 different NIRS models, one on each thenar eminence, before (baseline) and during a 3 min upper arm (brachial artery) VOT in 25 patients (15 septic shock (G1), 10 trauma (G2)), compared to 21 healthy volunteers (HV)(G3). NIRS probes were then shifted to the contra lateral thenar eminence and a second VOT was performed. StO 2 occlusion and reperfusion slopes from both devices were calculated in all groups by the same software, using linear adjustment (R 2 C 0.90 to be valid); p \ 0.05 was considered significant. Following parameters were collected in patients: SAPS II and SOFA scores, macrohemodynamic (heart rate (HR), mean arterial pressure (MAP), central venous pressure (CVP), cardiac output (CO) and SvO 2 (mixed venous O 2 saturation) or ScVO 2 ), and metabolic parameters (pH, Base Excess, and lactate). RESULTS. Median ± IQR. Patients (G1and G2) did not differ for macrohemodynamic or metabolic data, except MAP (74 (67-86)mmHg vs. 92 (78-102)mmHg; p = 0.05). Baseline NIRS StO 2 values were similar for both groups and for both devices, but were lower than in HV. During VOT, reperfusion slopes were also lower in patients than in HV regardless the device used. The minimum StO 2 during VOT, occlusion and reperfusion slopes were significantly different between the 2 devices: Intraclass correlation coefficient (ICC) 0.18, 0.16 and 0.26, respectively, and Bland and Altman poor agreement and large bias. CONCLUSIONS. Data obtained with Model 650 largely differ from those obtained with Model 325, regardless of the studied population for both StO 2 baseline and slopes. These differences appeared more pronounced in HV than in patients. Such differences may result from muscle depth, number of data output allowing to more precise linear adjustment, or the minimum value reached during occlusion. It becomes hazardous to compare data obtained with these 2 devices either in HV or in critically ill patients. CRRT is used increasingly for the management of acute renal failure in critically ill patients. One major problem with CRRT is coagulation of the filters, leading to decreased efficacy and increased costs. Regional anticoagulation with citrate is an effective and established form of anticoagulation during CRRT in critically ill patients (1, 2) . OBJECTIVES. The aim of this study was to investigate the filter life span during regional anticoagulation with citrate and regarding cost effectiveness. METHODS. This observational, retrospective study was performed in a mixed surgical and trauma ICU in a university hospital. Clinical characteristics are shown in Table 1 . Citrate CRRT was performed using commercially available equipment and fluid solutions (Multifiltrate Ò with integrated CiCa Ò -system; Fresenius Medical Care; Germany). To maintain stable metabolic and hemodynamic conditions we used an internal standard protocol for citrate CRRT. Reimbursement for CRRT is calculated on procedure related rates (according to German DRG). Data are shown as mean or median and standard deviation. RESULTS. f50 patients treated with citrate CRRT from April 2008 through December 2009 were evaluated ( Table 1 ). The mean circuit lifetime of CRRT for all Patients was 49±24 h (Fig. 1) . Mean daily costs per patient were calculated as 264 EUR and mean benefit for CRRT as 3095 EUR (Table 2) . 1 Commercially available interstitial glucose sensors have already been evaluated for this purpose with promising results. 2 However, because of the range of medications administered in the ICU, potential interference with sensor performance must be characterized. To minimize the undesired offset caused by these medications, an interference rejection membrane (IRM) was uniquely developed for a new subcutaneous glucose sensor for in-hospital monitoring. The novel IRM was studied within the ICU setting to gain a realistic picture of its performance in clinical use. OBJECTIVES. Acetaminophen is known to be an interfering agent for electrochemical sensors. 3 To study the functionality of the new IRM, the effect of acetaminophen on sensors worn by critically ill patients was assessed. Sensor signals were characterized to identify any undesired response from the medication. METHODS. ICU patients simultaneously wore 2-3-day sensors that were connected to iPro TM (Medtronic Diabetes, Northridge, CA) recorders to gather blinded sensor glucose values. Patients were given acetaminophen or a mix of hydrocodone and acetaminophen during their ICU stays; staff charted the exact time of each medication administration. To assess whether a signal offset would be introduced by the acetaminophen, 60 min of sensor signals before and after medication administration were compared. The period of 60 min was chosen based on acetaminophen's pharmacokinetic profile and the time to reach maximal plasma concentration. 4 The normalized medians for the signal segments before and after each acetaminophen delivery were calculated. The medians formed 2 vectors, each with elements representing signal characteristics before and after the medication deliveries. A paired t test was used to compare the vectors and assess for any effect (p \ 0.05) on sensor performance. Across the 8 patients evaluated for this study, acetaminophen and a mix of hydrocodone and acetaminophen were administered a total of 72 times. One sensor was not available during a medication delivery; thus, 143 occurrences of acetaminophen administration were analyzed. No effect on sensor signals could be identified in the 143 instances of acetaminophen delivery. No statistically significant difference was observed between the signal segments before and after administration (p [ 0.57). CONCLUSIONS. This study demonstrates that a novel IRM effectively reduces the undesired interference of acetaminophen on a continuous glucose sensor signal during clinical use. Although this analysis was focused on acetaminophen, the outcome suggests that the IRM may also effectively suppress interferences from other medications administered in the ICU. [1] . However, assessing elastance requires a highly invasive vena-cava occlusion maneuver and left and right ventricle pressure/volume waveforms, which are not typically available in an intensive care unit (ICU) and may raise ethical issues in regular use. A validated, lumped-parameter 8 chamber cardiovascular system (CVS) model is used to evaluate a time-varying elastance estimate at the bedside using standard clinical measurements. OBJECTIVES. To assess time-varying elastance at the bedside for the left and right ventricles using available ICU data, and prove the concept on a porcine model of pulmonary embolism. Five pigs had pulmonary embolism (PE) induced via injection of blood clots over 4 h, developing full PE in stages from a healthy state. At each state several data sets were taken (46 in total over 5 pigs), measuring aortic and pulmonary artery pressure waveforms (P ao (t), P pa (t)), left and right ventricular volume and pressure waveforms (Vlv(t), Vrv(t), Plv(t), Prv(t)). At each cardiac state in inducing PE, the time-varying elastances are estimated as Elv = Plv/ Vlv and Erv = Prv/Vrv. These values are correlated to readily measured quantities (Pao and GEDV). These correlations are used to approximate time-varying elastances Erv* and Elv* for use in a clinically validated 8-chamber CVS model. Note these approximations are load dependent and thus change with cardiac state. A fivefold cross validation was used to validate the model. A time-varying elastance is generated from data from 4 pigs and used to simulate the fifth pig. Simulated PV loops are compared to the originally measured PV loops to validate the approach. RESULTS. P ao (t) and Elv were highly correlated over the 46 data sets (R = 0.81 to R = 0.99). P ao (t) and Elv, GEDV and Erv are also well correlated (R = 0.73 to R = 0.98 In this case we report the worldwide first use of the novel Deltastream-DP3-System (Medos Corp.) in a patient suffering from acute right heart failure due to pulmonary embolism following cardiac surgery. In a 68 year-old male patient 6 days after mitral valve reconstruction cardiac arrest occurred during physiotherapy treatment. After failure of restoring circulation, a short-term ECLS system (Lifebridge Ò ) was implanted under cardiopulmonary resuscitation by inserting cannulas in venous and arterial femoral vessels and then switched immediately to the DP3-Deltastream system. CT-scan revealed the diagnosis of a massive central pulmonary embolism. Transesophageal echocardiography showed a dilated failing right ventricle. A thrombolytic therapy was carried out by administering 100 mg Alteplase. Following CT-scan showed reduced thrombus burden. The Deltastream system was carried out for 148 h. PTT was maintained to 1.5-fold under i.v. heparine therapy. Pump blood flow was held at a maximum of 4.5 l/min (7,000-8,000 r/min) for 2 days. Despite transesophageal echocardiography showing improved left ventricular function the ECLS flow was maintained for further 2 days focussed on the improvement of right heart. Further on the pump flow was reduced every 6 h and the system could be explanted after 6 days in now stable cardiolpulmonary situation. The patient was discharged on day 65 at home in good state without any neurological dysfunction. Overall duration of the ECLS Deltastream therapy was 148 h. No system related major complication occurred during the time. Even in maximum blood flow of 4.5 l/min no relevant hemolysis was measured. LDH level was only slightly elevated to 250-300 U/l. INTRODUCTION. Airway management has progressed dramatically in the last 10 years but the most significant advance has been video laryngoscopy. Several devices have been introduced since, the most important currently available are the GlideScope Ò , C-MAC Ò , McGrath Ò , Pentax Airway Scope Ò , Airtraq Ò , among others. A common practice has been to abandon direct laryngoscope intubation (DLI) after 3 attempts and move onto advance airway devices such as video laryngoscopy which is becoming the first choice when available. Although DLI is successful in the majority of patients, poor glottic exposure is more likely to require prolonged or multiple intubations attempts and therefore be associated with complications such as oxygen desaturation or airway and dental injuries. In the intensive care environment an airway should always be considered a difficult airway due to scarce time to perform assessment, to make decisions and to act. Should the use of video laryngoscopy be implemented as a routine for airway management in a critical care setting ? OBJECTIVES. The purpose in this study was to describe for the first time the use of video laryngoscopy, specifically the VEL 70, as a routine choice for airway management in the intensive care environment. Single center, prospective observational study, from 19 November 2009 to 18 February 2010, was conducted in our intensive care facility, which involved utilization of the VEL 70 for all tracheal intubations, no exclusion criteria, rapid sequence intubation (RSI) was the standard procedure. Information was recorded by the operator assistant on the same day identifying timings of intubation, number of attempts, success or failure and the difficulties encountered. VEL 70 was developed in our institution in 2002 and later adopted as a standard airway management by the department of anesthesia. The device has an original McCoy blade with an attached port that holds a channel for the displacement of an optical shaft 155 mm long, 4.0 mm in diameter with a 70°angle view (Tekno-Medical Ò Germany) which is assemble to a video camera (TelecanDX II, Karl Storz, Germany), an external light source and to a 24-in monitor. RESULTS. There were 49 tracheal intubations performed by 5 operators, 17 crash intubations and 32 rapid sequence intubations. All intubation attempts were successful, mean number of attempts 1. The median time to successful intubation was 22 s with no complications. Subjective assessment post intubation showed that in all cases vocal cords were view in full, all operators manifested to feel comfortable with the handling of the apparatus but felt dependent on a assistant specially to maintain view while maneuvering the endotracheal tube. CONCLUSIONS. Routine airway management with VEL 70 in critical care setting is effective with a high rate of success and most important, with a positive impact for patient safety. INTRODUCTION. Hypovolemia is a common complication in many clinical scenarios and its detection is considered of prime importance. In previous clinical studies, tissue oxygen saturation (StO 2 ) measured by near-infrared spectroscopy (NIRS) has been explored for this purpose; however, results are disappointing. It has been suggested that the sensitivity of NIRS for detection of hypovolemia might be improved when NIRS is applied in combination with a vascular occlusion test (VOT). NIRS in combination with a VOT, consisting of a 3-min period of arterial occlusion followed by reperfusion, allows quantification of muscle deoxygenation during ischemia (StO 2 downslope; a measure of muscle oxygen consumption rate) and muscle reoxygenation after ischemia (StO 2 upslope; a measure of microvascular reperfusion rate). OBJECTIVES. In the present study we applied multi-site and multi-depth NIRS in combination with a VOT in a model of simulated central hypovolemia; lower body negative pressure (LBNP). Eight healthy male subjects, with a mean ± SD age of 27 ± 6 years, participated in this study. The LBNP protocol consisted of a stepwise increase of LBNP from 0 to -60 mmHg. Stroke volume (SV), heart rate (HR), cardiac output (CO), and mean arterial pressure (MAP) were continuously measured using near-infrared finger plethysmography (Nexfin). Multi-depth NIRS, with probing depths *15 and *25 mm, was performed on forearm and thenar for the measurement of StO 2 . Three-min VOTs were performed by rapidly inflating a pneumatic cuff around the left upper arm before application of LBNP and at LBNP = -60 mmHg. VOT-derived StO 2 traces were analyzed for baseline, downslope, and upslope. . From baseline to LBNP = -60 mmHg, SV decreased from 121 ± 18 to 77 ± 14 mL (p \ 0.001), HR increased from 59 ± 10 to 83 ± 11 bpm (p \ 0.001) and CO and MAP were maintained around baseline level. Forearm StO 2 baseline decreased significantly from 83 ± 6 to 78 ± 7 (p \ 0.01) and 86 ± 6 to 82 ± 8% (p \ 0.01) for the 15 and 25 mm probing depth, respectively. Forearms StO 2 downslope, measured with the 15 and 25 mm probe, decreased from -7.2 ± 1.9 to -8.8 ± 1.9%/min (p \ 0.05) and -8.3 ± 1.3 to -11.4 ± 2.9 (p \ 0.05), respectively. Forearm StO 2 upslopes remained unchanged during LBNP. VOT-derived StO 2 parameters measured on the thenar did not shown any changes as a result of LBNP. CONCLUSIONS. VOT-derived StO 2 parameters measured on the forearm seem to be more sensitive to the hemodynamic changes associated with LBNP compared to StO 2 parameters measured at the thenar. GRANT ACKNOWLEDGMENT. This project was supported in part by Hutchinson Technologies Inc. INTRODUCTION. Hypovolemia is a common complication in many clinical scenarios and its detection is considered of prime importance. In previous clinical studies, near-infrared spectroscopy (NIRS) has been explored for this purpose; however results are conflicting due to inconsistencies in methodology with respect to NIRS probing depth and site. OBJECTIVES. In the present study we applied multi-site and multi-depth NIRS in a model of simulated central hypovolemia; lower body negative pressure (LBNP). Fifteen healthy male subjects, with a mean ± SD age of 28 ± 5 years, participated in this study. The LBNP protocol consisted of a stepwise increase of LBNP from 0 to -80 mmHg. Stroke volume (SV), heart rate (HR), cardiac output (CO), and mean arterial pressure (MAP) were continuously measured using near-infrared finger plethysmography (Nexfin). Multi-depth NIRS, with probing depths *15 and *25 mm, was performed on forearm and thenar for the measurement of tissue oxygen saturation (StO 2 ). . From baseline to LBNP = -80 mmHg, SV decreased from 117 ± 14 to 67 ± 9 mL (p\ 0.001), HR increased from 58 ± 10 to 99 ± 12 bpm (p \ 0.001), and CO and MAP were maintained around baseline level. Forearm StO 2 decreased significantly from 84 ± 6.7 to 78 ± 9.9% (p \ 0.001) and 81 ± 6.7 to 75 ± 9.9% (p \ 0.001) for the 25 and 15 mm probing depth, respectively. Thenar StO 2 measured with the 15 mm probe remained unchanged, but measured with the 25 mm probe, a decrease from 86 ± 3.6 to 83 ± 3.3% (p \ 0.01) could be observed. CONCLUSIONS. Forearm StO 2 seems to be more sensitive to (simulated) hypovolemia compared to thenar StO 2 and the sensitivity of NIRS seems to increase for increasing probing depth. GRANT ACKNOWLEDGMENT. This project was supported in part by Hutchinson Technologies Inc. INTRODUCTION. Sidestream dark field (SDF) is a microcirculatory imaging modality implemented in a hand-held microscope for the non-invasive bed-side visualization of the human microcirculation. Despite the many studies showing the importance of microcirculatory imaging in intensive care patients the introduction of SDF imaging into routine clinical practice remains cumbersome. One of the challenges is the need for automatic analysis of the images which currently is subjective and time consuming. OBJECTIVES. In the present study, we introduce a rapid automated software method for automatic quantification of microvascular density, a key microcirculatory parameter, based on SDF image contrast analysis. METHODS. Twenty-five sequential SDF images (duration = 1 s, resolution = 720 9 576 pixels) were isolated from an SDF movie clip, stabilized, and averaged. Subsequently, the mean ± SD gray scale intensity in a sliding 5 9 5 pixel window was calculated and the SDvalue was assigned to the window center pixel, creating an SDF contrast image. This is a simple and rapid algorithm for vessel wall detection as a pixel window at a tissue-vessel junction will have a high SD-value due to the presence of both light tissue cells and dark red blood cells. CONCLUSIONS. Here, we introduce and validate a rapid automated method for quantification of microvascular density in SDF images. As this algorithm detects vessel walls rather than vessel lumen, smaller and larger vessels have similar contribution to the microvascular density assessment. A limitation, however, is that vessel diameters cannot be detected with this algorithm. The preliminary results confirm the proof of concept of the SDF image contrast analysis software, however, further research is required for its optimization. The criteria believed to be necessary for the implementation of HCS in practice were that his name would be written{106(66)}, the document dated{96(60)} and signed{93(58)}. Physicians in private practice wanted date(p = .04) and signature(p = .004) more often than in institution. 96(60) physicians thought that the patient must be competent at the designation' time of HCS, especially those who possess advances directives(p = .003) and a HCS(p = .04) themselves. 58(36) thought the HCS should know about the patient's wishes regarding treatment and care objectives. CONCLUSIONS: More than 1/3 of physicians did not know who the HCS is. More than 3/4 thought HCS useful and at least 2/3 would encourage a patient to designate one before heart surgery. About 10% thought that being a HCS is a too high responsibility and that the HCS could not be the best representative when needed. The potential fear this topic might induce is a barrier for this minority. INTRODUCTION. The use of a daily goals chart has been shown to improve communication between the multi-disciplinary team leading to an increase in understanding of daily patient goals and a decrease in length of patient stay on the intensive care unit (ICU) [1] . We have used a daily goals chart on our ICU since 2004. We wanted to assess the value of this initiative in a general adult ICU. METHODS. The Royal Cornwall Hospital is a large UK district general hospital. We conducted the survey over a 4 week period in the ICU. Each day, after the morning multidisciplinary ward round, the consultant in charge was asked to give the main goals for each patient. These were compared with those written on the daily goal chart, or stated by the house medical and nursing staff. They were graded as complete match (100% of consultant goals matched), partial match (99-50% matched) or non match (\50% matched). RESULTS. 73 surveys were conducted. The daily goals sheet matched the consultant completely on 32 (44%) occasions and partially on 29 (40%) occasions. In comparison, the combination of house medical and nursing staff had complete match on 47 (67%) occasions and partial match on 19 (27%) occasions. House medical staff had a 95% complete or partial match, house nursing staff had a 88% complete or partial match. Overall house staff understanding of the goals set on the ward round is far better than that recorded on the goals chart. The goals related by medical and nursing staff showed differences that reflected their differing clinical priorities. Combining results of all staff led to higher levels of complete match than either group independently. Low levels of non-matches indicate that there is good overall understanding and communication within the team. Use of daily goals charts is an effective aid to augment communication on the ICU multidisciplinary ward round. OBJECTIVES. To assess the effectiveness of an ICU diary on post-ICU psychological symptoms of patients (pts) and their families. Single centre prospective study. Three periods: 1 = control (5 to 11/2008), 2 = diary (12/2008 to 04/2009), 3 = control (05/2009 to 09/2009). All the pts admitted C4 days for the first time to our medical-surgical ICU were included. During the intervention period, the diary was filled both by the caregivers and the pts' relatives, without directives except for the first (medical summary) and the last (recovery wishes) ones. At ICU discharge, their families were asked to fill a satisfaction questionnaire (CCFNI) and the hospital anxiety and depression scale (HADS), and to be contacted by phone to assess peri traumatic stress disorders [dissociation and impact of event scale-revised (IES-R)], HADS at 3 months and 1 year after ICU discharge. We excluded pts if they or their family refused to participate, were not fluent in French, or if their family was not present around the day of ICU discharge. The optimal theoretical content of the diary was determined by a Delphi technique involving a panel of ICU and non-ICU caregivers and a voluntary visitor. The content of the diaries was analysed and linked to the outcome measurements. Of the 378 admitted patients, 197 were included. After exclusion of 54 pts, 143 formed the basis of the study. The content of diaries and the results of IES-R are under analysis. The 1 year data is not yet available The SAPS II at admission, ICU and 3 months post ICU mortality were not significantly different between the three periods. The family satisfaction score was high and was not significantly different between the three periods.  Included: Patients with failure of two or more organs in the first 24 h, admitted to ICU during 2008. Excluded: neurocritical and politrauma patients. Contact 1 year following discharge from; questions were asked about the patients' different perceptions during their stay in ICU. If it was not possible to contact the patient, the next of kin was asked. RESULTS. 154 patients included. General characteristics during admittance to ICU: 63% male; age 60.2 ± 17.5; SOFA * 7 ± 2.8; APACHE ** II 16.8 ± 6.4; APACHE ** IV 57 ± 18.8; length of stay in ICU: 5.1 ± 28.4 days; 42.9% on invasive mechanical ventilation and 17.5% on non-invasive mechanical ventilation. Data collection was carried out over a period of 18 ± 4.4 months, on average 19 months (range: 12-26 months). 18.2% (28 patients) had died at the time of contact. The person interviewed was the patient in 33.3% of the cases, the spouse in 13.7% and immediate family (patient 0 s parent/child/sibling) in 43.1% of the cases. Overall, 43.9% do not have any memory of their stay in ICU. For 25.2%, the experience was unpleasant and for 1.6% of patients the memory is very unpleasant. 29.4% experienced fear, 28.7% disorientation, 4.4% a feeling of lack of hygiene, 9.7% a feeling of suffocation/drowning (with the endotraqueal tubes, etc.), 5.1% a lack of privacy (nudity, etc.) and 14.7% pain during procedures. 94.7% were very grateful for our phone interview. 64.8% were satisfied with the staff. CONCLUSIONS. In patients with high severity scores during their time in ICU, less than half have memory of their stay after 1 year. In those who do, the feeling of fear and disorientation predominates.  To determine the occurrence of communication failures in clinical ICUs, identifying their main detection tools and disclosing their effects on patient condition. A prospective cohort was conducted in four ICUs of a 1100-bed academic, tertiary-care urban hospital in Sao Paulo, Brazil, enrolling critical ill patients older than 15 years from July to August 2009. Communication failures were identified by daily direct observation of medical and nursing rounds and also by chart reviews. The association between communication failures and adverse event occurence was determined using multivariate logistic regression. RESULTS. Among the 54 enrolled admissions, as much as 24 admissions (45%) were affected by communication failures, with 53 occurrences. The vast majority of the communication problems was not registered in patient charts, and could only be identified during the medical and nursing direct monitoring. None of the identified communication failures caused patient harm. Nine out of ten communication issues involved exclusively members of the multidisciplinary ICU health team, patients and their relatives being seldom included in this scenario. Despite communication failures are considered important adverse event risk factors, no association was identified between these two variables. CONCLUSIONS. The incorporation of direct observation as a research tool for identifying untoward events was essential to the detection of communication failures in our study. Almost half of the studied admissions was affected by communication flaws, most of them involving exclusively the healthcare team. Nevertheless, these figures are underestimated, since the research team remained in the studied ICUs for no more than 5 h a day. Although patients were not harmed fortunately, the presence of these communication issues suggests the existence of important gaps in the provision of critical care. The issue regarding communication deficiencies in ICUs setting affecting Patient Safety deserves attention.  Relatives of patients in the intensive care unit (ICU) are exposed to considerable stress 1 . Effective communication with relatives has been shown to provide support and minimise stress whilst improving their wellbeing and decision making for critically ill patients 1 . Furthermore, satisfaction is dependent on communication by a senior caregiver 2 . No published guideline or recommendation exists for when relatives should be first spoken to, how often they should be updated, or how these conversations should be documented. To determine how well relatives of patients in the ICU are kept informed and to assess the quality of documentation. We retrospectively analysed data from the Metavision Ò Clinical Information System of patients staying over 4 days during 01/10/09-01/01/10 on the 20-bed ICU at the NNUH. Data obtained from the 'Relatives Communication' page included: when relatives were first spoken to, how often they were spoken to (according to the number of entries made) and the members of staff involved in the conversations. These variables were analysed in relation to patient outcome and length of stay on the ICU. . 64 patients were analysed. Communication with relatives was not documented in 45% of patients. 60% of communication was carried out by a consultant. Discussions were more likely to occur with relatives of patients who died; 83% compared to 48% of patients discharged to the ward. Similarly, relatives of patients who died were spoken to more frequently; 90% were talked to on more than one occasion compared to 28% of patients surviving to discharge. Relatives were more likely to be spoken to with an increased duration of admission on the ICU; communication occurred with only half the relatives of patients staying 1-5 days, compared to 100% of those staying more than 20 days. Two-thirds of relatives of patients staying more than 20 days were not communicated with until after the fourth day of admission, although the majority of these were spoken to on numerous occasions and all were seen by a consultant. Relatives of patients dying on the ICU are more likely to be communicated with, and are updated more often than those of patients surviving to discharge. A delay in communication with relatives of patients staying more than 20 days on the ICU was noted, but conversations occurred more regularly and involved a consultant. We suspect that our results demonstrate a lack of documentation rather than actual communication; auditing relatives' satisfaction with communication on the ICU may help clarify areas for improvement. Assessment of satisfaction with the quality of care provided to patients hospitalized in intensive care units, in most cases, is transferred to the relatives of the same, given the context of the patient himself unable to speak. The diagnosis of the needs of families of critically ill patients has been the subject of several studies. Aiming to assess the needs of relatives of patients admitted to the PICU (Polivalent Intensive Care Unit), we conducted studies in particular through an adapted version of the questionnaire CCFNI (Critical Care Family Needs Inventory) developed from the adaptation made by Johnson and col. (1998) and focus group. One of the needs identified in these studies was to improve information about what happens in the PICU. With this in mind we designed a manual to support relatives in order to improve communication and understanding in the context of the Intensive Care Unit. OBJECTIVES. This study aims to assess the impact on the level of family satisfaction of a manual we've created. The manual is available from January 2006 to all visitors at the entrance of that unit. The questionnaire was mailed to all families who had a family member hospitalized in the PICU during the year following the introduction of the manual. Together followed a letter to present the study and a stamped and addressed envelope for their return. Beyond the satisfaction and access to the manual or not, were collected socio-demographic data from relatives and socio-demographic and clinical data of patients. We obtained 90 responses, representing 28% of all potential families. 14 questionnaires were returned because of address failure (6.3%). Statistical analysis was performed using SPSS Ò v.17.0 RESULTS. The satisfaction of family members who had access to the manual was better in all dimensions tested (support, comfort, information, access, trust), and with a statistically significant difference (p \ 0.05). This difference was clearer in the fields Support (med1, 75/ 2.75) and Information (1.67/2.33). CONCLUSIONS. The impact of the Manual on the improvement of family satisfaction was positive in the various dimensions assessed. The questionnaire of family satisfaction monitoring and understanding of information given through a manual created by us can contribute to a better understanding of the needs of families and hence for the continued improvement of service quality. Johnson INTRODUCTION. The burnout can be defined in its multidimensionality: emotional exhaustion, understood as a feeling of exhaustion and failure of the person to give more of herself; depersonalization, in which the person's relationship with patients and with colleagues becomes cold, distant and guided by some cynicism, lack of personal and professional completion, which may manifest itself, on one hand, by the sense of incompetence and inability to respond to requests or, on the other hand, by the sense of omnipotence. The provision of Intensive care can lead to health care provider's physical, psychological and emotional exhaustion, which may develop to burnout. We notice the absence of specific studies on this syndrome, in Portuguese Intensive care Units. OBJECTIVES. The study here presented intend to identify the levels of burnout of physicians and nurses working in Portuguese intensive care (Adult polyvalent units in the north of the country), and to identify factors that can lead to the development of burnout in the Portuguese physicians and nurses working in that setting. The methodology presented consist of application of a questionnaire for self fulfilment with 3 items: 1, socio-demographic data of the study population; 2, experiences in the workplace; 3, Maslach Burnout Inventory-General Survey. For the application of methodological tools, we requested the authorization by the competent institutional bodies: the board, ethics committee and directors of services. The professionals who participated in the study were asked informed consent, whether in formal or informal. In addition, each instrument was accompanied by a cover sheet of the same. We have also done Observation of the work contexts, and Interviews. In this study we will focus on the results of the questionnaire. . Sample: 6 hospitals with a total of 10 intensive care units. Professionals participants in the study 300, 82 physicians 218 nurses. The mean ages of respondents 32, of Professional experience 8 years and of experience in Intensive Care were 4 years. MBI Preliminary results:Distribution of levels of burnout by occupational category: At the moment, portuguese physicians and nurses who work in intensive Care Units seam to have medium levels of burnout, obtained through the MBI. Results show higher levels at emotional exhaustion in nurses never less in general they showed higher personal and professional completion than physicians. Depersonalization were higher in physicians. The results presented here underline the importance of promoting the prevention of burnout at intensive care. The development of the burnout syndrome in physicians and nurses in intensive care has serious consequences, both for themselves, or the consequences that entails for patients and their families. INTRODUCTION. The hospitalization of a member of the family in the Intensive Care Unit (ICU) usually occurs in an acutely and inadvertent way, leaving little time for a family adjustment. Facing the stressful situation, the family may feel disorganized, helpless and with difficulties to mobilize themselves, enabling the rise of different types of needs. The scope of those needs leads to the alleviation of tension and uncertainties that could provide to the family the stability needed to cope with the situation disease 1 . To identify the needs of care of family members with persons admitted to the ICU. METHODS. This is a transversal study, held in two ICUs (a public one and a private one) in the city of Feira de Santana, Bahia, Brazil, after approval by ethics and research committees. The relative person is understood by the person who had consanguinity ties or who was closest to the patient, who lived with him and had close relationships. 40 relatives were interviewed when his relative was over 24 h of hospitalization. The The Brazilian adaptation of the Critical Care Family Need Inventory (INEFTI) was used for measuring the degree of importance, once it has 43 items distributed in five dimensions. Descriptive statistics were used for analysis. The INEFTI reliability was satisfactory (Cronbach a = 0.843). RESULTS. The needs of care considered most important by family members were those related to the security dimension, expressed by the items ''to know what are the chances of improvement of the patient'' (3.88 ± 0.33), ''to be informed about everything that relates to the evolution of the patient'' (3.85 ± 0.36) and ''to feel that hospital people care about the patient'' (3.80 ± 0.40). In the category Information, the item ''be able to talk to the doctor everyday'' (3.70 ± 0.36) obtained more average. In the category Proximity was consider more important to ''see the patient frequently'' (3.73 ± 0.45). The needs of the categories Support and Comfort categories showed lower scores. These results are similar to those presented by literature 1, 2 , what confirms the appreciation of the family to the aspects related to the recovery of the hospitalized relative, in detriment of their own needs. CONCLUSIONS. Having security, information and being around its ill relative is what the families need. The security is provided by the conviction that the person receives the best care in the pharmacological, technological and human aspects, and can be perceived by the information transmitted by the team and by the proximity established in the interaction with the sick relative.  A collaborative project was developed between the ITU clinical staff of a large, inner city teaching hospital, palliative care clinicians and an academic department of palliative care. Qualitative data collection included: (i) semi-structured interviews with staff and relatives of patients thought to be at the end of life; (ii) focus groups with staff (iii) observation of care and (iv) clinical note review. Data was analysed using the Framework Approach to identify key themes. RESULTS. Semi-structured interviews were carried out with 47 staff and 3 focus groups took place. A total of 24 relatives, representing 20 patients thought to be at the end of life, were interviewed. Half the patients represented were female, with diagnoses including infection, hypoxic brain injury, malignancy and liver failure. The participants were aged 28-80 and included a range of ethnic groups and religious affiliations. Non-participant observations of care took place for 15 and clinical note review for 16 of these patients. Data from the interviews with staff describe that an existing withdrawal of treatment document was working well but could be developed further along with suggestions for amendments. The interviews with relatives, observations and review of clinical notes show 4 key themes: communication, decision-making, patient and family needs, and symptoms and their management. Through discussion at ITU End of Life Group meetings, a consensus was reached to pilot a complex intervention comprising an amended withdrawal document; a psychosocial assessment; education and awareness-raising; palliative care team input and increased psychosocial support. The psychosocial assessment document was deemed valuable to all patients and was rolled out for all patients admitted to ITU. Initial evaluation shows greater staff awareness. Documentation of end of life issues and the collaborative research process has improved communication between ITU and palliative care staff. INTRODUCTION. Consumer-centric healthcare is a key component of NHS policy. When patients are critically ill, family members act as surrogates. Family members alone may inform patients of events that occurred, and provide physical, emotional and socioeconomic support during rehabilitation. Thus, high family satisfaction (FS) is important. The FS-ICU instrument was developed in Canada to quantify family satisfaction 1 and benchmark Intensive Care Units (ICUs). We have piloted and validated previously an adaptation of the FS-ICU such that its language was appropriate for the UK 2 . To date, no intervention has demonstrated improvement in the FS-ICU for a critical care unit. We hypothesise that provider-driven interventions fail to recognise central issues. Co-production is a framework that enables creation of parity between providers and consumers by validating both individual worth and specialised knowledge 3 . There are no published data on the use of co-production in intensive care. We undertook to co-produce interventions targeted to improve family satisfaction. The FS-ICU instrument will be used as an objective measure of their efficacy. OBJECTIVES. To co-produce some interventions targeted to improve family satisfaction and to use the FS-ICU instrument as an objective measure of their efficacy. METHODS. FS-ICU questionnaire responses were used to highlight potential areas for service development. Focused interviews with families provided detailed descriptions of the ''the way the ICU works''. These data were used to build exercises for a workshop of service users and providers which aimed to co-produce service developments. RESULTS. 88 FS-ICU questionnaires were received over the 12 months to April 2010 (70% response). Quality and consistency of communication between ICU doctors and relatives; the level of relatives' inclusion in decision-making processes; and the ICU waiting room atmosphere were identified as needing improvement. Four families were interviewed in detail. Workshop participants included Trust Directors, managers, clinicians, nurses, patients and their families. Proposed interventions from the workshop included: development of a non-clinical family liaison officer role with a dedicated contact number; increasing focus on managing patients' and relatives' expectations of care delivery; specific improvements to the waiting room area. Intensive care patients' relatives provided a unique insight into the ICU functioning that should be utilised as a resource. Co-production was used to design service improvements that may not have been obvious from a provider perspective. Workshop transactions were empowering for both staff members and patients' families, generating social capital that creates and improves social provider-consumer networks, now and in the future.  To evaluate the degree of satisfaction of ICU patients regarding their ICU stay. As the result of a fund sponsored by former patients and their relatives, our Dept of Intensive Care is able to provide a small team of assistants to welcome and accompany the relatives of ICU patients. One role of this team is to collect and evaluate impressions and criticisms from patients and relatives shortly after the ICU stay. We studied a convenience sample of ICU patients who stayed in our multidisciplinary Dept of Intensive Care between September 2009 and April 2010. The evaluation included 12 simple questions about the welcome (friendliness of the personnel, explanations), quality of care (including pain control, attention to patient needs, availability of nurses and speed of response) and comfort (temperature, light, noise). Data were analyzed using non-parametric (Mann-Whitney) and Chi 2 tests. We collected answers from 100 of 134 patients (22 were incapacitated, 7 had died and 5 declined), including 51 unplanned admissions and 49 patients after major surgery. More than 75% of the patients were very satisfied with all items, except for information provided by the attending physician (67% of patients) and the room temperature (66% of patients) (Figure 1 ). Post-ICU enquiries can provide valuable feed-back information that could improve the quality of care in the ICU. INTRODUCTION. Previous research suggests that family members of critically ill patients hospitalized in the ICU frequently suffer from severe anxiety. A survey conducted in our unit-a 12-bed, university-affiliated tertiary-care, closed, general ICU with restricted visiting hours-revealed a willingness of family members to participate in a support group. Such a group was recently introduced and we report on our initial experience over the last year. METHODS. The purpose of the support group was to provide a forum where family members could freely raise any topic related to the care of their loved one as well as to family-related issues. The meetings were held weekly in the ICU and chaired by a senior nurse and the unit social worker. Family members were informed of the meetings when the patient was admitted to the ICU and notifications were placed in the family waiting room. All family members were encouraged to take part and to raise any topic they felt was relevant. RESULTS. Since its introduction in 2008, there has been an increase in the percentage of a family representative attending the meetings from 13 to 47%. The most frequently raised issues included staff-family interaction (especially lack of empathy), lack of information regarding the patient's status and prognosis, and the lack of adequate visiting hours. In addition, other issues included technical aspect related directly to the family, in particular, overcrowding and lack of privacy in the waiting room. Finally, participants wanted to learn skills in order to cope with their new and uncertain circumstance. We have noted an ongoing readiness of family members to take part in the support group. The issues raised have and will allow us to make appropriate changes and to improve the current situation. In particular, the meetings help us to identify family members at risk who require more immediate and personal attention. INTRODUCTION. The SOAP study suggested outcomes of cancer patients admitted to ICU are similar to those without cancer in contrast to other reports . 1 We wanted to compare this with our own experience. (1) To determine critical care and hospital outcome of patients with malignancy referred to critical care in the previous 5 years. (2) To identify any factors influencing treatment decisions and survival after admission. Retrospective chart review of patients undergoing treatment for malignancy admitted to ICU for medical or surgical reasons from May 2006 to Feb 2010. Leukaemia patients were not included as they are treated at a different hospital by a different group of clinicians. Demographic information, tumour/treatment related factors e.g neutropenia, preadmission status and critical care diagnoses e.g. sepsis, were collected in addition to patient outcomes. RESULTS. 38 patients were identified (2.8% of all critical care admissions). ITU mortality was 39.5% (n = 15), however only 31.6% (n = 12) survived to hospital discharge (comparable overall unit mortality: 20-25%, hospital mortality:30%). Hospital survivors were younger (median 54.5 vs. 62 years), and more non-survivors had pre-existing comorbidities, sepsis, ALI and required more organ support (all ns). There was no difference between the groups regarding cancer treatment. Non-survivors had a longer stay in critical care and treatment withdrawal/limitation decisions were more common suggesting these were often based on lack of medical progress whilst on ICU rather than diagnostic nihilism. Hospital mortality in patients with malignancy is higher in our specialist centre than reported for a Europe wide cohort (68.4 vs. 27% overall and 41% in the medical subgroup). The majority of our patients were medical and not post-surgical unlike in the SOAP study. This may account for the greater mortality as a larger proportion of our patients had ALI, sepsis, neutropenia and required inotropes. Numbers admitted to critical care are much smaller than the 15.1% reported in the SOAP study, suggesting some referral and admission triaging by the oncologists and the ICU team. Our results are similar to single centre French (hospital survival rate 31.6 vs. 21.8%) and Brazilian studies (31.6 vs. 42%), although a majority of our patients did not receive mechanical ventilation. 2,3 A diagnosis of cancer or active treatment for it should not be the major determinant of critical care support, but the patient's general premorbid status and the extent of organ failures appear to be important factors in decision making as for any other critical care patient. Figures from the SOAP study for non specialist centres do not appear to reflect the experience of specialist oncology centres. Historically there has been a negative perception of the prognosis for patients with haematological malignancies requiring admission to the intensive care unit (ICU). However, advances in chemotherapeutic regimes and haematopoietic stem cell transplantation (HSCT), along with improved monitoring and supportive measures have suggested that outcomes for these patients have improved [1] . Establishing key prognostic indicators predictive of outcome may be useful in identifying patients most likely to benefit from ICU therapy. The aim of this study was to describe clinical outcomes and identify prognostic factors in patients with haematological malignancy requiring admission to ICU. Following research approval, a retrospective cohort study was undertaken in a 12-bedded specialist cancer ICU over a 5-year period (October 2004 -September 2009 . Recorded patient variables included demographics, haematological diagnosis, reason for ICU admission, HSCT, APACHE II, admission laboratory data, number of organ failure, use of invasive mechanical ventilation, renal replacement therapy (RRT) and vasopressors. The primary outcome was in-hospital mortality. Key prognostic variables in determining inhospital mortality were identified using univariate and multivariate analysis. RESULTS. 199 patients with haematological malignancies were admitted to the ICU during the study period: mean age 55.3 (SD 15.6); 43.7% female; haematological diagnosis (45.7% leukaemia, 40.2% lymphoma, and 13.6% myeloma); 54.2% emergency admissions and 43.9% were post-HSCT. Mean APACHE II was 21.6 (SD 7.4), mean number of organ failures 2.3 (SD 1.7), 52% required invasive mechanical ventilation, 41.4% RRT and 51.6% vasopressor therapy in the first 24 h of ICU admission. ICU, in-hospital and 6-month mortality were 32.7, 45.2 and 60% respectively. Significantly higher mortalities were seen in patients who were mechanically ventilated (65 vs. 25% non-ventilated patients p \ 0.001), on vasopressor support (57 vs. 25% no vasopressor support p \ 0.001), neutropenic (52 vs. 45% non-neutropenic p \ 0.001) and in multi-organ failure defined as C2 organ failures (84 deaths vs. 15 deaths in patients with B1 organ failure, p \ 0.001). Univariate analysis revealed mechanical ventilation, vasopressor support, albumin \20 g/l, neutropenia, platelet count \50 9 10 9 /l and multi-organ failure were all significant with p values \0.001, \0.001, 0.003, \0.001, 0.015 and\0.001 respectively. Multivariate analysis revealed that multi-organ failure was the only independent prognostic predictor of in-hospital mortality. CONCLUSION. Mechanical ventilation, APACHE II, vasopressor support, albumin\20 g/l, neutropenia, platelets \50 9 10 9 /l and multi-organ failure all had a significant association with mortality; however multi-organ failure was the only independent factor that predicted poor outcome. C.Y.C. Michael 1 , A. Vasu 1 , S. Eillyne 1 1 Tan Tock Seng Hospital, Emergency Department, Singapore, Singapore INTRODUCTION. Coronary heart disease is the leading cause of mortality and morbidity for both women and men. Although men are affected in greater numbers, women have been shown to have worse outcomes and higher mortality. OBJECTIVES. This study aims to examine gender differences in risk factors, angiographic severity, treatment and in-hospital mortality after STEMI. METHODS. In this retrospective study, the medical records of 619 patients with an admitting diagnosis of STEMI from Tan Tock Seng Hospital, Emergency Department (TTSH ED) between 1st January 2009 and 31st December 2009 were reviewed. We extracted the data from the electronic records of the emergency case notes and inpatient discharge summaries. RESULTS. Of the 619 patients studied, 123 (19.9%) were women and 496 (80.1%) men. Four hundred and forty-nine (72.5%) patients underwent coronary angiography. One hundred and seventy (27.5%) patients did not undergo coronary angiography, majority (65.3%) were elderly aged C65 years (men 34.1% and women 31.2%). Between women and men, there was no significant difference between the number and distribution of diseased coronary vessels (including triple vessel and left main stem diseases). Regardless of age, men were frequently treated with a coronary artery stent (67.9%). Elderly women (aged C65 years) were more often treated conservatively (67%) while those younger women (aged B64 years) were frequently treated with a coronary artery stent (62.1%). In-hospital mortality rate was significantly higher for women than men (6.5 vs. 3.8%, p = 0.013). Amongst the patients treated conservatively, elderly women had the highest in-hospital mortality when compared to the other patients (women C 65 years 19.2 vs. women B64 years 2.7%; men C65 years 13 vs. men B64 years 6.8%). Compared to men, women were significantly older (p \ 0.001; 95% CI 12. 6-17.6) , more likely to have a history of hypertension (73.2 vs. 50.2%; p \ 0.001), diabetes (45.5 vs. 28.2%; p \ 0.001), hyperlipidemia (63.4 vs. 46.6%; p = 0.001), peripheral vascular (5.7 vs. 1.2%; p = 0.006) or ischemic heart diseases (28.5 vs. 15 .7%; p = 0.002) and less likely to be smokers (12.2 vs. 57.7%; p \ 0.001) or consume alcohol (0 vs. 10.1%; p \ 0.001). CONCLUSIONS. Elderly women who were treated conservatively had the highest in-hospital mortality during the early management of STEMI. Hôpital Saint-Louis, AP-HP, Paris Diderot University, Hematology Department, Paris, France INTRODUCTION. AML is considered as an oncology emergency as a proportion of patients experience life threatening complications within the first hours or days after diagnosis. Early death had been shown to be statistically related to high white blood cell (WBC) and monoblastic leukemia 1-3 , with leukostasis and lysis syndrome as the most deadful events. OBJECTIVES. To evaluate the relationship between timing of ICU admission and outcomes in high risk AML patients at the earliest phase of the malignancy (before any chemotherapy) METHODS. Retrospective study in a tertiary care teaching hospital. Adult patients with newly diagnoses AML from 1998 to 2008 were included. Patients admitted for an immediate life sustaining therapy (ventilation, vasopressors or renal replacement therapy) were excluded. 42 patients admitted directly to the ICU (Early admission) were matched for age, WBC and FAB subtype with 42 patients primarily admitted in hematology ward. Datasets were extracted from medical charts. RESULTS. 84 patients were included (42 early admitted to the ICU and 42 admitted first to the wards). Median follow up was 10.3 months. Median age was 46.5 years (36-57). FAB M4 or M5 was retrieved in 58% of the patients. Karyotype was favorable for 30% and poor for 19%. Median WBC was 103 9 10 9 L -1 . No statistical difference was seen for demographic and hematological parameters between early admitted patients and matched controls. Among the 42 patients admitted first to the wards (controls), 20 were subsequently admitted to the ICU (Lately admitted) and 22 remained in ward during the entire treatment course (Never admitted). The median time between diagnostic and ICU admission of this last group was 4 (1-9) days. Strikingly, patients lately admitted had more frequently dyspnea,oxygen requirement, high respiratory rate, low diastolic arterial pressure and lower first 24 h urine output. Lately admitted patients were less likely to receive the complete dose of induction chemotherapy (68 vs. 88%) Furthermore, Late admission resulted in increased use of invasive mechanical ventilation (60 vs. 33%) and vaso-active drugs (60 vs. 16%). These differences resulted in longer stay in ICU and decreased survival. CONCLUSION. Patients at the earliest phase of High risk AML who are lately admitted to the ICU experience worse outcomes, with increased use of life-sustaining therapies and higher mortality, compared to patients early admitted to the ICU. Physiologic parameters at the time of AML diagnosis such as respiratory rate, diastolic blood pressure, SpO 2 , or oxygen need are likely to help clinicians distinguish those patients at risk of late ICU admission and subsequent adverse outcomes. Studies are needed to assess the right place for newly diagnosed AML with physiological abnormalities but no organ dysfunction. Atrial fibrillation (AF) is the most common sustained tachyarrhythmia in the community. It has a prevalence of *10% in those over 75 years of age (1) . The chronic health consequences of chronic AF are significant. It can cause impaired cardiac function, a fivefold increased risk of stroke and decreased life expectancy (2) . AF is also the commonest arrhythmia in the critically ill, though a recent systematic review (3) was unable to recommend evidence based standards due to the heterogeneity of the studies. OBJECTIVES. A retrospective cohort study to assess the impact that chronic AF has on the outcome from critical illness. METHODS. All patients admitted with chronic AF between 27/04/2006 and 05/09/2009 were identified. We recorded age, APACHE II and predicted hospital mortality, actual ICU and hospital mortality, past medical history, admitting diagnosis, medication, echo findings, anticoagulants given, therapy instituted, and any further events between ICU and hospital discharge. The only data collected for the patients who did not develop AF was their age, APACHE II and predicted hospital mortality and actual ICU and hospital mortality. Data analysis using Chi square test and Mann-Whitney U test were used where appropriate. RESULTS. 1168 patients were admitted to the ICU over the study period, 46 of which had a history of chronic AF (3.9%), the remaining results are shown in Table 1 .  Chronic AF had a prevalence of 3.9%, in keeping with previous studies, and the mean age in the chronic AF group was significantly higher. Interestingly, there was no difference in ICU and hospital mortality between the 2 groups. Despite the chronic AF group being older with significantly worse APACHE II scores. Indeed the hospital mortality (30.4%) of those patients admitted with chronic AF was over 30% less than predicted hospital mortality (44.2%). Why patients with chronic AF are outperforming expectation is not clear. It could be that APACHE II is over estimating the severity of illness in these individuals, or is there something about the way chronic AF is treated that affects the response to critical illness, for example, anticoagulation therapy? One of the major outcome measurements in burns centers is still mortality after severe burns. There are many predictive factors in admission as well as factors that are related with all the course of the disease responsible for survival after severe burn. Many centers have a minimum standard of burn survival or LA50 (the body surface area that kills 50% of people) and also have generated computer models of death probabilities based on age and TBSA (total body surface area) burned. OBJECTIVES. To evaluate the outcome of the severely burned patients treated in the burn center and to develop a predictive model for survival from major burns in Albania. The medical records of all acute burn patients admitted to the Burn Center of the University Hospital Center ''Mother Teresa'' in Tirana, Albania are reviewed retrospectively. Statistical analyses are conducted using SPSS version 15. Logistic regression is used for the prediction of death probability for two risk variables, TBSA burned and age. Based on the Index of Evidence the variables are grouped in significant strata, from 1 to 5 for each variable. Logistic regression equation is: where z = 3, 0-0 8, age 1-0 2, age 3-0 4, age 4-2 1, age 5+ 1, 5 TBSA1-1, 1 TBSA3-2, 0 TBSA4-2, 5 TBSA5 After calculating the probability of death for each record, we have done respective grouping according the mortality from 0-100%. RESULTS. During 1998-2008 are admitted altogether 2,337 patients in the burn center. Overall mortality in ICU is 10.5% with a significant reduction during the years, up to 4.4 in 2008. Row burn mortality is 0.8 for 100,000 persons per year. LA 50 for children is 60% TBSA; for adults 65% TBSA and for aged 45% TBSA. Based on probability of death, we notice that older age and larger burn size are associated with a higher like hood of mortality. Figure 1 gives an overview of death probability in our burn center. CONCLUSIONS. The mortality reduction speaks up for a better work of our staff toward the patients. The predictive model may assist all the burn team to identify the crucial determinants of clinical outcome to establish a real basis for treatment standards and to allow future comparisons of new treatment strategies. (1) in mechanically ventilated (MV) critically ill patients. METHODS. Prospective observational multicenter study during 2 weeks in November 2009. Consecutive patients admitted to the participating ICUs and requiring MV for at least 6 h were included. Maximal, minimal and mean intra-abdominal pressure (IAP), were recorded on day 1, 2, 4 and 7. IAH was defined as mean IAP C 12 mmHg/24 h at least 1 day. Following risk factors were recorded if evident during the first ICU day or immediately before: Respiratory failure, abdominal surgery with fascial closure, damage control laparatomy, major trauma/burns, prone positioning, gastroparesis, ileus, colonic pseudo-obstruction, ascites, hemo/pneumoperitoneum, intra-abdominal fluid collection, acidosis (pH \ 7.2), hypothermia (core t°\ 33°C), massive transfusion ([10 U of packed red cells/24 h), massive fluid resuscitation ([5 L/24 h), coagulopathy, oliguria and sepsis. RESULTS. 358 patients from 39 ICUs were included; mean APACHE II score on admission was 19.8 (8.0) and 28-day mortality 31%. Mean number of IAP measurements was 3.2 per day. IAH occurred in 163 patients (45.5%). Only 41 pt (11.5%) had none of the studied risk factors, nevertheless 22% of them still developed IAH. Of the 68 patients with 5 or more risk factors, only 64.7% developed IAH (Table 1) . OBJECTIVES. To describe the ICU admission of our hospital for serious complications of hematology patients in the last 10 years. Compare the characteristics of these patients throughout the study period. Analyze mortality and their evolution from their admission to the ICU. The evolution of hematologic patients has improved in recent years due to better supportive treatment, sometimes involving the use of specific treatments in the ICU. A retrospective study of medical records of all patients with hematologic diseases were admitted to our ICU from April 1999 until May 2009. We excluded patients admitted for channeling central catheter, diagnostic tests and bone marrow transplants. We selected a total of 85 patients (60% male) with a mean age of 45 years (range 15-77). The main hematological diagnoses were the most common AML (37%), acute lymphatic leukemia (16%), lymphoma (non-Hodgkin's lymphoma) (16%), coagulopathy (7%), myelodysplastic syndrome (5%) and myeloma Multiple (5%). The principal reason for admission in the unit were: acute respiratory failure (40%), followed by sepsis (35%) and less CNS and cardiac problems (8 and 7%) respectively. As important risk factors of neutropenia and peripheral blood stem cells after transplantation. The ICU mortality reached 52.6%. The average stay was 5.4 days. CONCLUSIONS. The transfer to the ICU allows a high percentage of hematological patients survive severe complications and the benefit continues after discharge. The mortality of ICU patients in our series has not changed over the past 10 years, keeping both the characteristics of patients transferred. The consensus among the services of Hematology and Intensive Care is essential to select and treat the best candidates to benefit from support in the ICU and to improve current survival results.  A retrospective (from 1994 to 2004) and prospective (from 2005 to 2008) analysis of obstetric patients (pregnant or postpartum admissions) admitted in our CCD was performed. Results are expressed as mean (standard deviation) or frequency (percentage). Chi 2 and t student tests were used for statistical analysis according to the different variables (SPSS 18.0, Inc. Chicago, IL), accepting a p-value \0.05 as significant. RESULTS. 204 obstetric patients were included. Mean maternal age was 30.53 (6.2) years and mean gestational age was 30.36 (8) weeks. APACHE II score was 10.8 (6) . 97 (47.5%) patients were admitted to CCD due to an obstetric cause. The main diagnosis of this group were thrombotic microangiopathies 60 (29.4%) and hemorrhagic shock 18 (8.8%). Thrombotic microangiopathy included 33 (55%) eclampsia-preeclampsia, 12 (20%) acute fatty liver, 9 (15%) HELLP syndrome and 6 (10%) PTT-SHU. In the remaining 52.5% (107 patients) the main reason for CCD admission not related to the pregnancy was respiratory failure 39 (36.4%). From the whole population included, 87 patients (42.6%) required mechanical ventilation (MV) with a mean duration of 4.94 (7.15) days. Furthermore, 59 (28.92%) patients required surgical intervention (15.7% hysterectomy). The ending of pregnancy was made in 164 patients (80.39%), most cases by caesarean 78.04% (128 patients). Mean length of stay in CCD was 7.17 (9.12) days. Maternal mortality was 3.4% (7 patients), basically in the non-obstetric group (6 vs. 1) . CONCLUSIONS. This is a large series of young obstetric critically ill patients with a low mortality. However, a non-depreciable part of the population included presented important morbidity. OBJECTIVES. To identify the association of co-morbidities with mortality. METHODS. Retrospective analysis of clinical process of diagnosing patients with severe sepsis/septic shock admitted to the intensive care unit (ICU) in the period of November 2008 to October 2009. We collected demographic data, co-morbidities, and mortality in the ICU hospitalization. Statistical tests used were Student's t and Chi-square. We analyzed 85 patients admitted with this diagnosis, median age of 66 years and females 32.9%. In 72.9% (62 patients) appear co-morbidities, distributed as follows: hypertension 56.5%, 41.9% diabetes mellitus, cerebrovascular disease 27.4%, 11.3% chronic kidney disease; 12.9% neoplasic disease and chronic obstructive pulmonary disease 9.7%. The mean age (68.7, p \ 0.0001) was higher in this group. The overall mortality in the ICU was 34.1% that has not increased significantly to 37.1% in the group with comorbidities, and the overall in-hospital mortality was 48.2% and rise significantly to 56.5% (p \ 0.03). CONCLUSIONS. In our study, around 3-4 patients had co-morbidities and these facts and the age were those who contributed to higher mortality. The factors of greatest weight are those related to metabolic disease. The characterization of chronic illness in the ICU is important in future larger epidemiological studies to better characterize this group of patients and the factors predictive of mortality to decrease the suffering of the patient and plan for admission to intensive care units. One year mortality of patients treated with an emergency department based early goal directed therapy protocol for severe sepsis and septic shock: a before and after study. INTRODUCTION. Despite the advances in respect to the development of objective criteria for admission of patients with hematologic malignancies to intensive care unit (ICU), no evidence exists that they contributed to a reduction in the mortality, which depends from the aggressiveness of the cancer itself, its complications and even as a consequence of therapy. Since the decision to admit one of these patients in ICUs involves a complex decision-making process, it becomes imperative to identify predictors that may help the clinician to discriminate the patients who may benefit from intensive care than those in which intensive care will be associated with just a prolongation of an agony. OBJECTIVES.: To identify early prognostic factors in the admission of patients with hematological malignancy, admitted in the ICU of a Central University Hospital. Analysis of data prospectively collected and registered in a database of patients with hematological malignancy, admitted to the ICU between January 2005 and December 2009. We collected for each patient demographic and clinical data (age, sex, length of stay, origin, previous treatment, stage of disease at admission, type of malignancy and aggressiveness, organ dysfunction at admission, co-morbidities, reason of admission), general severity scores (SAPS II and APACHE II) and organ dysfunction scores (SOFA at admission to the ICU, maximum SOFA score and delta SOFA). Specific variables were correlated with mortality at the ICU and Hospital discharge. RESULTS. 137 patients (86 males and 51 females) fulfilled the inclusion criteria. The average age was 54 ± 14.79 years (17-84 years). The type of hematological malignancy was acute leukemia (55.5%), multiple myeloma (7.3%), myelodysplastic syndrome (2.9%), chronic leukemia (7.3%), low grade non-Hodgkin lymphoma (6.6%), high grade non-Hodgkin lymphoma (17.5%). The average length of stay in the hospital was 20.2 ± 23.3 days. Most patients were admitted from the Department of hemato-oncology ward of the Hospital (72.3%), 6.6% of the emergency department and 21.2% of another hospital. The ICU mortality was 42.3%, with a corresponding hospital mortality of 75.2%. The discriminative capacity of the severity scores, as assessed by the area under the ROC curve (aROC) was 0.775 for SAPS II and 0.713 for APACHE II. For the delta SOFA calculated for each organ dysfunction, progression of respiratory dysfunction/failure and cardiovascular failure demonstrated the best discriminative power (aROC of 0.718). CONCLUSIONS. None of the variables showed a statistically acceptable relationship with ICU or Hospital mortality. The general severity indices SAPS II and APACHE II demonstrated a better discriminative power than the multiple organ failure scores. However, in this group of patients,it is still difficult to know objectively what factor or combination of factors may be useful in deciding the admission of the patient in an ICU.  Recently due to new developments in interventional gastroenterology and new therapeutic options for treatment, gastroenterological and hepatological (GEH) admissions to acute care settings has been decreased. For general intensive care units (ICU) gastroenterological and hepatological (GEH) diseases consititutes the minority of ICU admissions. So we planned to find the incidence and clinical course of admissions due to GEH complaints in a medical ICU. OBJECTIVES. Main objective is to analyze clinical and epidemiological features of patients admitted to ICU with GEH disorders. Other objectives are to analyze the mortality rate and the factors contributing mortality in these patients. and 2010 who stayed for more than 48 h were included. The prospectively developed data including demographics, prognostic scores and clinical features of patients were analyzed retrospectively. Patients with GEH disorders consituted 17% of patients admitted to ICU. One hundred thirthythree patients with an age of 66 [54-77] years and gender of %55 male were included. More than half of these patients (59%) did not have any chronic GEH disease. The patients were admitted most often from the emergency department (57%). The most frequent admission diagnosis was gastrointestinal bleeding (50%) followed by hepatic diseases including hepatic failure and acute hepatic encepahalopathy, biliary tract infection (15%), pancreatitis (5%) and enteric diseases including massive diarrhea and bowel obstruction (5%). On admission median APACHE II and glasgow coma scores were 18 [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] and 15 [12] [13] [14] [15] [16] [17] [18] [19] , respectively. Acute kidney injury (defined by RIFLE criteria risc, injury or failure) was found in 59 (%44) patients. The most common RIFLE class was class failure (22%). During ICU stay 24 patients (18%) needed renal replacement therapy and 42 patients (32%) received mechanical ventilation. Nosocomial infection developed in 23(17%) patients and ICU aqıired severe sepsis occured in 22(17%) patients. ICU and hospital mortality were 37% and 41% respectively. Length of ICU and hospital stays were 6 [4] [5] [6] [7] [8] [9] and 12 [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] days respectively. Respiratory failure requiring mechanical ventilation, acute renal failure on admission and severe sepsis in the ICU were found to be the independent factors determining mortality in these patients (p = 0.000, p = 0.042 and p = 0.002 respectively). Patients with GEH constitued 17% of patients admitted to ICU. They usually do not have any chronic GEH disease. Gastrointestinal bleeding is the most frequent admission diagnosis. Respiratuar and renal failure on admission and severe sepsis occured in the ICU are the major determinats of mortality in these patients. INTRODUCTION. In recent years described series with hematological patients in ICU, but these studies are often limited because they are retrospective, single center in a few patients divided over many years. To determine the characteristics of mortality in this group is very important to assess their management in the ICU. OBJECTIVE. To analyze prognostic factors associated with ICU mortality of patients (pts) with hematologic malignancies admitted to the intensive care unit (PTU). METHOD. An observational, transversal, prospective, multicenter OCT conducted between June 2007 and October 2008. We conducted a descriptive analysis, Chi-square, bivariate and logistic regression including variables with a value of p \ 0.2 with the SAS statistical Pauet to assess the factors influencing mortality in ICU. We included 450 patients from 34 ICUs. The mean age was 54 years. The APACHE II at admission was 22.89 ± 8.24 ) and the first day SOFA ± 4.34 9.24 (8.84-9.64). The crude mortality ICU was 51.6% (232 pts). We divide related mortality by infectious etiology (61%) versus other causes (39%). In univariate analysis the variables significantly associated with mortality were: males p \ 0.01, hematology plant from 0.007, 0.04 multiple myeloma, respiratory failure at admission \0.0001, tachycardia, 0.002, 0.001 hypothermia, tachypnea 0 02, APACHE II C 20, more than two organ failures \0.0001, presence of ARDS \ 0.0001, invasive mechanical ventilation (IMV) \ 0.0001, NIV 0.0003, 0.0002 transfusion (of all products: red cells, platelets and plasma), acquisition intraUCI infection 0.009, 10 days longer stay in ICU 0.002. The presence of neutropenia was not associated (p = 0.0533) at a significantly higher mortality, or personal history, septic shock, bone marrow transplant or other reasons for admission to the ICU. Table 1 describe the independent factors associated with mortality in logistic regression analysis.  Variables classics such as septic shock or neutropenia not associated with mortality. And the independent variables associated with increased ICU mortality were: VM, ARDS, severity and need for transfusion of blood products. RESULTS. 41 patients were identified. Major haematology diagnoses were acute leukaemia 32%, NHL 22% and lymphoma 12%. Mean time to ICU admission was 13.4 days with 31% admitted within 24 h. The commonest reasons for ICU admission were respiratory failure 49%, sepsis 33% and acute renal failure 7%. The mean number of organs supported was 2.9. 65% of patients had C 3 organ failure. Mean APACHE II score was 24.5. Increasing organ failure correlated with increasing mortality. Patients with 4 or 5 organ failure had 100% mortality. Mean ICU stay was 10 days with 35% having an ICU stay of less than 48 h. ICU mortality rate was 62.7%. 46.5% received invasive ventilation, 16.3% failed non-invasive ventilation (NIV) and required invasive ventilation, 16.3% had NIV only and 21% received no respiratory support. Vasoactive support was given to 74.3% and RRT to 23.3%. Invasive ventilation and NIV were associated with a higher mortality; 90 and 60% versus 40% in spontaneously ventilating patients. Vasoactive support was associated with more organ failure, longer ICU stay and higher mortality. RRT was associated with a higher mortality 90 versus 54%. Patients with a documented poor haematological prognosis had a higher mortality but also more organs supported. CONCLUSIONS. From this study invasive ventilation, cardiovascular support and multiorgan failure are strongly associated with increased mortality. The need for RRT was not an independent predictor of mortality. Close collaboration is needed between the specialities to allow early resuscitation and critical care support to avoid delayed admissions with multi organ failure. INTRODUCTION. The prescription of stress ulcer prophylaxis (SUP) in critically ill patients is relatively commonplace due to the association between physiological stress and gastrointestinal (G.I.) bleeding. However, recent guidelines recommend that only patients who are mechanically ventilated, and/or have a coagulopathy warrant prophylaxis. They also state that histamine receptor blockers (H2RB's) can be used primarily for SUP (1). OBJECTIVES. The aim of this audit was to compare prescription practice of SUP at the ITU/HDU at Mayday Hospital with those set out in the guidelines and to calculate the potential cost savings resulting from following these guidelines. METHODS. Data prospectively collected from consecutive admissions to Mayday Hospital ITU/HDU between October and November 2009. . Data was collected on 56 patients, 3 had a G.I. bleed on admission, and 8 were already on SUP so were excluded. 27 of 29 (96%) patients with major risk factors were prescribed SUP, compared with 11 of 15 (73%) patients with no major risk factors. Proton pump inhibitors (PPI's) were prescribed preferentially to H2RB's; 31 versus 14. The cost of SUP during the audit period was £5,646. If we had only prescribed it to those at high risk the cost would have been £5,079.86, and if we had only used H2RB's the cost would have been £745.07. Prescribing of SUP in our unit does not reflect Quenot's guidelines. This not only represents an increased cost but there are increased rates of nosocomial pneumonia and C. Difficile diarrhoea associated with SUP (2, 3) . There is little evidence showing the superiority of PPI's over H2RBs in the prophylaxis of bleeds; and there is evidence of an increased rate of the aforementioned infections with PPI's as compared to H2RB's (3). We prescribed PPI's to a significant majority of our patients; however, it is our opinion that our current unit practice is not dissimilar to that of the rest of the UK. We would encourage all critical care units to review their SUP prescribing as our results show that significant savings can be made with judicious prescription of these drugs. . Surprisingly little is published on the cost of drug treatment for critically ill patients. Critical care is expensive, mainly due to the high staff ratio, expensive equipment but also due to a significant reliance on pharmacological management, which is usually funded with a limited drug budget. OBJECTIVES. To explore the relationship between drug expenditure, patient acuity and outcome. METHODS. Data was generated by retrospective analysis of consecutive patients admitted to our 35 bedded general adult ICU/HDU in a London teaching hospital, during February 2009. Patients were excluded from analysis if they were present in ICU for less than 24 h. The first and final CCU days stay were not included so that only full days were analysed. Daily drug-use per patient was manually extracted from the computerized ICU management system (CIS, QS, GE Medical). Costs of prescribed drugs, fluids and parenteral nutrition (PN) were calculated from the pharmacy computer system and analyzed using regression analysis (SPSS ver18). RESULTS. The patient characteristics and outcomes of the 82 patients are described in Table 1 TABLE 1 PATIENT CHARACTERISTICS AND OUTCOMES Age 63 (50-75)* Gender (male n and %) 37 (45%) APACHE II score 17.9 (8.5)** TISS score/patient 15.9 (6.1)** Length of CCU stay (days) 3 (2-6)* CCU survival (n and %) 71 (86.6%) Daily drug cost for each patient's stay £28.2 (£17.9-61.5)* Daily drug cost for CCU and hospital survivors n = 61 £24.5 (13.8-47.8)* Daily drug cost for CCU survivors who died in hospital n = 10 £38.0 (25.2-73.6)* Daily drug cost for CCU non-survivors n = 11 £74.1 (39.7-80.3)* *Median (interquartile range), **mean (standard deviation) The median daily drug cost was £28.2. Of note, the drug cost was highest for CCU nonsurvivors compared with survivors and also compared with patients who died in hospital after CCU discharge (p = 0.01). Multivariate regression analysis demonstrated that median daily drug cost/patient = -4.2 + 1.1 (mean TISS score) + 1.4 (APACHE II score), R 2 = 35.6%; i.e median daily drug cost/patient was positively associated with TISS and APACHE II score explaining 36% of the variation in cost seen. CONCLUSIONS. This is the first study to show that daily drug expenditure in all general CCU adult patients correlates with patient acuity. Median daily drug costs/patient were found to be £28.2. This parameter would make an interesting comparison with other units both nationally and internationally. Daily drug costs can be predicted on the basis of APACHE II and TISS scores. Furthermore, this may be further refined to develop a quality marker of daily drug cost in relation to survivors and non-survivors. MATERIAL, METHODS AND RESULTS. All patients admitted to the ICU of neurotrauma, which underwent a tracheostomy after admission. Data were collected: affiliation, Cause of admission, average stay, indication of tracheostomy, tracheostomy time delay from its indication, place of performance of the procedure (ICU or operating room), perioperative complications (event during transfer to operating room, event during surgery: hypoxia, hypotension, arrhythmia, bleeding, premature extubation, false cannulation, cardiac arrest, pneumothorax or death), and postoperative complications in the first week (bleeding, difficulty in changing cannula, stomal infection, pneumothorax, death CONCLUSIONS. Tracheostomie is a simple surgical technique and 64.81% of tracheostomíes could be safely performed in the ICU, saving hours of scheduled interventions in the operating room. There were no serious event during the transfer to the operating room or during the performance of tracheostomy. Tracheostomized patients in ICU, had a higher incidence of hypotension during surgery, although this complication in any case was serious or required treatment with vasoactive amines. When the tracheostomy is performed in the operating room, the delay shows a tendency to be higher, although this difference is not SS INTRODUCTION. The concept of tight glyceamic control in critically ill has led to the rise of number of insulin infusion protocols designed to keep the blood sugar (BS) in predefined range. At the same time monitoring practices and patients populations vary greatly between intensive care units and thus so do the results. The matter is complicated by the absence of a widely agreed common glyceamic control indicators against which protocols can be evaluated and compared (1). To establish the quality of glyceamic control in two different intensive care units. To compare the quality of glyceamic control between two intensive care units, with different glyceamic protocols and blood sugar measurement practices. We conducted retrospective non-randomized population study comparing quality of glyceamic control in two independent and non-related intensive care units. Time spend in pre-defined glyceamic range was chosen as a quality indicator for both units (1, 2) . Data was collected from the electronic database and point of care BS measuring devices. The frequency distribution was analyzed to establish the patient-to-patient variability and a degree of BS deviation from the target value. RESULTS. Units were different in method of sampling, frequency of sampling, target for optimal glyceamic range and instigated insulin protocol. Data was collected on 104 patients (5, 234 BS measurement) in ITU1 and 120 patients (3, 232 BS measurements) in ITU2. Mean BS was 7.2 (SD = 1.9) mmol/l in ITU1 and 7.6 (SD = 2.3) mmol/l in ITU2. CONCLUSIONS. The performance of both protocols were satisfactory-92.8 and 89.24% of the time patients spend with BS less than 10 mmol/l in ITU1 and ITU2 respectively. The quality of glyceamic control on both ITUs is similar in terms of proportion of time spend in different glyceamic bands, with the exception of the longer time spend in a hyperglyceamic state in ITU2. This study confirms the notion for a need of unified approach for evaluating quality of glyceamic control for in-patient populations. with an ICU mortality of 36.8% and in-hospital mortality of 47.3%. The median transfusion threshold was a platelet count of 35 9 10 9 /L with yearly medians ranging from 21.5 9 10 9 /L to 40 9 10 9 /L. The % of platelet transfusions complying with BCSH guidelines increased from 53.1 to 68.8% during the 10 year study period. The specialties with the highest platelet requirement were General Surgery (27.6%), Haematology (12.1%) and General Medicine (10.9%) as a % of total units transfused. The yearly median threshold for haematology patients fell from 31.5 9 10 9 /L in 2000 to 6 x10 9 /L in 2009, increasing guideline compliance from 16. INTRODUCTION. Numerous protocols (e.g. glycaemic control, HHH, renal rescue) have been introduced into ICU. These protocols involve blood sampling to assess gases, haemoglobin, glucose and electrolytes. This may result in anaemia and subsequent transfusion and adverse clinical outcome (1, 2) . Reducing blood loss due to sampling is an important blood conservation strategy (3) . Currently, our ICU processes over 4,000 blood samples per month. OBJECTIVES. To study the indications for blood gas sampling in our ICU and identify strategies to reduce sampling. METHODS. We performed a prospective, observational study over 1 week in 2009. The nurses completed a questionnaire per shift per patient to assess the primary and any secondary reasons for each sample. Subsequent management changes, haemoglobin levels, active bleeding, and transfusion were also recorded. RESULTS. 424 blood samples from 25 patients and 106 questionnaires were analysed (61% of the nursing shifts). The range was 1-11 samples per patient per 12 h shift with a mean of 4. The secondary reasons showed that many samples were also being used for potassium (66%) and glucose (61%) monitoring. Only 54% of samples changed management (potassium 24%, ventilatory settings 21%, glucose 9%). Haemoglobin levels dropped by an average of 1 g/dl per week per patient with no active bleeding. 10 units of blood were transfused during the study period. CONCLUSIONS. Our study shows that reasons for sampling are often relatively weak and sampling is promoted by ICU protocols. Frequent sampling does not change management for a large proportion of samples and may cause anaemia. There are financial implications to frequent sampling-at the time of the study each sample cost £1.50 (€1.71) to process. Each unit of blood transfused cost £140 (€159). We have considered ways to reduce sampling including changing the glucose protocol to capillary sampling, using 1 ml syringes, increased use of end tidal CO 2 monitoring, protocol redesign and education of staff. REFERENCE(S It has been reported that tight glyceamic control is associated with net savings in terms of length of stay on the ITU and critical care bed occupancy (1) . Whilst it might be true for the overall length of stay, there is as yet, an un-quantified effect of frequent blood sugar measurement on the overall available nurse-patient time (2) . There is finite amount of nurse-patient time within any given shift and so prioritizing nursing care will be an important factor in critically ill and high dependency patients. This is specifically important for any saving to be realized from the introduction of automated blood sugar measurement devices (3). OBJECTIVES. To quantify the amount of nursing time devoted to glyceamic control on ITU or post-operative critical care environment based on data from four cohort studies on quality of glyceamic control in three intensive care units. A mathematical model, which takes into account frequency of blood sugar measurements and time to take each measurement was developed. Stochastic analysis was used to calculate interdependency between quality of glyceamic control and the frequency of blood sugar measurements. INTRODUCTION. Introduction of trans-catheter aortic valve implantation (TAVI) has been the latest technological advance in minimizing surgical stress and improving the chances of high-risk patient undergoing a successful aortic valve intervention (1) . The latest technology comes at considerable cost, which relates to both-the cost of the TAVI valve and to it's delivery system. Currently, there are no randomized controlled trails addressing the issue of cost-effectiveness of TAVI versus surgical AVR (2) . To build a cost-effectiveness model for patients undergoing either a TAVI procedure or a surgical AVR based on the level of care: Level1 (ward based care), Level2 (high dependency unit) and Level3 (intensive care unit) during in-hospital stay, taking into account the rate of post-operative complications in both groups. METHODS. 26 TAVI patients were matched against patients who had previously undergone surgical AVR. The groups were matched for demographic and physiological risk factors, as well as EuroSCORE. A decision analytical tree was constructed based on the length of stay in hospital and post-operative complications. A Markov model was built and the effectiveness was measured in terms of improvement in NYHA class, which was translated into the quality adjusted life years (QALY) (3) . RESULTS. The average in-hospital cost for TAVI was £16,940 versus £13,462 for the surgical AVR. The cost did not include the theatre time cost. In the surgical AVR group the in-patient mean cost was greater than respective cost of the TAVI group due to longer overall length of stay as in-patients. Patients in the AVR group spent more days in Level3 and Level2 care as compared to the TAVI group. CONCLUSIONS. The shorter length of stay and reduced rate of post-operative complications in the TAVI group has got the potential to substantially reduce the overall in-patient cost and offset high cost of the valve. The effectiveness arm of the models did not differ for both groups, due to the lack of published literature, and raises a need for a QALY assessment for the effectiveness of TAVI. The rate of post-operative complications in surgical AVR group (higher rate of stroke and need for cardiac pacemaker) substantially affected the projected long-term cost. OBJECTIVES. To determine if interventions for permanent pacing (PPM) and change of generator are more efficient in small hospitals. Retrospective, transversal, observational study, measured through five diagnosis related groups (DRG) that make up the casemix of pacemakers from the Spanish Minimum Basic Data Set in 2007, descriptively analyzing demographic variables (age, gender), clinical (number of secondary diagnoses (NSD) and procedures (NP), mortality) and management (total, preoperative length of stay, access, discharge, hospital size), defining inefficient stays exceeding 2 days the average. A bivariate study contrasting quantitative variables and comparisons between nominal and categorical, evaluating the independent association between short stay and different covariates studied building a binary logistic regression model, introducing as independent variables those that were significant in the bivariate as well as those considered that might be associated with the dependent variable. INTRODUCTION. Blood products are in short supply and with an ageing population the demand is likely to increase. Blood use has been shown to be declining within the surgical specialties and intensive care, however overall use has remained unchanged. This audit looks at the use of packed red cells amonsgst medical inpatients to determine appropriateness. To determine if red cell use is appropraite among medical inpatients METHODS. Medical blood transfusions were examined between August 2007 and August 2008. 207 patients were selected and pre and post transfusion haemoglobins were determined along with chronicity of anaemia. Transfusions with haemoglobins of C8.1 g/dL triggered a case note review. Over 12 months 1,071 patients were transfused 5,792 units. 3,593 units (62%) were given to 603 medical patients (56%), of which 207 patients were reviewed receiving 460 transfusions. Average age was 70. In 111 patients pre transfusion haemoglobin was B8 g/dL (54%) and in 79 patients C8.1 g/dL (38%). In the group B8 g/dL 49 patients had acute anaemia and 62 had chronic anaemia. In the group C8.1 g/dL 22 patients had acute anaemia and 57 had chronic anaemia. 14 patients were not transfused and 3 had absent data. Out of 71 case notes only 28 were available. 11 patients were transfused for acute anaemia, 17 for chronic anaemia of which 5 patients had cardiac disease, 4 had haematological disorders, 3 patients had iron deficiency anaemia and 1 patient was folate deficient. CONCLUSIONS. Chronic anaemia in the over 65 s accounted for the majority of transfusions. Documentation was substandard. Transfusions in chronic anaemia may be reduced by up-to-date guidance on transfusion triggers and alternative strategies to the use of blood products. (2009) RESULTS. The commonest indication for PCT was long-term mechanical ventilation (73%) followed by airway protection (25.58%). 9.9% patients had platelets count\1 lac while 1.3% had severe thrombocytopenia (\40,000). 21.26% patients had an additional coagulopathy (hepatic failure and multiple organ failure), with INR [ 1.5 was present in 15.28% and deranged APTT in 5.98% patients. PCT was safely performed in all these patients. The patients received platelets or fresh frozen plasma(FFP) before the procedure to optimize coagulation. Only 0.66% had minor bleed through stoma, which was stopped in 10-15 min requiring gauze compression. CONCLUSIONS. PCT under videobronchoscopic guidance has low haemorrhagic complication rate in patients with deranged coagulation profile. Platelets/FFP should be transfused before the procedure in these patients. INTRODUCTION. Blood components transfusion is common in the critically ill patient, as in the acute bleeding or the acute illness with multiorganic failure context. As any medical intervention, it has clinical indications and associated risks. Clinical guidelines have evolved in a restrictive direction, suggesting that decision should be based on particular clinical situation and not only on analytical results. OBJECTIVES. Understand our transfusional practice and how close it is to clinical recommendations, as a quality indicator of our Intensive Care Unit (ICU). Retrospective study using the ICU patients data base. The population consists of patients with more than 24 h ICU stay in 2009. The variables analysed are sex, age, diagnostic class (medical, surgical, trauma), SAPS II score, mortality, number of transfusional events (erithrocyte concentrate, platelets, fresh frozen plasma and albumin) and the concordance to our hospital clinical guidelines. RESULTS. The population is of 334 patients, 63% of male gender, with an average age of 58 years-old. The admission diagnostic is medical in 50% of patients, with an average SAPS II score of 44, median ICU stay of 10 days and a mortality rate of 27%. 54% (n = 181) of patients received any kind of blood component transfusion, mostly erithrocyte concentrate (85% of patients), followed by albumin (54%). The populations of transfused patients is older (60 vs. 56 years-old), has a longer ICU stay (12 vs. 7 days), higher SAPS II score (46 vs. 40) and mortality rate (28.8 vs. 24.3%) . Pretransfusional values are hemoglobin of 7.5 g/dL, 48,000 platelets/uL, and albumin of 2.1 g/dL. The level of concordance with recommendations is high for erithrocyte concentrate (85%), platelets (89%) and fresh frozen plasma (87%) but not for albumin (49%). CONCLUSIONS. The level of transfusion is high in ICU patients. The population who received transfusion has a more severe clinical condition and higher mortality rate. The level of concordance with recommendations is high with the exception of albumin, which use is still less standardized. with increasing acuity due to escalating ICU bed demand, but the impact on patient safety is unclear. SDU continuous non-invasive physiologic monitoring of HR, RR, BP and SpO 2 identifies cardio-respiratory instability often unnoticed by caregivers. Causes may be alarm fatigue and/or high SDU nurse-to-patient ratios which make bedside monitoring insensitive. Instability may become more resistant to intervention the longer it occurs. The impact of instability duration upon SDU patient outcomes is understudied. OBJECTIVES. The study purpose was to determine the impact of cardiorespiratory instability duration experienced by in-patients being cared for on a monitored SDU upon hospital length of stay (LOS) and hospital charges. Prospective study of monitored patients on a 24-bed trauma SDU over 16 weeks. Noninvasive continuous monitoring data were downloaded from bedside monitors and analyzed for vital signs (VS) beyond local instability criteria: HR\40 or [140, RR\8 or [36, systolic BP \80 or [200, diastolic BP [110, SpO 2 \85% . VS time plots of unstable patients were further assessed to judge instability as mild or serious. Instability duration categorized as: none, [4] [5] [6] [7] [8] [$200 K) . Relationships between instability duration and outcomes analyzed with Chi-Square for mild and serious instability. CONCLUSIONS. There has been a marked improvement in the overall recording of SEWS since the previous study. It is of concern that respiratory rate was again the least well recorded parameter as this has been shown to be the best physiological predictor of impending cardiopulmonary arrest 1, 4 . This may be because respiratory rate is not provided by the automated monitoring devices available on the general wards in our hospital, and must be calculated manually. it demonstrated an increase in mortality even when TISS scores were taken into account as an independent risk factor. 4 Since these publications critical care outreach and the use of early warning scores have become common place; however it was felt that time of discharge was still impacting on patient outcome. To review our post-unit mortality and readmission rate, with particular focus on the time of discharge. CONCLUSIONS. Our mortality and readmission data compare favourably with a recent publication. 5 There is a clear difference in mortality related to time of discharge; however this is for evening discharges as compared to night discharges in previous papers. [1] [2] [3] [4] The time of discharge may represent logistical issues of planned discharges or early discharge decisions due to pressure for beds. Overnight discharge is an uncommon occurrence in our unit; this evidence suggests that previous concern about night discharges should be extended to evening discharges.  Transferring critically ill patients is a challenging task in the day to day activities of the critical care team. Safe accomplishment of these transfers relies on skills of the persons accompanying and the resources available. Guidelines have been produced by various professional bodies [1, 2] to safely accomplish these transfers. The competency document released by the Royal College of Anaesthetists, UK requires that junior trainees have appropriate knowledge, skills, attitude and behaviour in the principles of safe transfer of critically ill patients [3, 4] . To obtain information about trainee's perspective, experience and knowledge in transfer of critically ill. A web based online survey was sent to all the anaesthetic/ITU trainees in the West Midlands region of the UK. RESULTS. Total number of respondents were 72. Of these, 12.5% had less than 3 months of anaesthetic training before undertaking a transfer. Only 33% had formal training on transfer of critically ill patients. 79% of the trainee's didn't have any competency based formal assessment of their skills, attitudes and behaviour in transfer of critically ill patients. Majority of them (86%) felt that every one should undergo formal training before undertaking transfers. While 91% of the respondents have undertaken transfers during their training, only 33% have experienced some form of critical incident during these transfers. More than 50% of these adverse events were related to equipment failures while 27% were due to patient deterioration. Nearly 75% of the trainees were not aware of terms and conditions of the insurance cover for these transfers. CONCLUSIONS. This survey highlights the deficiencies involved in training the trainee's for transfer and the transfer itself. The results demonstrates that majority of the trainees would prefer to attend specific transfer courses before venturing out on an actual transfer. We hence recommended the following for implementation: improvement of training process for those undertaking transfers; regular monitoring of this process; regular analysis of critical incidents and acting upon it; making the insurance compulsory for those undertaking the transfers.  Greek hospitals, including initial management of critically ill patients and primary care for a growing proportion of the population. The impact of ED length of stay (LOS) on patient outcome has not been covered adequately by existing surveys so far. OBJECTIVES. The aim of this study was to determine the association between ED overcrowding and outcomes for critically ill patients. In the present study, we included medical and surgical pts that all of them were intubated promptly to ED of 2 general hospitals of Athens GR, for 12 months. Pts survived [24 h were divided into 2 groups: ED boarding \6 h (group A) and ED boarding C6 h (group B). Demographics, APACHE II, diagnosis, LOS, and ICU and hospital mortality were recorded. ED boarding time was measured in min. Groups were compared using Chi-square, Mann-Whitney, unpaired Student's t tests and stepwise regression analysis. The collection of data lasted 12 months. RESULTS. In the ED, 196 critically ill patients with a mean age 59.6 ± 20.9 years and APACHE II score 24.6 ± 12.7 were intubated. 144 pts were males and 52 were females with a mean age 54.5 ± 20.1 and 72.1 ± 17.5 years, and Apache II score 23.8 ± 13.2 and 26.4 ± 11.5 respectively. Main diagnosis was multi trauma (72) OBJECTIVES. We sought to assess the baseline characteristics and outcomes of the patients presenting AF as a cause of MET call activation. Using the MET database of one tertiary teaching hospital, we retrospectively reviewed all patients for which the MET diagnosis was atrial fibrillation. We reviewed their clinical history, immediate treatment and outcome. These data were compared to those of a control group of randomly selected MET Calls with patients being matched for age, gender and ward of origin (surgical or medical). OBJECTIVES. To ascertain the proportion of preventable in-hospital cardiac arrests occurring at University Hospital Lewisham. Furthermore, to identify any common predictors of poor outcome that were apparent prior to those arrests and whether these are potentially modifiable. A case note review was performed on the cohort of patients who suffered inpatient cardiac arrests and who were admitted for ICU (level-3) care post-resuscitation. These patients were identified using our quarterly feedback from the Intensive Care National Audit and Research Centre (ICNARC) Case Mix Program dataset between April and September 2009. We found that half (11 out of 21) of our in hospital cardiac arrests resulted in death despite level-3 care post arrest within the audit period. 9 of these in-hospital arrests were deemed preventable from case note review and trust cardiac arrest call audit forms when available. In addition, in the preventable sub-group an arterial blood gas sample was not obtained in 7 out of 9, 77%. In all of these cases, the ICU outreach team was not aware of the patient prior to the arrest. CONCLUSIONS. In keeping with widely published data regarding survival to discharge after in-hospital cardiac arrest, the high mortality rate of 50% for this cohort of patients emphasises the importance of early recognition of abnormal physiology and timely intervention. With the sensitivity, specificity and validity of EWS yet to be validated and no clear benefit proved from the introduction of MET/outreach teams, an alternative strategy for earlier recognition of critically ill patients is needed. Our data suggests that arterial blood gas sampling, an essential investigation central to the recognition of critically ill patients is being consistently overlooked and is an important factor influencing outcome. RESULTS. Attended patients were 2,787, with mean age of 58, 7 years, and women represent 41, 2% of them. Most demanding services were Internal Medicine (31%) followed by General Surgery, Haematology and Nephrology. Global data may be seen in Table 1 . With regards to admissions to the ICU of these patients, Table 2 depicts the proportion between requested admissions, and refusals. INTRODUCTION. Tradicionally, critical care interventions are highly intensive, expensive and brief. Critical illnesses and interventions that we use, can both contribute to postICU disability: catheter-related bacteraemia, polineuropathy, resistant organism, nutricional problems, complications of tracheostomy, prolonged analgesic. All these factors and a premature discharge from an ever full ICU, can even have an impact on occult mortality after discharge from ICU (between 6 and 20%). In our Unit a follow up program have been implanted. When patients are about to be discharged from ICU, ICU clinicians selected those considered to be recoverable but fragile enough to have poor prognosis. OBJECTIVES. To quantify the workload that a after ICU follow-up entails, and to determine if this program impacts on mortality postICU. Prospective and interventional study carried out during a 7 months period. At a 18 beds medical UCI of a teaching hospital in Malaga ICU, 55 patients were enrolled in the Follow Up Program. We assessed prognosis with Sabadell score and severity of illness with APACHE II score; and registered our interventions after discharge from ICU. The final endpoint was status at hospital discharge: survivant or dead. We did 129 interventions in 55 patients: we changed a venous catheter 17 ocasions (40% of patients), changed analgesic schedule 15 times (27.2%), stopped antibiotics 13 times (24%), modified parenteral nutrition 25 times (45%) . We searched and treated sources of sleep deprivation (delirium, anxiety or insomnio) in 5 patients (9%); treated tracheostomy complications in 3 patients. Mortality of 55 patients enrolled in this program was 3.7% (2 patients) even if the mean expected mortality by APACHE II score was [30%. CONCLUSIONS. In our study, implementation of a continued follow-up program after ICU discharge in selected patients, carried out by ICU staff, was associated with an important decrease of mortality. Encouraging clinical results and a non-excesive workload for ICU staff justify continuing this follow-up. OBJECTIVES. Various therapeutic protocols were used for the management of sepsis including hyperbaric oxygene (HBO) therapy. It has been shown that ozone therapy (OT) reduced inflammation in several entities and exhibits some similarity with HBO in regard to mechanisms of action. Thus, we designed a study to evaluate the efficacy of OT in an experimental rat model of sepsis and to compare these effects with HBO. METHODS. Forty male Wistar albino rats were divided into sham, sepsis+cefepime (control), sepsis+cefepime+HBO (HBO), and sepsis+cefepime+OT (OT) groups. Sepsis was induced by an intraperitoneal injection of 2.1 9 10 9 cfu Escherichia coli; HBO was administered twice daily at 2.8-atm pressure for 90 min; OT was set as intraperitoneal injections of 0.7-mg/kg ozone/oxygen gas mixture once a day. The treatments were continued for 5 days after the induction of sepsis. At the end of experiment the lung tissues and blood samples of the study animals were harvested for biochemical and histopathologic analyses. RESULTS. Lung tissue myeleperoxidase activities and oxidative stress parameters, and serum proinflammatory cytokine levels, IL-1b and TNF-a, were found to be ameliorated by the adjuvant use of HBO and OT when compared with the antibiotherapy alone group. Histopathologic evaluation of the lung tissue samples confirmed the biochemical outcome. Some measures indicated significantly more efficacy of OT than HBO. CONCLUSIONS. Our data presented that both HBO and OT reduced inflammation and injury in the septic rats' lungs; a greater benefit was obtained for OT. These findings suggest that it may be possible to improve the outcome of sepsis by using OT as an adjuvant therapy. OBJECTIVES. To investigate the regularity for change of PAF, TM and vWF in septic rat, and the protective effects of statins on vascular endothelium. METHODS. Fifty-four male SD rats were randomized into simvastatin with LPS group (group A, n = 24) and LPS group (group B, n = 24) and control group(n = 6). They were respectively accepted 10 ml/kg normal saline (NS) abdominal injection for both control group and group B, 10 ml/kg simvastatin abdominal injection for group A, then 15 h later, total 48 male SD rats from group A and group B were respectively accepted LPS (10 mg/kg weight) abdominal injection to establish sepsis model and 10 ml/kg NS abdominal injection for control group. Thereafter, detected the serum concentration of von Willebrand factor (vWF), thrombomodulin(TM) and antithrombin (AT-III) at different point of time (1, 3, 6 and 12 h after LPS abdominal injection) in both group A and group B by ELISA, the endothelial cells from thoracic aorta was observed with electron microscope. Under electron microscope scanning, endothelial cells in septic rats from group B were found disarranged. Under transmission electron microscope, endothelial cells were found to be in prophase of apoptosis characterized by unclear cell membrane, thickened cellcell conjunction, disappeared desmosome and microfilament, dissolved or vacuolized organelles and agglutinated and evaporated chromatin gathering under the karyolemma, but the karyorrhexis were not found. No similar changes were found in group A. (1) INTRODUCTION. Sepsis induced lymphocyte apoptosis is believed to play an important role in the pathogenesis of sepsis and in the development of the immunesuppresion observed in septic patients. Lymphocyte apoptosis not only decreases the number of functional lymphocytes but may also modify the immune response towards an anti-inflammatory state. Erythropoietin (EPO) has recently been recognized as a multifunctional cytokine with antiinflammatory, antioxidative, and antiapoptotic properties. OBJECTIVES. This study aimed to test whether EPO could mitigate peripheral blood mononuclear cell (PBMC) apoptosis and whether EPO could modify the dynamic changes in lymphocyte-subsets in a porcine model of acute endotoxemia. METHODS. Twenty-eight anesthetized and mechanical ventilated pigs were randomized to one of three groups: 1) EPO group, EPO administered 1 h prior to endotoxemia (n = 9); 2) Placebo group, vehicle administered 1 h prior to endotoxemia (n = 9); 3) Sham group, animals only anesthetized and mechanical ventilated. Endotoxemia was induced by an infusion of lipopolysaccharide (LPS). After 2 h the LPS infusion was reduced to a maintenance dose and the animals were fluid resuscitated. PBMC were isolated at time 0, 60, 240, and 540 min of endotoxemia. Apoptosis in PBMC and relevant lymphocyte subsets were assessed by staining with 7-amino-actinomycin D (7AAD) and annexin V using multicolor flow cytometry. Apoptotic lymphocytes in spleen were quantified by immunohistochemical staining for activated caspase-3. Endotoxemia increased the number of apoptotic mononuclear cells in both blood (P = 0.002) and in spleen (P = 0.03), but with no significant modifying effects of EPO. The numbers of both CD4+ (T-helper) and CD8+ (cytotoxic) T-cells declined during endotoxemia. CD21+ cells, defining B-lymphocytes, demonstrated a biphasic response with an immediate decline followed by an increase in number of B-cells. The dynamic changes in the lymphocyte subsets were not modified by EPO. , and reduced the number of circulating leucocytes. EPO had no modifying effects on these dynamic changes. Furthermore, EPO did not mitigate apoptosis in PBMCs analyzed by flow cytometry or in spleen lymphocytes analyzed by immunohistochemistry. This study does not support that EPO confer protection against lymphocyte apoptosis. OBJECTIVES. Aim of this study was to investigate the effects of combined, recombinant human activated protein C (rhAPC) and ceftazidime (CEF) in our established model of acute respiratory distress syndrome (ARDS) and septic shock METHODS. Thirty sheep (35-40 kg) were operatively prepared for chronic study, and were randomly allocated either to sham, control, rhAPC, CEF, or rhAPC/CEF groups (n = 6 each). After tracheostomy, acute lung injury and sepsis was produced in all groups, following an established protocol (1, 2) , except the sham group that received the vehicle. The sheep were studied for 24 h in an awake state and were ventilated with 100% oxygen. PaO 2 /FiO 2 ratio was determined intermittently. CEF (3 g) was administered intravenously 1 and 13 h post injury. RhAPC was given as a continuous infusion (24 mcg/kg/h), starting 1 h post injury. The animals were resuscitated with Ringer's Lactate Solution to maintain filling pressures and hematocrit. Lung tissue was obtained during necropsy and analyzed for myeloperoxidase (MPO) using a commercially available kit. Statistical analysis: two-way ANOVA and Student-Newman-Keuls post hoc comparison. Data are expressed as mean ± SEM. Significance P \ 0.05. . MPO levels (mU/mg protein) were 70 ± 8 in sham and significantly increased in the control group (140 ± 15*). The rhAPC (118 ± 20*) and CEF group (120 ± 18*) increased significantly vs. sham and tended to be lower than controls, but not statistically significant. MPO levels of combined rhAPC/CEF (90 ± 20*) showed no difference to sham, but were significantly lower than controls or rhAPC or CEF alone. CONCLUSIONS. Combined administration of rhAPC and ceftazidime in ARDS associated with septic shock improved oxygenation more than CEF or rhAPC alone, and prevented the onset of ARDS. Seleno-compounds, such as sodium selenite (Na 2 SeO 3 ) show conflicting clinical results in the treatment of sepsis. Efficacy, as well as mechanism of action of Na 2 SeO 3 , are unclear, with prevailing opinion that it acts as an anti-oxidant. However, Na 2 SeO 3 has also oxidant properties that could have a paradoxical therapeutic role in septic shock by reducing over-activated phagocytic cells. Indeed, in septic sheep, high dose Na 2 SeO 3 injection as bolus rather than continuous administration resulted in a beneficial effect on survival time, macro and microcirculation (1). OBJECTIVES. To investigate at the endothelial level the mechanism of action of a bolus injection of a high oxidative dose of Na 2 SeO 3 . In 17 Male Wistar rats, lipopolysaccharide (LPS, 55 mg/kg) or normal saline were injected intraperitoneally, followed 1 h later by either an intravenous bolus injection of Na 2 SeO 3 (corresponding to 0.4 mg/kg Se) or normal saline. After 5 h of LPS, extravasation of fluoroisothiocyanate-dextran and leukocyte-endothelium interaction in venules of the cremaster muscle were quantified by intravital microscopy. RESULTS. Na 2 SeO 3 did not alter systemic haemodynamic variables as compared to LPS rats. There were no intergroup differences in fluoroisothiocyanate-dextran extravasation. LPS significantly decreased leukocyte rolling when compared to control animals (p \ 0.05). Bolus injection of Na 2 SeO 3 did not alter leukocyte rolling but decreased leukocyte adhesion and extravasation levels to control values. Our results in endotoxemic rats suggest that a toxic dose of Na 2 SeO 3 may have a beneficial effect of on leukocyte-endothelium interaction without a significant effect on plasma extravasation. OBJECTIVES. To design a model of sepsis in pigs characterized by an unchanged Q T over time. METHODS. After a 12 h fasting, pigs (weight 27-30 kg) were sedated with ketamine (10 mg/ kg) and midazolam (0.5 mg/kg) i.m. Animals were tracheostomized and anesthetized (propofol 15 mg/Kg iv bolus, followed by 10 mg/kg/h), atracurium (0.5 mg/kg/h) and fentanil (5 lg/Kg/ h). The internal jugular vein, carotid artery and pulmonary artery were catheterized for iv fluid administration and monitoring. A lumbotomy was performed and an ultrasonic blood flow and a Laser-Doppler microvascular flow probes were placed in the left renal artery and on the kidney surface to measure renal artery blood flow (RABF) and renal cortical blood flow (RCBF), respectively. A cystostomy was performed to collect and measure urine output (UO). Sepsis was induced by the iv administration of live E. coli (1.  Our previous study showed that citrulline (CIT) supplementation during endotoxemia improved microcirculatory flow and endothelial function, and prevented glycocalyx degradation as a consequence of increased arginine (ARG)-dependent vascular Nitric Oxide (NO) production. During sepsis the availability of ARG, the substrate for endothelial NO production, is tempered as a consequence of increased inflammatory NO synthase (iNOS) activity. The reduced endothelial NOS (eNOS) activity and vascular NO production is believed to result in endothelial and vascular dysfunction. A shortage of ARG availability for eNOS is considered the main cause of the dysfunction. Previous studies have indicated CIT as an important, if not exclusive, mediator for eNOS-derived NO production. CIT is a substrate for Argininosuccinate synthetase, an ARG-producing enzyme that co-localizes with eNOS in the caveolae, thus directly and exclusively supplying ARG to eNOS. OBJECTIVES. We investigated whether CIT supplementation during an ongoing endotoxemia rescues the eNOS-derived NO production in endothelial cells, thereby providing a mechanistic explanation for its positive in vivo effects. Mice received a continuous intravenous endotoxin (LPS, 200 lg total) infusion for 18 h alone or an 18 h LPS infusion with CIT (37.5 mg total) during the last 6 h of endotoxin infusion. After the 18 h infusion, the mice were sacrificed, arterial blood was sampled and the carotid arteries were removed. NO production in the carotid arteries was measured ex vivo with 2-photon fluorescence microscopy, using a fluorescent copper-based NO probe. Amino-acid concentrations in plasma were measured by HPLC. RESULTS. Both CIT and ARG plasma concentrations were significantly increased in the LPS-CIT group compared with mice treated with LPS alone (p \ 0.05). In vivo CIT supplementation led to detectable levels of NO production ex vivo in carotid smooth muscle cells (SMC) and endothelial cells (EC) by using the NO-probe with 2-photon fluorescence microscopy. While EC-derived NO production was absent in the carotid arteries of mice treated with only LPS, the SMC-related NO signal was undisturbed. NO production in the EC of the LPS-CIT group was not blocked by the iNOS inhibitor 1,400 W, suggesting eNOS to be responsible for the observed effect. Furthermore, ex vivo incubation of the carotid arteries of the LPS-CIT mice for 30 min with extra CIT (75 mg/mL) resulted in prominently increased NO production in the carotid EC, whilst this effect was not observed in the carotid arteries of LPS without CIT treated mice. CONCLUSIONS. CIT supplementation during murine sepsis rescues the eNOS-derived NO production in carotid artery endothelial cells, providing a mechanistic base for the positive effect of CIT supplementation on endothelial NO synthase during endotoxemia. GRANT ACKNOWLEDGMENT. OBJECTIVES. Investigated the mechanism involved in the clearance of bacteria observed after rPAF-AH treatment in sepsis model. Mice were subjected to CLP model, after 15 min, the mice were treated with rPAF-AH. The CFU counts and measured of mediators were determined. RESULTS. The numbers of bacteria (CFU) recovered in the peritoneal fluid was inhibited in rPAF-AH treated group (140.0/7.35), suggesting a more efficient clearance of bacteria after rPAF-AH treatment. Direct incubation of S. Typhimurium, E. coli and S. aureus failed to affect bacterial growth indicating lack of a direct effect of PAF-AH on bacteria. Administration of rPAF-AH in CCR2 (receptor for MCP-1/CCL2) deficient mice failed to increase bacterial clearance after CLP, suggesting that MCP-1 signaling is involved in this phenomenon. rPAF-AH treatment also failed to increase bacterial clearance in iNOS deficient mice and NO levels were found to be elevated (14.07 ± 5.5/22.57 ± 7.5) in peritoneal fluid of the mice treated with rPAF-AH after CLP surgery. Synergism for NO production was also seen when macrophages stimulated with E. coli were treated with rPAF-AH+MCP-1 and correlated with better bacterial killing by macrophages. Peritoneal macrophages from knockout mice for MCP-1, stimulated from LPS+IFN inhibited NO levels when compared to WT mice (60.18 ± 0.46/21.92 ± 0.12). This results indicating that, excessive MCP-1 favors macrophage production of NO and hence the ability of macrophages to deal with invading bacteria. CONCLUSIONS. We conclude that the increase in bacterial clearance is important for the protective effect of rPAF-AH in sepsis and that exist a signaling involving MCP-1/CCL2 and NO in this system. INTRODUCTION. Disturbances within the microcirculation represent an important factor in the pathogenesis of multiple organ dysfunction during systemic inflammation and sepsis [1] . Dehydroepiandosterone (DHEA) has immunomodulatory effects and improves survival in several animal models of trauma, hemorrhage and sepsis but also causes potent vasodilatation [2] . To maintain efficient microcirculation we combined DHEA with sodium orthovanadate (SOV), which augments vascular contraction. Furthermore, SOV has been identified to attenuate tissue injury and improve survival related to inflammatory response [3] . OBJECTIVES. We investigated whether the combined administration of DHEA and SOV has beneficial effects to microcirculation in experimental sepsis. We divided sixty male Lewis rats into six groups: control group; ethanol (solvent) treated control group; DHEA (50 mg/kg) + (7.5 mg/kg) treated control group; endotoxemic group (LPS 15 mg/kg); DHEA + SOV treated endotoxemic group; DHEA (25 mg/ kg) + SOV treated endotoxemic group. Two hours after LPS challenge we performed intravital fluorescence microscopy of the intestinal wall in order to study leukocyte adhesion and functional capillary density (FCD). TNF-a, IL-1a, IL-4 and INFc, GM-CSF and MCP were measured at baseline and following 3 h of endotoxemia in all experimental groups. In comparison to untreated rats subjected to endotoxemia the treatment with DHEA (both dosages) and SOV resulted in a significant reduced number of adhering leukocytes in intestinal submucosal venules. Furthermore, the mucosal functional capillary density was significantly improved. We did not identify any changes in cytokine plasma levels. CONCLUSIONS. The study demonstrated beneficial effects of combined treatment with DHEA and SOV within the intestinal microcirculation in experimental endotoxemia. Concomitant administration of SOV permitted to reduce DHEA dosage and prevent potential vasodilation without affecting anti-inflammatory DHEA action. 1. Spronk PE, Zandstra DF, Ince C: Bench-to-bedside review: sepsis is a disease of the microcirculation. Crit INTRODUCTION. Sepsis is a disease of the microcirculation and impairment of the intestinal microcirculation during sepsis may cause a breakdown of gut barrier function thus releasing bacteria and their toxins into the systemic circulation [1] . Consequently, the protection of the intestinal microcirculation represents a pivotal therapeutic target in severe systemic inflammation. Cannabinoids that interact with Cannabinoid receptors (CB1R and CB2R) have been shown to have immunomodulatory properties in in vivo and in vitro studies and the endocannabinoid system has been shown to be involved during systemic inflammation [2] . OBJECTIVES. The aim of the present study was to examine the effects of CB2 receptor modulation on the intestinal microcirculation in experimental sepsis (endotoxemia) using intravital microscopy (IVM). We studied four groups of animals (Lewis rats, n = 5 per group): healthy controls (CON), endotoxemic animals (20 mg/kg lipopolysaccharide; LPS), endotoxemic animals treated with CB2 agonist, HU308 (10 mg/kg IV), and endotoxemic animals treated with CB2 antagonist, AM630 (2.5 mg/kg IV). Intravital microscopy of the intestinal microcirculation was performed following 2 h LPS/placebo administration. Leukocyte adhesion and functional capillary density (FCD) were measured offline in a blinded fashion. RESULTS. Following 2 h of endotoxemia, a significant increase of leukocyte adhesion in the intestinal submucosal venules (e.g., V1 venules: CON 86.8 ± 16.8 n/mm 2 , LPS 189.8 ± 27.6 n/mm 2 , p\ 0.05) was observed. Capillary perfusion of the muscular and mucosal layers of the intestinal wall was significantly reduced (e.g., circular muscular layer: CON 109.9 ± 7.8 cm/cm 2 , LPS 82.4 ± 3.5 cm/cm 2 ). Treatment of endotoxemic animals with the CB2 receptor agonist, HU308, further increased leukocyte adhesion (V1 venules: 259.9 ± 20.0 n/mm 2 ), whereas CB2 receptor inhibition by AM630 significantly reduced leukocyte activation (V1 venules: 142.4 ± 16.1 n/mm 2 ) and restored capillary perfusion (circular muscular layer: 107.7 ± 8.9 cm/cm 2 ). CONCLUSIONS. The data support the hypothesis, that CB2 receptor signalling is involved in the impairment of the intestinal microcirculation during sepsis. Blocking CB2 receptor signalling reduces leukocyte activation and improves capillary perfusion in acute endotoxemia in rats. The long-term effect of modulating CB2 receptors in more clinical sepsis models needs further investigation. [1] . This study compares dobutamine and levosimendan for the treatment of circulatory failure in septic shock and assesses survival benefits. OBJECTIVES. In this controlled randomized doubleblinded study 25 anaesthetized and ventilated pigs (37.1 ± 5.1 kg) were enrolled after approval by the local governmental commission. METHODS. By continuous infusion of endotoxin (Escherichia coli serotype 0111:B4, Sigma-Aldrich; 7.8 ± 2.0 lg/kg/h) over a time period of 3.5 ± 0.2 h, septic shock was induced. Hemodynamic stabilization was performed by either use of the vasopressor norepinephrine alone (control group; n = 5) or in combination with levosimendan (0.4 lg/kg/min; n = 10) or dobutamine (15.0 lg/ kg/min; n = 10). In a setting of 10 h of measurements and treatment heart rate (HR), MAP, central venous pressure (CVP), pulmonary artery pressure (MPAP) and cardiac output (CO) were recorded continuously and evaluated hourly. Beside norepinephrine requirement and mixed venous oxygen saturation (SVO 2 ) mean survival time and survival rate within the measurement period were analysed. RESULTS. After endotoxinemia septic shock was marked by reduction of CO and SVO 2 [p \ 0.05]. Mean survival time and survival rate were superior in levosimendan treated animals ( Table 1 ). Norepinephrine consumption was lowest in the levosimendan group. After 10 h, CO of surviving animals was highest in the levosimendan group and statistically different compared with the control group. Comparison of parameters HR, MAP, CVP and MPAP showed no differences between treatments. CONCLUSIONS. The complementary use of the calcium sensitizer levosimendan provides potential survival advantage in endotoxemic septic shock. Beside an increase in CO, improvement of regional organ perfusion or protection could be an explanation and has to be shown by further analysis. REFERENCE(S METHODS. The study group consisted of 100 patients with shock on vasopressor support and control group had 100 normotensive patients. Arterial and capillary samples were taken simultaneously and were tested immediately at the bedside. The results of the paired measurements were analysed as a scatter plot by Bland and Altman method and were expressed as a correlation coefficient. Values were considered to disagree significantly when the difference exceeded 20%. RESULTS. Mean arterial and capillary sugars (mg/dl) in study and control groups were 164.7 ± 70 and 157.4 ± 68.9, and 167.1 ± 62.2 and 167.5 ± 61, respectively. On Bland-Altman analysis, 6% in study group and 5% in control group were out of range (acceptable limit \ 5%) [ Figures 1, 2] . Correlation between capillary and arterial values was less in the study group (r = 0.917, p \0.001 vs. r = 0.979, p \ 0.001). In addition, the disagreement between capillary and arterial values was more than 20% in 18% of the patients in the study group vs. 3% in control group (p = 0.015) (ISO standard \ 5%). CONCLUSIONS. Capillary blood glucose monitoring can be applied reliably to patients in ICU. However, caution must be exercised in patients with shock in whom arterial blood may be preferred. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 OBJECTIVES. Our primary objective was to evaluate the safety and efficacy of a single oral high dose vitamin D3 supplementation in an intensive care setting over a one-week observation period. METHODS. 540,000 IU (corresponding to 13.5 mg) of cholecalciferol (D) dissolved in 45 ml herbal oil or matched placebo (PBO) were given enterally (via nasogastric feeding tube or swallowed) to 25 patients with vitamin D deficiency [25(OH)D B 20 ng/ml] in the medical ICU. RESULTS. Baseline characteristics including age, sex and SAPS II were balanced between the two groups (mean age 62 ± 16 years, 76% male, SAPS II 36 ± 18). Mean serum 25(OH)D levels at baseline were 14 ± 4 ng/ml in both groups. The mean serum 25(OH)D increase in the intervention group was 25 ng/ml (range 1-47 ng/ml). Two patients showed a small (7 ng/ml) or no response (1 ng/ml) attributable to gastrointestinal dysfunction after prolonged hypoxia and gastrointestinal GVHD after allogeneic stem cell transplantation. The time course of the 25(OH)D response is given in Figure 1 . INTRODUCTION. Considerable controversy has emerged as to whether tight glucose control (TGC) is warranted in all critically ill adult patients. Recently, a new blood glucose upper limit (10 mmol/L) has been assessed as more appropriate. Rather than blood glucose target ranges, algorithms used to achieve TGC should be numerically evaluated before initiating clinical trials (preclinical validation test). Our purpose was to assess performances of TGC algorithms in realistic virtual ICU patients. We compared numerically the NICE-SUGAR algorithm (N-S) 1 and the CGAO system (CGAO) used in the ongoing CGAO-REA study [ClinicalTrials.gov, ID:NCT01002482] . A set of virtual patients constituting the test bench was built with 1) real data coming from patients controlled with CGAO before starting CGAO-REA and 2) a non-linear pharmaco-dynamic glucoseinsulin system model 2 where patient endogenous glucose clearance and insulin-sensitivity were time varying parameters. In order to anticipate how algorithms would manage glycaemic control in clinical settings, delayed controls and inaccuracy of glucometers were implemented. The overall performance of each algorithm over the whole stay was assessed according to standard scores. RESULTS. The percentage of time in the target range [4.4-6. 1 mmol/L] with N-S was less than 50% for almost all patients. In insulin-sensitive patients, glycemic fluctuations and sometimes severe hypoglycemia are induced by N-S (Fig. 1 ). The mean time in the target range with CGAO was about 60% and variability scores were significantly lower than with N-S. Mean glucose and standard deviations were always lower with CGAO than with N-S. A numerical test bench constituted of realistic virtual ICU patients, whose features were defined from real data obtained in patients under glycemic control, enabled to determine the best algorithms candidate for further evaluation in clinical settings. According to this approach, the algorithm used to achieve TGC in NICE-SUGAR would not have been selected for such a large clinical trial while CGAO reached the first validation step in simulation. We recommend that further glucose control studies focus not only on the target range but also on the algorithmic properties. INTRODUCTION. There has been much debate in recent years about the appropriate level of blood glucose for intensive care patients with proposals of different levels of glucose control using insulin infusions. One risk of intensive glucose control is hypoglycaemia and this has been proposed as a measure of quality of care given by delivering the protocol safely. The NICE-SUGAR 1 trial found that intensive glucose control increased mortality among adults in intensive care. OBJECTIVES. The aim of our study was to record hypoglycaemia and study it's relation to insulin therapy. Insulin therapy on our unit follows the recommendations of the NICE-SUGAR trial. METHODS. Hypoglycaemia was recorded as a blood glucose level\3 mmol/L. Levels were detected using the blood gas analyser (Radiometer 825 M). Data was recorded at the time of hypoglycaemia to provide an explanation using the Innovian system which is the paperless patient record system on our unit. Data was obtained over a period of 3 months between October 2009 and December 2009. Data recorded included adverse events which were defined as worsening shock and/or increasing inotropic support. Feeding status at the time of hypoglycaemia was recorded. RESULTS. There were a total of 375 admissions over this period and there were a total of 13,304 blood glucose measurements. 24 incidents of hypoglycaemia were recorded, of which 13 patients were on insulin and 11 were not. Of the 13 patients who were on insulin, 5 had adverse events at the time of hypoglycaemia. All these 5 patients died within 24 h of the adverse event. All except one was on full feed. The others had minimal feed due to poor absorption. Of the 8 patients who did not have adverse events, 7 were discharged and one died 2 days after the hypoglycaemic event due to worsening sepsis. Of the 13 patients on insulin, there were 3 iatrogenic errors where feeding was stopped and the insulin was left on. None resulted in any adverse outcome for the patients. Of the 11 patients who were not on insulin therapy, 8 had adverse events at the time. 7 died within 24 h of the adverse event and 1 died 2 days later. The remaining 3 patients were discharged. None of the 11 patients were on full feeding protocol. CONCLUSIONS. Our findings suggest that hypoglycaemia in our unit is not primarily related to insulin therapy. It is related to adverse events and possibly inappropriate feeding at the time of hypoglycaemia. Hypoglycaemia, in the absence of insulin therapy, is associated with a poor outcome. Use of hypoglycaemia as a quality indicator should be interpreted with caution. INTRODUCTION. Vitamin D deficiency seems increasingly prevalent. Pleiotropic effects of vitamin D like immunomodulation and effects on muscle strength may be of special importance to critically ill patients [1] . However, vitamin D deficiency has only been studied in small and selected groups of ICU patients [2] . OBJECTIVES. To prospectively determine the prevalence of vitamin D deficiency in winter and summer and relate vitamin D status to outcome in cohorts of critically ill patients. RESULTS. Vit D was measured in 111 patients admitted in winter and 112 patients admitted in summer (Table 1 ). Mean Vit D was significantly lower in winter than in summer. In winter, 85% was deficient, 49% severely deficient. In summer, 50% was deficient, 9% severely deficient. Predicted mortality was higher in winter and higher in Vit D deficient patients. Observed mortality was lower than predicted in all groups, but not different between groups. Including both Vit D and season in a Multiple Regression Analysis, winter (p = 0.004) and not vit D (p = 0.94) was related to predicted mortality. INTRODUCTION. Glucagon-like peptide-1 (GLP-1) lowers blood glucose via stimulation of insulin and suppression of glucagon secretion, as well as slowing gastric emptying. We have previously shown that exogenous GLP-1 attenuates hyperglycaemia in non-diabetic critically ill patients [1, 2] . However, islet cell function in critically ill diabetic patients may be so disturbed that pharmacological doses of GLP-1 have no effect in this group. OBJECTIVES. The aim of this study was to evaluate the effect of exogenous GLP-1 on glycaemic excursions during intraduodenal nutrient infusion in critically ill patients with preexisting type-2 diabetes mellitus. METHODS. Nine critically ill, mechanically ventilated, patients with pre-existing type-2 diabetes (8 M:1F, Age 56 ± 6 years, HbA1C 8.7% ± 0.7%, BMI 35 ± 3 kg/m 2 , APACHE II on day 1 of study 17 ± 3, days in ICU on day 1 of study 5 ± 1) received IV infusions of GLP-1 (1.2 pmol/kg/min), and placebo, from t = 0-270 min on separate days in a randomised, double-blind, fashion. Between t = 30-270 min a liquid nutrient (Ensure) was infused intraduodenally at a rate of 1 kcal/min via a naso-enteric feeding catheter. Blood glucose concentrations were measured by glucometer at 15 min intervals. Data are mean±SEM and comparisons are using Student's t test. RESULTS. Prior to the commencement of IV infusions there was no difference in blood glucose between the groups (at t-0 min: GLP-1: 8.1±0.7 mmol/l vs. placebo: 8.8 ±1.1 mmol/ l; P = 0.38). During fasting, GLP-1 had no effect on glycaemia (at t = 30 min: GLP-1: 7.7 ± 0.6 mmol/l vs. placebo: 8.9 ± 1.1 mmol/l; P = 0.18). However, GLP-1 attenuated the overall glycaemic response to the nutrient (AUC 30-270 min : GLP-1: 2,208 ± 158 mmol/l.min vs. placebo: 2,647 ± 247 mmol/l.min; P \ 0.01), as well as the peak blood glucose (GLP-1: 11.1 ± 0.9 mmol/l vs. placebo: 12.5 ± 1.1 mmol/l; P \ 0.04) CONCLUSIONS. Exogenous GLP-1 is effective in reducing the glycaemic excursions that occur with enteral nutrient critically ill patients with pre-existing type 2 diabetes mellitus. These data indicating that further studies using GLP-1, or its analogues, are warranted in this group. 2, 3, 4, 5 , whilst raising concerns regarding an increased risk of hypoglycaemia. 3, 4, 5 . Locally most units adopt a protocol that reflects the practice of the original 2001 study. OBJECTIVES. This study was conceived due to concerns around the safety of tight glycaemic control (TGC). Our objectives were to measure adherence to our local policies and ascertain our true rates of hypoglycaemia. METHODS. This study was designed as a retrospective audit on four critical care units in the Cheshire and Mersey Critical Care Network. Each site used the same audit tool but adapted it to allow for differences in local practice and protocols. Data pertaining to the prescribing and administration of insulin was collected daily over a 1 week period (the time of data collection varied from day to day). The doctors and nursing staff were unaware of the audit and the data was collected by the ward pharmacist who suggested modifications to therapy if it was deemed inappropriate or unsafe. RESULTS. 109 patient days worth of data was collected with 897 blood glucoses checked in this period. 100% of patients receiving insulin had insulin prescribed. Only 23% of blood glucoses were within the target range set by the local protocol. However, of all the results only 3.5% were ''low'' as defined by the local protocol, and only 0.1% (1/897) were hypoglycaemic episodes as defined in the Greet Van Den Berghe paper of 2001 (\2.2 mmol/L). Conversely, 73.5% were above the target range. In the 2 trusts that recorded how many of these levels were[8 mmol/L (a proposed alternative upper limit), the rates were 43 and 46%. In response to a blood glucose the policies suggest dosage adjustments/maintenance. On only 46% of occasions were the adjustments made correct. Insulin infusions appeared to be managed safely by nursing staff. Insulin, if given, was always prescribed and hypoglycaemia (blood glucose \2.2 mmol/L) occurred on only one occasion. Although safe, adustments often didn't follow the protocols and the patients' blood glucose were within the target range only 23% of the time, potentially negating many of the perceived benefits of TGC. Reasons for non-compliance with the protocols was difficult to objectively establish REFERENCE(S). INTRODUCTION. Diabetes mellitus has been associated with an increased risk of adverse outcomes after coronary artery bypass grafting. Hemoglobin A1c is a reliable measure of long-term glucose control. It is unknown whether adequacy of diabetic control, measured by hemoglobin A1c, is a predictor of adverse outcomes after coronary artery bypass grafting. MATERIAL AND METHOD. We evaluated 123 consecutive diabetic patients who underwent primary, elective coronary artery bypass grafting at the Anadolu Medical Center. HbA1c levels of all patients with diabetes mellitus were measured and value of 7% or greater was used as a threshold for uncontrolled hyperglycemia. All the peroperative variables were recorded and then, statistically evaluated. The statistical analysis was realised by t test for parametric variables and Chi-square test for nonparametric variables. RESULTS. There were 305 consecutive patients that underwent elective coronary artery bypass graft surgery between January 2009 and April 2010. Among them, 123 patients had diabetes mellitus and others not. There were no significant differences between groups regarding each adverse outcomes (Table 1) . Although, 13 (68.5%) of total 19 surgical site infection in 305 patients had been seen in 123 diabetic patients, there were also no significant differences between groups regarding the rate of infections (Table 2 ). There was no early postoperative mortality in 123 diabetic patients. Insuline Treatment (IIT) , by implementing a completely nurse driven protocol as in the Leuven I study, to achieve tight glucose control in our 16-bed medical(cardio-)surgical ICU and 6 non-ventilator beds. In the last year, the benefit of IIT and the possible detrimental effects of hypoglycemia on survival have been heavily debated. OBJECTIVES. The goal is to analyze our daily practice in all ICU patients and compare this with the intensive treated groups from the Leuven 1, VISEP en NICE-SUGAR trial. METHODS. We compared mean morning blood glucose levels and the percentage of patients who had a hypoglycaemia, defined as glucose below 2.3 mmol/l, from 2006 to 2009. The frequency of control and the insulin dosage was comparable to the Leuven 1 study. Enteral or parenteral feeding was started at admission. No standard intravenous glucose was used. Glucose was measured with arterial blood samples on the ABL800flex Radiometer as POCT. RESULTS. In our patients, the mean morning blood glucose was higher than in the Leuven 1 study and comparable to the VISEP and Nice-Sugar. The percentage of hypoglycemia on our ICU was lower in comparison with the VISEP and Nice-Sugar. This may be explained by the availability of a POCT on our ICU which allows quick adjustments of the insulin dosage. CONCLUSIONS. Effective TGC with SPRINT resolved organ failure faster, and for a greater percentage of patients who had similar admission and maximum SOFA scores, compared to a matched retrospective conventional control cohort. These morbidity reductions mirror the reduced mortality seen with SPRINT. These results suggest that reduced organ failure, assessed by SOFA, is a fundamental element in reduced mortality when TGC is implemented effectively. INTRODUCTION. Tight glycaemic control was reported to reduce mortality in selected surgical critically ill patients and lowering of blood glucose (BG) levels was recommended as a means of improving patient outcomes (1) . However, this approach has been linked with significant risk of hypoglycaemia. Recently, several studies have confirmed significant associations between variability of BG levels and patient outcomes (2). OBJECTIVES. To evaluate the association between BG variability and hypoglycaemia in a mixed adult ICU. METHODS. Retrospective analysis of the prospectively collected and stored BG measurements over a 1 year period, during which tight glycaemic control was targeted in all patients. Every day we have calculated the BG coefficient variation as expressed by SD/mean BG level. We have divided the patients into Low, Medium and High variability groups (0-15, 16-50 and [50, respectively) . Hypoglycaemia was determined if BG was below 4.4 mmol/L. For statistical analysis Chi-square test and Pearsons correlation test was used. RESULTS. 584 patients were admitted over the 1-year period, providing 2357 daily data points. BG variability was high in 16 daily measurements (0.7%), medium in 570 (24.2%) and low in 1771 (75.1%). Hypoglycaemia occurred in 401 measurement points (17.0%). Hypoglycaemia was observed at all points (100%) when BG variability was high vs. 32.8% when BG variability was medium and 11.2% when BG variability was low and this difference was statistically significant (p = 0.001). We observed a significant correlation between increased BG variability and hypoglycaemia (R = 0.280, p = 0.001). CONCLUSIONS. Increased BG variability as expressed by coefficient variation is associated with hypoglycaemia, when measured daily in a mixed ICU population employing tight glucose control. Decreasing the variability of the BG concentration may be an important dimension of glucose management. If reducing swings in the BG concentration is a major mechanism behind the beneficial effects of glucose control, it may not be necessary to pursue lower glucose levels with the associated risk of hypoglycemia. ). There were two major outliers which may skew the results in favour of the hypothesis. If these two results are removed (Fig. 1 ) the statistical significance remains strong (N v * p \ 0.008; **p = 0.003; ***p = 0.009)). Standard multiple regression analysis found the most useful predictors of T 4 [mid] were 'time with AKI' and 'serum urea' (beta coefficient 0.33 and 0.31 (p \ 0.05) respectively). 4 CrCl, Serum creatinine and urine output did not add further predictive statistical power. CONCLUSIONS. This study demonstrates a reduction in the hepatic metabolism of midazolam associated with AKI. This effect is related most strongly to the length of time the patient has suffered with AKI.  Our results are similar to the NCEPOD report. Even with multiple recommendations by NCEPOD and the National Institute for Clinical Excellence (NICE) 2 recognition of the critically ill remains poor. Detection of organ failure risk is vital to implement preventative strategies. We found a delay in AKI recognition and a lack of risk assessment. Observations, included in admission protocols, were recorded, but investigations outside of these, were often absent. NICE 2 suggest management should be physiologically and not diagnosis based but few patients had a documented physiological plan. We suggest improving under and postgraduate education to increase awareness of AKI. This could occur as an extension to the national, Acute Life-Threatening Events Recognition and Treatment Course. An AKI admission protocol may allow identification of at risk patients and instigate appropriate monitoring, investigation and management. Improved ward based fluid monitoring and management would reduce deterioration. Incorporation of a physiological monitoring plan on the ICU observation chart may reduce preventable AKI. There was no effect in 2 patients with extensive stroke and high severity of a Glasgow score (4-6 points In an observational prospective study, a total of 200 patients who admitted during 6 months in a medical and surgical intensive care unit and didn 0 t have any recent history of renal replacement therapy were included in the study. 66(33%) of all patients was in AKI (acute Kidney Injury) group according to the AKIN (Acute Kidney Injury Network) definition. The mean of age in AKI group was more than Non-AKI (54.5 ± 19.1, 43.9 ± 18.7 respectively; P \ 0.001); and had worse condition according to APACHE II (Acute Physiology and Chronic Health Evaluation II) score (12.3 ± 5.6 vs. 6.9 ± 3.6; P \ 0.001). The AKI patients stayed longer in ICU rather than Non-AKI patients (7.6 ± 7.6 vs. 3.7 ± 2.8 days respectively; P \ 0.001); with more mortality rate (19.7 vs. 1%; P \ 0.001). Also the mechanical ventilation days, time of vasoacive drugs and the use of dobutamin were more in AKI group (P \ 0.001; P = 0.007 and P = 0.007 respectively). The AKI was a significant predictor for mortality using the multivariate logistic regression (OR adj = 14.8; 95%CI: 1.8-121.98); and had the same sensitivity as the APACHE II score in prediction of mortality (Sen. = 0.93). OBJECTIVES. The purpose of this study was to evaluate renal function in children with congenital heart disease (CHD) undergoing cardiac surgery with CPB. We conducted prospective, non randomized observational study at the tertiary care University Children's hospital 12-bed surgical ICU. Study protocol was approved by Hospital Ethics commission. The study included 17 patients with CHD with body weight from 2.8 to 17 kg (Mean 9.41 ± 5.02 kg) and age from 14 days to 4 years (Mean age 20 months). There were 8 patients with ventricular septal defect (VSD), 4 patients had atrioventricular septal defect (AVSD), two had total anomalous pulmonary venous drainage (TAPVD), one had Tetrology of Fallot (TOF), one had transposition of great arteries (TGA), and one had aortic stenosis, requiring Ross operation. Urine was collected in the postoperative period during the first 24 h after surgery for determination of ClCr. The serum creatinine (SCr) level was determined by Jaffé 0 s method (Cobas 6000 analyzer, Roche). Harrison AM et al. [1] shows that estimated creatinine clearence (ClCr) using Schwartz formula does not accurately predict ClCr. Therefore we used standard formula for ClCr calculations. Urine output, inotrope score, duration of aortic cross clamping and cardiopulmonary bypass was recorded. We applied RIFLE criteria to assess renal functions, using ClCr as a variable reflecting glomerular filtration rate (GFR). OBJECTIVES. Evaluate whether a real-time alert of worsening of RIFLE class, through the physicians' DECT telephone system, would affect therapeutic interventions for AKI and progression of RIFLE class. Single centre, prospective intervention study during a 6-month period in our 36bed surgical and medical ICU. Three study phases were compared: a 1.5-month control phase (CON1) where physicians were blinded for the electronic alerts, a 3-month intervention phase where electronic alerts of worsening RIFLE class were made available to the physicians through the DECT telephone system (INT), followed by a second 1.5 month control period (CON2). PASW Statistics 18 was used for statistical analysis and a double sided P value of \0.05 was considered as significant. At study entry, before and after to receive antioxidant or placebo concentration the blood was drawn, to posterior determination of thiobarbituric acid reactive species (TBARS), protein carbonyls, total nitrite concentration and IL-6. RESULTS. The use of NAC+DFX decreases oxidative damage parameters. Patients at antioxidant arm have, despite not reaching statistical significance, a decrease on plasma IL-6 levels 24 h after the start of treatment. As observed to oxidative damage parameters, IL-6 returned to the placebo levels after the end of antioxidant administration. The nitrite levels increased 24 h after NAC+DFX, returning to placebo levels 48 and 72 h. The incidence of ARF using the RIFLE criteria was not significantly different in the two arms, and this was also true to a number of secondary end points, none of which showed significant differences between the treatment arms. Analyzing the subgroups of the SOFA score we observed at day 2 a worse cardiovascular SOFA in the NAC+DFX arm (3.5 ± 1.1 vs. 1.6 ± 1.9, p = 0.01) and a better renal SOFA in antioxidant treated patients (0.57 ± 1.0 vs. 1.6 ± 1.2, p = 0.02). CONCLUSIONS. We demonstrated that NAC + DFX administration was able to decrease plasma markers of oxidative damage and to a minor extend IL-6 plasma levels. We believe that the use of antioxidants could be an alternative adjuvant therapy to prevent ARF in critical ill patients with hypothension. Table 1 were found to be independent risk factors for postoperative AKI: OBJECTIVES. We aimed to access prospectively whether the use of antioxindants has beneficial effects in renal function of critical-ill patients undergoing imaging studies with intravenous radio-opaque agents (IVCA). Patients were recruited from those hospitalized in a tertiary intensive care unit between 2009 and 2010. Inclusion criteria were: a) requirement for imaging studies with IVCA b) no use of renal replacement therapy. Patients were randomized to receive before and after imaging, either antioxidants (N-acetyl-cysteine 1,200 mg and ascorbic acid 2 g and 200 ml NS0.9%) (SG) or 200 cc NS0.9% (CG). Renal function was assessed by serum levels of creatinine and cystatin C assessed before and at 24, 48 h following administration of IVCA. Patients were followed until discharge. Systatin C was measured by Elisa. CONCLUSIONS. The results of this study suggest that the use of preventive antioxidant therapy may protect critical-ill patients from contrast-induced nephropathy. Our preliminary results have to be confirmed in larger cohorts. Acute coronary occlusion is the leading cause of cardiac arrest. Because of limited data, the indications and timing of coronary angiography and angioplasty in survivors of out of hospital cardiac arrest are controversial. OBJECTIVES. Using data from the Parisian Region Out of hospital Cardiac ArresT (PROCAT) prospective registry, we performed an analysis to assess the impact of an invasive strategy on hospital survival. Between January 2003 and December 2008, 714 survivors of out of hospital cardiac arrest were referred to a tertiary center in Paris, France. In 435 survivors with no obvious extra-cardiac cause of arrest, an immediate coronary angiogram followed if indicated by coronary angioplasty was performed at admission. The prognostic value of pre-hospital and in-hospital characteristics on in-hospital mortality was evaluated using logistic regression analysis. RESULTS. At least one significant coronary artery lesion was found in 304 (70%) Therapeutic hypothermia has been shown to improve survival and neurological outcome in patients who have suffered out-of-hospital cardiac arrest and in whom the initial rhythm was ventricular fibrillation (VF) [1, 2] . International guidelines now recommend the use of therapeutic hypothermia as part of post-resuscitation care in patients fulfilling the above criteria [3] . OBJECTIVES. We surveyed current practice regarding the use of therapeutic hypothermia for post resuscitation care in Northern Ireland (NI) intensive care units. A questionnaire was devised, reviewed and agreed by each author prior to posting to the lead clinician in each of Northern Ireland's 10 adult intensive care units. A 100% response rate was obtained. We asked about the existence of a protocol for cooling, which patients were cooled, duration of cooling, by what particular method(s) cooling was achieved and how temperature was monitored during cooling. RESULTS. 8 out of 10 (80%) adult ICUs in NI institute therapeutic hypothermia routinely as part of their post-resuscitation care. Only 2 out of the 8 units (25%) have a protocol for institution and maintenance of hypothermia. All units that utilise hypothermia do so regardless of the initial cardiac rhythm. 5 out of 8 (62.5%) ICUs target a temperature of 32-34°C with 3 out of 8 (37.5%) targeting a temperature of 34-36°C. All units utilise surface cooling methods with 2 out of 8 (25%) also using cold intravenous fluids occasionally. 6 out of 8 (75%) units cool for 12-24 h, 1 (12.5%) unit 12-48 h and 1 unit 24-36 h. All units use more than one method of temperature monitoring during cooling. All units sedate patients during cooling and 5 out of 8 (62.5%) also routinely curarise patients during cooling. The 2 units that do not currently use therapeutic hypothermia cited lack of resources/funding as the main obstacle to adopting this evidence based practice. CONCLUSIONS. The practice of therapeutic hypothermia post cardiac arrest has been embraced by the majority of ICUs in NI. There appears however to be variation in the target temperature and duration of hypothermia once instituted. ICUs that cool patients appear to do so regardless of initial cardiac rhythm. Regional protocolisation of this therapeutic modality may help standardise practice across NI ICUs. REFERENCE(S We compared our data with those from 2008 retrospective audit [3] . The method of TH was via surface cooling technique together with cold intravenous saline infusion but not IVCD. Total 73 patients presented with cardiac arrest: 31 underwent TH (22 OOH VF/VT and 9 OOH non-VF/VT). In 2009, there was an overall improvement in adherence to the audit standards, as shown in Table 1 : Table 2:   TABLE 2 Hospital survival rate of TH % GCS 15 of the survivors at ICU discharge 2008 12/31 (39%) 7/12 (58%) 2009 12/28 (43%) 11/12 (92%) CONCLUSIONS. Introduction of IVCD has led to an improved compliance with local and ILCOR TH guidelines. Although the total numbers are small, there has been an increase in the patients discharged with GCS 15 from our ICU using IVCD. There are areas that require further improvement, notably the time to reach target temperature and prevention of rebound hyperthermia. Work continues on protocolised evaluation of neurologically damaged survivors. 23rd ESICM ANNUAL CONGRESS -BARCELONA, SPAIN -9-13 OCTOBER 2010 S177 0369   TARGET TEMPERATURE MANAGEMENT AFTER OUT-OF-HOSPITAL CAR-DIAC ARREST, AN INTERNATIONAL, MULTI-CENTRE, RANDOMISED,  PARALLEL GROUPS, ASSESSOR BLINDED CLINICAL TRIAL-RATIONALE  AND DESIGN OF THE TTM-TRIAL N. Nielsen 1,2 , and the TTM-trial study group 1 Helsingborg Hospital, Department of anesthesia and intensive care medicine, Helsingborg, Sweden, 2 Lund University, Department of clinical sciences, section of anesthesia and intensive care medicine, Lund, Sweden INTRODUCTION. Experimental studies and previous clinical trials suggest an improvement in mortality and neurological function with induced hypothermia after out-of-hospital cardiac arrest (OHCA). Previous trials have included highly selected populations and the optimal target temperature is not known. OBJECTIVES. To evaluate differences in efficacy and safety with target temperature management at 33 and 36°C for 24 h after OHCA of presumed cardiac cause. METHODS. Intervention: Patients will be managed with 24 h of temperature control at 33 versus 36°C according to randomisation. Temperature control will be delivered with temperature management equipment at the discretion of the trial sites. To facilitate cooling, when applicable, and to stabilise the circulation all patients will be treated with 30 ml/kg of crystalloid infusion (4°C or room temperature according to treatment arm). DESIGN. Randomised trial with 1:1 concealed allocation of 850 OHCA patients to temperature control for 24 h at 33 versus 36°C with blinded outcome assessment. Sample size is based on a relative risk reduction of 20% with a risk of type-1 error of 5% and a power of 90% with a 5% loss to follow-up. CONCLUSION. This study demonstrated that health care professionals, despite guidelines, are hyperventilating simulated cardiac arrests patients. Suboptimal ventilation was a problem across all the backgrounds investigated; although doctors performed best here, they were still found to be hyperventilating to an unacceptable level. Hyperventilation has a number of deleterious physiological effects and is associated with poor outcomes. Increased training, awareness and recertification may be the answer, and certainly improves short term compliance with guidelines. However, these effects may be short lived and other changes may be needed. A reasonable course of action may be the use of paediatric (1L) self inflating reservoir bags as a first line device. This simple measure may ensure delivery of more guideline consistent ventilation, independent of the level of experience.  Extracorporeal life support (ECLS) has been proposed as the ultimate heroic rescue measure in prolonged cardiac arrest unresponsive to conventional cardiopulmonary resuscitation. ECLS effectiveness in out-of-hospital cardiac arrest remains to be addressed. Decision to discontinue CPR due to medical futility is based upon presumed prolonged anoxia, with existing guidelines for termination. However, even when ECLS is implemented, failure to maintain stable hemodynamic conditions due to marked capillary leak frequently results in patient's death. To evaluate the usefulness of routine laboratory parameters in the decision to treat refractory cardiac arrest patients with ECLS . METHODS. Sixty-six adults with witnessed cardiac arrest of cardiac origin unrelated to poisoning or hypothermia undergoing cardiopulmonary resuscitation without return of spontaneous circulation (duration: 155 min [120-180], median, [25-75%-percentiles]) were included in a prospective cohort-study. ECLS was implanted under cardiac massage, using a centrifugal pump connected to a hollow-fiber membrane-oxygenator, aiming to maintain ECLS flow C2.5 l/min and mean arterial pressure C60 mmHg. INTRODUCTION. Due to the human lifespan increasing, people are living longer. Cardiac arrest (CA) in old people could be seen as a natural end of life process and cardio-pulmonary resuscitation (CPR) in this setting as a disturbance. Therefore, the question of prognosis in patients has been raised when performing CPR in the elderly. Data from the 1980s found 6month mortality in 94% of patients over 80 suggesting that CPR in elderly people could be futile (1) . The recent progresses in the management of resuscitated patients, such as mild hypothermia, were not evaluated in patients older than 75 years (2, 3) . In a recent study, we found that age [60 years was an independent pejorative prognostic factor (4) . Hence there is virtually no data of prognosis factor of elderly patients after CA. Our aim was to determine the prognosis factors in patients older than 75 years successfully resuscitated. METHODS. All patients admitted to ICU for CA with successful ROSC were consecutively included between 2000 and 2009. CA data were prospectively entered in a registry according to Utstein recommendations. Patients were managed following standardized procedures. Good prognosis was defined as CPC 1 or 2 at ICU discharge. Factor associated with a good outcome were identified using multivariate analysis. RESULTS. Among 1,210 patients admitted for CA, 225 were older than 75 years. Median age was 79.5 years (75-97), CA was from cardiac origin in 50% of patients and 57.3% had a VT/VF initial rhythm. Mean no flow (NF) and low flow (LF) were 4.5 (±6.5) and 16.3 min (±13.4). Mean blood lactate and creatinine level at admission were 6.5 mmol/L (±4.3) and 132 lmol/L (±49). 47.5% of patients presented post-resuscitation shock (PRS) and 67.5% were treated with hypothermia. CONCLUSIONS. CA in elderly patients is associated with an in-ICU 25% good outcome rate. This should promote the CPR in non-severely disable elderly patients with CA regardless of their age. We plan to collect the 6-month mortality and the functional status of survivors. INTRODUCTION. Post-resuscitation phase is often characterized by a ''sepsis-like'' syndrome, which may be associated with the development of organ dysfunction. Microcirculatory abnormalities play a key role in sepsis-related organ failure; however no data are available on microvascular function after cardiac arrest (CA). OBJECTIVES. The aim of this study was to investigate peripheral microcirculation during and after therapeutic hypothermia (TH) in CA patients. METHODS. This prospective, observational study included 10 patients treated by TH after CA. Sublingual microcirculation was evaluated using Sidestream Dark-Field (SDF, Microscan, The Netherlands) videomicroscopy at hypothermia and normothermia in all patients. At least 5 images of 20 s each from separate areas were recorded at each time point and stored under a random number to be analyzed, using a semi-quantitative method, by an investigator blinded to time and condition. Thenar oxygen saturation (StO 2 ) was measured using a tissue spectrometer (InSpectra 650; Hutchinson, USA). A vaso-occlusive test was performed at hypothermia and normothermia by rapid inflation of a pneumatic cuff around the arm to evaluate StO 2 reperfusion rate, reflecting microvascular reactivity. RESULTS. Compared to hypothermia, measurements at normothermia showed a significant increase in functional capillary density (FCD) from 7.2 ± 1.9 to 10.1 ± 1.4 n/mm (p = 0.002), the proportion of small perfused vessels (PPV) from 76 ± 13 to 92 ± 3% (p = 0.006) and mean flow index (MFI) from 2.1 ± 0.5 to 2.8 ± 0.2 (p = 0.01). FCD and PPV values were significantly correlated with body temperature. StO 2 reperfusion rate was largely decreased when compared to healthy volunteers, but it did not change over the study period (from 0.94 ± 0.38 to 1.13 ± 0.54%/sec) and showed large inter-individual variability. The same was found for StO 2 (from 78 ± 9 to 82 ± 8%). CONCLUSIONS. Mild hypothermia is associated with decreased FCD and PPV in the sublingual area when compared to normothermia. Microvascular reactivity is decreased but changes are unpredictable. INTRODUCTION. Acute posthypoxic myoclonus (PHM) occurs in deeply comatose patients, soon after a hypoxic episode. It is characterized by generalized, severe body jerks with violent flexor movements, but more focal myoclonus is reported too (1) . Acute PHM and status myoclonus are considered to have a poor prognostic outcome (1, 2) . Although the cerebral cortex is known to be the most common origin of myoclonus in ambulant patients (3) , the origin of acute PHM is uncertain (2) . To determine whether acute PHM originates from damage in cortical or subcortical structures. For this study patients with myoclonus in the first 72 h after admission were selected from the PROPAC II study, a prospective cohort study including patients admitted after CPR and treated with hypothermia. Exclusion criteria: pre-existing disease with life expectancy\6 months and severely disability before CPR. Baseline characteristics were used from the main database. Additional data of EEG and SSEP recordings made after rewarming were collected. EEGs were evaluated for presence of epileptic activity, status epilepticus, generalized periodic discharges, burst suppression pattern, iso-electric or low voltage amplitudes and reactivity of the background pattern. Data collected from SSEPs: N20 potential, giant potential (defined as a potential five times the size of a normal potential) and P27/N35 amplitudes (done by JHK). The Glasgow Outcome Scale (GOS) was used to assess outcome after 6 months, poor outcome was defined as a GOS of 1-3 (death, vegetative state, severe disability), good outcome as a GOS of 4-5 (moderate disability, good recovery). . From a total of 391 patients included in the PROPACII study, 68 (17%) patients developed myoclonus. Baseline characteristics of this group: age 67, 79% male, time to ROSC 20 min, primary cardiac arrest in 61 patients, hypoxic arrest in 7. SSEP recordings were available from 45 patients. N20 potentials were present bilaterally in 39% (23) and giant potentials were seen in 9% (2) of the patients with a present N20 potential. 32 EEGs were made, epileptic activity was seen in 34% (11) and a status epilepticus in 22% (7), thus 44% of the EEGs did not show any type of epileptic activity. Good outcome was seen in 10% of the patients, poor outcome in 90%. Mortality was 88%. CONCLUSIONS. The results of this study show that acute PHM is found in 17% of patients admitted after CPR and treated with hypothermia. It did not necessarily lead to a poor outcome, but we did not have information about the type of myoclonus. The available data seem to support the idea that the myoclonus originates mainly from subcortical structures, given the low number of patients with EEGs showing epileptiform activity and SSEPs with giant potentials, which can be seen in cortical myoclonus (3). INTRODUCTION. The International Liaison Committee on Resuscitation, the American Heart Association and the European Resuscitation Council recommend that mild therapeutic hypothermia improve neurological outcome in unconscious adult patients with return of spontaneous circulation (ROSC) after out-of-hospital cardiac arrest (OHCA) due to ventricular fibrillation (VF) or ventricular tachycardia (VT). In our Intensive Care Unit (ICU) we use mild hypothermia in all patients following CPR with successful ROSC regardless of initial rhythm. In this study we compared the effect of mild therapeutic hypothermia at neurological outcome and mortality between the patients who had OHCA due to VF or VT and them who had OHCA due to a different initial cardiac rhythm as asystole or pulseless electrical activity. The study protocol was approved by the local ethics committee on human research. A total of 23 patients were admitted to our ICU with ROSC after OHCA between May 2008 and December 2009. Therapeutic hypothermia was initiated after admission in ICU by intravenous infusion of cold saline (4°C 1,000 ml bolus) followed by intravenous cooling device (CoolLine Catheter, CoolGard Alsius Corporation Irvine, CA, USA). The target temperature was 34°C maintained for 48 h followed by slow active re-warming over a minimum period of 24 h (0.1°C per hour). Intravenous anesthesia was induced in all patients by a combination of propofol and remifentanyl with dose adjustment as needed. To prevent shivering, patients received muscle relaxation by iv administration of sisatracurium every 2 h. The primary end point was the neurological outcome at 6 months according to the Pittsburgh cerebral performance category (CPC). Secondary end point was mortality at 6 months. Prehostital cooling procedures were not applied. Nine of the 14 patients (64%) of the group of the patients who had OHCA due to VF or VT had favourable neurological outcome CPC 1 or 2 as compared with 3 of 9 (33%) of the group of the patients who had OHCA due to a different initial cardiac rhythm. Mortality at 6 months was 14% (2 of 14 patients died) in the group of the patients who had OHCA due to VF or VT as compared with 55% (5 of 9 patients died) in the group of the patients who had OHCA due to a different initial cardiac rhythm. In patients who had OHCA due to VF or VT mild therapeutic hypothermia inproves the neurological outcome and reduces mortality as compared with the patients who had OHCA due to a different initial cardiac rhythm. OBJECTIVES. We aimed to compare therapeutic hypothermia using either surface or endovascular techniques in terms of efficacy, complications and outcome at our institution, a 30 bedded tertiary referral ICU. A local research ethics committee reviewed the proposed study and waived the need for a full ethics submission, as the study met the national criteria for service evaluation. Data were collected from 83 patients undergoing therapeutic hypothermia following cardiac arrest over a 2.5 year period by retrospective casenote review and interrrogation of the Carevue (Phillips UK) database. Therapeutic hypothermia was initiated in the ICU using iced Hartmann's solution, followed by either surface (n = 41) or endovascular (n = 42) cooling; choice of technique was based upon endovascular device availability. The target temperature was 32-34°C for 12 to 24 h, followed by rewarming at a rate of 0.25 deg h -1 . The mean age was 61 ± 16 years; 88% of arrests occurred out of hospital, and 64% were ventricular fibrillation/tachycardia. Endovascular cooling provided a longer time within the target temperature range (p = 0.02), less temperature fluctuation (p = 0.003), better control during rewarming (0.04), and a lower 48-h temperature load (p = 0.008). Endovascular cooling also produced less cooling-associated complications in terms of both overcooling (p = 0.05) and failure to reach the target temperature (p = 0.04). After adjustment for known confounders, there were no differences in outcome between the groups in terms of ICU or hospital mortality, ventilator free days and neurological outcome. CONCLUSIONS. Endovascular cooling provides better temperature management than surface cooling, as well as a more favorable complication profile. The equivalence in outcome suggested by this small study requires confirmation in a randomized trial. INTRODUCTION. Ventricular assist devices (VADs) are successfully used in patients with end stage heart failure, usually as a bridge to transplantation or recovery, but increasingly as destination therapy as well. A major threat for patients with a VAD is the frequent occurrence of, mainly thromboembolic, stroke, with a reported incidence of up to 50%. Manufacture guidelines for anticoagulation therapy are based on relatively small observational studies and common sense rather than evidence, and as a consequence anticoagulation protocols vary widely between centers. OBJECTIVES. The aim of this systematic review was to provide more evidence in order to determine the optimal anticoagulation protocol to prevent stroke in patients supported with a VAD. A systematic search in Pubmed and Embase was performed in which we included all types of VADs. All types of anticoagulation drugs applied to prevent thromboembolism were included and divided in three categories; heparin, coumarins and antiplatelets. We included references with a full text available, written in English, Dutch, German or French, and which described patients with a stroke or TIA. Our primary outcome measure was defined as the onset of any type of stroke. Two authors evaluated independently the results of this search; doubtful references were evaluated by two other authors. After critical appraisal 50 articles were selected as relevant, which include 29 cohort studies, 6 case-control studies and 15 trials, totaling 3194 patients with VAD support between 1982 and 2008. The mean age was 50 years (range 7-79) and the mean duration of support was 116 days (0-1309). Stroke occurred in 0-50% patients supported by VAD, with an incidence of 0-23/patient-year. The majority of strokes occurred within the first year. Six types of anticoagulation protocols were used that combines drugs from one or all three categories. Most protocols used a combination of all 3 categories (1,162 patients with a total follow up of 115,082 days) and had an average stroke incidence of 1.28 events/patient-years. The lowest average stroke incidence was reported in studies that used only antiplatelets (0.62 events/patient-years) and the highest in which only heparin was used (22 events/patientyears). We could not detect a decreased risk for stroke in patients with VAD support when coumarines or heparin were used instead of or in addition to antiplatelets. Antiplatelets should be part of an anticoagulation protocol to prevent stroke in patients supported by VAD. A.M. de la Torre 1 , C. Marco 1 , D.J. Palacios 1 , A. Pedrosa 1 , I. Lopez de Toro 1 , V.A. Hortigüela 1 1 Hospital Virgen de la Salud, Toledo, Spain OBJECTIVES. To analyze the difference between two groups of patients with ICH considering severity, treatment, evolution and mortality. METHODS. Description retrospective study of admitted patients between 1st of January of 1999 to 31st of December 2001 and 1st of January of 2007 to 31st of December 2009 in the ICU of Virgen de la Salud Hospital (Toledo) with the diagnosis of ICH. There are 85 patients in the group of 99-01 and 124 patients in the groups of 07-09 without any difference of age. Regarding comorbidity between the two groups no differences can be found regarding the previous presence of HTA, but regarding diabetes and dislipemy, we do find a higher prevalence on the second group (11.8 vs. 23.4%, p \ 0.05 and 8.2 vs. 24.2%, p \ 0.01 respectively). Reviewing the presence of anticoagulated patients, no differences of significance can be found, but a trend (14.1 vs. 23.4%, p \ 0.1). Regarding the location of the hemorrhage, the most frequent is the basal ganglia (31.8 vs. 25%), existing no differences amongst the two groups. We don't find differences either in the presence of a intraventricular component, whether it is neither supratentorial nor infratentorial. There are differences between the ICH score of both groups with p \ 0.05: with a score of 0 (9.5 vs. CONCLUSIONS. An increase in the comorbidity can be observed in the included patients, which can be due to a better screening of these pathologies. We also find that the ICH score is higher than in the 07-09 sample, which is attributed to the admittance in the ICU of patients with the ultimate goal of organ donations. In the evolution, it can only be observed a longer stay in patients from the second sample, likely because they are more serious patients with a higher ICH score. The analysis of the two groups has not been conclusive when it comes to assessing the improvements that might have come out in these last years, although it is necessary a deeper analysis of the data. INTRODUCTION. Sodium dysbalances are frequent medical complications in patients with subarachnoid hemorrhage (SAH). Hyponatremia is more frequent but it is associated with better outcome than hypernatremia. The aim of this study was to observe differences in outcome between hyponatremic and hypernatremic patients with SAH. We performed the prospective 5 years study in incidence of hyponatremia (serum sodium \135 mmol/l) and hypernatremia (serum sodium [150 mmol/l) in 211 patients (pts) with SAH. We compared the incidence of cerebral complications, Glasgow Outcome Scale (GOS) upon discharge from the neurointensive care unit (NICU) and in mortality NICU. RESULTS. There were 82 (39%) pts with dysnatremia, more patients had hyponatremia (46, 22%), less hypernatremia (36, 17%). Between these groups there were no diferences in stay in NICU (p = 0.197), duration of dysnatremia (p = 0.055), fluid intake (p = 0.155, ml/day), daily sodium intake (p = 0.440, mmol/day) and fluid output (p = 0.055, ml/day). Hyponatremia was more frequent on admission (p \ 0.001) and connected with higher diuresis (p \ 0.001). Hypernatremic pts received more antiedematic therapy (p \ 0.001). Hypernatremia was arised in pts with significantly lower Glasgow Coma Scale (p = 0.001). These pts had more cerebral complications (p = 0.018), worse Glasgow Outcome Scale upon discharge from NICU (p \ 0.001) and higher mortality in the NICU (p = 0.002). CONCLUSION. Dysnatremia is frequent in patients with SAH (39%). Hyponatremia occurs more often, but hypernatremia is connected with worse outcome. OBJECTIVES. To analyze clinical, epidemiologic and outcome differences and to identify predictor factors of mortality at discharge from ICU of patients admitted after craneoencephalic trauma (CET) according to Glasgow Coma Scale (GCS) score. Observational prospective study of patients admitted in the Intensive Care Unit (ICU) after CET. We classified the traumatic brain injury, according to GCS score of B8 or C9 points groups. We analyzed clinical and demographic data during ICU stay, as well as physiological, functional and emotional data measured with PAECC scale (Project for the Epidemiological Analysis of Critical Patients) at discharge from ICU. Qualitative variables are expressed as a percentage and quantitative variables as mean and standard deviation. We used Chi 2 test, t-Student and multivariate analysis as required with a maximum alpha error of 5%. We analyzed 447 patients, 81.2% male. At admission 67.3% had GCS B 8. Traffic accidents (45.2% in GCS C 9 and 58.5% in GCS B 8) were the most frequent cause of CET. There was a higher rate of out hospital hypotension in the GCS B 8 group (p = 0.002, OR 6.01, 95% CI 1.7-20.1). Cranial computed tomography (CT) scan findings in the GCS C 9 group were diffuse injury I and II (58.9%) after Marshall classification versus 28.6% in the GCS B 8 group (p = 0.0001). Fewer complications were detected in patients in the GCS C 9 vs. GCS B 8 group (36.3 vs. 66 .8%, p = 0.0001, OR 0.82, 95% CI 0.047-0.14). ICU mortality rate was significantly lower in the GCS C 9 group than in the GCS B 8 group (10.3 vs. 36.2, p \ 0.01). Predictors of mortality were GCS at admission (p = 0.05), CT findings type III, IV and V (p = 0.014, 0.001 and 0.028 respectively), complications (p = 0.001), tracheotomy (p = 0.025), days on ventilator (p = 0.001), APACHE II (p = 0.001) and the length of ICU stay (p = 0.001). Best overall score in PAECC questionnaire at discharge from ICU was better in the GCS C 9 vs. GCS B group. (26.5 ± 5.8 vs. 19 .22 ± 7.7, p = 0.0001). CONCLUSIONS. Patients with lower GCS at admission presented higher rate of prehospital hypotension, more severe CT findings, more complications at ICU, worse physiologic, functional and emotional outcome, and higher rate of mortality, than patients with GCS C 9. Factors associated with increased mortality were coma level, type of findings in CT, complications, prolonged mechanical ventilation, length of ICU stay, APACHE II, and the need for a tracheotomy. OBJECTIVES. The aim of our study was to estimate the influence of HyperHAES infusion on haemodynamic regulation. We examined 25 patients with severe brain trauma (GCS score \8, sedation, artificial ventilation). The BP, stroke volume (SV) and their variability (BPV, SVV) were determined by the bioimpedance method. Additionally we determined the peripheral pulse (PP) and its variability (PPV) using plethysmography curve registration. Special attention were paid to the P3 (0.1-0.15 Hz) and P4 (0.2-0.5 Hz) bands of BPV, SVV and PPV, connected with volume state, breathing, and autonomic regulation, especially baroregulation. All the comparisons were made before and after 10 min. of the infusion of HyperHAES (250 ml). All patients had the autonomic dysfunction: the waves of baroregulation (P3) had low power compared with healthy. Hypovolemia was moderate: SV (50 ± 4.5) and PP (22 ± 2.6) were slightly decreased, but BP were 135 ± 5.2 mmHg. The BP increasing was registered as the first reaction on the infusion of HyperHAES (151 ± 4.1 mmHg). The same time PP increased more then twice and became 54 ± 3.3, and P4 of PPV decreased from 30 ± 2.8 to 19 ± 3.9, that reflected the improving of the volume state. Although SV did not rise significantly, the increasing of P3 were estimated in SVV, as a marker of the baroregulation restoration. CONCLUSIONS. The infusion of HyperHAES in severe brain trauma not only decrease the range of hypovolemia, but restore the baroregulation as a significant part of autonomic regulation, needed for cerebral perfusion support. INTRODUCTION. Continuous measurement of intracranial pressure (ICP) using intraparenchymal sensors has become part of the standard management of patients at risk of developing intracranial hypertension. Whilst reliability has been explored previously little is published on the accuracy of depth to which the sensor is placed. A difference in sensor location has been shown to affect the reliability of ICP readings and could impact negatively on patient management (1). To determine whether ICP sensors (Codman, J&J) placed by Neurosurgical staff were within the optimum depth of 2 cm from the cortex. METHODS. 50 consecutive patients were identified from a prospectively collected Neuro ICU database who had had a CT of the head (CTH) performed whilst an ICP sensor was in situ during 2009. The depth of the sensor tip on CTH was measured and patients were stratified according to whether they had surgery or no surgery to determine any differences between open and percutaneous placement. Of the 50 ICP sensors 36 (72%) were placed deeper than 2 cm. The greatest incidence of deep placement was in surgical patients 26/33 (79%) and in craniotomy patients 71% of these were deeper than 3 cm CONCLUSIONS. This investigation has shown that the majority of patients admitted to our NeuroICU have less than optimally placed ICP sensors. Inappropriately deep sensors appear more common in surgical patients, particularly following craniotomy. The impact of this on patient outcome is unknown and would require further study. This study has highlighted we need to implement new methods to improve the accuracy of our ICP sensor placement. Graduated marks on the sensor sheath during manufacture may assist accurate placement. CONCLUSIONS. If ICP is largely used, it remains below 50%. 40% of the cases have been monitored with at least 3 techniques suggesting an acceptance tendency for a multimodal monitoring. Among these techniques, the control of PCO 2 seemed considered important as the use of TCD to assess perfusion and vessel tone. On-going analysis of these data will provide information on the therapeutic strategy performed and the impact on outcome. INTRODUCTION. Raised intracranial pressure (RICP) can be evaluated sonographically by measuring the optic nerve sheath diameter (ONSD). A wide variation in the threshold measurement of ONSD for RICP has been reported in literature. It is likely that exaggeration of the hypoechoic edge artifact around the dura by high frequency ([10 MHz) linear transducers and uncertainty over whether to measure 3-mm behind the papilla or behind the globe (posterior margin of sclera) could have resulted in such differences. To determine the optimal site of measurement of ONSD by correlating it with RICP determined clinico-radiologically. We also evaluated if different sonographic appearances of the ONSD could be used qualitatively to determine the presence or absence of RICP. METHODS. Initially, in order to precisely delineate the anatomical dura sonographically and assess optimal cursor placement, 2 cadaver orbital preparations were studied before and after subarachnoid fluid insufflation. 60 scans were then done by a single sonographer using a 13-6 MHz linear transducer on 8 healthy volunteers and 46 patients admitted to the medical/ neurosurgical intensive care units. ONSD was measured at 2 locations; 3-mm behind the papillae and 3-mm behind the globe. In each location 1 measurement was made within the anatomical dura and another between the echogenic margins of retrobulbar fat as described in literature. Four patterns (Fig. 1 ) of the nerve sheath were identified based on the appearance of the CSF space and edge artifact. RICP was diagnosed by clinically correlated computed tomography of the brain. An independent 2 sample t test was done to correlate measurements with RICP. Classification of Optic nerve sheath appearances RESULTS. 14/60 (23%) scans were done on patients with RICP. All 4 measurements independently correlated with RICP (P \ 0.02); albeit cut-offs differed substantially ( Table 1) . The presence of a Type 3 pattern (Fig.) in both eyes strongly suggested RICP (100% positive predictive value) whilst its absence in both eyes ruled out RICP (89% negative predictive value). METHODS. Three years after the introduction of the concept of BS in our ICU, a questionnaire was sent to 40 people directly involved in the nursing of critically ill patients to study the current practice during the previous month. Responses were received from 26 persons, a 65% response rate. 25 (96%) persons had practiced BS. Only 10 (38%) employees used calming bath and 5 (19%) an invigorating bath. Guided oral care and guided suction was performed respectively by 18 (69%) and 10 (38%) nursing persons. Orientative positioning was used by 12 (46%) nurses. Everybody is very satisfied with the instruction manual which can be found in each room. 14 (54%) persons estimated to be well informed about BS. Others wanted more practice course and training at the bedside. CONCLUSION. Pattern suggested an increasing interest in BS since its introduction. Initial touch is well implemented. More effort is needed for continuous education and training. INTRODUCTION. Admittance to hospital for surgical treatment, is often linked with insecurity and anxiety for many patients. To most patients, the postoperative care unit constitutes an unknown environment, and can represent a frightening experience. Research has shown that preoperative information leads to subjective outcome as anxiety reduction, and objective outcome as shorter hospital stay and less intake of pain medication. Few studies, however, have addressed patients' experiences with preoperative information about the early postoperative phase. OBJECTIVES. The purpose of this study was to describe patients' experiences with preoperative information about events they may experience during their stay in the postoperative unit. Patients' experiences may contribute to increased knowledge about this topic. The study design was exploratory-descriptive, and a semi-structured interview based on thematic guide was used. Nine patients met the inclusion criteria, and they had an average age of 65 years. They were admitted to elective surgery for cancer and their stay in the postoperative unit varied from 1 to 3.5 days. The interviews were conducted 5-11 days after surgery and transcribed verbatim. The data material was subjected to qualitative content analysis. RESULTS. Experience with information before surgery and in the early postoperative phase, was categorized into four themes: being prepared before surgery, reactions to differing experience, discomfort and pain, management of some self-care activities and experiences with the environment of the postoperative unit. CONCLUSIONS. The patients received a fair amount of information before surgery, but only limited information concerning what to expect while in the postoperative unit. The patients' information needs differed and patients with former experience with surgery were more prepared for what to expect. The patients got mainly verbal information and most of this was given the day before surgery. O.M. Peters-Polman 1 , M. van Roosmalen 2 , J.E. Tulleken 3 , J.G. Zijlstra 3 1 UMC Groningen, Intensive Care, Groningen, Netherlands, 2 ARUP Nederland, Amsterdam, Netherlands, 3 UMC Groningen, Groningen, Netherlands BACKGROUND. WHO guidelines concerning sound levels in hospitals requires a maximum of 35 dB in daytime, a nighttime sound level below 30 dB to allow good sleep quality and peak levels that do not exceed 40 dB at all times. In an ICU environment, apart from being critically ill, patients are exposed to typical ICU environmental noise. Sleeping cycles disturbed by illness are further disrupted by care providers performing procedures and taking vital signs and alarms with delirium as a common result. We describe the acoustic environment in our mixed ICU. We conducted an observational study in which we continuously measured the sound level (dB), frequency and repetition of sound in our ICU. We used a SPLnet microphone and noise monitoring system which was placed, after informed consent, at the ear level of the patient. RESULTS. Noise sources are numerous and consist of human voices, doors slamming, pagers, telephones, shoes and equipment alarms. There is a round the clock continuous background noise of 45-68 dB, staff conversation with levels of 70-75 dB and peak levels up to 90-110 dB, mainly due to alarms. These levels of sound are comparable to loud conversation at 1 meter distance (45-68 dB), walking along a motorway (70-90 dB) or standing next to a roaring engine (110 dB). CONCLUSION. WHO guidelines clearly state maximum sound levels of 35 dB in daytime, 30 dB at night and peak levels of 40 dB. The sound level in our unit is exceptionally and unacceptably high throughout day and night and requires a behavioral intervention. Further research on the influence of these noise levels on our patients is necessary. OBJECTIVES. This study has been achieved in order to realize the comparison of efficiency of manual and mechanical compression techniques used for the maintenance of haemostasis after femoral sheath removal. METHODS. This study was planned and applied as a randomized controlled trial. The study was executed at a military education and research hospital in Turkey between January and March 2010. Data collecting form was prepared by the investigators after the literature examination. The form consists of 21 questions which are evaluating the demographic data of patients, the compression time, the pain level (before sheath removal, during the manual/ mechanical compression and after the sheath removal), the complications occurring in femoral zone, the mobilization/discharge period and the problems (bruise, oedema, hemorrhage and etc.) occurring the 5th day after the discharge. The patients have been called up in order to evaluate the problems occurring on the 5th day. The 55 persons that were applied mechanical compression have constituted the experimental group and the 59 patients that were applied manual compression have formed the control group. The patients volunteer to participate to the study have been informed in regard with the implementing procedures before the application. Descriptive statistics were shown in numbers and percentages for the variables obtained by counting and in mean ± standard deviation for variables obtained by measurement. RESULTS. The average of age is 52.70 ± 16.38 in the experimental group and is 47.62 ± 14.88 in the control group. The average of compression time is 39.66 ± 19.65 min in the experimental group and is 13.5 ± 5.03 min in the control group (p \ 0.05). The average of mobilization time after sheath removal is 103.36 ± 40.99 min in the experimental group and is 379.32 ± 50.37 min in the control group (p \ 0.05). It has been observed a lower pain level during compression and after sheath removal in patient that were applied mechanical compression in comparison to the patients that were applied manual compression(p \ 0.05). When the groups were compared in terms of femoral zone complications while no haematoma was observed in the experimental group, haematoma has been occurred in the 10.2% (n = 6) of the control group. CONCLUSIONS. The mechanical compression provides an earlier mobilization and earlier discharge of the patient. This study shows that mechanical compression is a method as safety as the manual method in order to obtain a haemostasis  A correlational survey was conducted in 6 public hospitals located in Athens. 143 critical care nurses completed anonymous questionnaires 4,5 , yielding a response rate of 63%. Greek critical care nurses believe that open visiting increases family's satisfaction (84.6%), exhausts family members (69.9%) and provides emotional support to the patient (89.5%); nevertheless the effects of visiting depend both on patient and family (91.6%). Furthermore open visiting hampers the planning of adequate nursing care (75.5%) and is not a helpful support for the caregivers (84.6%) while increases their physical and psychological burden (87.5%). Critical care nurses' attitudes toward visiting hours were rather negative and they didn't want to liberalize the visiting policy of their unit (94.4%). There was a positive correlation between nurses' beliefs and attitudes regarding visiting (r = 0.42, p \ 0.001, r = 0.45, p \ 0.001). The factors ''working experience'', ''adequacy in staff'' and ''the number of shifts'' were found to be independently correlated and they predicted the score of the 3 scales of the questionnaire.  Greek ICU nurses have rather negative beliefs and attitudes toward visiting and open visiting policy. This will be a challenging barrier to overcome when imposing new flexible policies in ICUs 6 . OBJECTIVES. Our aim was to elucidate potential mechanisms for the beneficial effects of rhAPC on ALI, as assessed by microarray analysis of lung tissue after sepsis induced by CLP in rats. METHODS. Sepsis (n = 14) was induced in rats by CLP. A sham-operated group (n = 5) underwent laparotomy and closure without CLP. A CLP group (n = 7) received subcutaneous saline (30 ml/kg) and a CLP + APC group (n = 7) additionally received 24 mg/kg rhAPC. Twelve hours postoperatively, lung tissue was preserved in mRNA later until mRNA isolation by Promega total RNA kit and analyzed using Illumina Beadarray. Data were Log2 variance stabilized and quantile normalized using the lumi package in R and the limma package was used for group comparisons and false discovery rate correction. Data were further analyzed using Panther and DAVID. The clinical outcomes of this study showed a marked attenuation of the sepsisinduced increase in lung permeability in rats treated with rhAPC 4 . Although no formal statistical significance was reached for the gene expression changes between the CLP and the CLP + APC groups, there was a clear attenuating effect of rhAPC on the changes in gene expression caused by sepsis reflected in generally lower fold change values and fewer significantly differentially regulated genes in the CLP + APC versus sham group compared to the non-treated CLP vs. sham group (153 vs. 863 genes). Nevertheless, there were only 18 genes of which the fold change difference between CLP versus sham and CLP + APC versus sham was more than one, indicating that although there was a large difference in the number of differentially expressed genes, the difference in fold change between these genes was small. CONCLUSIONS. These data suggest that the rhAPC treatment of septicemic rats does not only cause a down regulation of specific pathways as argued by previous investigators, but leads to a global reduction in the inflammatory response at a mRNA level. INTRODUCTION. Septic shock guidelines recommends the use of recombinant human activated C protein (ACP) in high risk mortality patients. The aim of our study is to describe the clinical characteristics, and the outcome of patients treated with ACP in our hospital. METHODS. Retrospective and descriptive study which includes patients with severe sepsis/ septic shock treated with PCA in a tertiary hospital Intensive Care Unit (ICU) over 5 years (2005-2009) . We analyze epidemiological data, reason for admission, infectious focus and agent, severity scores, organ failure, complications, stay and mortality. We used Chi-square analysis to compare categorical data and Student's t test to compare continuous variables. CONCLUSIONS. In our study most patients were admitted from emergency department, with organic failure caused by pneumonia. We haven't detected deaths related with ACP complications, even in patients undergoing surgery. We found as prognostic factors for mortality: organ dysfunction, ACP indication, renal failure, PaO 2 /FiO 2 relation, amount of vasopressors, bicarbonate and base deficit levels, APACHEII and ICU stay. OBJECTIVES. To analyze changes on hemodynamics in patients with severe sepsis treated with high volume hemofiltration (35 ml/kg/h) vs. patients treated with very high volume hemofiltration ([55 ml/kg/h). We conducted a prospective randomized trial from January to November 2009 in patients admitted into ICU with a diagnosis of septic shock in which HF was indicated. Patients were randomized to one of each group of therapy. The control group received high volume hemofiltration therapy and the experimental group received very high volume hemofiltration. The hemodynamic parameters were measured at the admittance in ICU and every 24 h onwards. RESULTS. Data of 30 patients were collected (21 men and 9 women) mean age 59 ± 13 years old. The hemodynamic parameters registered at the admittance and during the therapy had no significant difference between the groups. The control group received HF therapy during 6.4 ± 4.5 days and the intervention group 5.7 ± 3.1 days. There wasn't any difference either in the administration of vasoactive drugs between both groups. The most significant difference between the groups was the 28-day survival rate, 86.7% of the experimental group against 53.3% of the control group (p = 0.46). From these results we can conclude that very high volume hemofiltration therapy should be the therapy of election because it improves the survival of patients with severe sepsis without impairing the hemodynamic parameters. We have to point out the importance of the nursing staff in the assembly and management of the equipment as well as in the patient care and thus avoiding potential complications. INTRODUCTION. The use of herbal products is increasing, and may result in increased drug-herb interactions or form a potential for adverse reactions in cardiovascular surgery patients. OBJECTIVES. The aim of this study was to describe the utilization patterns for herbal products in patients with cardiovascular disease. METHODS. This was a descriptive study which was carried out among adult patients presenting to Cardiovascular Surgery Department for elective cardiac surgery between September 2009 and April 2010 in a research and training hospital. After giving informed consent, patients were interviewed by researchers using a structured survey instrument in the preoperative period. RESULTS. Interviews were conducted with 289 patients (mean age 68.12 ± 12.85, range: 45-79 years), 92% of them were married, 70% were men, and 62% of the patients had high school or university education. The majority (72%) had coronary artery disease and most of the patients (58%) had concomitant diabetes mellitus and hypertension. The most common used drugs were anti-hypertensives, NSAI's, and anti-aggregants. Most patients (84%) reported the regular use of drugs. Eighty-nine (31%) among the surveyed 289 patients reported the use of herbal products. The most common used herbal products were garlic (43%), apple vinegar (39%), lavandula stoechas (31%), cratageus (29%) and ginger-honey mixture (27%). The average educational degree of herbal product users was found to be higher when compared with the others. Many patients report being informed about those products from television, internet, newspapers, herbal-stores personal communications, and report the use of those products after the diagnosis is made. None of those patients have informed physicians or nursing staff about the use of those herbs. The demographic variables of patients and the herbal-product usage has failed to show a statistically significant difference (p [ 0.05). CONCLUSIONS. The use of herbal products is common among the patients with cardiovascular diseases. Health professionals should be aware of the usage of those products in order to prevent possible adverse reactions and drug-herb interactions. INTRODUCTION. Nurses employed in the ICU operate in a complex environment, under time pressure, and with limited information available. Thus, errors are inevitable and, besides their adverse consequences, they offer the potential for learning 1 . In this concept, properly copying with errors is a prerequisite for avoiding their recurrence and improving nursing practice. OBJECTIVES. Our aim was to investigate how error-copying strategies are associated with constructive and defensive changes in ICU nursing practice. METHODS. 62 questionnaires were completed (a 60% response rate) from nurses employed in the ICUs of adults, children, and the Coronary Care Unit of two Greek hospitals, between January-June 2007. ''Ways of copying'' scale as revised by Wu et al. 2 was used for evaluating copying strategies. This includes 6 copying subscales, each ranging between 0 and 9. Constructive changes in response to error included 7 items (paying more attention to detail, keeping better patient records, reading patient notes more carefully, seeking advice, discussing with colleagues about similar situations, devoting more observation on patients, reading for covering knowledge deficiencies), while defensive changes included 5 items (getting more worried, feeling less confident at work, being more likely not to discuss errors, being less trusting of others, thinking to leave profession.). A four-point Likert scale (0-3) was used for evaluating each item, and points were summed to estimate total scores of constructive and defensive changes. . 72.6% of participants were female and 87.1% were registered nurses. Mean (±SE) age was 36.2 ± 1.0 years and mean ICU experience was 11.9 ± 0.9 years. Multiple linear regressions with constructive and defensive changes in practice as dependent variables and copying strategies as independent variables are summarized in Table 1 . Participants were more likely to make constructive changes if they coped by seeking social support (p = 0.015) and accepting responsibility (p = 0.041). At the same time, they were more likely to make defensive changes if they coped by escape-avoidance (p = 0.029). Reasons for high risks are e.g. sedation and analgesia, immobility, malnutrition and hemodynamic or oxygenation problems as well as poor identification or unsystematic assessment of the risks. In our unit, we performed a 6 months retrospective review of pressure ulcer risks for all patients (n = 747) using Jackson-Cubbin calculator. The risk point level in this instrument is 29 and below. 314 patients of 747 (42%) exceeded the risk limit already in the ICU admission phase. OBJECTIVES. To change care practices of pressure ulcer prevention and care with action research. With the measurement tool nurses are able to identify patients at risk of developing pressure ulcers during the whole ICU in-patient time, and to prevent risks of pressure ulcer in an early stage. With the assessment tool, the measurement is systematic which enables the benchmarking and have effects on material recourse planning and cost caused by pressure ulcers. The study unit is a 24-bed ICU for adults taking care annually circa 1,800 patients with multiple disorders. Firstly, the Jackson-Cubbin pressure area risk calculator was translated into Finnish. A few changes which have an effect on pressure ulcer risk were added; weight limits were also defined with BMI values, Hyperbaric Oxygen Therapy was added in deducted points as well as 24 h limit for blood transfusions and limits for hypothermia from 35 Celsius or under. Secondly, standardized guidelines for different risk levels were developed; if patients have a high risk specialized mattresses should be used and changes of positions and beds should be stressed. Thirdly, an electronic evolution form for patient information system was planned and implemented. Finally, a systematic education program for ICU personnel including special lectures, material demonstrations and familiarization by the nurse responsible for wound care was started. RESULTS. After the development project and systematic education the knowledge of personnel about pressure ulcer risks and care has increased. Risk points are counted once a day for every patient using the electronic form. All the mattresses at the ICU have been changed to medium and high risk mattresses and are chosen for a patient related to the risk assessment points. CONCLUSIONS. A reliable assessment scale, systematic measurement and continuous evaluation and education are crucial for identification of high risk pressure ulcer patient at the ICUs. With a systematic measurement and recognizing high risk patients we can also improve patients' quality of life and reduce the cost caused by pressure ulcers. REFERENCE(S ) is considered to be one of the main agents in gram negative sepsis. In recent years several adsorption dispositives have been designed in order to achieve low blood endotoxin levels with a theorical clinical improvement. Toramyxin (polymixine B fixed to polyesthirene fibers) and Alteco LPS adsorber (polyethylene discs) are two of these dispositives. Both are used with 2 h sessions for several days until patient clinical improvement. • Design a nursery prothocol with the most important procedures in gram negative septic shock patients with acute renal failure that undergo adsorption cartridge therapy. • Evaluate initial experience in the use of endotoxin adsorption cartridges. METHODS. Nursery prothocol with special attention to the settlement and management of the cartridge therapy, based on library references and practice guidelines. Once prothocol was stablised, prospective observational study was started from January 2009 till January 2010. Inclusion criteria were: patients admitted to our intensive care department with gram negative confirmed septic shock and acute renal dysfunction requiring continuous renal replacement therapies (CRRT). Adsorptive cartridge were added and several parameters were studied: heart rate, mean blood pressure, vasopressor support (norepinephrine), PaO 2 / FiO 2 , and Lactate. The information was analyzed in Excel. RESULTS. Nursery protocol was correctly applied in all patients and showed to be basic in the maintenance and early complication detection. Hemodynamic improvement that allowed norepinephrine lowering dose and normalized lactate levels with no changes in PaO 2 /FiO 2 . Patient 1 (Toraymyxin): 55 years man, acute pancreatitis with septic shock. Patient 2 (Toraymyxin): 44 years man, pneumococic pneumonia and klebsiella septic shock. Patient 3(Alteco): 55 years man, acute pancreatitis with enterobacter cloacae septic shock. Patient 4 (Alteco): 60 years woman, acute peritonitis with E. Coli septic shock.  
